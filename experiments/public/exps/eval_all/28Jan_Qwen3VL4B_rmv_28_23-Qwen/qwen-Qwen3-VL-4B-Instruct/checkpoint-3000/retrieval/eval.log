/home/infres/zzhu-24/anaconda3/envs/vlm2vec_update/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec_update/lib/python3.10/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
[2026-01-29 11:20:20,593] INFO [src.utils:21] Distributed init debug info:
[2026-01-29 11:20:20,594] INFO [src.utils:21] RANK: None
[2026-01-29 11:20:20,594] INFO [src.utils:21] LOCAL_RANK: None
[2026-01-29 11:20:20,594] INFO [src.utils:21] WORLD_SIZE: None
[2026-01-29 11:20:20,594] INFO [src.utils:21] MASTER_ADDR: None
[2026-01-29 11:20:20,594] INFO [src.utils:21] MASTER_PORT: None
/home/infres/zzhu-24/anaconda3/envs/vlm2vec_update/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
[2026-01-29 11:20:22,278] INFO [src.utils:21] Model Backbone: qwen3_vl
[2026-01-29 11:20:22,278] INFO [src.utils:21] Loading processor from: /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/28Jan_Qwen3VL4B_rmv_28_23-Qwen/Qwen3-VL-4B-Instruct/checkpoint-3000
[2026-01-29 11:20:24,279] INFO [src.utils:21] Loading backbone [qwen3_vl] from /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/28Jan_Qwen3VL4B_rmv_28_23-Qwen/Qwen3-VL-4B-Instruct/checkpoint-3000
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 20.54it/s]
[2026-01-29 11:20:24,809] INFO [src.utils:21] Loading LoRA from /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/28Jan_Qwen3VL4B_rmv_28_23-Qwen/Qwen3-VL-4B-Instruct/checkpoint-3000
[2026-01-29 11:20:44,645] INFO [src.utils:21] [rank=0] Loading the model from Huggingface: Qwen/Qwen3-VL-4B-Instruct...
[2026-01-29 11:20:44,656] INFO [src.utils:21] --- Evaluating MSCOCO_i2t ---
Map (num_proc=4): 100%|██████████| 1000/1000 [00:00<?, ? examples/s]Map (num_proc=4): 1250 examples [00:00, 319.79 examples/s]          Map (num_proc=4): 2000 examples [00:02, 481.08 examples/s]Map (num_proc=4): 2000 examples [00:02, 398.02 examples/s]
[2026-01-29 11:20:53,362] INFO [src.utils:21] Encoding queries...
Queries for MSCOCO_i2t (rank 0):   0%|          | 0/125 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/infres/zzhu-24/anaconda3/envs/vlm2vec_update/lib/python3.10/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
Queries for MSCOCO_i2t (rank 0):   1%|          | 1/125 [28:48<59:32:23, 1728.58s/it]Queries for MSCOCO_i2t (rank 0):   2%|▏         | 2/125 [56:24<57:35:48, 1685.76s/it]Queries for MSCOCO_i2t (rank 0):   2%|▏         | 3/125 [1:28:15<60:37:01, 1788.70s/it]Queries for MSCOCO_i2t (rank 0):   3%|▎         | 4/125 [1:53:51<56:46:03, 1688.95s/it]Queries for MSCOCO_i2t (rank 0):   4%|▍         | 5/125 [2:19:20<54:22:42, 1631.35s/it]Queries for MSCOCO_i2t (rank 0):   5%|▍         | 6/125 [2:48:23<55:10:22, 1669.09s/it]Queries for MSCOCO_i2t (rank 0):   6%|▌         | 7/125 [3:14:48<53:48:45, 1641.74s/it]Queries for MSCOCO_i2t (rank 0):   6%|▋         | 8/125 [3:41:00<52:38:15, 1619.62s/it]Queries for MSCOCO_i2t (rank 0):   7%|▋         | 9/125 [4:06:30<51:16:51, 1591.48s/it]Queries for MSCOCO_i2t (rank 0):   8%|▊         | 10/125 [4:32:49<50:42:54, 1587.60s/it]Queries for MSCOCO_i2t (rank 0):   9%|▉         | 11/125 [4:59:24<50:20:44, 1589.87s/it]Queries for MSCOCO_i2t (rank 0):  10%|▉         | 12/125 [5:28:48<51:34:20, 1643.01s/it]Queries for MSCOCO_i2t (rank 0):  10%|█         | 13/125 [5:57:24<51:47:52, 1664.93s/it]Queries for MSCOCO_i2t (rank 0):  11%|█         | 14/125 [6:24:41<51:04:45, 1656.62s/it]Queries for MSCOCO_i2t (rank 0):  12%|█▏        | 15/125 [6:53:23<51:13:04, 1676.23s/it]Queries for MSCOCO_i2t (rank 0):  13%|█▎        | 16/125 [7:21:37<50:54:48, 1681.55s/it]Queries for MSCOCO_i2t (rank 0):  14%|█▎        | 17/125 [7:47:58<49:32:13, 1651.23s/it]Queries for MSCOCO_i2t (rank 0):  14%|█▍        | 18/125 [8:14:18<48:26:49, 1629.99s/it]Queries for MSCOCO_i2t (rank 0):  15%|█▌        | 19/125 [8:42:39<48:37:30, 1651.42s/it]Queries for MSCOCO_i2t (rank 0):  16%|█▌        | 20/125 [9:11:21<48:47:04, 1672.61s/it]Queries for MSCOCO_i2t (rank 0):  17%|█▋        | 21/125 [9:37:42<47:31:05, 1644.86s/it]Queries for MSCOCO_i2t (rank 0):  18%|█▊        | 22/125 [10:03:38<46:18:12, 1618.37s/it]Queries for MSCOCO_i2t (rank 0):  18%|█▊        | 23/125 [10:32:20<46:44:14, 1649.56s/it]Queries for MSCOCO_i2t (rank 0):  19%|█▉        | 24/125 [10:59:44<46:13:39, 1647.72s/it]Queries for MSCOCO_i2t (rank 0):  20%|██        | 25/125 [11:29:14<46:47:31, 1684.52s/it]Queries for MSCOCO_i2t (rank 0):  21%|██        | 26/125 [11:58:16<46:47:37, 1701.59s/it]Queries for MSCOCO_i2t (rank 0):  22%|██▏       | 27/125 [12:23:38<44:51:29, 1647.85s/it]Queries for MSCOCO_i2t (rank 0):  22%|██▏       | 28/125 [12:48:55<43:20:35, 1608.61s/it]Queries for MSCOCO_i2t (rank 0):  23%|██▎       | 29/125 [13:15:00<42:32:53, 1595.55s/it]Queries for MSCOCO_i2t (rank 0):  24%|██▍       | 30/125 [13:40:53<41:45:56, 1582.70s/it]Queries for MSCOCO_i2t (rank 0):  25%|██▍       | 31/125 [14:09:55<42:34:26, 1630.50s/it]Queries for MSCOCO_i2t (rank 0):  26%|██▌       | 32/125 [14:36:23<41:47:26, 1617.70s/it]Queries for MSCOCO_i2t (rank 0):  26%|██▋       | 33/125 [15:03:11<41:16:15, 1614.95s/it]Queries for MSCOCO_i2t (rank 0):  27%|██▋       | 34/125 [15:29:16<40:26:21, 1599.80s/it]Queries for MSCOCO_i2t (rank 0):  28%|██▊       | 35/125 [15:55:20<39:43:31, 1589.02s/it]Queries for MSCOCO_i2t (rank 0):  29%|██▉       | 36/125 [16:21:11<39:00:09, 1577.63s/it]Queries for MSCOCO_i2t (rank 0):  30%|██▉       | 37/125 [16:51:27<40:18:46, 1649.16s/it]Queries for MSCOCO_i2t (rank 0):  30%|███       | 38/125 [17:17:56<39:25:10, 1631.16s/it]Queries for MSCOCO_i2t (rank 0):  31%|███       | 39/125 [17:48:32<40:26:00, 1692.56s/it]Queries for MSCOCO_i2t (rank 0):  32%|███▏      | 40/125 [18:14:52<39:10:06, 1658.90s/it]Queries for MSCOCO_i2t (rank 0):  33%|███▎      | 41/125 [18:40:56<38:02:40, 1630.48s/it]Queries for MSCOCO_i2t (rank 0):  34%|███▎      | 42/125 [19:07:15<37:14:09, 1615.06s/it]Queries for MSCOCO_i2t (rank 0):  34%|███▍      | 43/125 [19:34:16<36:49:35, 1616.77s/it]Queries for MSCOCO_i2t (rank 0):  35%|███▌      | 44/125 [19:59:53<35:50:16, 1592.80s/it]Queries for MSCOCO_i2t (rank 0):  36%|███▌      | 45/125 [20:24:28<34:36:36, 1557.46s/it]Queries for MSCOCO_i2t (rank 0):  37%|███▋      | 46/125 [20:52:04<34:49:42, 1587.12s/it]Queries for MSCOCO_i2t (rank 0):  38%|███▊      | 47/125 [21:18:22<34:19:40, 1584.37s/it]Queries for MSCOCO_i2t (rank 0):  38%|███▊      | 48/125 [21:44:20<33:42:53, 1576.28s/it]Queries for MSCOCO_i2t (rank 0):  39%|███▉      | 49/125 [22:10:17<33:09:30, 1570.67s/it]Queries for MSCOCO_i2t (rank 0):  40%|████      | 50/125 [22:36:30<32:43:57, 1571.17s/it]Queries for MSCOCO_i2t (rank 0):  41%|████      | 51/125 [23:02:59<32:24:19, 1576.48s/it]Queries for MSCOCO_i2t (rank 0):  42%|████▏     | 52/125 [23:29:06<31:54:34, 1573.63s/it]Queries for MSCOCO_i2t (rank 0):  42%|████▏     | 53/125 [23:56:31<31:54:17, 1595.24s/it]