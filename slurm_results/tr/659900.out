==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/13Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name 13Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/13Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 1e-5 --max_steps 6000 --warmup_steps 100 --save_steps 500 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/13Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/train.log
W1113 02:06:46.600000 125964460894016 torch/distributed/run.py:779] 
W1113 02:06:46.600000 125964460894016 torch/distributed/run.py:779] *****************************************
W1113 02:06:46.600000 125964460894016 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1113 02:06:46.600000 125964460894016 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!DropoutAddRMSNorm of flash_attn is not installed!!!

/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-11-13 02:06:54,407] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.72it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.98it/s]
wandb: setting up run cnaoiasa
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/13Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251113_020654-cnaoiasa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 13Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/cnaoiasa
[2025-11-13 02:06:55,882] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.88it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.25it/s]
[2025-11-13 02:06:56,484] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-11-13 02:07:02,866] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-11-13 02:07:04,010] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-11-13 02:07:04,011] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-11-13 02:07:07,678] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-11-13 02:07:07,680] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-11-13 02:07:08,461] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-11-13 02:07:08,461] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-11-13 02:07:08,462] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-11-13 02:07:08,462] INFO [src.utils:19] ==================================================
[2025-11-13 02:07:08,463] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-11-13 02:07:08,463] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-13 02:07:08,464] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-13 02:07:08,464] INFO [src.utils:19] ==================================================
[2025-11-13 02:07:10,430] INFO [src.trainer:350] ***** Running training *****
[2025-11-13 02:07:10,430] INFO [src.trainer:350] ***** Running training *****
[2025-11-13 02:07:10,430] INFO [src.trainer:351]   Num examples = 192,000
[2025-11-13 02:07:10,430] INFO [src.trainer:352]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-13 02:07:10,430] INFO [src.trainer:353]   Instantaneous batch size per device = 16
[2025-11-13 02:07:10,430] INFO [src.trainer:356]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-13 02:07:10,430] INFO [src.trainer:357]   Gradient Accumulation steps = 1
[2025-11-13 02:07:10,430] INFO [src.trainer:358]   Total optimization steps = 6,000
[2025-11-13 02:07:10,430] INFO [src.trainer:351]   Num examples = 192,000
[2025-11-13 02:07:10,431] INFO [src.trainer:352]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-13 02:07:10,431] INFO [src.trainer:353]   Instantaneous batch size per device = 16
[2025-11-13 02:07:10,431] INFO [src.trainer:356]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-13 02:07:10,431] INFO [src.trainer:357]   Gradient Accumulation steps = 1
[2025-11-13 02:07:10,432] INFO [src.trainer:358]   Total optimization steps = 6,000
[2025-11-13 02:07:10,434] INFO [src.trainer:359]   Number of trainable parameters = 9,205,248
[2025-11-13 02:07:10,436] INFO [src.trainer:359]   Number of trainable parameters = 9,205,248
[2025-11-13 02:07:10,437] INFO [src.trainer:360]   Trainable Parameters = ['module.tail_token', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-11-13 02:07:10,439] INFO [src.trainer:360]   Trainable Parameters = ['module.tail_token', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[2025-11-13 02:07:11,219] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:11,221] INFO [src.utils:19] ------------
[2025-11-13 02:07:11,222] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[rank0]:[W1113 02:07:13.595582722 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1113 02:07:13.608875726 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/6000 [00:03<5:34:15,  3.34s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.1919564460404217e-05, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:03<5:34:15,  3.34s/it][2025-11-13 02:07:13,811] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:13,811] INFO [src.utils:19] ------------
[2025-11-13 02:07:13,811] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 2/6000 [00:05<4:09:41,  2.50s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.1919564460404217e-05, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}
  0%|          | 2/6000 [00:05<4:09:41,  2.50s/it][2025-11-13 02:07:15,717] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:15,717] INFO [src.utils:19] ------------
[2025-11-13 02:07:15,717] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 3/6000 [00:07<3:50:47,  2.31s/it]                                                  {'loss': 3.4657, 'grad_norm': 1.946486736414954e-05, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.0}
  0%|          | 3/6000 [00:07<3:50:47,  2.31s/it][2025-11-13 02:07:17,802] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:17,803] INFO [src.utils:19] ------------
[2025-11-13 02:07:17,803] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 4/6000 [00:09<3:37:01,  2.17s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.0906894860672764e-05, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.0}
  0%|          | 4/6000 [00:09<3:37:01,  2.17s/it][2025-11-13 02:07:19,761] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:19,761] INFO [src.utils:19] ------------
[2025-11-13 02:07:19,762] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 5/6000 [00:11<3:32:20,  2.13s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.1899006242165342e-05, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 5/6000 [00:11<3:32:20,  2.13s/it][2025-11-13 02:07:21,803] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:21,804] INFO [src.utils:19] ------------
[2025-11-13 02:07:21,805] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 6/6000 [00:13<3:27:45,  2.08s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.0569152184179984e-05, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.0}
  0%|          | 6/6000 [00:13<3:27:45,  2.08s/it][2025-11-13 02:07:23,797] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:23,798] INFO [src.utils:19] ------------
[2025-11-13 02:07:23,798] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 7/6000 [00:15<3:24:11,  2.04s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.0673243852797896e-05, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.0}
  0%|          | 7/6000 [00:15<3:24:11,  2.04s/it][2025-11-13 02:07:25,772] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:25,773] INFO [src.utils:19] ------------
[2025-11-13 02:07:25,773] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 8/6000 [00:17<3:20:55,  2.01s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.145716098311823e-05, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.0}
  0%|          | 8/6000 [00:17<3:20:55,  2.01s/it][2025-11-13 02:07:27,712] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:27,712] INFO [src.utils:19] ------------
[2025-11-13 02:07:27,713] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 9/6000 [00:19<3:23:50,  2.04s/it]                                                  {'loss': 3.4657, 'grad_norm': 2.1039395505795255e-05, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.0}
  0%|          | 9/6000 [00:19<3:23:50,  2.04s/it][2025-11-13 02:07:29,817] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:29,817] INFO [src.utils:19] ------------
[2025-11-13 02:07:29,818] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 10/6000 [00:21<3:22:16,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.3158378351363353e-05, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:21<3:22:16,  2.03s/it][2025-11-13 02:07:31,808] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:31,809] INFO [src.utils:19] ------------
[2025-11-13 02:07:31,809] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 11/6000 [00:23<3:22:52,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.108160697389394e-05, 'learning_rate': 1.1e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:23<3:22:52,  2.03s/it][2025-11-13 02:07:33,856] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:33,857] INFO [src.utils:19] ------------
[2025-11-13 02:07:33,857] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 12/6000 [00:25<3:25:18,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1258405467960984e-05, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:25<3:25:18,  2.06s/it][2025-11-13 02:07:35,967] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:35,968] INFO [src.utils:19] ------------
[2025-11-13 02:07:35,968] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 13/6000 [00:27<3:23:53,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0891593521810137e-05, 'learning_rate': 1.3e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:27<3:23:53,  2.04s/it][2025-11-13 02:07:37,978] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:37,979] INFO [src.utils:19] ------------
[2025-11-13 02:07:37,979] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 14/6000 [00:29<3:24:34,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1494277461897582e-05, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:29<3:24:34,  2.05s/it][2025-11-13 02:07:40,047] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:40,047] INFO [src.utils:19] ------------
[2025-11-13 02:07:40,048] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 15/6000 [00:31<3:24:41,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.045704604825005e-05, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:31<3:24:41,  2.05s/it][2025-11-13 02:07:42,101] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:42,101] INFO [src.utils:19] ------------
[2025-11-13 02:07:42,102] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 16/6000 [00:33<3:22:45,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1583764464594424e-05, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:33<3:22:45,  2.03s/it][2025-11-13 02:07:44,094] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:44,094] INFO [src.utils:19] ------------
[2025-11-13 02:07:44,094] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 17/6000 [00:35<3:22:25,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1943407773505896e-05, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:35<3:22:25,  2.03s/it][2025-11-13 02:07:46,123] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:46,124] INFO [src.utils:19] ------------
[2025-11-13 02:07:46,125] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 18/6000 [00:37<3:23:13,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.2257761884247884e-05, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.0}
  0%|          | 18/6000 [00:37<3:23:13,  2.04s/it][2025-11-13 02:07:48,178] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:48,178] INFO [src.utils:19] ------------
[2025-11-13 02:07:48,179] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 19/6000 [00:39<3:20:41,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1842162823304534e-05, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.0}
  0%|          | 19/6000 [00:39<3:20:41,  2.01s/it][2025-11-13 02:07:50,130] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:50,130] INFO [src.utils:19] ------------
[2025-11-13 02:07:50,130] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 20/6000 [00:41<3:22:48,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.904087548609823e-05, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 20/6000 [00:41<3:22:48,  2.03s/it][2025-11-13 02:07:52,215] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:52,215] INFO [src.utils:19] ------------
[2025-11-13 02:07:52,216] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 21/6000 [00:43<3:22:31,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.2309041014523245e-05, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.0}
  0%|          | 21/6000 [00:43<3:22:31,  2.03s/it][2025-11-13 02:07:54,241] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:54,242] INFO [src.utils:19] ------------
[2025-11-13 02:07:54,242] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 22/6000 [00:45<3:23:24,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.00995691557182e-05, 'learning_rate': 2.2e-06, 'epoch': 0.0}
  0%|          | 22/6000 [00:45<3:23:24,  2.04s/it][2025-11-13 02:07:56,306] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:56,307] INFO [src.utils:19] ------------
[2025-11-13 02:07:56,307] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 23/6000 [00:47<3:22:17,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.193771979364101e-05, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.0}
  0%|          | 23/6000 [00:47<3:22:17,  2.03s/it][2025-11-13 02:07:58,305] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:07:58,305] INFO [src.utils:19] ------------
[2025-11-13 02:07:58,306] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 24/6000 [00:49<3:25:49,  2.07s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.091385431413073e-05, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.0}
  0%|          | 24/6000 [00:49<3:25:49,  2.07s/it][2025-11-13 02:08:00,468] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:00,470] INFO [src.utils:19] ------------
[2025-11-13 02:08:00,470] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 25/6000 [00:51<3:23:52,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.885481469798833e-05, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 25/6000 [00:51<3:23:52,  2.05s/it][2025-11-13 02:08:02,463] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:02,463] INFO [src.utils:19] ------------
[2025-11-13 02:08:02,463] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 26/6000 [00:53<3:22:13,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.978354157472495e-05, 'learning_rate': 2.6e-06, 'epoch': 0.0}
  0%|          | 26/6000 [00:53<3:22:13,  2.03s/it][2025-11-13 02:08:04,457] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:04,457] INFO [src.utils:19] ------------
[2025-11-13 02:08:04,458] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 27/6000 [00:56<3:22:04,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0343022697488777e-05, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.0}
  0%|          | 27/6000 [00:56<3:22:04,  2.03s/it][2025-11-13 02:08:06,478] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:06,478] INFO [src.utils:19] ------------
[2025-11-13 02:08:06,479] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 28/6000 [00:58<3:31:18,  2.12s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1725310944020748e-05, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.0}
  0%|          | 28/6000 [00:58<3:31:18,  2.12s/it][2025-11-13 02:08:08,819] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:08,820] INFO [src.utils:19] ------------
[2025-11-13 02:08:08,820] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 29/6000 [01:00<3:28:43,  2.10s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.2793154130340554e-05, 'learning_rate': 2.9e-06, 'epoch': 0.0}
  0%|          | 29/6000 [01:00<3:28:43,  2.10s/it][2025-11-13 02:08:10,856] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:10,857] INFO [src.utils:19] ------------
[2025-11-13 02:08:10,857] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 30/6000 [01:02<3:25:15,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.3288601369131356e-05, 'learning_rate': 3e-06, 'epoch': 0.01}
  0%|          | 30/6000 [01:02<3:25:15,  2.06s/it][2025-11-13 02:08:12,837] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:12,838] INFO [src.utils:19] ------------
[2025-11-13 02:08:12,838] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 31/6000 [01:04<3:26:20,  2.07s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1401821868494153e-05, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.01}
  1%|          | 31/6000 [01:04<3:26:20,  2.07s/it][2025-11-13 02:08:14,945] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:14,945] INFO [src.utils:19] ------------
[2025-11-13 02:08:14,946] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 32/6000 [01:06<3:25:11,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.011478500207886e-05, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.01}
  1%|          | 32/6000 [01:06<3:25:11,  2.06s/it][2025-11-13 02:08:16,981] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:16,982] INFO [src.utils:19] ------------
[2025-11-13 02:08:16,982] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 33/6000 [01:08<3:23:49,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1782600015285425e-05, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.01}
  1%|          | 33/6000 [01:08<3:23:49,  2.05s/it][2025-11-13 02:08:18,998] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:18,998] INFO [src.utils:19] ------------
[2025-11-13 02:08:18,999] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 34/6000 [01:10<3:21:55,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1266143448883668e-05, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.01}
  1%|          | 34/6000 [01:10<3:21:55,  2.03s/it][2025-11-13 02:08:20,979] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:20,979] INFO [src.utils:19] ------------
[2025-11-13 02:08:20,980] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 35/6000 [01:12<3:22:59,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.170552033931017e-05, 'learning_rate': 3.5e-06, 'epoch': 0.01}
  1%|          | 35/6000 [01:12<3:22:59,  2.04s/it][2025-11-13 02:08:23,061] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:23,062] INFO [src.utils:19] ------------
[2025-11-13 02:08:23,062] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 36/6000 [01:14<3:22:26,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.867047649284359e-05, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.01}
  1%|          | 36/6000 [01:14<3:22:26,  2.04s/it][2025-11-13 02:08:25,088] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:25,088] INFO [src.utils:19] ------------
[2025-11-13 02:08:25,089] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 37/6000 [01:16<3:23:54,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1066975023131818e-05, 'learning_rate': 3.7e-06, 'epoch': 0.01}
  1%|          | 37/6000 [01:16<3:23:54,  2.05s/it][2025-11-13 02:08:27,166] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:27,167] INFO [src.utils:19] ------------
[2025-11-13 02:08:27,167] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 38/6000 [01:18<3:20:20,  2.02s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.7742124327924103e-05, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.01}
  1%|          | 38/6000 [01:18<3:20:20,  2.02s/it][2025-11-13 02:08:29,095] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:29,096] INFO [src.utils:19] ------------
[2025-11-13 02:08:29,096] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 39/6000 [01:20<3:18:13,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1656798708136193e-05, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.01}
  1%|          | 39/6000 [01:20<3:18:13,  2.00s/it][2025-11-13 02:08:31,038] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:31,039] INFO [src.utils:19] ------------
[2025-11-13 02:08:31,039] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 40/6000 [01:22<3:18:55,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0572368157445453e-05, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 40/6000 [01:22<3:18:55,  2.00s/it][2025-11-13 02:08:33,060] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:33,060] INFO [src.utils:19] ------------
[2025-11-13 02:08:33,061] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 41/6000 [01:24<3:17:02,  1.98s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1025382011430338e-05, 'learning_rate': 4.1e-06, 'epoch': 0.01}
  1%|          | 41/6000 [01:24<3:17:02,  1.98s/it][2025-11-13 02:08:35,003] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:35,003] INFO [src.utils:19] ------------
[2025-11-13 02:08:35,004] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 42/6000 [01:26<3:15:49,  1.97s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.2470618205261417e-05, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.01}
  1%|          | 42/6000 [01:26<3:15:49,  1.97s/it][2025-11-13 02:08:36,946] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:36,947] INFO [src.utils:19] ------------
[2025-11-13 02:08:36,947] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 43/6000 [01:28<3:29:07,  2.11s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0189731003483757e-05, 'learning_rate': 4.3e-06, 'epoch': 0.01}
  1%|          | 43/6000 [01:28<3:29:07,  2.11s/it][2025-11-13 02:08:39,362] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:39,362] INFO [src.utils:19] ------------
[2025-11-13 02:08:39,363] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 44/6000 [01:30<3:28:21,  2.10s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.030094947258476e-05, 'learning_rate': 4.4e-06, 'epoch': 0.01}
  1%|          | 44/6000 [01:30<3:28:21,  2.10s/it][2025-11-13 02:08:41,445] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:41,446] INFO [src.utils:19] ------------
[2025-11-13 02:08:41,446] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 45/6000 [01:32<3:25:09,  2.07s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0272855181246996e-05, 'learning_rate': 4.5e-06, 'epoch': 0.01}
  1%|          | 45/6000 [01:32<3:25:09,  2.07s/it][2025-11-13 02:08:43,447] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:43,447] INFO [src.utils:19] ------------
[2025-11-13 02:08:43,448] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 46/6000 [01:35<3:24:33,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1023170120315626e-05, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.01}
  1%|          | 46/6000 [01:35<3:24:33,  2.06s/it][2025-11-13 02:08:45,491] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:45,491] INFO [src.utils:19] ------------
[2025-11-13 02:08:45,492] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 47/6000 [01:37<3:23:53,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.100210804201197e-05, 'learning_rate': 4.7e-06, 'epoch': 0.01}
  1%|          | 47/6000 [01:37<3:23:53,  2.06s/it][2025-11-13 02:08:47,530] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:47,531] INFO [src.utils:19] ------------
[2025-11-13 02:08:47,531] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 48/6000 [01:39<3:22:32,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1315738194971345e-05, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.01}
  1%|          | 48/6000 [01:39<3:22:32,  2.04s/it][2025-11-13 02:08:49,537] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:49,537] INFO [src.utils:19] ------------
[2025-11-13 02:08:49,538] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 49/6000 [01:41<3:21:57,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.8941051166621037e-05, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.01}
  1%|          | 49/6000 [01:41<3:21:57,  2.04s/it][2025-11-13 02:08:51,569] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:51,570] INFO [src.utils:19] ------------
[2025-11-13 02:08:51,570] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 50/6000 [01:43<3:22:37,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0420409782673232e-05, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 50/6000 [01:43<3:22:37,  2.04s/it][2025-11-13 02:08:53,619] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:53,620] INFO [src.utils:19] ------------
[2025-11-13 02:08:53,620] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 51/6000 [01:45<3:19:41,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.048236819973681e-05, 'learning_rate': 5.1e-06, 'epoch': 0.01}
  1%|          | 51/6000 [01:45<3:19:41,  2.01s/it][2025-11-13 02:08:55,569] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:55,570] INFO [src.utils:19] ------------
[2025-11-13 02:08:55,570] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 52/6000 [01:47<3:17:26,  1.99s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.081499587802682e-05, 'learning_rate': 5.2e-06, 'epoch': 0.01}
  1%|          | 52/6000 [01:47<3:17:26,  1.99s/it][2025-11-13 02:08:57,512] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:57,513] INFO [src.utils:19] ------------
[2025-11-13 02:08:57,513] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 53/6000 [01:49<3:18:16,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0379551642690785e-05, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.01}
  1%|          | 53/6000 [01:49<3:18:16,  2.00s/it][2025-11-13 02:08:59,529] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:08:59,529] INFO [src.utils:19] ------------
[2025-11-13 02:08:59,529] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 54/6000 [01:51<3:21:45,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.127014522557147e-05, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.01}
  1%|          | 54/6000 [01:51<3:21:45,  2.04s/it][2025-11-13 02:09:01,657] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:01,658] INFO [src.utils:19] ------------
[2025-11-13 02:09:01,659] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 55/6000 [01:53<3:21:03,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.055160621239338e-05, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.01}
  1%|          | 55/6000 [01:53<3:21:03,  2.03s/it][2025-11-13 02:09:03,661] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:03,661] INFO [src.utils:19] ------------
[2025-11-13 02:09:03,661] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 56/6000 [01:55<3:18:40,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1129675587872043e-05, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.01}
  1%|          | 56/6000 [01:55<3:18:40,  2.01s/it][2025-11-13 02:09:05,614] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:05,615] INFO [src.utils:19] ------------
[2025-11-13 02:09:05,615] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 57/6000 [01:57<3:19:49,  2.02s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.000844688154757e-05, 'learning_rate': 5.7e-06, 'epoch': 0.01}
  1%|          | 57/6000 [01:57<3:19:49,  2.02s/it][2025-11-13 02:09:07,665] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:07,666] INFO [src.utils:19] ------------
[2025-11-13 02:09:07,666] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 58/6000 [01:59<3:19:20,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1958114302833565e-05, 'learning_rate': 5.8e-06, 'epoch': 0.01}
  1%|          | 58/6000 [01:59<3:19:20,  2.01s/it][2025-11-13 02:09:09,657] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:09,658] INFO [src.utils:19] ------------
[2025-11-13 02:09:09,658] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 59/6000 [02:01<3:18:07,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0879608200630173e-05, 'learning_rate': 5.9e-06, 'epoch': 0.01}
  1%|          | 59/6000 [02:01<3:18:07,  2.00s/it][2025-11-13 02:09:11,635] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:11,635] INFO [src.utils:19] ------------
[2025-11-13 02:09:11,636] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 60/6000 [02:03<3:17:55,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.9899522158084437e-05, 'learning_rate': 6e-06, 'epoch': 0.01}
  1%|          | 60/6000 [02:03<3:17:55,  2.00s/it][2025-11-13 02:09:13,632] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:13,632] INFO [src.utils:19] ------------
[2025-11-13 02:09:13,633] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 61/6000 [02:05<3:16:38,  1.99s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.219770431111101e-05, 'learning_rate': 6.1e-06, 'epoch': 0.01}
  1%|          | 61/6000 [02:05<3:16:38,  1.99s/it][2025-11-13 02:09:15,588] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:15,589] INFO [src.utils:19] ------------
[2025-11-13 02:09:15,589] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 62/6000 [02:07<3:19:45,  2.02s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.403157122898847e-05, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.01}
  1%|          | 62/6000 [02:07<3:19:45,  2.02s/it][2025-11-13 02:09:17,675] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:17,675] INFO [src.utils:19] ------------
[2025-11-13 02:09:17,675] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 63/6000 [02:09<3:18:52,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.019858584390022e-05, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.01}
  1%|          | 63/6000 [02:09<3:18:52,  2.01s/it][2025-11-13 02:09:19,663] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:19,664] INFO [src.utils:19] ------------
[2025-11-13 02:09:19,664] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 64/6000 [02:11<3:16:04,  1.98s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1481268049683422e-05, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.01}
  1%|          | 64/6000 [02:11<3:16:04,  1.98s/it][2025-11-13 02:09:21,587] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:21,588] INFO [src.utils:19] ------------
[2025-11-13 02:09:21,588] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 65/6000 [02:13<3:18:14,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1900885258219205e-05, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.01}
  1%|          | 65/6000 [02:13<3:18:14,  2.00s/it][2025-11-13 02:09:23,639] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:23,640] INFO [src.utils:19] ------------
[2025-11-13 02:09:23,640] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 66/6000 [02:15<3:21:04,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1021773136453703e-05, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.01}
  1%|          | 66/6000 [02:15<3:21:04,  2.03s/it][2025-11-13 02:09:25,743] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:25,744] INFO [src.utils:19] ------------
[2025-11-13 02:09:25,745] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 67/6000 [02:17<3:19:54,  2.02s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.125393075402826e-05, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.01}
  1%|          | 67/6000 [02:17<3:19:54,  2.02s/it][2025-11-13 02:09:27,733] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:27,733] INFO [src.utils:19] ------------
[2025-11-13 02:09:27,733] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 68/6000 [02:19<3:18:08,  2.00s/it]                                                   {'loss': 3.4657, 'grad_norm': 1.9492725186864845e-05, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.01}
  1%|          | 68/6000 [02:19<3:18:08,  2.00s/it][2025-11-13 02:09:29,695] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:29,696] INFO [src.utils:19] ------------
[2025-11-13 02:09:29,696] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 69/6000 [02:21<3:19:08,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.060338738374412e-05, 'learning_rate': 6.9e-06, 'epoch': 0.01}
  1%|          | 69/6000 [02:21<3:19:08,  2.01s/it][2025-11-13 02:09:31,733] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:31,733] INFO [src.utils:19] ------------
[2025-11-13 02:09:31,734] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 70/6000 [02:23<3:18:56,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.037698322965298e-05, 'learning_rate': 7e-06, 'epoch': 0.01}
  1%|          | 70/6000 [02:23<3:18:56,  2.01s/it][2025-11-13 02:09:33,755] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:33,755] INFO [src.utils:19] ------------
[2025-11-13 02:09:33,756] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 71/6000 [02:25<3:18:28,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.170937841583509e-05, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.01}
  1%|          | 71/6000 [02:25<3:18:28,  2.01s/it][2025-11-13 02:09:35,741] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:35,742] INFO [src.utils:19] ------------
[2025-11-13 02:09:35,742] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 72/6000 [02:27<3:20:37,  2.03s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.2804102627560496e-05, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.01}
  1%|          | 72/6000 [02:27<3:20:37,  2.03s/it][2025-11-13 02:09:37,825] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:37,825] INFO [src.utils:19] ------------
[2025-11-13 02:09:37,825] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 73/6000 [02:29<3:18:55,  2.01s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.184114964620676e-05, 'learning_rate': 7.3e-06, 'epoch': 0.01}
  1%|          | 73/6000 [02:29<3:18:55,  2.01s/it][2025-11-13 02:09:39,797] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:39,798] INFO [src.utils:19] ------------
[2025-11-13 02:09:39,798] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 74/6000 [02:31<3:19:03,  2.02s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1030004063504748e-05, 'learning_rate': 7.4e-06, 'epoch': 0.01}
  1%|          | 74/6000 [02:31<3:19:03,  2.02s/it][2025-11-13 02:09:41,832] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:41,833] INFO [src.utils:19] ------------
[2025-11-13 02:09:41,834] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 75/6000 [02:33<3:19:13,  2.02s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0561657947837375e-05, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.01}
  1%|â–         | 75/6000 [02:33<3:19:13,  2.02s/it][2025-11-13 02:09:43,845] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:43,846] INFO [src.utils:19] ------------
[2025-11-13 02:09:43,846] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 76/6000 [02:35<3:26:08,  2.09s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.2243208150030114e-05, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.01}
  1%|â–         | 76/6000 [02:35<3:26:08,  2.09s/it][2025-11-13 02:09:46,094] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:46,095] INFO [src.utils:19] ------------
[2025-11-13 02:09:46,095] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 77/6000 [02:37<3:32:09,  2.15s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0023706383653916e-05, 'learning_rate': 7.7e-06, 'epoch': 0.01}
  1%|â–         | 77/6000 [02:37<3:32:09,  2.15s/it][2025-11-13 02:09:48,384] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:48,384] INFO [src.utils:19] ------------
[2025-11-13 02:09:48,385] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 78/6000 [02:39<3:29:15,  2.12s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1778223526780494e-05, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.01}
  1%|â–         | 78/6000 [02:39<3:29:15,  2.12s/it][2025-11-13 02:09:50,440] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:50,441] INFO [src.utils:19] ------------
[2025-11-13 02:09:50,441] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 79/6000 [02:41<3:25:47,  2.09s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0416013285284862e-05, 'learning_rate': 7.9e-06, 'epoch': 0.01}
  1%|â–         | 79/6000 [02:41<3:25:47,  2.09s/it][2025-11-13 02:09:52,449] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:52,450] INFO [src.utils:19] ------------
[2025-11-13 02:09:52,450] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 80/6000 [02:43<3:23:16,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1170295440242626e-05, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  1%|â–         | 80/6000 [02:43<3:23:16,  2.06s/it][2025-11-13 02:09:54,454] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:54,455] INFO [src.utils:19] ------------
[2025-11-13 02:09:54,455] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 81/6000 [02:46<3:22:24,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0722491171909496e-05, 'learning_rate': 8.1e-06, 'epoch': 0.01}
  1%|â–         | 81/6000 [02:46<3:22:24,  2.05s/it][2025-11-13 02:09:56,478] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:56,478] INFO [src.utils:19] ------------
[2025-11-13 02:09:56,479] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 82/6000 [02:48<3:21:59,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1304005713318475e-05, 'learning_rate': 8.2e-06, 'epoch': 0.01}
  1%|â–         | 82/6000 [02:48<3:21:59,  2.05s/it][2025-11-13 02:09:58,517] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:09:58,518] INFO [src.utils:19] ------------
[2025-11-13 02:09:58,518] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 83/6000 [02:50<3:21:42,  2.05s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.194848275394179e-05, 'learning_rate': 8.3e-06, 'epoch': 0.01}
  1%|â–         | 83/6000 [02:50<3:21:42,  2.05s/it][2025-11-13 02:10:00,557] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:10:00,558] INFO [src.utils:19] ------------
[2025-11-13 02:10:00,558] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 84/6000 [02:52<3:21:19,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.1976791686029173e-05, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.01}
  1%|â–         | 84/6000 [02:52<3:21:19,  2.04s/it][2025-11-13 02:10:02,586] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:10:02,587] INFO [src.utils:19] ------------
[2025-11-13 02:10:02,587] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 85/6000 [02:54<3:23:01,  2.06s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.08819819818018e-05, 'learning_rate': 8.5e-06, 'epoch': 0.01}
  1%|â–         | 85/6000 [02:54<3:23:01,  2.06s/it][2025-11-13 02:10:04,693] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:10:04,694] INFO [src.utils:19] ------------
[2025-11-13 02:10:04,694] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 86/6000 [02:56<3:21:30,  2.04s/it]                                                   {'loss': 3.4657, 'grad_norm': 2.0004377802251838e-05, 'learning_rate': 8.6e-06, 'epoch': 0.01}
  1%|â–         | 86/6000 [02:56<3:21:30,  2.04s/it][2025-11-13 02:10:06,695] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 02:10:06,696] INFO [src.utils:19] ------------
[2025-11-13 02:10:06,697] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
