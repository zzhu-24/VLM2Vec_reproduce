==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name 1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 1e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/train.log
W1118 11:17:59.464000 125040693593920 torch/distributed/run.py:779] 
W1118 11:17:59.464000 125040693593920 torch/distributed/run.py:779] *****************************************
W1118 11:17:59.464000 125040693593920 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 11:17:59.464000 125040693593920 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!DropoutAddRMSNorm of flash_attn is not installed!!!

/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-11-18 11:18:06,289] INFO [__main__:61] Resuming from checkpoint: /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
[2025-11-18 11:18:06,290] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
[2025-11-18 11:18:06,425] INFO [__main__:61] Resuming from checkpoint: /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.49it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.57it/s]
Some weights of Qwen2VLForConditionalGenerationWithTail were not initialized from the model checkpoint at Qwen/Qwen2-VL-2B-Instruct and are newly initialized: ['tail_emb']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: setting up run 7zig9id5
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251118_111806-7zig9id5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/7zig9id5
[2025-11-18 11:18:07,906] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.79it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.07it/s]
Some weights of Qwen2VLForConditionalGenerationWithTail were not initialized from the model checkpoint at Qwen/Qwen2-VL-2B-Instruct and are newly initialized: ['tail_emb']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2025-11-18 11:18:08,423] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGenerationWithTail(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-11-18 11:18:14,790] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-11-18 11:18:16,043] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-11-18 11:18:16,043] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-11-18 11:18:19,467] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-11-18 11:18:19,467] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-11-18 11:18:19,858] INFO [src.trainer:161] Loading checkpoint from /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.45it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.53it/s]
HTTP Error 504 thrown while requesting HEAD https://huggingface.co/datasets/TIGER-Lab/MMEB-train/resolve/76dd0a440b6d4c02776830a804443fffbb2d0bfa/dataset_infos.json
[2025-11-18 11:18:20,663] WARNING [huggingface_hub.utils._http:313] HTTP Error 504 thrown while requesting HEAD https://huggingface.co/datasets/TIGER-Lab/MMEB-train/resolve/76dd0a440b6d4c02776830a804443fffbb2d0bfa/dataset_infos.json
Retrying in 1s [Retry 1/5].
[2025-11-18 11:18:20,664] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
HTTP Error 504 thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/generation_config.json
[2025-11-18 11:18:21,005] WARNING [huggingface_hub.utils._http:313] HTTP Error 504 thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/generation_config.json
Retrying in 1s [Retry 1/5].
[2025-11-18 11:18:21,005] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Traceback (most recent call last):
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 407, in hf_raise_for_status
    response.raise_for_status()
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 504 Server Error: Gateway Timeout for url: https://huggingface.co/api/datasets/TIGER-Lab/MMEB-train/tree/76dd0a440b6d4c02776830a804443fffbb2d0bfa/MSCOCO_i2t?recursive=True&expand=False

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
    main()
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 89, in main
    train_dataset = init_mixed_dataset(dataset_config, model_args, data_args, training_args)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/loader/mixed_dataset.py", line 15, in init_mixed_dataset
    train_dataset = AutoPairDataset.instantiate(model_args=model_args, data_args=data_args, training_args=training_args, **dataset_config)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/dataset/base_pair_dataset.py", line 68, in instantiate
    raise e
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/dataset/base_pair_dataset.py", line 66, in instantiate
    return cls.registry[dataset_parser](*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/dataset/mmeb_dataset.py", line 90, in load_mmeb_dataset
    dataset = load_dataset(dataset_name, subset_name, split=f"{dataset_split}")
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/load.py", line 1392, in load_dataset
    builder_instance = load_dataset_builder(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/load.py", line 1166, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/builder.py", line 343, in __init__
    self.config, self.config_id = self._create_builder_config(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/builder.py", line 567, in _create_builder_config
    builder_config._resolve_data_files(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/builder.py", line 207, in _resolve_data_files
    self.data_files = self.data_files.resolve(base_path, download_config)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/data_files.py", line 788, in resolve
    out[key] = data_files_patterns_list.resolve(base_path, download_config)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/data_files.py", line 741, in resolve
    resolve_pattern(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/data_files.py", line 360, in resolve_pattern
    for filepath, info in fs.glob(pattern, detail=True, **glob_kwargs).items()
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 530, in glob
    return super().glob(path, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/fsspec/spec.py", line 637, in glob
    allpaths = self.find(root, maxdepth=depth, withdirs=True, detail=True, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 569, in find
    out = self._ls_tree(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 473, in _ls_tree
    for path_info in tree:
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 3188, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/utils/_pagination.py", line 37, in paginate
    hf_raise_for_status(r)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 480, in hf_raise_for_status
    raise _format(HfHubHTTPError, str(e), response) from e
huggingface_hub.errors.HfHubHTTPError: 504 Server Error: Gateway Timeout for url: https://huggingface.co/api/datasets/TIGER-Lab/MMEB-train/tree/76dd0a440b6d4c02776830a804443fffbb2d0bfa/MSCOCO_i2t?recursive=True&expand=False (Request ID: Root=1-691c47ed-2184289433836aab53c117e6;77b16da0-327b-434a-ac7a-8280ae087291)

The request is taking longer than expected, please try again later.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 407, in hf_raise_for_status
[rank0]:     response.raise_for_status()
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
[rank0]:     raise HTTPError(http_error_msg, response=self)
[rank0]: requests.exceptions.HTTPError: 504 Server Error: Gateway Timeout for url: https://huggingface.co/api/datasets/TIGER-Lab/MMEB-train/tree/76dd0a440b6d4c02776830a804443fffbb2d0bfa/MSCOCO_i2t?recursive=True&expand=False

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
[rank0]:     main()
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 89, in main
[rank0]:     train_dataset = init_mixed_dataset(dataset_config, model_args, data_args, training_args)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/loader/mixed_dataset.py", line 15, in init_mixed_dataset
[rank0]:     train_dataset = AutoPairDataset.instantiate(model_args=model_args, data_args=data_args, training_args=training_args, **dataset_config)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/dataset/base_pair_dataset.py", line 68, in instantiate
[rank0]:     raise e
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/dataset/base_pair_dataset.py", line 66, in instantiate
[rank0]:     return cls.registry[dataset_parser](*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/data/dataset/mmeb_dataset.py", line 90, in load_mmeb_dataset
[rank0]:     dataset = load_dataset(dataset_name, subset_name, split=f"{dataset_split}")
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/load.py", line 1392, in load_dataset
[rank0]:     builder_instance = load_dataset_builder(
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/load.py", line 1166, in load_dataset_builder
[rank0]:     builder_instance: DatasetBuilder = builder_cls(
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/builder.py", line 343, in __init__
[rank0]:     self.config, self.config_id = self._create_builder_config(
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/builder.py", line 567, in _create_builder_config
[rank0]:     builder_config._resolve_data_files(
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/builder.py", line 207, in _resolve_data_files
[rank0]:     self.data_files = self.data_files.resolve(base_path, download_config)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/data_files.py", line 788, in resolve
[rank0]:     out[key] = data_files_patterns_list.resolve(base_path, download_config)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/data_files.py", line 741, in resolve
[rank0]:     resolve_pattern(
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/datasets/data_files.py", line 360, in resolve_pattern
[rank0]:     for filepath, info in fs.glob(pattern, detail=True, **glob_kwargs).items()
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 530, in glob
[rank0]:     return super().glob(path, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/fsspec/spec.py", line 637, in glob
[rank0]:     allpaths = self.find(root, maxdepth=depth, withdirs=True, detail=True, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 569, in find
[rank0]:     out = self._ls_tree(
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 473, in _ls_tree
[rank0]:     for path_info in tree:
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 3188, in list_repo_tree
[rank0]:     for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/utils/_pagination.py", line 37, in paginate
[rank0]:     hf_raise_for_status(r)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 480, in hf_raise_for_status
[rank0]:     raise _format(HfHubHTTPError, str(e), response) from e
[rank0]: huggingface_hub.errors.HfHubHTTPError: 504 Server Error: Gateway Timeout for url: https://huggingface.co/api/datasets/TIGER-Lab/MMEB-train/tree/76dd0a440b6d4c02776830a804443fffbb2d0bfa/MSCOCO_i2t?recursive=True&expand=False (Request ID: Root=1-691c47ed-2184289433836aab53c117e6;77b16da0-327b-434a-ac7a-8280ae087291)

[rank0]: The request is taking longer than expected, please try again later.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33m1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/public/exps/train/1Nov_AddTail-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251118_111806-7zig9id5/logs[0m
W1118 11:18:24.224000 125040693593920 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2784633 closing signal SIGTERM
E1118 11:18:24.588000 125040693593920 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 2784632) of binary: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python3.10
Traceback (most recent call last):
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-18_11:18:24
  host      : nodeaudible01.enst.fr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2784632)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Job finished at: Tue Nov 18 11:18:24 CET 2025
