==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/12Nov_repro-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name 12Nov_repro-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/12Nov_repro-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 1e-5 --max_steps 6000 --warmup_steps 100 --save_steps 500 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/12Nov_repro-Qwen/Qwen2-VL-2B-Instruct/train.log
W1113 01:35:52.760000 134243558131520 torch/distributed/run.py:779] 
W1113 01:35:52.760000 134243558131520 torch/distributed/run.py:779] *****************************************
W1113 01:35:52.760000 134243558131520 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1113 01:35:52.760000 134243558131520 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-11-13 01:36:00,522] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.40it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.39it/s]
wandb: setting up run uj7csrcm
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/12Nov_repro-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251113_013600-uj7csrcm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 12Nov_repro-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/uj7csrcm
[2025-11-13 01:36:02,230] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.99it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.43it/s]
[2025-11-13 01:36:02,793] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-11-13 01:36:08,804] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-11-13 01:36:10,166] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-11-13 01:36:10,166] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-11-13 01:36:13,979] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-11-13 01:36:13,979] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-11-13 01:36:14,731] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-11-13 01:36:14,732] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-11-13 01:36:14,732] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-11-13 01:36:14,733] INFO [src.utils:19] ==================================================
[2025-11-13 01:36:14,733] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-11-13 01:36:14,734] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-13 01:36:14,735] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-13 01:36:14,735] INFO [src.utils:19] ==================================================
[2025-11-13 01:36:16,576] INFO [src.trainer:350] ***** Running training *****
[2025-11-13 01:36:16,577] INFO [src.trainer:351]   Num examples = 192,000
[2025-11-13 01:36:16,577] INFO [src.trainer:352]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-13 01:36:16,577] INFO [src.trainer:353]   Instantaneous batch size per device = 16
[2025-11-13 01:36:16,577] INFO [src.trainer:356]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-13 01:36:16,577] INFO [src.trainer:357]   Gradient Accumulation steps = 1
[2025-11-13 01:36:16,577] INFO [src.trainer:358]   Total optimization steps = 6,000
[2025-11-13 01:36:16,577] INFO [src.trainer:350] ***** Running training *****
[2025-11-13 01:36:16,578] INFO [src.trainer:351]   Num examples = 192,000
[2025-11-13 01:36:16,578] INFO [src.trainer:352]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-13 01:36:16,578] INFO [src.trainer:353]   Instantaneous batch size per device = 16
[2025-11-13 01:36:16,579] INFO [src.trainer:356]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-13 01:36:16,579] INFO [src.trainer:357]   Gradient Accumulation steps = 1
[2025-11-13 01:36:16,579] INFO [src.trainer:358]   Total optimization steps = 6,000
[2025-11-13 01:36:16,580] INFO [src.trainer:359]   Number of trainable parameters = 9,203,712
[2025-11-13 01:36:16,582] INFO [src.trainer:359]   Number of trainable parameters = 9,203,712
[2025-11-13 01:36:16,583] INFO [src.trainer:360]   Trainable Parameters = ['module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-11-13 01:36:16,585] INFO [src.trainer:360]   Trainable Parameters = ['module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[2025-11-13 01:36:17,336] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:17,337] INFO [src.utils:19] ------------
[2025-11-13 01:36:17,339] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[rank1]:[W1113 01:36:19.783908424 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W1113 01:36:19.785626040 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/6000 [00:03<5:38:56,  3.39s/it]                                                  {'loss': 20.6075, 'grad_norm': 1383.2357177734375, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:03<5:38:56,  3.39s/it][2025-11-13 01:36:20,005] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:20,005] INFO [src.utils:19] ------------
[2025-11-13 01:36:20,005] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 2/6000 [00:05<4:15:13,  2.55s/it]                                                  {'loss': 17.7575, 'grad_norm': 1962.6446533203125, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}
  0%|          | 2/6000 [00:05<4:15:13,  2.55s/it][2025-11-13 01:36:21,970] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:21,973] INFO [src.utils:19] ------------
[2025-11-13 01:36:21,973] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 3/6000 [00:07<3:48:58,  2.29s/it]                                                  {'loss': 16.0989, 'grad_norm': 2236.689453125, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.0}
  0%|          | 3/6000 [00:07<3:48:58,  2.29s/it][2025-11-13 01:36:23,954] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:23,954] INFO [src.utils:19] ------------
[2025-11-13 01:36:23,955] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 4/6000 [00:09<3:36:44,  2.17s/it]                                                  {'loss': 16.4534, 'grad_norm': 2247.879638671875, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.0}
  0%|          | 4/6000 [00:09<3:36:44,  2.17s/it][2025-11-13 01:36:25,938] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:25,938] INFO [src.utils:19] ------------
[2025-11-13 01:36:25,939] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 5/6000 [00:11<3:31:24,  2.12s/it]                                                  {'loss': 16.6901, 'grad_norm': 1925.0728759765625, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 5/6000 [00:11<3:31:24,  2.12s/it][2025-11-13 01:36:27,954] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:27,955] INFO [src.utils:19] ------------
[2025-11-13 01:36:27,955] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 6/6000 [00:13<3:25:39,  2.06s/it]                                                  {'loss': 18.3733, 'grad_norm': 1570.0484619140625, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.0}
  0%|          | 6/6000 [00:13<3:25:39,  2.06s/it][2025-11-13 01:36:29,904] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:29,904] INFO [src.utils:19] ------------
[2025-11-13 01:36:29,905] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 7/6000 [00:15<3:24:40,  2.05s/it]                                                  {'loss': 17.9329, 'grad_norm': 1908.934326171875, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.0}
  0%|          | 7/6000 [00:15<3:24:40,  2.05s/it][2025-11-13 01:36:31,935] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:31,936] INFO [src.utils:19] ------------
[2025-11-13 01:36:31,937] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 8/6000 [00:17<3:22:27,  2.03s/it]                                                  {'loss': 19.1783, 'grad_norm': 1756.2833251953125, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.0}
  0%|          | 8/6000 [00:17<3:22:27,  2.03s/it][2025-11-13 01:36:33,911] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:33,911] INFO [src.utils:19] ------------
[2025-11-13 01:36:33,911] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 9/6000 [00:19<3:25:04,  2.05s/it]                                                  {'loss': 14.9063, 'grad_norm': 1844.7208251953125, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.0}
  0%|          | 9/6000 [00:19<3:25:04,  2.05s/it][2025-11-13 01:36:36,027] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:36,028] INFO [src.utils:19] ------------
[2025-11-13 01:36:36,029] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 10/6000 [00:21<3:20:59,  2.01s/it]                                                   {'loss': 18.4606, 'grad_norm': 1377.032470703125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:21<3:20:59,  2.01s/it][2025-11-13 01:36:37,954] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:37,954] INFO [src.utils:19] ------------
[2025-11-13 01:36:37,955] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 11/6000 [00:23<3:22:00,  2.02s/it]                                                   {'loss': 21.1653, 'grad_norm': 1686.567626953125, 'learning_rate': 1.1e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:23<3:22:00,  2.02s/it][2025-11-13 01:36:39,996] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:39,997] INFO [src.utils:19] ------------
[2025-11-13 01:36:39,997] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 12/6000 [00:25<3:21:54,  2.02s/it]                                                   {'loss': 18.0712, 'grad_norm': 1824.6082763671875, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:25<3:21:54,  2.02s/it][2025-11-13 01:36:42,014] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:42,015] INFO [src.utils:19] ------------
[2025-11-13 01:36:42,015] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 13/6000 [00:27<3:19:12,  2.00s/it]                                                   {'loss': 18.4145, 'grad_norm': 2015.442138671875, 'learning_rate': 1.3e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:27<3:19:12,  2.00s/it][2025-11-13 01:36:43,951] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:43,951] INFO [src.utils:19] ------------
[2025-11-13 01:36:43,952] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 14/6000 [00:29<3:19:54,  2.00s/it]                                                   {'loss': 17.9529, 'grad_norm': 3319.582275390625, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:29<3:19:54,  2.00s/it][2025-11-13 01:36:45,976] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:45,977] INFO [src.utils:19] ------------
[2025-11-13 01:36:45,978] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 15/6000 [00:31<3:22:26,  2.03s/it]                                                   {'loss': 14.4378, 'grad_norm': 2430.519287109375, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:31<3:22:26,  2.03s/it][2025-11-13 01:36:48,067] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:48,068] INFO [src.utils:19] ------------
[2025-11-13 01:36:48,068] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 16/6000 [00:33<3:21:54,  2.02s/it]                                                   {'loss': 16.2033, 'grad_norm': 1656.3577880859375, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:33<3:21:54,  2.02s/it][2025-11-13 01:36:50,076] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:50,077] INFO [src.utils:19] ------------
[2025-11-13 01:36:50,077] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 17/6000 [00:35<3:22:03,  2.03s/it]                                                   {'loss': 15.5897, 'grad_norm': 1447.76611328125, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:35<3:22:03,  2.03s/it][2025-11-13 01:36:52,112] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:52,112] INFO [src.utils:19] ------------
[2025-11-13 01:36:52,112] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 18/6000 [00:37<3:21:54,  2.03s/it]                                                   {'loss': 12.1726, 'grad_norm': 1432.6409912109375, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.0}
  0%|          | 18/6000 [00:37<3:21:54,  2.03s/it][2025-11-13 01:36:54,128] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:54,128] INFO [src.utils:19] ------------
[2025-11-13 01:36:54,129] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 19/6000 [00:39<3:20:30,  2.01s/it]                                                   {'loss': 13.5016, 'grad_norm': 2011.44970703125, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.0}
  0%|          | 19/6000 [00:39<3:20:30,  2.01s/it][2025-11-13 01:36:56,114] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:56,114] INFO [src.utils:19] ------------
[2025-11-13 01:36:56,115] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 20/6000 [00:41<3:19:59,  2.01s/it]                                                   {'loss': 14.7968, 'grad_norm': 2120.33251953125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 20/6000 [00:41<3:19:59,  2.01s/it][2025-11-13 01:36:58,108] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:36:58,108] INFO [src.utils:19] ------------
[2025-11-13 01:36:58,109] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 21/6000 [00:43<3:20:22,  2.01s/it]                                                   {'loss': 12.0563, 'grad_norm': 1849.3822021484375, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.0}
  0%|          | 21/6000 [00:43<3:20:22,  2.01s/it][2025-11-13 01:37:00,130] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:00,130] INFO [src.utils:19] ------------
[2025-11-13 01:37:00,130] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 22/6000 [00:45<3:19:51,  2.01s/it]                                                   {'loss': 11.5244, 'grad_norm': 1729.5301513671875, 'learning_rate': 2.2e-06, 'epoch': 0.0}
  0%|          | 22/6000 [00:45<3:19:51,  2.01s/it][2025-11-13 01:37:02,127] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:02,127] INFO [src.utils:19] ------------
[2025-11-13 01:37:02,128] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 23/6000 [00:47<3:21:09,  2.02s/it]                                                   {'loss': 11.1318, 'grad_norm': 1946.552001953125, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.0}
  0%|          | 23/6000 [00:47<3:21:09,  2.02s/it][2025-11-13 01:37:04,168] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:04,169] INFO [src.utils:19] ------------
[2025-11-13 01:37:04,169] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 24/6000 [00:49<3:24:18,  2.05s/it]                                                   {'loss': 10.9502, 'grad_norm': 1804.7657470703125, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.0}
  0%|          | 24/6000 [00:49<3:24:18,  2.05s/it][2025-11-13 01:37:06,299] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:06,299] INFO [src.utils:19] ------------
[2025-11-13 01:37:06,299] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 25/6000 [00:51<3:22:46,  2.04s/it]                                                   {'loss': 11.3564, 'grad_norm': 2649.61669921875, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 25/6000 [00:51<3:22:46,  2.04s/it][2025-11-13 01:37:08,305] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:08,306] INFO [src.utils:19] ------------
[2025-11-13 01:37:08,306] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 26/6000 [00:53<3:22:08,  2.03s/it]                                                   {'loss': 8.7549, 'grad_norm': 2958.50244140625, 'learning_rate': 2.6e-06, 'epoch': 0.0}
  0%|          | 26/6000 [00:53<3:22:08,  2.03s/it][2025-11-13 01:37:10,319] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:10,320] INFO [src.utils:19] ------------
[2025-11-13 01:37:10,320] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 27/6000 [00:55<3:22:11,  2.03s/it]                                                   {'loss': 6.4873, 'grad_norm': 1727.30224609375, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.0}
  0%|          | 27/6000 [00:55<3:22:11,  2.03s/it][2025-11-13 01:37:12,348] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:12,348] INFO [src.utils:19] ------------
[2025-11-13 01:37:12,349] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 28/6000 [00:58<3:31:52,  2.13s/it]                                                   {'loss': 7.4692, 'grad_norm': 1439.448974609375, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.0}
  0%|          | 28/6000 [00:58<3:31:52,  2.13s/it][2025-11-13 01:37:14,702] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:14,702] INFO [src.utils:19] ------------
[2025-11-13 01:37:14,703] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 29/6000 [01:00<3:27:24,  2.08s/it]                                                   {'loss': 6.5166, 'grad_norm': 3295.850830078125, 'learning_rate': 2.9e-06, 'epoch': 0.0}
  0%|          | 29/6000 [01:00<3:27:24,  2.08s/it][2025-11-13 01:37:16,682] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:16,682] INFO [src.utils:19] ------------
[2025-11-13 01:37:16,683] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  0%|          | 30/6000 [01:02<3:28:23,  2.09s/it]                                                   {'loss': 5.3802, 'grad_norm': 1814.3607177734375, 'learning_rate': 3e-06, 'epoch': 0.01}
  0%|          | 30/6000 [01:02<3:28:23,  2.09s/it][2025-11-13 01:37:18,800] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:18,800] INFO [src.utils:19] ------------
[2025-11-13 01:37:18,801] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 31/6000 [01:04<3:26:29,  2.08s/it]                                                   {'loss': 5.5936, 'grad_norm': 3333.522216796875, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.01}
  1%|          | 31/6000 [01:04<3:26:29,  2.08s/it][2025-11-13 01:37:20,843] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:20,843] INFO [src.utils:19] ------------
[2025-11-13 01:37:20,844] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 32/6000 [01:06<3:24:19,  2.05s/it]                                                   {'loss': 6.5985, 'grad_norm': 3940.102783203125, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.01}
  1%|          | 32/6000 [01:06<3:24:19,  2.05s/it][2025-11-13 01:37:22,845] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:22,845] INFO [src.utils:19] ------------
[2025-11-13 01:37:22,845] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 33/6000 [01:08<3:22:44,  2.04s/it]                                                   {'loss': 4.187, 'grad_norm': 1535.482666015625, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.01}
  1%|          | 33/6000 [01:08<3:22:44,  2.04s/it][2025-11-13 01:37:24,844] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:24,845] INFO [src.utils:19] ------------
[2025-11-13 01:37:24,845] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 34/6000 [01:10<3:20:26,  2.02s/it]                                                   {'loss': 5.1421, 'grad_norm': 1229.7708740234375, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.01}
  1%|          | 34/6000 [01:10<3:20:26,  2.02s/it][2025-11-13 01:37:26,807] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:26,807] INFO [src.utils:19] ------------
[2025-11-13 01:37:26,807] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 35/6000 [01:12<3:20:11,  2.01s/it]                                                   {'loss': 4.7763, 'grad_norm': 2587.418212890625, 'learning_rate': 3.5e-06, 'epoch': 0.01}
  1%|          | 35/6000 [01:12<3:20:11,  2.01s/it][2025-11-13 01:37:28,808] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:28,809] INFO [src.utils:19] ------------
[2025-11-13 01:37:28,809] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 36/6000 [01:14<3:16:34,  1.98s/it]                                                   {'loss': 5.0207, 'grad_norm': 2070.8671875, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.01}
  1%|          | 36/6000 [01:14<3:16:34,  1.98s/it][2025-11-13 01:37:30,704] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:30,705] INFO [src.utils:19] ------------
[2025-11-13 01:37:30,705] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 37/6000 [01:16<3:17:01,  1.98s/it]                                                   {'loss': 4.454, 'grad_norm': 869.9176025390625, 'learning_rate': 3.7e-06, 'epoch': 0.01}
  1%|          | 37/6000 [01:16<3:17:01,  1.98s/it][2025-11-13 01:37:32,698] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:32,698] INFO [src.utils:19] ------------
[2025-11-13 01:37:32,698] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 38/6000 [01:18<3:15:26,  1.97s/it]                                                   {'loss': 4.2177, 'grad_norm': 2842.30517578125, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.01}
  1%|          | 38/6000 [01:18<3:15:26,  1.97s/it][2025-11-13 01:37:34,628] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:34,628] INFO [src.utils:19] ------------
[2025-11-13 01:37:34,629] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 39/6000 [01:19<3:15:56,  1.97s/it]                                                   {'loss': 3.999, 'grad_norm': 633.3478393554688, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.01}
  1%|          | 39/6000 [01:19<3:15:56,  1.97s/it][2025-11-13 01:37:36,613] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:36,613] INFO [src.utils:19] ------------
[2025-11-13 01:37:36,613] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 40/6000 [01:22<3:18:12,  2.00s/it]                                                   {'loss': 4.2004, 'grad_norm': 2339.796875, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 40/6000 [01:22<3:18:12,  2.00s/it][2025-11-13 01:37:38,663] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:38,663] INFO [src.utils:19] ------------
[2025-11-13 01:37:38,663] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 41/6000 [01:24<3:19:50,  2.01s/it]                                                   {'loss': 4.2645, 'grad_norm': 1088.516845703125, 'learning_rate': 4.1e-06, 'epoch': 0.01}
  1%|          | 41/6000 [01:24<3:19:50,  2.01s/it][2025-11-13 01:37:40,712] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:40,712] INFO [src.utils:19] ------------
[2025-11-13 01:37:40,712] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 42/6000 [01:26<3:19:17,  2.01s/it]                                                   {'loss': 3.3904, 'grad_norm': 402.7860412597656, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.01}
  1%|          | 42/6000 [01:26<3:19:17,  2.01s/it][2025-11-13 01:37:42,706] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:42,707] INFO [src.utils:19] ------------
[2025-11-13 01:37:42,707] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 43/6000 [01:28<3:32:26,  2.14s/it]                                                   {'loss': 4.3592, 'grad_norm': 862.7857055664062, 'learning_rate': 4.3e-06, 'epoch': 0.01}
  1%|          | 43/6000 [01:28<3:32:26,  2.14s/it][2025-11-13 01:37:45,155] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:45,156] INFO [src.utils:19] ------------
[2025-11-13 01:37:45,156] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 44/6000 [01:30<3:32:52,  2.14s/it]                                                   {'loss': 3.6244, 'grad_norm': 444.7391357421875, 'learning_rate': 4.4e-06, 'epoch': 0.01}
  1%|          | 44/6000 [01:30<3:32:52,  2.14s/it][2025-11-13 01:37:47,314] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:47,315] INFO [src.utils:19] ------------
[2025-11-13 01:37:47,316] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 45/6000 [01:32<3:30:17,  2.12s/it]                                                   {'loss': 3.0953, 'grad_norm': 1404.7264404296875, 'learning_rate': 4.5e-06, 'epoch': 0.01}
  1%|          | 45/6000 [01:32<3:30:17,  2.12s/it][2025-11-13 01:37:49,381] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:49,381] INFO [src.utils:19] ------------
[2025-11-13 01:37:49,382] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 46/6000 [01:34<3:28:22,  2.10s/it]                                                   {'loss': 3.4924, 'grad_norm': 521.1378173828125, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.01}
  1%|          | 46/6000 [01:34<3:28:22,  2.10s/it][2025-11-13 01:37:51,432] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:51,433] INFO [src.utils:19] ------------
[2025-11-13 01:37:51,433] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 47/6000 [01:36<3:25:50,  2.07s/it]                                                   {'loss': 3.4819, 'grad_norm': 282.3681945800781, 'learning_rate': 4.7e-06, 'epoch': 0.01}
  1%|          | 47/6000 [01:36<3:25:50,  2.07s/it][2025-11-13 01:37:53,446] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:53,447] INFO [src.utils:19] ------------
[2025-11-13 01:37:53,447] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 48/6000 [01:38<3:24:49,  2.06s/it]                                                   {'loss': 3.3452, 'grad_norm': 327.98846435546875, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.01}
  1%|          | 48/6000 [01:38<3:24:49,  2.06s/it][2025-11-13 01:37:55,485] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:55,485] INFO [src.utils:19] ------------
[2025-11-13 01:37:55,486] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 49/6000 [01:40<3:23:33,  2.05s/it]                                                   {'loss': 3.6071, 'grad_norm': 250.74337768554688, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.01}
  1%|          | 49/6000 [01:40<3:23:33,  2.05s/it][2025-11-13 01:37:57,514] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:57,515] INFO [src.utils:19] ------------
[2025-11-13 01:37:57,515] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 50/6000 [01:42<3:23:35,  2.05s/it]                                                   {'loss': 3.5544, 'grad_norm': 264.3508605957031, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 50/6000 [01:42<3:23:35,  2.05s/it][2025-11-13 01:37:59,563] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:37:59,563] INFO [src.utils:19] ------------
[2025-11-13 01:37:59,563] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 51/6000 [01:45<3:24:07,  2.06s/it]                                                   {'loss': 3.7899, 'grad_norm': 216.73928833007812, 'learning_rate': 5.1e-06, 'epoch': 0.01}
  1%|          | 51/6000 [01:45<3:24:07,  2.06s/it][2025-11-13 01:38:01,639] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:01,639] INFO [src.utils:19] ------------
[2025-11-13 01:38:01,640] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 52/6000 [01:46<3:21:00,  2.03s/it]                                                   {'loss': 3.2206, 'grad_norm': 391.2967529296875, 'learning_rate': 5.2e-06, 'epoch': 0.01}
  1%|          | 52/6000 [01:46<3:21:00,  2.03s/it][2025-11-13 01:38:03,588] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:03,589] INFO [src.utils:19] ------------
[2025-11-13 01:38:03,589] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 53/6000 [01:48<3:20:52,  2.03s/it]                                                   {'loss': 4.0248, 'grad_norm': 760.037353515625, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.01}
  1%|          | 53/6000 [01:49<3:20:52,  2.03s/it][2025-11-13 01:38:05,617] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:05,617] INFO [src.utils:19] ------------
[2025-11-13 01:38:05,618] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 54/6000 [01:50<3:19:30,  2.01s/it]                                                   {'loss': 3.19, 'grad_norm': 276.4334411621094, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.01}
  1%|          | 54/6000 [01:50<3:19:30,  2.01s/it][2025-11-13 01:38:07,596] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:07,597] INFO [src.utils:19] ------------
[2025-11-13 01:38:07,597] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 55/6000 [01:52<3:19:00,  2.01s/it]                                                   {'loss': 3.1877, 'grad_norm': 220.88890075683594, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.01}
  1%|          | 55/6000 [01:52<3:19:00,  2.01s/it][2025-11-13 01:38:09,598] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:09,599] INFO [src.utils:19] ------------
[2025-11-13 01:38:09,600] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 56/6000 [01:54<3:19:07,  2.01s/it]                                                   {'loss': 3.3054, 'grad_norm': 205.94528198242188, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.01}
  1%|          | 56/6000 [01:54<3:19:07,  2.01s/it][2025-11-13 01:38:11,612] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:11,613] INFO [src.utils:19] ------------
[2025-11-13 01:38:11,613] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 57/6000 [01:57<3:20:18,  2.02s/it]                                                   {'loss': 3.4098, 'grad_norm': 206.0811309814453, 'learning_rate': 5.7e-06, 'epoch': 0.01}
  1%|          | 57/6000 [01:57<3:20:18,  2.02s/it][2025-11-13 01:38:13,666] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:13,666] INFO [src.utils:19] ------------
[2025-11-13 01:38:13,666] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 58/6000 [01:59<3:20:48,  2.03s/it]                                                   {'loss': 3.264, 'grad_norm': 176.41705322265625, 'learning_rate': 5.8e-06, 'epoch': 0.01}
  1%|          | 58/6000 [01:59<3:20:48,  2.03s/it][2025-11-13 01:38:15,699] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:15,700] INFO [src.utils:19] ------------
[2025-11-13 01:38:15,700] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 59/6000 [02:01<3:18:16,  2.00s/it]                                                   {'loss': 3.118, 'grad_norm': 396.8981018066406, 'learning_rate': 5.9e-06, 'epoch': 0.01}
  1%|          | 59/6000 [02:01<3:18:16,  2.00s/it][2025-11-13 01:38:17,643] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:17,643] INFO [src.utils:19] ------------
[2025-11-13 01:38:17,644] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 60/6000 [02:03<3:17:35,  2.00s/it]                                                   {'loss': 3.1602, 'grad_norm': 162.68389892578125, 'learning_rate': 6e-06, 'epoch': 0.01}
  1%|          | 60/6000 [02:03<3:17:35,  2.00s/it][2025-11-13 01:38:19,626] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:19,627] INFO [src.utils:19] ------------
[2025-11-13 01:38:19,627] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 61/6000 [02:05<3:19:23,  2.01s/it]                                                   {'loss': 3.1144, 'grad_norm': 205.89588928222656, 'learning_rate': 6.1e-06, 'epoch': 0.01}
  1%|          | 61/6000 [02:05<3:19:23,  2.01s/it][2025-11-13 01:38:21,681] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:21,681] INFO [src.utils:19] ------------
[2025-11-13 01:38:21,682] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 62/6000 [02:07<3:17:44,  2.00s/it]                                                   {'loss': 2.8534, 'grad_norm': 174.03785705566406, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.01}
  1%|          | 62/6000 [02:07<3:17:44,  2.00s/it][2025-11-13 01:38:23,645] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:23,645] INFO [src.utils:19] ------------
[2025-11-13 01:38:23,645] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 63/6000 [02:08<3:16:22,  1.98s/it]                                                   {'loss': 3.1982, 'grad_norm': 185.04779052734375, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.01}
  1%|          | 63/6000 [02:08<3:16:22,  1.98s/it][2025-11-13 01:38:25,591] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:25,592] INFO [src.utils:19] ------------
[2025-11-13 01:38:25,592] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 64/6000 [02:10<3:14:48,  1.97s/it]                                                   {'loss': 2.8098, 'grad_norm': 187.54232788085938, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.01}
  1%|          | 64/6000 [02:10<3:14:48,  1.97s/it][2025-11-13 01:38:27,534] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:27,535] INFO [src.utils:19] ------------
[2025-11-13 01:38:27,535] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 65/6000 [02:12<3:16:12,  1.98s/it]                                                   {'loss': 3.1479, 'grad_norm': 488.6595458984375, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.01}
  1%|          | 65/6000 [02:12<3:16:12,  1.98s/it][2025-11-13 01:38:29,550] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:29,550] INFO [src.utils:19] ------------
[2025-11-13 01:38:29,551] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 66/6000 [02:15<3:20:19,  2.03s/it]                                                   {'loss': 2.9594, 'grad_norm': 189.2418670654297, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.01}
  1%|          | 66/6000 [02:15<3:20:19,  2.03s/it][2025-11-13 01:38:31,669] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:31,669] INFO [src.utils:19] ------------
[2025-11-13 01:38:31,670] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 67/6000 [02:17<3:18:37,  2.01s/it]                                                   {'loss': 2.9401, 'grad_norm': 286.4405212402344, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.01}
  1%|          | 67/6000 [02:17<3:18:37,  2.01s/it][2025-11-13 01:38:33,637] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:33,637] INFO [src.utils:19] ------------
[2025-11-13 01:38:33,638] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 68/6000 [02:19<3:17:44,  2.00s/it]                                                   {'loss': 3.1715, 'grad_norm': 245.7219696044922, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.01}
  1%|          | 68/6000 [02:19<3:17:44,  2.00s/it][2025-11-13 01:38:35,617] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:35,617] INFO [src.utils:19] ------------
[2025-11-13 01:38:35,618] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 69/6000 [02:21<3:18:42,  2.01s/it]                                                   {'loss': 2.9798, 'grad_norm': 318.208740234375, 'learning_rate': 6.9e-06, 'epoch': 0.01}
  1%|          | 69/6000 [02:21<3:18:42,  2.01s/it][2025-11-13 01:38:37,652] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:37,652] INFO [src.utils:19] ------------
[2025-11-13 01:38:37,652] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 70/6000 [02:23<3:20:19,  2.03s/it]                                                   {'loss': 2.8345, 'grad_norm': 253.38662719726562, 'learning_rate': 7e-06, 'epoch': 0.01}
  1%|          | 70/6000 [02:23<3:20:19,  2.03s/it][2025-11-13 01:38:39,717] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:39,719] INFO [src.utils:19] ------------
[2025-11-13 01:38:39,719] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 71/6000 [02:25<3:19:25,  2.02s/it]                                                   {'loss': 2.9128, 'grad_norm': 191.01309204101562, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.01}
  1%|          | 71/6000 [02:25<3:19:25,  2.02s/it][2025-11-13 01:38:41,715] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:41,715] INFO [src.utils:19] ------------
[2025-11-13 01:38:41,715] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 72/6000 [02:27<3:22:51,  2.05s/it]                                                   {'loss': 2.9945, 'grad_norm': 306.3248291015625, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.01}
  1%|          | 72/6000 [02:27<3:22:51,  2.05s/it][2025-11-13 01:38:43,846] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:43,847] INFO [src.utils:19] ------------
[2025-11-13 01:38:43,847] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 73/6000 [02:29<3:21:16,  2.04s/it]                                                   {'loss': 2.6133, 'grad_norm': 209.33169555664062, 'learning_rate': 7.3e-06, 'epoch': 0.01}
  1%|          | 73/6000 [02:29<3:21:16,  2.04s/it][2025-11-13 01:38:45,849] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:45,850] INFO [src.utils:19] ------------
[2025-11-13 01:38:45,850] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|          | 74/6000 [02:31<3:22:45,  2.05s/it]                                                   {'loss': 2.8429, 'grad_norm': 304.4790954589844, 'learning_rate': 7.4e-06, 'epoch': 0.01}
  1%|          | 74/6000 [02:31<3:22:45,  2.05s/it][2025-11-13 01:38:47,945] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:47,946] INFO [src.utils:19] ------------
[2025-11-13 01:38:47,946] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 75/6000 [02:33<3:31:16,  2.14s/it]                                                   {'loss': 2.6155, 'grad_norm': 161.34024047851562, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.01}
  1%|â–         | 75/6000 [02:33<3:31:16,  2.14s/it][2025-11-13 01:38:50,276] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:50,277] INFO [src.utils:19] ------------
[2025-11-13 01:38:50,277] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 76/6000 [02:35<3:27:13,  2.10s/it]                                                   {'loss': 2.9585, 'grad_norm': 205.78089904785156, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.01}
  1%|â–         | 76/6000 [02:35<3:27:13,  2.10s/it][2025-11-13 01:38:52,286] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:52,287] INFO [src.utils:19] ------------
[2025-11-13 01:38:52,287] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 77/6000 [02:37<3:26:50,  2.10s/it]                                                   {'loss': 2.9511, 'grad_norm': 185.375732421875, 'learning_rate': 7.7e-06, 'epoch': 0.01}
  1%|â–         | 77/6000 [02:37<3:26:50,  2.10s/it][2025-11-13 01:38:54,372] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:54,372] INFO [src.utils:19] ------------
[2025-11-13 01:38:54,373] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 78/6000 [02:40<3:33:01,  2.16s/it]                                                   {'loss': 2.7657, 'grad_norm': 215.8031005859375, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.01}
  1%|â–         | 78/6000 [02:40<3:33:01,  2.16s/it][2025-11-13 01:38:56,679] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:56,679] INFO [src.utils:19] ------------
[2025-11-13 01:38:56,679] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 79/6000 [02:42<3:28:49,  2.12s/it]                                                   {'loss': 2.6047, 'grad_norm': 129.2764434814453, 'learning_rate': 7.9e-06, 'epoch': 0.01}
  1%|â–         | 79/6000 [02:42<3:28:49,  2.12s/it][2025-11-13 01:38:58,699] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:38:58,700] INFO [src.utils:19] ------------
[2025-11-13 01:38:58,700] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 80/6000 [02:44<3:27:08,  2.10s/it]                                                   {'loss': 2.6274, 'grad_norm': 187.7565155029297, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  1%|â–         | 80/6000 [02:44<3:27:08,  2.10s/it][2025-11-13 01:39:00,761] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:39:00,761] INFO [src.utils:19] ------------
[2025-11-13 01:39:00,762] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
  1%|â–         | 81/6000 [02:46<3:23:22,  2.06s/it]                                                   {'loss': 2.6952, 'grad_norm': 269.69891357421875, 'learning_rate': 8.1e-06, 'epoch': 0.01}
  1%|â–         | 81/6000 [02:46<3:23:22,  2.06s/it][2025-11-13 01:39:02,727] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
[2025-11-13 01:39:02,727] INFO [src.utils:19] ------------
[2025-11-13 01:39:02,727] INFO [src.utils:19] dict_keys(['input_ids', 'attention_mask', 'texts', 'images', 'pixel_values', 'image_grid_thw', 'pixel_values_videos', 'video_grid_thw', 'text', 'global_dataset_name'])
