==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name 11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 1e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --tail_gradient_flow_only True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/train.log
W1111 21:52:52.431000 125705797912384 torch/distributed/run.py:779] 
W1111 21:52:52.431000 125705797912384 torch/distributed/run.py:779] *****************************************
W1111 21:52:52.431000 125705797912384 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1111 21:52:52.431000 125705797912384 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-11-11 21:52:59,767] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.68it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.94it/s]
wandb: setting up run tnijsxvm
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251111_215300-tnijsxvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/tnijsxvm
[2025-11-11 21:53:01,386] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.95it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.41it/s]
[2025-11-11 21:53:02,207] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-11-11 21:53:07,845] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-11-11 21:53:09,403] INFO [src.utils:19] PeftModel(
  (base_model): LoraModel(
    (model): Qwen2VLForConditionalGeneration(
      (visual): Qwen2VisionTransformerPretrainedModel(
        (patch_embed): PatchEmbed(
          (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
        )
        (rotary_pos_emb): VisionRotaryEmbedding()
        (blocks): ModuleList(
          (0-31): 32 x Qwen2VLVisionBlock(
            (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (attn): VisionFlashAttention2(
              (qkv): Linear(in_features=1280, out_features=3840, bias=True)
              (proj): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (mlp): VisionMlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): QuickGELUActivation()
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            )
          )
        )
        (merger): PatchMerger(
          (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=5120, out_features=5120, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=5120, out_features=1536, bias=True)
          )
        )
      )
      (model): Qwen2VLModel(
        (embed_tokens): Embedding(151936, 1536)
        (layers): ModuleList(
          (0-27): 28 x Qwen2VLDecoderLayer(
            (self_attn): Qwen2VLFlashAttention2(
              (q_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=1536, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (k_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=256, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=256, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (v_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=256, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=256, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=1536, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (rotary_emb): Qwen2VLRotaryEmbedding()
            )
            (mlp): Qwen2MLP(
              (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
              (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
              (down_proj): lora.Linear(
                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8960, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=1536, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (act_fn): SiLU()
            )
            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
          )
        )
        (norm): Qwen2RMSNorm((1536,), eps=1e-06)
        (rotary_emb): Qwen2VLRotaryEmbedding()
      )
      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
    )
  )
)
[2025-11-11 21:53:09,410] INFO [src.utils:19] Gradient will only flow through the tail token embedding.
[2025-11-11 21:53:09,411] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-11-11 21:53:09,412] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-11-11 21:53:12,780] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-11-11 21:53:12,781] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-11-11 21:53:13,544] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-11-11 21:53:13,544] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-11-11 21:53:13,545] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-11-11 21:53:13,546] INFO [src.utils:19] ==================================================
[2025-11-11 21:53:13,546] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-11-11 21:53:13,546] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-11 21:53:13,547] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-11 21:53:13,547] INFO [src.utils:19] ==================================================
[2025-11-11 21:53:15,392] INFO [src.trainer:350] ***** Running training *****
[2025-11-11 21:53:15,392] INFO [src.trainer:351]   Num examples = 192,000
[2025-11-11 21:53:15,393] INFO [src.trainer:350] ***** Running training *****
[2025-11-11 21:53:15,393] INFO [src.trainer:351]   Num examples = 192,000
[2025-11-11 21:53:15,393] INFO [src.trainer:352]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-11 21:53:15,393] INFO [src.trainer:353]   Instantaneous batch size per device = 16
[2025-11-11 21:53:15,393] INFO [src.trainer:356]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-11 21:53:15,393] INFO [src.trainer:357]   Gradient Accumulation steps = 1
[2025-11-11 21:53:15,393] INFO [src.trainer:358]   Total optimization steps = 6,000
[2025-11-11 21:53:15,393] INFO [src.trainer:352]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-11 21:53:15,393] INFO [src.trainer:353]   Instantaneous batch size per device = 16
[2025-11-11 21:53:15,393] INFO [src.trainer:356]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-11 21:53:15,394] INFO [src.trainer:357]   Gradient Accumulation steps = 1
[2025-11-11 21:53:15,394] INFO [src.trainer:358]   Total optimization steps = 6,000
[2025-11-11 21:53:15,396] INFO [src.trainer:359]   Number of trainable parameters = 9,205,248
[2025-11-11 21:53:15,398] INFO [src.trainer:359]   Number of trainable parameters = 9,205,248
[2025-11-11 21:53:15,399] INFO [src.trainer:360]   Trainable Parameters = ['module.encoder.tail_token', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-11-11 21:53:15,401] INFO [src.trainer:360]   Trainable Parameters = ['module.encoder.tail_token', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.block.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.block.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/6000 [00:03<5:34:53,  3.35s/it]                                                  {'loss': 20.6075, 'grad_norm': 931.9451293945312, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:03<5:34:53,  3.35s/it]  0%|          | 2/6000 [00:05<4:09:44,  2.50s/it]                                                  {'loss': 17.7575, 'grad_norm': 1052.721435546875, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}
  0%|          | 2/6000 [00:05<4:09:44,  2.50s/it]  0%|          | 3/6000 [00:07<3:44:51,  2.25s/it]                                                  {'loss': 16.1774, 'grad_norm': 1170.56103515625, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.0}
  0%|          | 3/6000 [00:07<3:44:51,  2.25s/it]  0%|          | 4/6000 [00:09<3:33:34,  2.14s/it]                                                  {'loss': 16.4339, 'grad_norm': 1284.107421875, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.0}
  0%|          | 4/6000 [00:09<3:33:34,  2.14s/it]  0%|          | 5/6000 [00:11<3:23:40,  2.04s/it]                                                  {'loss': 16.8295, 'grad_norm': 1316.3204345703125, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 5/6000 [00:11<3:23:40,  2.04s/it]  0%|          | 6/6000 [00:12<3:19:08,  1.99s/it]                                                  {'loss': 18.3433, 'grad_norm': 1061.7589111328125, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.0}
  0%|          | 6/6000 [00:12<3:19:08,  1.99s/it]  0%|          | 7/6000 [00:14<3:16:40,  1.97s/it]                                                  {'loss': 17.8979, 'grad_norm': 1019.922119140625, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.0}
  0%|          | 7/6000 [00:14<3:16:40,  1.97s/it]  0%|          | 8/6000 [00:16<3:13:01,  1.93s/it]                                                  {'loss': 19.0642, 'grad_norm': 1148.87841796875, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.0}
  0%|          | 8/6000 [00:16<3:13:01,  1.93s/it]  0%|          | 9/6000 [00:18<3:12:20,  1.93s/it]                                                  {'loss': 14.8934, 'grad_norm': 1190.7303466796875, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.0}
  0%|          | 9/6000 [00:18<3:12:20,  1.93s/it]  0%|          | 10/6000 [00:20<3:22:29,  2.03s/it]                                                   {'loss': 18.5808, 'grad_norm': 824.1814575195312, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:20<3:22:29,  2.03s/it]  0%|          | 11/6000 [00:22<3:19:50,  2.00s/it]                                                   {'loss': 21.0384, 'grad_norm': 1267.659912109375, 'learning_rate': 1.1e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:22<3:19:50,  2.00s/it]  0%|          | 12/6000 [00:24<3:18:00,  1.98s/it]                                                   {'loss': 18.2545, 'grad_norm': 1124.347900390625, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:24<3:18:00,  1.98s/it]  0%|          | 13/6000 [00:26<3:14:47,  1.95s/it]                                                   {'loss': 17.9932, 'grad_norm': 1620.6156005859375, 'learning_rate': 1.3e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:26<3:14:47,  1.95s/it]  0%|          | 14/6000 [00:28<3:13:34,  1.94s/it]                                                   {'loss': 18.2185, 'grad_norm': 2101.77880859375, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:28<3:13:34,  1.94s/it]  0%|          | 15/6000 [00:30<3:14:48,  1.95s/it]                                                   {'loss': 14.5469, 'grad_norm': 1487.9691162109375, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:30<3:14:48,  1.95s/it]  0%|          | 16/6000 [00:32<3:15:37,  1.96s/it]                                                   {'loss': 16.4213, 'grad_norm': 1057.6014404296875, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:32<3:15:37,  1.96s/it]  0%|          | 17/6000 [00:34<3:14:34,  1.95s/it]                                                   {'loss': 16.2736, 'grad_norm': 863.6925659179688, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:34<3:14:34,  1.95s/it]  0%|          | 18/6000 [00:36<3:14:15,  1.95s/it]                                                   {'loss': 12.7289, 'grad_norm': 911.4193115234375, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.0}
  0%|          | 18/6000 [00:36<3:14:15,  1.95s/it]  0%|          | 19/6000 [00:38<3:13:19,  1.94s/it]                                                   {'loss': 13.6485, 'grad_norm': 1272.39794921875, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.0}
  0%|          | 19/6000 [00:38<3:13:19,  1.94s/it]  0%|          | 20/6000 [00:40<3:11:48,  1.92s/it]                                                   {'loss': 15.0507, 'grad_norm': 1170.2203369140625, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 20/6000 [00:40<3:11:48,  1.92s/it]  0%|          | 21/6000 [00:42<3:12:07,  1.93s/it]                                                   {'loss': 12.9805, 'grad_norm': 1203.573974609375, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.0}
  0%|          | 21/6000 [00:42<3:12:07,  1.93s/it]  0%|          | 22/6000 [00:44<3:11:57,  1.93s/it]                                                   {'loss': 12.5635, 'grad_norm': 1701.9012451171875, 'learning_rate': 2.2e-06, 'epoch': 0.0}
  0%|          | 22/6000 [00:44<3:11:57,  1.93s/it]  0%|          | 23/6000 [00:45<3:10:34,  1.91s/it]                                                   {'loss': 12.1544, 'grad_norm': 1183.06640625, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.0}
  0%|          | 23/6000 [00:45<3:10:34,  1.91s/it]  0%|          | 24/6000 [00:47<3:13:24,  1.94s/it]                                                   {'loss': 12.216, 'grad_norm': 1235.507568359375, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.0}
  0%|          | 24/6000 [00:47<3:13:24,  1.94s/it]  0%|          | 25/6000 [00:49<3:12:32,  1.93s/it]                                                   {'loss': 14.1688, 'grad_norm': 1800.3175048828125, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 25/6000 [00:49<3:12:32,  1.93s/it]  0%|          | 26/6000 [00:51<3:11:45,  1.93s/it]                                                   {'loss': 11.2993, 'grad_norm': 1672.53271484375, 'learning_rate': 2.6e-06, 'epoch': 0.0}
  0%|          | 26/6000 [00:51<3:11:45,  1.93s/it]  0%|          | 27/6000 [00:53<3:10:46,  1.92s/it]                                                   {'loss': 10.1879, 'grad_norm': 1650.179931640625, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.0}
  0%|          | 27/6000 [00:53<3:10:46,  1.92s/it]  0%|          | 28/6000 [00:55<3:20:27,  2.01s/it]                                                   {'loss': 9.0597, 'grad_norm': 4402.00634765625, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.0}
  0%|          | 28/6000 [00:55<3:20:27,  2.01s/it]  0%|          | 29/6000 [00:57<3:16:03,  1.97s/it]                                                   {'loss': 8.3296, 'grad_norm': 1652.3026123046875, 'learning_rate': 2.9e-06, 'epoch': 0.0}
  0%|          | 29/6000 [00:57<3:16:03,  1.97s/it]  0%|          | 30/6000 [00:59<3:13:31,  1.95s/it]                                                   {'loss': 6.9813, 'grad_norm': 1210.0406494140625, 'learning_rate': 3e-06, 'epoch': 0.01}
  0%|          | 30/6000 [00:59<3:13:31,  1.95s/it]  1%|          | 31/6000 [01:01<3:12:45,  1.94s/it]                                                   {'loss': 5.4705, 'grad_norm': 953.5492553710938, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.01}
  1%|          | 31/6000 [01:01<3:12:45,  1.94s/it]  1%|          | 32/6000 [01:03<3:11:23,  1.92s/it]                                                   {'loss': 6.0186, 'grad_norm': 1900.401611328125, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.01}
  1%|          | 32/6000 [01:03<3:11:23,  1.92s/it]  1%|          | 33/6000 [01:05<3:11:23,  1.92s/it]                                                   {'loss': 5.2765, 'grad_norm': 2908.26953125, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.01}
  1%|          | 33/6000 [01:05<3:11:23,  1.92s/it]  1%|          | 34/6000 [01:07<3:10:03,  1.91s/it]                                                   {'loss': 5.3164, 'grad_norm': 845.366943359375, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.01}
  1%|          | 34/6000 [01:07<3:10:03,  1.91s/it]  1%|          | 35/6000 [01:09<3:10:31,  1.92s/it]                                                   {'loss': 6.7412, 'grad_norm': 1719.7926025390625, 'learning_rate': 3.5e-06, 'epoch': 0.01}
  1%|          | 35/6000 [01:09<3:10:31,  1.92s/it]  1%|          | 36/6000 [01:11<3:08:52,  1.90s/it]                                                   {'loss': 5.2147, 'grad_norm': 1090.02294921875, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.01}
  1%|          | 36/6000 [01:11<3:08:52,  1.90s/it]  1%|          | 37/6000 [01:12<3:07:51,  1.89s/it]                                                   {'loss': 5.4528, 'grad_norm': 767.8629150390625, 'learning_rate': 3.7e-06, 'epoch': 0.01}
  1%|          | 37/6000 [01:12<3:07:51,  1.89s/it]  1%|          | 38/6000 [01:14<3:07:01,  1.88s/it]                                                   {'loss': 4.668, 'grad_norm': 876.449951171875, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.01}
  1%|          | 38/6000 [01:14<3:07:01,  1.88s/it]  1%|          | 39/6000 [01:16<3:07:03,  1.88s/it]                                                   {'loss': 4.1305, 'grad_norm': 460.8967590332031, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.01}
  1%|          | 39/6000 [01:16<3:07:03,  1.88s/it]  1%|          | 40/6000 [01:18<3:06:41,  1.88s/it]                                                   {'loss': 4.223, 'grad_norm': 447.4038391113281, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 40/6000 [01:18<3:06:41,  1.88s/it]  1%|          | 41/6000 [01:20<3:06:47,  1.88s/it]                                                   {'loss': 4.6215, 'grad_norm': 1338.44970703125, 'learning_rate': 4.1e-06, 'epoch': 0.01}
  1%|          | 41/6000 [01:20<3:06:47,  1.88s/it]  1%|          | 42/6000 [01:22<3:07:00,  1.88s/it]                                                   {'loss': 3.5099, 'grad_norm': 532.8428955078125, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.01}
  1%|          | 42/6000 [01:22<3:07:00,  1.88s/it]  1%|          | 43/6000 [01:24<3:19:48,  2.01s/it]                                                   {'loss': 4.5515, 'grad_norm': 2037.64501953125, 'learning_rate': 4.3e-06, 'epoch': 0.01}
  1%|          | 43/6000 [01:24<3:19:48,  2.01s/it]  1%|          | 44/6000 [01:26<3:19:55,  2.01s/it]                                                   {'loss': 3.6215, 'grad_norm': 363.77349853515625, 'learning_rate': 4.4e-06, 'epoch': 0.01}
  1%|          | 44/6000 [01:26<3:19:55,  2.01s/it]  1%|          | 45/6000 [01:28<3:17:09,  1.99s/it]                                                   {'loss': 3.4607, 'grad_norm': 598.808349609375, 'learning_rate': 4.5e-06, 'epoch': 0.01}
  1%|          | 45/6000 [01:28<3:17:09,  1.99s/it]  1%|          | 46/6000 [01:30<3:15:19,  1.97s/it]                                                   {'loss': 3.8278, 'grad_norm': 449.8585205078125, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.01}
  1%|          | 46/6000 [01:30<3:15:19,  1.97s/it]  1%|          | 47/6000 [01:32<3:12:25,  1.94s/it]                                                   {'loss': 3.5667, 'grad_norm': 330.6480712890625, 'learning_rate': 4.7e-06, 'epoch': 0.01}
  1%|          | 47/6000 [01:32<3:12:25,  1.94s/it]  1%|          | 48/6000 [01:34<3:10:41,  1.92s/it]                                                   {'loss': 3.1959, 'grad_norm': 625.0792236328125, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.01}
  1%|          | 48/6000 [01:34<3:10:41,  1.92s/it]  1%|          | 49/6000 [01:36<3:09:03,  1.91s/it]                                                   {'loss': 3.4569, 'grad_norm': 467.80706787109375, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.01}
  1%|          | 49/6000 [01:36<3:09:03,  1.91s/it]  1%|          | 50/6000 [01:38<3:10:06,  1.92s/it]                                                   {'loss': 3.4614, 'grad_norm': 230.5223846435547, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 50/6000 [01:38<3:10:06,  1.92s/it][2025-11-11 21:54:53,497] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
[2025-11-11 21:54:53,504] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 21:54:53,785] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  1%|          | 51/6000 [01:40<3:31:19,  2.13s/it]                                                   {'loss': 3.3063, 'grad_norm': 508.7091369628906, 'learning_rate': 5.1e-06, 'epoch': 0.01}
  1%|          | 51/6000 [01:40<3:31:19,  2.13s/it]  1%|          | 52/6000 [01:42<3:23:48,  2.06s/it]                                                   {'loss': 3.4419, 'grad_norm': 446.4837341308594, 'learning_rate': 5.2e-06, 'epoch': 0.01}
  1%|          | 52/6000 [01:42<3:23:48,  2.06s/it]  1%|          | 53/6000 [01:44<3:19:33,  2.01s/it]                                                   {'loss': 4.64, 'grad_norm': 597.7972412109375, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.01}
  1%|          | 53/6000 [01:44<3:19:33,  2.01s/it]  1%|          | 54/6000 [01:46<3:15:30,  1.97s/it]                                                   {'loss': 3.2212, 'grad_norm': 260.82147216796875, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.01}
  1%|          | 54/6000 [01:46<3:15:30,  1.97s/it]  1%|          | 55/6000 [01:48<3:12:11,  1.94s/it]                                                   {'loss': 3.2573, 'grad_norm': 420.32086181640625, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.01}
  1%|          | 55/6000 [01:48<3:12:11,  1.94s/it]  1%|          | 56/6000 [01:50<3:10:32,  1.92s/it]                                                   {'loss': 3.591, 'grad_norm': 258.9591979980469, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.01}
  1%|          | 56/6000 [01:50<3:10:32,  1.92s/it]  1%|          | 57/6000 [01:52<3:09:42,  1.92s/it]                                                   {'loss': 3.4441, 'grad_norm': 207.17913818359375, 'learning_rate': 5.7e-06, 'epoch': 0.01}
  1%|          | 57/6000 [01:52<3:09:42,  1.92s/it]  1%|          | 58/6000 [01:53<3:07:46,  1.90s/it]                                                   {'loss': 3.2276, 'grad_norm': 201.3687286376953, 'learning_rate': 5.8e-06, 'epoch': 0.01}
  1%|          | 58/6000 [01:53<3:07:46,  1.90s/it]  1%|          | 59/6000 [01:55<3:05:03,  1.87s/it]                                                   {'loss': 3.3522, 'grad_norm': 512.22412109375, 'learning_rate': 5.9e-06, 'epoch': 0.01}
  1%|          | 59/6000 [01:55<3:05:03,  1.87s/it]  1%|          | 60/6000 [01:57<3:04:44,  1.87s/it]                                                   {'loss': 3.1054, 'grad_norm': 223.27032470703125, 'learning_rate': 6e-06, 'epoch': 0.01}
  1%|          | 60/6000 [01:57<3:04:44,  1.87s/it]  1%|          | 61/6000 [01:59<3:04:00,  1.86s/it]                                                   {'loss': 3.4864, 'grad_norm': 235.26377868652344, 'learning_rate': 6.1e-06, 'epoch': 0.01}
  1%|          | 61/6000 [01:59<3:04:00,  1.86s/it]  1%|          | 62/6000 [02:01<3:04:56,  1.87s/it]                                                   {'loss': 3.2128, 'grad_norm': 294.689697265625, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.01}
  1%|          | 62/6000 [02:01<3:04:56,  1.87s/it]  1%|          | 63/6000 [02:03<3:05:38,  1.88s/it]                                                   {'loss': 3.3221, 'grad_norm': 1030.4072265625, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.01}
  1%|          | 63/6000 [02:03<3:05:38,  1.88s/it]  1%|          | 64/6000 [02:05<3:04:20,  1.86s/it]                                                   {'loss': 3.0497, 'grad_norm': 196.49949645996094, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.01}
  1%|          | 64/6000 [02:05<3:04:20,  1.86s/it]  1%|          | 65/6000 [02:06<3:03:38,  1.86s/it]                                                   {'loss': 3.3768, 'grad_norm': 187.030029296875, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.01}
  1%|          | 65/6000 [02:06<3:03:38,  1.86s/it]  1%|          | 66/6000 [02:08<3:07:29,  1.90s/it]                                                   {'loss': 2.8774, 'grad_norm': 197.36399841308594, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.01}
  1%|          | 66/6000 [02:08<3:07:29,  1.90s/it]  1%|          | 67/6000 [02:10<3:13:50,  1.96s/it]                                                   {'loss': 2.9115, 'grad_norm': 415.59161376953125, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.01}
  1%|          | 67/6000 [02:10<3:13:50,  1.96s/it]  1%|          | 68/6000 [02:12<3:10:23,  1.93s/it]                                                   {'loss': 3.5214, 'grad_norm': 285.2782287597656, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.01}
  1%|          | 68/6000 [02:12<3:10:23,  1.93s/it]  1%|          | 69/6000 [02:14<3:09:01,  1.91s/it]                                                   {'loss': 3.006, 'grad_norm': 137.23391723632812, 'learning_rate': 6.9e-06, 'epoch': 0.01}
  1%|          | 69/6000 [02:14<3:09:01,  1.91s/it]  1%|          | 70/6000 [02:16<3:08:56,  1.91s/it]                                                   {'loss': 2.8171, 'grad_norm': 153.26036071777344, 'learning_rate': 7e-06, 'epoch': 0.01}
  1%|          | 70/6000 [02:16<3:08:56,  1.91s/it]  1%|          | 71/6000 [02:18<3:06:27,  1.89s/it]                                                   {'loss': 3.1765, 'grad_norm': 171.5402069091797, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.01}
  1%|          | 71/6000 [02:18<3:06:27,  1.89s/it]  1%|          | 72/6000 [02:20<3:09:09,  1.91s/it]                                                   {'loss': 3.3954, 'grad_norm': 187.545166015625, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.01}
  1%|          | 72/6000 [02:20<3:09:09,  1.91s/it]  1%|          | 73/6000 [02:22<3:07:41,  1.90s/it]                                                   {'loss': 2.8469, 'grad_norm': 195.48948669433594, 'learning_rate': 7.3e-06, 'epoch': 0.01}
  1%|          | 73/6000 [02:22<3:07:41,  1.90s/it]  1%|          | 74/6000 [02:24<3:05:32,  1.88s/it]                                                   {'loss': 3.0746, 'grad_norm': 224.47430419921875, 'learning_rate': 7.4e-06, 'epoch': 0.01}
  1%|          | 74/6000 [02:24<3:05:32,  1.88s/it]  1%|â–         | 75/6000 [02:26<3:10:14,  1.93s/it]                                                   {'loss': 2.9593, 'grad_norm': 164.36587524414062, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.01}
  1%|â–         | 75/6000 [02:26<3:10:14,  1.93s/it]  1%|â–         | 76/6000 [02:28<3:09:04,  1.92s/it]                                                   {'loss': 3.2212, 'grad_norm': 153.55882263183594, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.01}
  1%|â–         | 76/6000 [02:28<3:09:04,  1.92s/it]  1%|â–         | 77/6000 [02:29<3:07:53,  1.90s/it]                                                   {'loss': 3.3242, 'grad_norm': 147.13902282714844, 'learning_rate': 7.7e-06, 'epoch': 0.01}
  1%|â–         | 77/6000 [02:29<3:07:53,  1.90s/it]  1%|â–         | 78/6000 [02:31<3:09:22,  1.92s/it]                                                   {'loss': 3.0636, 'grad_norm': 119.66771697998047, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.01}
  1%|â–         | 78/6000 [02:31<3:09:22,  1.92s/it]  1%|â–         | 79/6000 [02:33<3:08:22,  1.91s/it]                                                   {'loss': 2.7821, 'grad_norm': 122.88496398925781, 'learning_rate': 7.9e-06, 'epoch': 0.01}
  1%|â–         | 79/6000 [02:33<3:08:22,  1.91s/it]  1%|â–         | 80/6000 [02:35<3:08:21,  1.91s/it]                                                   {'loss': 3.0656, 'grad_norm': 135.96783447265625, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  1%|â–         | 80/6000 [02:35<3:08:21,  1.91s/it]  1%|â–         | 81/6000 [02:37<3:07:33,  1.90s/it]                                                   {'loss': 2.936, 'grad_norm': 437.95751953125, 'learning_rate': 8.1e-06, 'epoch': 0.01}
  1%|â–         | 81/6000 [02:37<3:07:33,  1.90s/it]  1%|â–         | 82/6000 [02:39<3:07:51,  1.90s/it]                                                   {'loss': 2.8618, 'grad_norm': 125.46512603759766, 'learning_rate': 8.2e-06, 'epoch': 0.01}
  1%|â–         | 82/6000 [02:39<3:07:51,  1.90s/it]  1%|â–         | 83/6000 [02:41<3:07:50,  1.90s/it]                                                   {'loss': 2.9547, 'grad_norm': 142.26739501953125, 'learning_rate': 8.3e-06, 'epoch': 0.01}
  1%|â–         | 83/6000 [02:41<3:07:50,  1.90s/it]  1%|â–         | 84/6000 [02:43<3:07:58,  1.91s/it]                                                   {'loss': 2.8829, 'grad_norm': 165.86460876464844, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.01}
  1%|â–         | 84/6000 [02:43<3:07:58,  1.91s/it]  1%|â–         | 85/6000 [02:45<3:10:53,  1.94s/it]                                                   {'loss': 2.8602, 'grad_norm': 133.74728393554688, 'learning_rate': 8.5e-06, 'epoch': 0.01}
  1%|â–         | 85/6000 [02:45<3:10:53,  1.94s/it]  1%|â–         | 86/6000 [02:47<3:09:57,  1.93s/it]                                                   {'loss': 2.8138, 'grad_norm': 117.842041015625, 'learning_rate': 8.6e-06, 'epoch': 0.01}
  1%|â–         | 86/6000 [02:47<3:09:57,  1.93s/it]  1%|â–         | 87/6000 [02:48<3:07:13,  1.90s/it]                                                   {'loss': 2.8663, 'grad_norm': 116.66524505615234, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.01}
  1%|â–         | 87/6000 [02:48<3:07:13,  1.90s/it]  1%|â–         | 88/6000 [02:50<3:05:16,  1.88s/it]                                                   {'loss': 3.0044, 'grad_norm': 196.5617218017578, 'learning_rate': 8.8e-06, 'epoch': 0.01}
  1%|â–         | 88/6000 [02:50<3:05:16,  1.88s/it]  1%|â–         | 89/6000 [02:52<3:04:15,  1.87s/it]                                                   {'loss': 2.5479, 'grad_norm': 112.66143035888672, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.01}
  1%|â–         | 89/6000 [02:52<3:04:15,  1.87s/it]  2%|â–         | 90/6000 [02:54<3:06:29,  1.89s/it]                                                   {'loss': 2.546, 'grad_norm': 99.37785339355469, 'learning_rate': 9e-06, 'epoch': 0.01}
  2%|â–         | 90/6000 [02:54<3:06:29,  1.89s/it]  2%|â–         | 91/6000 [02:56<3:06:02,  1.89s/it]                                                   {'loss': 2.4232, 'grad_norm': 87.99676513671875, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.02}
  2%|â–         | 91/6000 [02:56<3:06:02,  1.89s/it]  2%|â–         | 92/6000 [02:58<3:07:58,  1.91s/it]                                                   {'loss': 2.5579, 'grad_norm': 134.366455078125, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.02}
  2%|â–         | 92/6000 [02:58<3:07:58,  1.91s/it]  2%|â–         | 93/6000 [03:00<3:08:26,  1.91s/it]                                                   {'loss': 2.412, 'grad_norm': 115.03168487548828, 'learning_rate': 9.3e-06, 'epoch': 0.02}
  2%|â–         | 93/6000 [03:00<3:08:26,  1.91s/it]  2%|â–         | 94/6000 [03:02<3:07:49,  1.91s/it]                                                   {'loss': 2.5552, 'grad_norm': 144.3934783935547, 'learning_rate': 9.4e-06, 'epoch': 0.02}
  2%|â–         | 94/6000 [03:02<3:07:49,  1.91s/it]  2%|â–         | 95/6000 [03:04<3:07:03,  1.90s/it]                                                   {'loss': 2.2105, 'grad_norm': 139.1851348876953, 'learning_rate': 9.5e-06, 'epoch': 0.02}
  2%|â–         | 95/6000 [03:04<3:07:03,  1.90s/it]  2%|â–         | 96/6000 [03:06<3:06:05,  1.89s/it]                                                   {'loss': 2.2842, 'grad_norm': 133.68760681152344, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.02}
  2%|â–         | 96/6000 [03:06<3:06:05,  1.89s/it]  2%|â–         | 97/6000 [03:07<3:05:21,  1.88s/it]                                                   {'loss': 2.5125, 'grad_norm': 97.61087799072266, 'learning_rate': 9.7e-06, 'epoch': 0.02}
  2%|â–         | 97/6000 [03:07<3:05:21,  1.88s/it]  2%|â–         | 98/6000 [03:09<3:05:04,  1.88s/it]                                                   {'loss': 2.2614, 'grad_norm': 93.4971923828125, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.02}
  2%|â–         | 98/6000 [03:09<3:05:04,  1.88s/it]  2%|â–         | 99/6000 [03:11<3:03:41,  1.87s/it]                                                   {'loss': 1.8736, 'grad_norm': 101.44398498535156, 'learning_rate': 9.9e-06, 'epoch': 0.02}
  2%|â–         | 99/6000 [03:11<3:03:41,  1.87s/it]  2%|â–         | 100/6000 [03:13<3:02:14,  1.85s/it]                                                    {'loss': 2.1025, 'grad_norm': 104.72521209716797, 'learning_rate': 1e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [03:13<3:02:14,  1.85s/it][2025-11-11 21:56:28,846] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
[2025-11-11 21:56:28,853] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 21:56:29,134] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  2%|â–         | 101/6000 [03:16<3:36:08,  2.20s/it]                                                    {'loss': 1.6394, 'grad_norm': 102.01119232177734, 'learning_rate': 9.998305084745762e-06, 'epoch': 0.02}
  2%|â–         | 101/6000 [03:16<3:36:08,  2.20s/it]  2%|â–         | 102/6000 [03:18<3:26:04,  2.10s/it]                                                    {'loss': 2.0378, 'grad_norm': 85.37857818603516, 'learning_rate': 9.996610169491526e-06, 'epoch': 0.02}
  2%|â–         | 102/6000 [03:18<3:26:04,  2.10s/it]  2%|â–         | 103/6000 [03:20<3:20:38,  2.04s/it]                                                    {'loss': 1.7661, 'grad_norm': 100.30106353759766, 'learning_rate': 9.994915254237289e-06, 'epoch': 0.02}
  2%|â–         | 103/6000 [03:20<3:20:38,  2.04s/it]  2%|â–         | 104/6000 [03:22<3:19:01,  2.03s/it]                                                    {'loss': 1.6751, 'grad_norm': 88.0770034790039, 'learning_rate': 9.993220338983052e-06, 'epoch': 0.02}
  2%|â–         | 104/6000 [03:22<3:19:01,  2.03s/it]  2%|â–         | 105/6000 [03:24<3:14:44,  1.98s/it]                                                    {'loss': 1.442, 'grad_norm': 77.8652572631836, 'learning_rate': 9.991525423728814e-06, 'epoch': 0.02}
  2%|â–         | 105/6000 [03:24<3:14:44,  1.98s/it]  2%|â–         | 106/6000 [03:26<3:14:13,  1.98s/it]                                                    {'loss': 1.2691, 'grad_norm': 104.49791717529297, 'learning_rate': 9.989830508474577e-06, 'epoch': 0.02}
  2%|â–         | 106/6000 [03:26<3:14:13,  1.98s/it]  2%|â–         | 107/6000 [03:27<3:10:23,  1.94s/it]                                                    {'loss': 1.4116, 'grad_norm': 94.79035949707031, 'learning_rate': 9.988135593220339e-06, 'epoch': 0.02}
  2%|â–         | 107/6000 [03:27<3:10:23,  1.94s/it]  2%|â–         | 108/6000 [03:29<3:10:20,  1.94s/it]                                                    {'loss': 1.0703, 'grad_norm': 81.07391357421875, 'learning_rate': 9.986440677966102e-06, 'epoch': 0.02}
  2%|â–         | 108/6000 [03:29<3:10:20,  1.94s/it]  2%|â–         | 109/6000 [03:31<3:12:41,  1.96s/it]                                                    {'loss': 0.9959, 'grad_norm': 75.36346435546875, 'learning_rate': 9.984745762711865e-06, 'epoch': 0.02}
  2%|â–         | 109/6000 [03:31<3:12:41,  1.96s/it]  2%|â–         | 110/6000 [03:33<3:10:32,  1.94s/it]                                                    {'loss': 1.0074, 'grad_norm': 66.53825378417969, 'learning_rate': 9.983050847457628e-06, 'epoch': 0.02}
  2%|â–         | 110/6000 [03:33<3:10:32,  1.94s/it]  2%|â–         | 111/6000 [03:35<3:08:42,  1.92s/it]                                                    {'loss': 0.8093, 'grad_norm': 55.664894104003906, 'learning_rate': 9.98135593220339e-06, 'epoch': 0.02}
  2%|â–         | 111/6000 [03:35<3:08:42,  1.92s/it]  2%|â–         | 112/6000 [03:37<3:11:43,  1.95s/it]                                                    {'loss': 1.0087, 'grad_norm': 115.10186767578125, 'learning_rate': 9.979661016949153e-06, 'epoch': 0.02}
  2%|â–         | 112/6000 [03:37<3:11:43,  1.95s/it]  2%|â–         | 113/6000 [03:39<3:10:55,  1.95s/it]                                                    {'loss': 0.6364, 'grad_norm': 46.526878356933594, 'learning_rate': 9.977966101694917e-06, 'epoch': 0.02}
  2%|â–         | 113/6000 [03:39<3:10:55,  1.95s/it]  2%|â–         | 114/6000 [03:41<3:09:35,  1.93s/it]                                                    {'loss': 0.6578, 'grad_norm': 90.13226318359375, 'learning_rate': 9.97627118644068e-06, 'epoch': 0.02}
  2%|â–         | 114/6000 [03:41<3:09:35,  1.93s/it]  2%|â–         | 115/6000 [03:43<3:08:42,  1.92s/it]                                                    {'loss': 0.8479, 'grad_norm': 72.88560485839844, 'learning_rate': 9.974576271186441e-06, 'epoch': 0.02}
  2%|â–         | 115/6000 [03:43<3:08:42,  1.92s/it]  2%|â–         | 116/6000 [03:45<3:07:40,  1.91s/it]                                                    {'loss': 0.5664, 'grad_norm': 38.486534118652344, 'learning_rate': 9.972881355932205e-06, 'epoch': 0.02}
  2%|â–         | 116/6000 [03:45<3:07:40,  1.91s/it]  2%|â–         | 117/6000 [03:47<3:06:25,  1.90s/it]                                                    {'loss': 1.0896, 'grad_norm': 59.916446685791016, 'learning_rate': 9.971186440677966e-06, 'epoch': 0.02}
  2%|â–         | 117/6000 [03:47<3:06:25,  1.90s/it]  2%|â–         | 118/6000 [03:49<3:11:15,  1.95s/it]                                                    {'loss': 0.6614, 'grad_norm': 48.80194854736328, 'learning_rate': 9.96949152542373e-06, 'epoch': 0.02}
  2%|â–         | 118/6000 [03:49<3:11:15,  1.95s/it]  2%|â–         | 119/6000 [03:51<3:08:38,  1.92s/it]                                                    {'loss': 0.522, 'grad_norm': 38.38718795776367, 'learning_rate': 9.967796610169493e-06, 'epoch': 0.02}
  2%|â–         | 119/6000 [03:51<3:08:38,  1.92s/it]  2%|â–         | 120/6000 [03:52<3:07:40,  1.91s/it]                                                    {'loss': 0.5936, 'grad_norm': 33.2905387878418, 'learning_rate': 9.966101694915256e-06, 'epoch': 0.02}
  2%|â–         | 120/6000 [03:52<3:07:40,  1.91s/it]  2%|â–         | 121/6000 [03:54<3:06:27,  1.90s/it]                                                    {'loss': 0.4119, 'grad_norm': 32.951324462890625, 'learning_rate': 9.964406779661018e-06, 'epoch': 0.02}
  2%|â–         | 121/6000 [03:54<3:06:27,  1.90s/it]  2%|â–         | 122/6000 [03:56<3:06:33,  1.90s/it]                                                    {'loss': 0.4155, 'grad_norm': 34.748077392578125, 'learning_rate': 9.96271186440678e-06, 'epoch': 0.02}
  2%|â–         | 122/6000 [03:56<3:06:33,  1.90s/it]  2%|â–         | 123/6000 [03:58<3:06:24,  1.90s/it]                                                    {'loss': 0.3307, 'grad_norm': 30.172204971313477, 'learning_rate': 9.961016949152543e-06, 'epoch': 0.02}
  2%|â–         | 123/6000 [03:58<3:06:24,  1.90s/it]  2%|â–         | 124/6000 [04:00<3:05:31,  1.89s/it]                                                    {'loss': 0.3695, 'grad_norm': 31.110523223876953, 'learning_rate': 9.959322033898306e-06, 'epoch': 0.02}
  2%|â–         | 124/6000 [04:00<3:05:31,  1.89s/it]  2%|â–         | 125/6000 [04:02<3:09:35,  1.94s/it]                                                    {'loss': 0.2517, 'grad_norm': 39.10848617553711, 'learning_rate': 9.957627118644069e-06, 'epoch': 0.02}
  2%|â–         | 125/6000 [04:02<3:09:35,  1.94s/it]  2%|â–         | 126/6000 [04:04<3:08:19,  1.92s/it]                                                    {'loss': 0.5019, 'grad_norm': 31.24382972717285, 'learning_rate': 9.95593220338983e-06, 'epoch': 0.02}
  2%|â–         | 126/6000 [04:04<3:08:19,  1.92s/it]  2%|â–         | 127/6000 [04:06<3:09:00,  1.93s/it]                                                    {'loss': 0.2759, 'grad_norm': 17.763835906982422, 'learning_rate': 9.954237288135594e-06, 'epoch': 0.02}
  2%|â–         | 127/6000 [04:06<3:09:00,  1.93s/it]  2%|â–         | 128/6000 [04:08<3:09:39,  1.94s/it]                                                    {'loss': 0.3305, 'grad_norm': 29.240156173706055, 'learning_rate': 9.952542372881356e-06, 'epoch': 0.02}
  2%|â–         | 128/6000 [04:08<3:09:39,  1.94s/it]  2%|â–         | 129/6000 [04:10<3:08:59,  1.93s/it]                                                    {'loss': 0.8, 'grad_norm': 32.321571350097656, 'learning_rate': 9.95084745762712e-06, 'epoch': 0.02}
  2%|â–         | 129/6000 [04:10<3:08:59,  1.93s/it]  2%|â–         | 130/6000 [04:12<3:08:14,  1.92s/it]                                                    {'loss': 0.3078, 'grad_norm': 25.473918914794922, 'learning_rate': 9.949152542372882e-06, 'epoch': 0.02}
  2%|â–         | 130/6000 [04:12<3:08:14,  1.92s/it]  2%|â–         | 131/6000 [04:14<3:10:54,  1.95s/it]                                                    {'loss': 0.4573, 'grad_norm': 26.84246253967285, 'learning_rate': 9.947457627118645e-06, 'epoch': 0.02}
  2%|â–         | 131/6000 [04:14<3:10:54,  1.95s/it]  2%|â–         | 132/6000 [04:16<3:11:25,  1.96s/it]                                                    {'loss': 0.1838, 'grad_norm': 17.523914337158203, 'learning_rate': 9.945762711864407e-06, 'epoch': 0.02}
  2%|â–         | 132/6000 [04:16<3:11:25,  1.96s/it]  2%|â–         | 133/6000 [04:18<3:10:03,  1.94s/it]                                                    {'loss': 0.3758, 'grad_norm': 25.113731384277344, 'learning_rate': 9.94406779661017e-06, 'epoch': 0.02}
  2%|â–         | 133/6000 [04:18<3:10:03,  1.94s/it]  2%|â–         | 134/6000 [04:19<3:09:29,  1.94s/it]                                                    {'loss': 0.5383, 'grad_norm': 36.524749755859375, 'learning_rate': 9.942372881355933e-06, 'epoch': 0.02}
  2%|â–         | 134/6000 [04:19<3:09:29,  1.94s/it]  2%|â–         | 135/6000 [04:21<3:07:32,  1.92s/it]                                                    {'loss': 0.4287, 'grad_norm': 34.076087951660156, 'learning_rate': 9.940677966101697e-06, 'epoch': 0.02}
  2%|â–         | 135/6000 [04:21<3:07:32,  1.92s/it]  2%|â–         | 136/6000 [04:23<3:05:33,  1.90s/it]                                                    {'loss': 0.2213, 'grad_norm': 17.54899024963379, 'learning_rate': 9.938983050847458e-06, 'epoch': 0.02}
  2%|â–         | 136/6000 [04:23<3:05:33,  1.90s/it]  2%|â–         | 137/6000 [04:25<3:10:18,  1.95s/it]                                                    {'loss': 0.3105, 'grad_norm': 19.38758087158203, 'learning_rate': 9.937288135593222e-06, 'epoch': 0.02}
  2%|â–         | 137/6000 [04:25<3:10:18,  1.95s/it]  2%|â–         | 138/6000 [04:27<3:09:17,  1.94s/it]                                                    {'loss': 0.3189, 'grad_norm': 18.61573028564453, 'learning_rate': 9.935593220338983e-06, 'epoch': 0.02}
  2%|â–         | 138/6000 [04:27<3:09:17,  1.94s/it]  2%|â–         | 139/6000 [04:29<3:10:54,  1.95s/it]                                                    {'loss': 0.4092, 'grad_norm': 29.81534767150879, 'learning_rate': 9.933898305084746e-06, 'epoch': 0.02}
  2%|â–         | 139/6000 [04:29<3:10:54,  1.95s/it]  2%|â–         | 140/6000 [04:31<3:13:22,  1.98s/it]                                                    {'loss': 0.3044, 'grad_norm': 25.85209083557129, 'learning_rate': 9.93220338983051e-06, 'epoch': 0.02}
  2%|â–         | 140/6000 [04:31<3:13:22,  1.98s/it]  2%|â–         | 141/6000 [04:33<3:11:30,  1.96s/it]                                                    {'loss': 0.3696, 'grad_norm': 26.38091278076172, 'learning_rate': 9.930508474576273e-06, 'epoch': 0.02}
  2%|â–         | 141/6000 [04:33<3:11:30,  1.96s/it]  2%|â–         | 142/6000 [04:35<3:12:07,  1.97s/it]                                                    {'loss': 0.2778, 'grad_norm': 22.05105209350586, 'learning_rate': 9.928813559322035e-06, 'epoch': 0.02}
  2%|â–         | 142/6000 [04:35<3:12:07,  1.97s/it]  2%|â–         | 143/6000 [04:37<3:09:19,  1.94s/it]                                                    {'loss': 0.228, 'grad_norm': 106.3753890991211, 'learning_rate': 9.927118644067796e-06, 'epoch': 0.02}
  2%|â–         | 143/6000 [04:37<3:09:19,  1.94s/it]  2%|â–         | 144/6000 [04:39<3:08:18,  1.93s/it]                                                    {'loss': 0.2326, 'grad_norm': 44.59348678588867, 'learning_rate': 9.92542372881356e-06, 'epoch': 0.02}
  2%|â–         | 144/6000 [04:39<3:08:18,  1.93s/it]  2%|â–         | 145/6000 [04:41<3:05:28,  1.90s/it]                                                    {'loss': 0.1506, 'grad_norm': 12.831721305847168, 'learning_rate': 9.923728813559323e-06, 'epoch': 0.02}
  2%|â–         | 145/6000 [04:41<3:05:28,  1.90s/it]  2%|â–         | 146/6000 [04:43<3:06:43,  1.91s/it]                                                    {'loss': 0.3894, 'grad_norm': 24.036649703979492, 'learning_rate': 9.922033898305086e-06, 'epoch': 0.02}
  2%|â–         | 146/6000 [04:43<3:06:43,  1.91s/it]  2%|â–         | 147/6000 [04:45<3:05:22,  1.90s/it]                                                    {'loss': 0.3276, 'grad_norm': 19.958396911621094, 'learning_rate': 9.920338983050848e-06, 'epoch': 0.02}
  2%|â–         | 147/6000 [04:45<3:05:22,  1.90s/it]  2%|â–         | 148/6000 [04:46<3:05:49,  1.91s/it]                                                    {'loss': 0.1485, 'grad_norm': 17.953872680664062, 'learning_rate': 9.918644067796611e-06, 'epoch': 0.02}
  2%|â–         | 148/6000 [04:46<3:05:49,  1.91s/it]  2%|â–         | 149/6000 [04:48<3:03:29,  1.88s/it]                                                    {'loss': 0.249, 'grad_norm': 23.523324966430664, 'learning_rate': 9.916949152542374e-06, 'epoch': 0.02}
  2%|â–         | 149/6000 [04:48<3:03:29,  1.88s/it]  2%|â–Ž         | 150/6000 [04:50<3:03:25,  1.88s/it]                                                    {'loss': 0.1084, 'grad_norm': 17.92093276977539, 'learning_rate': 9.915254237288137e-06, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [04:50<3:03:25,  1.88s/it][2025-11-11 21:58:06,093] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150
[2025-11-11 21:58:06,100] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 21:58:06,388] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 151/6000 [04:53<3:25:28,  2.11s/it]                                                    {'loss': 0.1078, 'grad_norm': 8.611441612243652, 'learning_rate': 9.913559322033899e-06, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [04:53<3:25:28,  2.11s/it]  3%|â–Ž         | 152/6000 [04:55<3:19:50,  2.05s/it]                                                    {'loss': 0.1142, 'grad_norm': 10.791797637939453, 'learning_rate': 9.911864406779662e-06, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [04:55<3:19:50,  2.05s/it]  3%|â–Ž         | 153/6000 [04:57<3:14:01,  1.99s/it]                                                    {'loss': 0.1954, 'grad_norm': 97.85970306396484, 'learning_rate': 9.910169491525424e-06, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [04:57<3:14:01,  1.99s/it]  3%|â–Ž         | 154/6000 [04:58<3:11:49,  1.97s/it]                                                    {'loss': 0.1794, 'grad_norm': 21.97723388671875, 'learning_rate': 9.908474576271187e-06, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [04:59<3:11:49,  1.97s/it]  3%|â–Ž         | 155/6000 [05:01<3:21:17,  2.07s/it]                                                    {'loss': 0.2322, 'grad_norm': 14.217467308044434, 'learning_rate': 9.90677966101695e-06, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [05:01<3:21:17,  2.07s/it]  3%|â–Ž         | 156/6000 [05:03<3:16:25,  2.02s/it]                                                    {'loss': 0.1123, 'grad_norm': 11.488256454467773, 'learning_rate': 9.905084745762714e-06, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [05:03<3:16:25,  2.02s/it]  3%|â–Ž         | 157/6000 [05:05<3:17:51,  2.03s/it]                                                    {'loss': 0.1813, 'grad_norm': 20.089900970458984, 'learning_rate': 9.903389830508475e-06, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [05:05<3:17:51,  2.03s/it]  3%|â–Ž         | 158/6000 [05:07<3:13:50,  1.99s/it]                                                    {'loss': 0.0871, 'grad_norm': 7.525465965270996, 'learning_rate': 9.901694915254239e-06, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [05:07<3:13:50,  1.99s/it]  3%|â–Ž         | 159/6000 [05:09<3:10:20,  1.96s/it]                                                    {'loss': 0.2023, 'grad_norm': 21.446279525756836, 'learning_rate': 9.9e-06, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [05:09<3:10:20,  1.96s/it]  3%|â–Ž         | 160/6000 [05:11<3:16:04,  2.01s/it]                                                    {'loss': 0.171, 'grad_norm': 15.58542537689209, 'learning_rate': 9.898305084745763e-06, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [05:11<3:16:04,  2.01s/it]  3%|â–Ž         | 161/6000 [05:13<3:13:31,  1.99s/it]                                                    {'loss': 0.2391, 'grad_norm': 20.33731460571289, 'learning_rate': 9.896610169491527e-06, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [05:13<3:13:31,  1.99s/it]  3%|â–Ž         | 162/6000 [05:14<3:10:05,  1.95s/it]                                                    {'loss': 0.077, 'grad_norm': 6.671239852905273, 'learning_rate': 9.89491525423729e-06, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [05:14<3:10:05,  1.95s/it]  3%|â–Ž         | 163/6000 [05:17<3:13:05,  1.98s/it]                                                    {'loss': 0.1714, 'grad_norm': 15.718178749084473, 'learning_rate': 9.893220338983051e-06, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [05:17<3:13:05,  1.98s/it]  3%|â–Ž         | 164/6000 [05:18<3:10:44,  1.96s/it]                                                    {'loss': 0.4913, 'grad_norm': 33.594093322753906, 'learning_rate': 9.891525423728813e-06, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [05:18<3:10:44,  1.96s/it]  3%|â–Ž         | 165/6000 [05:20<3:10:07,  1.95s/it]                                                    {'loss': 0.1015, 'grad_norm': 12.951675415039062, 'learning_rate': 9.889830508474576e-06, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [05:20<3:10:07,  1.95s/it]  3%|â–Ž         | 166/6000 [05:22<3:08:06,  1.93s/it]                                                    {'loss': 0.1403, 'grad_norm': 7.936149597167969, 'learning_rate': 9.88813559322034e-06, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [05:22<3:08:06,  1.93s/it]  3%|â–Ž         | 167/6000 [05:24<3:06:00,  1.91s/it]                                                    {'loss': 0.2186, 'grad_norm': 35.7783203125, 'learning_rate': 9.886440677966103e-06, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [05:24<3:06:00,  1.91s/it]  3%|â–Ž         | 168/6000 [05:26<3:05:03,  1.90s/it]                                                    {'loss': 0.9461, 'grad_norm': 42.92014694213867, 'learning_rate': 9.884745762711864e-06, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [05:26<3:05:03,  1.90s/it]  3%|â–Ž         | 169/6000 [05:28<3:09:08,  1.95s/it]                                                    {'loss': 0.2927, 'grad_norm': 20.13665199279785, 'learning_rate': 9.883050847457628e-06, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [05:28<3:09:08,  1.95s/it]  3%|â–Ž         | 170/6000 [05:30<3:06:52,  1.92s/it]                                                    {'loss': 0.1569, 'grad_norm': 12.121755599975586, 'learning_rate': 9.881355932203391e-06, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [05:30<3:06:52,  1.92s/it]  3%|â–Ž         | 171/6000 [05:32<3:05:31,  1.91s/it]                                                    {'loss': 0.2555, 'grad_norm': 15.8558931350708, 'learning_rate': 9.879661016949154e-06, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [05:32<3:05:31,  1.91s/it]  3%|â–Ž         | 172/6000 [05:34<3:05:57,  1.91s/it]                                                    {'loss': 0.3342, 'grad_norm': 30.151538848876953, 'learning_rate': 9.877966101694916e-06, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [05:34<3:05:57,  1.91s/it]  3%|â–Ž         | 173/6000 [05:36<3:06:13,  1.92s/it]                                                    {'loss': 0.1478, 'grad_norm': 23.749481201171875, 'learning_rate': 9.876271186440679e-06, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [05:36<3:06:13,  1.92s/it]  3%|â–Ž         | 174/6000 [05:38<3:12:22,  1.98s/it]                                                    {'loss': 0.0657, 'grad_norm': 5.767971515655518, 'learning_rate': 9.87457627118644e-06, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [05:38<3:12:22,  1.98s/it]  3%|â–Ž         | 175/6000 [05:40<3:10:00,  1.96s/it]                                                    {'loss': 0.3702, 'grad_norm': 22.65642738342285, 'learning_rate': 9.872881355932204e-06, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [05:40<3:10:00,  1.96s/it]  3%|â–Ž         | 176/6000 [05:42<3:10:08,  1.96s/it]                                                    {'loss': 0.2576, 'grad_norm': 23.77674102783203, 'learning_rate': 9.871186440677967e-06, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [05:42<3:10:08,  1.96s/it]  3%|â–Ž         | 177/6000 [05:44<3:07:56,  1.94s/it]                                                    {'loss': 0.16, 'grad_norm': 13.820286750793457, 'learning_rate': 9.86949152542373e-06, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [05:44<3:07:56,  1.94s/it]  3%|â–Ž         | 178/6000 [05:45<3:08:28,  1.94s/it]                                                    {'loss': 0.1227, 'grad_norm': 12.189225196838379, 'learning_rate': 9.867796610169492e-06, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [05:45<3:08:28,  1.94s/it]  3%|â–Ž         | 179/6000 [05:47<3:06:37,  1.92s/it]                                                    {'loss': 0.1695, 'grad_norm': 11.739541053771973, 'learning_rate': 9.866101694915255e-06, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [05:47<3:06:37,  1.92s/it]  3%|â–Ž         | 180/6000 [05:49<3:07:39,  1.93s/it]                                                    {'loss': 0.2609, 'grad_norm': 15.41657543182373, 'learning_rate': 9.864406779661017e-06, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [05:49<3:07:39,  1.93s/it]  3%|â–Ž         | 181/6000 [05:52<3:16:02,  2.02s/it]                                                    {'loss': 0.307, 'grad_norm': 11.367512702941895, 'learning_rate': 9.86271186440678e-06, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [05:52<3:16:02,  2.02s/it]  3%|â–Ž         | 182/6000 [05:54<3:30:53,  2.17s/it]                                                    {'loss': 0.208, 'grad_norm': 17.62000274658203, 'learning_rate': 9.861016949152544e-06, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [05:54<3:30:53,  2.17s/it]  3%|â–Ž         | 183/6000 [05:56<3:24:26,  2.11s/it]                                                    {'loss': 0.1889, 'grad_norm': 15.008018493652344, 'learning_rate': 9.859322033898307e-06, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [05:56<3:24:26,  2.11s/it]  3%|â–Ž         | 184/6000 [05:58<3:21:39,  2.08s/it]                                                    {'loss': 0.1571, 'grad_norm': 13.574034690856934, 'learning_rate': 9.857627118644068e-06, 'epoch': 0.03}
  3%|â–Ž         | 184/6000 [05:58<3:21:39,  2.08s/it]  3%|â–Ž         | 185/6000 [06:00<3:17:08,  2.03s/it]                                                    {'loss': 0.0918, 'grad_norm': 10.122329711914062, 'learning_rate': 9.855932203389832e-06, 'epoch': 0.03}
  3%|â–Ž         | 185/6000 [06:00<3:17:08,  2.03s/it]  3%|â–Ž         | 186/6000 [06:02<3:14:34,  2.01s/it]                                                    {'loss': 0.1908, 'grad_norm': 19.387062072753906, 'learning_rate': 9.854237288135595e-06, 'epoch': 0.03}
  3%|â–Ž         | 186/6000 [06:02<3:14:34,  2.01s/it]  3%|â–Ž         | 187/6000 [06:04<3:12:03,  1.98s/it]                                                    {'loss': 0.1569, 'grad_norm': 18.159013748168945, 'learning_rate': 9.852542372881356e-06, 'epoch': 0.03}
  3%|â–Ž         | 187/6000 [06:04<3:12:03,  1.98s/it]  3%|â–Ž         | 188/6000 [06:06<3:10:36,  1.97s/it]                                                    {'loss': 0.2571, 'grad_norm': 17.114547729492188, 'learning_rate': 9.85084745762712e-06, 'epoch': 0.03}
  3%|â–Ž         | 188/6000 [06:06<3:10:36,  1.97s/it]  3%|â–Ž         | 189/6000 [06:08<3:08:51,  1.95s/it]                                                    {'loss': 0.2001, 'grad_norm': 13.255970001220703, 'learning_rate': 9.849152542372881e-06, 'epoch': 0.03}
  3%|â–Ž         | 189/6000 [06:08<3:08:51,  1.95s/it]  3%|â–Ž         | 190/6000 [06:10<3:06:09,  1.92s/it]                                                    {'loss': 0.1149, 'grad_norm': 16.891643524169922, 'learning_rate': 9.847457627118645e-06, 'epoch': 0.03}
  3%|â–Ž         | 190/6000 [06:10<3:06:09,  1.92s/it]  3%|â–Ž         | 191/6000 [06:11<3:05:40,  1.92s/it]                                                    {'loss': 0.0663, 'grad_norm': 6.00129508972168, 'learning_rate': 9.845762711864408e-06, 'epoch': 0.03}
  3%|â–Ž         | 191/6000 [06:11<3:05:40,  1.92s/it]  3%|â–Ž         | 192/6000 [06:14<3:13:06,  1.99s/it]                                                    {'loss': 0.1477, 'grad_norm': 16.069049835205078, 'learning_rate': 9.844067796610171e-06, 'epoch': 0.03}
  3%|â–Ž         | 192/6000 [06:14<3:13:06,  1.99s/it]  3%|â–Ž         | 193/6000 [06:16<3:13:07,  2.00s/it]                                                    {'loss': 0.2956, 'grad_norm': 15.888354301452637, 'learning_rate': 9.842372881355933e-06, 'epoch': 0.03}
  3%|â–Ž         | 193/6000 [06:16<3:13:07,  2.00s/it]  3%|â–Ž         | 194/6000 [06:18<3:09:34,  1.96s/it]                                                    {'loss': 0.2186, 'grad_norm': 22.156892776489258, 'learning_rate': 9.840677966101696e-06, 'epoch': 0.03}
  3%|â–Ž         | 194/6000 [06:18<3:09:34,  1.96s/it]  3%|â–Ž         | 195/6000 [06:19<3:08:57,  1.95s/it]                                                    {'loss': 0.0302, 'grad_norm': 4.5238189697265625, 'learning_rate': 9.838983050847458e-06, 'epoch': 0.03}
  3%|â–Ž         | 195/6000 [06:19<3:08:57,  1.95s/it]  3%|â–Ž         | 196/6000 [06:21<3:07:39,  1.94s/it]                                                    {'loss': 0.1155, 'grad_norm': 15.693958282470703, 'learning_rate': 9.837288135593221e-06, 'epoch': 0.03}
  3%|â–Ž         | 196/6000 [06:21<3:07:39,  1.94s/it]  3%|â–Ž         | 197/6000 [06:23<3:11:29,  1.98s/it]                                                    {'loss': 0.0945, 'grad_norm': 6.88771915435791, 'learning_rate': 9.835593220338984e-06, 'epoch': 0.03}
  3%|â–Ž         | 197/6000 [06:23<3:11:29,  1.98s/it]  3%|â–Ž         | 198/6000 [06:25<3:11:18,  1.98s/it]                                                    {'loss': 0.1047, 'grad_norm': 10.917961120605469, 'learning_rate': 9.833898305084747e-06, 'epoch': 0.03}
  3%|â–Ž         | 198/6000 [06:25<3:11:18,  1.98s/it]  3%|â–Ž         | 199/6000 [06:27<3:08:36,  1.95s/it]                                                    {'loss': 0.0935, 'grad_norm': 8.474860191345215, 'learning_rate': 9.832203389830509e-06, 'epoch': 0.03}
  3%|â–Ž         | 199/6000 [06:27<3:08:36,  1.95s/it]  3%|â–Ž         | 200/6000 [06:29<3:11:35,  1.98s/it]                                                    {'loss': 0.3058, 'grad_norm': 30.614545822143555, 'learning_rate': 9.830508474576272e-06, 'epoch': 0.03}
  3%|â–Ž         | 200/6000 [06:29<3:11:35,  1.98s/it][2025-11-11 21:59:45,266] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200
[2025-11-11 21:59:45,273] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 21:59:45,561] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 201/6000 [06:32<3:32:29,  2.20s/it]                                                    {'loss': 0.3483, 'grad_norm': 25.805688858032227, 'learning_rate': 9.828813559322034e-06, 'epoch': 0.03}
  3%|â–Ž         | 201/6000 [06:32<3:32:29,  2.20s/it]  3%|â–Ž         | 202/6000 [06:34<3:23:55,  2.11s/it]                                                    {'loss': 0.221, 'grad_norm': 12.658262252807617, 'learning_rate': 9.827118644067797e-06, 'epoch': 0.03}
  3%|â–Ž         | 202/6000 [06:34<3:23:55,  2.11s/it]  3%|â–Ž         | 203/6000 [06:36<3:19:14,  2.06s/it]                                                    {'loss': 0.1611, 'grad_norm': 21.436843872070312, 'learning_rate': 9.82542372881356e-06, 'epoch': 0.03}
  3%|â–Ž         | 203/6000 [06:36<3:19:14,  2.06s/it]  3%|â–Ž         | 204/6000 [06:38<3:15:45,  2.03s/it]                                                    {'loss': 0.079, 'grad_norm': 8.535421371459961, 'learning_rate': 9.823728813559322e-06, 'epoch': 0.03}
  3%|â–Ž         | 204/6000 [06:38<3:15:45,  2.03s/it]  3%|â–Ž         | 205/6000 [06:40<3:10:29,  1.97s/it]                                                    {'loss': 0.234, 'grad_norm': 22.24861717224121, 'learning_rate': 9.822033898305085e-06, 'epoch': 0.03}
  3%|â–Ž         | 205/6000 [06:40<3:10:29,  1.97s/it]  3%|â–Ž         | 206/6000 [06:42<3:07:42,  1.94s/it]                                                    {'loss': 0.0466, 'grad_norm': 7.446783065795898, 'learning_rate': 9.820338983050849e-06, 'epoch': 0.03}
  3%|â–Ž         | 206/6000 [06:42<3:07:42,  1.94s/it]  3%|â–Ž         | 207/6000 [06:43<3:07:06,  1.94s/it]                                                    {'loss': 0.0361, 'grad_norm': 4.431384086608887, 'learning_rate': 9.818644067796612e-06, 'epoch': 0.03}
  3%|â–Ž         | 207/6000 [06:43<3:07:06,  1.94s/it]  3%|â–Ž         | 208/6000 [06:45<3:06:08,  1.93s/it]                                                    {'loss': 0.2428, 'grad_norm': 17.012659072875977, 'learning_rate': 9.816949152542373e-06, 'epoch': 0.03}
  3%|â–Ž         | 208/6000 [06:45<3:06:08,  1.93s/it]  3%|â–Ž         | 209/6000 [06:47<3:07:04,  1.94s/it]                                                    {'loss': 0.0465, 'grad_norm': 7.280428886413574, 'learning_rate': 9.815254237288137e-06, 'epoch': 0.03}
  3%|â–Ž         | 209/6000 [06:47<3:07:04,  1.94s/it]  4%|â–Ž         | 210/6000 [06:49<3:08:38,  1.95s/it]                                                    {'loss': 0.0896, 'grad_norm': 15.46841812133789, 'learning_rate': 9.813559322033898e-06, 'epoch': 0.04}
  4%|â–Ž         | 210/6000 [06:49<3:08:38,  1.95s/it]  4%|â–Ž         | 211/6000 [06:51<3:08:24,  1.95s/it]                                                    {'loss': 0.08, 'grad_norm': 7.483093738555908, 'learning_rate': 9.811864406779662e-06, 'epoch': 0.04}
  4%|â–Ž         | 211/6000 [06:51<3:08:24,  1.95s/it]  4%|â–Ž         | 212/6000 [06:53<3:09:22,  1.96s/it]                                                    {'loss': 0.2732, 'grad_norm': 15.071211814880371, 'learning_rate': 9.810169491525425e-06, 'epoch': 0.04}
  4%|â–Ž         | 212/6000 [06:53<3:09:22,  1.96s/it]  4%|â–Ž         | 213/6000 [06:55<3:07:58,  1.95s/it]                                                    {'loss': 0.2213, 'grad_norm': 22.902029037475586, 'learning_rate': 9.808474576271188e-06, 'epoch': 0.04}
  4%|â–Ž         | 213/6000 [06:55<3:07:58,  1.95s/it]  4%|â–Ž         | 214/6000 [06:57<3:06:17,  1.93s/it]                                                    {'loss': 0.0774, 'grad_norm': 9.53747272491455, 'learning_rate': 9.80677966101695e-06, 'epoch': 0.04}
  4%|â–Ž         | 214/6000 [06:57<3:06:17,  1.93s/it]  4%|â–Ž         | 215/6000 [06:59<3:04:42,  1.92s/it]                                                    {'loss': 0.2192, 'grad_norm': 25.04012107849121, 'learning_rate': 9.805084745762713e-06, 'epoch': 0.04}
  4%|â–Ž         | 215/6000 [06:59<3:04:42,  1.92s/it]  4%|â–Ž         | 216/6000 [07:01<3:05:07,  1.92s/it]                                                    {'loss': 0.0476, 'grad_norm': 5.106335639953613, 'learning_rate': 9.803389830508474e-06, 'epoch': 0.04}
  4%|â–Ž         | 216/6000 [07:01<3:05:07,  1.92s/it]  4%|â–Ž         | 217/6000 [07:03<3:11:13,  1.98s/it]                                                    {'loss': 0.1018, 'grad_norm': 11.105681419372559, 'learning_rate': 9.801694915254238e-06, 'epoch': 0.04}
  4%|â–Ž         | 217/6000 [07:03<3:11:13,  1.98s/it]  4%|â–Ž         | 218/6000 [07:05<3:09:45,  1.97s/it]                                                    {'loss': 0.1251, 'grad_norm': 12.582578659057617, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.04}
  4%|â–Ž         | 218/6000 [07:05<3:09:45,  1.97s/it]  4%|â–Ž         | 219/6000 [07:07<3:08:23,  1.96s/it]                                                    {'loss': 0.1599, 'grad_norm': 14.896100997924805, 'learning_rate': 9.798305084745764e-06, 'epoch': 0.04}
  4%|â–Ž         | 219/6000 [07:07<3:08:23,  1.96s/it]  4%|â–Ž         | 220/6000 [07:09<3:07:59,  1.95s/it]                                                    {'loss': 0.5287, 'grad_norm': 32.09944534301758, 'learning_rate': 9.796610169491526e-06, 'epoch': 0.04}
  4%|â–Ž         | 220/6000 [07:09<3:07:59,  1.95s/it]  4%|â–Ž         | 221/6000 [07:11<3:08:51,  1.96s/it]                                                    {'loss': 0.1104, 'grad_norm': 20.284404754638672, 'learning_rate': 9.79491525423729e-06, 'epoch': 0.04}
  4%|â–Ž         | 221/6000 [07:11<3:08:51,  1.96s/it]  4%|â–Ž         | 222/6000 [07:13<3:06:20,  1.94s/it]                                                    {'loss': 0.1602, 'grad_norm': 36.80909729003906, 'learning_rate': 9.79322033898305e-06, 'epoch': 0.04}
  4%|â–Ž         | 222/6000 [07:13<3:06:20,  1.94s/it]  4%|â–Ž         | 223/6000 [07:15<3:07:09,  1.94s/it]                                                    {'loss': 0.1683, 'grad_norm': 14.80753231048584, 'learning_rate': 9.791525423728816e-06, 'epoch': 0.04}
  4%|â–Ž         | 223/6000 [07:15<3:07:09,  1.94s/it]  4%|â–Ž         | 224/6000 [07:17<3:06:18,  1.94s/it]                                                    {'loss': 0.0771, 'grad_norm': 5.530135154724121, 'learning_rate': 9.789830508474577e-06, 'epoch': 0.04}
  4%|â–Ž         | 224/6000 [07:17<3:06:18,  1.94s/it]  4%|â–         | 225/6000 [07:19<3:06:57,  1.94s/it]                                                    {'loss': 0.2252, 'grad_norm': 13.778671264648438, 'learning_rate': 9.788135593220339e-06, 'epoch': 0.04}
  4%|â–         | 225/6000 [07:19<3:06:57,  1.94s/it]  4%|â–         | 226/6000 [07:21<3:10:35,  1.98s/it]                                                    {'loss': 0.0996, 'grad_norm': 14.79841136932373, 'learning_rate': 9.786440677966102e-06, 'epoch': 0.04}
  4%|â–         | 226/6000 [07:21<3:10:35,  1.98s/it]  4%|â–         | 227/6000 [07:23<3:08:09,  1.96s/it]                                                    {'loss': 0.2836, 'grad_norm': 23.01027488708496, 'learning_rate': 9.784745762711865e-06, 'epoch': 0.04}
  4%|â–         | 227/6000 [07:23<3:08:09,  1.96s/it]  4%|â–         | 228/6000 [07:24<3:06:54,  1.94s/it]                                                    {'loss': 0.0937, 'grad_norm': 9.764233589172363, 'learning_rate': 9.783050847457629e-06, 'epoch': 0.04}
  4%|â–         | 228/6000 [07:24<3:06:54,  1.94s/it]  4%|â–         | 229/6000 [07:26<3:05:36,  1.93s/it]                                                    {'loss': 0.132, 'grad_norm': 16.920055389404297, 'learning_rate': 9.78135593220339e-06, 'epoch': 0.04}
  4%|â–         | 229/6000 [07:26<3:05:36,  1.93s/it]  4%|â–         | 230/6000 [07:28<3:06:26,  1.94s/it]                                                    {'loss': 0.0812, 'grad_norm': 16.674800872802734, 'learning_rate': 9.779661016949154e-06, 'epoch': 0.04}
  4%|â–         | 230/6000 [07:28<3:06:26,  1.94s/it]  4%|â–         | 231/6000 [07:30<3:05:57,  1.93s/it]                                                    {'loss': 0.0805, 'grad_norm': 9.657057762145996, 'learning_rate': 9.777966101694915e-06, 'epoch': 0.04}
  4%|â–         | 231/6000 [07:30<3:05:57,  1.93s/it]  4%|â–         | 232/6000 [07:32<3:06:26,  1.94s/it]                                                    {'loss': 0.2092, 'grad_norm': 18.772809982299805, 'learning_rate': 9.776271186440678e-06, 'epoch': 0.04}
  4%|â–         | 232/6000 [07:32<3:06:26,  1.94s/it]  4%|â–         | 233/6000 [07:34<3:07:26,  1.95s/it]                                                    {'loss': 0.1307, 'grad_norm': 12.619999885559082, 'learning_rate': 9.774576271186442e-06, 'epoch': 0.04}
  4%|â–         | 233/6000 [07:34<3:07:26,  1.95s/it]  4%|â–         | 234/6000 [07:36<3:07:35,  1.95s/it]                                                    {'loss': 0.1077, 'grad_norm': 12.451866149902344, 'learning_rate': 9.772881355932205e-06, 'epoch': 0.04}
  4%|â–         | 234/6000 [07:36<3:07:35,  1.95s/it]  4%|â–         | 235/6000 [07:38<3:05:57,  1.94s/it]                                                    {'loss': 0.1694, 'grad_norm': 10.520753860473633, 'learning_rate': 9.771186440677967e-06, 'epoch': 0.04}
  4%|â–         | 235/6000 [07:38<3:05:57,  1.94s/it]  4%|â–         | 236/6000 [07:40<3:12:23,  2.00s/it]                                                    {'loss': 0.1104, 'grad_norm': 7.961800575256348, 'learning_rate': 9.76949152542373e-06, 'epoch': 0.04}
  4%|â–         | 236/6000 [07:40<3:12:23,  2.00s/it]  4%|â–         | 237/6000 [07:42<3:11:17,  1.99s/it]                                                    {'loss': 0.3439, 'grad_norm': 17.983631134033203, 'learning_rate': 9.767796610169491e-06, 'epoch': 0.04}
  4%|â–         | 237/6000 [07:42<3:11:17,  1.99s/it]  4%|â–         | 238/6000 [07:44<3:14:07,  2.02s/it]                                                    {'loss': 0.435, 'grad_norm': 15.717788696289062, 'learning_rate': 9.766101694915255e-06, 'epoch': 0.04}
  4%|â–         | 238/6000 [07:44<3:14:07,  2.02s/it]  4%|â–         | 239/6000 [07:46<3:12:10,  2.00s/it]                                                    {'loss': 0.0875, 'grad_norm': 12.106762886047363, 'learning_rate': 9.764406779661018e-06, 'epoch': 0.04}
  4%|â–         | 239/6000 [07:46<3:12:10,  2.00s/it]  4%|â–         | 240/6000 [07:48<3:09:27,  1.97s/it]                                                    {'loss': 0.1303, 'grad_norm': 13.243415832519531, 'learning_rate': 9.762711864406781e-06, 'epoch': 0.04}
  4%|â–         | 240/6000 [07:48<3:09:27,  1.97s/it]  4%|â–         | 241/6000 [07:50<3:09:16,  1.97s/it]                                                    {'loss': 0.1743, 'grad_norm': 13.468232154846191, 'learning_rate': 9.761016949152543e-06, 'epoch': 0.04}
  4%|â–         | 241/6000 [07:50<3:09:16,  1.97s/it]  4%|â–         | 242/6000 [07:52<3:06:32,  1.94s/it]                                                    {'loss': 0.1208, 'grad_norm': 9.743512153625488, 'learning_rate': 9.759322033898306e-06, 'epoch': 0.04}
  4%|â–         | 242/6000 [07:52<3:06:32,  1.94s/it]  4%|â–         | 243/6000 [07:54<3:08:19,  1.96s/it]                                                    {'loss': 0.2036, 'grad_norm': 14.114203453063965, 'learning_rate': 9.75762711864407e-06, 'epoch': 0.04}
  4%|â–         | 243/6000 [07:54<3:08:19,  1.96s/it]  4%|â–         | 244/6000 [07:56<3:06:27,  1.94s/it]                                                    {'loss': 0.097, 'grad_norm': 8.089869499206543, 'learning_rate': 9.755932203389833e-06, 'epoch': 0.04}
  4%|â–         | 244/6000 [07:56<3:06:27,  1.94s/it]  4%|â–         | 245/6000 [07:58<3:07:00,  1.95s/it]                                                    {'loss': 0.0968, 'grad_norm': 9.344141006469727, 'learning_rate': 9.754237288135594e-06, 'epoch': 0.04}
  4%|â–         | 245/6000 [07:58<3:07:00,  1.95s/it]  4%|â–         | 246/6000 [08:00<3:07:26,  1.95s/it]                                                    {'loss': 0.0544, 'grad_norm': 10.534460067749023, 'learning_rate': 9.752542372881356e-06, 'epoch': 0.04}
  4%|â–         | 246/6000 [08:00<3:07:26,  1.95s/it]  4%|â–         | 247/6000 [08:02<3:07:42,  1.96s/it]                                                    {'loss': 0.1349, 'grad_norm': 12.064817428588867, 'learning_rate': 9.750847457627119e-06, 'epoch': 0.04}
  4%|â–         | 247/6000 [08:02<3:07:42,  1.96s/it]  4%|â–         | 248/6000 [08:04<3:07:17,  1.95s/it]                                                    {'loss': 0.0321, 'grad_norm': 4.615086078643799, 'learning_rate': 9.749152542372882e-06, 'epoch': 0.04}
  4%|â–         | 248/6000 [08:04<3:07:17,  1.95s/it]  4%|â–         | 249/6000 [08:06<3:05:03,  1.93s/it]                                                    {'loss': 0.075, 'grad_norm': 12.900365829467773, 'learning_rate': 9.747457627118646e-06, 'epoch': 0.04}
  4%|â–         | 249/6000 [08:06<3:05:03,  1.93s/it]  4%|â–         | 250/6000 [08:07<3:03:15,  1.91s/it]                                                    {'loss': 0.1061, 'grad_norm': 7.525448799133301, 'learning_rate': 9.745762711864407e-06, 'epoch': 0.04}
  4%|â–         | 250/6000 [08:07<3:03:15,  1.91s/it][2025-11-11 22:01:23,320] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-250
[2025-11-11 22:01:23,329] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:01:23,670] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-250/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  4%|â–         | 251/6000 [08:10<3:24:48,  2.14s/it]                                                    {'loss': 0.1162, 'grad_norm': 11.701400756835938, 'learning_rate': 9.74406779661017e-06, 'epoch': 0.04}
  4%|â–         | 251/6000 [08:10<3:24:48,  2.14s/it]  4%|â–         | 252/6000 [08:12<3:22:37,  2.12s/it]                                                    {'loss': 0.0855, 'grad_norm': 8.117926597595215, 'learning_rate': 9.742372881355932e-06, 'epoch': 0.04}
  4%|â–         | 252/6000 [08:12<3:22:37,  2.12s/it]  4%|â–         | 253/6000 [08:14<3:17:10,  2.06s/it]                                                    {'loss': 0.1595, 'grad_norm': 15.89218807220459, 'learning_rate': 9.740677966101695e-06, 'epoch': 0.04}
  4%|â–         | 253/6000 [08:14<3:17:10,  2.06s/it]  4%|â–         | 254/6000 [08:16<3:13:15,  2.02s/it]                                                    {'loss': 0.2065, 'grad_norm': 12.50153636932373, 'learning_rate': 9.738983050847459e-06, 'epoch': 0.04}
  4%|â–         | 254/6000 [08:16<3:13:15,  2.02s/it]  4%|â–         | 255/6000 [08:18<3:09:03,  1.97s/it]                                                    {'loss': 0.1905, 'grad_norm': 17.680736541748047, 'learning_rate': 9.737288135593222e-06, 'epoch': 0.04}
  4%|â–         | 255/6000 [08:18<3:09:03,  1.97s/it]  4%|â–         | 256/6000 [08:20<3:10:12,  1.99s/it]                                                    {'loss': 0.1297, 'grad_norm': 12.13327693939209, 'learning_rate': 9.735593220338983e-06, 'epoch': 0.04}
  4%|â–         | 256/6000 [08:20<3:10:12,  1.99s/it]  4%|â–         | 257/6000 [08:22<3:08:03,  1.96s/it]                                                    {'loss': 0.0951, 'grad_norm': 12.791116714477539, 'learning_rate': 9.733898305084747e-06, 'epoch': 0.04}
  4%|â–         | 257/6000 [08:22<3:08:03,  1.96s/it]  4%|â–         | 258/6000 [08:24<3:06:13,  1.95s/it]                                                    {'loss': 0.0512, 'grad_norm': 3.6000277996063232, 'learning_rate': 9.732203389830508e-06, 'epoch': 0.04}
  4%|â–         | 258/6000 [08:24<3:06:13,  1.95s/it]  4%|â–         | 259/6000 [08:26<3:03:29,  1.92s/it]                                                    {'loss': 0.0446, 'grad_norm': 6.127479076385498, 'learning_rate': 9.730508474576272e-06, 'epoch': 0.04}
  4%|â–         | 259/6000 [08:26<3:03:29,  1.92s/it]  4%|â–         | 260/6000 [08:27<3:02:50,  1.91s/it]                                                    {'loss': 0.0061, 'grad_norm': 0.6119905114173889, 'learning_rate': 9.728813559322035e-06, 'epoch': 0.04}
  4%|â–         | 260/6000 [08:27<3:02:50,  1.91s/it]  4%|â–         | 261/6000 [08:29<3:05:00,  1.93s/it]                                                    {'loss': 0.093, 'grad_norm': 6.064860820770264, 'learning_rate': 9.727118644067798e-06, 'epoch': 0.04}
  4%|â–         | 261/6000 [08:29<3:05:00,  1.93s/it]  4%|â–         | 262/6000 [08:31<3:06:16,  1.95s/it]                                                    {'loss': 0.0387, 'grad_norm': 8.01418399810791, 'learning_rate': 9.72542372881356e-06, 'epoch': 0.04}
  4%|â–         | 262/6000 [08:31<3:06:16,  1.95s/it]  4%|â–         | 263/6000 [08:33<3:09:19,  1.98s/it]                                                    {'loss': 0.0729, 'grad_norm': 6.56519079208374, 'learning_rate': 9.723728813559323e-06, 'epoch': 0.04}
  4%|â–         | 263/6000 [08:33<3:09:19,  1.98s/it]  4%|â–         | 264/6000 [08:35<3:05:58,  1.95s/it]                                                    {'loss': 0.227, 'grad_norm': 18.797636032104492, 'learning_rate': 9.722033898305086e-06, 'epoch': 0.04}
  4%|â–         | 264/6000 [08:35<3:05:58,  1.95s/it]  4%|â–         | 265/6000 [08:37<3:07:22,  1.96s/it]                                                    {'loss': 0.0459, 'grad_norm': 4.9487714767456055, 'learning_rate': 9.72033898305085e-06, 'epoch': 0.04}
  4%|â–         | 265/6000 [08:37<3:07:22,  1.96s/it]  4%|â–         | 266/6000 [08:39<3:06:06,  1.95s/it]                                                    {'loss': 0.0555, 'grad_norm': 6.348206520080566, 'learning_rate': 9.718644067796611e-06, 'epoch': 0.04}
  4%|â–         | 266/6000 [08:39<3:06:06,  1.95s/it]  4%|â–         | 267/6000 [08:41<3:03:42,  1.92s/it]                                                    {'loss': 0.0896, 'grad_norm': 8.981741905212402, 'learning_rate': 9.716949152542373e-06, 'epoch': 0.04}
  4%|â–         | 267/6000 [08:41<3:03:42,  1.92s/it]  4%|â–         | 268/6000 [08:43<3:02:20,  1.91s/it]                                                    {'loss': 0.0428, 'grad_norm': 3.3707172870635986, 'learning_rate': 9.715254237288136e-06, 'epoch': 0.04}
  4%|â–         | 268/6000 [08:43<3:02:20,  1.91s/it]  4%|â–         | 269/6000 [08:45<3:03:37,  1.92s/it]                                                    {'loss': 0.1203, 'grad_norm': 17.38958168029785, 'learning_rate': 9.7135593220339e-06, 'epoch': 0.04}
  4%|â–         | 269/6000 [08:45<3:03:37,  1.92s/it]  4%|â–         | 270/6000 [08:47<3:02:40,  1.91s/it]                                                    {'loss': 0.1045, 'grad_norm': 14.729040145874023, 'learning_rate': 9.711864406779662e-06, 'epoch': 0.04}
  4%|â–         | 270/6000 [08:47<3:02:40,  1.91s/it]  5%|â–         | 271/6000 [08:49<3:01:22,  1.90s/it]                                                    {'loss': 0.0244, 'grad_norm': 3.4034721851348877, 'learning_rate': 9.710169491525424e-06, 'epoch': 0.05}
  5%|â–         | 271/6000 [08:49<3:01:22,  1.90s/it]  5%|â–         | 272/6000 [08:51<3:01:44,  1.90s/it]                                                    {'loss': 0.2147, 'grad_norm': 19.469303131103516, 'learning_rate': 9.708474576271187e-06, 'epoch': 0.05}
  5%|â–         | 272/6000 [08:51<3:01:44,  1.90s/it]  5%|â–         | 273/6000 [08:53<3:02:00,  1.91s/it]                                                    {'loss': 0.0501, 'grad_norm': 10.972200393676758, 'learning_rate': 9.706779661016949e-06, 'epoch': 0.05}
  5%|â–         | 273/6000 [08:53<3:02:00,  1.91s/it]  5%|â–         | 274/6000 [08:54<3:04:12,  1.93s/it]                                                    {'loss': 0.128, 'grad_norm': 11.436408996582031, 'learning_rate': 9.705084745762712e-06, 'epoch': 0.05}
  5%|â–         | 274/6000 [08:54<3:04:12,  1.93s/it]  5%|â–         | 275/6000 [08:56<3:04:14,  1.93s/it]                                                    {'loss': 0.1558, 'grad_norm': 15.635388374328613, 'learning_rate': 9.703389830508475e-06, 'epoch': 0.05}
  5%|â–         | 275/6000 [08:56<3:04:14,  1.93s/it]  5%|â–         | 276/6000 [08:58<3:04:17,  1.93s/it]                                                    {'loss': 0.1257, 'grad_norm': 9.124899864196777, 'learning_rate': 9.701694915254239e-06, 'epoch': 0.05}
  5%|â–         | 276/6000 [08:58<3:04:17,  1.93s/it]  5%|â–         | 277/6000 [09:00<3:03:08,  1.92s/it]                                                    {'loss': 0.1446, 'grad_norm': 12.912132263183594, 'learning_rate': 9.7e-06, 'epoch': 0.05}
  5%|â–         | 277/6000 [09:00<3:03:08,  1.92s/it]  5%|â–         | 278/6000 [09:02<3:02:08,  1.91s/it]                                                    {'loss': 0.0345, 'grad_norm': 3.726355791091919, 'learning_rate': 9.698305084745764e-06, 'epoch': 0.05}
  5%|â–         | 278/6000 [09:02<3:02:08,  1.91s/it]  5%|â–         | 279/6000 [09:04<3:02:15,  1.91s/it]                                                    {'loss': 0.219, 'grad_norm': 12.48205852508545, 'learning_rate': 9.696610169491527e-06, 'epoch': 0.05}
  5%|â–         | 279/6000 [09:04<3:02:15,  1.91s/it]  5%|â–         | 280/6000 [09:06<3:02:06,  1.91s/it]                                                    {'loss': 0.1148, 'grad_norm': 8.074721336364746, 'learning_rate': 9.69491525423729e-06, 'epoch': 0.05}
  5%|â–         | 280/6000 [09:06<3:02:06,  1.91s/it]  5%|â–         | 281/6000 [09:08<3:02:30,  1.91s/it]                                                    {'loss': 0.3286, 'grad_norm': 15.656092643737793, 'learning_rate': 9.693220338983052e-06, 'epoch': 0.05}
  5%|â–         | 281/6000 [09:08<3:02:30,  1.91s/it]  5%|â–         | 282/6000 [09:10<3:06:25,  1.96s/it]                                                    {'loss': 0.1404, 'grad_norm': 14.537700653076172, 'learning_rate': 9.691525423728815e-06, 'epoch': 0.05}
  5%|â–         | 282/6000 [09:10<3:06:25,  1.96s/it]  5%|â–         | 283/6000 [09:12<3:05:35,  1.95s/it]                                                    {'loss': 0.035, 'grad_norm': 6.701271057128906, 'learning_rate': 9.689830508474577e-06, 'epoch': 0.05}
  5%|â–         | 283/6000 [09:12<3:05:35,  1.95s/it]  5%|â–         | 284/6000 [09:14<3:10:41,  2.00s/it]                                                    {'loss': 0.0488, 'grad_norm': 6.6055426597595215, 'learning_rate': 9.68813559322034e-06, 'epoch': 0.05}
  5%|â–         | 284/6000 [09:14<3:10:41,  2.00s/it]  5%|â–         | 285/6000 [09:16<3:08:58,  1.98s/it]                                                    {'loss': 0.1269, 'grad_norm': 12.615889549255371, 'learning_rate': 9.686440677966103e-06, 'epoch': 0.05}
  5%|â–         | 285/6000 [09:16<3:08:58,  1.98s/it]  5%|â–         | 286/6000 [09:18<3:06:48,  1.96s/it]                                                    {'loss': 0.1631, 'grad_norm': 17.196754455566406, 'learning_rate': 9.684745762711866e-06, 'epoch': 0.05}
  5%|â–         | 286/6000 [09:18<3:06:48,  1.96s/it]  5%|â–         | 287/6000 [09:20<3:05:49,  1.95s/it]                                                    {'loss': 0.0685, 'grad_norm': 12.174681663513184, 'learning_rate': 9.683050847457628e-06, 'epoch': 0.05}
  5%|â–         | 287/6000 [09:20<3:05:49,  1.95s/it]  5%|â–         | 288/6000 [09:22<3:03:40,  1.93s/it]                                                    {'loss': 0.0218, 'grad_norm': 3.3100593090057373, 'learning_rate': 9.68135593220339e-06, 'epoch': 0.05}
  5%|â–         | 288/6000 [09:22<3:03:40,  1.93s/it]  5%|â–         | 289/6000 [09:24<3:08:14,  1.98s/it]                                                    {'loss': 0.0973, 'grad_norm': 6.798863410949707, 'learning_rate': 9.679661016949153e-06, 'epoch': 0.05}
  5%|â–         | 289/6000 [09:24<3:08:14,  1.98s/it]  5%|â–         | 290/6000 [09:26<3:04:58,  1.94s/it]                                                    {'loss': 0.0531, 'grad_norm': 7.081611156463623, 'learning_rate': 9.677966101694916e-06, 'epoch': 0.05}
  5%|â–         | 290/6000 [09:26<3:04:58,  1.94s/it]  5%|â–         | 291/6000 [09:27<3:02:21,  1.92s/it]                                                    {'loss': 0.3557, 'grad_norm': 15.564533233642578, 'learning_rate': 9.67627118644068e-06, 'epoch': 0.05}
  5%|â–         | 291/6000 [09:27<3:02:21,  1.92s/it]  5%|â–         | 292/6000 [09:29<3:01:14,  1.91s/it]                                                    {'loss': 0.2974, 'grad_norm': 17.237945556640625, 'learning_rate': 9.674576271186441e-06, 'epoch': 0.05}
  5%|â–         | 292/6000 [09:29<3:01:14,  1.91s/it]  5%|â–         | 293/6000 [09:31<3:00:33,  1.90s/it]                                                    {'loss': 0.0697, 'grad_norm': 8.75666332244873, 'learning_rate': 9.672881355932204e-06, 'epoch': 0.05}
  5%|â–         | 293/6000 [09:31<3:00:33,  1.90s/it]  5%|â–         | 294/6000 [09:33<3:00:28,  1.90s/it]                                                    {'loss': 0.4555, 'grad_norm': 16.209518432617188, 'learning_rate': 9.671186440677966e-06, 'epoch': 0.05}
  5%|â–         | 294/6000 [09:33<3:00:28,  1.90s/it]  5%|â–         | 295/6000 [09:35<2:59:36,  1.89s/it]                                                    {'loss': 0.1196, 'grad_norm': 10.86408519744873, 'learning_rate': 9.669491525423729e-06, 'epoch': 0.05}
  5%|â–         | 295/6000 [09:35<2:59:36,  1.89s/it]  5%|â–         | 296/6000 [09:37<3:01:24,  1.91s/it]                                                    {'loss': 0.1285, 'grad_norm': 7.976175308227539, 'learning_rate': 9.667796610169492e-06, 'epoch': 0.05}
  5%|â–         | 296/6000 [09:37<3:01:24,  1.91s/it]  5%|â–         | 297/6000 [09:39<3:00:55,  1.90s/it]                                                    {'loss': 0.0473, 'grad_norm': 4.741007328033447, 'learning_rate': 9.666101694915256e-06, 'epoch': 0.05}
  5%|â–         | 297/6000 [09:39<3:00:55,  1.90s/it]  5%|â–         | 298/6000 [09:41<3:01:50,  1.91s/it]                                                    {'loss': 0.0725, 'grad_norm': 6.502717018127441, 'learning_rate': 9.664406779661017e-06, 'epoch': 0.05}
  5%|â–         | 298/6000 [09:41<3:01:50,  1.91s/it]  5%|â–         | 299/6000 [09:43<3:11:41,  2.02s/it]                                                    {'loss': 0.0782, 'grad_norm': 4.912985801696777, 'learning_rate': 9.66271186440678e-06, 'epoch': 0.05}
  5%|â–         | 299/6000 [09:43<3:11:41,  2.02s/it]  5%|â–Œ         | 300/6000 [09:45<3:09:13,  1.99s/it]                                                    {'loss': 0.0134, 'grad_norm': 2.785489797592163, 'learning_rate': 9.661016949152544e-06, 'epoch': 0.05}
  5%|â–Œ         | 300/6000 [09:45<3:09:13,  1.99s/it][2025-11-11 22:03:00,877] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300
[2025-11-11 22:03:00,884] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:03:01,167] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  5%|â–Œ         | 301/6000 [09:48<3:29:18,  2.20s/it]                                                    {'loss': 0.2054, 'grad_norm': 19.958372116088867, 'learning_rate': 9.659322033898307e-06, 'epoch': 0.05}
  5%|â–Œ         | 301/6000 [09:48<3:29:18,  2.20s/it]  5%|â–Œ         | 302/6000 [09:50<3:22:19,  2.13s/it]                                                    {'loss': 0.0415, 'grad_norm': 5.2322258949279785, 'learning_rate': 9.657627118644069e-06, 'epoch': 0.05}
  5%|â–Œ         | 302/6000 [09:50<3:22:19,  2.13s/it]  5%|â–Œ         | 303/6000 [09:52<3:15:47,  2.06s/it]                                                    {'loss': 0.0698, 'grad_norm': 10.666529655456543, 'learning_rate': 9.655932203389832e-06, 'epoch': 0.05}
  5%|â–Œ         | 303/6000 [09:52<3:15:47,  2.06s/it]  5%|â–Œ         | 304/6000 [09:53<3:11:07,  2.01s/it]                                                    {'loss': 0.0853, 'grad_norm': 12.3480863571167, 'learning_rate': 9.654237288135593e-06, 'epoch': 0.05}
  5%|â–Œ         | 304/6000 [09:53<3:11:07,  2.01s/it]  5%|â–Œ         | 305/6000 [09:55<3:06:36,  1.97s/it]                                                    {'loss': 0.1881, 'grad_norm': 15.527978897094727, 'learning_rate': 9.652542372881357e-06, 'epoch': 0.05}
  5%|â–Œ         | 305/6000 [09:55<3:06:36,  1.97s/it]  5%|â–Œ         | 306/6000 [09:57<3:03:41,  1.94s/it]                                                    {'loss': 0.0538, 'grad_norm': 6.77026891708374, 'learning_rate': 9.65084745762712e-06, 'epoch': 0.05}
  5%|â–Œ         | 306/6000 [09:57<3:03:41,  1.94s/it]  5%|â–Œ         | 307/6000 [09:59<3:04:06,  1.94s/it]                                                    {'loss': 0.057, 'grad_norm': 4.584674835205078, 'learning_rate': 9.649152542372883e-06, 'epoch': 0.05}
  5%|â–Œ         | 307/6000 [09:59<3:04:06,  1.94s/it]  5%|â–Œ         | 308/6000 [10:01<3:02:57,  1.93s/it]                                                    {'loss': 0.0626, 'grad_norm': 3.0850813388824463, 'learning_rate': 9.647457627118645e-06, 'epoch': 0.05}
  5%|â–Œ         | 308/6000 [10:01<3:02:57,  1.93s/it]  5%|â–Œ         | 309/6000 [10:03<3:03:17,  1.93s/it]                                                    {'loss': 0.2189, 'grad_norm': 13.49921703338623, 'learning_rate': 9.645762711864406e-06, 'epoch': 0.05}
  5%|â–Œ         | 309/6000 [10:03<3:03:17,  1.93s/it]  5%|â–Œ         | 310/6000 [10:05<3:01:19,  1.91s/it]                                                    {'loss': 0.0627, 'grad_norm': 6.5177321434021, 'learning_rate': 9.64406779661017e-06, 'epoch': 0.05}
  5%|â–Œ         | 310/6000 [10:05<3:01:19,  1.91s/it]  5%|â–Œ         | 311/6000 [10:07<3:00:56,  1.91s/it]                                                    {'loss': 0.2573, 'grad_norm': 15.447503089904785, 'learning_rate': 9.642372881355933e-06, 'epoch': 0.05}
  5%|â–Œ         | 311/6000 [10:07<3:00:56,  1.91s/it]  5%|â–Œ         | 312/6000 [10:09<3:01:32,  1.92s/it]                                                    {'loss': 0.358, 'grad_norm': 22.295909881591797, 'learning_rate': 9.640677966101696e-06, 'epoch': 0.05}
  5%|â–Œ         | 312/6000 [10:09<3:01:32,  1.92s/it]  5%|â–Œ         | 313/6000 [10:11<3:01:03,  1.91s/it]                                                    {'loss': 0.1024, 'grad_norm': 10.305608749389648, 'learning_rate': 9.638983050847458e-06, 'epoch': 0.05}
  5%|â–Œ         | 313/6000 [10:11<3:01:03,  1.91s/it]  5%|â–Œ         | 314/6000 [10:12<3:00:03,  1.90s/it]                                                    {'loss': 0.172, 'grad_norm': 11.628393173217773, 'learning_rate': 9.637288135593221e-06, 'epoch': 0.05}
  5%|â–Œ         | 314/6000 [10:12<3:00:03,  1.90s/it]  5%|â–Œ         | 315/6000 [10:14<2:59:40,  1.90s/it]                                                    {'loss': 0.0976, 'grad_norm': 11.260863304138184, 'learning_rate': 9.635593220338983e-06, 'epoch': 0.05}
  5%|â–Œ         | 315/6000 [10:14<2:59:40,  1.90s/it]  5%|â–Œ         | 316/6000 [10:16<2:59:57,  1.90s/it]                                                    {'loss': 0.0163, 'grad_norm': 2.12248158454895, 'learning_rate': 9.633898305084746e-06, 'epoch': 0.05}
  5%|â–Œ         | 316/6000 [10:16<2:59:57,  1.90s/it]  5%|â–Œ         | 317/6000 [10:18<3:05:28,  1.96s/it]                                                    {'loss': 0.107, 'grad_norm': 13.02086067199707, 'learning_rate': 9.63220338983051e-06, 'epoch': 0.05}
  5%|â–Œ         | 317/6000 [10:18<3:05:28,  1.96s/it]  5%|â–Œ         | 318/6000 [10:20<3:05:50,  1.96s/it]                                                    {'loss': 0.1347, 'grad_norm': 13.302054405212402, 'learning_rate': 9.630508474576272e-06, 'epoch': 0.05}
  5%|â–Œ         | 318/6000 [10:20<3:05:50,  1.96s/it]  5%|â–Œ         | 319/6000 [10:22<3:03:29,  1.94s/it]                                                    {'loss': 0.4366, 'grad_norm': 24.01153564453125, 'learning_rate': 9.628813559322034e-06, 'epoch': 0.05}
  5%|â–Œ         | 319/6000 [10:22<3:03:29,  1.94s/it]  5%|â–Œ         | 320/6000 [10:24<3:02:32,  1.93s/it]                                                    {'loss': 0.1922, 'grad_norm': 12.78014850616455, 'learning_rate': 9.627118644067797e-06, 'epoch': 0.05}
  5%|â–Œ         | 320/6000 [10:24<3:02:32,  1.93s/it]  5%|â–Œ         | 321/6000 [10:26<3:05:04,  1.96s/it]                                                    {'loss': 0.0522, 'grad_norm': 8.401925086975098, 'learning_rate': 9.62542372881356e-06, 'epoch': 0.05}
  5%|â–Œ         | 321/6000 [10:26<3:05:04,  1.96s/it]  5%|â–Œ         | 322/6000 [10:28<3:02:39,  1.93s/it]                                                    {'loss': 0.193, 'grad_norm': 17.427106857299805, 'learning_rate': 9.623728813559324e-06, 'epoch': 0.05}
  5%|â–Œ         | 322/6000 [10:28<3:02:39,  1.93s/it]  5%|â–Œ         | 323/6000 [10:30<3:07:41,  1.98s/it]                                                    {'loss': 0.0414, 'grad_norm': 3.17941951751709, 'learning_rate': 9.622033898305085e-06, 'epoch': 0.05}
  5%|â–Œ         | 323/6000 [10:30<3:07:41,  1.98s/it]  5%|â–Œ         | 324/6000 [10:32<3:04:15,  1.95s/it]                                                    {'loss': 0.1269, 'grad_norm': 10.776026725769043, 'learning_rate': 9.620338983050849e-06, 'epoch': 0.05}
  5%|â–Œ         | 324/6000 [10:32<3:04:15,  1.95s/it]  5%|â–Œ         | 325/6000 [10:34<3:02:39,  1.93s/it]                                                    {'loss': 0.1776, 'grad_norm': 13.642250061035156, 'learning_rate': 9.61864406779661e-06, 'epoch': 0.05}
  5%|â–Œ         | 325/6000 [10:34<3:02:39,  1.93s/it]  5%|â–Œ         | 326/6000 [10:36<3:02:10,  1.93s/it]                                                    {'loss': 0.1212, 'grad_norm': 8.407061576843262, 'learning_rate': 9.616949152542374e-06, 'epoch': 0.05}
  5%|â–Œ         | 326/6000 [10:36<3:02:10,  1.93s/it]  5%|â–Œ         | 327/6000 [10:38<2:59:46,  1.90s/it]                                                    {'loss': 0.0436, 'grad_norm': 3.736124277114868, 'learning_rate': 9.615254237288137e-06, 'epoch': 0.05}
  5%|â–Œ         | 327/6000 [10:38<2:59:46,  1.90s/it]  5%|â–Œ         | 328/6000 [10:39<3:00:33,  1.91s/it]                                                    {'loss': 0.043, 'grad_norm': 8.345502853393555, 'learning_rate': 9.6135593220339e-06, 'epoch': 0.05}
  5%|â–Œ         | 328/6000 [10:39<3:00:33,  1.91s/it]  5%|â–Œ         | 329/6000 [10:41<2:59:38,  1.90s/it]                                                    {'loss': 0.1671, 'grad_norm': 12.318243980407715, 'learning_rate': 9.611864406779662e-06, 'epoch': 0.05}
  5%|â–Œ         | 329/6000 [10:41<2:59:38,  1.90s/it]  6%|â–Œ         | 330/6000 [10:43<2:58:52,  1.89s/it]                                                    {'loss': 0.137, 'grad_norm': 11.802030563354492, 'learning_rate': 9.610169491525423e-06, 'epoch': 0.06}
  6%|â–Œ         | 330/6000 [10:43<2:58:52,  1.89s/it]  6%|â–Œ         | 331/6000 [10:45<2:57:36,  1.88s/it]                                                    {'loss': 0.1336, 'grad_norm': 10.372028350830078, 'learning_rate': 9.608474576271187e-06, 'epoch': 0.06}
  6%|â–Œ         | 331/6000 [10:45<2:57:36,  1.88s/it]  6%|â–Œ         | 332/6000 [10:47<2:56:15,  1.87s/it]                                                    {'loss': 0.0797, 'grad_norm': 6.775356769561768, 'learning_rate': 9.60677966101695e-06, 'epoch': 0.06}
  6%|â–Œ         | 332/6000 [10:47<2:56:15,  1.87s/it]  6%|â–Œ         | 333/6000 [10:49<2:55:26,  1.86s/it]                                                    {'loss': 0.035, 'grad_norm': 4.91175651550293, 'learning_rate': 9.605084745762713e-06, 'epoch': 0.06}
  6%|â–Œ         | 333/6000 [10:49<2:55:26,  1.86s/it]  6%|â–Œ         | 334/6000 [10:51<2:57:16,  1.88s/it]                                                    {'loss': 0.0584, 'grad_norm': 3.3620970249176025, 'learning_rate': 9.603389830508475e-06, 'epoch': 0.06}
  6%|â–Œ         | 334/6000 [10:51<2:57:16,  1.88s/it]  6%|â–Œ         | 335/6000 [10:53<2:59:17,  1.90s/it]                                                    {'loss': 0.0752, 'grad_norm': 11.015556335449219, 'learning_rate': 9.601694915254238e-06, 'epoch': 0.06}
  6%|â–Œ         | 335/6000 [10:53<2:59:17,  1.90s/it]  6%|â–Œ         | 336/6000 [10:55<2:58:32,  1.89s/it]                                                    {'loss': 0.0788, 'grad_norm': 5.035325527191162, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.06}
  6%|â–Œ         | 336/6000 [10:55<2:58:32,  1.89s/it]  6%|â–Œ         | 337/6000 [10:56<2:59:23,  1.90s/it]                                                    {'loss': 0.0409, 'grad_norm': 2.798129081726074, 'learning_rate': 9.598305084745765e-06, 'epoch': 0.06}
  6%|â–Œ         | 337/6000 [10:56<2:59:23,  1.90s/it]  6%|â–Œ         | 338/6000 [10:58<2:58:38,  1.89s/it]                                                    {'loss': 0.1072, 'grad_norm': 5.073017120361328, 'learning_rate': 9.596610169491526e-06, 'epoch': 0.06}
  6%|â–Œ         | 338/6000 [10:58<2:58:38,  1.89s/it]  6%|â–Œ         | 339/6000 [11:00<2:58:40,  1.89s/it]                                                    {'loss': 0.0148, 'grad_norm': 1.899692177772522, 'learning_rate': 9.59491525423729e-06, 'epoch': 0.06}
  6%|â–Œ         | 339/6000 [11:00<2:58:40,  1.89s/it]  6%|â–Œ         | 340/6000 [11:02<3:00:58,  1.92s/it]                                                    {'loss': 0.1992, 'grad_norm': 14.400827407836914, 'learning_rate': 9.593220338983051e-06, 'epoch': 0.06}
  6%|â–Œ         | 340/6000 [11:02<3:00:58,  1.92s/it]  6%|â–Œ         | 341/6000 [11:04<2:59:57,  1.91s/it]                                                    {'loss': 0.1066, 'grad_norm': 9.818389892578125, 'learning_rate': 9.591525423728814e-06, 'epoch': 0.06}
  6%|â–Œ         | 341/6000 [11:04<2:59:57,  1.91s/it]  6%|â–Œ         | 342/6000 [11:06<2:59:21,  1.90s/it]                                                    {'loss': 0.1917, 'grad_norm': 8.47175407409668, 'learning_rate': 9.589830508474578e-06, 'epoch': 0.06}
  6%|â–Œ         | 342/6000 [11:06<2:59:21,  1.90s/it]  6%|â–Œ         | 343/6000 [11:08<3:06:40,  1.98s/it]                                                    {'loss': 0.1504, 'grad_norm': 18.339632034301758, 'learning_rate': 9.58813559322034e-06, 'epoch': 0.06}
  6%|â–Œ         | 343/6000 [11:08<3:06:40,  1.98s/it]  6%|â–Œ         | 344/6000 [11:10<3:04:26,  1.96s/it]                                                    {'loss': 0.1165, 'grad_norm': 11.743438720703125, 'learning_rate': 9.586440677966102e-06, 'epoch': 0.06}
  6%|â–Œ         | 344/6000 [11:10<3:04:26,  1.96s/it]  6%|â–Œ         | 345/6000 [11:12<3:02:14,  1.93s/it]                                                    {'loss': 0.0855, 'grad_norm': 7.7375688552856445, 'learning_rate': 9.584745762711866e-06, 'epoch': 0.06}
  6%|â–Œ         | 345/6000 [11:12<3:02:14,  1.93s/it]  6%|â–Œ         | 346/6000 [11:14<3:03:06,  1.94s/it]                                                    {'loss': 0.0978, 'grad_norm': 10.654743194580078, 'learning_rate': 9.583050847457627e-06, 'epoch': 0.06}
  6%|â–Œ         | 346/6000 [11:14<3:03:06,  1.94s/it]  6%|â–Œ         | 347/6000 [11:16<3:00:12,  1.91s/it]                                                    {'loss': 0.04, 'grad_norm': 4.488690376281738, 'learning_rate': 9.58135593220339e-06, 'epoch': 0.06}
  6%|â–Œ         | 347/6000 [11:16<3:00:12,  1.91s/it]  6%|â–Œ         | 348/6000 [11:18<2:59:40,  1.91s/it]                                                    {'loss': 0.1889, 'grad_norm': 10.416924476623535, 'learning_rate': 9.579661016949154e-06, 'epoch': 0.06}
  6%|â–Œ         | 348/6000 [11:18<2:59:40,  1.91s/it]  6%|â–Œ         | 349/6000 [11:20<2:59:57,  1.91s/it]                                                    {'loss': 0.0264, 'grad_norm': 10.970519065856934, 'learning_rate': 9.577966101694917e-06, 'epoch': 0.06}
  6%|â–Œ         | 349/6000 [11:20<2:59:57,  1.91s/it]  6%|â–Œ         | 350/6000 [11:21<2:59:30,  1.91s/it]                                                    {'loss': 0.2565, 'grad_norm': 10.704184532165527, 'learning_rate': 9.576271186440679e-06, 'epoch': 0.06}
  6%|â–Œ         | 350/6000 [11:21<2:59:30,  1.91s/it][2025-11-11 22:04:37,336] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-350
[2025-11-11 22:04:37,344] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:04:37,704] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-350/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  6%|â–Œ         | 351/6000 [11:24<3:25:54,  2.19s/it]                                                    {'loss': 0.1336, 'grad_norm': 14.127612113952637, 'learning_rate': 9.57457627118644e-06, 'epoch': 0.06}
  6%|â–Œ         | 351/6000 [11:24<3:25:54,  2.19s/it]  6%|â–Œ         | 352/6000 [11:26<3:16:15,  2.08s/it]                                                    {'loss': 0.1052, 'grad_norm': 15.24807071685791, 'learning_rate': 9.572881355932203e-06, 'epoch': 0.06}
  6%|â–Œ         | 352/6000 [11:26<3:16:15,  2.08s/it]  6%|â–Œ         | 353/6000 [11:28<3:09:54,  2.02s/it]                                                    {'loss': 0.1243, 'grad_norm': 8.503005027770996, 'learning_rate': 9.571186440677967e-06, 'epoch': 0.06}
  6%|â–Œ         | 353/6000 [11:28<3:09:54,  2.02s/it]  6%|â–Œ         | 354/6000 [11:30<3:07:12,  1.99s/it]                                                    {'loss': 0.0637, 'grad_norm': 6.929838180541992, 'learning_rate': 9.56949152542373e-06, 'epoch': 0.06}
  6%|â–Œ         | 354/6000 [11:30<3:07:12,  1.99s/it]  6%|â–Œ         | 355/6000 [11:32<3:03:16,  1.95s/it]                                                    {'loss': 0.0152, 'grad_norm': 2.0146379470825195, 'learning_rate': 9.567796610169492e-06, 'epoch': 0.06}
  6%|â–Œ         | 355/6000 [11:32<3:03:16,  1.95s/it]  6%|â–Œ         | 356/6000 [11:34<3:03:31,  1.95s/it]                                                    {'loss': 0.0678, 'grad_norm': 8.719919204711914, 'learning_rate': 9.566101694915255e-06, 'epoch': 0.06}
  6%|â–Œ         | 356/6000 [11:34<3:03:31,  1.95s/it]  6%|â–Œ         | 357/6000 [11:36<3:01:57,  1.93s/it]                                                    {'loss': 0.0642, 'grad_norm': 5.795377254486084, 'learning_rate': 9.564406779661018e-06, 'epoch': 0.06}
  6%|â–Œ         | 357/6000 [11:36<3:01:57,  1.93s/it]  6%|â–Œ         | 358/6000 [11:37<2:58:40,  1.90s/it]                                                    {'loss': 0.0491, 'grad_norm': 10.838489532470703, 'learning_rate': 9.562711864406781e-06, 'epoch': 0.06}
  6%|â–Œ         | 358/6000 [11:37<2:58:40,  1.90s/it]  6%|â–Œ         | 359/6000 [11:39<2:58:22,  1.90s/it]                                                    {'loss': 0.101, 'grad_norm': 12.062500953674316, 'learning_rate': 9.561016949152543e-06, 'epoch': 0.06}
  6%|â–Œ         | 359/6000 [11:39<2:58:22,  1.90s/it]  6%|â–Œ         | 360/6000 [11:41<2:57:27,  1.89s/it]                                                    {'loss': 0.2115, 'grad_norm': 11.03702449798584, 'learning_rate': 9.559322033898306e-06, 'epoch': 0.06}
  6%|â–Œ         | 360/6000 [11:41<2:57:27,  1.89s/it]  6%|â–Œ         | 361/6000 [11:43<2:56:08,  1.87s/it]                                                    {'loss': 0.2564, 'grad_norm': 14.540362358093262, 'learning_rate': 9.557627118644068e-06, 'epoch': 0.06}
  6%|â–Œ         | 361/6000 [11:43<2:56:08,  1.87s/it]  6%|â–Œ         | 362/6000 [11:45<2:56:17,  1.88s/it]                                                    {'loss': 0.1476, 'grad_norm': 14.848091125488281, 'learning_rate': 9.555932203389831e-06, 'epoch': 0.06}
  6%|â–Œ         | 362/6000 [11:45<2:56:17,  1.88s/it]  6%|â–Œ         | 363/6000 [11:47<3:00:38,  1.92s/it]                                                    {'loss': 0.025, 'grad_norm': 4.118728160858154, 'learning_rate': 9.554237288135594e-06, 'epoch': 0.06}
  6%|â–Œ         | 363/6000 [11:47<3:00:38,  1.92s/it]  6%|â–Œ         | 364/6000 [11:49<3:00:31,  1.92s/it]                                                    {'loss': 0.0657, 'grad_norm': 7.612853527069092, 'learning_rate': 9.552542372881358e-06, 'epoch': 0.06}
  6%|â–Œ         | 364/6000 [11:49<3:00:31,  1.92s/it]  6%|â–Œ         | 365/6000 [11:51<2:58:51,  1.90s/it]                                                    {'loss': 0.0217, 'grad_norm': 2.3047430515289307, 'learning_rate': 9.55084745762712e-06, 'epoch': 0.06}
  6%|â–Œ         | 365/6000 [11:51<2:58:51,  1.90s/it]  6%|â–Œ         | 366/6000 [11:53<2:57:36,  1.89s/it]                                                    {'loss': 0.0311, 'grad_norm': 2.032877206802368, 'learning_rate': 9.549152542372883e-06, 'epoch': 0.06}
  6%|â–Œ         | 366/6000 [11:53<2:57:36,  1.89s/it]  6%|â–Œ         | 367/6000 [11:54<2:57:06,  1.89s/it]                                                    {'loss': 0.0557, 'grad_norm': 7.360962867736816, 'learning_rate': 9.547457627118644e-06, 'epoch': 0.06}
  6%|â–Œ         | 367/6000 [11:54<2:57:06,  1.89s/it]  6%|â–Œ         | 368/6000 [11:56<3:01:02,  1.93s/it]                                                    {'loss': 0.0903, 'grad_norm': 10.858745574951172, 'learning_rate': 9.545762711864407e-06, 'epoch': 0.06}
  6%|â–Œ         | 368/6000 [11:56<3:01:02,  1.93s/it]  6%|â–Œ         | 369/6000 [11:58<2:59:04,  1.91s/it]                                                    {'loss': 0.0655, 'grad_norm': 5.186822891235352, 'learning_rate': 9.54406779661017e-06, 'epoch': 0.06}
  6%|â–Œ         | 369/6000 [11:58<2:59:04,  1.91s/it]  6%|â–Œ         | 370/6000 [12:00<2:58:57,  1.91s/it]                                                    {'loss': 0.0171, 'grad_norm': 4.713582992553711, 'learning_rate': 9.542372881355934e-06, 'epoch': 0.06}
  6%|â–Œ         | 370/6000 [12:00<2:58:57,  1.91s/it]  6%|â–Œ         | 371/6000 [12:02<2:58:50,  1.91s/it]                                                    {'loss': 0.0953, 'grad_norm': 7.366657257080078, 'learning_rate': 9.540677966101696e-06, 'epoch': 0.06}
  6%|â–Œ         | 371/6000 [12:02<2:58:50,  1.91s/it]  6%|â–Œ         | 372/6000 [12:04<2:58:49,  1.91s/it]                                                    {'loss': 0.0313, 'grad_norm': 6.5396270751953125, 'learning_rate': 9.538983050847457e-06, 'epoch': 0.06}
  6%|â–Œ         | 372/6000 [12:04<2:58:49,  1.91s/it]  6%|â–Œ         | 373/6000 [12:06<2:58:06,  1.90s/it]                                                    {'loss': 0.0062, 'grad_norm': 0.9645143151283264, 'learning_rate': 9.53728813559322e-06, 'epoch': 0.06}
  6%|â–Œ         | 373/6000 [12:06<2:58:06,  1.90s/it]  6%|â–Œ         | 374/6000 [12:08<2:58:08,  1.90s/it]                                                    {'loss': 0.3712, 'grad_norm': 18.532304763793945, 'learning_rate': 9.535593220338984e-06, 'epoch': 0.06}
  6%|â–Œ         | 374/6000 [12:08<2:58:08,  1.90s/it]  6%|â–‹         | 375/6000 [12:10<2:57:56,  1.90s/it]                                                    {'loss': 0.0439, 'grad_norm': 5.951915740966797, 'learning_rate': 9.533898305084747e-06, 'epoch': 0.06}
  6%|â–‹         | 375/6000 [12:10<2:57:56,  1.90s/it]  6%|â–‹         | 376/6000 [12:12<2:56:54,  1.89s/it]                                                    {'loss': 0.119, 'grad_norm': 17.750770568847656, 'learning_rate': 9.532203389830508e-06, 'epoch': 0.06}
  6%|â–‹         | 376/6000 [12:12<2:56:54,  1.89s/it]  6%|â–‹         | 377/6000 [12:13<2:56:23,  1.88s/it]                                                    {'loss': 0.0819, 'grad_norm': 14.826295852661133, 'learning_rate': 9.530508474576272e-06, 'epoch': 0.06}
  6%|â–‹         | 377/6000 [12:13<2:56:23,  1.88s/it]  6%|â–‹         | 378/6000 [12:15<2:57:49,  1.90s/it]                                                    {'loss': 0.0578, 'grad_norm': 3.378063440322876, 'learning_rate': 9.528813559322035e-06, 'epoch': 0.06}
  6%|â–‹         | 378/6000 [12:15<2:57:49,  1.90s/it]  6%|â–‹         | 379/6000 [12:17<2:57:38,  1.90s/it]                                                    {'loss': 0.0339, 'grad_norm': 12.008121490478516, 'learning_rate': 9.527118644067798e-06, 'epoch': 0.06}
  6%|â–‹         | 379/6000 [12:17<2:57:38,  1.90s/it]  6%|â–‹         | 380/6000 [12:19<3:00:07,  1.92s/it]                                                    {'loss': 0.1429, 'grad_norm': 8.612137794494629, 'learning_rate': 9.52542372881356e-06, 'epoch': 0.06}
  6%|â–‹         | 380/6000 [12:19<3:00:07,  1.92s/it]  6%|â–‹         | 381/6000 [12:21<2:58:51,  1.91s/it]                                                    {'loss': 0.0641, 'grad_norm': 10.867738723754883, 'learning_rate': 9.523728813559323e-06, 'epoch': 0.06}
  6%|â–‹         | 381/6000 [12:21<2:58:51,  1.91s/it]  6%|â–‹         | 382/6000 [12:23<2:57:13,  1.89s/it]                                                    {'loss': 0.064, 'grad_norm': 8.643975257873535, 'learning_rate': 9.522033898305085e-06, 'epoch': 0.06}
  6%|â–‹         | 382/6000 [12:23<2:57:13,  1.89s/it]  6%|â–‹         | 383/6000 [12:25<2:56:50,  1.89s/it]                                                    {'loss': 0.0947, 'grad_norm': 9.585556983947754, 'learning_rate': 9.520338983050848e-06, 'epoch': 0.06}
  6%|â–‹         | 383/6000 [12:25<2:56:50,  1.89s/it]  6%|â–‹         | 384/6000 [12:27<2:57:44,  1.90s/it]                                                    {'loss': 0.1154, 'grad_norm': 19.157119750976562, 'learning_rate': 9.518644067796611e-06, 'epoch': 0.06}
  6%|â–‹         | 384/6000 [12:27<2:57:44,  1.90s/it]  6%|â–‹         | 385/6000 [12:29<2:58:59,  1.91s/it]                                                    {'loss': 0.0163, 'grad_norm': 2.916745185852051, 'learning_rate': 9.516949152542375e-06, 'epoch': 0.06}
  6%|â–‹         | 385/6000 [12:29<2:58:59,  1.91s/it]  6%|â–‹         | 386/6000 [12:31<2:57:57,  1.90s/it]                                                    {'loss': 0.0487, 'grad_norm': 12.695883750915527, 'learning_rate': 9.515254237288136e-06, 'epoch': 0.06}
  6%|â–‹         | 386/6000 [12:31<2:57:57,  1.90s/it]  6%|â–‹         | 387/6000 [12:33<3:00:36,  1.93s/it]                                                    {'loss': 0.0818, 'grad_norm': 11.821711540222168, 'learning_rate': 9.5135593220339e-06, 'epoch': 0.06}
  6%|â–‹         | 387/6000 [12:33<3:00:36,  1.93s/it]  6%|â–‹         | 388/6000 [12:35<3:01:00,  1.94s/it]                                                    {'loss': 0.0498, 'grad_norm': 6.13370943069458, 'learning_rate': 9.511864406779661e-06, 'epoch': 0.06}
  6%|â–‹         | 388/6000 [12:35<3:01:00,  1.94s/it]  6%|â–‹         | 389/6000 [12:36<2:59:27,  1.92s/it]                                                    {'loss': 0.0144, 'grad_norm': 3.085771322250366, 'learning_rate': 9.510169491525424e-06, 'epoch': 0.06}
  6%|â–‹         | 389/6000 [12:36<2:59:27,  1.92s/it]  6%|â–‹         | 390/6000 [12:38<2:59:05,  1.92s/it]                                                    {'loss': 0.0287, 'grad_norm': 7.512725830078125, 'learning_rate': 9.508474576271188e-06, 'epoch': 0.07}
  6%|â–‹         | 390/6000 [12:38<2:59:05,  1.92s/it]  7%|â–‹         | 391/6000 [12:40<2:56:35,  1.89s/it]                                                    {'loss': 0.417, 'grad_norm': 19.83355140686035, 'learning_rate': 9.506779661016949e-06, 'epoch': 0.07}
  7%|â–‹         | 391/6000 [12:40<2:56:35,  1.89s/it]  7%|â–‹         | 392/6000 [12:42<2:57:10,  1.90s/it]                                                    {'loss': 0.0113, 'grad_norm': 3.1958985328674316, 'learning_rate': 9.505084745762712e-06, 'epoch': 0.07}
  7%|â–‹         | 392/6000 [12:42<2:57:10,  1.90s/it]  7%|â–‹         | 393/6000 [12:44<2:57:04,  1.89s/it]                                                    {'loss': 0.0242, 'grad_norm': 6.84541130065918, 'learning_rate': 9.503389830508476e-06, 'epoch': 0.07}
  7%|â–‹         | 393/6000 [12:44<2:57:04,  1.89s/it]  7%|â–‹         | 394/6000 [12:46<2:57:20,  1.90s/it]                                                    {'loss': 0.0524, 'grad_norm': 6.267857074737549, 'learning_rate': 9.501694915254239e-06, 'epoch': 0.07}
  7%|â–‹         | 394/6000 [12:46<2:57:20,  1.90s/it]  7%|â–‹         | 395/6000 [12:48<2:57:02,  1.90s/it]                                                    {'loss': 0.0788, 'grad_norm': 16.052154541015625, 'learning_rate': 9.5e-06, 'epoch': 0.07}
  7%|â–‹         | 395/6000 [12:48<2:57:02,  1.90s/it]  7%|â–‹         | 396/6000 [12:50<2:56:30,  1.89s/it]                                                    {'loss': 0.024, 'grad_norm': 2.430091381072998, 'learning_rate': 9.498305084745764e-06, 'epoch': 0.07}
  7%|â–‹         | 396/6000 [12:50<2:56:30,  1.89s/it]  7%|â–‹         | 397/6000 [12:52<3:01:02,  1.94s/it]                                                    {'loss': 0.1098, 'grad_norm': 6.931595802307129, 'learning_rate': 9.496610169491525e-06, 'epoch': 0.07}
  7%|â–‹         | 397/6000 [12:52<3:01:02,  1.94s/it]  7%|â–‹         | 398/6000 [12:54<3:02:46,  1.96s/it]                                                    {'loss': 0.1325, 'grad_norm': 13.430540084838867, 'learning_rate': 9.494915254237289e-06, 'epoch': 0.07}
  7%|â–‹         | 398/6000 [12:54<3:02:46,  1.96s/it]  7%|â–‹         | 399/6000 [12:56<3:01:16,  1.94s/it]                                                    {'loss': 0.1978, 'grad_norm': 19.55072593688965, 'learning_rate': 9.493220338983052e-06, 'epoch': 0.07}
  7%|â–‹         | 399/6000 [12:56<3:01:16,  1.94s/it]  7%|â–‹         | 400/6000 [12:58<2:59:40,  1.93s/it]                                                    {'loss': 0.0318, 'grad_norm': 5.522397994995117, 'learning_rate': 9.491525423728815e-06, 'epoch': 0.07}
  7%|â–‹         | 400/6000 [12:58<2:59:40,  1.93s/it][2025-11-11 22:06:13,428] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400
[2025-11-11 22:06:13,435] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:06:13,713] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  7%|â–‹         | 401/6000 [13:00<3:18:25,  2.13s/it]                                                    {'loss': 0.0482, 'grad_norm': 3.134650945663452, 'learning_rate': 9.489830508474577e-06, 'epoch': 0.07}
  7%|â–‹         | 401/6000 [13:00<3:18:25,  2.13s/it]  7%|â–‹         | 402/6000 [13:02<3:09:58,  2.04s/it]                                                    {'loss': 0.1452, 'grad_norm': 17.824731826782227, 'learning_rate': 9.48813559322034e-06, 'epoch': 0.07}
  7%|â–‹         | 402/6000 [13:02<3:09:58,  2.04s/it]  7%|â–‹         | 403/6000 [13:04<3:04:56,  1.98s/it]                                                    {'loss': 0.2134, 'grad_norm': 17.161115646362305, 'learning_rate': 9.486440677966102e-06, 'epoch': 0.07}
  7%|â–‹         | 403/6000 [13:04<3:04:56,  1.98s/it]  7%|â–‹         | 404/6000 [13:06<3:04:03,  1.97s/it]                                                    {'loss': 0.2269, 'grad_norm': 13.402077674865723, 'learning_rate': 9.484745762711865e-06, 'epoch': 0.07}
  7%|â–‹         | 404/6000 [13:06<3:04:03,  1.97s/it]  7%|â–‹         | 405/6000 [13:08<3:01:34,  1.95s/it]                                                    {'loss': 0.1801, 'grad_norm': 12.025894165039062, 'learning_rate': 9.483050847457628e-06, 'epoch': 0.07}
  7%|â–‹         | 405/6000 [13:08<3:01:34,  1.95s/it]  7%|â–‹         | 406/6000 [13:09<2:58:52,  1.92s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.7834214568138123, 'learning_rate': 9.481355932203391e-06, 'epoch': 0.07}
  7%|â–‹         | 406/6000 [13:09<2:58:52,  1.92s/it]  7%|â–‹         | 407/6000 [13:11<2:57:34,  1.91s/it]                                                    {'loss': 0.0299, 'grad_norm': 3.204383373260498, 'learning_rate': 9.479661016949153e-06, 'epoch': 0.07}
  7%|â–‹         | 407/6000 [13:11<2:57:34,  1.91s/it]  7%|â–‹         | 408/6000 [13:13<3:02:10,  1.95s/it]                                                    {'loss': 0.0945, 'grad_norm': 9.073745727539062, 'learning_rate': 9.477966101694916e-06, 'epoch': 0.07}
  7%|â–‹         | 408/6000 [13:13<3:02:10,  1.95s/it]  7%|â–‹         | 409/6000 [13:15<3:00:58,  1.94s/it]                                                    {'loss': 0.0972, 'grad_norm': 11.608589172363281, 'learning_rate': 9.476271186440678e-06, 'epoch': 0.07}
  7%|â–‹         | 409/6000 [13:15<3:00:58,  1.94s/it]  7%|â–‹         | 410/6000 [13:17<2:58:51,  1.92s/it]                                                    {'loss': 0.1981, 'grad_norm': 21.42583656311035, 'learning_rate': 9.474576271186441e-06, 'epoch': 0.07}
  7%|â–‹         | 410/6000 [13:17<2:58:51,  1.92s/it]  7%|â–‹         | 411/6000 [13:19<3:05:35,  1.99s/it]                                                    {'loss': 0.0179, 'grad_norm': 1.3019901514053345, 'learning_rate': 9.472881355932204e-06, 'epoch': 0.07}
  7%|â–‹         | 411/6000 [13:19<3:05:35,  1.99s/it]  7%|â–‹         | 412/6000 [13:21<3:01:19,  1.95s/it]                                                    {'loss': 0.1057, 'grad_norm': 7.162957191467285, 'learning_rate': 9.471186440677966e-06, 'epoch': 0.07}
  7%|â–‹         | 412/6000 [13:21<3:01:19,  1.95s/it]  7%|â–‹         | 413/6000 [13:23<3:01:37,  1.95s/it]                                                    {'loss': 0.3962, 'grad_norm': 18.054542541503906, 'learning_rate': 9.46949152542373e-06, 'epoch': 0.07}
  7%|â–‹         | 413/6000 [13:23<3:01:37,  1.95s/it]  7%|â–‹         | 414/6000 [13:25<2:59:08,  1.92s/it]                                                    {'loss': 0.1448, 'grad_norm': 14.224140167236328, 'learning_rate': 9.467796610169493e-06, 'epoch': 0.07}
  7%|â–‹         | 414/6000 [13:25<2:59:08,  1.92s/it]  7%|â–‹         | 415/6000 [13:27<2:59:47,  1.93s/it]                                                    {'loss': 0.0479, 'grad_norm': 6.0695295333862305, 'learning_rate': 9.466101694915256e-06, 'epoch': 0.07}
  7%|â–‹         | 415/6000 [13:27<2:59:47,  1.93s/it]  7%|â–‹         | 416/6000 [13:29<2:58:55,  1.92s/it]                                                    {'loss': 0.0598, 'grad_norm': 7.365317344665527, 'learning_rate': 9.464406779661017e-06, 'epoch': 0.07}
  7%|â–‹         | 416/6000 [13:29<2:58:55,  1.92s/it]  7%|â–‹         | 417/6000 [13:31<2:59:18,  1.93s/it]                                                    {'loss': 0.016, 'grad_norm': 4.110325813293457, 'learning_rate': 9.46271186440678e-06, 'epoch': 0.07}
  7%|â–‹         | 417/6000 [13:31<2:59:18,  1.93s/it]  7%|â–‹         | 418/6000 [13:33<2:58:25,  1.92s/it]                                                    {'loss': 0.1091, 'grad_norm': 7.594520092010498, 'learning_rate': 9.461016949152542e-06, 'epoch': 0.07}
  7%|â–‹         | 418/6000 [13:33<2:58:25,  1.92s/it]  7%|â–‹         | 419/6000 [13:35<3:01:04,  1.95s/it]                                                    {'loss': 0.0457, 'grad_norm': 3.4226109981536865, 'learning_rate': 9.459322033898306e-06, 'epoch': 0.07}
  7%|â–‹         | 419/6000 [13:35<3:01:04,  1.95s/it]  7%|â–‹         | 420/6000 [13:37<3:00:08,  1.94s/it]                                                    {'loss': 0.019, 'grad_norm': 4.621494770050049, 'learning_rate': 9.457627118644069e-06, 'epoch': 0.07}
  7%|â–‹         | 420/6000 [13:37<3:00:08,  1.94s/it]  7%|â–‹         | 421/6000 [13:39<2:58:43,  1.92s/it]                                                    {'loss': 0.2259, 'grad_norm': 14.916301727294922, 'learning_rate': 9.455932203389832e-06, 'epoch': 0.07}
  7%|â–‹         | 421/6000 [13:39<2:58:43,  1.92s/it]  7%|â–‹         | 422/6000 [13:40<2:57:25,  1.91s/it]                                                    {'loss': 0.1388, 'grad_norm': 13.377220153808594, 'learning_rate': 9.454237288135594e-06, 'epoch': 0.07}
  7%|â–‹         | 422/6000 [13:40<2:57:25,  1.91s/it]  7%|â–‹         | 423/6000 [13:42<2:57:59,  1.91s/it]                                                    {'loss': 0.0749, 'grad_norm': 8.033788681030273, 'learning_rate': 9.452542372881357e-06, 'epoch': 0.07}
  7%|â–‹         | 423/6000 [13:42<2:57:59,  1.91s/it]  7%|â–‹         | 424/6000 [13:44<2:56:31,  1.90s/it]                                                    {'loss': 0.0135, 'grad_norm': 1.6299139261245728, 'learning_rate': 9.450847457627119e-06, 'epoch': 0.07}
  7%|â–‹         | 424/6000 [13:44<2:56:31,  1.90s/it]  7%|â–‹         | 425/6000 [13:46<2:56:21,  1.90s/it]                                                    {'loss': 0.1009, 'grad_norm': 9.312556266784668, 'learning_rate': 9.449152542372882e-06, 'epoch': 0.07}
  7%|â–‹         | 425/6000 [13:46<2:56:21,  1.90s/it]  7%|â–‹         | 426/6000 [13:48<2:55:54,  1.89s/it]                                                    {'loss': 0.0644, 'grad_norm': 14.285225868225098, 'learning_rate': 9.447457627118645e-06, 'epoch': 0.07}
  7%|â–‹         | 426/6000 [13:48<2:55:54,  1.89s/it]  7%|â–‹         | 427/6000 [13:50<2:56:22,  1.90s/it]                                                    {'loss': 0.1935, 'grad_norm': 9.505450248718262, 'learning_rate': 9.445762711864408e-06, 'epoch': 0.07}
  7%|â–‹         | 427/6000 [13:50<2:56:22,  1.90s/it]  7%|â–‹         | 428/6000 [13:52<2:55:50,  1.89s/it]                                                    {'loss': 0.0084, 'grad_norm': 1.6505221128463745, 'learning_rate': 9.44406779661017e-06, 'epoch': 0.07}
  7%|â–‹         | 428/6000 [13:52<2:55:50,  1.89s/it]  7%|â–‹         | 429/6000 [13:54<2:55:21,  1.89s/it]                                                    {'loss': 0.0454, 'grad_norm': 5.319647312164307, 'learning_rate': 9.442372881355933e-06, 'epoch': 0.07}
  7%|â–‹         | 429/6000 [13:54<2:55:21,  1.89s/it]  7%|â–‹         | 430/6000 [13:56<2:55:19,  1.89s/it]                                                    {'loss': 0.2676, 'grad_norm': 12.768814086914062, 'learning_rate': 9.440677966101696e-06, 'epoch': 0.07}
  7%|â–‹         | 430/6000 [13:56<2:55:19,  1.89s/it]  7%|â–‹         | 431/6000 [13:57<2:55:05,  1.89s/it]                                                    {'loss': 0.084, 'grad_norm': 10.485347747802734, 'learning_rate': 9.43898305084746e-06, 'epoch': 0.07}
  7%|â–‹         | 431/6000 [13:57<2:55:05,  1.89s/it]  7%|â–‹         | 432/6000 [13:59<2:55:06,  1.89s/it]                                                    {'loss': 0.0915, 'grad_norm': 5.907474040985107, 'learning_rate': 9.437288135593221e-06, 'epoch': 0.07}
  7%|â–‹         | 432/6000 [13:59<2:55:06,  1.89s/it]  7%|â–‹         | 433/6000 [14:01<2:54:57,  1.89s/it]                                                    {'loss': 0.0112, 'grad_norm': 1.9895987510681152, 'learning_rate': 9.435593220338983e-06, 'epoch': 0.07}
  7%|â–‹         | 433/6000 [14:01<2:54:57,  1.89s/it]  7%|â–‹         | 434/6000 [14:03<2:55:18,  1.89s/it]                                                    {'loss': 0.0089, 'grad_norm': 1.031530737876892, 'learning_rate': 9.433898305084746e-06, 'epoch': 0.07}
  7%|â–‹         | 434/6000 [14:03<2:55:18,  1.89s/it]  7%|â–‹         | 435/6000 [14:05<2:55:43,  1.89s/it]                                                    {'loss': 0.0613, 'grad_norm': 8.455737113952637, 'learning_rate': 9.43220338983051e-06, 'epoch': 0.07}
  7%|â–‹         | 435/6000 [14:05<2:55:43,  1.89s/it]  7%|â–‹         | 436/6000 [14:07<2:56:03,  1.90s/it]                                                    {'loss': 0.0773, 'grad_norm': 28.603958129882812, 'learning_rate': 9.430508474576273e-06, 'epoch': 0.07}
  7%|â–‹         | 436/6000 [14:07<2:56:03,  1.90s/it]  7%|â–‹         | 437/6000 [14:09<2:56:40,  1.91s/it]                                                    {'loss': 0.0559, 'grad_norm': 4.699077129364014, 'learning_rate': 9.428813559322034e-06, 'epoch': 0.07}
  7%|â–‹         | 437/6000 [14:09<2:56:40,  1.91s/it]  7%|â–‹         | 438/6000 [14:11<2:57:55,  1.92s/it]                                                    {'loss': 0.0511, 'grad_norm': 6.418408393859863, 'learning_rate': 9.427118644067798e-06, 'epoch': 0.07}
  7%|â–‹         | 438/6000 [14:11<2:57:55,  1.92s/it]  7%|â–‹         | 439/6000 [14:13<2:56:59,  1.91s/it]                                                    {'loss': 0.0633, 'grad_norm': 11.32211971282959, 'learning_rate': 9.425423728813559e-06, 'epoch': 0.07}
  7%|â–‹         | 439/6000 [14:13<2:56:59,  1.91s/it]  7%|â–‹         | 440/6000 [14:15<2:56:33,  1.91s/it]                                                    {'loss': 0.0568, 'grad_norm': 9.499273300170898, 'learning_rate': 9.423728813559322e-06, 'epoch': 0.07}
  7%|â–‹         | 440/6000 [14:15<2:56:33,  1.91s/it]  7%|â–‹         | 441/6000 [14:17<3:03:27,  1.98s/it]                                                    {'loss': 0.0167, 'grad_norm': 3.242495059967041, 'learning_rate': 9.422033898305086e-06, 'epoch': 0.07}
  7%|â–‹         | 441/6000 [14:17<3:03:27,  1.98s/it]  7%|â–‹         | 442/6000 [14:19<3:02:01,  1.97s/it]                                                    {'loss': 0.0856, 'grad_norm': 10.667556762695312, 'learning_rate': 9.420338983050849e-06, 'epoch': 0.07}
  7%|â–‹         | 442/6000 [14:19<3:02:01,  1.97s/it]  7%|â–‹         | 443/6000 [14:21<2:59:44,  1.94s/it]                                                    {'loss': 0.0261, 'grad_norm': 1.8896613121032715, 'learning_rate': 9.41864406779661e-06, 'epoch': 0.07}
  7%|â–‹         | 443/6000 [14:21<2:59:44,  1.94s/it]  7%|â–‹         | 444/6000 [14:22<2:57:48,  1.92s/it]                                                    {'loss': 0.0738, 'grad_norm': 10.11275577545166, 'learning_rate': 9.416949152542374e-06, 'epoch': 0.07}
  7%|â–‹         | 444/6000 [14:22<2:57:48,  1.92s/it]  7%|â–‹         | 445/6000 [14:24<2:56:38,  1.91s/it]                                                    {'loss': 0.1576, 'grad_norm': 19.125741958618164, 'learning_rate': 9.415254237288135e-06, 'epoch': 0.07}
  7%|â–‹         | 445/6000 [14:24<2:56:38,  1.91s/it]  7%|â–‹         | 446/6000 [14:26<2:55:40,  1.90s/it]                                                    {'loss': 0.0268, 'grad_norm': 4.835649013519287, 'learning_rate': 9.413559322033899e-06, 'epoch': 0.07}
  7%|â–‹         | 446/6000 [14:26<2:55:40,  1.90s/it]  7%|â–‹         | 447/6000 [14:28<2:56:42,  1.91s/it]                                                    {'loss': 0.112, 'grad_norm': 14.339605331420898, 'learning_rate': 9.411864406779662e-06, 'epoch': 0.07}
  7%|â–‹         | 447/6000 [14:28<2:56:42,  1.91s/it]  7%|â–‹         | 448/6000 [14:30<2:56:00,  1.90s/it]                                                    {'loss': 0.0508, 'grad_norm': 7.181931495666504, 'learning_rate': 9.410169491525425e-06, 'epoch': 0.07}
  7%|â–‹         | 448/6000 [14:30<2:56:00,  1.90s/it]  7%|â–‹         | 449/6000 [14:32<2:55:20,  1.90s/it]                                                    {'loss': 0.042, 'grad_norm': 10.359692573547363, 'learning_rate': 9.408474576271187e-06, 'epoch': 0.07}
  7%|â–‹         | 449/6000 [14:32<2:55:20,  1.90s/it]  8%|â–Š         | 450/6000 [14:34<2:56:27,  1.91s/it]                                                    {'loss': 0.1506, 'grad_norm': 15.336588859558105, 'learning_rate': 9.40677966101695e-06, 'epoch': 0.07}
  8%|â–Š         | 450/6000 [14:34<2:56:27,  1.91s/it][2025-11-11 22:07:49,703] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-450
[2025-11-11 22:07:49,710] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:07:49,995] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-450/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 451/6000 [14:36<3:17:00,  2.13s/it]                                                    {'loss': 0.0612, 'grad_norm': 9.115713119506836, 'learning_rate': 9.405084745762713e-06, 'epoch': 0.08}
  8%|â–Š         | 451/6000 [14:36<3:17:00,  2.13s/it]  8%|â–Š         | 452/6000 [14:38<3:12:05,  2.08s/it]                                                    {'loss': 0.1291, 'grad_norm': 6.206338405609131, 'learning_rate': 9.403389830508477e-06, 'epoch': 0.08}
  8%|â–Š         | 452/6000 [14:38<3:12:05,  2.08s/it]  8%|â–Š         | 453/6000 [14:40<3:06:19,  2.02s/it]                                                    {'loss': 0.1437, 'grad_norm': 10.019250869750977, 'learning_rate': 9.401694915254238e-06, 'epoch': 0.08}
  8%|â–Š         | 453/6000 [14:40<3:06:19,  2.02s/it]  8%|â–Š         | 454/6000 [14:42<3:02:54,  1.98s/it]                                                    {'loss': 0.1475, 'grad_norm': 11.511894226074219, 'learning_rate': 9.4e-06, 'epoch': 0.08}
  8%|â–Š         | 454/6000 [14:42<3:02:54,  1.98s/it]  8%|â–Š         | 455/6000 [14:44<2:58:53,  1.94s/it]                                                    {'loss': 0.0475, 'grad_norm': 5.239468574523926, 'learning_rate': 9.398305084745763e-06, 'epoch': 0.08}
  8%|â–Š         | 455/6000 [14:44<2:58:53,  1.94s/it]  8%|â–Š         | 456/6000 [14:46<2:57:14,  1.92s/it]                                                    {'loss': 0.3048, 'grad_norm': 17.377944946289062, 'learning_rate': 9.396610169491526e-06, 'epoch': 0.08}
  8%|â–Š         | 456/6000 [14:46<2:57:14,  1.92s/it]  8%|â–Š         | 457/6000 [14:48<2:55:02,  1.89s/it]                                                    {'loss': 0.0519, 'grad_norm': 3.415797233581543, 'learning_rate': 9.39491525423729e-06, 'epoch': 0.08}
  8%|â–Š         | 457/6000 [14:48<2:55:02,  1.89s/it]  8%|â–Š         | 458/6000 [14:50<2:53:51,  1.88s/it]                                                    {'loss': 0.1297, 'grad_norm': 17.70437240600586, 'learning_rate': 9.393220338983051e-06, 'epoch': 0.08}
  8%|â–Š         | 458/6000 [14:50<2:53:51,  1.88s/it]  8%|â–Š         | 459/6000 [14:51<2:54:13,  1.89s/it]                                                    {'loss': 0.1815, 'grad_norm': 11.680439949035645, 'learning_rate': 9.391525423728814e-06, 'epoch': 0.08}
  8%|â–Š         | 459/6000 [14:51<2:54:13,  1.89s/it]  8%|â–Š         | 460/6000 [14:53<2:53:17,  1.88s/it]                                                    {'loss': 0.06, 'grad_norm': 5.47872257232666, 'learning_rate': 9.389830508474576e-06, 'epoch': 0.08}
  8%|â–Š         | 460/6000 [14:53<2:53:17,  1.88s/it]  8%|â–Š         | 461/6000 [14:55<2:52:48,  1.87s/it]                                                    {'loss': 0.0553, 'grad_norm': 3.206176280975342, 'learning_rate': 9.38813559322034e-06, 'epoch': 0.08}
  8%|â–Š         | 461/6000 [14:55<2:52:48,  1.87s/it]  8%|â–Š         | 462/6000 [14:57<2:52:25,  1.87s/it]                                                    {'loss': 0.0488, 'grad_norm': 2.750415802001953, 'learning_rate': 9.386440677966103e-06, 'epoch': 0.08}
  8%|â–Š         | 462/6000 [14:57<2:52:25,  1.87s/it]  8%|â–Š         | 463/6000 [14:59<2:53:01,  1.87s/it]                                                    {'loss': 0.1533, 'grad_norm': 14.211408615112305, 'learning_rate': 9.384745762711866e-06, 'epoch': 0.08}
  8%|â–Š         | 463/6000 [14:59<2:53:01,  1.87s/it]  8%|â–Š         | 464/6000 [15:01<2:52:47,  1.87s/it]                                                    {'loss': 0.1331, 'grad_norm': 16.387649536132812, 'learning_rate': 9.383050847457627e-06, 'epoch': 0.08}
  8%|â–Š         | 464/6000 [15:01<2:52:47,  1.87s/it]  8%|â–Š         | 465/6000 [15:03<2:53:41,  1.88s/it]                                                    {'loss': 0.3095, 'grad_norm': 17.873029708862305, 'learning_rate': 9.38135593220339e-06, 'epoch': 0.08}
  8%|â–Š         | 465/6000 [15:03<2:53:41,  1.88s/it]  8%|â–Š         | 466/6000 [15:05<2:53:10,  1.88s/it]                                                    {'loss': 0.0436, 'grad_norm': 3.580031156539917, 'learning_rate': 9.379661016949152e-06, 'epoch': 0.08}
  8%|â–Š         | 466/6000 [15:05<2:53:10,  1.88s/it]  8%|â–Š         | 467/6000 [15:06<2:54:40,  1.89s/it]                                                    {'loss': 0.1698, 'grad_norm': 14.460020065307617, 'learning_rate': 9.377966101694916e-06, 'epoch': 0.08}
  8%|â–Š         | 467/6000 [15:06<2:54:40,  1.89s/it]  8%|â–Š         | 468/6000 [15:08<2:55:50,  1.91s/it]                                                    {'loss': 0.088, 'grad_norm': 6.717678070068359, 'learning_rate': 9.376271186440679e-06, 'epoch': 0.08}
  8%|â–Š         | 468/6000 [15:08<2:55:50,  1.91s/it]  8%|â–Š         | 469/6000 [15:10<2:54:05,  1.89s/it]                                                    {'loss': 0.204, 'grad_norm': 11.536002159118652, 'learning_rate': 9.374576271186442e-06, 'epoch': 0.08}
  8%|â–Š         | 469/6000 [15:10<2:54:05,  1.89s/it]  8%|â–Š         | 470/6000 [15:12<2:53:15,  1.88s/it]                                                    {'loss': 0.0362, 'grad_norm': 5.3508219718933105, 'learning_rate': 9.372881355932204e-06, 'epoch': 0.08}
  8%|â–Š         | 470/6000 [15:12<2:53:15,  1.88s/it]  8%|â–Š         | 471/6000 [15:14<2:52:35,  1.87s/it]                                                    {'loss': 0.1822, 'grad_norm': 12.722342491149902, 'learning_rate': 9.371186440677967e-06, 'epoch': 0.08}
  8%|â–Š         | 471/6000 [15:14<2:52:35,  1.87s/it]  8%|â–Š         | 472/6000 [15:16<2:53:52,  1.89s/it]                                                    {'loss': 0.2303, 'grad_norm': 7.5804595947265625, 'learning_rate': 9.36949152542373e-06, 'epoch': 0.08}
  8%|â–Š         | 472/6000 [15:16<2:53:52,  1.89s/it]  8%|â–Š         | 473/6000 [15:18<2:54:35,  1.90s/it]                                                    {'loss': 0.1452, 'grad_norm': 9.749788284301758, 'learning_rate': 9.367796610169494e-06, 'epoch': 0.08}
  8%|â–Š         | 473/6000 [15:18<2:54:35,  1.90s/it]  8%|â–Š         | 474/6000 [15:20<2:53:37,  1.89s/it]                                                    {'loss': 0.025, 'grad_norm': 2.7898426055908203, 'learning_rate': 9.366101694915255e-06, 'epoch': 0.08}
  8%|â–Š         | 474/6000 [15:20<2:53:37,  1.89s/it]  8%|â–Š         | 475/6000 [15:22<2:53:44,  1.89s/it]                                                    {'loss': 0.0931, 'grad_norm': 4.562988758087158, 'learning_rate': 9.364406779661017e-06, 'epoch': 0.08}
  8%|â–Š         | 475/6000 [15:22<2:53:44,  1.89s/it]  8%|â–Š         | 476/6000 [15:23<2:54:09,  1.89s/it]                                                    {'loss': 0.0647, 'grad_norm': 8.156384468078613, 'learning_rate': 9.36271186440678e-06, 'epoch': 0.08}
  8%|â–Š         | 476/6000 [15:23<2:54:09,  1.89s/it]  8%|â–Š         | 477/6000 [15:25<2:53:47,  1.89s/it]                                                    {'loss': 0.0721, 'grad_norm': 9.849912643432617, 'learning_rate': 9.361016949152543e-06, 'epoch': 0.08}
  8%|â–Š         | 477/6000 [15:25<2:53:47,  1.89s/it]  8%|â–Š         | 478/6000 [15:27<2:54:07,  1.89s/it]                                                    {'loss': 0.0243, 'grad_norm': 5.147907733917236, 'learning_rate': 9.359322033898306e-06, 'epoch': 0.08}
  8%|â–Š         | 478/6000 [15:27<2:54:07,  1.89s/it]  8%|â–Š         | 479/6000 [15:29<2:53:43,  1.89s/it]                                                    {'loss': 0.1092, 'grad_norm': 12.369718551635742, 'learning_rate': 9.357627118644068e-06, 'epoch': 0.08}
  8%|â–Š         | 479/6000 [15:29<2:53:43,  1.89s/it]  8%|â–Š         | 480/6000 [15:31<2:57:33,  1.93s/it]                                                    {'loss': 0.0472, 'grad_norm': 6.8167500495910645, 'learning_rate': 9.355932203389831e-06, 'epoch': 0.08}
  8%|â–Š         | 480/6000 [15:31<2:57:33,  1.93s/it]  8%|â–Š         | 481/6000 [15:33<2:57:26,  1.93s/it]                                                    {'loss': 0.0099, 'grad_norm': 1.292832374572754, 'learning_rate': 9.354237288135593e-06, 'epoch': 0.08}
  8%|â–Š         | 481/6000 [15:33<2:57:26,  1.93s/it]  8%|â–Š         | 482/6000 [15:35<2:55:37,  1.91s/it]                                                    {'loss': 0.0448, 'grad_norm': 6.155189514160156, 'learning_rate': 9.352542372881356e-06, 'epoch': 0.08}
  8%|â–Š         | 482/6000 [15:35<2:55:37,  1.91s/it]  8%|â–Š         | 483/6000 [15:37<2:54:33,  1.90s/it]                                                    {'loss': 0.0978, 'grad_norm': 9.325177192687988, 'learning_rate': 9.35084745762712e-06, 'epoch': 0.08}
  8%|â–Š         | 483/6000 [15:37<2:54:33,  1.90s/it]  8%|â–Š         | 484/6000 [15:39<2:55:50,  1.91s/it]                                                    {'loss': 0.0538, 'grad_norm': 9.188200950622559, 'learning_rate': 9.349152542372883e-06, 'epoch': 0.08}
  8%|â–Š         | 484/6000 [15:39<2:55:50,  1.91s/it]  8%|â–Š         | 485/6000 [15:41<2:59:11,  1.95s/it]                                                    {'loss': 0.04, 'grad_norm': 5.271223545074463, 'learning_rate': 9.347457627118644e-06, 'epoch': 0.08}
  8%|â–Š         | 485/6000 [15:41<2:59:11,  1.95s/it]  8%|â–Š         | 486/6000 [15:43<2:56:39,  1.92s/it]                                                    {'loss': 0.0193, 'grad_norm': 2.985305070877075, 'learning_rate': 9.345762711864408e-06, 'epoch': 0.08}
  8%|â–Š         | 486/6000 [15:43<2:56:39,  1.92s/it]  8%|â–Š         | 487/6000 [15:45<2:56:57,  1.93s/it]                                                    {'loss': 0.2654, 'grad_norm': 10.350582122802734, 'learning_rate': 9.344067796610171e-06, 'epoch': 0.08}
  8%|â–Š         | 487/6000 [15:45<2:56:57,  1.93s/it]  8%|â–Š         | 488/6000 [15:47<2:57:16,  1.93s/it]                                                    {'loss': 0.4257, 'grad_norm': 18.530662536621094, 'learning_rate': 9.342372881355934e-06, 'epoch': 0.08}
  8%|â–Š         | 488/6000 [15:47<2:57:16,  1.93s/it]  8%|â–Š         | 489/6000 [15:48<2:56:26,  1.92s/it]                                                    {'loss': 0.187, 'grad_norm': 17.935571670532227, 'learning_rate': 9.340677966101696e-06, 'epoch': 0.08}
  8%|â–Š         | 489/6000 [15:48<2:56:26,  1.92s/it]  8%|â–Š         | 490/6000 [15:50<2:55:10,  1.91s/it]                                                    {'loss': 0.2057, 'grad_norm': 11.390376091003418, 'learning_rate': 9.338983050847459e-06, 'epoch': 0.08}
  8%|â–Š         | 490/6000 [15:50<2:55:10,  1.91s/it]  8%|â–Š         | 491/6000 [15:52<2:55:34,  1.91s/it]                                                    {'loss': 0.1441, 'grad_norm': 12.634461402893066, 'learning_rate': 9.33728813559322e-06, 'epoch': 0.08}
  8%|â–Š         | 491/6000 [15:52<2:55:34,  1.91s/it]  8%|â–Š         | 492/6000 [15:54<2:54:16,  1.90s/it]                                                    {'loss': 0.0502, 'grad_norm': 3.9724555015563965, 'learning_rate': 9.335593220338984e-06, 'epoch': 0.08}
  8%|â–Š         | 492/6000 [15:54<2:54:16,  1.90s/it]  8%|â–Š         | 493/6000 [15:56<2:54:17,  1.90s/it]                                                    {'loss': 0.096, 'grad_norm': 7.355453014373779, 'learning_rate': 9.333898305084747e-06, 'epoch': 0.08}
  8%|â–Š         | 493/6000 [15:56<2:54:17,  1.90s/it]  8%|â–Š         | 494/6000 [15:58<2:53:14,  1.89s/it]                                                    {'loss': 0.1184, 'grad_norm': 10.121016502380371, 'learning_rate': 9.33220338983051e-06, 'epoch': 0.08}
  8%|â–Š         | 494/6000 [15:58<2:53:14,  1.89s/it]  8%|â–Š         | 495/6000 [16:00<2:54:00,  1.90s/it]                                                    {'loss': 0.0832, 'grad_norm': 7.6713104248046875, 'learning_rate': 9.330508474576272e-06, 'epoch': 0.08}
  8%|â–Š         | 495/6000 [16:00<2:54:00,  1.90s/it]  8%|â–Š         | 496/6000 [16:02<2:53:49,  1.89s/it]                                                    {'loss': 0.0182, 'grad_norm': 2.6662349700927734, 'learning_rate': 9.328813559322034e-06, 'epoch': 0.08}
  8%|â–Š         | 496/6000 [16:02<2:53:49,  1.89s/it]  8%|â–Š         | 497/6000 [16:04<2:52:20,  1.88s/it]                                                    {'loss': 0.0251, 'grad_norm': 4.191686630249023, 'learning_rate': 9.327118644067797e-06, 'epoch': 0.08}
  8%|â–Š         | 497/6000 [16:04<2:52:20,  1.88s/it]  8%|â–Š         | 498/6000 [16:05<2:52:31,  1.88s/it]                                                    {'loss': 0.0921, 'grad_norm': 9.83350944519043, 'learning_rate': 9.32542372881356e-06, 'epoch': 0.08}
  8%|â–Š         | 498/6000 [16:05<2:52:31,  1.88s/it]  8%|â–Š         | 499/6000 [16:07<2:52:23,  1.88s/it]                                                    {'loss': 0.0691, 'grad_norm': 4.069448471069336, 'learning_rate': 9.323728813559323e-06, 'epoch': 0.08}
  8%|â–Š         | 499/6000 [16:07<2:52:23,  1.88s/it]  8%|â–Š         | 500/6000 [16:09<2:53:00,  1.89s/it]                                                    {'loss': 0.1384, 'grad_norm': 12.501069068908691, 'learning_rate': 9.322033898305085e-06, 'epoch': 0.08}
  8%|â–Š         | 500/6000 [16:09<2:53:00,  1.89s/it][2025-11-11 22:09:25,108] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500
[2025-11-11 22:09:25,115] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:09:25,402] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 501/6000 [16:12<3:14:08,  2.12s/it]                                                    {'loss': 0.1198, 'grad_norm': 12.062049865722656, 'learning_rate': 9.320338983050848e-06, 'epoch': 0.08}
  8%|â–Š         | 501/6000 [16:12<3:14:08,  2.12s/it]  8%|â–Š         | 502/6000 [16:14<3:09:56,  2.07s/it]                                                    {'loss': 0.0417, 'grad_norm': 4.972482204437256, 'learning_rate': 9.31864406779661e-06, 'epoch': 0.08}
  8%|â–Š         | 502/6000 [16:14<3:09:56,  2.07s/it]  8%|â–Š         | 503/6000 [16:16<3:04:55,  2.02s/it]                                                    {'loss': 0.105, 'grad_norm': 13.41305923461914, 'learning_rate': 9.316949152542373e-06, 'epoch': 0.08}
  8%|â–Š         | 503/6000 [16:16<3:04:55,  2.02s/it]  8%|â–Š         | 504/6000 [16:18<2:59:45,  1.96s/it]                                                    {'loss': 0.0353, 'grad_norm': 4.720577716827393, 'learning_rate': 9.315254237288136e-06, 'epoch': 0.08}
  8%|â–Š         | 504/6000 [16:18<2:59:45,  1.96s/it]  8%|â–Š         | 505/6000 [16:19<2:58:06,  1.94s/it]                                                    {'loss': 0.1213, 'grad_norm': 11.83594036102295, 'learning_rate': 9.3135593220339e-06, 'epoch': 0.08}
  8%|â–Š         | 505/6000 [16:19<2:58:06,  1.94s/it]  8%|â–Š         | 506/6000 [16:21<2:58:44,  1.95s/it]                                                    {'loss': 0.1451, 'grad_norm': 14.16990852355957, 'learning_rate': 9.311864406779661e-06, 'epoch': 0.08}
  8%|â–Š         | 506/6000 [16:21<2:58:44,  1.95s/it]  8%|â–Š         | 507/6000 [16:23<2:56:02,  1.92s/it]                                                    {'loss': 0.1247, 'grad_norm': 10.378792762756348, 'learning_rate': 9.310169491525424e-06, 'epoch': 0.08}
  8%|â–Š         | 507/6000 [16:23<2:56:02,  1.92s/it]  8%|â–Š         | 508/6000 [16:25<2:53:37,  1.90s/it]                                                    {'loss': 0.0637, 'grad_norm': 7.750091552734375, 'learning_rate': 9.308474576271188e-06, 'epoch': 0.08}
  8%|â–Š         | 508/6000 [16:25<2:53:37,  1.90s/it]  8%|â–Š         | 509/6000 [16:27<2:52:21,  1.88s/it]                                                    {'loss': 0.0751, 'grad_norm': 5.8495893478393555, 'learning_rate': 9.306779661016951e-06, 'epoch': 0.08}
  8%|â–Š         | 509/6000 [16:27<2:52:21,  1.88s/it]  8%|â–Š         | 510/6000 [16:29<2:53:10,  1.89s/it]                                                    {'loss': 0.1405, 'grad_norm': 30.993165969848633, 'learning_rate': 9.305084745762713e-06, 'epoch': 0.09}
  8%|â–Š         | 510/6000 [16:29<2:53:10,  1.89s/it]  9%|â–Š         | 511/6000 [16:31<2:53:34,  1.90s/it]                                                    {'loss': 0.0763, 'grad_norm': 4.606898307800293, 'learning_rate': 9.303389830508476e-06, 'epoch': 0.09}
  9%|â–Š         | 511/6000 [16:31<2:53:34,  1.90s/it]  9%|â–Š         | 512/6000 [16:33<2:52:10,  1.88s/it]                                                    {'loss': 0.0898, 'grad_norm': 10.089995384216309, 'learning_rate': 9.301694915254237e-06, 'epoch': 0.09}
  9%|â–Š         | 512/6000 [16:33<2:52:10,  1.88s/it]  9%|â–Š         | 513/6000 [16:35<2:53:06,  1.89s/it]                                                    {'loss': 0.0822, 'grad_norm': 10.647629737854004, 'learning_rate': 9.3e-06, 'epoch': 0.09}
  9%|â–Š         | 513/6000 [16:35<2:53:06,  1.89s/it]  9%|â–Š         | 514/6000 [16:37<2:58:46,  1.96s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.3100678026676178, 'learning_rate': 9.298305084745764e-06, 'epoch': 0.09}
  9%|â–Š         | 514/6000 [16:37<2:58:46,  1.96s/it]  9%|â–Š         | 515/6000 [16:39<2:56:27,  1.93s/it]                                                    {'loss': 0.1273, 'grad_norm': 9.215694427490234, 'learning_rate': 9.296610169491527e-06, 'epoch': 0.09}
  9%|â–Š         | 515/6000 [16:39<2:56:27,  1.93s/it]  9%|â–Š         | 516/6000 [16:40<2:55:40,  1.92s/it]                                                    {'loss': 0.0924, 'grad_norm': 10.316155433654785, 'learning_rate': 9.294915254237289e-06, 'epoch': 0.09}
  9%|â–Š         | 516/6000 [16:40<2:55:40,  1.92s/it]  9%|â–Š         | 517/6000 [16:42<2:54:45,  1.91s/it]                                                    {'loss': 0.0046, 'grad_norm': 1.244552731513977, 'learning_rate': 9.29322033898305e-06, 'epoch': 0.09}
  9%|â–Š         | 517/6000 [16:42<2:54:45,  1.91s/it]  9%|â–Š         | 518/6000 [16:44<2:53:08,  1.89s/it]                                                    {'loss': 0.202, 'grad_norm': 15.272970199584961, 'learning_rate': 9.291525423728814e-06, 'epoch': 0.09}
  9%|â–Š         | 518/6000 [16:44<2:53:08,  1.89s/it]  9%|â–Š         | 519/6000 [16:46<2:53:14,  1.90s/it]                                                    {'loss': 0.0616, 'grad_norm': 7.096123218536377, 'learning_rate': 9.289830508474577e-06, 'epoch': 0.09}
  9%|â–Š         | 519/6000 [16:46<2:53:14,  1.90s/it]  9%|â–Š         | 520/6000 [16:48<2:54:30,  1.91s/it]                                                    {'loss': 0.1083, 'grad_norm': 9.368260383605957, 'learning_rate': 9.28813559322034e-06, 'epoch': 0.09}
  9%|â–Š         | 520/6000 [16:48<2:54:30,  1.91s/it]  9%|â–Š         | 521/6000 [16:50<2:53:00,  1.89s/it]                                                    {'loss': 0.0333, 'grad_norm': 5.998836517333984, 'learning_rate': 9.286440677966102e-06, 'epoch': 0.09}
  9%|â–Š         | 521/6000 [16:50<2:53:00,  1.89s/it]  9%|â–Š         | 522/6000 [16:52<2:52:21,  1.89s/it]                                                    {'loss': 0.0118, 'grad_norm': 1.95026433467865, 'learning_rate': 9.284745762711865e-06, 'epoch': 0.09}
  9%|â–Š         | 522/6000 [16:52<2:52:21,  1.89s/it]  9%|â–Š         | 523/6000 [16:54<2:52:49,  1.89s/it]                                                    {'loss': 0.0436, 'grad_norm': 6.163888454437256, 'learning_rate': 9.283050847457627e-06, 'epoch': 0.09}
  9%|â–Š         | 523/6000 [16:54<2:52:49,  1.89s/it]  9%|â–Š         | 524/6000 [16:56<2:52:04,  1.89s/it]                                                    {'loss': 0.1786, 'grad_norm': 11.593180656433105, 'learning_rate': 9.28135593220339e-06, 'epoch': 0.09}
  9%|â–Š         | 524/6000 [16:56<2:52:04,  1.89s/it]  9%|â–‰         | 525/6000 [16:57<2:51:53,  1.88s/it]                                                    {'loss': 0.1797, 'grad_norm': 16.52405548095703, 'learning_rate': 9.279661016949153e-06, 'epoch': 0.09}
  9%|â–‰         | 525/6000 [16:57<2:51:53,  1.88s/it]  9%|â–‰         | 526/6000 [16:59<2:50:56,  1.87s/it]                                                    {'loss': 0.0211, 'grad_norm': 2.3717806339263916, 'learning_rate': 9.277966101694917e-06, 'epoch': 0.09}
  9%|â–‰         | 526/6000 [16:59<2:50:56,  1.87s/it]  9%|â–‰         | 527/6000 [17:01<2:50:55,  1.87s/it]                                                    {'loss': 0.0923, 'grad_norm': 15.64695930480957, 'learning_rate': 9.276271186440678e-06, 'epoch': 0.09}
  9%|â–‰         | 527/6000 [17:01<2:50:55,  1.87s/it]  9%|â–‰         | 528/6000 [17:03<2:52:17,  1.89s/it]                                                    {'loss': 0.1266, 'grad_norm': 10.293288230895996, 'learning_rate': 9.274576271186441e-06, 'epoch': 0.09}
  9%|â–‰         | 528/6000 [17:03<2:52:17,  1.89s/it]  9%|â–‰         | 529/6000 [17:05<2:51:28,  1.88s/it]                                                    {'loss': 0.0121, 'grad_norm': 3.404634475708008, 'learning_rate': 9.272881355932205e-06, 'epoch': 0.09}
  9%|â–‰         | 529/6000 [17:05<2:51:28,  1.88s/it]  9%|â–‰         | 530/6000 [17:07<2:52:05,  1.89s/it]                                                    {'loss': 0.0206, 'grad_norm': 3.4968981742858887, 'learning_rate': 9.271186440677968e-06, 'epoch': 0.09}
  9%|â–‰         | 530/6000 [17:07<2:52:05,  1.89s/it]  9%|â–‰         | 531/6000 [17:09<2:50:46,  1.87s/it]                                                    {'loss': 0.0595, 'grad_norm': 11.941437721252441, 'learning_rate': 9.26949152542373e-06, 'epoch': 0.09}
  9%|â–‰         | 531/6000 [17:09<2:50:46,  1.87s/it]  9%|â–‰         | 532/6000 [17:11<2:51:03,  1.88s/it]                                                    {'loss': 0.1169, 'grad_norm': 10.055644989013672, 'learning_rate': 9.267796610169493e-06, 'epoch': 0.09}
  9%|â–‰         | 532/6000 [17:11<2:51:03,  1.88s/it]  9%|â–‰         | 533/6000 [17:12<2:49:15,  1.86s/it]                                                    {'loss': 0.129, 'grad_norm': 14.433694839477539, 'learning_rate': 9.266101694915254e-06, 'epoch': 0.09}
  9%|â–‰         | 533/6000 [17:12<2:49:15,  1.86s/it]  9%|â–‰         | 534/6000 [17:14<2:49:28,  1.86s/it]                                                    {'loss': 0.0217, 'grad_norm': 3.6371641159057617, 'learning_rate': 9.264406779661018e-06, 'epoch': 0.09}
  9%|â–‰         | 534/6000 [17:14<2:49:28,  1.86s/it]  9%|â–‰         | 535/6000 [17:16<2:50:29,  1.87s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.3477323353290558, 'learning_rate': 9.262711864406781e-06, 'epoch': 0.09}
  9%|â–‰         | 535/6000 [17:16<2:50:29,  1.87s/it]  9%|â–‰         | 536/6000 [17:18<2:51:27,  1.88s/it]                                                    {'loss': 0.2344, 'grad_norm': 13.912741661071777, 'learning_rate': 9.261016949152544e-06, 'epoch': 0.09}
  9%|â–‰         | 536/6000 [17:18<2:51:27,  1.88s/it]  9%|â–‰         | 537/6000 [17:20<2:51:55,  1.89s/it]                                                    {'loss': 0.0345, 'grad_norm': 4.555958271026611, 'learning_rate': 9.259322033898306e-06, 'epoch': 0.09}
  9%|â–‰         | 537/6000 [17:20<2:51:55,  1.89s/it]  9%|â–‰         | 538/6000 [17:22<2:50:41,  1.88s/it]                                                    {'loss': 0.0119, 'grad_norm': 2.112903356552124, 'learning_rate': 9.257627118644067e-06, 'epoch': 0.09}
  9%|â–‰         | 538/6000 [17:22<2:50:41,  1.88s/it]  9%|â–‰         | 539/6000 [17:24<2:49:32,  1.86s/it]                                                    {'loss': 0.0049, 'grad_norm': 1.158860206604004, 'learning_rate': 9.25593220338983e-06, 'epoch': 0.09}
  9%|â–‰         | 539/6000 [17:24<2:49:32,  1.86s/it]  9%|â–‰         | 540/6000 [17:25<2:49:01,  1.86s/it]                                                    {'loss': 0.1121, 'grad_norm': 12.956205368041992, 'learning_rate': 9.254237288135594e-06, 'epoch': 0.09}
  9%|â–‰         | 540/6000 [17:25<2:49:01,  1.86s/it]  9%|â–‰         | 541/6000 [17:27<2:49:41,  1.87s/it]                                                    {'loss': 0.0946, 'grad_norm': 15.579065322875977, 'learning_rate': 9.252542372881357e-06, 'epoch': 0.09}
  9%|â–‰         | 541/6000 [17:27<2:49:41,  1.87s/it]  9%|â–‰         | 542/6000 [17:29<2:49:56,  1.87s/it]                                                    {'loss': 0.022, 'grad_norm': 2.5468597412109375, 'learning_rate': 9.250847457627119e-06, 'epoch': 0.09}
  9%|â–‰         | 542/6000 [17:29<2:49:56,  1.87s/it]  9%|â–‰         | 543/6000 [17:31<2:50:22,  1.87s/it]                                                    {'loss': 0.0714, 'grad_norm': 6.4402384757995605, 'learning_rate': 9.249152542372882e-06, 'epoch': 0.09}
  9%|â–‰         | 543/6000 [17:31<2:50:22,  1.87s/it]  9%|â–‰         | 544/6000 [17:33<2:50:38,  1.88s/it]                                                    {'loss': 0.1038, 'grad_norm': 11.122308731079102, 'learning_rate': 9.247457627118645e-06, 'epoch': 0.09}
  9%|â–‰         | 544/6000 [17:33<2:50:38,  1.88s/it]  9%|â–‰         | 545/6000 [17:35<2:49:49,  1.87s/it]                                                    {'loss': 0.2778, 'grad_norm': 16.903417587280273, 'learning_rate': 9.245762711864409e-06, 'epoch': 0.09}
  9%|â–‰         | 545/6000 [17:35<2:49:49,  1.87s/it]  9%|â–‰         | 546/6000 [17:37<2:51:26,  1.89s/it]                                                    {'loss': 0.0234, 'grad_norm': 2.293060302734375, 'learning_rate': 9.24406779661017e-06, 'epoch': 0.09}
  9%|â–‰         | 546/6000 [17:37<2:51:26,  1.89s/it]  9%|â–‰         | 547/6000 [17:39<2:51:58,  1.89s/it]                                                    {'loss': 0.0383, 'grad_norm': 7.04558801651001, 'learning_rate': 9.242372881355933e-06, 'epoch': 0.09}
  9%|â–‰         | 547/6000 [17:39<2:51:58,  1.89s/it]  9%|â–‰         | 548/6000 [17:41<2:52:04,  1.89s/it]                                                    {'loss': 0.0464, 'grad_norm': 8.3607177734375, 'learning_rate': 9.240677966101695e-06, 'epoch': 0.09}
  9%|â–‰         | 548/6000 [17:41<2:52:04,  1.89s/it]  9%|â–‰         | 549/6000 [17:42<2:51:00,  1.88s/it]                                                    {'loss': 0.0682, 'grad_norm': 7.085785865783691, 'learning_rate': 9.238983050847458e-06, 'epoch': 0.09}
  9%|â–‰         | 549/6000 [17:42<2:51:00,  1.88s/it]  9%|â–‰         | 550/6000 [17:44<2:50:43,  1.88s/it]                                                    {'loss': 0.2048, 'grad_norm': 13.80323314666748, 'learning_rate': 9.237288135593222e-06, 'epoch': 0.09}
  9%|â–‰         | 550/6000 [17:44<2:50:43,  1.88s/it][2025-11-11 22:11:00,191] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-550
[2025-11-11 22:11:00,198] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:11:00,474] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-550/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  9%|â–‰         | 551/6000 [17:47<3:21:16,  2.22s/it]                                                    {'loss': 0.0444, 'grad_norm': 5.822117328643799, 'learning_rate': 9.235593220338985e-06, 'epoch': 0.09}
  9%|â–‰         | 551/6000 [17:47<3:21:16,  2.22s/it]  9%|â–‰         | 552/6000 [17:49<3:13:14,  2.13s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.35773327946662903, 'learning_rate': 9.233898305084746e-06, 'epoch': 0.09}
  9%|â–‰         | 552/6000 [17:49<3:13:14,  2.13s/it]  9%|â–‰         | 553/6000 [17:51<3:07:10,  2.06s/it]                                                    {'loss': 0.1296, 'grad_norm': 14.461138725280762, 'learning_rate': 9.23220338983051e-06, 'epoch': 0.09}
  9%|â–‰         | 553/6000 [17:51<3:07:10,  2.06s/it]  9%|â–‰         | 554/6000 [17:53<3:02:09,  2.01s/it]                                                    {'loss': 0.3869, 'grad_norm': 15.518166542053223, 'learning_rate': 9.230508474576271e-06, 'epoch': 0.09}
  9%|â–‰         | 554/6000 [17:53<3:02:09,  2.01s/it]  9%|â–‰         | 555/6000 [17:55<2:57:25,  1.96s/it]                                                    {'loss': 0.0754, 'grad_norm': 8.513615608215332, 'learning_rate': 9.228813559322035e-06, 'epoch': 0.09}
  9%|â–‰         | 555/6000 [17:55<2:57:25,  1.96s/it]  9%|â–‰         | 556/6000 [17:57<2:54:31,  1.92s/it]                                                    {'loss': 0.114, 'grad_norm': 11.496475219726562, 'learning_rate': 9.227118644067798e-06, 'epoch': 0.09}
  9%|â–‰         | 556/6000 [17:57<2:54:31,  1.92s/it]  9%|â–‰         | 557/6000 [17:59<2:53:27,  1.91s/it]                                                    {'loss': 0.0702, 'grad_norm': 4.141156196594238, 'learning_rate': 9.225423728813561e-06, 'epoch': 0.09}
  9%|â–‰         | 557/6000 [17:59<2:53:27,  1.91s/it]  9%|â–‰         | 558/6000 [18:00<2:52:55,  1.91s/it]                                                    {'loss': 0.1881, 'grad_norm': 16.01765251159668, 'learning_rate': 9.223728813559323e-06, 'epoch': 0.09}
  9%|â–‰         | 558/6000 [18:00<2:52:55,  1.91s/it]  9%|â–‰         | 559/6000 [18:02<2:53:43,  1.92s/it]                                                    {'loss': 0.0941, 'grad_norm': 13.790514945983887, 'learning_rate': 9.222033898305084e-06, 'epoch': 0.09}
  9%|â–‰         | 559/6000 [18:02<2:53:43,  1.92s/it]  9%|â–‰         | 560/6000 [18:04<2:52:21,  1.90s/it]                                                    {'loss': 0.2453, 'grad_norm': 15.753341674804688, 'learning_rate': 9.220338983050847e-06, 'epoch': 0.09}
  9%|â–‰         | 560/6000 [18:04<2:52:21,  1.90s/it]  9%|â–‰         | 561/6000 [18:06<3:00:45,  1.99s/it]                                                    {'loss': 0.0591, 'grad_norm': 6.818332195281982, 'learning_rate': 9.21864406779661e-06, 'epoch': 0.09}
  9%|â–‰         | 561/6000 [18:06<3:00:45,  1.99s/it]  9%|â–‰         | 562/6000 [18:08<2:56:18,  1.95s/it]                                                    {'loss': 0.1998, 'grad_norm': 10.249180793762207, 'learning_rate': 9.216949152542374e-06, 'epoch': 0.09}
  9%|â–‰         | 562/6000 [18:08<2:56:18,  1.95s/it]  9%|â–‰         | 563/6000 [18:10<2:53:49,  1.92s/it]                                                    {'loss': 0.0447, 'grad_norm': 6.139087677001953, 'learning_rate': 9.215254237288136e-06, 'epoch': 0.09}
  9%|â–‰         | 563/6000 [18:10<2:53:49,  1.92s/it]  9%|â–‰         | 564/6000 [18:12<2:52:28,  1.90s/it]                                                    {'loss': 0.0235, 'grad_norm': 3.1872565746307373, 'learning_rate': 9.213559322033899e-06, 'epoch': 0.09}
  9%|â–‰         | 564/6000 [18:12<2:52:28,  1.90s/it]  9%|â–‰         | 565/6000 [18:14<2:54:18,  1.92s/it]                                                    {'loss': 0.0186, 'grad_norm': 2.1637043952941895, 'learning_rate': 9.211864406779662e-06, 'epoch': 0.09}
  9%|â–‰         | 565/6000 [18:14<2:54:18,  1.92s/it]  9%|â–‰         | 566/6000 [18:16<2:52:48,  1.91s/it]                                                    {'loss': 0.0169, 'grad_norm': 3.2406842708587646, 'learning_rate': 9.210169491525425e-06, 'epoch': 0.09}
  9%|â–‰         | 566/6000 [18:16<2:52:48,  1.91s/it]  9%|â–‰         | 567/6000 [18:18<2:57:15,  1.96s/it]                                                    {'loss': 0.0768, 'grad_norm': 13.045697212219238, 'learning_rate': 9.208474576271187e-06, 'epoch': 0.09}
  9%|â–‰         | 567/6000 [18:18<2:57:15,  1.96s/it]  9%|â–‰         | 568/6000 [18:20<2:56:06,  1.95s/it]                                                    {'loss': 0.0673, 'grad_norm': 4.014973163604736, 'learning_rate': 9.20677966101695e-06, 'epoch': 0.09}
  9%|â–‰         | 568/6000 [18:20<2:56:06,  1.95s/it]  9%|â–‰         | 569/6000 [18:22<2:55:07,  1.93s/it]                                                    {'loss': 0.0126, 'grad_norm': 3.354997396469116, 'learning_rate': 9.205084745762712e-06, 'epoch': 0.09}
  9%|â–‰         | 569/6000 [18:22<2:55:07,  1.93s/it] 10%|â–‰         | 570/6000 [18:24<2:53:56,  1.92s/it]                                                    {'loss': 0.0786, 'grad_norm': 3.808166980743408, 'learning_rate': 9.203389830508475e-06, 'epoch': 0.1}
 10%|â–‰         | 570/6000 [18:24<2:53:56,  1.92s/it] 10%|â–‰         | 571/6000 [18:26<3:07:24,  2.07s/it]                                                    {'loss': 0.0477, 'grad_norm': 8.080853462219238, 'learning_rate': 9.201694915254238e-06, 'epoch': 0.1}
 10%|â–‰         | 571/6000 [18:26<3:07:24,  2.07s/it] 10%|â–‰         | 572/6000 [18:28<3:02:56,  2.02s/it]                                                    {'loss': 0.47, 'grad_norm': 19.209182739257812, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.1}
 10%|â–‰         | 572/6000 [18:28<3:02:56,  2.02s/it] 10%|â–‰         | 573/6000 [18:30<2:58:22,  1.97s/it]                                                    {'loss': 0.2057, 'grad_norm': 11.152022361755371, 'learning_rate': 9.198305084745763e-06, 'epoch': 0.1}
 10%|â–‰         | 573/6000 [18:30<2:58:22,  1.97s/it] 10%|â–‰         | 574/6000 [18:32<2:56:24,  1.95s/it]                                                    {'loss': 0.408, 'grad_norm': 13.462716102600098, 'learning_rate': 9.196610169491527e-06, 'epoch': 0.1}
 10%|â–‰         | 574/6000 [18:32<2:56:24,  1.95s/it] 10%|â–‰         | 575/6000 [18:34<2:54:17,  1.93s/it]                                                    {'loss': 0.0137, 'grad_norm': 2.063255786895752, 'learning_rate': 9.194915254237288e-06, 'epoch': 0.1}
 10%|â–‰         | 575/6000 [18:34<2:54:17,  1.93s/it] 10%|â–‰         | 576/6000 [18:36<2:54:39,  1.93s/it]                                                    {'loss': 0.1637, 'grad_norm': 11.743054389953613, 'learning_rate': 9.193220338983051e-06, 'epoch': 0.1}
 10%|â–‰         | 576/6000 [18:36<2:54:39,  1.93s/it] 10%|â–‰         | 577/6000 [18:38<2:55:18,  1.94s/it]                                                    {'loss': 0.0863, 'grad_norm': 6.107784271240234, 'learning_rate': 9.191525423728815e-06, 'epoch': 0.1}
 10%|â–‰         | 577/6000 [18:38<2:55:18,  1.94s/it] 10%|â–‰         | 578/6000 [18:40<2:58:22,  1.97s/it]                                                    {'loss': 0.2097, 'grad_norm': 13.446390151977539, 'learning_rate': 9.189830508474576e-06, 'epoch': 0.1}
 10%|â–‰         | 578/6000 [18:40<2:58:22,  1.97s/it] 10%|â–‰         | 579/6000 [18:42<3:00:05,  1.99s/it]                                                    {'loss': 0.0208, 'grad_norm': 2.535189628601074, 'learning_rate': 9.18813559322034e-06, 'epoch': 0.1}
 10%|â–‰         | 579/6000 [18:42<3:00:05,  1.99s/it] 10%|â–‰         | 580/6000 [18:43<2:57:18,  1.96s/it]                                                    {'loss': 0.1549, 'grad_norm': 8.874007225036621, 'learning_rate': 9.186440677966101e-06, 'epoch': 0.1}
 10%|â–‰         | 580/6000 [18:44<2:57:18,  1.96s/it] 10%|â–‰         | 581/6000 [18:46<3:04:49,  2.05s/it]                                                    {'loss': 0.2936, 'grad_norm': 12.091005325317383, 'learning_rate': 9.184745762711866e-06, 'epoch': 0.1}
 10%|â–‰         | 581/6000 [18:46<3:04:49,  2.05s/it] 10%|â–‰         | 582/6000 [18:48<3:13:09,  2.14s/it]                                                    {'loss': 0.2445, 'grad_norm': 17.774715423583984, 'learning_rate': 9.183050847457628e-06, 'epoch': 0.1}
 10%|â–‰         | 582/6000 [18:48<3:13:09,  2.14s/it] 10%|â–‰         | 583/6000 [18:50<3:07:28,  2.08s/it]                                                    {'loss': 0.0453, 'grad_norm': 5.251152038574219, 'learning_rate': 9.181355932203391e-06, 'epoch': 0.1}
 10%|â–‰         | 583/6000 [18:50<3:07:28,  2.08s/it] 10%|â–‰         | 584/6000 [18:52<3:03:07,  2.03s/it]                                                    {'loss': 0.5832, 'grad_norm': 13.092486381530762, 'learning_rate': 9.179661016949153e-06, 'epoch': 0.1}
 10%|â–‰         | 584/6000 [18:52<3:03:07,  2.03s/it] 10%|â–‰         | 585/6000 [18:54<3:04:15,  2.04s/it]                                                    {'loss': 0.0064, 'grad_norm': 0.7221869230270386, 'learning_rate': 9.177966101694916e-06, 'epoch': 0.1}
 10%|â–‰         | 585/6000 [18:54<3:04:15,  2.04s/it] 10%|â–‰         | 586/6000 [18:56<2:59:59,  1.99s/it]                                                    {'loss': 0.0909, 'grad_norm': 9.244020462036133, 'learning_rate': 9.176271186440679e-06, 'epoch': 0.1}
 10%|â–‰         | 586/6000 [18:56<2:59:59,  1.99s/it] 10%|â–‰         | 587/6000 [18:58<2:56:14,  1.95s/it]                                                    {'loss': 0.0432, 'grad_norm': 2.9044058322906494, 'learning_rate': 9.174576271186442e-06, 'epoch': 0.1}
 10%|â–‰         | 587/6000 [18:58<2:56:14,  1.95s/it] 10%|â–‰         | 588/6000 [19:00<2:54:14,  1.93s/it]                                                    {'loss': 0.0238, 'grad_norm': 4.3440656661987305, 'learning_rate': 9.172881355932204e-06, 'epoch': 0.1}
 10%|â–‰         | 588/6000 [19:00<2:54:14,  1.93s/it] 10%|â–‰         | 589/6000 [19:02<2:57:58,  1.97s/it]                                                    {'loss': 0.0091, 'grad_norm': 0.9977855086326599, 'learning_rate': 9.171186440677967e-06, 'epoch': 0.1}
 10%|â–‰         | 589/6000 [19:02<2:57:58,  1.97s/it] 10%|â–‰         | 590/6000 [19:04<2:56:09,  1.95s/it]                                                    {'loss': 0.0886, 'grad_norm': 8.403742790222168, 'learning_rate': 9.169491525423729e-06, 'epoch': 0.1}
 10%|â–‰         | 590/6000 [19:04<2:56:09,  1.95s/it] 10%|â–‰         | 591/6000 [19:05<2:53:45,  1.93s/it]                                                    {'loss': 0.1184, 'grad_norm': 8.349766731262207, 'learning_rate': 9.167796610169492e-06, 'epoch': 0.1}
 10%|â–‰         | 591/6000 [19:05<2:53:45,  1.93s/it] 10%|â–‰         | 592/6000 [19:07<2:52:10,  1.91s/it]                                                    {'loss': 0.1266, 'grad_norm': 10.558732032775879, 'learning_rate': 9.166101694915255e-06, 'epoch': 0.1}
 10%|â–‰         | 592/6000 [19:07<2:52:10,  1.91s/it] 10%|â–‰         | 593/6000 [19:09<2:52:18,  1.91s/it]                                                    {'loss': 0.0432, 'grad_norm': 3.3644778728485107, 'learning_rate': 9.164406779661019e-06, 'epoch': 0.1}
 10%|â–‰         | 593/6000 [19:09<2:52:18,  1.91s/it] 10%|â–‰         | 594/6000 [19:11<2:51:56,  1.91s/it]                                                    {'loss': 0.0907, 'grad_norm': 9.083406448364258, 'learning_rate': 9.16271186440678e-06, 'epoch': 0.1}
 10%|â–‰         | 594/6000 [19:11<2:51:56,  1.91s/it] 10%|â–‰         | 595/6000 [19:13<2:53:16,  1.92s/it]                                                    {'loss': 0.1208, 'grad_norm': 11.558517456054688, 'learning_rate': 9.161016949152543e-06, 'epoch': 0.1}
 10%|â–‰         | 595/6000 [19:13<2:53:16,  1.92s/it] 10%|â–‰         | 596/6000 [19:15<3:02:58,  2.03s/it]                                                    {'loss': 0.0922, 'grad_norm': 3.9479446411132812, 'learning_rate': 9.159322033898305e-06, 'epoch': 0.1}
 10%|â–‰         | 596/6000 [19:15<3:02:58,  2.03s/it] 10%|â–‰         | 597/6000 [19:17<2:58:10,  1.98s/it]                                                    {'loss': 0.0589, 'grad_norm': 6.0381340980529785, 'learning_rate': 9.157627118644068e-06, 'epoch': 0.1}
 10%|â–‰         | 597/6000 [19:17<2:58:10,  1.98s/it] 10%|â–‰         | 598/6000 [19:19<2:55:46,  1.95s/it]                                                    {'loss': 0.0759, 'grad_norm': 8.503299713134766, 'learning_rate': 9.155932203389832e-06, 'epoch': 0.1}
 10%|â–‰         | 598/6000 [19:19<2:55:46,  1.95s/it] 10%|â–‰         | 599/6000 [19:21<2:52:30,  1.92s/it]                                                    {'loss': 0.0592, 'grad_norm': 4.463313579559326, 'learning_rate': 9.154237288135593e-06, 'epoch': 0.1}
 10%|â–‰         | 599/6000 [19:21<2:52:30,  1.92s/it] 10%|â–ˆ         | 600/6000 [19:23<2:51:05,  1.90s/it]                                                    {'loss': 0.1338, 'grad_norm': 10.464824676513672, 'learning_rate': 9.152542372881356e-06, 'epoch': 0.1}
 10%|â–ˆ         | 600/6000 [19:23<2:51:05,  1.90s/it][2025-11-11 22:12:38,769] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600
[2025-11-11 22:12:38,776] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:12:39,078] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 10%|â–ˆ         | 601/6000 [19:26<3:11:30,  2.13s/it]                                                    {'loss': 0.2178, 'grad_norm': 11.318414688110352, 'learning_rate': 9.15084745762712e-06, 'epoch': 0.1}
 10%|â–ˆ         | 601/6000 [19:26<3:11:30,  2.13s/it] 10%|â–ˆ         | 602/6000 [19:27<3:05:26,  2.06s/it]                                                    {'loss': 0.0855, 'grad_norm': 8.40632438659668, 'learning_rate': 9.149152542372883e-06, 'epoch': 0.1}
 10%|â–ˆ         | 602/6000 [19:27<3:05:26,  2.06s/it] 10%|â–ˆ         | 603/6000 [19:29<3:01:04,  2.01s/it]                                                    {'loss': 0.18, 'grad_norm': 11.757610321044922, 'learning_rate': 9.147457627118645e-06, 'epoch': 0.1}
 10%|â–ˆ         | 603/6000 [19:29<3:01:04,  2.01s/it] 10%|â–ˆ         | 604/6000 [19:31<3:02:06,  2.02s/it]                                                    {'loss': 0.1485, 'grad_norm': 11.78051471710205, 'learning_rate': 9.145762711864408e-06, 'epoch': 0.1}
 10%|â–ˆ         | 604/6000 [19:31<3:02:06,  2.02s/it] 10%|â–ˆ         | 605/6000 [19:33<2:58:20,  1.98s/it]                                                    {'loss': 0.1532, 'grad_norm': 11.15582275390625, 'learning_rate': 9.14406779661017e-06, 'epoch': 0.1}
 10%|â–ˆ         | 605/6000 [19:33<2:58:20,  1.98s/it] 10%|â–ˆ         | 606/6000 [19:35<2:57:50,  1.98s/it]                                                    {'loss': 0.0289, 'grad_norm': 3.6484594345092773, 'learning_rate': 9.142372881355933e-06, 'epoch': 0.1}
 10%|â–ˆ         | 606/6000 [19:35<2:57:50,  1.98s/it] 10%|â–ˆ         | 607/6000 [19:37<2:54:05,  1.94s/it]                                                    {'loss': 0.0694, 'grad_norm': 9.634749412536621, 'learning_rate': 9.140677966101696e-06, 'epoch': 0.1}
 10%|â–ˆ         | 607/6000 [19:37<2:54:05,  1.94s/it] 10%|â–ˆ         | 608/6000 [19:39<2:53:37,  1.93s/it]                                                    {'loss': 0.1665, 'grad_norm': 8.873924255371094, 'learning_rate': 9.13898305084746e-06, 'epoch': 0.1}
 10%|â–ˆ         | 608/6000 [19:39<2:53:37,  1.93s/it] 10%|â–ˆ         | 609/6000 [19:41<2:51:31,  1.91s/it]                                                    {'loss': 0.1579, 'grad_norm': 9.032426834106445, 'learning_rate': 9.13728813559322e-06, 'epoch': 0.1}
 10%|â–ˆ         | 609/6000 [19:41<2:51:31,  1.91s/it] 10%|â–ˆ         | 610/6000 [19:43<2:51:00,  1.90s/it]                                                    {'loss': 0.0562, 'grad_norm': 8.569855690002441, 'learning_rate': 9.135593220338984e-06, 'epoch': 0.1}
 10%|â–ˆ         | 610/6000 [19:43<2:51:00,  1.90s/it] 10%|â–ˆ         | 611/6000 [19:45<2:50:07,  1.89s/it]                                                    {'loss': 0.2561, 'grad_norm': 11.314508438110352, 'learning_rate': 9.133898305084746e-06, 'epoch': 0.1}
 10%|â–ˆ         | 611/6000 [19:45<2:50:07,  1.89s/it] 10%|â–ˆ         | 612/6000 [19:47<2:50:37,  1.90s/it]                                                    {'loss': 0.0452, 'grad_norm': 3.2120959758758545, 'learning_rate': 9.132203389830509e-06, 'epoch': 0.1}
 10%|â–ˆ         | 612/6000 [19:47<2:50:37,  1.90s/it] 10%|â–ˆ         | 613/6000 [19:48<2:51:25,  1.91s/it]                                                    {'loss': 0.1549, 'grad_norm': 9.345671653747559, 'learning_rate': 9.130508474576272e-06, 'epoch': 0.1}
 10%|â–ˆ         | 613/6000 [19:48<2:51:25,  1.91s/it] 10%|â–ˆ         | 614/6000 [19:50<2:49:58,  1.89s/it]                                                    {'loss': 0.0163, 'grad_norm': 1.3961737155914307, 'learning_rate': 9.128813559322035e-06, 'epoch': 0.1}
 10%|â–ˆ         | 614/6000 [19:50<2:49:58,  1.89s/it] 10%|â–ˆ         | 615/6000 [19:52<2:49:49,  1.89s/it]                                                    {'loss': 0.0816, 'grad_norm': 7.335258960723877, 'learning_rate': 9.127118644067797e-06, 'epoch': 0.1}
 10%|â–ˆ         | 615/6000 [19:52<2:49:49,  1.89s/it] 10%|â–ˆ         | 616/6000 [19:54<2:48:41,  1.88s/it]                                                    {'loss': 0.1173, 'grad_norm': 8.060426712036133, 'learning_rate': 9.12542372881356e-06, 'epoch': 0.1}
 10%|â–ˆ         | 616/6000 [19:54<2:48:41,  1.88s/it] 10%|â–ˆ         | 617/6000 [19:56<2:48:54,  1.88s/it]                                                    {'loss': 0.0097, 'grad_norm': 2.058450698852539, 'learning_rate': 9.123728813559322e-06, 'epoch': 0.1}
 10%|â–ˆ         | 617/6000 [19:56<2:48:54,  1.88s/it] 10%|â–ˆ         | 618/6000 [19:58<2:48:49,  1.88s/it]                                                    {'loss': 0.0694, 'grad_norm': 6.499181270599365, 'learning_rate': 9.122033898305085e-06, 'epoch': 0.1}
 10%|â–ˆ         | 618/6000 [19:58<2:48:49,  1.88s/it] 10%|â–ˆ         | 619/6000 [20:00<2:48:53,  1.88s/it]                                                    {'loss': 0.1862, 'grad_norm': 11.530773162841797, 'learning_rate': 9.120338983050848e-06, 'epoch': 0.1}
 10%|â–ˆ         | 619/6000 [20:00<2:48:53,  1.88s/it] 10%|â–ˆ         | 620/6000 [20:02<2:49:18,  1.89s/it]                                                    {'loss': 0.0225, 'grad_norm': 2.1676783561706543, 'learning_rate': 9.11864406779661e-06, 'epoch': 0.1}
 10%|â–ˆ         | 620/6000 [20:02<2:49:18,  1.89s/it] 10%|â–ˆ         | 621/6000 [20:03<2:48:19,  1.88s/it]                                                    {'loss': 0.111, 'grad_norm': 8.169676780700684, 'learning_rate': 9.116949152542373e-06, 'epoch': 0.1}
 10%|â–ˆ         | 621/6000 [20:03<2:48:19,  1.88s/it] 10%|â–ˆ         | 622/6000 [20:05<2:47:07,  1.86s/it]                                                    {'loss': 0.239, 'grad_norm': 9.936331748962402, 'learning_rate': 9.115254237288137e-06, 'epoch': 0.1}
 10%|â–ˆ         | 622/6000 [20:05<2:47:07,  1.86s/it] 10%|â–ˆ         | 623/6000 [20:07<2:47:38,  1.87s/it]                                                    {'loss': 0.2231, 'grad_norm': 11.610504150390625, 'learning_rate': 9.1135593220339e-06, 'epoch': 0.1}
 10%|â–ˆ         | 623/6000 [20:07<2:47:38,  1.87s/it] 10%|â–ˆ         | 624/6000 [20:09<2:47:42,  1.87s/it]                                                    {'loss': 0.258, 'grad_norm': 13.195420265197754, 'learning_rate': 9.111864406779661e-06, 'epoch': 0.1}
 10%|â–ˆ         | 624/6000 [20:09<2:47:42,  1.87s/it] 10%|â–ˆ         | 625/6000 [20:11<2:50:50,  1.91s/it]                                                    {'loss': 0.0174, 'grad_norm': 1.726722002029419, 'learning_rate': 9.110169491525425e-06, 'epoch': 0.1}
 10%|â–ˆ         | 625/6000 [20:11<2:50:50,  1.91s/it] 10%|â–ˆ         | 626/6000 [20:13<2:49:10,  1.89s/it]                                                    {'loss': 0.09, 'grad_norm': 6.678661346435547, 'learning_rate': 9.108474576271186e-06, 'epoch': 0.1}
 10%|â–ˆ         | 626/6000 [20:13<2:49:10,  1.89s/it] 10%|â–ˆ         | 627/6000 [20:15<2:57:26,  1.98s/it]                                                    {'loss': 0.0284, 'grad_norm': 3.2611327171325684, 'learning_rate': 9.10677966101695e-06, 'epoch': 0.1}
 10%|â–ˆ         | 627/6000 [20:15<2:57:26,  1.98s/it] 10%|â–ˆ         | 628/6000 [20:17<2:54:57,  1.95s/it]                                                    {'loss': 0.2282, 'grad_norm': 18.00103759765625, 'learning_rate': 9.105084745762713e-06, 'epoch': 0.1}
 10%|â–ˆ         | 628/6000 [20:17<2:54:57,  1.95s/it] 10%|â–ˆ         | 629/6000 [20:19<2:52:08,  1.92s/it]                                                    {'loss': 0.0269, 'grad_norm': 3.7301502227783203, 'learning_rate': 9.103389830508476e-06, 'epoch': 0.1}
 10%|â–ˆ         | 629/6000 [20:19<2:52:08,  1.92s/it] 10%|â–ˆ         | 630/6000 [20:21<2:50:37,  1.91s/it]                                                    {'loss': 0.4499, 'grad_norm': 13.518789291381836, 'learning_rate': 9.101694915254238e-06, 'epoch': 0.1}
 10%|â–ˆ         | 630/6000 [20:21<2:50:37,  1.91s/it] 11%|â–ˆ         | 631/6000 [20:23<2:49:56,  1.90s/it]                                                    {'loss': 0.222, 'grad_norm': 13.952620506286621, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.11}
 11%|â–ˆ         | 631/6000 [20:23<2:49:56,  1.90s/it] 11%|â–ˆ         | 632/6000 [20:24<2:50:31,  1.91s/it]                                                    {'loss': 0.1247, 'grad_norm': 8.810921669006348, 'learning_rate': 9.098305084745763e-06, 'epoch': 0.11}
 11%|â–ˆ         | 632/6000 [20:24<2:50:31,  1.91s/it] 11%|â–ˆ         | 633/6000 [20:26<2:51:28,  1.92s/it]                                                    {'loss': 0.1421, 'grad_norm': 9.117986679077148, 'learning_rate': 9.096610169491526e-06, 'epoch': 0.11}
 11%|â–ˆ         | 633/6000 [20:26<2:51:28,  1.92s/it] 11%|â–ˆ         | 634/6000 [20:28<2:53:26,  1.94s/it]                                                    {'loss': 0.0406, 'grad_norm': 17.909137725830078, 'learning_rate': 9.094915254237289e-06, 'epoch': 0.11}
 11%|â–ˆ         | 634/6000 [20:28<2:53:26,  1.94s/it] 11%|â–ˆ         | 635/6000 [20:30<2:54:35,  1.95s/it]                                                    {'loss': 0.1245, 'grad_norm': 10.989261627197266, 'learning_rate': 9.093220338983052e-06, 'epoch': 0.11}
 11%|â–ˆ         | 635/6000 [20:30<2:54:35,  1.95s/it] 11%|â–ˆ         | 636/6000 [20:32<2:53:01,  1.94s/it]                                                    {'loss': 0.0115, 'grad_norm': 2.3691437244415283, 'learning_rate': 9.091525423728814e-06, 'epoch': 0.11}
 11%|â–ˆ         | 636/6000 [20:32<2:53:01,  1.94s/it] 11%|â–ˆ         | 637/6000 [20:34<2:51:29,  1.92s/it]                                                    {'loss': 0.0194, 'grad_norm': 2.077059745788574, 'learning_rate': 9.089830508474577e-06, 'epoch': 0.11}
 11%|â–ˆ         | 637/6000 [20:34<2:51:29,  1.92s/it] 11%|â–ˆ         | 638/6000 [20:36<2:56:09,  1.97s/it]                                                    {'loss': 0.0705, 'grad_norm': 4.808448791503906, 'learning_rate': 9.08813559322034e-06, 'epoch': 0.11}
 11%|â–ˆ         | 638/6000 [20:36<2:56:09,  1.97s/it] 11%|â–ˆ         | 639/6000 [20:38<2:54:50,  1.96s/it]                                                    {'loss': 0.0759, 'grad_norm': 5.06146764755249, 'learning_rate': 9.086440677966104e-06, 'epoch': 0.11}
 11%|â–ˆ         | 639/6000 [20:38<2:54:50,  1.96s/it] 11%|â–ˆ         | 640/6000 [20:40<2:55:10,  1.96s/it]                                                    {'loss': 0.0211, 'grad_norm': 2.4456374645233154, 'learning_rate': 9.084745762711865e-06, 'epoch': 0.11}
 11%|â–ˆ         | 640/6000 [20:40<2:55:10,  1.96s/it] 11%|â–ˆ         | 641/6000 [20:42<2:56:59,  1.98s/it]                                                    {'loss': 0.0199, 'grad_norm': 2.809218645095825, 'learning_rate': 9.083050847457627e-06, 'epoch': 0.11}
 11%|â–ˆ         | 641/6000 [20:42<2:56:59,  1.98s/it] 11%|â–ˆ         | 642/6000 [20:44<2:58:09,  2.00s/it]                                                    {'loss': 0.0964, 'grad_norm': 11.721925735473633, 'learning_rate': 9.08135593220339e-06, 'epoch': 0.11}
 11%|â–ˆ         | 642/6000 [20:44<2:58:09,  2.00s/it] 11%|â–ˆ         | 643/6000 [20:46<2:56:04,  1.97s/it]                                                    {'loss': 0.0487, 'grad_norm': 5.2275614738464355, 'learning_rate': 9.079661016949153e-06, 'epoch': 0.11}
 11%|â–ˆ         | 643/6000 [20:46<2:56:04,  1.97s/it] 11%|â–ˆ         | 644/6000 [20:48<2:54:49,  1.96s/it]                                                    {'loss': 0.013, 'grad_norm': 1.6490572690963745, 'learning_rate': 9.077966101694917e-06, 'epoch': 0.11}
 11%|â–ˆ         | 644/6000 [20:48<2:54:49,  1.96s/it] 11%|â–ˆ         | 645/6000 [20:50<2:51:36,  1.92s/it]                                                    {'loss': 0.1945, 'grad_norm': 12.837913513183594, 'learning_rate': 9.076271186440678e-06, 'epoch': 0.11}
 11%|â–ˆ         | 645/6000 [20:50<2:51:36,  1.92s/it] 11%|â–ˆ         | 646/6000 [20:52<2:53:03,  1.94s/it]                                                    {'loss': 0.1114, 'grad_norm': 10.490872383117676, 'learning_rate': 9.074576271186442e-06, 'epoch': 0.11}
 11%|â–ˆ         | 646/6000 [20:52<2:53:03,  1.94s/it] 11%|â–ˆ         | 647/6000 [20:54<2:51:32,  1.92s/it]                                                    {'loss': 0.1251, 'grad_norm': 5.864545822143555, 'learning_rate': 9.072881355932203e-06, 'epoch': 0.11}
 11%|â–ˆ         | 647/6000 [20:54<2:51:32,  1.92s/it] 11%|â–ˆ         | 648/6000 [20:56<2:55:00,  1.96s/it]                                                    {'loss': 0.1897, 'grad_norm': 12.5955810546875, 'learning_rate': 9.071186440677966e-06, 'epoch': 0.11}
 11%|â–ˆ         | 648/6000 [20:56<2:55:00,  1.96s/it] 11%|â–ˆ         | 649/6000 [20:58<2:52:40,  1.94s/it]                                                    {'loss': 0.1381, 'grad_norm': 11.166022300720215, 'learning_rate': 9.06949152542373e-06, 'epoch': 0.11}
 11%|â–ˆ         | 649/6000 [20:58<2:52:40,  1.94s/it] 11%|â–ˆ         | 650/6000 [21:00<2:50:45,  1.92s/it]                                                    {'loss': 0.1325, 'grad_norm': 10.527779579162598, 'learning_rate': 9.067796610169493e-06, 'epoch': 0.11}
 11%|â–ˆ         | 650/6000 [21:00<2:50:45,  1.92s/it][2025-11-11 22:14:15,487] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-650
[2025-11-11 22:14:15,494] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:14:15,768] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-650/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 11%|â–ˆ         | 651/6000 [21:02<3:15:24,  2.19s/it]                                                    {'loss': 0.2268, 'grad_norm': 8.67938232421875, 'learning_rate': 9.066101694915255e-06, 'epoch': 0.11}
 11%|â–ˆ         | 651/6000 [21:02<3:15:24,  2.19s/it] 11%|â–ˆ         | 652/6000 [21:04<3:10:39,  2.14s/it]                                                    {'loss': 0.0127, 'grad_norm': 1.3421838283538818, 'learning_rate': 9.064406779661018e-06, 'epoch': 0.11}
 11%|â–ˆ         | 652/6000 [21:04<3:10:39,  2.14s/it] 11%|â–ˆ         | 653/6000 [21:06<3:04:56,  2.08s/it]                                                    {'loss': 0.1176, 'grad_norm': 5.198462009429932, 'learning_rate': 9.06271186440678e-06, 'epoch': 0.11}
 11%|â–ˆ         | 653/6000 [21:06<3:04:56,  2.08s/it] 11%|â–ˆ         | 654/6000 [21:08<2:59:22,  2.01s/it]                                                    {'loss': 0.0373, 'grad_norm': 5.668822765350342, 'learning_rate': 9.061016949152543e-06, 'epoch': 0.11}
 11%|â–ˆ         | 654/6000 [21:08<2:59:22,  2.01s/it] 11%|â–ˆ         | 655/6000 [21:10<2:55:50,  1.97s/it]                                                    {'loss': 0.0841, 'grad_norm': 7.532530307769775, 'learning_rate': 9.059322033898306e-06, 'epoch': 0.11}
 11%|â–ˆ         | 655/6000 [21:10<2:55:50,  1.97s/it] 11%|â–ˆ         | 656/6000 [21:12<2:53:47,  1.95s/it]                                                    {'loss': 0.1845, 'grad_norm': 9.92575454711914, 'learning_rate': 9.05762711864407e-06, 'epoch': 0.11}
 11%|â–ˆ         | 656/6000 [21:12<2:53:47,  1.95s/it] 11%|â–ˆ         | 657/6000 [21:14<2:53:42,  1.95s/it]                                                    {'loss': 0.1616, 'grad_norm': 11.469752311706543, 'learning_rate': 9.05593220338983e-06, 'epoch': 0.11}
 11%|â–ˆ         | 657/6000 [21:14<2:53:42,  1.95s/it] 11%|â–ˆ         | 658/6000 [21:16<2:55:49,  1.97s/it]                                                    {'loss': 0.0388, 'grad_norm': 5.778670310974121, 'learning_rate': 9.054237288135594e-06, 'epoch': 0.11}
 11%|â–ˆ         | 658/6000 [21:16<2:55:49,  1.97s/it] 11%|â–ˆ         | 659/6000 [21:18<2:52:04,  1.93s/it]                                                    {'loss': 0.0105, 'grad_norm': 1.799578070640564, 'learning_rate': 9.052542372881357e-06, 'epoch': 0.11}
 11%|â–ˆ         | 659/6000 [21:18<2:52:04,  1.93s/it] 11%|â–ˆ         | 660/6000 [21:20<2:50:52,  1.92s/it]                                                    {'loss': 0.0259, 'grad_norm': 4.54740571975708, 'learning_rate': 9.05084745762712e-06, 'epoch': 0.11}
 11%|â–ˆ         | 660/6000 [21:20<2:50:52,  1.92s/it] 11%|â–ˆ         | 661/6000 [21:22<2:52:44,  1.94s/it]                                                    {'loss': 0.0425, 'grad_norm': 6.621892929077148, 'learning_rate': 9.049152542372882e-06, 'epoch': 0.11}
 11%|â–ˆ         | 661/6000 [21:22<2:52:44,  1.94s/it] 11%|â–ˆ         | 662/6000 [21:24<2:51:02,  1.92s/it]                                                    {'loss': 0.0845, 'grad_norm': 7.04101037979126, 'learning_rate': 9.047457627118644e-06, 'epoch': 0.11}
 11%|â–ˆ         | 662/6000 [21:24<2:51:02,  1.92s/it] 11%|â–ˆ         | 663/6000 [21:25<2:49:43,  1.91s/it]                                                    {'loss': 0.1303, 'grad_norm': 9.22833251953125, 'learning_rate': 9.045762711864407e-06, 'epoch': 0.11}
 11%|â–ˆ         | 663/6000 [21:25<2:49:43,  1.91s/it] 11%|â–ˆ         | 664/6000 [21:27<2:51:18,  1.93s/it]                                                    {'loss': 0.0199, 'grad_norm': 3.3779489994049072, 'learning_rate': 9.04406779661017e-06, 'epoch': 0.11}
 11%|â–ˆ         | 664/6000 [21:27<2:51:18,  1.93s/it] 11%|â–ˆ         | 665/6000 [21:29<2:50:11,  1.91s/it]                                                    {'loss': 0.0949, 'grad_norm': 5.772327899932861, 'learning_rate': 9.042372881355934e-06, 'epoch': 0.11}
 11%|â–ˆ         | 665/6000 [21:29<2:50:11,  1.91s/it] 11%|â–ˆ         | 666/6000 [21:31<2:49:53,  1.91s/it]                                                    {'loss': 0.0629, 'grad_norm': 4.611466407775879, 'learning_rate': 9.040677966101695e-06, 'epoch': 0.11}
 11%|â–ˆ         | 666/6000 [21:31<2:49:53,  1.91s/it] 11%|â–ˆ         | 667/6000 [21:33<2:50:08,  1.91s/it]                                                    {'loss': 0.1027, 'grad_norm': 7.379674434661865, 'learning_rate': 9.038983050847458e-06, 'epoch': 0.11}
 11%|â–ˆ         | 667/6000 [21:33<2:50:08,  1.91s/it] 11%|â–ˆ         | 668/6000 [21:35<2:49:29,  1.91s/it]                                                    {'loss': 0.0793, 'grad_norm': 8.506434440612793, 'learning_rate': 9.03728813559322e-06, 'epoch': 0.11}
 11%|â–ˆ         | 668/6000 [21:35<2:49:29,  1.91s/it] 11%|â–ˆ         | 669/6000 [21:37<2:48:47,  1.90s/it]                                                    {'loss': 0.0111, 'grad_norm': 1.2865872383117676, 'learning_rate': 9.035593220338983e-06, 'epoch': 0.11}
 11%|â–ˆ         | 669/6000 [21:37<2:48:47,  1.90s/it] 11%|â–ˆ         | 670/6000 [21:39<2:50:45,  1.92s/it]                                                    {'loss': 0.0824, 'grad_norm': 6.433751583099365, 'learning_rate': 9.033898305084747e-06, 'epoch': 0.11}
 11%|â–ˆ         | 670/6000 [21:39<2:50:45,  1.92s/it] 11%|â–ˆ         | 671/6000 [21:41<2:49:25,  1.91s/it]                                                    {'loss': 0.0681, 'grad_norm': 5.107852458953857, 'learning_rate': 9.03220338983051e-06, 'epoch': 0.11}
 11%|â–ˆ         | 671/6000 [21:41<2:49:25,  1.91s/it] 11%|â–ˆ         | 672/6000 [21:43<2:47:21,  1.88s/it]                                                    {'loss': 0.1547, 'grad_norm': 10.053833961486816, 'learning_rate': 9.030508474576271e-06, 'epoch': 0.11}
 11%|â–ˆ         | 672/6000 [21:43<2:47:21,  1.88s/it] 11%|â–ˆ         | 673/6000 [21:44<2:46:57,  1.88s/it]                                                    {'loss': 0.0762, 'grad_norm': 7.487069606781006, 'learning_rate': 9.028813559322035e-06, 'epoch': 0.11}
 11%|â–ˆ         | 673/6000 [21:44<2:46:57,  1.88s/it] 11%|â–ˆ         | 674/6000 [21:46<2:47:10,  1.88s/it]                                                    {'loss': 0.0917, 'grad_norm': 5.611661911010742, 'learning_rate': 9.027118644067796e-06, 'epoch': 0.11}
 11%|â–ˆ         | 674/6000 [21:46<2:47:10,  1.88s/it] 11%|â–ˆâ–        | 675/6000 [21:48<2:46:00,  1.87s/it]                                                    {'loss': 0.165, 'grad_norm': 12.810842514038086, 'learning_rate': 9.02542372881356e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 675/6000 [21:48<2:46:00,  1.87s/it] 11%|â–ˆâ–        | 676/6000 [21:50<2:45:54,  1.87s/it]                                                    {'loss': 0.0827, 'grad_norm': 4.389065265655518, 'learning_rate': 9.023728813559323e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 676/6000 [21:50<2:45:54,  1.87s/it] 11%|â–ˆâ–        | 677/6000 [21:52<2:45:30,  1.87s/it]                                                    {'loss': 0.1178, 'grad_norm': 9.8567533493042, 'learning_rate': 9.022033898305086e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 677/6000 [21:52<2:45:30,  1.87s/it] 11%|â–ˆâ–        | 678/6000 [21:54<2:46:50,  1.88s/it]                                                    {'loss': 0.0398, 'grad_norm': 3.8133490085601807, 'learning_rate': 9.020338983050848e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 678/6000 [21:54<2:46:50,  1.88s/it] 11%|â–ˆâ–        | 679/6000 [21:56<2:45:35,  1.87s/it]                                                    {'loss': 0.0591, 'grad_norm': 6.5978102684021, 'learning_rate': 9.018644067796611e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 679/6000 [21:56<2:45:35,  1.87s/it] 11%|â–ˆâ–        | 680/6000 [21:58<2:47:03,  1.88s/it]                                                    {'loss': 0.0851, 'grad_norm': 8.3484468460083, 'learning_rate': 9.016949152542374e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 680/6000 [21:58<2:47:03,  1.88s/it] 11%|â–ˆâ–        | 681/6000 [22:00<2:51:29,  1.93s/it]                                                    {'loss': 0.0197, 'grad_norm': 2.275376081466675, 'learning_rate': 9.015254237288138e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 681/6000 [22:00<2:51:29,  1.93s/it] 11%|â–ˆâ–        | 682/6000 [22:02<2:51:00,  1.93s/it]                                                    {'loss': 0.0245, 'grad_norm': 4.084304332733154, 'learning_rate': 9.013559322033899e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 682/6000 [22:02<2:51:00,  1.93s/it] 11%|â–ˆâ–        | 683/6000 [22:03<2:49:57,  1.92s/it]                                                    {'loss': 0.0806, 'grad_norm': 7.810581207275391, 'learning_rate': 9.01186440677966e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 683/6000 [22:03<2:49:57,  1.92s/it] 11%|â–ˆâ–        | 684/6000 [22:05<2:49:17,  1.91s/it]                                                    {'loss': 0.1112, 'grad_norm': 84.05329132080078, 'learning_rate': 9.010169491525424e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 684/6000 [22:05<2:49:17,  1.91s/it] 11%|â–ˆâ–        | 685/6000 [22:07<2:48:54,  1.91s/it]                                                    {'loss': 0.1153, 'grad_norm': 9.871186256408691, 'learning_rate': 9.008474576271187e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 685/6000 [22:07<2:48:54,  1.91s/it] 11%|â–ˆâ–        | 686/6000 [22:09<2:54:18,  1.97s/it]                                                    {'loss': 0.1346, 'grad_norm': 7.347407817840576, 'learning_rate': 9.00677966101695e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 686/6000 [22:09<2:54:18,  1.97s/it] 11%|â–ˆâ–        | 687/6000 [22:11<2:51:40,  1.94s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.24481208622455597, 'learning_rate': 9.005084745762712e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 687/6000 [22:11<2:51:40,  1.94s/it] 11%|â–ˆâ–        | 688/6000 [22:13<2:49:18,  1.91s/it]                                                    {'loss': 0.0309, 'grad_norm': 3.610999345779419, 'learning_rate': 9.003389830508475e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 688/6000 [22:13<2:49:18,  1.91s/it] 11%|â–ˆâ–        | 689/6000 [22:15<2:48:49,  1.91s/it]                                                    {'loss': 0.1735, 'grad_norm': 12.551942825317383, 'learning_rate': 9.001694915254237e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 689/6000 [22:15<2:48:49,  1.91s/it] 12%|â–ˆâ–        | 690/6000 [22:17<2:48:00,  1.90s/it]                                                    {'loss': 0.1037, 'grad_norm': 7.234025478363037, 'learning_rate': 9e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 690/6000 [22:17<2:48:00,  1.90s/it] 12%|â–ˆâ–        | 691/6000 [22:19<2:47:40,  1.90s/it]                                                    {'loss': 0.0694, 'grad_norm': 7.809553146362305, 'learning_rate': 8.998305084745764e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 691/6000 [22:19<2:47:40,  1.90s/it] 12%|â–ˆâ–        | 692/6000 [22:21<2:47:24,  1.89s/it]                                                    {'loss': 0.2733, 'grad_norm': 13.435977935791016, 'learning_rate': 8.996610169491527e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 692/6000 [22:21<2:47:24,  1.89s/it] 12%|â–ˆâ–        | 693/6000 [22:22<2:46:29,  1.88s/it]                                                    {'loss': 0.0946, 'grad_norm': 7.6613335609436035, 'learning_rate': 8.994915254237288e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 693/6000 [22:22<2:46:29,  1.88s/it] 12%|â–ˆâ–        | 694/6000 [22:24<2:47:08,  1.89s/it]                                                    {'loss': 0.0018, 'grad_norm': 0.1798262745141983, 'learning_rate': 8.993220338983052e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 694/6000 [22:24<2:47:08,  1.89s/it] 12%|â–ˆâ–        | 695/6000 [22:26<2:47:29,  1.89s/it]                                                    {'loss': 0.0296, 'grad_norm': 3.120943307876587, 'learning_rate': 8.991525423728815e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 695/6000 [22:26<2:47:29,  1.89s/it] 12%|â–ˆâ–        | 696/6000 [22:28<2:50:01,  1.92s/it]                                                    {'loss': 0.1055, 'grad_norm': 12.854844093322754, 'learning_rate': 8.989830508474578e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 696/6000 [22:28<2:50:01,  1.92s/it] 12%|â–ˆâ–        | 697/6000 [22:30<2:48:20,  1.90s/it]                                                    {'loss': 0.2313, 'grad_norm': 12.89133358001709, 'learning_rate': 8.98813559322034e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 697/6000 [22:30<2:48:20,  1.90s/it] 12%|â–ˆâ–        | 698/6000 [22:32<2:47:37,  1.90s/it]                                                    {'loss': 0.1079, 'grad_norm': 9.51220417022705, 'learning_rate': 8.986440677966103e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 698/6000 [22:32<2:47:37,  1.90s/it] 12%|â–ˆâ–        | 699/6000 [22:34<2:48:15,  1.90s/it]                                                    {'loss': 0.0417, 'grad_norm': 5.209376335144043, 'learning_rate': 8.984745762711865e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 699/6000 [22:34<2:48:15,  1.90s/it] 12%|â–ˆâ–        | 700/6000 [22:36<2:48:55,  1.91s/it]                                                    {'loss': 0.0189, 'grad_norm': 2.0365657806396484, 'learning_rate': 8.983050847457628e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 700/6000 [22:36<2:48:55,  1.91s/it][2025-11-11 22:15:51,783] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700
[2025-11-11 22:15:51,791] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:15:52,081] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|â–ˆâ–        | 701/6000 [22:39<3:10:33,  2.16s/it]                                                    {'loss': 0.0211, 'grad_norm': 3.0396625995635986, 'learning_rate': 8.981355932203391e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 701/6000 [22:39<3:10:33,  2.16s/it] 12%|â–ˆâ–        | 702/6000 [22:41<3:06:32,  2.11s/it]                                                    {'loss': 0.0813, 'grad_norm': 8.14387035369873, 'learning_rate': 8.979661016949154e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 702/6000 [22:41<3:06:32,  2.11s/it] 12%|â–ˆâ–        | 703/6000 [22:43<3:01:55,  2.06s/it]                                                    {'loss': 0.0177, 'grad_norm': 2.148137092590332, 'learning_rate': 8.977966101694916e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 703/6000 [22:43<3:01:55,  2.06s/it] 12%|â–ˆâ–        | 704/6000 [22:45<3:00:51,  2.05s/it]                                                    {'loss': 0.0319, 'grad_norm': 3.450711250305176, 'learning_rate': 8.976271186440678e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 704/6000 [22:45<3:00:51,  2.05s/it] 12%|â–ˆâ–        | 705/6000 [22:47<2:57:53,  2.02s/it]                                                    {'loss': 0.1184, 'grad_norm': 9.257235527038574, 'learning_rate': 8.974576271186441e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 705/6000 [22:47<2:57:53,  2.02s/it] 12%|â–ˆâ–        | 706/6000 [22:48<2:54:46,  1.98s/it]                                                    {'loss': 0.1186, 'grad_norm': 6.474087238311768, 'learning_rate': 8.972881355932204e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 706/6000 [22:48<2:54:46,  1.98s/it] 12%|â–ˆâ–        | 707/6000 [22:50<2:53:08,  1.96s/it]                                                    {'loss': 0.0495, 'grad_norm': 7.224219799041748, 'learning_rate': 8.971186440677967e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 707/6000 [22:50<2:53:08,  1.96s/it] 12%|â–ˆâ–        | 708/6000 [22:52<2:51:27,  1.94s/it]                                                    {'loss': 0.0118, 'grad_norm': 1.52439284324646, 'learning_rate': 8.969491525423729e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 708/6000 [22:52<2:51:27,  1.94s/it] 12%|â–ˆâ–        | 709/6000 [22:54<2:50:04,  1.93s/it]                                                    {'loss': 0.1048, 'grad_norm': 9.207730293273926, 'learning_rate': 8.967796610169492e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 709/6000 [22:54<2:50:04,  1.93s/it] 12%|â–ˆâ–        | 710/6000 [22:56<2:50:24,  1.93s/it]                                                    {'loss': 0.0362, 'grad_norm': 4.786989212036133, 'learning_rate': 8.966101694915254e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 710/6000 [22:56<2:50:24,  1.93s/it] 12%|â–ˆâ–        | 711/6000 [22:58<2:49:01,  1.92s/it]                                                    {'loss': 0.0023, 'grad_norm': 0.4092416763305664, 'learning_rate': 8.964406779661017e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 711/6000 [22:58<2:49:01,  1.92s/it] 12%|â–ˆâ–        | 712/6000 [23:00<2:47:57,  1.91s/it]                                                    {'loss': 0.0224, 'grad_norm': 3.679969549179077, 'learning_rate': 8.96271186440678e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 712/6000 [23:00<2:47:57,  1.91s/it] 12%|â–ˆâ–        | 713/6000 [23:02<2:47:00,  1.90s/it]                                                    {'loss': 0.1922, 'grad_norm': 18.491043090820312, 'learning_rate': 8.961016949152544e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 713/6000 [23:02<2:47:00,  1.90s/it] 12%|â–ˆâ–        | 714/6000 [23:04<2:46:52,  1.89s/it]                                                    {'loss': 0.0306, 'grad_norm': 4.455043315887451, 'learning_rate': 8.959322033898305e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 714/6000 [23:04<2:46:52,  1.89s/it] 12%|â–ˆâ–        | 715/6000 [23:05<2:46:02,  1.89s/it]                                                    {'loss': 0.0379, 'grad_norm': 4.914524555206299, 'learning_rate': 8.957627118644069e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 715/6000 [23:05<2:46:02,  1.89s/it] 12%|â–ˆâ–        | 716/6000 [23:07<2:45:37,  1.88s/it]                                                    {'loss': 0.0812, 'grad_norm': 7.185983657836914, 'learning_rate': 8.955932203389832e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 716/6000 [23:07<2:45:37,  1.88s/it] 12%|â–ˆâ–        | 717/6000 [23:09<2:47:44,  1.91s/it]                                                    {'loss': 0.1645, 'grad_norm': 12.632716178894043, 'learning_rate': 8.954237288135595e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 717/6000 [23:09<2:47:44,  1.91s/it] 12%|â–ˆâ–        | 718/6000 [23:11<2:46:02,  1.89s/it]                                                    {'loss': 0.0527, 'grad_norm': 5.989517688751221, 'learning_rate': 8.952542372881357e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 718/6000 [23:11<2:46:02,  1.89s/it] 12%|â–ˆâ–        | 719/6000 [23:13<2:45:41,  1.88s/it]                                                    {'loss': 0.1189, 'grad_norm': 10.941277503967285, 'learning_rate': 8.95084745762712e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 719/6000 [23:13<2:45:41,  1.88s/it] 12%|â–ˆâ–        | 720/6000 [23:15<2:44:00,  1.86s/it]                                                    {'loss': 0.007, 'grad_norm': 0.7538619041442871, 'learning_rate': 8.949152542372881e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 720/6000 [23:15<2:44:00,  1.86s/it] 12%|â–ˆâ–        | 721/6000 [23:17<2:49:03,  1.92s/it]                                                    {'loss': 0.0389, 'grad_norm': 2.928645372390747, 'learning_rate': 8.947457627118645e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 721/6000 [23:17<2:49:03,  1.92s/it] 12%|â–ˆâ–        | 722/6000 [23:19<2:48:01,  1.91s/it]                                                    {'loss': 0.0593, 'grad_norm': 4.004528999328613, 'learning_rate': 8.945762711864408e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 722/6000 [23:19<2:48:01,  1.91s/it] 12%|â–ˆâ–        | 723/6000 [23:21<2:51:41,  1.95s/it]                                                    {'loss': 0.0932, 'grad_norm': 8.87156867980957, 'learning_rate': 8.944067796610171e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 723/6000 [23:21<2:51:41,  1.95s/it] 12%|â–ˆâ–        | 724/6000 [23:23<2:48:57,  1.92s/it]                                                    {'loss': 0.0718, 'grad_norm': 6.569359302520752, 'learning_rate': 8.942372881355933e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 724/6000 [23:23<2:48:57,  1.92s/it] 12%|â–ˆâ–        | 725/6000 [23:25<2:47:29,  1.91s/it]                                                    {'loss': 0.1881, 'grad_norm': 13.35422420501709, 'learning_rate': 8.940677966101694e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 725/6000 [23:25<2:47:29,  1.91s/it] 12%|â–ˆâ–        | 726/6000 [23:26<2:47:12,  1.90s/it]                                                    {'loss': 0.0195, 'grad_norm': 1.724866509437561, 'learning_rate': 8.938983050847458e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 726/6000 [23:26<2:47:12,  1.90s/it] 12%|â–ˆâ–        | 727/6000 [23:28<2:46:39,  1.90s/it]                                                    {'loss': 0.152, 'grad_norm': 8.40677261352539, 'learning_rate': 8.937288135593221e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 727/6000 [23:28<2:46:39,  1.90s/it] 12%|â–ˆâ–        | 728/6000 [23:30<2:46:25,  1.89s/it]                                                    {'loss': 0.055, 'grad_norm': 5.8113532066345215, 'learning_rate': 8.935593220338984e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 728/6000 [23:30<2:46:25,  1.89s/it] 12%|â–ˆâ–        | 729/6000 [23:32<2:46:12,  1.89s/it]                                                    {'loss': 0.0103, 'grad_norm': 1.9100310802459717, 'learning_rate': 8.933898305084746e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 729/6000 [23:32<2:46:12,  1.89s/it] 12%|â–ˆâ–        | 730/6000 [23:34<2:45:42,  1.89s/it]                                                    {'loss': 0.1064, 'grad_norm': 3.406611442565918, 'learning_rate': 8.932203389830509e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 730/6000 [23:34<2:45:42,  1.89s/it] 12%|â–ˆâ–        | 731/6000 [23:36<2:44:24,  1.87s/it]                                                    {'loss': 0.0171, 'grad_norm': 2.3227925300598145, 'learning_rate': 8.93050847457627e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 731/6000 [23:36<2:44:24,  1.87s/it] 12%|â–ˆâ–        | 732/6000 [23:38<2:46:01,  1.89s/it]                                                    {'loss': 0.1005, 'grad_norm': 8.640180587768555, 'learning_rate': 8.928813559322036e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 732/6000 [23:38<2:46:01,  1.89s/it] 12%|â–ˆâ–        | 733/6000 [23:40<2:47:32,  1.91s/it]                                                    {'loss': 0.0151, 'grad_norm': 2.349381923675537, 'learning_rate': 8.927118644067797e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 733/6000 [23:40<2:47:32,  1.91s/it] 12%|â–ˆâ–        | 734/6000 [23:42<2:52:08,  1.96s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.781737208366394, 'learning_rate': 8.92542372881356e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 734/6000 [23:42<2:52:08,  1.96s/it] 12%|â–ˆâ–        | 735/6000 [23:44<2:49:42,  1.93s/it]                                                    {'loss': 0.0278, 'grad_norm': 4.038482666015625, 'learning_rate': 8.923728813559322e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 735/6000 [23:44<2:49:42,  1.93s/it] 12%|â–ˆâ–        | 736/6000 [23:45<2:46:45,  1.90s/it]                                                    {'loss': 0.0455, 'grad_norm': 4.211441993713379, 'learning_rate': 8.922033898305085e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 736/6000 [23:45<2:46:45,  1.90s/it] 12%|â–ˆâ–        | 737/6000 [23:47<2:45:57,  1.89s/it]                                                    {'loss': 0.0951, 'grad_norm': 7.158553123474121, 'learning_rate': 8.920338983050849e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 737/6000 [23:47<2:45:57,  1.89s/it] 12%|â–ˆâ–        | 738/6000 [23:49<2:44:31,  1.88s/it]                                                    {'loss': 0.2152, 'grad_norm': 12.847042083740234, 'learning_rate': 8.918644067796612e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 738/6000 [23:49<2:44:31,  1.88s/it] 12%|â–ˆâ–        | 739/6000 [23:51<2:49:01,  1.93s/it]                                                    {'loss': 0.018, 'grad_norm': 0.9943739175796509, 'learning_rate': 8.916949152542374e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 739/6000 [23:51<2:49:01,  1.93s/it] 12%|â–ˆâ–        | 740/6000 [23:53<2:48:16,  1.92s/it]                                                    {'loss': 0.3375, 'grad_norm': 12.14339828491211, 'learning_rate': 8.915254237288137e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 740/6000 [23:53<2:48:16,  1.92s/it] 12%|â–ˆâ–        | 741/6000 [23:55<2:48:00,  1.92s/it]                                                    {'loss': 0.0499, 'grad_norm': 4.000787734985352, 'learning_rate': 8.913559322033898e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 741/6000 [23:55<2:48:00,  1.92s/it] 12%|â–ˆâ–        | 742/6000 [23:57<2:46:25,  1.90s/it]                                                    {'loss': 0.0125, 'grad_norm': 1.852599859237671, 'learning_rate': 8.911864406779662e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 742/6000 [23:57<2:46:25,  1.90s/it] 12%|â–ˆâ–        | 743/6000 [23:59<2:45:10,  1.89s/it]                                                    {'loss': 0.1238, 'grad_norm': 11.867486000061035, 'learning_rate': 8.910169491525425e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 743/6000 [23:59<2:45:10,  1.89s/it] 12%|â–ˆâ–        | 744/6000 [24:01<2:44:06,  1.87s/it]                                                    {'loss': 0.0192, 'grad_norm': 1.553092122077942, 'learning_rate': 8.908474576271188e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 744/6000 [24:01<2:44:06,  1.87s/it] 12%|â–ˆâ–        | 745/6000 [24:02<2:43:34,  1.87s/it]                                                    {'loss': 0.2959, 'grad_norm': 17.732376098632812, 'learning_rate': 8.90677966101695e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 745/6000 [24:02<2:43:34,  1.87s/it] 12%|â–ˆâ–        | 746/6000 [24:04<2:43:37,  1.87s/it]                                                    {'loss': 0.2311, 'grad_norm': 8.885825157165527, 'learning_rate': 8.905084745762711e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 746/6000 [24:04<2:43:37,  1.87s/it] 12%|â–ˆâ–        | 747/6000 [24:06<2:43:39,  1.87s/it]                                                    {'loss': 0.0512, 'grad_norm': 4.744688987731934, 'learning_rate': 8.903389830508475e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 747/6000 [24:06<2:43:39,  1.87s/it] 12%|â–ˆâ–        | 748/6000 [24:08<2:44:49,  1.88s/it]                                                    {'loss': 0.0598, 'grad_norm': 8.317927360534668, 'learning_rate': 8.901694915254238e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 748/6000 [24:08<2:44:49,  1.88s/it] 12%|â–ˆâ–        | 749/6000 [24:10<2:53:12,  1.98s/it]                                                    {'loss': 0.1274, 'grad_norm': 10.449708938598633, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 749/6000 [24:10<2:53:12,  1.98s/it] 12%|â–ˆâ–Ž        | 750/6000 [24:12<2:52:29,  1.97s/it]                                                    {'loss': 0.2131, 'grad_norm': 10.067599296569824, 'learning_rate': 8.898305084745763e-06, 'epoch': 0.12}
 12%|â–ˆâ–Ž        | 750/6000 [24:12<2:52:29,  1.97s/it][2025-11-11 22:17:28,162] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-750
[2025-11-11 22:17:28,169] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:17:28,455] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-750/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 751/6000 [24:15<3:10:34,  2.18s/it]                                                    {'loss': 0.0542, 'grad_norm': 4.997625350952148, 'learning_rate': 8.896610169491526e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 751/6000 [24:15<3:10:34,  2.18s/it] 13%|â–ˆâ–Ž        | 752/6000 [24:17<3:07:07,  2.14s/it]                                                    {'loss': 0.0494, 'grad_norm': 5.5802717208862305, 'learning_rate': 8.89491525423729e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 752/6000 [24:17<3:07:07,  2.14s/it] 13%|â–ˆâ–Ž        | 753/6000 [24:19<3:00:00,  2.06s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.059174422174692154, 'learning_rate': 8.893220338983053e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 753/6000 [24:19<3:00:00,  2.06s/it] 13%|â–ˆâ–Ž        | 754/6000 [24:21<2:55:18,  2.01s/it]                                                    {'loss': 0.0677, 'grad_norm': 5.4763007164001465, 'learning_rate': 8.891525423728814e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 754/6000 [24:21<2:55:18,  2.01s/it] 13%|â–ˆâ–Ž        | 755/6000 [24:23<2:50:42,  1.95s/it]                                                    {'loss': 0.0046, 'grad_norm': 1.0716115236282349, 'learning_rate': 8.889830508474577e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 755/6000 [24:23<2:50:42,  1.95s/it] 13%|â–ˆâ–Ž        | 756/6000 [24:24<2:47:27,  1.92s/it]                                                    {'loss': 0.0217, 'grad_norm': 4.460322380065918, 'learning_rate': 8.888135593220339e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 756/6000 [24:24<2:47:27,  1.92s/it] 13%|â–ˆâ–Ž        | 757/6000 [24:26<2:48:22,  1.93s/it]                                                    {'loss': 0.029, 'grad_norm': 4.358399391174316, 'learning_rate': 8.886440677966102e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 757/6000 [24:26<2:48:22,  1.93s/it] 13%|â–ˆâ–Ž        | 758/6000 [24:28<2:48:25,  1.93s/it]                                                    {'loss': 0.0889, 'grad_norm': 7.517561435699463, 'learning_rate': 8.884745762711866e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 758/6000 [24:28<2:48:25,  1.93s/it] 13%|â–ˆâ–Ž        | 759/6000 [24:30<2:46:52,  1.91s/it]                                                    {'loss': 0.2467, 'grad_norm': 13.765374183654785, 'learning_rate': 8.883050847457629e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 759/6000 [24:30<2:46:52,  1.91s/it] 13%|â–ˆâ–Ž        | 760/6000 [24:32<2:46:14,  1.90s/it]                                                    {'loss': 0.0041, 'grad_norm': 0.6169062852859497, 'learning_rate': 8.88135593220339e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 760/6000 [24:32<2:46:14,  1.90s/it] 13%|â–ˆâ–Ž        | 761/6000 [24:34<2:46:13,  1.90s/it]                                                    {'loss': 0.0686, 'grad_norm': 4.518242359161377, 'learning_rate': 8.879661016949154e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 761/6000 [24:34<2:46:13,  1.90s/it] 13%|â–ˆâ–Ž        | 762/6000 [24:36<2:46:44,  1.91s/it]                                                    {'loss': 0.0931, 'grad_norm': 8.550538063049316, 'learning_rate': 8.877966101694915e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 762/6000 [24:36<2:46:44,  1.91s/it] 13%|â–ˆâ–Ž        | 763/6000 [24:38<2:45:08,  1.89s/it]                                                    {'loss': 0.158, 'grad_norm': 6.982670783996582, 'learning_rate': 8.876271186440679e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 763/6000 [24:38<2:45:08,  1.89s/it] 13%|â–ˆâ–Ž        | 764/6000 [24:40<2:45:18,  1.89s/it]                                                    {'loss': 0.0817, 'grad_norm': 9.985743522644043, 'learning_rate': 8.874576271186442e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 764/6000 [24:40<2:45:18,  1.89s/it] 13%|â–ˆâ–Ž        | 765/6000 [24:41<2:44:41,  1.89s/it]                                                    {'loss': 0.0439, 'grad_norm': 4.380531311035156, 'learning_rate': 8.872881355932203e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 765/6000 [24:41<2:44:41,  1.89s/it] 13%|â–ˆâ–Ž        | 766/6000 [24:43<2:45:10,  1.89s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.05223878100514412, 'learning_rate': 8.871186440677967e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 766/6000 [24:43<2:45:10,  1.89s/it] 13%|â–ˆâ–Ž        | 767/6000 [24:45<2:46:38,  1.91s/it]                                                    {'loss': 0.0248, 'grad_norm': 4.896833896636963, 'learning_rate': 8.869491525423728e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 767/6000 [24:45<2:46:38,  1.91s/it] 13%|â–ˆâ–Ž        | 768/6000 [24:47<2:45:20,  1.90s/it]                                                    {'loss': 0.0149, 'grad_norm': 2.6774020195007324, 'learning_rate': 8.867796610169492e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 768/6000 [24:47<2:45:20,  1.90s/it] 13%|â–ˆâ–Ž        | 769/6000 [24:49<2:47:29,  1.92s/it]                                                    {'loss': 0.0424, 'grad_norm': 1.787517786026001, 'learning_rate': 8.866101694915255e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 769/6000 [24:49<2:47:29,  1.92s/it] 13%|â–ˆâ–Ž        | 770/6000 [24:51<2:45:31,  1.90s/it]                                                    {'loss': 0.1524, 'grad_norm': 8.857673645019531, 'learning_rate': 8.864406779661018e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 770/6000 [24:51<2:45:31,  1.90s/it] 13%|â–ˆâ–Ž        | 771/6000 [24:53<2:44:24,  1.89s/it]                                                    {'loss': 0.0102, 'grad_norm': 1.3680294752120972, 'learning_rate': 8.86271186440678e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 771/6000 [24:53<2:44:24,  1.89s/it] 13%|â–ˆâ–Ž        | 772/6000 [24:55<2:43:54,  1.88s/it]                                                    {'loss': 0.0043, 'grad_norm': 0.8709355592727661, 'learning_rate': 8.861016949152543e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 772/6000 [24:55<2:43:54,  1.88s/it] 13%|â–ˆâ–Ž        | 773/6000 [24:57<2:42:26,  1.86s/it]                                                    {'loss': 0.1903, 'grad_norm': 10.647605895996094, 'learning_rate': 8.859322033898306e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 773/6000 [24:57<2:42:26,  1.86s/it] 13%|â–ˆâ–Ž        | 774/6000 [24:58<2:42:45,  1.87s/it]                                                    {'loss': 0.0074, 'grad_norm': 0.8842568397521973, 'learning_rate': 8.85762711864407e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 774/6000 [24:58<2:42:45,  1.87s/it] 13%|â–ˆâ–Ž        | 775/6000 [25:00<2:44:31,  1.89s/it]                                                    {'loss': 0.0258, 'grad_norm': 3.98006534576416, 'learning_rate': 8.855932203389831e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 775/6000 [25:00<2:44:31,  1.89s/it] 13%|â–ˆâ–Ž        | 776/6000 [25:02<2:44:31,  1.89s/it]                                                    {'loss': 0.0758, 'grad_norm': 9.572864532470703, 'learning_rate': 8.854237288135594e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 776/6000 [25:02<2:44:31,  1.89s/it] 13%|â–ˆâ–Ž        | 777/6000 [25:04<2:46:48,  1.92s/it]                                                    {'loss': 0.0246, 'grad_norm': 4.896695137023926, 'learning_rate': 8.852542372881356e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 777/6000 [25:04<2:46:48,  1.92s/it] 13%|â–ˆâ–Ž        | 778/6000 [25:06<2:46:54,  1.92s/it]                                                    {'loss': 0.2624, 'grad_norm': 16.253026962280273, 'learning_rate': 8.85084745762712e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 778/6000 [25:06<2:46:54,  1.92s/it] 13%|â–ˆâ–Ž        | 779/6000 [25:08<2:45:00,  1.90s/it]                                                    {'loss': 0.0687, 'grad_norm': 8.1597261428833, 'learning_rate': 8.849152542372882e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 779/6000 [25:08<2:45:00,  1.90s/it] 13%|â–ˆâ–Ž        | 780/6000 [25:10<2:44:21,  1.89s/it]                                                    {'loss': 0.0083, 'grad_norm': 0.8777769207954407, 'learning_rate': 8.847457627118646e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 780/6000 [25:10<2:44:21,  1.89s/it] 13%|â–ˆâ–Ž        | 781/6000 [25:12<2:44:33,  1.89s/it]                                                    {'loss': 0.0341, 'grad_norm': 8.452178955078125, 'learning_rate': 8.845762711864407e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 781/6000 [25:12<2:44:33,  1.89s/it] 13%|â–ˆâ–Ž        | 782/6000 [25:14<2:43:50,  1.88s/it]                                                    {'loss': 0.0436, 'grad_norm': 7.528553485870361, 'learning_rate': 8.84406779661017e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 782/6000 [25:14<2:43:50,  1.88s/it] 13%|â–ˆâ–Ž        | 783/6000 [25:15<2:42:56,  1.87s/it]                                                    {'loss': 0.044, 'grad_norm': 6.552030086517334, 'learning_rate': 8.842372881355932e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 783/6000 [25:15<2:42:56,  1.87s/it] 13%|â–ˆâ–Ž        | 784/6000 [25:17<2:41:39,  1.86s/it]                                                    {'loss': 0.0859, 'grad_norm': 6.643801689147949, 'learning_rate': 8.840677966101695e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 784/6000 [25:17<2:41:39,  1.86s/it] 13%|â–ˆâ–Ž        | 785/6000 [25:19<2:41:07,  1.85s/it]                                                    {'loss': 0.2796, 'grad_norm': 18.529800415039062, 'learning_rate': 8.838983050847459e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 785/6000 [25:19<2:41:07,  1.85s/it] 13%|â–ˆâ–Ž        | 786/6000 [25:21<2:40:44,  1.85s/it]                                                    {'loss': 0.0544, 'grad_norm': 9.814433097839355, 'learning_rate': 8.83728813559322e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 786/6000 [25:21<2:40:44,  1.85s/it] 13%|â–ˆâ–Ž        | 787/6000 [25:23<2:42:10,  1.87s/it]                                                    {'loss': 0.0618, 'grad_norm': 9.06969165802002, 'learning_rate': 8.835593220338984e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 787/6000 [25:23<2:42:10,  1.87s/it] 13%|â–ˆâ–Ž        | 788/6000 [25:25<2:42:04,  1.87s/it]                                                    {'loss': 0.03, 'grad_norm': 3.4082415103912354, 'learning_rate': 8.833898305084747e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 788/6000 [25:25<2:42:04,  1.87s/it] 13%|â–ˆâ–Ž        | 789/6000 [25:27<2:42:44,  1.87s/it]                                                    {'loss': 0.0557, 'grad_norm': 9.321134567260742, 'learning_rate': 8.83220338983051e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 789/6000 [25:27<2:42:44,  1.87s/it] 13%|â–ˆâ–Ž        | 790/6000 [25:29<2:42:10,  1.87s/it]                                                    {'loss': 0.2158, 'grad_norm': 11.792683601379395, 'learning_rate': 8.830508474576272e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 790/6000 [25:29<2:42:10,  1.87s/it] 13%|â–ˆâ–Ž        | 791/6000 [25:30<2:42:30,  1.87s/it]                                                    {'loss': 0.0405, 'grad_norm': 3.1690661907196045, 'learning_rate': 8.828813559322035e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 791/6000 [25:30<2:42:30,  1.87s/it] 13%|â–ˆâ–Ž        | 792/6000 [25:32<2:42:55,  1.88s/it]                                                    {'loss': 0.1111, 'grad_norm': 12.45565414428711, 'learning_rate': 8.827118644067797e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 792/6000 [25:32<2:42:55,  1.88s/it] 13%|â–ˆâ–Ž        | 793/6000 [25:34<2:42:21,  1.87s/it]                                                    {'loss': 0.0074, 'grad_norm': 1.4144158363342285, 'learning_rate': 8.82542372881356e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 793/6000 [25:34<2:42:21,  1.87s/it] 13%|â–ˆâ–Ž        | 794/6000 [25:36<2:42:41,  1.88s/it]                                                    {'loss': 0.0075, 'grad_norm': 1.4343137741088867, 'learning_rate': 8.823728813559323e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 794/6000 [25:36<2:42:41,  1.88s/it] 13%|â–ˆâ–Ž        | 795/6000 [25:38<2:45:12,  1.90s/it]                                                    {'loss': 0.0203, 'grad_norm': 2.984731912612915, 'learning_rate': 8.822033898305086e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 795/6000 [25:38<2:45:12,  1.90s/it] 13%|â–ˆâ–Ž        | 796/6000 [25:40<2:43:38,  1.89s/it]                                                    {'loss': 0.2131, 'grad_norm': 14.03100299835205, 'learning_rate': 8.820338983050848e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 796/6000 [25:40<2:43:38,  1.89s/it] 13%|â–ˆâ–Ž        | 797/6000 [25:42<2:44:27,  1.90s/it]                                                    {'loss': 0.0431, 'grad_norm': 6.330636978149414, 'learning_rate': 8.818644067796611e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 797/6000 [25:42<2:44:27,  1.90s/it] 13%|â–ˆâ–Ž        | 798/6000 [25:44<2:43:25,  1.88s/it]                                                    {'loss': 0.0046, 'grad_norm': 1.1379201412200928, 'learning_rate': 8.816949152542373e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 798/6000 [25:44<2:43:25,  1.88s/it] 13%|â–ˆâ–Ž        | 799/6000 [25:46<2:43:23,  1.88s/it]                                                    {'loss': 0.326, 'grad_norm': 17.519386291503906, 'learning_rate': 8.815254237288136e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 799/6000 [25:46<2:43:23,  1.88s/it] 13%|â–ˆâ–Ž        | 800/6000 [25:47<2:43:42,  1.89s/it]                                                    {'loss': 0.1011, 'grad_norm': 9.887874603271484, 'learning_rate': 8.8135593220339e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 800/6000 [25:47<2:43:42,  1.89s/it][2025-11-11 22:19:03,323] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800
[2025-11-11 22:19:03,330] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:19:03,612] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 801/6000 [25:50<3:05:00,  2.14s/it]                                                    {'loss': 0.0139, 'grad_norm': 2.9225826263427734, 'learning_rate': 8.811864406779663e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 801/6000 [25:50<3:05:00,  2.14s/it] 13%|â–ˆâ–Ž        | 802/6000 [25:52<2:58:49,  2.06s/it]                                                    {'loss': 0.0347, 'grad_norm': 11.251105308532715, 'learning_rate': 8.810169491525424e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 802/6000 [25:52<2:58:49,  2.06s/it] 13%|â–ˆâ–Ž        | 803/6000 [25:54<2:57:32,  2.05s/it]                                                    {'loss': 0.2044, 'grad_norm': 7.28373384475708, 'learning_rate': 8.808474576271187e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 803/6000 [25:54<2:57:32,  2.05s/it] 13%|â–ˆâ–Ž        | 804/6000 [25:56<2:52:52,  2.00s/it]                                                    {'loss': 0.2312, 'grad_norm': 11.035117149353027, 'learning_rate': 8.806779661016949e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 804/6000 [25:56<2:52:52,  2.00s/it] 13%|â–ˆâ–Ž        | 805/6000 [25:58<2:49:59,  1.96s/it]                                                    {'loss': 0.0104, 'grad_norm': 1.5119216442108154, 'learning_rate': 8.805084745762712e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 805/6000 [25:58<2:49:59,  1.96s/it] 13%|â–ˆâ–Ž        | 806/6000 [26:00<2:48:59,  1.95s/it]                                                    {'loss': 0.007, 'grad_norm': 1.5450527667999268, 'learning_rate': 8.803389830508476e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 806/6000 [26:00<2:48:59,  1.95s/it] 13%|â–ˆâ–Ž        | 807/6000 [26:02<2:46:37,  1.93s/it]                                                    {'loss': 0.0261, 'grad_norm': 4.219038009643555, 'learning_rate': 8.801694915254237e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 807/6000 [26:02<2:46:37,  1.93s/it] 13%|â–ˆâ–Ž        | 808/6000 [26:03<2:44:57,  1.91s/it]                                                    {'loss': 0.0525, 'grad_norm': 7.100835800170898, 'learning_rate': 8.8e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 808/6000 [26:03<2:44:57,  1.91s/it] 13%|â–ˆâ–Ž        | 809/6000 [26:05<2:43:55,  1.89s/it]                                                    {'loss': 0.0507, 'grad_norm': 6.960504531860352, 'learning_rate': 8.798305084745764e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 809/6000 [26:05<2:43:55,  1.89s/it] 14%|â–ˆâ–Ž        | 810/6000 [26:07<2:44:55,  1.91s/it]                                                    {'loss': 0.457, 'grad_norm': 16.628128051757812, 'learning_rate': 8.796610169491527e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 810/6000 [26:07<2:44:55,  1.91s/it] 14%|â–ˆâ–Ž        | 811/6000 [26:09<2:44:28,  1.90s/it]                                                    {'loss': 0.0114, 'grad_norm': 1.6233088970184326, 'learning_rate': 8.794915254237289e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 811/6000 [26:09<2:44:28,  1.90s/it] 14%|â–ˆâ–Ž        | 812/6000 [26:11<2:43:09,  1.89s/it]                                                    {'loss': 0.0355, 'grad_norm': 3.867807626724243, 'learning_rate': 8.793220338983052e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 812/6000 [26:11<2:43:09,  1.89s/it] 14%|â–ˆâ–Ž        | 813/6000 [26:13<2:50:46,  1.98s/it]                                                    {'loss': 0.0996, 'grad_norm': 8.297682762145996, 'learning_rate': 8.791525423728813e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 813/6000 [26:13<2:50:46,  1.98s/it] 14%|â–ˆâ–Ž        | 814/6000 [26:15<2:48:27,  1.95s/it]                                                    {'loss': 0.0841, 'grad_norm': 6.240425109863281, 'learning_rate': 8.789830508474577e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 814/6000 [26:15<2:48:27,  1.95s/it] 14%|â–ˆâ–Ž        | 815/6000 [26:17<2:50:21,  1.97s/it]                                                    {'loss': 0.0136, 'grad_norm': 1.6975785493850708, 'learning_rate': 8.78813559322034e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 815/6000 [26:17<2:50:21,  1.97s/it] 14%|â–ˆâ–Ž        | 816/6000 [26:19<2:46:47,  1.93s/it]                                                    {'loss': 0.1408, 'grad_norm': 8.821329116821289, 'learning_rate': 8.786440677966103e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 816/6000 [26:19<2:46:47,  1.93s/it] 14%|â–ˆâ–Ž        | 817/6000 [26:21<2:52:06,  1.99s/it]                                                    {'loss': 0.2, 'grad_norm': 11.904397010803223, 'learning_rate': 8.784745762711865e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 817/6000 [26:21<2:52:06,  1.99s/it] 14%|â–ˆâ–Ž        | 818/6000 [26:23<2:48:44,  1.95s/it]                                                    {'loss': 0.0562, 'grad_norm': 6.125057697296143, 'learning_rate': 8.783050847457628e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 818/6000 [26:23<2:48:44,  1.95s/it] 14%|â–ˆâ–Ž        | 819/6000 [26:25<2:47:11,  1.94s/it]                                                    {'loss': 0.0829, 'grad_norm': 6.566797733306885, 'learning_rate': 8.78135593220339e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 819/6000 [26:25<2:47:11,  1.94s/it] 14%|â–ˆâ–Ž        | 820/6000 [26:27<2:45:52,  1.92s/it]                                                    {'loss': 0.081, 'grad_norm': 9.807198524475098, 'learning_rate': 8.779661016949153e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 820/6000 [26:27<2:45:52,  1.92s/it] 14%|â–ˆâ–Ž        | 821/6000 [26:29<2:45:23,  1.92s/it]                                                    {'loss': 0.0339, 'grad_norm': 5.083004951477051, 'learning_rate': 8.777966101694916e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 821/6000 [26:29<2:45:23,  1.92s/it] 14%|â–ˆâ–Ž        | 822/6000 [26:30<2:43:30,  1.89s/it]                                                    {'loss': 0.0078, 'grad_norm': 1.2880109548568726, 'learning_rate': 8.77627118644068e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 822/6000 [26:30<2:43:30,  1.89s/it] 14%|â–ˆâ–Ž        | 823/6000 [26:32<2:44:17,  1.90s/it]                                                    {'loss': 0.4195, 'grad_norm': 254.6563262939453, 'learning_rate': 8.774576271186441e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 823/6000 [26:32<2:44:17,  1.90s/it] 14%|â–ˆâ–Ž        | 824/6000 [26:34<2:42:40,  1.89s/it]                                                    {'loss': 0.0051, 'grad_norm': 0.8911167979240417, 'learning_rate': 8.772881355932204e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 824/6000 [26:34<2:42:40,  1.89s/it] 14%|â–ˆâ–        | 825/6000 [26:36<2:43:52,  1.90s/it]                                                    {'loss': 0.0945, 'grad_norm': 7.590132236480713, 'learning_rate': 8.771186440677966e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 825/6000 [26:36<2:43:52,  1.90s/it] 14%|â–ˆâ–        | 826/6000 [26:38<2:42:49,  1.89s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.6639949679374695, 'learning_rate': 8.76949152542373e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 826/6000 [26:38<2:42:49,  1.89s/it] 14%|â–ˆâ–        | 827/6000 [26:40<2:42:37,  1.89s/it]                                                    {'loss': 0.0167, 'grad_norm': 3.2500524520874023, 'learning_rate': 8.767796610169492e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 827/6000 [26:40<2:42:37,  1.89s/it] 14%|â–ˆâ–        | 828/6000 [26:42<2:42:58,  1.89s/it]                                                    {'loss': 0.3901, 'grad_norm': 15.97122573852539, 'learning_rate': 8.766101694915254e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 828/6000 [26:42<2:42:58,  1.89s/it] 14%|â–ˆâ–        | 829/6000 [26:44<2:43:41,  1.90s/it]                                                    {'loss': 0.1133, 'grad_norm': 5.127806663513184, 'learning_rate': 8.764406779661017e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 829/6000 [26:44<2:43:41,  1.90s/it] 14%|â–ˆâ–        | 830/6000 [26:46<2:53:28,  2.01s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.26696833968162537, 'learning_rate': 8.76271186440678e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 830/6000 [26:46<2:53:28,  2.01s/it] 14%|â–ˆâ–        | 831/6000 [26:48<2:51:01,  1.99s/it]                                                    {'loss': 0.1328, 'grad_norm': 11.92546272277832, 'learning_rate': 8.761016949152544e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 831/6000 [26:48<2:51:01,  1.99s/it] 14%|â–ˆâ–        | 832/6000 [26:50<2:47:28,  1.94s/it]                                                    {'loss': 0.1203, 'grad_norm': 11.715651512145996, 'learning_rate': 8.759322033898305e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 832/6000 [26:50<2:47:28,  1.94s/it] 14%|â–ˆâ–        | 833/6000 [26:52<2:44:29,  1.91s/it]                                                    {'loss': 0.0189, 'grad_norm': 4.127523422241211, 'learning_rate': 8.757627118644069e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 833/6000 [26:52<2:44:29,  1.91s/it] 14%|â–ˆâ–        | 834/6000 [26:53<2:42:52,  1.89s/it]                                                    {'loss': 0.0466, 'grad_norm': 5.625030040740967, 'learning_rate': 8.75593220338983e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 834/6000 [26:53<2:42:52,  1.89s/it] 14%|â–ˆâ–        | 835/6000 [26:55<2:46:11,  1.93s/it]                                                    {'loss': 0.0441, 'grad_norm': 5.003623962402344, 'learning_rate': 8.754237288135594e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 835/6000 [26:55<2:46:11,  1.93s/it] 14%|â–ˆâ–        | 836/6000 [26:57<2:43:34,  1.90s/it]                                                    {'loss': 0.0969, 'grad_norm': 9.83375072479248, 'learning_rate': 8.752542372881357e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 836/6000 [26:57<2:43:34,  1.90s/it] 14%|â–ˆâ–        | 837/6000 [27:00<2:51:46,  2.00s/it]                                                    {'loss': 0.0188, 'grad_norm': 4.902773857116699, 'learning_rate': 8.75084745762712e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 837/6000 [27:00<2:51:46,  2.00s/it] 14%|â–ˆâ–        | 838/6000 [27:01<2:51:30,  1.99s/it]                                                    {'loss': 0.1527, 'grad_norm': 15.056129455566406, 'learning_rate': 8.749152542372882e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 838/6000 [27:01<2:51:30,  1.99s/it] 14%|â–ˆâ–        | 839/6000 [27:03<2:48:33,  1.96s/it]                                                    {'loss': 0.0041, 'grad_norm': 0.5688828229904175, 'learning_rate': 8.747457627118645e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 839/6000 [27:03<2:48:33,  1.96s/it] 14%|â–ˆâ–        | 840/6000 [27:05<2:46:48,  1.94s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.28582751750946045, 'learning_rate': 8.745762711864407e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 840/6000 [27:05<2:46:48,  1.94s/it] 14%|â–ˆâ–        | 841/6000 [27:07<2:48:07,  1.96s/it]                                                    {'loss': 0.0484, 'grad_norm': 3.9629037380218506, 'learning_rate': 8.74406779661017e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 841/6000 [27:07<2:48:07,  1.96s/it] 14%|â–ˆâ–        | 842/6000 [27:09<2:46:15,  1.93s/it]                                                    {'loss': 0.1512, 'grad_norm': 10.478055953979492, 'learning_rate': 8.742372881355933e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 842/6000 [27:09<2:46:15,  1.93s/it] 14%|â–ˆâ–        | 843/6000 [27:11<2:44:05,  1.91s/it]                                                    {'loss': 0.0107, 'grad_norm': 1.3946901559829712, 'learning_rate': 8.740677966101696e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 843/6000 [27:11<2:44:05,  1.91s/it] 14%|â–ˆâ–        | 844/6000 [27:13<2:42:43,  1.89s/it]                                                    {'loss': 0.0126, 'grad_norm': 3.1058664321899414, 'learning_rate': 8.738983050847458e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 844/6000 [27:13<2:42:43,  1.89s/it] 14%|â–ˆâ–        | 845/6000 [27:15<2:41:23,  1.88s/it]                                                    {'loss': 0.0434, 'grad_norm': 5.969369888305664, 'learning_rate': 8.737288135593221e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 845/6000 [27:15<2:41:23,  1.88s/it] 14%|â–ˆâ–        | 846/6000 [27:17<2:42:45,  1.89s/it]                                                    {'loss': 0.0582, 'grad_norm': 8.834416389465332, 'learning_rate': 8.735593220338985e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 846/6000 [27:17<2:42:45,  1.89s/it] 14%|â–ˆâ–        | 847/6000 [27:19<2:42:26,  1.89s/it]                                                    {'loss': 0.0856, 'grad_norm': 4.722596168518066, 'learning_rate': 8.733898305084748e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 847/6000 [27:19<2:42:26,  1.89s/it] 14%|â–ˆâ–        | 848/6000 [27:20<2:44:01,  1.91s/it]                                                    {'loss': 0.1109, 'grad_norm': 7.504942417144775, 'learning_rate': 8.73220338983051e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 848/6000 [27:20<2:44:01,  1.91s/it] 14%|â–ˆâ–        | 849/6000 [27:22<2:43:49,  1.91s/it]                                                    {'loss': 0.0357, 'grad_norm': 8.124288558959961, 'learning_rate': 8.730508474576271e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 849/6000 [27:22<2:43:49,  1.91s/it] 14%|â–ˆâ–        | 850/6000 [27:24<2:43:45,  1.91s/it]                                                    {'loss': 0.127, 'grad_norm': 11.27800178527832, 'learning_rate': 8.728813559322034e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 850/6000 [27:24<2:43:45,  1.91s/it][2025-11-11 22:20:40,192] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-850
[2025-11-11 22:20:40,199] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:20:40,485] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-850/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 14%|â–ˆâ–        | 851/6000 [27:27<3:03:04,  2.13s/it]                                                    {'loss': 0.0916, 'grad_norm': 9.889551162719727, 'learning_rate': 8.727118644067797e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 851/6000 [27:27<3:03:04,  2.13s/it] 14%|â–ˆâ–        | 852/6000 [27:29<2:56:31,  2.06s/it]                                                    {'loss': 0.1747, 'grad_norm': 8.732095718383789, 'learning_rate': 8.72542372881356e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 852/6000 [27:29<2:56:31,  2.06s/it] 14%|â–ˆâ–        | 853/6000 [27:31<2:51:20,  2.00s/it]                                                    {'loss': 0.0228, 'grad_norm': 3.8170125484466553, 'learning_rate': 8.723728813559322e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 853/6000 [27:31<2:51:20,  2.00s/it] 14%|â–ˆâ–        | 854/6000 [27:33<2:49:19,  1.97s/it]                                                    {'loss': 0.0773, 'grad_norm': 8.523496627807617, 'learning_rate': 8.722033898305086e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 854/6000 [27:33<2:49:19,  1.97s/it] 14%|â–ˆâ–        | 855/6000 [27:34<2:47:32,  1.95s/it]                                                    {'loss': 0.0072, 'grad_norm': 1.0805588960647583, 'learning_rate': 8.720338983050847e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 855/6000 [27:34<2:47:32,  1.95s/it] 14%|â–ˆâ–        | 856/6000 [27:36<2:46:48,  1.95s/it]                                                    {'loss': 0.2423, 'grad_norm': 18.153121948242188, 'learning_rate': 8.71864406779661e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 856/6000 [27:36<2:46:48,  1.95s/it] 14%|â–ˆâ–        | 857/6000 [27:38<2:44:53,  1.92s/it]                                                    {'loss': 0.0123, 'grad_norm': 2.4428153038024902, 'learning_rate': 8.716949152542374e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 857/6000 [27:38<2:44:53,  1.92s/it] 14%|â–ˆâ–        | 858/6000 [27:40<2:43:16,  1.91s/it]                                                    {'loss': 0.0389, 'grad_norm': 3.3363726139068604, 'learning_rate': 8.715254237288137e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 858/6000 [27:40<2:43:16,  1.91s/it] 14%|â–ˆâ–        | 859/6000 [27:42<2:41:45,  1.89s/it]                                                    {'loss': 0.0173, 'grad_norm': 1.5559170246124268, 'learning_rate': 8.713559322033899e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 859/6000 [27:42<2:41:45,  1.89s/it] 14%|â–ˆâ–        | 860/6000 [27:44<2:44:13,  1.92s/it]                                                    {'loss': 0.1035, 'grad_norm': 8.202038764953613, 'learning_rate': 8.711864406779662e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 860/6000 [27:44<2:44:13,  1.92s/it] 14%|â–ˆâ–        | 861/6000 [27:46<2:42:52,  1.90s/it]                                                    {'loss': 0.0051, 'grad_norm': 1.137713074684143, 'learning_rate': 8.710169491525423e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 861/6000 [27:46<2:42:52,  1.90s/it] 14%|â–ˆâ–        | 862/6000 [27:48<2:42:06,  1.89s/it]                                                    {'loss': 0.1829, 'grad_norm': 15.019108772277832, 'learning_rate': 8.708474576271187e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 862/6000 [27:48<2:42:06,  1.89s/it] 14%|â–ˆâ–        | 863/6000 [27:50<2:41:27,  1.89s/it]                                                    {'loss': 0.0433, 'grad_norm': 7.8863348960876465, 'learning_rate': 8.70677966101695e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 863/6000 [27:50<2:41:27,  1.89s/it] 14%|â–ˆâ–        | 864/6000 [27:51<2:41:24,  1.89s/it]                                                    {'loss': 0.0003, 'grad_norm': 0.04689394682645798, 'learning_rate': 8.705084745762713e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 864/6000 [27:51<2:41:24,  1.89s/it] 14%|â–ˆâ–        | 865/6000 [27:53<2:43:14,  1.91s/it]                                                    {'loss': 0.2725, 'grad_norm': 12.328068733215332, 'learning_rate': 8.703389830508475e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 865/6000 [27:53<2:43:14,  1.91s/it] 14%|â–ˆâ–        | 866/6000 [27:55<2:42:17,  1.90s/it]                                                    {'loss': 0.1253, 'grad_norm': 8.065742492675781, 'learning_rate': 8.701694915254238e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 866/6000 [27:55<2:42:17,  1.90s/it] 14%|â–ˆâ–        | 867/6000 [27:57<2:42:46,  1.90s/it]                                                    {'loss': 0.1883, 'grad_norm': 10.313885688781738, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 867/6000 [27:57<2:42:46,  1.90s/it] 14%|â–ˆâ–        | 868/6000 [27:59<2:40:52,  1.88s/it]                                                    {'loss': 0.2794, 'grad_norm': 15.566638946533203, 'learning_rate': 8.698305084745765e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 868/6000 [27:59<2:40:52,  1.88s/it] 14%|â–ˆâ–        | 869/6000 [28:01<2:40:31,  1.88s/it]                                                    {'loss': 0.0109, 'grad_norm': 2.0835494995117188, 'learning_rate': 8.696610169491526e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 869/6000 [28:01<2:40:31,  1.88s/it] 14%|â–ˆâ–        | 870/6000 [28:03<2:40:59,  1.88s/it]                                                    {'loss': 0.1565, 'grad_norm': 12.635635375976562, 'learning_rate': 8.694915254237288e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 870/6000 [28:03<2:40:59,  1.88s/it] 15%|â–ˆâ–        | 871/6000 [28:05<2:40:42,  1.88s/it]                                                    {'loss': 0.0395, 'grad_norm': 5.831827163696289, 'learning_rate': 8.693220338983051e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 871/6000 [28:05<2:40:42,  1.88s/it] 15%|â–ˆâ–        | 872/6000 [28:07<2:40:36,  1.88s/it]                                                    {'loss': 0.1345, 'grad_norm': 8.955157279968262, 'learning_rate': 8.691525423728814e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 872/6000 [28:07<2:40:36,  1.88s/it] 15%|â–ˆâ–        | 873/6000 [28:08<2:40:47,  1.88s/it]                                                    {'loss': 0.0331, 'grad_norm': 2.977482795715332, 'learning_rate': 8.689830508474578e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 873/6000 [28:08<2:40:47,  1.88s/it] 15%|â–ˆâ–        | 874/6000 [28:10<2:41:09,  1.89s/it]                                                    {'loss': 0.1679, 'grad_norm': 14.395947456359863, 'learning_rate': 8.68813559322034e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 874/6000 [28:10<2:41:09,  1.89s/it] 15%|â–ˆâ–        | 875/6000 [28:12<2:43:56,  1.92s/it]                                                    {'loss': 0.1084, 'grad_norm': 8.4774169921875, 'learning_rate': 8.686440677966103e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 875/6000 [28:12<2:43:56,  1.92s/it] 15%|â–ˆâ–        | 876/6000 [28:14<2:42:33,  1.90s/it]                                                    {'loss': 0.0298, 'grad_norm': 2.9432291984558105, 'learning_rate': 8.684745762711864e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 876/6000 [28:14<2:42:33,  1.90s/it] 15%|â–ˆâ–        | 877/6000 [28:16<2:42:13,  1.90s/it]                                                    {'loss': 0.2018, 'grad_norm': 16.05885124206543, 'learning_rate': 8.683050847457627e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 877/6000 [28:16<2:42:13,  1.90s/it] 15%|â–ˆâ–        | 878/6000 [28:18<2:41:55,  1.90s/it]                                                    {'loss': 0.1014, 'grad_norm': 10.623011589050293, 'learning_rate': 8.68135593220339e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 878/6000 [28:18<2:41:55,  1.90s/it] 15%|â–ˆâ–        | 879/6000 [28:20<2:46:14,  1.95s/it]                                                    {'loss': 0.1095, 'grad_norm': 8.133989334106445, 'learning_rate': 8.679661016949154e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 879/6000 [28:20<2:46:14,  1.95s/it] 15%|â–ˆâ–        | 880/6000 [28:22<2:43:44,  1.92s/it]                                                    {'loss': 0.4014, 'grad_norm': 15.446612358093262, 'learning_rate': 8.677966101694915e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 880/6000 [28:22<2:43:44,  1.92s/it] 15%|â–ˆâ–        | 881/6000 [28:24<2:43:08,  1.91s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.5489179491996765, 'learning_rate': 8.676271186440679e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 881/6000 [28:24<2:43:08,  1.91s/it] 15%|â–ˆâ–        | 882/6000 [28:26<2:43:27,  1.92s/it]                                                    {'loss': 0.0166, 'grad_norm': 6.019874095916748, 'learning_rate': 8.67457627118644e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 882/6000 [28:26<2:43:27,  1.92s/it] 15%|â–ˆâ–        | 883/6000 [28:28<2:46:15,  1.95s/it]                                                    {'loss': 0.0483, 'grad_norm': 5.691011905670166, 'learning_rate': 8.672881355932205e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 883/6000 [28:28<2:46:15,  1.95s/it] 15%|â–ˆâ–        | 884/6000 [28:30<2:46:03,  1.95s/it]                                                    {'loss': 0.2439, 'grad_norm': 15.490930557250977, 'learning_rate': 8.671186440677967e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 884/6000 [28:30<2:46:03,  1.95s/it] 15%|â–ˆâ–        | 885/6000 [28:32<2:44:30,  1.93s/it]                                                    {'loss': 0.0133, 'grad_norm': 1.372974157333374, 'learning_rate': 8.66949152542373e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 885/6000 [28:32<2:44:30,  1.93s/it] 15%|â–ˆâ–        | 886/6000 [28:34<2:44:24,  1.93s/it]                                                    {'loss': 0.066, 'grad_norm': 6.887638568878174, 'learning_rate': 8.667796610169492e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 886/6000 [28:34<2:44:24,  1.93s/it] 15%|â–ˆâ–        | 887/6000 [28:35<2:43:34,  1.92s/it]                                                    {'loss': 0.0027, 'grad_norm': 0.41505885124206543, 'learning_rate': 8.666101694915255e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 887/6000 [28:35<2:43:34,  1.92s/it] 15%|â–ˆâ–        | 888/6000 [28:37<2:43:01,  1.91s/it]                                                    {'loss': 0.0088, 'grad_norm': 1.286523461341858, 'learning_rate': 8.664406779661018e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 888/6000 [28:37<2:43:01,  1.91s/it] 15%|â–ˆâ–        | 889/6000 [28:39<2:41:59,  1.90s/it]                                                    {'loss': 0.0804, 'grad_norm': 7.498806953430176, 'learning_rate': 8.662711864406782e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 889/6000 [28:39<2:41:59,  1.90s/it] 15%|â–ˆâ–        | 890/6000 [28:41<2:41:17,  1.89s/it]                                                    {'loss': 0.0159, 'grad_norm': 1.5467033386230469, 'learning_rate': 8.661016949152543e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 890/6000 [28:41<2:41:17,  1.89s/it] 15%|â–ˆâ–        | 891/6000 [28:43<2:43:57,  1.93s/it]                                                    {'loss': 0.0206, 'grad_norm': 1.4153169393539429, 'learning_rate': 8.659322033898305e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 891/6000 [28:43<2:43:57,  1.93s/it] 15%|â–ˆâ–        | 892/6000 [28:45<2:42:11,  1.91s/it]                                                    {'loss': 0.0907, 'grad_norm': 6.135895252227783, 'learning_rate': 8.657627118644068e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 892/6000 [28:45<2:42:11,  1.91s/it] 15%|â–ˆâ–        | 893/6000 [28:47<2:40:47,  1.89s/it]                                                    {'loss': 0.205, 'grad_norm': 9.135744094848633, 'learning_rate': 8.655932203389831e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 893/6000 [28:47<2:40:47,  1.89s/it] 15%|â–ˆâ–        | 894/6000 [28:49<2:39:57,  1.88s/it]                                                    {'loss': 0.1278, 'grad_norm': 10.715289115905762, 'learning_rate': 8.654237288135595e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 894/6000 [28:49<2:39:57,  1.88s/it] 15%|â–ˆâ–        | 895/6000 [28:50<2:38:51,  1.87s/it]                                                    {'loss': 0.0336, 'grad_norm': 3.5311524868011475, 'learning_rate': 8.652542372881356e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 895/6000 [28:50<2:38:51,  1.87s/it] 15%|â–ˆâ–        | 896/6000 [28:52<2:38:13,  1.86s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.523223876953125, 'learning_rate': 8.65084745762712e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 896/6000 [28:52<2:38:13,  1.86s/it] 15%|â–ˆâ–        | 897/6000 [28:54<2:38:48,  1.87s/it]                                                    {'loss': 0.0287, 'grad_norm': 3.2044811248779297, 'learning_rate': 8.649152542372881e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 897/6000 [28:54<2:38:48,  1.87s/it] 15%|â–ˆâ–        | 898/6000 [28:56<2:38:09,  1.86s/it]                                                    {'loss': 0.0707, 'grad_norm': 3.020066022872925, 'learning_rate': 8.647457627118644e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 898/6000 [28:56<2:38:09,  1.86s/it] 15%|â–ˆâ–        | 899/6000 [28:58<2:47:30,  1.97s/it]                                                    {'loss': 0.003, 'grad_norm': 0.3285653293132782, 'learning_rate': 8.645762711864408e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 899/6000 [28:58<2:47:30,  1.97s/it] 15%|â–ˆâ–Œ        | 900/6000 [29:00<2:45:36,  1.95s/it]                                                    {'loss': 0.0515, 'grad_norm': 6.264090061187744, 'learning_rate': 8.64406779661017e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 900/6000 [29:00<2:45:36,  1.95s/it][2025-11-11 22:22:16,092] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900
[2025-11-11 22:22:16,099] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:22:16,387] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|â–ˆâ–Œ        | 901/6000 [29:03<3:05:37,  2.18s/it]                                                    {'loss': 0.0662, 'grad_norm': 6.759766101837158, 'learning_rate': 8.642372881355932e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 901/6000 [29:03<3:05:37,  2.18s/it] 15%|â–ˆâ–Œ        | 902/6000 [29:05<2:57:12,  2.09s/it]                                                    {'loss': 0.0204, 'grad_norm': 3.2987260818481445, 'learning_rate': 8.640677966101696e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 902/6000 [29:05<2:57:12,  2.09s/it] 15%|â–ˆâ–Œ        | 903/6000 [29:07<2:52:04,  2.03s/it]                                                    {'loss': 0.0847, 'grad_norm': 5.496716499328613, 'learning_rate': 8.638983050847459e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 903/6000 [29:07<2:52:04,  2.03s/it] 15%|â–ˆâ–Œ        | 904/6000 [29:09<2:47:38,  1.97s/it]                                                    {'loss': 0.2048, 'grad_norm': 9.86215877532959, 'learning_rate': 8.637288135593222e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 904/6000 [29:09<2:47:38,  1.97s/it] 15%|â–ˆâ–Œ        | 905/6000 [29:11<2:51:45,  2.02s/it]                                                    {'loss': 0.1073, 'grad_norm': 9.545589447021484, 'learning_rate': 8.635593220338984e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 905/6000 [29:11<2:51:45,  2.02s/it] 15%|â–ˆâ–Œ        | 906/6000 [29:13<2:49:38,  2.00s/it]                                                    {'loss': 0.0231, 'grad_norm': 1.6239993572235107, 'learning_rate': 8.633898305084747e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 906/6000 [29:13<2:49:38,  2.00s/it] 15%|â–ˆâ–Œ        | 907/6000 [29:15<2:49:05,  1.99s/it]                                                    {'loss': 0.1189, 'grad_norm': 4.278718948364258, 'learning_rate': 8.632203389830509e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 907/6000 [29:15<2:49:05,  1.99s/it] 15%|â–ˆâ–Œ        | 908/6000 [29:17<2:48:02,  1.98s/it]                                                    {'loss': 0.1945, 'grad_norm': 9.283036231994629, 'learning_rate': 8.630508474576272e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 908/6000 [29:17<2:48:02,  1.98s/it] 15%|â–ˆâ–Œ        | 909/6000 [29:18<2:44:54,  1.94s/it]                                                    {'loss': 0.1463, 'grad_norm': 11.883070945739746, 'learning_rate': 8.628813559322035e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 909/6000 [29:18<2:44:54,  1.94s/it] 15%|â–ˆâ–Œ        | 910/6000 [29:20<2:42:35,  1.92s/it]                                                    {'loss': 0.0629, 'grad_norm': 6.111797332763672, 'learning_rate': 8.627118644067798e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 910/6000 [29:20<2:42:35,  1.92s/it] 15%|â–ˆâ–Œ        | 911/6000 [29:22<2:42:17,  1.91s/it]                                                    {'loss': 0.0908, 'grad_norm': 9.404143333435059, 'learning_rate': 8.62542372881356e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 911/6000 [29:22<2:42:17,  1.91s/it] 15%|â–ˆâ–Œ        | 912/6000 [29:24<2:41:46,  1.91s/it]                                                    {'loss': 0.0175, 'grad_norm': 2.0516865253448486, 'learning_rate': 8.623728813559322e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 912/6000 [29:24<2:41:46,  1.91s/it] 15%|â–ˆâ–Œ        | 913/6000 [29:26<2:40:03,  1.89s/it]                                                    {'loss': 0.0583, 'grad_norm': 3.70804762840271, 'learning_rate': 8.622033898305085e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 913/6000 [29:26<2:40:03,  1.89s/it] 15%|â–ˆâ–Œ        | 914/6000 [29:28<2:44:20,  1.94s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.20015768706798553, 'learning_rate': 8.620338983050848e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 914/6000 [29:28<2:44:20,  1.94s/it] 15%|â–ˆâ–Œ        | 915/6000 [29:30<2:51:47,  2.03s/it]                                                    {'loss': 0.1411, 'grad_norm': 8.35509204864502, 'learning_rate': 8.618644067796611e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 915/6000 [29:30<2:51:47,  2.03s/it] 15%|â–ˆâ–Œ        | 916/6000 [29:32<2:47:26,  1.98s/it]                                                    {'loss': 0.054, 'grad_norm': 4.237730503082275, 'learning_rate': 8.616949152542373e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 916/6000 [29:32<2:47:26,  1.98s/it] 15%|â–ˆâ–Œ        | 917/6000 [29:34<2:44:24,  1.94s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.6422502994537354, 'learning_rate': 8.615254237288136e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 917/6000 [29:34<2:44:24,  1.94s/it] 15%|â–ˆâ–Œ        | 918/6000 [29:36<2:43:22,  1.93s/it]                                                    {'loss': 0.0122, 'grad_norm': 1.7841681241989136, 'learning_rate': 8.613559322033898e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 918/6000 [29:36<2:43:22,  1.93s/it] 15%|â–ˆâ–Œ        | 919/6000 [29:38<2:42:40,  1.92s/it]                                                    {'loss': 0.0684, 'grad_norm': 3.1812260150909424, 'learning_rate': 8.611864406779661e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 919/6000 [29:38<2:42:40,  1.92s/it] 15%|â–ˆâ–Œ        | 920/6000 [29:40<2:42:07,  1.91s/it]                                                    {'loss': 0.0259, 'grad_norm': 2.8376002311706543, 'learning_rate': 8.610169491525424e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 920/6000 [29:40<2:42:07,  1.91s/it] 15%|â–ˆâ–Œ        | 921/6000 [29:41<2:42:05,  1.91s/it]                                                    {'loss': 0.1573, 'grad_norm': 9.270336151123047, 'learning_rate': 8.608474576271188e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 921/6000 [29:41<2:42:05,  1.91s/it] 15%|â–ˆâ–Œ        | 922/6000 [29:43<2:40:46,  1.90s/it]                                                    {'loss': 0.0081, 'grad_norm': 1.1043200492858887, 'learning_rate': 8.60677966101695e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 922/6000 [29:43<2:40:46,  1.90s/it] 15%|â–ˆâ–Œ        | 923/6000 [29:45<2:41:20,  1.91s/it]                                                    {'loss': 0.0736, 'grad_norm': 6.207492828369141, 'learning_rate': 8.605084745762713e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 923/6000 [29:45<2:41:20,  1.91s/it] 15%|â–ˆâ–Œ        | 924/6000 [29:47<2:40:17,  1.89s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.0776290893554688, 'learning_rate': 8.603389830508476e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 924/6000 [29:47<2:40:17,  1.89s/it] 15%|â–ˆâ–Œ        | 925/6000 [29:49<2:39:21,  1.88s/it]                                                    {'loss': 0.0512, 'grad_norm': 3.020890712738037, 'learning_rate': 8.601694915254239e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 925/6000 [29:49<2:39:21,  1.88s/it] 15%|â–ˆâ–Œ        | 926/6000 [29:51<2:40:15,  1.89s/it]                                                    {'loss': 0.1236, 'grad_norm': 9.303394317626953, 'learning_rate': 8.6e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 926/6000 [29:51<2:40:15,  1.89s/it] 15%|â–ˆâ–Œ        | 927/6000 [29:53<2:39:31,  1.89s/it]                                                    {'loss': 0.272, 'grad_norm': 10.30710220336914, 'learning_rate': 8.598305084745764e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 927/6000 [29:53<2:39:31,  1.89s/it] 15%|â–ˆâ–Œ        | 928/6000 [29:55<2:38:58,  1.88s/it]                                                    {'loss': 0.0869, 'grad_norm': 6.597987174987793, 'learning_rate': 8.596610169491526e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 928/6000 [29:55<2:38:58,  1.88s/it] 15%|â–ˆâ–Œ        | 929/6000 [29:57<2:39:51,  1.89s/it]                                                    {'loss': 0.1414, 'grad_norm': 8.205209732055664, 'learning_rate': 8.594915254237289e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 929/6000 [29:57<2:39:51,  1.89s/it] 16%|â–ˆâ–Œ        | 930/6000 [29:58<2:39:26,  1.89s/it]                                                    {'loss': 0.2583, 'grad_norm': 8.406299591064453, 'learning_rate': 8.593220338983052e-06, 'epoch': 0.15}
 16%|â–ˆâ–Œ        | 930/6000 [29:58<2:39:26,  1.89s/it] 16%|â–ˆâ–Œ        | 931/6000 [30:00<2:39:58,  1.89s/it]                                                    {'loss': 0.0241, 'grad_norm': 3.2025623321533203, 'learning_rate': 8.591525423728814e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 931/6000 [30:00<2:39:58,  1.89s/it] 16%|â–ˆâ–Œ        | 932/6000 [30:02<2:39:38,  1.89s/it]                                                    {'loss': 0.0133, 'grad_norm': 2.770472764968872, 'learning_rate': 8.589830508474577e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 932/6000 [30:02<2:39:38,  1.89s/it] 16%|â–ˆâ–Œ        | 933/6000 [30:04<2:39:30,  1.89s/it]                                                    {'loss': 0.0663, 'grad_norm': 8.606029510498047, 'learning_rate': 8.588135593220339e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 933/6000 [30:04<2:39:30,  1.89s/it] 16%|â–ˆâ–Œ        | 934/6000 [30:06<2:41:28,  1.91s/it]                                                    {'loss': 0.0443, 'grad_norm': 3.501244306564331, 'learning_rate': 8.586440677966102e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 934/6000 [30:06<2:41:28,  1.91s/it] 16%|â–ˆâ–Œ        | 935/6000 [30:08<2:39:35,  1.89s/it]                                                    {'loss': 0.0223, 'grad_norm': 1.6839780807495117, 'learning_rate': 8.584745762711865e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 935/6000 [30:08<2:39:35,  1.89s/it] 16%|â–ˆâ–Œ        | 936/6000 [30:10<2:39:16,  1.89s/it]                                                    {'loss': 0.1366, 'grad_norm': 11.653482437133789, 'learning_rate': 8.583050847457628e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 936/6000 [30:10<2:39:16,  1.89s/it] 16%|â–ˆâ–Œ        | 937/6000 [30:12<2:40:48,  1.91s/it]                                                    {'loss': 0.0809, 'grad_norm': 7.209054470062256, 'learning_rate': 8.58135593220339e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 937/6000 [30:12<2:40:48,  1.91s/it] 16%|â–ˆâ–Œ        | 938/6000 [30:14<2:40:03,  1.90s/it]                                                    {'loss': 0.0085, 'grad_norm': 1.049639105796814, 'learning_rate': 8.579661016949153e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 938/6000 [30:14<2:40:03,  1.90s/it] 16%|â–ˆâ–Œ        | 939/6000 [30:16<2:40:59,  1.91s/it]                                                    {'loss': 0.0305, 'grad_norm': 5.7630181312561035, 'learning_rate': 8.577966101694916e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 939/6000 [30:16<2:40:59,  1.91s/it] 16%|â–ˆâ–Œ        | 940/6000 [30:17<2:41:15,  1.91s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.18618963658809662, 'learning_rate': 8.57627118644068e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 940/6000 [30:17<2:41:15,  1.91s/it] 16%|â–ˆâ–Œ        | 941/6000 [30:20<2:45:38,  1.96s/it]                                                    {'loss': 0.0658, 'grad_norm': 6.612568378448486, 'learning_rate': 8.574576271186441e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 941/6000 [30:20<2:45:38,  1.96s/it] 16%|â–ˆâ–Œ        | 942/6000 [30:21<2:42:51,  1.93s/it]                                                    {'loss': 0.1552, 'grad_norm': 13.340106010437012, 'learning_rate': 8.572881355932205e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 942/6000 [30:21<2:42:51,  1.93s/it] 16%|â–ˆâ–Œ        | 943/6000 [30:23<2:41:19,  1.91s/it]                                                    {'loss': 0.0109, 'grad_norm': 1.397533655166626, 'learning_rate': 8.571186440677966e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 943/6000 [30:23<2:41:19,  1.91s/it] 16%|â–ˆâ–Œ        | 944/6000 [30:25<2:40:22,  1.90s/it]                                                    {'loss': 0.1221, 'grad_norm': 10.887445449829102, 'learning_rate': 8.56949152542373e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 944/6000 [30:25<2:40:22,  1.90s/it] 16%|â–ˆâ–Œ        | 945/6000 [30:27<2:41:46,  1.92s/it]                                                    {'loss': 0.1705, 'grad_norm': 9.42741584777832, 'learning_rate': 8.567796610169493e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 945/6000 [30:27<2:41:46,  1.92s/it] 16%|â–ˆâ–Œ        | 946/6000 [30:29<2:41:33,  1.92s/it]                                                    {'loss': 0.0139, 'grad_norm': 2.6889736652374268, 'learning_rate': 8.566101694915256e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 946/6000 [30:29<2:41:33,  1.92s/it] 16%|â–ˆâ–Œ        | 947/6000 [30:31<2:41:39,  1.92s/it]                                                    {'loss': 0.1072, 'grad_norm': 6.11393404006958, 'learning_rate': 8.564406779661018e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 947/6000 [30:31<2:41:39,  1.92s/it] 16%|â–ˆâ–Œ        | 948/6000 [30:33<2:42:30,  1.93s/it]                                                    {'loss': 0.0892, 'grad_norm': 7.8415422439575195, 'learning_rate': 8.56271186440678e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 948/6000 [30:33<2:42:30,  1.93s/it] 16%|â–ˆâ–Œ        | 949/6000 [30:35<2:44:24,  1.95s/it]                                                    {'loss': 0.0738, 'grad_norm': 7.5185956954956055, 'learning_rate': 8.561016949152542e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 949/6000 [30:35<2:44:24,  1.95s/it] 16%|â–ˆâ–Œ        | 950/6000 [30:37<2:43:31,  1.94s/it]                                                    {'loss': 0.0693, 'grad_norm': 9.556852340698242, 'learning_rate': 8.559322033898306e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 950/6000 [30:37<2:43:31,  1.94s/it][2025-11-11 22:23:52,783] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-950
[2025-11-11 22:23:52,790] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:23:53,073] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-950/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 16%|â–ˆâ–Œ        | 951/6000 [30:40<3:01:11,  2.15s/it]                                                    {'loss': 0.1075, 'grad_norm': 5.524027347564697, 'learning_rate': 8.557627118644069e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 951/6000 [30:40<3:01:11,  2.15s/it] 16%|â–ˆâ–Œ        | 952/6000 [30:41<2:54:21,  2.07s/it]                                                    {'loss': 0.1883, 'grad_norm': 10.661358833312988, 'learning_rate': 8.55593220338983e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 952/6000 [30:41<2:54:21,  2.07s/it] 16%|â–ˆâ–Œ        | 953/6000 [30:43<2:51:01,  2.03s/it]                                                    {'loss': 0.0028, 'grad_norm': 0.2412448227405548, 'learning_rate': 8.554237288135594e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 953/6000 [30:43<2:51:01,  2.03s/it] 16%|â–ˆâ–Œ        | 954/6000 [30:45<2:46:53,  1.98s/it]                                                    {'loss': 0.0252, 'grad_norm': 3.2196896076202393, 'learning_rate': 8.552542372881355e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 954/6000 [30:45<2:46:53,  1.98s/it] 16%|â–ˆâ–Œ        | 955/6000 [30:47<2:44:44,  1.96s/it]                                                    {'loss': 0.1384, 'grad_norm': 11.246910095214844, 'learning_rate': 8.550847457627119e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 955/6000 [30:47<2:44:44,  1.96s/it] 16%|â–ˆâ–Œ        | 956/6000 [30:49<2:45:00,  1.96s/it]                                                    {'loss': 0.0813, 'grad_norm': 8.034307479858398, 'learning_rate': 8.549152542372882e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 956/6000 [30:49<2:45:00,  1.96s/it] 16%|â–ˆâ–Œ        | 957/6000 [30:51<2:42:54,  1.94s/it]                                                    {'loss': 0.0449, 'grad_norm': 3.8254404067993164, 'learning_rate': 8.547457627118645e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 957/6000 [30:51<2:42:54,  1.94s/it] 16%|â–ˆâ–Œ        | 958/6000 [30:53<2:42:53,  1.94s/it]                                                    {'loss': 0.124, 'grad_norm': 9.124600410461426, 'learning_rate': 8.545762711864407e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 958/6000 [30:53<2:42:53,  1.94s/it] 16%|â–ˆâ–Œ        | 959/6000 [30:55<2:40:30,  1.91s/it]                                                    {'loss': 0.0607, 'grad_norm': 5.688096523284912, 'learning_rate': 8.54406779661017e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 959/6000 [30:55<2:40:30,  1.91s/it] 16%|â–ˆâ–Œ        | 960/6000 [30:57<2:40:16,  1.91s/it]                                                    {'loss': 0.434, 'grad_norm': 13.753677368164062, 'learning_rate': 8.542372881355933e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 960/6000 [30:57<2:40:16,  1.91s/it] 16%|â–ˆâ–Œ        | 961/6000 [30:59<2:44:43,  1.96s/it]                                                    {'loss': 0.0439, 'grad_norm': 3.3965811729431152, 'learning_rate': 8.540677966101697e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 961/6000 [30:59<2:44:43,  1.96s/it] 16%|â–ˆâ–Œ        | 962/6000 [31:01<2:45:32,  1.97s/it]                                                    {'loss': 0.1651, 'grad_norm': 8.504183769226074, 'learning_rate': 8.538983050847458e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 962/6000 [31:01<2:45:32,  1.97s/it] 16%|â–ˆâ–Œ        | 963/6000 [31:03<2:43:17,  1.95s/it]                                                    {'loss': 0.109, 'grad_norm': 6.492303371429443, 'learning_rate': 8.537288135593221e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 963/6000 [31:03<2:43:17,  1.95s/it] 16%|â–ˆâ–Œ        | 964/6000 [31:04<2:40:58,  1.92s/it]                                                    {'loss': 0.121, 'grad_norm': 6.491610527038574, 'learning_rate': 8.535593220338983e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 964/6000 [31:04<2:40:58,  1.92s/it] 16%|â–ˆâ–Œ        | 965/6000 [31:06<2:40:32,  1.91s/it]                                                    {'loss': 0.0988, 'grad_norm': 6.3124237060546875, 'learning_rate': 8.533898305084746e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 965/6000 [31:06<2:40:32,  1.91s/it] 16%|â–ˆâ–Œ        | 966/6000 [31:08<2:45:40,  1.97s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.47559675574302673, 'learning_rate': 8.53220338983051e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 966/6000 [31:08<2:45:40,  1.97s/it] 16%|â–ˆâ–Œ        | 967/6000 [31:10<2:44:29,  1.96s/it]                                                    {'loss': 0.0125, 'grad_norm': 1.3195823431015015, 'learning_rate': 8.530508474576273e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 967/6000 [31:10<2:44:29,  1.96s/it] 16%|â–ˆâ–Œ        | 968/6000 [31:12<2:45:13,  1.97s/it]                                                    {'loss': 0.0381, 'grad_norm': 5.0861663818359375, 'learning_rate': 8.528813559322034e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 968/6000 [31:12<2:45:13,  1.97s/it] 16%|â–ˆâ–Œ        | 969/6000 [31:14<2:42:19,  1.94s/it]                                                    {'loss': 0.0171, 'grad_norm': 2.3536202907562256, 'learning_rate': 8.527118644067798e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 969/6000 [31:14<2:42:19,  1.94s/it] 16%|â–ˆâ–Œ        | 970/6000 [31:16<2:42:30,  1.94s/it]                                                    {'loss': 0.0484, 'grad_norm': 5.455329895019531, 'learning_rate': 8.52542372881356e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 970/6000 [31:16<2:42:30,  1.94s/it] 16%|â–ˆâ–Œ        | 971/6000 [31:18<2:39:37,  1.90s/it]                                                    {'loss': 0.1769, 'grad_norm': 8.4021635055542, 'learning_rate': 8.523728813559323e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 971/6000 [31:18<2:39:37,  1.90s/it] 16%|â–ˆâ–Œ        | 972/6000 [31:20<2:38:12,  1.89s/it]                                                    {'loss': 0.0842, 'grad_norm': 6.416773319244385, 'learning_rate': 8.522033898305086e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 972/6000 [31:20<2:38:12,  1.89s/it] 16%|â–ˆâ–Œ        | 973/6000 [31:22<2:37:25,  1.88s/it]                                                    {'loss': 0.2117, 'grad_norm': 11.835698127746582, 'learning_rate': 8.520338983050847e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 973/6000 [31:22<2:37:25,  1.88s/it] 16%|â–ˆâ–Œ        | 974/6000 [31:24<2:38:44,  1.89s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.42388662695884705, 'learning_rate': 8.51864406779661e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 974/6000 [31:24<2:38:44,  1.89s/it] 16%|â–ˆâ–‹        | 975/6000 [31:26<2:38:24,  1.89s/it]                                                    {'loss': 0.1197, 'grad_norm': 7.123849391937256, 'learning_rate': 8.516949152542372e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 975/6000 [31:26<2:38:24,  1.89s/it] 16%|â–ˆâ–‹        | 976/6000 [31:27<2:38:21,  1.89s/it]                                                    {'loss': 0.0021, 'grad_norm': 0.29190143942832947, 'learning_rate': 8.515254237288136e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 976/6000 [31:27<2:38:21,  1.89s/it] 16%|â–ˆâ–‹        | 977/6000 [31:29<2:37:07,  1.88s/it]                                                    {'loss': 0.219, 'grad_norm': 12.524981498718262, 'learning_rate': 8.513559322033899e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 977/6000 [31:29<2:37:07,  1.88s/it] 16%|â–ˆâ–‹        | 978/6000 [31:31<2:36:10,  1.87s/it]                                                    {'loss': 0.0966, 'grad_norm': 9.94301700592041, 'learning_rate': 8.511864406779662e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 978/6000 [31:31<2:36:10,  1.87s/it] 16%|â–ˆâ–‹        | 979/6000 [31:33<2:35:32,  1.86s/it]                                                    {'loss': 0.0569, 'grad_norm': 6.1418843269348145, 'learning_rate': 8.510169491525424e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 979/6000 [31:33<2:35:32,  1.86s/it] 16%|â–ˆâ–‹        | 980/6000 [31:35<2:37:21,  1.88s/it]                                                    {'loss': 0.1052, 'grad_norm': 7.465909004211426, 'learning_rate': 8.508474576271187e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 980/6000 [31:35<2:37:21,  1.88s/it] 16%|â–ˆâ–‹        | 981/6000 [31:37<2:37:42,  1.89s/it]                                                    {'loss': 0.0547, 'grad_norm': 2.9789280891418457, 'learning_rate': 8.50677966101695e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 981/6000 [31:37<2:37:42,  1.89s/it] 16%|â–ˆâ–‹        | 982/6000 [31:39<2:39:02,  1.90s/it]                                                    {'loss': 0.1563, 'grad_norm': 8.874040603637695, 'learning_rate': 8.505084745762714e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 982/6000 [31:39<2:39:02,  1.90s/it] 16%|â–ˆâ–‹        | 983/6000 [31:41<2:38:46,  1.90s/it]                                                    {'loss': 0.0282, 'grad_norm': 2.7512619495391846, 'learning_rate': 8.503389830508475e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 983/6000 [31:41<2:38:46,  1.90s/it] 16%|â–ˆâ–‹        | 984/6000 [31:42<2:37:38,  1.89s/it]                                                    {'loss': 0.0836, 'grad_norm': 4.944221496582031, 'learning_rate': 8.501694915254238e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 984/6000 [31:42<2:37:38,  1.89s/it] 16%|â–ˆâ–‹        | 985/6000 [31:44<2:38:54,  1.90s/it]                                                    {'loss': 0.0967, 'grad_norm': 9.117660522460938, 'learning_rate': 8.5e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 985/6000 [31:44<2:38:54,  1.90s/it] 16%|â–ˆâ–‹        | 986/6000 [31:46<2:36:58,  1.88s/it]                                                    {'loss': 0.1185, 'grad_norm': 4.501888751983643, 'learning_rate': 8.498305084745763e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 986/6000 [31:46<2:36:58,  1.88s/it] 16%|â–ˆâ–‹        | 987/6000 [31:48<2:37:50,  1.89s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.1805039793252945, 'learning_rate': 8.496610169491526e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 987/6000 [31:48<2:37:50,  1.89s/it] 16%|â–ˆâ–‹        | 988/6000 [31:50<2:37:34,  1.89s/it]                                                    {'loss': 0.0841, 'grad_norm': 7.408618450164795, 'learning_rate': 8.49491525423729e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 988/6000 [31:50<2:37:34,  1.89s/it] 16%|â–ˆâ–‹        | 989/6000 [31:52<2:37:13,  1.88s/it]                                                    {'loss': 0.114, 'grad_norm': 8.888171195983887, 'learning_rate': 8.493220338983051e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 989/6000 [31:52<2:37:13,  1.88s/it] 16%|â–ˆâ–‹        | 990/6000 [31:54<2:38:39,  1.90s/it]                                                    {'loss': 0.051, 'grad_norm': 6.244494915008545, 'learning_rate': 8.491525423728815e-06, 'epoch': 0.17}
 16%|â–ˆâ–‹        | 990/6000 [31:54<2:38:39,  1.90s/it] 17%|â–ˆâ–‹        | 991/6000 [31:56<2:41:11,  1.93s/it]                                                    {'loss': 0.0239, 'grad_norm': 2.728536367416382, 'learning_rate': 8.489830508474576e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 991/6000 [31:56<2:41:11,  1.93s/it] 17%|â–ˆâ–‹        | 992/6000 [31:58<2:40:22,  1.92s/it]                                                    {'loss': 0.0053, 'grad_norm': 1.0369133949279785, 'learning_rate': 8.48813559322034e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 992/6000 [31:58<2:40:22,  1.92s/it] 17%|â–ˆâ–‹        | 993/6000 [32:00<2:40:20,  1.92s/it]                                                    {'loss': 0.0289, 'grad_norm': 3.3804564476013184, 'learning_rate': 8.486440677966103e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 993/6000 [32:00<2:40:20,  1.92s/it] 17%|â–ˆâ–‹        | 994/6000 [32:02<2:40:51,  1.93s/it]                                                    {'loss': 0.0352, 'grad_norm': 2.560335397720337, 'learning_rate': 8.484745762711864e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 994/6000 [32:02<2:40:51,  1.93s/it] 17%|â–ˆâ–‹        | 995/6000 [32:03<2:39:00,  1.91s/it]                                                    {'loss': 0.164, 'grad_norm': 8.166254997253418, 'learning_rate': 8.483050847457628e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 995/6000 [32:03<2:39:00,  1.91s/it] 17%|â–ˆâ–‹        | 996/6000 [32:05<2:37:35,  1.89s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.5221568942070007, 'learning_rate': 8.481355932203391e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 996/6000 [32:05<2:37:35,  1.89s/it] 17%|â–ˆâ–‹        | 997/6000 [32:07<2:38:14,  1.90s/it]                                                    {'loss': 0.1578, 'grad_norm': 6.8642425537109375, 'learning_rate': 8.479661016949154e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 997/6000 [32:07<2:38:14,  1.90s/it] 17%|â–ˆâ–‹        | 998/6000 [32:09<2:37:01,  1.88s/it]                                                    {'loss': 0.1332, 'grad_norm': 10.618510246276855, 'learning_rate': 8.477966101694916e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 998/6000 [32:09<2:37:01,  1.88s/it] 17%|â–ˆâ–‹        | 999/6000 [32:11<2:36:32,  1.88s/it]                                                    {'loss': 0.0879, 'grad_norm': 7.89333438873291, 'learning_rate': 8.476271186440679e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 999/6000 [32:11<2:36:32,  1.88s/it] 17%|â–ˆâ–‹        | 1000/6000 [32:13<2:37:40,  1.89s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.1400499790906906, 'learning_rate': 8.47457627118644e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1000/6000 [32:13<2:37:40,  1.89s/it][2025-11-11 22:25:28,805] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000
[2025-11-11 22:25:28,811] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:25:29,093] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 17%|â–ˆâ–‹        | 1001/6000 [32:16<2:56:30,  2.12s/it]                                                     {'loss': 0.3655, 'grad_norm': 11.274413108825684, 'learning_rate': 8.472881355932204e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1001/6000 [32:16<2:56:30,  2.12s/it] 17%|â–ˆâ–‹        | 1002/6000 [32:17<2:51:13,  2.06s/it]                                                     {'loss': 0.0121, 'grad_norm': 2.2418301105499268, 'learning_rate': 8.471186440677967e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1002/6000 [32:17<2:51:13,  2.06s/it] 17%|â–ˆâ–‹        | 1003/6000 [32:19<2:44:56,  1.98s/it]                                                     {'loss': 0.2339, 'grad_norm': 11.09118366241455, 'learning_rate': 8.46949152542373e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1003/6000 [32:19<2:44:56,  1.98s/it] 17%|â–ˆâ–‹        | 1004/6000 [32:21<2:40:33,  1.93s/it]                                                     {'loss': 0.0367, 'grad_norm': 4.9360809326171875, 'learning_rate': 8.467796610169492e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1004/6000 [32:21<2:40:33,  1.93s/it] 17%|â–ˆâ–‹        | 1005/6000 [32:23<2:39:53,  1.92s/it]                                                     {'loss': 0.0429, 'grad_norm': 5.909400939941406, 'learning_rate': 8.466101694915255e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1005/6000 [32:23<2:39:53,  1.92s/it] 17%|â–ˆâ–‹        | 1006/6000 [32:25<2:37:09,  1.89s/it]                                                     {'loss': 0.0815, 'grad_norm': 8.742558479309082, 'learning_rate': 8.464406779661017e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1006/6000 [32:25<2:37:09,  1.89s/it] 17%|â–ˆâ–‹        | 1007/6000 [32:27<2:36:02,  1.88s/it]                                                     {'loss': 0.0392, 'grad_norm': 4.812780380249023, 'learning_rate': 8.46271186440678e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1007/6000 [32:27<2:36:02,  1.88s/it] 17%|â–ˆâ–‹        | 1008/6000 [32:28<2:36:17,  1.88s/it]                                                     {'loss': 0.0049, 'grad_norm': 0.8267285227775574, 'learning_rate': 8.461016949152543e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1008/6000 [32:29<2:36:17,  1.88s/it] 17%|â–ˆâ–‹        | 1009/6000 [32:30<2:35:55,  1.87s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.06222247704863548, 'learning_rate': 8.459322033898307e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1009/6000 [32:30<2:35:55,  1.87s/it] 17%|â–ˆâ–‹        | 1010/6000 [32:32<2:34:58,  1.86s/it]                                                     {'loss': 0.0858, 'grad_norm': 5.42970609664917, 'learning_rate': 8.457627118644068e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1010/6000 [32:32<2:34:58,  1.86s/it] 17%|â–ˆâ–‹        | 1011/6000 [32:34<2:36:08,  1.88s/it]                                                     {'loss': 0.0852, 'grad_norm': 4.890714645385742, 'learning_rate': 8.455932203389831e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1011/6000 [32:34<2:36:08,  1.88s/it] 17%|â–ˆâ–‹        | 1012/6000 [32:36<2:36:49,  1.89s/it]                                                     {'loss': 0.026, 'grad_norm': 3.888430595397949, 'learning_rate': 8.454237288135593e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1012/6000 [32:36<2:36:49,  1.89s/it] 17%|â–ˆâ–‹        | 1013/6000 [32:38<2:36:23,  1.88s/it]                                                     {'loss': 0.1032, 'grad_norm': 8.892343521118164, 'learning_rate': 8.452542372881356e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1013/6000 [32:38<2:36:23,  1.88s/it] 17%|â–ˆâ–‹        | 1014/6000 [32:40<2:35:19,  1.87s/it]                                                     {'loss': 0.2461, 'grad_norm': 12.140054702758789, 'learning_rate': 8.45084745762712e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1014/6000 [32:40<2:35:19,  1.87s/it] 17%|â–ˆâ–‹        | 1015/6000 [32:42<2:35:10,  1.87s/it]                                                     {'loss': 0.012, 'grad_norm': 2.69600248336792, 'learning_rate': 8.449152542372881e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1015/6000 [32:42<2:35:10,  1.87s/it] 17%|â–ˆâ–‹        | 1016/6000 [32:44<2:36:16,  1.88s/it]                                                     {'loss': 0.0891, 'grad_norm': 7.349796772003174, 'learning_rate': 8.447457627118644e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1016/6000 [32:44<2:36:16,  1.88s/it] 17%|â–ˆâ–‹        | 1017/6000 [32:45<2:36:32,  1.88s/it]                                                     {'loss': 0.1466, 'grad_norm': 8.12447738647461, 'learning_rate': 8.445762711864408e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1017/6000 [32:45<2:36:32,  1.88s/it] 17%|â–ˆâ–‹        | 1018/6000 [32:47<2:37:30,  1.90s/it]                                                     {'loss': 0.0329, 'grad_norm': 4.116011619567871, 'learning_rate': 8.444067796610171e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1018/6000 [32:47<2:37:30,  1.90s/it] 17%|â–ˆâ–‹        | 1019/6000 [32:49<2:36:58,  1.89s/it]                                                     {'loss': 0.0583, 'grad_norm': 5.002951145172119, 'learning_rate': 8.442372881355933e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1019/6000 [32:49<2:36:58,  1.89s/it] 17%|â–ˆâ–‹        | 1020/6000 [32:51<2:36:52,  1.89s/it]                                                     {'loss': 0.2377, 'grad_norm': 7.867788314819336, 'learning_rate': 8.440677966101696e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1020/6000 [32:51<2:36:52,  1.89s/it] 17%|â–ˆâ–‹        | 1021/6000 [32:53<2:36:25,  1.88s/it]                                                     {'loss': 0.0365, 'grad_norm': 2.0967228412628174, 'learning_rate': 8.438983050847457e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1021/6000 [32:53<2:36:25,  1.88s/it] 17%|â–ˆâ–‹        | 1022/6000 [32:55<2:38:38,  1.91s/it]                                                     {'loss': 0.0686, 'grad_norm': 9.027356147766113, 'learning_rate': 8.43728813559322e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1022/6000 [32:55<2:38:38,  1.91s/it] 17%|â–ˆâ–‹        | 1023/6000 [32:57<2:37:56,  1.90s/it]                                                     {'loss': 0.1702, 'grad_norm': 9.39840030670166, 'learning_rate': 8.435593220338984e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1023/6000 [32:57<2:37:56,  1.90s/it] 17%|â–ˆâ–‹        | 1024/6000 [32:59<2:36:51,  1.89s/it]                                                     {'loss': 0.0115, 'grad_norm': 2.3683669567108154, 'learning_rate': 8.433898305084747e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1024/6000 [32:59<2:36:51,  1.89s/it] 17%|â–ˆâ–‹        | 1025/6000 [33:01<2:36:32,  1.89s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.060296785086393356, 'learning_rate': 8.432203389830509e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1025/6000 [33:01<2:36:32,  1.89s/it] 17%|â–ˆâ–‹        | 1026/6000 [33:02<2:35:37,  1.88s/it]                                                     {'loss': 0.0589, 'grad_norm': 5.95614767074585, 'learning_rate': 8.430508474576272e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1026/6000 [33:02<2:35:37,  1.88s/it] 17%|â–ˆâ–‹        | 1027/6000 [33:04<2:36:04,  1.88s/it]                                                     {'loss': 0.0309, 'grad_norm': 3.7719621658325195, 'learning_rate': 8.428813559322034e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1027/6000 [33:04<2:36:04,  1.88s/it] 17%|â–ˆâ–‹        | 1028/6000 [33:06<2:35:13,  1.87s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.2591117322444916, 'learning_rate': 8.427118644067797e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1028/6000 [33:06<2:35:13,  1.87s/it] 17%|â–ˆâ–‹        | 1029/6000 [33:08<2:35:42,  1.88s/it]                                                     {'loss': 0.0058, 'grad_norm': 0.6823612451553345, 'learning_rate': 8.42542372881356e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1029/6000 [33:08<2:35:42,  1.88s/it] 17%|â–ˆâ–‹        | 1030/6000 [33:10<2:34:17,  1.86s/it]                                                     {'loss': 0.0498, 'grad_norm': 4.920538425445557, 'learning_rate': 8.423728813559324e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1030/6000 [33:10<2:34:17,  1.86s/it] 17%|â–ˆâ–‹        | 1031/6000 [33:12<2:34:50,  1.87s/it]                                                     {'loss': 0.123, 'grad_norm': 9.520930290222168, 'learning_rate': 8.422033898305085e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1031/6000 [33:12<2:34:50,  1.87s/it] 17%|â–ˆâ–‹        | 1032/6000 [33:14<2:34:30,  1.87s/it]                                                     {'loss': 0.0934, 'grad_norm': 10.546948432922363, 'learning_rate': 8.420338983050848e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1032/6000 [33:14<2:34:30,  1.87s/it] 17%|â–ˆâ–‹        | 1033/6000 [33:16<2:35:48,  1.88s/it]                                                     {'loss': 0.003, 'grad_norm': 0.31694111227989197, 'learning_rate': 8.41864406779661e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1033/6000 [33:16<2:35:48,  1.88s/it] 17%|â–ˆâ–‹        | 1034/6000 [33:17<2:34:33,  1.87s/it]                                                     {'loss': 0.0894, 'grad_norm': 3.7329068183898926, 'learning_rate': 8.416949152542375e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1034/6000 [33:17<2:34:33,  1.87s/it] 17%|â–ˆâ–‹        | 1035/6000 [33:19<2:39:03,  1.92s/it]                                                     {'loss': 0.0374, 'grad_norm': 3.961815595626831, 'learning_rate': 8.415254237288137e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1035/6000 [33:19<2:39:03,  1.92s/it] 17%|â–ˆâ–‹        | 1036/6000 [33:21<2:38:33,  1.92s/it]                                                     {'loss': 0.158, 'grad_norm': 8.216557502746582, 'learning_rate': 8.413559322033898e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1036/6000 [33:21<2:38:33,  1.92s/it] 17%|â–ˆâ–‹        | 1037/6000 [33:23<2:38:26,  1.92s/it]                                                     {'loss': 0.0819, 'grad_norm': 6.718271732330322, 'learning_rate': 8.411864406779661e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1037/6000 [33:23<2:38:26,  1.92s/it] 17%|â–ˆâ–‹        | 1038/6000 [33:25<2:40:36,  1.94s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.19829250872135162, 'learning_rate': 8.410169491525425e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1038/6000 [33:25<2:40:36,  1.94s/it] 17%|â–ˆâ–‹        | 1039/6000 [33:27<2:39:14,  1.93s/it]                                                     {'loss': 0.0244, 'grad_norm': 1.5664018392562866, 'learning_rate': 8.408474576271188e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1039/6000 [33:27<2:39:14,  1.93s/it] 17%|â–ˆâ–‹        | 1040/6000 [33:29<2:38:16,  1.91s/it]                                                     {'loss': 0.1097, 'grad_norm': 8.56519889831543, 'learning_rate': 8.40677966101695e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1040/6000 [33:29<2:38:16,  1.91s/it] 17%|â–ˆâ–‹        | 1041/6000 [33:31<2:36:52,  1.90s/it]                                                     {'loss': 0.1218, 'grad_norm': 9.408929824829102, 'learning_rate': 8.405084745762713e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1041/6000 [33:31<2:36:52,  1.90s/it] 17%|â–ˆâ–‹        | 1042/6000 [33:33<2:37:26,  1.91s/it]                                                     {'loss': 0.0076, 'grad_norm': 0.857668936252594, 'learning_rate': 8.403389830508474e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1042/6000 [33:33<2:37:26,  1.91s/it] 17%|â–ˆâ–‹        | 1043/6000 [33:35<2:35:34,  1.88s/it]                                                     {'loss': 0.13, 'grad_norm': 10.574769020080566, 'learning_rate': 8.401694915254238e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1043/6000 [33:35<2:35:34,  1.88s/it] 17%|â–ˆâ–‹        | 1044/6000 [33:37<2:36:17,  1.89s/it]                                                     {'loss': 0.0834, 'grad_norm': 7.827561855316162, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1044/6000 [33:37<2:36:17,  1.89s/it] 17%|â–ˆâ–‹        | 1045/6000 [33:38<2:36:55,  1.90s/it]                                                     {'loss': 0.1707, 'grad_norm': 10.674474716186523, 'learning_rate': 8.398305084745764e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1045/6000 [33:38<2:36:55,  1.90s/it] 17%|â–ˆâ–‹        | 1046/6000 [33:40<2:37:05,  1.90s/it]                                                     {'loss': 0.1252, 'grad_norm': 8.865195274353027, 'learning_rate': 8.396610169491526e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1046/6000 [33:40<2:37:05,  1.90s/it] 17%|â–ˆâ–‹        | 1047/6000 [33:43<2:43:00,  1.97s/it]                                                     {'loss': 0.339, 'grad_norm': 11.57794189453125, 'learning_rate': 8.394915254237289e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1047/6000 [33:43<2:43:00,  1.97s/it] 17%|â–ˆâ–‹        | 1048/6000 [33:44<2:40:49,  1.95s/it]                                                     {'loss': 0.0344, 'grad_norm': 6.050080299377441, 'learning_rate': 8.39322033898305e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1048/6000 [33:44<2:40:49,  1.95s/it] 17%|â–ˆâ–‹        | 1049/6000 [33:46<2:39:19,  1.93s/it]                                                     {'loss': 0.2337, 'grad_norm': 10.075176239013672, 'learning_rate': 8.391525423728814e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1049/6000 [33:46<2:39:19,  1.93s/it] 18%|â–ˆâ–Š        | 1050/6000 [33:48<2:45:17,  2.00s/it]                                                     {'loss': 0.0296, 'grad_norm': 4.478202819824219, 'learning_rate': 8.389830508474577e-06, 'epoch': 0.17}
 18%|â–ˆâ–Š        | 1050/6000 [33:48<2:45:17,  2.00s/it][2025-11-11 22:27:04,390] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1050
[2025-11-11 22:27:04,397] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:27:04,872] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1050/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1051/6000 [33:51<3:05:38,  2.25s/it]                                                     {'loss': 0.1589, 'grad_norm': 7.467913627624512, 'learning_rate': 8.38813559322034e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1051/6000 [33:51<3:05:38,  2.25s/it] 18%|â–ˆâ–Š        | 1052/6000 [33:53<2:57:02,  2.15s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.8997153043746948, 'learning_rate': 8.386440677966102e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1052/6000 [33:53<2:57:02,  2.15s/it] 18%|â–ˆâ–Š        | 1053/6000 [33:55<2:51:54,  2.08s/it]                                                     {'loss': 0.0347, 'grad_norm': 2.7642982006073, 'learning_rate': 8.384745762711865e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1053/6000 [33:55<2:51:54,  2.08s/it] 18%|â–ˆâ–Š        | 1054/6000 [33:57<2:47:54,  2.04s/it]                                                     {'loss': 0.0964, 'grad_norm': 10.209552764892578, 'learning_rate': 8.383050847457629e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1054/6000 [33:57<2:47:54,  2.04s/it] 18%|â–ˆâ–Š        | 1055/6000 [33:59<2:43:36,  1.99s/it]                                                     {'loss': 0.114, 'grad_norm': 9.1054105758667, 'learning_rate': 8.381355932203392e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1055/6000 [33:59<2:43:36,  1.99s/it] 18%|â–ˆâ–Š        | 1056/6000 [34:01<2:41:49,  1.96s/it]                                                     {'loss': 0.0233, 'grad_norm': 2.743328094482422, 'learning_rate': 8.379661016949153e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1056/6000 [34:01<2:41:49,  1.96s/it] 18%|â–ˆâ–Š        | 1057/6000 [34:03<2:39:36,  1.94s/it]                                                     {'loss': 0.0069, 'grad_norm': 0.9868406653404236, 'learning_rate': 8.377966101694915e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1057/6000 [34:03<2:39:36,  1.94s/it] 18%|â–ˆâ–Š        | 1058/6000 [34:05<2:37:45,  1.92s/it]                                                     {'loss': 0.0063, 'grad_norm': 1.0357409715652466, 'learning_rate': 8.376271186440678e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1058/6000 [34:05<2:37:45,  1.92s/it] 18%|â–ˆâ–Š        | 1059/6000 [34:06<2:37:29,  1.91s/it]                                                     {'loss': 0.0661, 'grad_norm': 6.514591693878174, 'learning_rate': 8.374576271186442e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1059/6000 [34:06<2:37:29,  1.91s/it] 18%|â–ˆâ–Š        | 1060/6000 [34:08<2:35:31,  1.89s/it]                                                     {'loss': 0.0163, 'grad_norm': 1.373566746711731, 'learning_rate': 8.372881355932205e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1060/6000 [34:08<2:35:31,  1.89s/it] 18%|â–ˆâ–Š        | 1061/6000 [34:10<2:36:54,  1.91s/it]                                                     {'loss': 0.0538, 'grad_norm': 5.933731555938721, 'learning_rate': 8.371186440677966e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1061/6000 [34:10<2:36:54,  1.91s/it] 18%|â–ˆâ–Š        | 1062/6000 [34:12<2:36:33,  1.90s/it]                                                     {'loss': 0.0119, 'grad_norm': 1.6175494194030762, 'learning_rate': 8.36949152542373e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1062/6000 [34:12<2:36:33,  1.90s/it] 18%|â–ˆâ–Š        | 1063/6000 [34:14<2:36:13,  1.90s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.124654620885849, 'learning_rate': 8.367796610169491e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1063/6000 [34:14<2:36:13,  1.90s/it] 18%|â–ˆâ–Š        | 1064/6000 [34:16<2:36:21,  1.90s/it]                                                     {'loss': 0.0471, 'grad_norm': 6.243730545043945, 'learning_rate': 8.366101694915255e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1064/6000 [34:16<2:36:21,  1.90s/it] 18%|â–ˆâ–Š        | 1065/6000 [34:18<2:35:12,  1.89s/it]                                                     {'loss': 0.0743, 'grad_norm': 5.344978332519531, 'learning_rate': 8.364406779661018e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1065/6000 [34:18<2:35:12,  1.89s/it] 18%|â–ˆâ–Š        | 1066/6000 [34:20<2:34:55,  1.88s/it]                                                     {'loss': 0.0994, 'grad_norm': 7.745555877685547, 'learning_rate': 8.362711864406781e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1066/6000 [34:20<2:34:55,  1.88s/it] 18%|â–ˆâ–Š        | 1067/6000 [34:22<2:35:20,  1.89s/it]                                                     {'loss': 0.0943, 'grad_norm': 5.908247947692871, 'learning_rate': 8.361016949152543e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1067/6000 [34:22<2:35:20,  1.89s/it] 18%|â–ˆâ–Š        | 1068/6000 [34:23<2:34:00,  1.87s/it]                                                     {'loss': 0.0061, 'grad_norm': 1.2720261812210083, 'learning_rate': 8.359322033898306e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1068/6000 [34:23<2:34:00,  1.87s/it] 18%|â–ˆâ–Š        | 1069/6000 [34:25<2:33:59,  1.87s/it]                                                     {'loss': 0.0157, 'grad_norm': 1.7992535829544067, 'learning_rate': 8.357627118644067e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1069/6000 [34:25<2:33:59,  1.87s/it] 18%|â–ˆâ–Š        | 1070/6000 [34:27<2:34:53,  1.89s/it]                                                     {'loss': 0.1651, 'grad_norm': 10.509033203125, 'learning_rate': 8.35593220338983e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1070/6000 [34:27<2:34:53,  1.89s/it] 18%|â–ˆâ–Š        | 1071/6000 [34:29<2:34:09,  1.88s/it]                                                     {'loss': 0.0055, 'grad_norm': 1.2976367473602295, 'learning_rate': 8.354237288135594e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1071/6000 [34:29<2:34:09,  1.88s/it] 18%|â–ˆâ–Š        | 1072/6000 [34:31<2:33:19,  1.87s/it]                                                     {'loss': 0.1111, 'grad_norm': 6.5376787185668945, 'learning_rate': 8.352542372881357e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1072/6000 [34:31<2:33:19,  1.87s/it] 18%|â–ˆâ–Š        | 1073/6000 [34:33<2:33:57,  1.87s/it]                                                     {'loss': 0.0225, 'grad_norm': 3.778704881668091, 'learning_rate': 8.350847457627119e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1073/6000 [34:33<2:33:57,  1.87s/it] 18%|â–ˆâ–Š        | 1074/6000 [34:35<2:34:06,  1.88s/it]                                                     {'loss': 0.0183, 'grad_norm': 2.0355474948883057, 'learning_rate': 8.349152542372882e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1074/6000 [34:35<2:34:06,  1.88s/it] 18%|â–ˆâ–Š        | 1075/6000 [34:37<2:34:24,  1.88s/it]                                                     {'loss': 0.1837, 'grad_norm': 8.13874340057373, 'learning_rate': 8.347457627118645e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1075/6000 [34:37<2:34:24,  1.88s/it] 18%|â–ˆâ–Š        | 1076/6000 [34:38<2:34:02,  1.88s/it]                                                     {'loss': 0.0354, 'grad_norm': 5.1456122398376465, 'learning_rate': 8.345762711864409e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1076/6000 [34:38<2:34:02,  1.88s/it] 18%|â–ˆâ–Š        | 1077/6000 [34:40<2:33:51,  1.88s/it]                                                     {'loss': 0.0035, 'grad_norm': 0.3909280598163605, 'learning_rate': 8.34406779661017e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1077/6000 [34:40<2:33:51,  1.88s/it] 18%|â–ˆâ–Š        | 1078/6000 [34:42<2:34:04,  1.88s/it]                                                     {'loss': 0.0474, 'grad_norm': 3.9471206665039062, 'learning_rate': 8.342372881355932e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1078/6000 [34:42<2:34:04,  1.88s/it] 18%|â–ˆâ–Š        | 1079/6000 [34:44<2:36:02,  1.90s/it]                                                     {'loss': 0.1576, 'grad_norm': 8.185250282287598, 'learning_rate': 8.340677966101695e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1079/6000 [34:44<2:36:02,  1.90s/it] 18%|â–ˆâ–Š        | 1080/6000 [34:46<2:34:55,  1.89s/it]                                                     {'loss': 0.0796, 'grad_norm': 6.2295403480529785, 'learning_rate': 8.338983050847458e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1080/6000 [34:46<2:34:55,  1.89s/it] 18%|â–ˆâ–Š        | 1081/6000 [34:48<2:33:35,  1.87s/it]                                                     {'loss': 0.0302, 'grad_norm': 3.142594814300537, 'learning_rate': 8.337288135593222e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1081/6000 [34:48<2:33:35,  1.87s/it] 18%|â–ˆâ–Š        | 1082/6000 [34:50<2:34:26,  1.88s/it]                                                     {'loss': 0.0339, 'grad_norm': 2.6629221439361572, 'learning_rate': 8.335593220338983e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1082/6000 [34:50<2:34:26,  1.88s/it] 18%|â–ˆâ–Š        | 1083/6000 [34:52<2:34:12,  1.88s/it]                                                     {'loss': 0.0178, 'grad_norm': 1.755009651184082, 'learning_rate': 8.333898305084747e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1083/6000 [34:52<2:34:12,  1.88s/it] 18%|â–ˆâ–Š        | 1084/6000 [34:54<2:35:31,  1.90s/it]                                                     {'loss': 0.1614, 'grad_norm': 7.691860198974609, 'learning_rate': 8.332203389830508e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1084/6000 [34:54<2:35:31,  1.90s/it] 18%|â–ˆâ–Š        | 1085/6000 [34:55<2:34:25,  1.89s/it]                                                     {'loss': 0.0202, 'grad_norm': 1.1058125495910645, 'learning_rate': 8.330508474576271e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1085/6000 [34:55<2:34:25,  1.89s/it] 18%|â–ˆâ–Š        | 1086/6000 [34:57<2:36:35,  1.91s/it]                                                     {'loss': 0.0857, 'grad_norm': 6.330394268035889, 'learning_rate': 8.328813559322035e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1086/6000 [34:57<2:36:35,  1.91s/it] 18%|â–ˆâ–Š        | 1087/6000 [34:59<2:36:09,  1.91s/it]                                                     {'loss': 0.0972, 'grad_norm': 10.676980972290039, 'learning_rate': 8.327118644067798e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1087/6000 [34:59<2:36:09,  1.91s/it] 18%|â–ˆâ–Š        | 1088/6000 [35:01<2:35:18,  1.90s/it]                                                     {'loss': 0.0927, 'grad_norm': 9.050359725952148, 'learning_rate': 8.32542372881356e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1088/6000 [35:01<2:35:18,  1.90s/it] 18%|â–ˆâ–Š        | 1089/6000 [35:03<2:45:00,  2.02s/it]                                                     {'loss': 0.2593, 'grad_norm': 12.375078201293945, 'learning_rate': 8.323728813559323e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1089/6000 [35:03<2:45:00,  2.02s/it] 18%|â–ˆâ–Š        | 1090/6000 [35:05<2:41:42,  1.98s/it]                                                     {'loss': 0.1389, 'grad_norm': 7.6651225090026855, 'learning_rate': 8.322033898305086e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1090/6000 [35:05<2:41:42,  1.98s/it] 18%|â–ˆâ–Š        | 1091/6000 [35:07<2:38:42,  1.94s/it]                                                     {'loss': 0.0065, 'grad_norm': 0.9135778546333313, 'learning_rate': 8.32033898305085e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1091/6000 [35:07<2:38:42,  1.94s/it] 18%|â–ˆâ–Š        | 1092/6000 [35:09<2:36:52,  1.92s/it]                                                     {'loss': 0.1991, 'grad_norm': 11.528483390808105, 'learning_rate': 8.318644067796611e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1092/6000 [35:09<2:36:52,  1.92s/it] 18%|â–ˆâ–Š        | 1093/6000 [35:11<2:35:33,  1.90s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.04691029340028763, 'learning_rate': 8.316949152542374e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1093/6000 [35:11<2:35:33,  1.90s/it] 18%|â–ˆâ–Š        | 1094/6000 [35:13<2:34:35,  1.89s/it]                                                     {'loss': 0.1108, 'grad_norm': 4.989190578460693, 'learning_rate': 8.315254237288136e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1094/6000 [35:13<2:34:35,  1.89s/it] 18%|â–ˆâ–Š        | 1095/6000 [35:15<2:34:01,  1.88s/it]                                                     {'loss': 0.0232, 'grad_norm': 2.7718210220336914, 'learning_rate': 8.313559322033899e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1095/6000 [35:15<2:34:01,  1.88s/it] 18%|â–ˆâ–Š        | 1096/6000 [35:17<2:35:23,  1.90s/it]                                                     {'loss': 0.0735, 'grad_norm': 5.8665547370910645, 'learning_rate': 8.311864406779662e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1096/6000 [35:17<2:35:23,  1.90s/it] 18%|â–ˆâ–Š        | 1097/6000 [35:19<2:34:55,  1.90s/it]                                                     {'loss': 0.0222, 'grad_norm': 1.9845012426376343, 'learning_rate': 8.310169491525426e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1097/6000 [35:19<2:34:55,  1.90s/it] 18%|â–ˆâ–Š        | 1098/6000 [35:21<2:39:31,  1.95s/it]                                                     {'loss': 0.1247, 'grad_norm': 9.318381309509277, 'learning_rate': 8.308474576271187e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1098/6000 [35:21<2:39:31,  1.95s/it] 18%|â–ˆâ–Š        | 1099/6000 [35:23<2:44:32,  2.01s/it]                                                     {'loss': 0.0881, 'grad_norm': 10.518976211547852, 'learning_rate': 8.306779661016949e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1099/6000 [35:23<2:44:32,  2.01s/it] 18%|â–ˆâ–Š        | 1100/6000 [35:25<2:40:45,  1.97s/it]                                                     {'loss': 0.1425, 'grad_norm': 9.413612365722656, 'learning_rate': 8.305084745762712e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1100/6000 [35:25<2:40:45,  1.97s/it][2025-11-11 22:28:40,527] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100
[2025-11-11 22:28:40,534] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:28:40,835] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1101/6000 [35:27<2:58:11,  2.18s/it]                                                     {'loss': 0.1313, 'grad_norm': 9.227152824401855, 'learning_rate': 8.303389830508475e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1101/6000 [35:27<2:58:11,  2.18s/it] 18%|â–ˆâ–Š        | 1102/6000 [35:29<2:50:13,  2.09s/it]                                                     {'loss': 0.0268, 'grad_norm': 4.754018783569336, 'learning_rate': 8.301694915254239e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1102/6000 [35:29<2:50:13,  2.09s/it] 18%|â–ˆâ–Š        | 1103/6000 [35:31<2:45:17,  2.03s/it]                                                     {'loss': 0.09, 'grad_norm': 6.104984283447266, 'learning_rate': 8.3e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1103/6000 [35:31<2:45:17,  2.03s/it] 18%|â–ˆâ–Š        | 1104/6000 [35:33<2:41:43,  1.98s/it]                                                     {'loss': 0.02, 'grad_norm': 3.9663476943969727, 'learning_rate': 8.298305084745763e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1104/6000 [35:33<2:41:43,  1.98s/it] 18%|â–ˆâ–Š        | 1105/6000 [35:35<2:38:54,  1.95s/it]                                                     {'loss': 0.0049, 'grad_norm': 0.6062338948249817, 'learning_rate': 8.296610169491525e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1105/6000 [35:35<2:38:54,  1.95s/it] 18%|â–ˆâ–Š        | 1106/6000 [35:37<2:37:47,  1.93s/it]                                                     {'loss': 0.0553, 'grad_norm': 4.620777130126953, 'learning_rate': 8.294915254237288e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1106/6000 [35:37<2:37:47,  1.93s/it] 18%|â–ˆâ–Š        | 1107/6000 [35:39<2:40:32,  1.97s/it]                                                     {'loss': 0.0101, 'grad_norm': 1.2240513563156128, 'learning_rate': 8.293220338983052e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1107/6000 [35:39<2:40:32,  1.97s/it] 18%|â–ˆâ–Š        | 1108/6000 [35:41<2:38:33,  1.94s/it]                                                     {'loss': 0.0239, 'grad_norm': 3.1080546379089355, 'learning_rate': 8.291525423728815e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1108/6000 [35:41<2:38:33,  1.94s/it] 18%|â–ˆâ–Š        | 1109/6000 [35:42<2:36:24,  1.92s/it]                                                     {'loss': 0.0571, 'grad_norm': 4.15327262878418, 'learning_rate': 8.289830508474576e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1109/6000 [35:42<2:36:24,  1.92s/it] 18%|â–ˆâ–Š        | 1110/6000 [35:44<2:35:03,  1.90s/it]                                                     {'loss': 0.1451, 'grad_norm': 6.730526924133301, 'learning_rate': 8.28813559322034e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1110/6000 [35:44<2:35:03,  1.90s/it] 19%|â–ˆâ–Š        | 1111/6000 [35:46<2:34:25,  1.90s/it]                                                     {'loss': 0.0965, 'grad_norm': 6.378761291503906, 'learning_rate': 8.286440677966103e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1111/6000 [35:46<2:34:25,  1.90s/it] 19%|â–ˆâ–Š        | 1112/6000 [35:48<2:33:40,  1.89s/it]                                                     {'loss': 0.004, 'grad_norm': 0.49668535590171814, 'learning_rate': 8.284745762711866e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1112/6000 [35:48<2:33:40,  1.89s/it] 19%|â–ˆâ–Š        | 1113/6000 [35:50<2:33:14,  1.88s/it]                                                     {'loss': 0.0571, 'grad_norm': 4.7308502197265625, 'learning_rate': 8.283050847457628e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1113/6000 [35:50<2:33:14,  1.88s/it] 19%|â–ˆâ–Š        | 1114/6000 [35:52<2:32:06,  1.87s/it]                                                     {'loss': 0.1529, 'grad_norm': 7.134611129760742, 'learning_rate': 8.281355932203391e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1114/6000 [35:52<2:32:06,  1.87s/it] 19%|â–ˆâ–Š        | 1115/6000 [35:54<2:31:50,  1.86s/it]                                                     {'loss': 0.1318, 'grad_norm': 6.182133674621582, 'learning_rate': 8.279661016949153e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1115/6000 [35:54<2:31:50,  1.86s/it] 19%|â–ˆâ–Š        | 1116/6000 [35:56<2:31:43,  1.86s/it]                                                     {'loss': 0.2378, 'grad_norm': 11.815276145935059, 'learning_rate': 8.277966101694916e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1116/6000 [35:56<2:31:43,  1.86s/it] 19%|â–ˆâ–Š        | 1117/6000 [35:57<2:33:00,  1.88s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.7572507858276367, 'learning_rate': 8.27627118644068e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1117/6000 [35:57<2:33:00,  1.88s/it] 19%|â–ˆâ–Š        | 1118/6000 [35:59<2:33:48,  1.89s/it]                                                     {'loss': 0.4852, 'grad_norm': 13.649240493774414, 'learning_rate': 8.27457627118644e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1118/6000 [35:59<2:33:48,  1.89s/it] 19%|â–ˆâ–Š        | 1119/6000 [36:01<2:34:30,  1.90s/it]                                                     {'loss': 0.0373, 'grad_norm': 5.372833728790283, 'learning_rate': 8.272881355932204e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1119/6000 [36:01<2:34:30,  1.90s/it] 19%|â–ˆâ–Š        | 1120/6000 [36:03<2:34:36,  1.90s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.5595555305480957, 'learning_rate': 8.271186440677966e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1120/6000 [36:03<2:34:36,  1.90s/it] 19%|â–ˆâ–Š        | 1121/6000 [36:05<2:34:12,  1.90s/it]                                                     {'loss': 0.06, 'grad_norm': 3.610991954803467, 'learning_rate': 8.269491525423729e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1121/6000 [36:05<2:34:12,  1.90s/it] 19%|â–ˆâ–Š        | 1122/6000 [36:07<2:34:12,  1.90s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.3700748383998871, 'learning_rate': 8.267796610169492e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1122/6000 [36:07<2:34:12,  1.90s/it] 19%|â–ˆâ–Š        | 1123/6000 [36:09<2:33:40,  1.89s/it]                                                     {'loss': 0.0076, 'grad_norm': 1.0228713750839233, 'learning_rate': 8.266101694915255e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1123/6000 [36:09<2:33:40,  1.89s/it] 19%|â–ˆâ–Š        | 1124/6000 [36:11<2:35:32,  1.91s/it]                                                     {'loss': 0.0959, 'grad_norm': 9.660025596618652, 'learning_rate': 8.264406779661017e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1124/6000 [36:11<2:35:32,  1.91s/it] 19%|â–ˆâ–‰        | 1125/6000 [36:13<2:35:04,  1.91s/it]                                                     {'loss': 0.1225, 'grad_norm': 7.756285667419434, 'learning_rate': 8.26271186440678e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1125/6000 [36:13<2:35:04,  1.91s/it] 19%|â–ˆâ–‰        | 1126/6000 [36:15<2:33:42,  1.89s/it]                                                     {'loss': 0.4717, 'grad_norm': 10.463595390319824, 'learning_rate': 8.261016949152542e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1126/6000 [36:15<2:33:42,  1.89s/it] 19%|â–ˆâ–‰        | 1127/6000 [36:16<2:33:45,  1.89s/it]                                                     {'loss': 0.1485, 'grad_norm': 11.45840072631836, 'learning_rate': 8.259322033898305e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1127/6000 [36:16<2:33:45,  1.89s/it] 19%|â–ˆâ–‰        | 1128/6000 [36:18<2:32:38,  1.88s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.0672188401222229, 'learning_rate': 8.257627118644068e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1128/6000 [36:18<2:32:38,  1.88s/it] 19%|â–ˆâ–‰        | 1129/6000 [36:20<2:35:56,  1.92s/it]                                                     {'loss': 0.0505, 'grad_norm': 3.377377510070801, 'learning_rate': 8.255932203389832e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1129/6000 [36:20<2:35:56,  1.92s/it] 19%|â–ˆâ–‰        | 1130/6000 [36:22<2:34:57,  1.91s/it]                                                     {'loss': 0.1097, 'grad_norm': 6.118441581726074, 'learning_rate': 8.254237288135593e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1130/6000 [36:22<2:34:57,  1.91s/it] 19%|â–ˆâ–‰        | 1131/6000 [36:24<2:32:40,  1.88s/it]                                                     {'loss': 0.1797, 'grad_norm': 11.058622360229492, 'learning_rate': 8.252542372881357e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1131/6000 [36:24<2:32:40,  1.88s/it] 19%|â–ˆâ–‰        | 1132/6000 [36:26<2:31:36,  1.87s/it]                                                     {'loss': 0.0575, 'grad_norm': 6.150632381439209, 'learning_rate': 8.25084745762712e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1132/6000 [36:26<2:31:36,  1.87s/it] 19%|â–ˆâ–‰        | 1133/6000 [36:28<2:35:28,  1.92s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.6265004873275757, 'learning_rate': 8.249152542372883e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1133/6000 [36:28<2:35:28,  1.92s/it] 19%|â–ˆâ–‰        | 1134/6000 [36:30<2:38:12,  1.95s/it]                                                     {'loss': 0.0238, 'grad_norm': 2.9652111530303955, 'learning_rate': 8.247457627118645e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1134/6000 [36:30<2:38:12,  1.95s/it] 19%|â–ˆâ–‰        | 1135/6000 [36:32<2:36:50,  1.93s/it]                                                     {'loss': 0.0714, 'grad_norm': 6.9453043937683105, 'learning_rate': 8.245762711864408e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1135/6000 [36:32<2:36:50,  1.93s/it] 19%|â–ˆâ–‰        | 1136/6000 [36:34<2:35:57,  1.92s/it]                                                     {'loss': 0.0292, 'grad_norm': 4.104408264160156, 'learning_rate': 8.24406779661017e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1136/6000 [36:34<2:35:57,  1.92s/it] 19%|â–ˆâ–‰        | 1137/6000 [36:36<2:35:50,  1.92s/it]                                                     {'loss': 0.0142, 'grad_norm': 2.109187364578247, 'learning_rate': 8.242372881355933e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1137/6000 [36:36<2:35:50,  1.92s/it] 19%|â–ˆâ–‰        | 1138/6000 [36:38<2:35:03,  1.91s/it]                                                     {'loss': 0.0606, 'grad_norm': 8.1166353225708, 'learning_rate': 8.240677966101696e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1138/6000 [36:38<2:35:03,  1.91s/it] 19%|â–ˆâ–‰        | 1139/6000 [36:39<2:35:22,  1.92s/it]                                                     {'loss': 0.0185, 'grad_norm': 2.5010294914245605, 'learning_rate': 8.238983050847458e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1139/6000 [36:39<2:35:22,  1.92s/it] 19%|â–ˆâ–‰        | 1140/6000 [36:41<2:36:19,  1.93s/it]                                                     {'loss': 0.1539, 'grad_norm': 12.066155433654785, 'learning_rate': 8.237288135593221e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1140/6000 [36:41<2:36:19,  1.93s/it] 19%|â–ˆâ–‰        | 1141/6000 [36:43<2:36:15,  1.93s/it]                                                     {'loss': 0.2165, 'grad_norm': 9.102311134338379, 'learning_rate': 8.235593220338983e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1141/6000 [36:43<2:36:15,  1.93s/it] 19%|â–ˆâ–‰        | 1142/6000 [36:45<2:36:56,  1.94s/it]                                                     {'loss': 0.0468, 'grad_norm': 6.829596996307373, 'learning_rate': 8.233898305084746e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1142/6000 [36:45<2:36:56,  1.94s/it] 19%|â–ˆâ–‰        | 1143/6000 [36:47<2:34:53,  1.91s/it]                                                     {'loss': 0.2429, 'grad_norm': 6.874999046325684, 'learning_rate': 8.232203389830509e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1143/6000 [36:47<2:34:53,  1.91s/it] 19%|â–ˆâ–‰        | 1144/6000 [36:49<2:34:07,  1.90s/it]                                                     {'loss': 0.0269, 'grad_norm': 1.571717381477356, 'learning_rate': 8.230508474576272e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1144/6000 [36:49<2:34:07,  1.90s/it] 19%|â–ˆâ–‰        | 1145/6000 [36:51<2:33:38,  1.90s/it]                                                     {'loss': 0.0791, 'grad_norm': 4.284994125366211, 'learning_rate': 8.228813559322034e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1145/6000 [36:51<2:33:38,  1.90s/it] 19%|â–ˆâ–‰        | 1146/6000 [36:53<2:33:31,  1.90s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.0271349735558033, 'learning_rate': 8.227118644067797e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1146/6000 [36:53<2:33:31,  1.90s/it] 19%|â–ˆâ–‰        | 1147/6000 [36:55<2:33:05,  1.89s/it]                                                     {'loss': 0.0928, 'grad_norm': 5.92990779876709, 'learning_rate': 8.22542372881356e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1147/6000 [36:55<2:33:05,  1.89s/it] 19%|â–ˆâ–‰        | 1148/6000 [36:57<2:33:19,  1.90s/it]                                                     {'loss': 0.1392, 'grad_norm': 11.295783996582031, 'learning_rate': 8.223728813559324e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1148/6000 [36:57<2:33:19,  1.90s/it] 19%|â–ˆâ–‰        | 1149/6000 [36:59<2:35:14,  1.92s/it]                                                     {'loss': 0.1585, 'grad_norm': 7.653684139251709, 'learning_rate': 8.222033898305085e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1149/6000 [36:59<2:35:14,  1.92s/it] 19%|â–ˆâ–‰        | 1150/6000 [37:00<2:34:37,  1.91s/it]                                                     {'loss': 0.0272, 'grad_norm': 2.9097273349761963, 'learning_rate': 8.220338983050849e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1150/6000 [37:00<2:34:37,  1.91s/it][2025-11-11 22:30:16,385] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1150
[2025-11-11 22:30:16,392] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:30:16,676] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1150/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 19%|â–ˆâ–‰        | 1151/6000 [37:03<2:52:59,  2.14s/it]                                                     {'loss': 0.1459, 'grad_norm': 10.419602394104004, 'learning_rate': 8.21864406779661e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1151/6000 [37:03<2:52:59,  2.14s/it] 19%|â–ˆâ–‰        | 1152/6000 [37:05<2:46:11,  2.06s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.23740719258785248, 'learning_rate': 8.216949152542373e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1152/6000 [37:05<2:46:11,  2.06s/it] 19%|â–ˆâ–‰        | 1153/6000 [37:07<2:42:27,  2.01s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.07981277257204056, 'learning_rate': 8.215254237288137e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1153/6000 [37:07<2:42:27,  2.01s/it] 19%|â–ˆâ–‰        | 1154/6000 [37:09<2:39:38,  1.98s/it]                                                     {'loss': 0.1117, 'grad_norm': 9.25552749633789, 'learning_rate': 8.2135593220339e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1154/6000 [37:09<2:39:38,  1.98s/it] 19%|â–ˆâ–‰        | 1155/6000 [37:11<2:36:59,  1.94s/it]                                                     {'loss': 0.0493, 'grad_norm': 5.483560562133789, 'learning_rate': 8.211864406779662e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1155/6000 [37:11<2:36:59,  1.94s/it] 19%|â–ˆâ–‰        | 1156/6000 [37:13<2:34:54,  1.92s/it]                                                     {'loss': 0.2325, 'grad_norm': 10.803906440734863, 'learning_rate': 8.210169491525425e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1156/6000 [37:13<2:34:54,  1.92s/it] 19%|â–ˆâ–‰        | 1157/6000 [37:14<2:34:14,  1.91s/it]                                                     {'loss': 0.1138, 'grad_norm': 9.089997291564941, 'learning_rate': 8.208474576271186e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1157/6000 [37:14<2:34:14,  1.91s/it] 19%|â–ˆâ–‰        | 1158/6000 [37:16<2:33:23,  1.90s/it]                                                     {'loss': 0.0058, 'grad_norm': 0.8596354722976685, 'learning_rate': 8.20677966101695e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1158/6000 [37:16<2:33:23,  1.90s/it] 19%|â–ˆâ–‰        | 1159/6000 [37:18<2:33:09,  1.90s/it]                                                     {'loss': 0.0301, 'grad_norm': 3.5246999263763428, 'learning_rate': 8.205084745762713e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1159/6000 [37:18<2:33:09,  1.90s/it] 19%|â–ˆâ–‰        | 1160/6000 [37:20<2:32:20,  1.89s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.060204390436410904, 'learning_rate': 8.203389830508475e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1160/6000 [37:20<2:32:20,  1.89s/it] 19%|â–ˆâ–‰        | 1161/6000 [37:22<2:31:24,  1.88s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.3435570001602173, 'learning_rate': 8.201694915254238e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1161/6000 [37:22<2:31:24,  1.88s/it] 19%|â–ˆâ–‰        | 1162/6000 [37:24<2:30:06,  1.86s/it]                                                     {'loss': 0.0151, 'grad_norm': 1.5388520956039429, 'learning_rate': 8.2e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1162/6000 [37:24<2:30:06,  1.86s/it] 19%|â–ˆâ–‰        | 1163/6000 [37:26<2:30:35,  1.87s/it]                                                     {'loss': 0.0155, 'grad_norm': 2.1518797874450684, 'learning_rate': 8.198305084745763e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1163/6000 [37:26<2:30:35,  1.87s/it] 19%|â–ˆâ–‰        | 1164/6000 [37:27<2:30:05,  1.86s/it]                                                     {'loss': 0.1513, 'grad_norm': 8.977210998535156, 'learning_rate': 8.196610169491526e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1164/6000 [37:27<2:30:05,  1.86s/it] 19%|â–ˆâ–‰        | 1165/6000 [37:29<2:31:43,  1.88s/it]                                                     {'loss': 0.1305, 'grad_norm': 8.739502906799316, 'learning_rate': 8.19491525423729e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1165/6000 [37:29<2:31:43,  1.88s/it] 19%|â–ˆâ–‰        | 1166/6000 [37:31<2:31:07,  1.88s/it]                                                     {'loss': 0.0499, 'grad_norm': 2.4048173427581787, 'learning_rate': 8.19322033898305e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1166/6000 [37:31<2:31:07,  1.88s/it] 19%|â–ˆâ–‰        | 1167/6000 [37:33<2:35:45,  1.93s/it]                                                     {'loss': 0.1899, 'grad_norm': 9.863640785217285, 'learning_rate': 8.191525423728814e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1167/6000 [37:33<2:35:45,  1.93s/it] 19%|â–ˆâ–‰        | 1168/6000 [37:35<2:33:37,  1.91s/it]                                                     {'loss': 0.0905, 'grad_norm': 9.086523056030273, 'learning_rate': 8.189830508474577e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1168/6000 [37:35<2:33:37,  1.91s/it] 19%|â–ˆâ–‰        | 1169/6000 [37:37<2:34:07,  1.91s/it]                                                     {'loss': 0.1525, 'grad_norm': 11.457594871520996, 'learning_rate': 8.18813559322034e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1169/6000 [37:37<2:34:07,  1.91s/it] 20%|â–ˆâ–‰        | 1170/6000 [37:39<2:33:39,  1.91s/it]                                                     {'loss': 0.029, 'grad_norm': 4.747619152069092, 'learning_rate': 8.186440677966102e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1170/6000 [37:39<2:33:39,  1.91s/it] 20%|â–ˆâ–‰        | 1171/6000 [37:41<2:33:41,  1.91s/it]                                                     {'loss': 0.03, 'grad_norm': 3.0638856887817383, 'learning_rate': 8.184745762711865e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1171/6000 [37:41<2:33:41,  1.91s/it] 20%|â–ˆâ–‰        | 1172/6000 [37:43<2:33:34,  1.91s/it]                                                     {'loss': 0.052, 'grad_norm': 9.653502464294434, 'learning_rate': 8.183050847457627e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1172/6000 [37:43<2:33:34,  1.91s/it] 20%|â–ˆâ–‰        | 1173/6000 [37:45<2:32:32,  1.90s/it]                                                     {'loss': 0.0568, 'grad_norm': 4.642902851104736, 'learning_rate': 8.18135593220339e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1173/6000 [37:45<2:32:32,  1.90s/it] 20%|â–ˆâ–‰        | 1174/6000 [37:47<2:36:45,  1.95s/it]                                                     {'loss': 0.1824, 'grad_norm': 9.06170654296875, 'learning_rate': 8.179661016949154e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1174/6000 [37:47<2:36:45,  1.95s/it] 20%|â–ˆâ–‰        | 1175/6000 [37:49<2:35:00,  1.93s/it]                                                     {'loss': 0.0066, 'grad_norm': 0.9926297664642334, 'learning_rate': 8.177966101694917e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1175/6000 [37:49<2:35:00,  1.93s/it] 20%|â–ˆâ–‰        | 1176/6000 [37:50<2:32:47,  1.90s/it]                                                     {'loss': 0.0336, 'grad_norm': 5.488523006439209, 'learning_rate': 8.176271186440678e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1176/6000 [37:50<2:32:47,  1.90s/it] 20%|â–ˆâ–‰        | 1177/6000 [37:52<2:32:07,  1.89s/it]                                                     {'loss': 0.0663, 'grad_norm': 3.579969644546509, 'learning_rate': 8.174576271186442e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1177/6000 [37:52<2:32:07,  1.89s/it] 20%|â–ˆâ–‰        | 1178/6000 [37:54<2:34:58,  1.93s/it]                                                     {'loss': 0.0605, 'grad_norm': 3.7031946182250977, 'learning_rate': 8.172881355932203e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1178/6000 [37:54<2:34:58,  1.93s/it] 20%|â–ˆâ–‰        | 1179/6000 [37:56<2:35:38,  1.94s/it]                                                     {'loss': 0.0889, 'grad_norm': 7.307832717895508, 'learning_rate': 8.171186440677967e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1179/6000 [37:56<2:35:38,  1.94s/it] 20%|â–ˆâ–‰        | 1180/6000 [37:58<2:37:25,  1.96s/it]                                                     {'loss': 0.0511, 'grad_norm': 2.102079153060913, 'learning_rate': 8.16949152542373e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1180/6000 [37:58<2:37:25,  1.96s/it] 20%|â–ˆâ–‰        | 1181/6000 [38:00<2:35:52,  1.94s/it]                                                     {'loss': 0.0452, 'grad_norm': 4.706406116485596, 'learning_rate': 8.167796610169491e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1181/6000 [38:00<2:35:52,  1.94s/it] 20%|â–ˆâ–‰        | 1182/6000 [38:02<2:43:41,  2.04s/it]                                                     {'loss': 0.0042, 'grad_norm': 1.097407579421997, 'learning_rate': 8.166101694915255e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1182/6000 [38:02<2:43:41,  2.04s/it] 20%|â–ˆâ–‰        | 1183/6000 [38:04<2:39:54,  1.99s/it]                                                     {'loss': 0.1071, 'grad_norm': 7.747265815734863, 'learning_rate': 8.164406779661016e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1183/6000 [38:04<2:39:54,  1.99s/it] 20%|â–ˆâ–‰        | 1184/6000 [38:06<2:37:04,  1.96s/it]                                                     {'loss': 0.1829, 'grad_norm': 7.137964725494385, 'learning_rate': 8.162711864406781e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1184/6000 [38:06<2:37:04,  1.96s/it] 20%|â–ˆâ–‰        | 1185/6000 [38:08<2:37:58,  1.97s/it]                                                     {'loss': 0.1185, 'grad_norm': 9.337535858154297, 'learning_rate': 8.161016949152543e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1185/6000 [38:08<2:37:58,  1.97s/it] 20%|â–ˆâ–‰        | 1186/6000 [38:10<2:35:28,  1.94s/it]                                                     {'loss': 0.1385, 'grad_norm': 4.041003227233887, 'learning_rate': 8.159322033898306e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1186/6000 [38:10<2:35:28,  1.94s/it] 20%|â–ˆâ–‰        | 1187/6000 [38:12<2:34:11,  1.92s/it]                                                     {'loss': 0.0193, 'grad_norm': 1.8513437509536743, 'learning_rate': 8.157627118644068e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1187/6000 [38:12<2:34:11,  1.92s/it] 20%|â–ˆâ–‰        | 1188/6000 [38:14<2:32:19,  1.90s/it]                                                     {'loss': 0.0368, 'grad_norm': 4.716688632965088, 'learning_rate': 8.155932203389831e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1188/6000 [38:14<2:32:19,  1.90s/it] 20%|â–ˆâ–‰        | 1189/6000 [38:16<2:31:34,  1.89s/it]                                                     {'loss': 0.0946, 'grad_norm': 7.941192150115967, 'learning_rate': 8.154237288135594e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1189/6000 [38:16<2:31:34,  1.89s/it] 20%|â–ˆâ–‰        | 1190/6000 [38:18<2:32:39,  1.90s/it]                                                     {'loss': 0.0086, 'grad_norm': 1.1477450132369995, 'learning_rate': 8.152542372881358e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1190/6000 [38:18<2:32:39,  1.90s/it] 20%|â–ˆâ–‰        | 1191/6000 [38:19<2:31:11,  1.89s/it]                                                     {'loss': 0.0114, 'grad_norm': 1.2579742670059204, 'learning_rate': 8.150847457627119e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1191/6000 [38:19<2:31:11,  1.89s/it] 20%|â–ˆâ–‰        | 1192/6000 [38:21<2:31:07,  1.89s/it]                                                     {'loss': 0.0141, 'grad_norm': 1.529239296913147, 'learning_rate': 8.149152542372882e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1192/6000 [38:21<2:31:07,  1.89s/it] 20%|â–ˆâ–‰        | 1193/6000 [38:23<2:30:27,  1.88s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.8647010922431946, 'learning_rate': 8.147457627118644e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1193/6000 [38:23<2:30:27,  1.88s/it] 20%|â–ˆâ–‰        | 1194/6000 [38:25<2:31:02,  1.89s/it]                                                     {'loss': 0.0755, 'grad_norm': 9.288827896118164, 'learning_rate': 8.145762711864407e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1194/6000 [38:25<2:31:02,  1.89s/it] 20%|â–ˆâ–‰        | 1195/6000 [38:27<2:31:02,  1.89s/it]                                                     {'loss': 0.0386, 'grad_norm': 6.397812366485596, 'learning_rate': 8.14406779661017e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1195/6000 [38:27<2:31:02,  1.89s/it] 20%|â–ˆâ–‰        | 1196/6000 [38:29<2:30:38,  1.88s/it]                                                     {'loss': 0.001, 'grad_norm': 0.08908989280462265, 'learning_rate': 8.142372881355934e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1196/6000 [38:29<2:30:38,  1.88s/it] 20%|â–ˆâ–‰        | 1197/6000 [38:31<2:31:42,  1.90s/it]                                                     {'loss': 0.0246, 'grad_norm': 2.2756576538085938, 'learning_rate': 8.140677966101695e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1197/6000 [38:31<2:31:42,  1.90s/it] 20%|â–ˆâ–‰        | 1198/6000 [38:33<2:30:38,  1.88s/it]                                                     {'loss': 0.0886, 'grad_norm': 8.709007263183594, 'learning_rate': 8.138983050847459e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1198/6000 [38:33<2:30:38,  1.88s/it] 20%|â–ˆâ–‰        | 1199/6000 [38:35<2:30:22,  1.88s/it]                                                     {'loss': 0.0437, 'grad_norm': 4.935596466064453, 'learning_rate': 8.13728813559322e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1199/6000 [38:35<2:30:22,  1.88s/it] 20%|â–ˆâ–ˆ        | 1200/6000 [38:36<2:29:18,  1.87s/it]                                                     {'loss': 0.2863, 'grad_norm': 10.757099151611328, 'learning_rate': 8.135593220338983e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1200/6000 [38:36<2:29:18,  1.87s/it][2025-11-11 22:31:52,300] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200
[2025-11-11 22:31:52,307] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:31:52,594] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 20%|â–ˆâ–ˆ        | 1201/6000 [38:39<2:48:28,  2.11s/it]                                                     {'loss': 0.1823, 'grad_norm': 7.596662998199463, 'learning_rate': 8.133898305084747e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1201/6000 [38:39<2:48:28,  2.11s/it] 20%|â–ˆâ–ˆ        | 1202/6000 [38:41<2:42:34,  2.03s/it]                                                     {'loss': 0.0791, 'grad_norm': 9.341646194458008, 'learning_rate': 8.132203389830508e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1202/6000 [38:41<2:42:34,  2.03s/it] 20%|â–ˆâ–ˆ        | 1203/6000 [38:43<2:39:00,  1.99s/it]                                                     {'loss': 0.0434, 'grad_norm': 5.177955627441406, 'learning_rate': 8.130508474576272e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1203/6000 [38:43<2:39:00,  1.99s/it] 20%|â–ˆâ–ˆ        | 1204/6000 [38:45<2:38:48,  1.99s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.5851483345031738, 'learning_rate': 8.128813559322035e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1204/6000 [38:45<2:38:48,  1.99s/it] 20%|â–ˆâ–ˆ        | 1205/6000 [38:47<2:38:00,  1.98s/it]                                                     {'loss': 0.1578, 'grad_norm': 7.385910987854004, 'learning_rate': 8.127118644067798e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1205/6000 [38:47<2:38:00,  1.98s/it] 20%|â–ˆâ–ˆ        | 1206/6000 [38:49<2:35:18,  1.94s/it]                                                     {'loss': 0.0585, 'grad_norm': 5.847715377807617, 'learning_rate': 8.12542372881356e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1206/6000 [38:49<2:35:18,  1.94s/it] 20%|â–ˆâ–ˆ        | 1207/6000 [38:50<2:33:46,  1.93s/it]                                                     {'loss': 0.1503, 'grad_norm': 8.318869590759277, 'learning_rate': 8.123728813559323e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1207/6000 [38:50<2:33:46,  1.93s/it] 20%|â–ˆâ–ˆ        | 1208/6000 [38:52<2:33:09,  1.92s/it]                                                     {'loss': 0.1465, 'grad_norm': 9.818740844726562, 'learning_rate': 8.122033898305085e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1208/6000 [38:52<2:33:09,  1.92s/it] 20%|â–ˆâ–ˆ        | 1209/6000 [38:54<2:31:21,  1.90s/it]                                                     {'loss': 0.0336, 'grad_norm': 4.4473652839660645, 'learning_rate': 8.120338983050848e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1209/6000 [38:54<2:31:21,  1.90s/it] 20%|â–ˆâ–ˆ        | 1210/6000 [38:56<2:31:29,  1.90s/it]                                                     {'loss': 0.3273, 'grad_norm': 10.994511604309082, 'learning_rate': 8.118644067796611e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1210/6000 [38:56<2:31:29,  1.90s/it] 20%|â–ˆâ–ˆ        | 1211/6000 [38:58<2:30:55,  1.89s/it]                                                     {'loss': 0.0778, 'grad_norm': 7.836894989013672, 'learning_rate': 8.116949152542374e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1211/6000 [38:58<2:30:55,  1.89s/it] 20%|â–ˆâ–ˆ        | 1212/6000 [39:00<2:34:42,  1.94s/it]                                                     {'loss': 0.1065, 'grad_norm': 7.411339282989502, 'learning_rate': 8.115254237288136e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1212/6000 [39:00<2:34:42,  1.94s/it] 20%|â–ˆâ–ˆ        | 1213/6000 [39:02<2:32:42,  1.91s/it]                                                     {'loss': 0.1294, 'grad_norm': 6.8356122970581055, 'learning_rate': 8.1135593220339e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1213/6000 [39:02<2:32:42,  1.91s/it] 20%|â–ˆâ–ˆ        | 1214/6000 [39:04<2:33:16,  1.92s/it]                                                     {'loss': 0.015, 'grad_norm': 0.9767583608627319, 'learning_rate': 8.111864406779661e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1214/6000 [39:04<2:33:16,  1.92s/it] 20%|â–ˆâ–ˆ        | 1215/6000 [39:06<2:32:35,  1.91s/it]                                                     {'loss': 0.0572, 'grad_norm': 6.850306034088135, 'learning_rate': 8.110169491525424e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1215/6000 [39:06<2:32:35,  1.91s/it] 20%|â–ˆâ–ˆ        | 1216/6000 [39:08<2:31:10,  1.90s/it]                                                     {'loss': 0.0527, 'grad_norm': 4.10826301574707, 'learning_rate': 8.108474576271187e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1216/6000 [39:08<2:31:10,  1.90s/it] 20%|â–ˆâ–ˆ        | 1217/6000 [39:10<2:33:33,  1.93s/it]                                                     {'loss': 0.1542, 'grad_norm': 7.272923946380615, 'learning_rate': 8.10677966101695e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1217/6000 [39:10<2:33:33,  1.93s/it] 20%|â–ˆâ–ˆ        | 1218/6000 [39:11<2:32:23,  1.91s/it]                                                     {'loss': 0.0047, 'grad_norm': 0.5118841528892517, 'learning_rate': 8.105084745762712e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1218/6000 [39:11<2:32:23,  1.91s/it] 20%|â–ˆâ–ˆ        | 1219/6000 [39:13<2:32:15,  1.91s/it]                                                     {'loss': 0.0305, 'grad_norm': 3.360071897506714, 'learning_rate': 8.103389830508476e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1219/6000 [39:13<2:32:15,  1.91s/it] 20%|â–ˆâ–ˆ        | 1220/6000 [39:15<2:31:58,  1.91s/it]                                                     {'loss': 0.0553, 'grad_norm': 4.5856404304504395, 'learning_rate': 8.101694915254237e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1220/6000 [39:15<2:31:58,  1.91s/it] 20%|â–ˆâ–ˆ        | 1221/6000 [39:17<2:32:18,  1.91s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.3309735357761383, 'learning_rate': 8.1e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1221/6000 [39:17<2:32:18,  1.91s/it] 20%|â–ˆâ–ˆ        | 1222/6000 [39:19<2:31:40,  1.90s/it]                                                     {'loss': 0.113, 'grad_norm': 6.592051982879639, 'learning_rate': 8.098305084745764e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1222/6000 [39:19<2:31:40,  1.90s/it] 20%|â–ˆâ–ˆ        | 1223/6000 [39:21<2:29:57,  1.88s/it]                                                     {'loss': 0.0329, 'grad_norm': 4.5761542320251465, 'learning_rate': 8.096610169491525e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1223/6000 [39:21<2:29:57,  1.88s/it] 20%|â–ˆâ–ˆ        | 1224/6000 [39:23<2:29:27,  1.88s/it]                                                     {'loss': 0.0133, 'grad_norm': 1.7776439189910889, 'learning_rate': 8.094915254237289e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1224/6000 [39:23<2:29:27,  1.88s/it] 20%|â–ˆâ–ˆ        | 1225/6000 [39:25<2:31:04,  1.90s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.07791327685117722, 'learning_rate': 8.093220338983052e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1225/6000 [39:25<2:31:04,  1.90s/it] 20%|â–ˆâ–ˆ        | 1226/6000 [39:27<2:31:56,  1.91s/it]                                                     {'loss': 0.2277, 'grad_norm': 8.562129020690918, 'learning_rate': 8.091525423728815e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1226/6000 [39:27<2:31:56,  1.91s/it] 20%|â–ˆâ–ˆ        | 1227/6000 [39:29<2:34:05,  1.94s/it]                                                     {'loss': 0.0149, 'grad_norm': 2.2367281913757324, 'learning_rate': 8.089830508474577e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1227/6000 [39:29<2:34:05,  1.94s/it] 20%|â–ˆâ–ˆ        | 1228/6000 [39:31<2:33:00,  1.92s/it]                                                     {'loss': 0.0701, 'grad_norm': 3.8948798179626465, 'learning_rate': 8.08813559322034e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1228/6000 [39:31<2:33:00,  1.92s/it] 20%|â–ˆâ–ˆ        | 1229/6000 [39:32<2:31:19,  1.90s/it]                                                     {'loss': 0.0125, 'grad_norm': 2.2585909366607666, 'learning_rate': 8.086440677966101e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1229/6000 [39:32<2:31:19,  1.90s/it] 20%|â–ˆâ–ˆ        | 1230/6000 [39:34<2:30:00,  1.89s/it]                                                     {'loss': 0.0806, 'grad_norm': 6.12435245513916, 'learning_rate': 8.084745762711865e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1230/6000 [39:34<2:30:00,  1.89s/it] 21%|â–ˆâ–ˆ        | 1231/6000 [39:36<2:30:14,  1.89s/it]                                                     {'loss': 0.2007, 'grad_norm': 11.114310264587402, 'learning_rate': 8.083050847457628e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1231/6000 [39:36<2:30:14,  1.89s/it] 21%|â–ˆâ–ˆ        | 1232/6000 [39:38<2:30:52,  1.90s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.2699596881866455, 'learning_rate': 8.081355932203391e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1232/6000 [39:38<2:30:52,  1.90s/it] 21%|â–ˆâ–ˆ        | 1233/6000 [39:40<2:32:15,  1.92s/it]                                                     {'loss': 0.0466, 'grad_norm': 5.8352484703063965, 'learning_rate': 8.079661016949153e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1233/6000 [39:40<2:32:15,  1.92s/it] 21%|â–ˆâ–ˆ        | 1234/6000 [39:42<2:35:05,  1.95s/it]                                                     {'loss': 0.1734, 'grad_norm': 9.355985641479492, 'learning_rate': 8.077966101694916e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1234/6000 [39:42<2:35:05,  1.95s/it] 21%|â–ˆâ–ˆ        | 1235/6000 [39:44<2:33:31,  1.93s/it]                                                     {'loss': 0.0192, 'grad_norm': 3.8896596431732178, 'learning_rate': 8.076271186440678e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1235/6000 [39:44<2:33:31,  1.93s/it] 21%|â–ˆâ–ˆ        | 1236/6000 [39:46<2:32:29,  1.92s/it]                                                     {'loss': 0.1155, 'grad_norm': 9.883049011230469, 'learning_rate': 8.074576271186441e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1236/6000 [39:46<2:32:29,  1.92s/it] 21%|â–ˆâ–ˆ        | 1237/6000 [39:48<2:30:55,  1.90s/it]                                                     {'loss': 0.0428, 'grad_norm': 4.426822185516357, 'learning_rate': 8.072881355932204e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1237/6000 [39:48<2:30:55,  1.90s/it] 21%|â–ˆâ–ˆ        | 1238/6000 [39:50<2:30:29,  1.90s/it]                                                     {'loss': 0.0128, 'grad_norm': 1.7728644609451294, 'learning_rate': 8.071186440677968e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1238/6000 [39:50<2:30:29,  1.90s/it] 21%|â–ˆâ–ˆ        | 1239/6000 [39:51<2:29:01,  1.88s/it]                                                     {'loss': 0.0234, 'grad_norm': 1.8730747699737549, 'learning_rate': 8.069491525423729e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1239/6000 [39:51<2:29:01,  1.88s/it] 21%|â–ˆâ–ˆ        | 1240/6000 [39:53<2:29:43,  1.89s/it]                                                     {'loss': 0.042, 'grad_norm': 2.5371198654174805, 'learning_rate': 8.067796610169492e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1240/6000 [39:53<2:29:43,  1.89s/it] 21%|â–ˆâ–ˆ        | 1241/6000 [39:55<2:29:04,  1.88s/it]                                                     {'loss': 0.0116, 'grad_norm': 2.4408998489379883, 'learning_rate': 8.066101694915256e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1241/6000 [39:55<2:29:04,  1.88s/it] 21%|â–ˆâ–ˆ        | 1242/6000 [39:57<2:30:17,  1.90s/it]                                                     {'loss': 0.3137, 'grad_norm': 12.207493782043457, 'learning_rate': 8.064406779661019e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1242/6000 [39:57<2:30:17,  1.90s/it] 21%|â–ˆâ–ˆ        | 1243/6000 [39:59<2:30:19,  1.90s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.9778029322624207, 'learning_rate': 8.06271186440678e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1243/6000 [39:59<2:30:19,  1.90s/it] 21%|â–ˆâ–ˆ        | 1244/6000 [40:01<2:29:32,  1.89s/it]                                                     {'loss': 0.0725, 'grad_norm': 6.492187976837158, 'learning_rate': 8.061016949152542e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1244/6000 [40:01<2:29:32,  1.89s/it] 21%|â–ˆâ–ˆ        | 1245/6000 [40:03<2:28:49,  1.88s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.814654529094696, 'learning_rate': 8.059322033898305e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1245/6000 [40:03<2:28:49,  1.88s/it] 21%|â–ˆâ–ˆ        | 1246/6000 [40:05<2:28:53,  1.88s/it]                                                     {'loss': 0.0272, 'grad_norm': 5.008150100708008, 'learning_rate': 8.057627118644069e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1246/6000 [40:05<2:28:53,  1.88s/it] 21%|â–ˆâ–ˆ        | 1247/6000 [40:07<2:29:46,  1.89s/it]                                                     {'loss': 0.053, 'grad_norm': 2.532928228378296, 'learning_rate': 8.055932203389832e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1247/6000 [40:07<2:29:46,  1.89s/it] 21%|â–ˆâ–ˆ        | 1248/6000 [40:08<2:29:52,  1.89s/it]                                                     {'loss': 0.002, 'grad_norm': 0.19607755541801453, 'learning_rate': 8.054237288135594e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1248/6000 [40:08<2:29:52,  1.89s/it] 21%|â–ˆâ–ˆ        | 1249/6000 [40:10<2:29:28,  1.89s/it]                                                     {'loss': 0.1454, 'grad_norm': 7.399168968200684, 'learning_rate': 8.052542372881357e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1249/6000 [40:10<2:29:28,  1.89s/it] 21%|â–ˆâ–ˆ        | 1250/6000 [40:12<2:27:49,  1.87s/it]                                                     {'loss': 0.0739, 'grad_norm': 7.4087958335876465, 'learning_rate': 8.050847457627118e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1250/6000 [40:12<2:27:49,  1.87s/it][2025-11-11 22:33:28,068] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1250
[2025-11-11 22:33:28,075] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:33:28,362] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1250/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 21%|â–ˆâ–ˆ        | 1251/6000 [40:15<2:47:08,  2.11s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.3776743412017822, 'learning_rate': 8.049152542372882e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1251/6000 [40:15<2:47:08,  2.11s/it] 21%|â–ˆâ–ˆ        | 1252/6000 [40:17<2:41:09,  2.04s/it]                                                     {'loss': 0.1899, 'grad_norm': 9.798176765441895, 'learning_rate': 8.047457627118645e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1252/6000 [40:17<2:41:09,  2.04s/it] 21%|â–ˆâ–ˆ        | 1253/6000 [40:19<2:40:45,  2.03s/it]                                                     {'loss': 0.2072, 'grad_norm': 9.566774368286133, 'learning_rate': 8.045762711864408e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1253/6000 [40:19<2:40:45,  2.03s/it] 21%|â–ˆâ–ˆ        | 1254/6000 [40:21<2:36:27,  1.98s/it]                                                     {'loss': 0.0267, 'grad_norm': 2.649733066558838, 'learning_rate': 8.04406779661017e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1254/6000 [40:21<2:36:27,  1.98s/it] 21%|â–ˆâ–ˆ        | 1255/6000 [40:22<2:34:21,  1.95s/it]                                                     {'loss': 0.075, 'grad_norm': 8.17798900604248, 'learning_rate': 8.042372881355933e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1255/6000 [40:22<2:34:21,  1.95s/it] 21%|â–ˆâ–ˆ        | 1256/6000 [40:24<2:33:21,  1.94s/it]                                                     {'loss': 0.0211, 'grad_norm': 2.4155516624450684, 'learning_rate': 8.040677966101695e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1256/6000 [40:24<2:33:21,  1.94s/it] 21%|â–ˆâ–ˆ        | 1257/6000 [40:26<2:31:44,  1.92s/it]                                                     {'loss': 0.0087, 'grad_norm': 1.8944950103759766, 'learning_rate': 8.038983050847458e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1257/6000 [40:26<2:31:44,  1.92s/it] 21%|â–ˆâ–ˆ        | 1258/6000 [40:28<2:31:54,  1.92s/it]                                                     {'loss': 0.041, 'grad_norm': 1.5518121719360352, 'learning_rate': 8.037288135593221e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1258/6000 [40:28<2:31:54,  1.92s/it] 21%|â–ˆâ–ˆ        | 1259/6000 [40:30<2:34:59,  1.96s/it]                                                     {'loss': 0.4227, 'grad_norm': 10.973153114318848, 'learning_rate': 8.035593220338984e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1259/6000 [40:30<2:34:59,  1.96s/it] 21%|â–ˆâ–ˆ        | 1260/6000 [40:32<2:33:06,  1.94s/it]                                                     {'loss': 0.0624, 'grad_norm': 5.052258014678955, 'learning_rate': 8.033898305084746e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1260/6000 [40:32<2:33:06,  1.94s/it] 21%|â–ˆâ–ˆ        | 1261/6000 [40:34<2:32:28,  1.93s/it]                                                     {'loss': 0.054, 'grad_norm': 6.442466735839844, 'learning_rate': 8.03220338983051e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1261/6000 [40:34<2:32:28,  1.93s/it] 21%|â–ˆâ–ˆ        | 1262/6000 [40:36<2:34:33,  1.96s/it]                                                     {'loss': 0.1052, 'grad_norm': 8.198107719421387, 'learning_rate': 8.030508474576273e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1262/6000 [40:36<2:34:33,  1.96s/it] 21%|â–ˆâ–ˆ        | 1263/6000 [40:38<2:33:53,  1.95s/it]                                                     {'loss': 0.0145, 'grad_norm': 1.7102700471878052, 'learning_rate': 8.028813559322036e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1263/6000 [40:38<2:33:53,  1.95s/it] 21%|â–ˆâ–ˆ        | 1264/6000 [40:40<2:32:26,  1.93s/it]                                                     {'loss': 0.0681, 'grad_norm': 7.738765239715576, 'learning_rate': 8.027118644067797e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1264/6000 [40:40<2:32:26,  1.93s/it] 21%|â–ˆâ–ˆ        | 1265/6000 [40:42<2:32:30,  1.93s/it]                                                     {'loss': 0.0755, 'grad_norm': 5.5207695960998535, 'learning_rate': 8.025423728813559e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1265/6000 [40:42<2:32:30,  1.93s/it] 21%|â–ˆâ–ˆ        | 1266/6000 [40:44<2:31:42,  1.92s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.6400758624076843, 'learning_rate': 8.023728813559322e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1266/6000 [40:44<2:31:42,  1.92s/it] 21%|â–ˆâ–ˆ        | 1267/6000 [40:46<2:34:18,  1.96s/it]                                                     {'loss': 0.1557, 'grad_norm': 10.13512134552002, 'learning_rate': 8.022033898305086e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1267/6000 [40:46<2:34:18,  1.96s/it] 21%|â–ˆâ–ˆ        | 1268/6000 [40:48<2:32:07,  1.93s/it]                                                     {'loss': 0.0403, 'grad_norm': 5.200417995452881, 'learning_rate': 8.020338983050849e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1268/6000 [40:48<2:32:07,  1.93s/it] 21%|â–ˆâ–ˆ        | 1269/6000 [40:50<2:31:38,  1.92s/it]                                                     {'loss': 0.0764, 'grad_norm': 9.01119327545166, 'learning_rate': 8.01864406779661e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1269/6000 [40:50<2:31:38,  1.92s/it] 21%|â–ˆâ–ˆ        | 1270/6000 [40:51<2:31:36,  1.92s/it]                                                     {'loss': 0.0049, 'grad_norm': 0.536883533000946, 'learning_rate': 8.016949152542374e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1270/6000 [40:51<2:31:36,  1.92s/it] 21%|â–ˆâ–ˆ        | 1271/6000 [40:53<2:31:39,  1.92s/it]                                                     {'loss': 0.1237, 'grad_norm': 9.769481658935547, 'learning_rate': 8.015254237288135e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1271/6000 [40:53<2:31:39,  1.92s/it] 21%|â–ˆâ–ˆ        | 1272/6000 [40:55<2:33:00,  1.94s/it]                                                     {'loss': 0.0646, 'grad_norm': 4.717374324798584, 'learning_rate': 8.013559322033899e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1272/6000 [40:55<2:33:00,  1.94s/it] 21%|â–ˆâ–ˆ        | 1273/6000 [40:57<2:31:32,  1.92s/it]                                                     {'loss': 0.0216, 'grad_norm': 1.2539583444595337, 'learning_rate': 8.011864406779662e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1273/6000 [40:57<2:31:32,  1.92s/it] 21%|â–ˆâ–ˆ        | 1274/6000 [40:59<2:29:57,  1.90s/it]                                                     {'loss': 0.0291, 'grad_norm': 4.183343410491943, 'learning_rate': 8.010169491525425e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1274/6000 [40:59<2:29:57,  1.90s/it] 21%|â–ˆâ–ˆâ–       | 1275/6000 [41:01<2:30:21,  1.91s/it]                                                     {'loss': 0.201, 'grad_norm': 9.9849853515625, 'learning_rate': 8.008474576271187e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1275/6000 [41:01<2:30:21,  1.91s/it] 21%|â–ˆâ–ˆâ–       | 1276/6000 [41:03<2:30:17,  1.91s/it]                                                     {'loss': 0.3855, 'grad_norm': 13.782170295715332, 'learning_rate': 8.00677966101695e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1276/6000 [41:03<2:30:17,  1.91s/it] 21%|â–ˆâ–ˆâ–       | 1277/6000 [41:05<2:30:21,  1.91s/it]                                                     {'loss': 0.3607, 'grad_norm': 16.53249740600586, 'learning_rate': 8.005084745762712e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1277/6000 [41:05<2:30:21,  1.91s/it] 21%|â–ˆâ–ˆâ–       | 1278/6000 [41:07<2:30:16,  1.91s/it]                                                     {'loss': 0.0873, 'grad_norm': 5.051853656768799, 'learning_rate': 8.003389830508475e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1278/6000 [41:07<2:30:16,  1.91s/it] 21%|â–ˆâ–ˆâ–       | 1279/6000 [41:09<2:29:12,  1.90s/it]                                                     {'loss': 0.2566, 'grad_norm': 9.792016983032227, 'learning_rate': 8.001694915254238e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1279/6000 [41:09<2:29:12,  1.90s/it] 21%|â–ˆâ–ˆâ–       | 1280/6000 [41:10<2:29:13,  1.90s/it]                                                     {'loss': 0.0556, 'grad_norm': 8.737325668334961, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1280/6000 [41:10<2:29:13,  1.90s/it] 21%|â–ˆâ–ˆâ–       | 1281/6000 [41:12<2:28:40,  1.89s/it]                                                     {'loss': 0.0303, 'grad_norm': 3.311500310897827, 'learning_rate': 7.998305084745763e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1281/6000 [41:12<2:28:40,  1.89s/it] 21%|â–ˆâ–ˆâ–       | 1282/6000 [41:14<2:28:12,  1.88s/it]                                                     {'loss': 0.0244, 'grad_norm': 1.6745253801345825, 'learning_rate': 7.996610169491526e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1282/6000 [41:14<2:28:12,  1.88s/it] 21%|â–ˆâ–ˆâ–       | 1283/6000 [41:16<2:26:57,  1.87s/it]                                                     {'loss': 0.0574, 'grad_norm': 4.3628129959106445, 'learning_rate': 7.99491525423729e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1283/6000 [41:16<2:26:57,  1.87s/it] 21%|â–ˆâ–ˆâ–       | 1284/6000 [41:18<2:27:50,  1.88s/it]                                                     {'loss': 0.0211, 'grad_norm': 2.79645037651062, 'learning_rate': 7.993220338983053e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1284/6000 [41:18<2:27:50,  1.88s/it] 21%|â–ˆâ–ˆâ–       | 1285/6000 [41:20<2:27:44,  1.88s/it]                                                     {'loss': 0.0752, 'grad_norm': 3.531956195831299, 'learning_rate': 7.991525423728814e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1285/6000 [41:20<2:27:44,  1.88s/it] 21%|â–ˆâ–ˆâ–       | 1286/6000 [41:22<2:28:56,  1.90s/it]                                                     {'loss': 0.064, 'grad_norm': 5.006547927856445, 'learning_rate': 7.989830508474576e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1286/6000 [41:22<2:28:56,  1.90s/it] 21%|â–ˆâ–ˆâ–       | 1287/6000 [41:24<2:29:31,  1.90s/it]                                                     {'loss': 0.0123, 'grad_norm': 1.7612483501434326, 'learning_rate': 7.98813559322034e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1287/6000 [41:24<2:29:31,  1.90s/it] 21%|â–ˆâ–ˆâ–       | 1288/6000 [41:26<2:28:49,  1.90s/it]                                                     {'loss': 0.0741, 'grad_norm': 6.601555824279785, 'learning_rate': 7.986440677966102e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1288/6000 [41:26<2:28:49,  1.90s/it] 21%|â–ˆâ–ˆâ–       | 1289/6000 [41:27<2:28:03,  1.89s/it]                                                     {'loss': 0.0117, 'grad_norm': 1.4069608449935913, 'learning_rate': 7.984745762711866e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1289/6000 [41:27<2:28:03,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1290/6000 [41:29<2:28:26,  1.89s/it]                                                     {'loss': 0.0031, 'grad_norm': 0.5009135007858276, 'learning_rate': 7.983050847457627e-06, 'epoch': 0.21}
 22%|â–ˆâ–ˆâ–       | 1290/6000 [41:29<2:28:26,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1291/6000 [41:31<2:28:09,  1.89s/it]                                                     {'loss': 0.0606, 'grad_norm': 5.490057945251465, 'learning_rate': 7.98135593220339e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1291/6000 [41:31<2:28:09,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1292/6000 [41:33<2:27:28,  1.88s/it]                                                     {'loss': 0.0431, 'grad_norm': 5.3828020095825195, 'learning_rate': 7.979661016949152e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1292/6000 [41:33<2:27:28,  1.88s/it] 22%|â–ˆâ–ˆâ–       | 1293/6000 [41:35<2:27:37,  1.88s/it]                                                     {'loss': 0.0054, 'grad_norm': 0.46694350242614746, 'learning_rate': 7.977966101694915e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1293/6000 [41:35<2:27:37,  1.88s/it] 22%|â–ˆâ–ˆâ–       | 1294/6000 [41:37<2:30:00,  1.91s/it]                                                     {'loss': 0.1012, 'grad_norm': 6.684520721435547, 'learning_rate': 7.976271186440679e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1294/6000 [41:37<2:30:00,  1.91s/it] 22%|â–ˆâ–ˆâ–       | 1295/6000 [41:39<2:27:59,  1.89s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.7426574230194092, 'learning_rate': 7.974576271186442e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1295/6000 [41:39<2:27:59,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1296/6000 [41:41<2:28:12,  1.89s/it]                                                     {'loss': 0.0078, 'grad_norm': 0.610264241695404, 'learning_rate': 7.972881355932204e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1296/6000 [41:41<2:28:12,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1297/6000 [41:43<2:28:47,  1.90s/it]                                                     {'loss': 0.0132, 'grad_norm': 1.173915982246399, 'learning_rate': 7.971186440677967e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1297/6000 [41:43<2:28:47,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1298/6000 [41:44<2:28:33,  1.90s/it]                                                     {'loss': 0.1565, 'grad_norm': 10.926127433776855, 'learning_rate': 7.96949152542373e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1298/6000 [41:44<2:28:33,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1299/6000 [41:46<2:28:54,  1.90s/it]                                                     {'loss': 0.0169, 'grad_norm': 1.9441598653793335, 'learning_rate': 7.967796610169493e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1299/6000 [41:46<2:28:54,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1300/6000 [41:48<2:28:22,  1.89s/it]                                                     {'loss': 0.122, 'grad_norm': 6.968554973602295, 'learning_rate': 7.966101694915255e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1300/6000 [41:48<2:28:22,  1.89s/it][2025-11-11 22:35:04,207] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300
[2025-11-11 22:35:04,214] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:35:04,513] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|â–ˆâ–ˆâ–       | 1301/6000 [41:51<2:46:32,  2.13s/it]                                                     {'loss': 0.014, 'grad_norm': 1.2517300844192505, 'learning_rate': 7.964406779661018e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1301/6000 [41:51<2:46:32,  2.13s/it] 22%|â–ˆâ–ˆâ–       | 1302/6000 [41:53<2:40:41,  2.05s/it]                                                     {'loss': 0.0482, 'grad_norm': 4.373978614807129, 'learning_rate': 7.96271186440678e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1302/6000 [41:53<2:40:41,  2.05s/it] 22%|â–ˆâ–ˆâ–       | 1303/6000 [41:55<2:37:48,  2.02s/it]                                                     {'loss': 0.0608, 'grad_norm': 7.098552227020264, 'learning_rate': 7.961016949152543e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1303/6000 [41:55<2:37:48,  2.02s/it] 22%|â–ˆâ–ˆâ–       | 1304/6000 [41:57<2:35:08,  1.98s/it]                                                     {'loss': 0.1574, 'grad_norm': 10.069063186645508, 'learning_rate': 7.959322033898306e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1304/6000 [41:57<2:35:08,  1.98s/it] 22%|â–ˆâ–ˆâ–       | 1305/6000 [41:59<2:32:31,  1.95s/it]                                                     {'loss': 0.0958, 'grad_norm': 8.507062911987305, 'learning_rate': 7.957627118644068e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1305/6000 [41:59<2:32:31,  1.95s/it] 22%|â–ˆâ–ˆâ–       | 1306/6000 [42:00<2:32:22,  1.95s/it]                                                     {'loss': 0.0391, 'grad_norm': 3.776303291320801, 'learning_rate': 7.955932203389831e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1306/6000 [42:00<2:32:22,  1.95s/it] 22%|â–ˆâ–ˆâ–       | 1307/6000 [42:02<2:30:29,  1.92s/it]                                                     {'loss': 0.0176, 'grad_norm': 3.6330459117889404, 'learning_rate': 7.954237288135593e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1307/6000 [42:02<2:30:29,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1308/6000 [42:04<2:30:04,  1.92s/it]                                                     {'loss': 0.0207, 'grad_norm': 3.8172309398651123, 'learning_rate': 7.952542372881356e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1308/6000 [42:04<2:30:04,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1309/6000 [42:06<2:30:24,  1.92s/it]                                                     {'loss': 0.0048, 'grad_norm': 0.7696753144264221, 'learning_rate': 7.95084745762712e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1309/6000 [42:06<2:30:24,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1310/6000 [42:08<2:29:51,  1.92s/it]                                                     {'loss': 0.0788, 'grad_norm': 4.604064464569092, 'learning_rate': 7.949152542372883e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1310/6000 [42:08<2:29:51,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1311/6000 [42:10<2:27:36,  1.89s/it]                                                     {'loss': 0.0198, 'grad_norm': 2.332350254058838, 'learning_rate': 7.947457627118644e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1311/6000 [42:10<2:27:36,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1312/6000 [42:12<2:27:39,  1.89s/it]                                                     {'loss': 0.4672, 'grad_norm': 13.606358528137207, 'learning_rate': 7.945762711864407e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1312/6000 [42:12<2:27:39,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1313/6000 [42:14<2:27:28,  1.89s/it]                                                     {'loss': 0.0927, 'grad_norm': 6.055354595184326, 'learning_rate': 7.944067796610169e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1313/6000 [42:14<2:27:28,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1314/6000 [42:16<2:27:16,  1.89s/it]                                                     {'loss': 0.0036, 'grad_norm': 0.34165066480636597, 'learning_rate': 7.942372881355932e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1314/6000 [42:16<2:27:16,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1315/6000 [42:17<2:26:56,  1.88s/it]                                                     {'loss': 0.1772, 'grad_norm': 6.488428115844727, 'learning_rate': 7.940677966101696e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1315/6000 [42:17<2:26:56,  1.88s/it] 22%|â–ˆâ–ˆâ–       | 1316/6000 [42:19<2:25:49,  1.87s/it]                                                     {'loss': 0.2903, 'grad_norm': 6.877398490905762, 'learning_rate': 7.938983050847459e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1316/6000 [42:19<2:25:49,  1.87s/it] 22%|â–ˆâ–ˆâ–       | 1317/6000 [42:21<2:25:34,  1.87s/it]                                                     {'loss': 0.002, 'grad_norm': 0.2401553839445114, 'learning_rate': 7.93728813559322e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1317/6000 [42:21<2:25:34,  1.87s/it] 22%|â–ˆâ–ˆâ–       | 1318/6000 [42:23<2:25:14,  1.86s/it]                                                     {'loss': 0.1544, 'grad_norm': 8.756086349487305, 'learning_rate': 7.935593220338984e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1318/6000 [42:23<2:25:14,  1.86s/it] 22%|â–ˆâ–ˆâ–       | 1319/6000 [42:25<2:24:53,  1.86s/it]                                                     {'loss': 0.2099, 'grad_norm': 8.908002853393555, 'learning_rate': 7.933898305084747e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1319/6000 [42:25<2:24:53,  1.86s/it] 22%|â–ˆâ–ˆâ–       | 1320/6000 [42:27<2:25:23,  1.86s/it]                                                     {'loss': 0.204, 'grad_norm': 13.361298561096191, 'learning_rate': 7.93220338983051e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1320/6000 [42:27<2:25:23,  1.86s/it] 22%|â–ˆâ–ˆâ–       | 1321/6000 [42:29<2:26:03,  1.87s/it]                                                     {'loss': 0.3719, 'grad_norm': 12.432808876037598, 'learning_rate': 7.930508474576272e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1321/6000 [42:29<2:26:03,  1.87s/it] 22%|â–ˆâ–ˆâ–       | 1322/6000 [42:31<2:30:24,  1.93s/it]                                                     {'loss': 0.088, 'grad_norm': 7.180022716522217, 'learning_rate': 7.928813559322035e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1322/6000 [42:31<2:30:24,  1.93s/it] 22%|â–ˆâ–ˆâ–       | 1323/6000 [42:33<2:29:37,  1.92s/it]                                                     {'loss': 0.0223, 'grad_norm': 3.0146169662475586, 'learning_rate': 7.927118644067797e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1323/6000 [42:33<2:29:37,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1324/6000 [42:34<2:28:47,  1.91s/it]                                                     {'loss': 0.0343, 'grad_norm': 3.3987925052642822, 'learning_rate': 7.92542372881356e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1324/6000 [42:34<2:28:47,  1.91s/it] 22%|â–ˆâ–ˆâ–       | 1325/6000 [42:36<2:27:59,  1.90s/it]                                                     {'loss': 0.0295, 'grad_norm': 3.1604933738708496, 'learning_rate': 7.923728813559323e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1325/6000 [42:36<2:27:59,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1326/6000 [42:38<2:27:13,  1.89s/it]                                                     {'loss': 0.1064, 'grad_norm': 10.473362922668457, 'learning_rate': 7.922033898305085e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1326/6000 [42:38<2:27:13,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1327/6000 [42:40<2:27:21,  1.89s/it]                                                     {'loss': 0.1025, 'grad_norm': 9.559224128723145, 'learning_rate': 7.920338983050848e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1327/6000 [42:40<2:27:21,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1328/6000 [42:42<2:27:52,  1.90s/it]                                                     {'loss': 0.1131, 'grad_norm': 8.996922492980957, 'learning_rate': 7.91864406779661e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1328/6000 [42:42<2:27:52,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1329/6000 [42:44<2:29:37,  1.92s/it]                                                     {'loss': 0.0586, 'grad_norm': 6.730920314788818, 'learning_rate': 7.916949152542373e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1329/6000 [42:44<2:29:37,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1330/6000 [42:46<2:29:04,  1.92s/it]                                                     {'loss': 0.077, 'grad_norm': 5.272786617279053, 'learning_rate': 7.915254237288136e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1330/6000 [42:46<2:29:04,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1331/6000 [42:48<2:29:16,  1.92s/it]                                                     {'loss': 0.1155, 'grad_norm': 7.476075649261475, 'learning_rate': 7.9135593220339e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1331/6000 [42:48<2:29:16,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1332/6000 [42:50<2:27:56,  1.90s/it]                                                     {'loss': 0.0627, 'grad_norm': 5.033754348754883, 'learning_rate': 7.911864406779661e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1332/6000 [42:50<2:27:56,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1333/6000 [42:52<2:31:21,  1.95s/it]                                                     {'loss': 0.0364, 'grad_norm': 5.0062737464904785, 'learning_rate': 7.910169491525424e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1333/6000 [42:52<2:31:21,  1.95s/it] 22%|â–ˆâ–ˆâ–       | 1334/6000 [42:54<2:29:33,  1.92s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.8739220499992371, 'learning_rate': 7.908474576271186e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1334/6000 [42:54<2:29:33,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1335/6000 [42:55<2:27:31,  1.90s/it]                                                     {'loss': 0.0837, 'grad_norm': 5.3637895584106445, 'learning_rate': 7.906779661016951e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1335/6000 [42:55<2:27:31,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1336/6000 [42:57<2:26:45,  1.89s/it]                                                     {'loss': 0.0086, 'grad_norm': 1.1884605884552002, 'learning_rate': 7.905084745762712e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1336/6000 [42:57<2:26:45,  1.89s/it] 22%|â–ˆâ–ˆâ–       | 1337/6000 [42:59<2:25:25,  1.87s/it]                                                     {'loss': 0.1102, 'grad_norm': 7.374536037445068, 'learning_rate': 7.903389830508476e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1337/6000 [42:59<2:25:25,  1.87s/it] 22%|â–ˆâ–ˆâ–       | 1338/6000 [43:01<2:25:37,  1.87s/it]                                                     {'loss': 0.0072, 'grad_norm': 0.9682073593139648, 'learning_rate': 7.901694915254237e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1338/6000 [43:01<2:25:37,  1.87s/it] 22%|â–ˆâ–ˆâ–       | 1339/6000 [43:03<2:25:39,  1.88s/it]                                                     {'loss': 0.0325, 'grad_norm': 3.757936716079712, 'learning_rate': 7.9e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1339/6000 [43:03<2:25:39,  1.88s/it] 22%|â–ˆâ–ˆâ–       | 1340/6000 [43:05<2:25:33,  1.87s/it]                                                     {'loss': 0.0801, 'grad_norm': 6.196788311004639, 'learning_rate': 7.898305084745764e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1340/6000 [43:05<2:25:33,  1.87s/it] 22%|â–ˆâ–ˆâ–       | 1341/6000 [43:07<2:26:15,  1.88s/it]                                                     {'loss': 0.1536, 'grad_norm': 8.279324531555176, 'learning_rate': 7.896610169491527e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1341/6000 [43:07<2:26:15,  1.88s/it] 22%|â–ˆâ–ˆâ–       | 1342/6000 [43:09<2:27:44,  1.90s/it]                                                     {'loss': 0.2307, 'grad_norm': 11.500481605529785, 'learning_rate': 7.894915254237289e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1342/6000 [43:09<2:27:44,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1343/6000 [43:11<2:29:03,  1.92s/it]                                                     {'loss': 0.0881, 'grad_norm': 3.6187658309936523, 'learning_rate': 7.893220338983052e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1343/6000 [43:11<2:29:03,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1344/6000 [43:12<2:28:39,  1.92s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.7178274393081665, 'learning_rate': 7.891525423728814e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1344/6000 [43:12<2:28:39,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1345/6000 [43:14<2:29:06,  1.92s/it]                                                     {'loss': 0.0723, 'grad_norm': 5.257812976837158, 'learning_rate': 7.889830508474577e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1345/6000 [43:14<2:29:06,  1.92s/it] 22%|â–ˆâ–ˆâ–       | 1346/6000 [43:16<2:28:06,  1.91s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.3868696093559265, 'learning_rate': 7.88813559322034e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1346/6000 [43:16<2:28:06,  1.91s/it] 22%|â–ˆâ–ˆâ–       | 1347/6000 [43:18<2:28:09,  1.91s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.45140382647514343, 'learning_rate': 7.886440677966102e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1347/6000 [43:18<2:28:09,  1.91s/it] 22%|â–ˆâ–ˆâ–       | 1348/6000 [43:20<2:26:58,  1.90s/it]                                                     {'loss': 0.0074, 'grad_norm': 0.6106786727905273, 'learning_rate': 7.884745762711865e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1348/6000 [43:20<2:26:58,  1.90s/it] 22%|â–ˆâ–ˆâ–       | 1349/6000 [43:22<2:29:00,  1.92s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.8756670951843262, 'learning_rate': 7.883050847457627e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1349/6000 [43:22<2:29:00,  1.92s/it] 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [43:24<2:29:59,  1.94s/it]                                                     {'loss': 0.0766, 'grad_norm': 6.7248735427856445, 'learning_rate': 7.88135593220339e-06, 'epoch': 0.23}
 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [43:24<2:29:59,  1.94s/it][2025-11-11 22:36:39,944] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1350
[2025-11-11 22:36:39,951] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:36:40,242] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1350/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [43:27<2:47:12,  2.16s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.00952172465622425, 'learning_rate': 7.879661016949153e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [43:27<2:47:12,  2.16s/it] 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [43:29<2:42:24,  2.10s/it]                                                     {'loss': 0.066, 'grad_norm': 5.288205623626709, 'learning_rate': 7.877966101694916e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [43:29<2:42:24,  2.10s/it] 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [43:31<2:39:17,  2.06s/it]                                                     {'loss': 0.0382, 'grad_norm': 4.752935409545898, 'learning_rate': 7.876271186440678e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [43:31<2:39:17,  2.06s/it] 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [43:33<2:35:25,  2.01s/it]                                                     {'loss': 0.0258, 'grad_norm': 2.077974319458008, 'learning_rate': 7.874576271186441e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [43:33<2:35:25,  2.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [43:34<2:32:38,  1.97s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.7000163793563843, 'learning_rate': 7.872881355932205e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [43:34<2:32:38,  1.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [43:37<2:35:42,  2.01s/it]                                                     {'loss': 0.0215, 'grad_norm': 2.586623191833496, 'learning_rate': 7.871186440677968e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [43:37<2:35:42,  2.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [43:38<2:33:15,  1.98s/it]                                                     {'loss': 0.0204, 'grad_norm': 2.8028557300567627, 'learning_rate': 7.86949152542373e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [43:38<2:33:15,  1.98s/it] 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [43:40<2:31:50,  1.96s/it]                                                     {'loss': 0.1202, 'grad_norm': 9.616307258605957, 'learning_rate': 7.867796610169493e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [43:40<2:31:50,  1.96s/it] 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [43:42<2:31:06,  1.95s/it]                                                     {'loss': 0.0057, 'grad_norm': 0.5567473769187927, 'learning_rate': 7.866101694915254e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [43:42<2:31:06,  1.95s/it] 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [43:44<2:28:40,  1.92s/it]                                                     {'loss': 0.1692, 'grad_norm': 6.3391618728637695, 'learning_rate': 7.864406779661017e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [43:44<2:28:40,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [43:46<2:26:41,  1.90s/it]                                                     {'loss': 0.0703, 'grad_norm': 6.524025917053223, 'learning_rate': 7.86271186440678e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [43:46<2:26:41,  1.90s/it] 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [43:48<2:27:51,  1.91s/it]                                                     {'loss': 0.0291, 'grad_norm': 5.3317341804504395, 'learning_rate': 7.861016949152544e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [43:48<2:27:51,  1.91s/it] 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [43:50<2:27:25,  1.91s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.07218821346759796, 'learning_rate': 7.859322033898306e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [43:50<2:27:25,  1.91s/it] 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [43:52<2:25:27,  1.88s/it]                                                     {'loss': 0.0748, 'grad_norm': 6.722545623779297, 'learning_rate': 7.857627118644069e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [43:52<2:25:27,  1.88s/it] 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [43:54<2:27:00,  1.90s/it]                                                     {'loss': 0.0093, 'grad_norm': 1.5099202394485474, 'learning_rate': 7.85593220338983e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [43:54<2:27:00,  1.90s/it] 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [43:56<2:29:36,  1.94s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.2610648572444916, 'learning_rate': 7.854237288135594e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [43:56<2:29:36,  1.94s/it] 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [43:58<2:30:48,  1.95s/it]                                                     {'loss': 0.0767, 'grad_norm': 5.689319133758545, 'learning_rate': 7.852542372881357e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [43:58<2:30:48,  1.95s/it] 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [43:59<2:29:42,  1.94s/it]                                                     {'loss': 0.006, 'grad_norm': 0.9027696251869202, 'learning_rate': 7.850847457627119e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [43:59<2:29:42,  1.94s/it] 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [44:01<2:28:22,  1.92s/it]                                                     {'loss': 0.0335, 'grad_norm': 3.1947269439697266, 'learning_rate': 7.849152542372882e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [44:01<2:28:22,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [44:04<2:36:33,  2.03s/it]                                                     {'loss': 0.1496, 'grad_norm': 7.219958782196045, 'learning_rate': 7.847457627118643e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [44:04<2:36:33,  2.03s/it] 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [44:06<2:33:47,  1.99s/it]                                                     {'loss': 0.0222, 'grad_norm': 2.5919528007507324, 'learning_rate': 7.845762711864407e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [44:06<2:33:47,  1.99s/it] 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [44:07<2:30:55,  1.96s/it]                                                     {'loss': 0.0241, 'grad_norm': 3.4761548042297363, 'learning_rate': 7.84406779661017e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [44:07<2:30:55,  1.96s/it] 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [44:09<2:29:59,  1.95s/it]                                                     {'loss': 0.0347, 'grad_norm': 5.790881633758545, 'learning_rate': 7.842372881355933e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [44:09<2:29:59,  1.95s/it] 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [44:11<2:29:51,  1.94s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.7947400212287903, 'learning_rate': 7.840677966101695e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [44:11<2:29:51,  1.94s/it] 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [44:13<2:32:06,  1.97s/it]                                                     {'loss': 0.0101, 'grad_norm': 1.6655172109603882, 'learning_rate': 7.838983050847458e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [44:13<2:32:06,  1.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [44:15<2:31:25,  1.96s/it]                                                     {'loss': 0.2121, 'grad_norm': 11.072543144226074, 'learning_rate': 7.837288135593221e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [44:15<2:31:25,  1.96s/it] 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [44:17<2:28:03,  1.92s/it]                                                     {'loss': 0.1892, 'grad_norm': 4.986434459686279, 'learning_rate': 7.835593220338985e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [44:17<2:28:03,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [44:19<2:25:31,  1.89s/it]                                                     {'loss': 0.0169, 'grad_norm': 2.2351372241973877, 'learning_rate': 7.833898305084746e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [44:19<2:25:31,  1.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [44:21<2:25:23,  1.89s/it]                                                     {'loss': 0.0906, 'grad_norm': 7.414060592651367, 'learning_rate': 7.83220338983051e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [44:21<2:25:23,  1.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [44:23<2:24:49,  1.88s/it]                                                     {'loss': 0.0727, 'grad_norm': 5.210459232330322, 'learning_rate': 7.830508474576271e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [44:23<2:24:49,  1.88s/it] 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [44:25<2:26:44,  1.91s/it]                                                     {'loss': 0.4045, 'grad_norm': 12.380989074707031, 'learning_rate': 7.828813559322034e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [44:25<2:26:44,  1.91s/it] 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [44:27<2:27:29,  1.92s/it]                                                     {'loss': 0.2994, 'grad_norm': 9.168098449707031, 'learning_rate': 7.827118644067798e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [44:27<2:27:29,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [44:29<2:28:26,  1.93s/it]                                                     {'loss': 0.0075, 'grad_norm': 1.117754578590393, 'learning_rate': 7.825423728813561e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [44:29<2:28:26,  1.93s/it] 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [44:30<2:28:55,  1.94s/it]                                                     {'loss': 0.177, 'grad_norm': 7.512203693389893, 'learning_rate': 7.823728813559322e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [44:30<2:28:55,  1.94s/it] 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [44:32<2:27:53,  1.92s/it]                                                     {'loss': 0.0829, 'grad_norm': 7.366794586181641, 'learning_rate': 7.822033898305086e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [44:32<2:27:53,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [44:34<2:27:59,  1.92s/it]                                                     {'loss': 0.0581, 'grad_norm': 7.054478645324707, 'learning_rate': 7.820338983050847e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [44:34<2:27:59,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [44:36<2:26:37,  1.91s/it]                                                     {'loss': 0.0342, 'grad_norm': 4.70766544342041, 'learning_rate': 7.81864406779661e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [44:36<2:26:37,  1.91s/it] 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [44:38<2:27:14,  1.92s/it]                                                     {'loss': 0.1416, 'grad_norm': 7.305534362792969, 'learning_rate': 7.816949152542374e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [44:38<2:27:14,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [44:40<2:34:16,  2.01s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.34317246079444885, 'learning_rate': 7.815254237288135e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [44:40<2:34:16,  2.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [44:42<2:31:32,  1.97s/it]                                                     {'loss': 0.0076, 'grad_norm': 0.9161334037780762, 'learning_rate': 7.813559322033899e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [44:42<2:31:32,  1.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [44:44<2:28:34,  1.93s/it]                                                     {'loss': 0.0586, 'grad_norm': 6.820377349853516, 'learning_rate': 7.811864406779662e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [44:44<2:28:34,  1.93s/it] 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [44:46<2:27:48,  1.92s/it]                                                     {'loss': 0.03, 'grad_norm': 4.497051239013672, 'learning_rate': 7.810169491525425e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [44:46<2:27:48,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [44:48<2:26:57,  1.91s/it]                                                     {'loss': 0.1314, 'grad_norm': 8.414121627807617, 'learning_rate': 7.808474576271187e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [44:48<2:26:57,  1.91s/it] 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [44:50<2:25:16,  1.89s/it]                                                     {'loss': 0.0774, 'grad_norm': 3.838423252105713, 'learning_rate': 7.80677966101695e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [44:50<2:25:16,  1.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [44:52<2:25:22,  1.89s/it]                                                     {'loss': 0.1757, 'grad_norm': 8.539008140563965, 'learning_rate': 7.805084745762712e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [44:52<2:25:22,  1.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [44:53<2:25:16,  1.89s/it]                                                     {'loss': 0.0157, 'grad_norm': 2.235217809677124, 'learning_rate': 7.803389830508475e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [44:53<2:25:16,  1.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [44:55<2:24:56,  1.89s/it]                                                     {'loss': 0.004, 'grad_norm': 0.34483879804611206, 'learning_rate': 7.801694915254238e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [44:55<2:24:56,  1.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [44:57<2:24:17,  1.88s/it]                                                     {'loss': 0.0773, 'grad_norm': 6.988432884216309, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [44:57<2:24:17,  1.88s/it] 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [44:59<2:23:18,  1.87s/it]                                                     {'loss': 0.2043, 'grad_norm': 7.745800971984863, 'learning_rate': 7.798305084745763e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [44:59<2:23:18,  1.87s/it] 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [45:01<2:23:16,  1.87s/it]                                                     {'loss': 0.0079, 'grad_norm': 1.3951839208602905, 'learning_rate': 7.796610169491526e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [45:01<2:23:16,  1.87s/it][2025-11-11 22:38:16,847] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400
[2025-11-11 22:38:16,855] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:38:17,142] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [45:04<2:41:26,  2.11s/it]                                                     {'loss': 0.0402, 'grad_norm': 5.10496187210083, 'learning_rate': 7.794915254237288e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [45:04<2:41:26,  2.11s/it] 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [45:05<2:36:31,  2.04s/it]                                                     {'loss': 0.148, 'grad_norm': 6.9785380363464355, 'learning_rate': 7.793220338983051e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [45:05<2:36:31,  2.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [45:07<2:31:46,  1.98s/it]                                                     {'loss': 0.0654, 'grad_norm': 5.907252311706543, 'learning_rate': 7.791525423728815e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [45:07<2:31:46,  1.98s/it] 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [45:09<2:28:11,  1.93s/it]                                                     {'loss': 0.0759, 'grad_norm': 5.469388008117676, 'learning_rate': 7.789830508474578e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [45:09<2:28:11,  1.93s/it] 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [45:11<2:26:40,  1.92s/it]                                                     {'loss': 0.19, 'grad_norm': 6.8335089683532715, 'learning_rate': 7.78813559322034e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [45:11<2:26:40,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [45:13<2:25:36,  1.90s/it]                                                     {'loss': 0.0489, 'grad_norm': 4.465513229370117, 'learning_rate': 7.786440677966103e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [45:13<2:25:36,  1.90s/it] 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [45:15<2:26:49,  1.92s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.191908597946167, 'learning_rate': 7.784745762711864e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [45:15<2:26:49,  1.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [45:17<2:25:44,  1.90s/it]                                                     {'loss': 0.001, 'grad_norm': 0.17540647089481354, 'learning_rate': 7.783050847457628e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [45:17<2:25:44,  1.90s/it] 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [45:19<2:27:58,  1.93s/it]                                                     {'loss': 0.008, 'grad_norm': 1.0189323425292969, 'learning_rate': 7.78135593220339e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [45:19<2:27:58,  1.93s/it] 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [45:21<2:28:03,  1.94s/it]                                                     {'loss': 0.0872, 'grad_norm': 5.298556327819824, 'learning_rate': 7.779661016949152e-06, 'epoch': 0.23}
 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [45:21<2:28:03,  1.94s/it] 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [45:23<2:27:37,  1.93s/it]                                                     {'loss': 0.0132, 'grad_norm': 1.1762229204177856, 'learning_rate': 7.777966101694916e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [45:23<2:27:37,  1.93s/it] 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [45:25<2:31:09,  1.98s/it]                                                     {'loss': 0.0626, 'grad_norm': 3.976423501968384, 'learning_rate': 7.776271186440679e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [45:25<2:31:09,  1.98s/it] 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [45:27<2:28:13,  1.94s/it]                                                     {'loss': 0.0141, 'grad_norm': 2.396615505218506, 'learning_rate': 7.774576271186442e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [45:27<2:28:13,  1.94s/it] 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [45:28<2:26:57,  1.92s/it]                                                     {'loss': 0.2203, 'grad_norm': 5.774310111999512, 'learning_rate': 7.772881355932204e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [45:28<2:26:57,  1.92s/it] 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [45:30<2:28:12,  1.94s/it]                                                     {'loss': 0.1405, 'grad_norm': 12.065799713134766, 'learning_rate': 7.771186440677967e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [45:30<2:28:12,  1.94s/it] 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [45:32<2:27:39,  1.93s/it]                                                     {'loss': 0.0103, 'grad_norm': 1.9661884307861328, 'learning_rate': 7.769491525423729e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [45:32<2:27:39,  1.93s/it] 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [45:34<2:27:01,  1.92s/it]                                                     {'loss': 0.1098, 'grad_norm': 7.482693672180176, 'learning_rate': 7.767796610169492e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [45:34<2:27:01,  1.92s/it] 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [45:36<2:25:54,  1.91s/it]                                                     {'loss': 0.004, 'grad_norm': 0.7447500228881836, 'learning_rate': 7.766101694915255e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [45:36<2:25:54,  1.91s/it] 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [45:38<2:26:41,  1.92s/it]                                                     {'loss': 0.0952, 'grad_norm': 7.7839531898498535, 'learning_rate': 7.764406779661018e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [45:38<2:26:41,  1.92s/it] 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [45:40<2:25:31,  1.91s/it]                                                     {'loss': 0.0653, 'grad_norm': 2.9936721324920654, 'learning_rate': 7.76271186440678e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [45:40<2:25:31,  1.91s/it] 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [45:42<2:25:07,  1.90s/it]                                                     {'loss': 0.0742, 'grad_norm': 5.375247001647949, 'learning_rate': 7.761016949152543e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [45:42<2:25:07,  1.90s/it] 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [45:44<2:24:25,  1.89s/it]                                                     {'loss': 0.0395, 'grad_norm': 3.2980000972747803, 'learning_rate': 7.759322033898305e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [45:44<2:24:25,  1.89s/it] 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [45:45<2:23:12,  1.88s/it]                                                     {'loss': 0.0512, 'grad_norm': 4.914055347442627, 'learning_rate': 7.757627118644068e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [45:45<2:23:12,  1.88s/it] 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [45:47<2:22:18,  1.87s/it]                                                     {'loss': 0.2626, 'grad_norm': 8.698379516601562, 'learning_rate': 7.755932203389831e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [45:47<2:22:18,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1425/6000 [45:49<2:23:12,  1.88s/it]                                                     {'loss': 0.1508, 'grad_norm': 9.071443557739258, 'learning_rate': 7.754237288135595e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1425/6000 [45:49<2:23:12,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1426/6000 [45:51<2:24:23,  1.89s/it]                                                     {'loss': 0.0817, 'grad_norm': 5.2362871170043945, 'learning_rate': 7.752542372881356e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1426/6000 [45:51<2:24:23,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1427/6000 [45:53<2:23:22,  1.88s/it]                                                     {'loss': 0.0263, 'grad_norm': 3.5517590045928955, 'learning_rate': 7.75084745762712e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1427/6000 [45:53<2:23:22,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1428/6000 [45:55<2:23:26,  1.88s/it]                                                     {'loss': 0.0864, 'grad_norm': 6.952049255371094, 'learning_rate': 7.749152542372881e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1428/6000 [45:55<2:23:26,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1429/6000 [45:57<2:23:09,  1.88s/it]                                                     {'loss': 0.024, 'grad_norm': 3.419156789779663, 'learning_rate': 7.747457627118644e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1429/6000 [45:57<2:23:09,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1430/6000 [45:59<2:22:19,  1.87s/it]                                                     {'loss': 0.0184, 'grad_norm': 2.6691582202911377, 'learning_rate': 7.745762711864408e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1430/6000 [45:59<2:22:19,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1431/6000 [46:00<2:22:08,  1.87s/it]                                                     {'loss': 0.0168, 'grad_norm': 2.293348550796509, 'learning_rate': 7.74406779661017e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1431/6000 [46:00<2:22:08,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1432/6000 [46:02<2:21:58,  1.86s/it]                                                     {'loss': 0.0247, 'grad_norm': 4.070571422576904, 'learning_rate': 7.742372881355933e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1432/6000 [46:02<2:21:58,  1.86s/it] 24%|â–ˆâ–ˆâ–       | 1433/6000 [46:04<2:25:33,  1.91s/it]                                                     {'loss': 0.0408, 'grad_norm': 3.3097050189971924, 'learning_rate': 7.740677966101696e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1433/6000 [46:04<2:25:33,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1434/6000 [46:06<2:25:40,  1.91s/it]                                                     {'loss': 0.0502, 'grad_norm': 4.639880657196045, 'learning_rate': 7.738983050847459e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1434/6000 [46:06<2:25:40,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1435/6000 [46:08<2:25:28,  1.91s/it]                                                     {'loss': 0.003, 'grad_norm': 0.386584997177124, 'learning_rate': 7.73728813559322e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1435/6000 [46:08<2:25:28,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1436/6000 [46:10<2:27:13,  1.94s/it]                                                     {'loss': 0.047, 'grad_norm': 4.949789047241211, 'learning_rate': 7.735593220338984e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1436/6000 [46:10<2:27:13,  1.94s/it] 24%|â–ˆâ–ˆâ–       | 1437/6000 [46:12<2:27:05,  1.93s/it]                                                     {'loss': 0.0818, 'grad_norm': 3.571800708770752, 'learning_rate': 7.733898305084746e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1437/6000 [46:12<2:27:05,  1.93s/it] 24%|â–ˆâ–ˆâ–       | 1438/6000 [46:14<2:25:25,  1.91s/it]                                                     {'loss': 0.0602, 'grad_norm': 4.552914142608643, 'learning_rate': 7.732203389830509e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1438/6000 [46:14<2:25:25,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1439/6000 [46:16<2:24:16,  1.90s/it]                                                     {'loss': 0.0086, 'grad_norm': 1.1228878498077393, 'learning_rate': 7.730508474576272e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1439/6000 [46:16<2:24:16,  1.90s/it] 24%|â–ˆâ–ˆâ–       | 1440/6000 [46:18<2:23:50,  1.89s/it]                                                     {'loss': 0.0599, 'grad_norm': 5.987142086029053, 'learning_rate': 7.728813559322035e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1440/6000 [46:18<2:23:50,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1441/6000 [46:20<2:23:10,  1.88s/it]                                                     {'loss': 0.1142, 'grad_norm': 6.8354010581970215, 'learning_rate': 7.727118644067797e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1441/6000 [46:20<2:23:10,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1442/6000 [46:21<2:23:41,  1.89s/it]                                                     {'loss': 0.2087, 'grad_norm': 10.479264259338379, 'learning_rate': 7.72542372881356e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1442/6000 [46:22<2:23:41,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1443/6000 [46:23<2:22:20,  1.87s/it]                                                     {'loss': 0.1146, 'grad_norm': 10.752669334411621, 'learning_rate': 7.723728813559322e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1443/6000 [46:23<2:22:20,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1444/6000 [46:25<2:22:27,  1.88s/it]                                                     {'loss': 0.0249, 'grad_norm': 3.15122127532959, 'learning_rate': 7.722033898305085e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1444/6000 [46:25<2:22:27,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1445/6000 [46:27<2:21:55,  1.87s/it]                                                     {'loss': 0.1133, 'grad_norm': 9.84902286529541, 'learning_rate': 7.720338983050848e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1445/6000 [46:27<2:21:55,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1446/6000 [46:29<2:21:56,  1.87s/it]                                                     {'loss': 0.0732, 'grad_norm': 7.325924396514893, 'learning_rate': 7.718644067796612e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1446/6000 [46:29<2:21:56,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1447/6000 [46:31<2:21:20,  1.86s/it]                                                     {'loss': 0.0206, 'grad_norm': 2.1650283336639404, 'learning_rate': 7.716949152542373e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1447/6000 [46:31<2:21:20,  1.86s/it] 24%|â–ˆâ–ˆâ–       | 1448/6000 [46:33<2:21:23,  1.86s/it]                                                     {'loss': 0.6414, 'grad_norm': 12.833735466003418, 'learning_rate': 7.715254237288136e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1448/6000 [46:33<2:21:23,  1.86s/it] 24%|â–ˆâ–ˆâ–       | 1449/6000 [46:34<2:20:54,  1.86s/it]                                                     {'loss': 0.0192, 'grad_norm': 1.5067198276519775, 'learning_rate': 7.7135593220339e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1449/6000 [46:34<2:20:54,  1.86s/it] 24%|â–ˆâ–ˆâ–       | 1450/6000 [46:36<2:20:51,  1.86s/it]                                                     {'loss': 0.0336, 'grad_norm': 4.707464218139648, 'learning_rate': 7.711864406779663e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1450/6000 [46:36<2:20:51,  1.86s/it][2025-11-11 22:39:52,268] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1450
[2025-11-11 22:39:52,276] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:39:52,549] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1450/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 24%|â–ˆâ–ˆâ–       | 1451/6000 [46:39<2:38:19,  2.09s/it]                                                     {'loss': 0.0698, 'grad_norm': 6.414261341094971, 'learning_rate': 7.710169491525425e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1451/6000 [46:39<2:38:19,  2.09s/it] 24%|â–ˆâ–ˆâ–       | 1452/6000 [46:41<2:32:46,  2.02s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.7234233021736145, 'learning_rate': 7.708474576271186e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1452/6000 [46:41<2:32:46,  2.02s/it] 24%|â–ˆâ–ˆâ–       | 1453/6000 [46:43<2:29:23,  1.97s/it]                                                     {'loss': 0.2998, 'grad_norm': 9.975829124450684, 'learning_rate': 7.70677966101695e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1453/6000 [46:43<2:29:23,  1.97s/it] 24%|â–ˆâ–ˆâ–       | 1454/6000 [46:45<2:26:40,  1.94s/it]                                                     {'loss': 0.0887, 'grad_norm': 5.717090606689453, 'learning_rate': 7.705084745762713e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1454/6000 [46:45<2:26:40,  1.94s/it] 24%|â–ˆâ–ˆâ–       | 1455/6000 [46:46<2:25:27,  1.92s/it]                                                     {'loss': 0.1056, 'grad_norm': 7.029162883758545, 'learning_rate': 7.703389830508476e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1455/6000 [46:46<2:25:27,  1.92s/it] 24%|â–ˆâ–ˆâ–       | 1456/6000 [46:48<2:28:30,  1.96s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.7422950267791748, 'learning_rate': 7.701694915254238e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1456/6000 [46:48<2:28:30,  1.96s/it] 24%|â–ˆâ–ˆâ–       | 1457/6000 [46:50<2:26:12,  1.93s/it]                                                     {'loss': 0.0631, 'grad_norm': 5.870210647583008, 'learning_rate': 7.7e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1457/6000 [46:50<2:26:12,  1.93s/it] 24%|â–ˆâ–ˆâ–       | 1458/6000 [46:52<2:25:50,  1.93s/it]                                                     {'loss': 0.0564, 'grad_norm': 5.753820896148682, 'learning_rate': 7.698305084745762e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1458/6000 [46:52<2:25:50,  1.93s/it] 24%|â–ˆâ–ˆâ–       | 1459/6000 [46:54<2:24:20,  1.91s/it]                                                     {'loss': 0.0326, 'grad_norm': 4.654932022094727, 'learning_rate': 7.696610169491526e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1459/6000 [46:54<2:24:20,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1460/6000 [46:56<2:22:30,  1.88s/it]                                                     {'loss': 0.3103, 'grad_norm': 10.893599510192871, 'learning_rate': 7.694915254237289e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1460/6000 [46:56<2:22:30,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1461/6000 [46:58<2:24:22,  1.91s/it]                                                     {'loss': 0.1204, 'grad_norm': 6.822918891906738, 'learning_rate': 7.693220338983052e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1461/6000 [46:58<2:24:22,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1462/6000 [47:00<2:22:57,  1.89s/it]                                                     {'loss': 0.1162, 'grad_norm': 9.817475318908691, 'learning_rate': 7.691525423728814e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1462/6000 [47:00<2:22:57,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1463/6000 [47:02<2:22:52,  1.89s/it]                                                     {'loss': 0.06, 'grad_norm': 5.212504863739014, 'learning_rate': 7.689830508474577e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1463/6000 [47:02<2:22:52,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1464/6000 [47:04<2:22:52,  1.89s/it]                                                     {'loss': 0.141, 'grad_norm': 9.764699935913086, 'learning_rate': 7.688135593220339e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1464/6000 [47:04<2:22:52,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1465/6000 [47:05<2:22:56,  1.89s/it]                                                     {'loss': 0.0594, 'grad_norm': 6.111203670501709, 'learning_rate': 7.686440677966102e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1465/6000 [47:05<2:22:56,  1.89s/it] 24%|â–ˆâ–ˆâ–       | 1466/6000 [47:07<2:21:39,  1.87s/it]                                                     {'loss': 0.0447, 'grad_norm': 3.9817557334899902, 'learning_rate': 7.684745762711865e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1466/6000 [47:07<2:21:39,  1.87s/it] 24%|â–ˆâ–ˆâ–       | 1467/6000 [47:09<2:22:21,  1.88s/it]                                                     {'loss': 0.0735, 'grad_norm': 4.280807971954346, 'learning_rate': 7.683050847457628e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1467/6000 [47:09<2:22:21,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1468/6000 [47:11<2:22:13,  1.88s/it]                                                     {'loss': 0.308, 'grad_norm': 12.071833610534668, 'learning_rate': 7.68135593220339e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1468/6000 [47:11<2:22:13,  1.88s/it] 24%|â–ˆâ–ˆâ–       | 1469/6000 [47:13<2:24:07,  1.91s/it]                                                     {'loss': 0.0176, 'grad_norm': 1.4433480501174927, 'learning_rate': 7.679661016949153e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1469/6000 [47:13<2:24:07,  1.91s/it] 24%|â–ˆâ–ˆâ–       | 1470/6000 [47:15<2:23:28,  1.90s/it]                                                     {'loss': 0.2457, 'grad_norm': 8.495943069458008, 'learning_rate': 7.677966101694917e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1470/6000 [47:15<2:23:28,  1.90s/it] 25%|â–ˆâ–ˆâ–       | 1471/6000 [47:17<2:23:37,  1.90s/it]                                                     {'loss': 0.1384, 'grad_norm': 8.652874946594238, 'learning_rate': 7.67627118644068e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1471/6000 [47:17<2:23:37,  1.90s/it] 25%|â–ˆâ–ˆâ–       | 1472/6000 [47:19<2:22:30,  1.89s/it]                                                     {'loss': 0.0336, 'grad_norm': 3.7933719158172607, 'learning_rate': 7.674576271186441e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1472/6000 [47:19<2:22:30,  1.89s/it] 25%|â–ˆâ–ˆâ–       | 1473/6000 [47:21<2:21:51,  1.88s/it]                                                     {'loss': 0.0225, 'grad_norm': 3.7203354835510254, 'learning_rate': 7.672881355932203e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1473/6000 [47:21<2:21:51,  1.88s/it] 25%|â–ˆâ–ˆâ–       | 1474/6000 [47:22<2:20:56,  1.87s/it]                                                     {'loss': 0.0157, 'grad_norm': 2.477374792098999, 'learning_rate': 7.671186440677966e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1474/6000 [47:22<2:20:56,  1.87s/it] 25%|â–ˆâ–ˆâ–       | 1475/6000 [47:25<2:27:59,  1.96s/it]                                                     {'loss': 0.151, 'grad_norm': 8.338238716125488, 'learning_rate': 7.66949152542373e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1475/6000 [47:25<2:27:59,  1.96s/it] 25%|â–ˆâ–ˆâ–       | 1476/6000 [47:26<2:25:59,  1.94s/it]                                                     {'loss': 0.0458, 'grad_norm': 4.4813971519470215, 'learning_rate': 7.667796610169493e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1476/6000 [47:26<2:25:59,  1.94s/it] 25%|â–ˆâ–ˆâ–       | 1477/6000 [47:28<2:24:04,  1.91s/it]                                                     {'loss': 0.1586, 'grad_norm': 8.103206634521484, 'learning_rate': 7.666101694915254e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1477/6000 [47:28<2:24:04,  1.91s/it] 25%|â–ˆâ–ˆâ–       | 1478/6000 [47:30<2:23:20,  1.90s/it]                                                     {'loss': 0.004, 'grad_norm': 0.5641897320747375, 'learning_rate': 7.664406779661018e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1478/6000 [47:30<2:23:20,  1.90s/it] 25%|â–ˆâ–ˆâ–       | 1479/6000 [47:32<2:22:47,  1.89s/it]                                                     {'loss': 0.2486, 'grad_norm': 9.505794525146484, 'learning_rate': 7.66271186440678e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1479/6000 [47:32<2:22:47,  1.89s/it] 25%|â–ˆâ–ˆâ–       | 1480/6000 [47:34<2:21:47,  1.88s/it]                                                     {'loss': 0.0035, 'grad_norm': 0.4525444209575653, 'learning_rate': 7.661016949152543e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1480/6000 [47:34<2:21:47,  1.88s/it] 25%|â–ˆâ–ˆâ–       | 1481/6000 [47:36<2:21:36,  1.88s/it]                                                     {'loss': 0.0935, 'grad_norm': 7.774894714355469, 'learning_rate': 7.659322033898306e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1481/6000 [47:36<2:21:36,  1.88s/it] 25%|â–ˆâ–ˆâ–       | 1482/6000 [47:38<2:21:12,  1.88s/it]                                                     {'loss': 0.0845, 'grad_norm': 3.8074793815612793, 'learning_rate': 7.657627118644069e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1482/6000 [47:38<2:21:12,  1.88s/it] 25%|â–ˆâ–ˆâ–       | 1483/6000 [47:40<2:21:02,  1.87s/it]                                                     {'loss': 0.0777, 'grad_norm': 5.695568084716797, 'learning_rate': 7.65593220338983e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1483/6000 [47:40<2:21:02,  1.87s/it] 25%|â–ˆâ–ˆâ–       | 1484/6000 [47:41<2:20:55,  1.87s/it]                                                     {'loss': 0.0986, 'grad_norm': 8.690511703491211, 'learning_rate': 7.654237288135594e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1484/6000 [47:41<2:20:55,  1.87s/it] 25%|â–ˆâ–ˆâ–       | 1485/6000 [47:43<2:21:10,  1.88s/it]                                                     {'loss': 0.2049, 'grad_norm': 8.018239974975586, 'learning_rate': 7.652542372881356e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1485/6000 [47:43<2:21:10,  1.88s/it] 25%|â–ˆâ–ˆâ–       | 1486/6000 [47:45<2:21:11,  1.88s/it]                                                     {'loss': 0.025, 'grad_norm': 3.299558162689209, 'learning_rate': 7.65084745762712e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1486/6000 [47:45<2:21:11,  1.88s/it] 25%|â–ˆâ–ˆâ–       | 1487/6000 [47:47<2:23:17,  1.90s/it]                                                     {'loss': 0.0958, 'grad_norm': 5.201086521148682, 'learning_rate': 7.649152542372882e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1487/6000 [47:47<2:23:17,  1.90s/it] 25%|â–ˆâ–ˆâ–       | 1488/6000 [47:49<2:22:12,  1.89s/it]                                                     {'loss': 0.1738, 'grad_norm': 9.156325340270996, 'learning_rate': 7.647457627118645e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1488/6000 [47:49<2:22:12,  1.89s/it] 25%|â–ˆâ–ˆâ–       | 1489/6000 [47:51<2:27:30,  1.96s/it]                                                     {'loss': 0.1788, 'grad_norm': 10.737399101257324, 'learning_rate': 7.645762711864407e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1489/6000 [47:51<2:27:30,  1.96s/it] 25%|â–ˆâ–ˆâ–       | 1490/6000 [47:53<2:26:23,  1.95s/it]                                                     {'loss': 0.0593, 'grad_norm': 3.500143527984619, 'learning_rate': 7.64406779661017e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1490/6000 [47:53<2:26:23,  1.95s/it] 25%|â–ˆâ–ˆâ–       | 1491/6000 [47:55<2:24:57,  1.93s/it]                                                     {'loss': 0.003, 'grad_norm': 0.4106482267379761, 'learning_rate': 7.642372881355933e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1491/6000 [47:55<2:24:57,  1.93s/it] 25%|â–ˆâ–ˆâ–       | 1492/6000 [47:57<2:26:40,  1.95s/it]                                                     {'loss': 0.056, 'grad_norm': 5.2167534828186035, 'learning_rate': 7.640677966101695e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1492/6000 [47:57<2:26:40,  1.95s/it] 25%|â–ˆâ–ˆâ–       | 1493/6000 [47:59<2:23:57,  1.92s/it]                                                     {'loss': 0.0143, 'grad_norm': 1.9175620079040527, 'learning_rate': 7.638983050847458e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1493/6000 [47:59<2:23:57,  1.92s/it] 25%|â–ˆâ–ˆâ–       | 1494/6000 [48:01<2:22:35,  1.90s/it]                                                     {'loss': 0.0129, 'grad_norm': 1.4191508293151855, 'learning_rate': 7.63728813559322e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1494/6000 [48:01<2:22:35,  1.90s/it] 25%|â–ˆâ–ˆâ–       | 1495/6000 [48:02<2:22:12,  1.89s/it]                                                     {'loss': 0.2406, 'grad_norm': 9.533315658569336, 'learning_rate': 7.635593220338983e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1495/6000 [48:02<2:22:12,  1.89s/it] 25%|â–ˆâ–ˆâ–       | 1496/6000 [48:04<2:22:18,  1.90s/it]                                                     {'loss': 0.1974, 'grad_norm': 8.384988784790039, 'learning_rate': 7.633898305084746e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1496/6000 [48:04<2:22:18,  1.90s/it] 25%|â–ˆâ–ˆâ–       | 1497/6000 [48:06<2:21:58,  1.89s/it]                                                     {'loss': 0.3659, 'grad_norm': 11.164199829101562, 'learning_rate': 7.63220338983051e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1497/6000 [48:06<2:21:58,  1.89s/it] 25%|â–ˆâ–ˆâ–       | 1498/6000 [48:08<2:21:32,  1.89s/it]                                                     {'loss': 0.051, 'grad_norm': 3.8363661766052246, 'learning_rate': 7.630508474576271e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1498/6000 [48:08<2:21:32,  1.89s/it] 25%|â–ˆâ–ˆâ–       | 1499/6000 [48:10<2:21:04,  1.88s/it]                                                     {'loss': 0.0077, 'grad_norm': 0.8038399815559387, 'learning_rate': 7.628813559322035e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1499/6000 [48:10<2:21:04,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [48:12<2:20:30,  1.87s/it]                                                     {'loss': 0.0062, 'grad_norm': 0.6941923499107361, 'learning_rate': 7.627118644067797e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [48:12<2:20:30,  1.87s/it][2025-11-11 22:41:27,774] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500
[2025-11-11 22:41:27,781] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:41:28,231] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [48:15<2:42:34,  2.17s/it]                                                     {'loss': 0.1201, 'grad_norm': 6.505423545837402, 'learning_rate': 7.62542372881356e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [48:15<2:42:34,  2.17s/it] 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [48:17<2:36:36,  2.09s/it]                                                     {'loss': 0.0769, 'grad_norm': 6.007782459259033, 'learning_rate': 7.623728813559323e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [48:17<2:36:36,  2.09s/it] 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [48:18<2:30:24,  2.01s/it]                                                     {'loss': 0.1545, 'grad_norm': 7.657699108123779, 'learning_rate': 7.622033898305086e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [48:18<2:30:24,  2.01s/it] 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [48:20<2:27:01,  1.96s/it]                                                     {'loss': 0.0094, 'grad_norm': 1.9442805051803589, 'learning_rate': 7.6203389830508476e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [48:20<2:27:01,  1.96s/it] 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [48:22<2:24:22,  1.93s/it]                                                     {'loss': 0.0053, 'grad_norm': 0.5188623070716858, 'learning_rate': 7.618644067796611e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [48:22<2:24:22,  1.93s/it] 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [48:24<2:23:27,  1.92s/it]                                                     {'loss': 0.0199, 'grad_norm': 2.9870035648345947, 'learning_rate': 7.616949152542373e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [48:24<2:23:27,  1.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [48:26<2:22:48,  1.91s/it]                                                     {'loss': 0.1061, 'grad_norm': 6.672546863555908, 'learning_rate': 7.6152542372881365e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [48:26<2:22:48,  1.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [48:28<2:23:04,  1.91s/it]                                                     {'loss': 0.1051, 'grad_norm': 7.651910305023193, 'learning_rate': 7.613559322033899e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [48:28<2:23:04,  1.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [48:30<2:22:16,  1.90s/it]                                                     {'loss': 0.034, 'grad_norm': 4.035192489624023, 'learning_rate': 7.611864406779662e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [48:30<2:22:16,  1.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [48:32<2:20:56,  1.88s/it]                                                     {'loss': 0.1041, 'grad_norm': 4.63902473449707, 'learning_rate': 7.610169491525425e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [48:32<2:20:56,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [48:33<2:20:29,  1.88s/it]                                                     {'loss': 0.0975, 'grad_norm': 9.467312812805176, 'learning_rate': 7.608474576271188e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [48:33<2:20:29,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [48:35<2:20:06,  1.87s/it]                                                     {'loss': 0.1068, 'grad_norm': 6.773814678192139, 'learning_rate': 7.6067796610169495e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [48:35<2:20:06,  1.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [48:37<2:20:07,  1.87s/it]                                                     {'loss': 0.2046, 'grad_norm': 11.438241004943848, 'learning_rate': 7.605084745762712e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [48:37<2:20:07,  1.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [48:39<2:19:31,  1.87s/it]                                                     {'loss': 0.0063, 'grad_norm': 0.5716531872749329, 'learning_rate': 7.603389830508475e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [48:39<2:19:31,  1.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [48:41<2:19:34,  1.87s/it]                                                     {'loss': 0.0646, 'grad_norm': 5.908068656921387, 'learning_rate': 7.601694915254238e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [48:41<2:19:34,  1.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [48:43<2:19:29,  1.87s/it]                                                     {'loss': 0.109, 'grad_norm': 7.000522136688232, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [48:43<2:19:29,  1.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [48:45<2:20:26,  1.88s/it]                                                     {'loss': 0.0959, 'grad_norm': 5.762232303619385, 'learning_rate': 7.5983050847457625e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [48:45<2:20:26,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [48:47<2:20:24,  1.88s/it]                                                     {'loss': 0.0048, 'grad_norm': 0.4600616991519928, 'learning_rate': 7.596610169491526e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [48:47<2:20:24,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [48:48<2:19:13,  1.86s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.44781801104545593, 'learning_rate': 7.594915254237288e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [48:48<2:19:13,  1.86s/it] 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [48:50<2:21:03,  1.89s/it]                                                     {'loss': 0.1811, 'grad_norm': 8.674586296081543, 'learning_rate': 7.5932203389830515e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [48:50<2:21:03,  1.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [48:52<2:20:51,  1.89s/it]                                                     {'loss': 0.015, 'grad_norm': 0.9043034315109253, 'learning_rate': 7.591525423728814e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [48:52<2:20:51,  1.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [48:54<2:20:19,  1.88s/it]                                                     {'loss': 0.1837, 'grad_norm': 8.279818534851074, 'learning_rate': 7.589830508474577e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [48:54<2:20:19,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [48:56<2:20:18,  1.88s/it]                                                     {'loss': 0.0215, 'grad_norm': 2.0903079509735107, 'learning_rate': 7.58813559322034e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [48:56<2:20:18,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [48:58<2:20:15,  1.88s/it]                                                     {'loss': 0.1988, 'grad_norm': 10.106927871704102, 'learning_rate': 7.586440677966103e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [48:58<2:20:15,  1.88s/it] 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [49:00<2:21:19,  1.89s/it]                                                     {'loss': 0.0623, 'grad_norm': 3.326497793197632, 'learning_rate': 7.5847457627118645e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [49:00<2:21:19,  1.89s/it] 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [49:02<2:21:19,  1.90s/it]                                                     {'loss': 0.0099, 'grad_norm': 1.0837467908859253, 'learning_rate': 7.583050847457628e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [49:02<2:21:19,  1.90s/it] 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [49:04<2:23:15,  1.92s/it]                                                     {'loss': 0.0349, 'grad_norm': 3.8134114742279053, 'learning_rate': 7.58135593220339e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [49:04<2:23:15,  1.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [49:06<2:26:38,  1.97s/it]                                                     {'loss': 0.0209, 'grad_norm': 2.6747989654541016, 'learning_rate': 7.5796610169491534e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [49:06<2:26:38,  1.97s/it] 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [49:08<2:24:00,  1.93s/it]                                                     {'loss': 0.005, 'grad_norm': 0.6751875281333923, 'learning_rate': 7.577966101694916e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [49:08<2:24:00,  1.93s/it] 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [49:10<2:26:36,  1.97s/it]                                                     {'loss': 0.005, 'grad_norm': 0.9556649327278137, 'learning_rate': 7.576271186440679e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [49:10<2:26:36,  1.97s/it] 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [49:11<2:24:45,  1.94s/it]                                                     {'loss': 0.0794, 'grad_norm': 6.448014736175537, 'learning_rate': 7.5745762711864416e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [49:11<2:24:45,  1.94s/it] 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [49:13<2:23:03,  1.92s/it]                                                     {'loss': 0.133, 'grad_norm': 7.323605060577393, 'learning_rate': 7.572881355932205e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [49:13<2:23:03,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [49:15<2:21:56,  1.91s/it]                                                     {'loss': 0.2244, 'grad_norm': 10.68072509765625, 'learning_rate': 7.571186440677966e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [49:15<2:21:56,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [49:17<2:21:18,  1.90s/it]                                                     {'loss': 0.0499, 'grad_norm': 4.122539043426514, 'learning_rate': 7.569491525423729e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [49:17<2:21:18,  1.90s/it] 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [49:19<2:19:44,  1.88s/it]                                                     {'loss': 0.0577, 'grad_norm': 2.2885401248931885, 'learning_rate': 7.567796610169492e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [49:19<2:19:44,  1.88s/it] 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [49:21<2:18:26,  1.86s/it]                                                     {'loss': 0.1156, 'grad_norm': 8.41043472290039, 'learning_rate': 7.5661016949152545e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [49:21<2:18:26,  1.86s/it] 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [49:23<2:22:37,  1.92s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.3102398216724396, 'learning_rate': 7.564406779661018e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [49:23<2:22:37,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [49:25<2:23:06,  1.92s/it]                                                     {'loss': 0.0571, 'grad_norm': 2.2175374031066895, 'learning_rate': 7.56271186440678e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [49:25<2:23:06,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [49:27<2:21:38,  1.91s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.44186481833457947, 'learning_rate': 7.5610169491525435e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [49:27<2:21:38,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [49:29<2:21:44,  1.91s/it]                                                     {'loss': 0.0592, 'grad_norm': 4.83668327331543, 'learning_rate': 7.559322033898305e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [49:29<2:21:44,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [49:30<2:22:59,  1.92s/it]                                                     {'loss': 0.199, 'grad_norm': 10.10918140411377, 'learning_rate': 7.557627118644068e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [49:30<2:22:59,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [49:32<2:21:37,  1.91s/it]                                                     {'loss': 0.0085, 'grad_norm': 0.7294186353683472, 'learning_rate': 7.555932203389831e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [49:32<2:21:37,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [49:34<2:21:30,  1.90s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.013926378451287746, 'learning_rate': 7.554237288135594e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [49:34<2:21:30,  1.90s/it] 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [49:36<2:20:37,  1.89s/it]                                                     {'loss': 0.1719, 'grad_norm': 10.05838394165039, 'learning_rate': 7.5525423728813565e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [49:36<2:20:37,  1.89s/it] 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [49:38<2:19:49,  1.88s/it]                                                     {'loss': 0.0396, 'grad_norm': 2.3454015254974365, 'learning_rate': 7.55084745762712e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [49:38<2:19:49,  1.88s/it] 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [49:40<2:19:19,  1.88s/it]                                                     {'loss': 0.085, 'grad_norm': 8.129316329956055, 'learning_rate': 7.549152542372881e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [49:40<2:19:19,  1.88s/it] 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [49:42<2:18:50,  1.87s/it]                                                     {'loss': 0.0102, 'grad_norm': 1.3756346702575684, 'learning_rate': 7.5474576271186455e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [49:42<2:18:50,  1.87s/it] 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [49:44<2:18:07,  1.86s/it]                                                     {'loss': 0.043, 'grad_norm': 4.032196998596191, 'learning_rate': 7.545762711864407e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [49:44<2:18:07,  1.86s/it] 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [49:45<2:19:02,  1.87s/it]                                                     {'loss': 0.0599, 'grad_norm': 8.82633113861084, 'learning_rate': 7.54406779661017e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [49:45<2:19:02,  1.87s/it] 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [49:47<2:19:54,  1.89s/it]                                                     {'loss': 0.0161, 'grad_norm': 1.204201579093933, 'learning_rate': 7.542372881355933e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [49:47<2:19:54,  1.89s/it][2025-11-11 22:43:03,262] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1550
[2025-11-11 22:43:03,269] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:43:03,539] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1550/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [49:50<2:36:36,  2.11s/it]                                                     {'loss': 0.0198, 'grad_norm': 0.7995350360870361, 'learning_rate': 7.540677966101696e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [49:50<2:36:36,  2.11s/it] 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [49:52<2:31:31,  2.04s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.9547420740127563, 'learning_rate': 7.5389830508474584e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [49:52<2:31:31,  2.04s/it] 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [49:54<2:26:36,  1.98s/it]                                                     {'loss': 0.1013, 'grad_norm': 4.47955846786499, 'learning_rate': 7.537288135593222e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [49:54<2:26:36,  1.98s/it] 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [49:56<2:24:38,  1.95s/it]                                                     {'loss': 0.0831, 'grad_norm': 5.6589579582214355, 'learning_rate': 7.535593220338983e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [49:56<2:24:38,  1.95s/it] 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [49:57<2:21:30,  1.91s/it]                                                     {'loss': 0.0528, 'grad_norm': 3.8500638008117676, 'learning_rate': 7.533898305084746e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [49:57<2:21:30,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [49:59<2:19:39,  1.89s/it]                                                     {'loss': 0.0121, 'grad_norm': 1.7342671155929565, 'learning_rate': 7.532203389830509e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [49:59<2:19:39,  1.89s/it] 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [50:01<2:23:21,  1.94s/it]                                                     {'loss': 0.0506, 'grad_norm': 3.780302047729492, 'learning_rate': 7.5305084745762714e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [50:01<2:23:21,  1.94s/it] 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [50:03<2:22:05,  1.92s/it]                                                     {'loss': 0.0715, 'grad_norm': 3.8852362632751465, 'learning_rate': 7.528813559322035e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [50:03<2:22:05,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [50:05<2:24:27,  1.95s/it]                                                     {'loss': 0.0086, 'grad_norm': 1.4705257415771484, 'learning_rate': 7.527118644067797e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [50:05<2:24:27,  1.95s/it] 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [50:07<2:22:02,  1.92s/it]                                                     {'loss': 0.0495, 'grad_norm': 3.0307278633117676, 'learning_rate': 7.52542372881356e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [50:07<2:22:02,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [50:09<2:21:01,  1.91s/it]                                                     {'loss': 0.0513, 'grad_norm': 1.3485677242279053, 'learning_rate': 7.523728813559322e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [50:09<2:21:01,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [50:11<2:20:55,  1.91s/it]                                                     {'loss': 0.0131, 'grad_norm': 0.9325070977210999, 'learning_rate': 7.522033898305085e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [50:11<2:20:55,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [50:13<2:19:28,  1.89s/it]                                                     {'loss': 0.0484, 'grad_norm': 4.75478982925415, 'learning_rate': 7.520338983050848e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [50:13<2:19:28,  1.89s/it] 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [50:15<2:20:49,  1.90s/it]                                                     {'loss': 0.0825, 'grad_norm': 5.726593971252441, 'learning_rate': 7.518644067796611e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [50:15<2:20:49,  1.90s/it] 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [50:16<2:19:49,  1.89s/it]                                                     {'loss': 0.0058, 'grad_norm': 1.4906938076019287, 'learning_rate': 7.516949152542373e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [50:16<2:19:49,  1.89s/it] 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [50:18<2:21:32,  1.92s/it]                                                     {'loss': 0.0272, 'grad_norm': 2.783722400665283, 'learning_rate': 7.515254237288137e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [50:18<2:21:32,  1.92s/it] 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [50:20<2:23:55,  1.95s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.2857937216758728, 'learning_rate': 7.513559322033899e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [50:20<2:23:55,  1.95s/it] 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [50:22<2:21:26,  1.91s/it]                                                     {'loss': 0.0175, 'grad_norm': 1.7125942707061768, 'learning_rate': 7.511864406779662e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [50:22<2:21:26,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [50:24<2:20:51,  1.91s/it]                                                     {'loss': 0.135, 'grad_norm': 9.344398498535156, 'learning_rate': 7.510169491525424e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [50:24<2:20:51,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [50:26<2:21:23,  1.91s/it]                                                     {'loss': 0.1845, 'grad_norm': 9.056194305419922, 'learning_rate': 7.508474576271187e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [50:26<2:21:23,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [50:28<2:21:17,  1.91s/it]                                                     {'loss': 0.0949, 'grad_norm': 3.0109171867370605, 'learning_rate': 7.50677966101695e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [50:28<2:21:17,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [50:30<2:21:17,  1.91s/it]                                                     {'loss': 0.1302, 'grad_norm': 8.543781280517578, 'learning_rate': 7.505084745762713e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [50:30<2:21:17,  1.91s/it] 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [50:32<2:20:16,  1.90s/it]                                                     {'loss': 0.0156, 'grad_norm': 1.2952960729599, 'learning_rate': 7.503389830508475e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [50:32<2:20:16,  1.90s/it] 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [50:34<2:20:48,  1.91s/it]                                                     {'loss': 0.0553, 'grad_norm': 5.804090976715088, 'learning_rate': 7.501694915254239e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [50:34<2:20:48,  1.91s/it] 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [50:36<2:19:55,  1.90s/it]                                                     {'loss': 0.0525, 'grad_norm': 5.661253452301025, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [50:36<2:19:55,  1.90s/it] 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [50:38<2:20:30,  1.91s/it]                                                     {'loss': 0.0251, 'grad_norm': 3.529075860977173, 'learning_rate': 7.498305084745763e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [50:38<2:20:30,  1.91s/it] 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [50:39<2:19:36,  1.89s/it]                                                     {'loss': 0.224, 'grad_norm': 9.864409446716309, 'learning_rate': 7.496610169491526e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [50:39<2:19:36,  1.89s/it] 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [50:41<2:19:27,  1.89s/it]                                                     {'loss': 0.0072, 'grad_norm': 1.6865535974502563, 'learning_rate': 7.494915254237288e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [50:41<2:19:27,  1.89s/it] 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [50:43<2:19:35,  1.89s/it]                                                     {'loss': 0.0116, 'grad_norm': 2.0237016677856445, 'learning_rate': 7.493220338983052e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [50:43<2:19:35,  1.89s/it] 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [50:45<2:18:21,  1.88s/it]                                                     {'loss': 0.121, 'grad_norm': 5.0965681076049805, 'learning_rate': 7.491525423728814e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [50:45<2:18:21,  1.88s/it] 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [50:47<2:21:32,  1.92s/it]                                                     {'loss': 0.0036, 'grad_norm': 0.4203856587409973, 'learning_rate': 7.489830508474577e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [50:47<2:21:32,  1.92s/it] 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [50:49<2:20:52,  1.91s/it]                                                     {'loss': 0.1651, 'grad_norm': 9.946185111999512, 'learning_rate': 7.488135593220339e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [50:49<2:20:52,  1.91s/it] 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [50:51<2:19:31,  1.90s/it]                                                     {'loss': 0.0224, 'grad_norm': 1.6696621179580688, 'learning_rate': 7.486440677966102e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [50:51<2:19:31,  1.90s/it] 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [50:53<2:18:19,  1.88s/it]                                                     {'loss': 0.0175, 'grad_norm': 2.778118133544922, 'learning_rate': 7.4847457627118646e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [50:53<2:18:19,  1.88s/it] 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [50:55<2:18:20,  1.88s/it]                                                     {'loss': 0.136, 'grad_norm': 9.579482078552246, 'learning_rate': 7.483050847457628e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [50:55<2:18:20,  1.88s/it] 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [50:56<2:17:43,  1.87s/it]                                                     {'loss': 0.0749, 'grad_norm': 6.281518936157227, 'learning_rate': 7.48135593220339e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [50:56<2:17:43,  1.87s/it] 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [50:58<2:18:34,  1.88s/it]                                                     {'loss': 0.0345, 'grad_norm': 4.421245574951172, 'learning_rate': 7.4796610169491535e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [50:58<2:18:34,  1.88s/it] 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [51:00<2:17:55,  1.88s/it]                                                     {'loss': 0.0253, 'grad_norm': 4.261903762817383, 'learning_rate': 7.477966101694916e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [51:00<2:17:55,  1.88s/it] 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [51:02<2:20:09,  1.91s/it]                                                     {'loss': 0.001, 'grad_norm': 0.16508500277996063, 'learning_rate': 7.476271186440679e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [51:02<2:20:09,  1.91s/it] 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [51:04<2:18:12,  1.88s/it]                                                     {'loss': 0.0111, 'grad_norm': 2.2096307277679443, 'learning_rate': 7.474576271186441e-06, 'epoch': 0.27}
 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [51:04<2:18:12,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [51:06<2:17:47,  1.88s/it]                                                     {'loss': 0.0707, 'grad_norm': 5.994531154632568, 'learning_rate': 7.472881355932204e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [51:06<2:17:47,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [51:08<2:17:30,  1.87s/it]                                                     {'loss': 0.0321, 'grad_norm': 2.208881378173828, 'learning_rate': 7.4711864406779665e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [51:08<2:17:30,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [51:10<2:17:23,  1.87s/it]                                                     {'loss': 0.0174, 'grad_norm': 2.3271095752716064, 'learning_rate': 7.46949152542373e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [51:10<2:17:23,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [51:11<2:17:12,  1.87s/it]                                                     {'loss': 0.0271, 'grad_norm': 3.9946389198303223, 'learning_rate': 7.467796610169492e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [51:11<2:17:12,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [51:13<2:17:46,  1.88s/it]                                                     {'loss': 0.0469, 'grad_norm': 8.126774787902832, 'learning_rate': 7.4661016949152555e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [51:13<2:17:46,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [51:15<2:17:47,  1.88s/it]                                                     {'loss': 0.1153, 'grad_norm': 6.223846435546875, 'learning_rate': 7.464406779661018e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [51:15<2:17:47,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [51:17<2:18:28,  1.89s/it]                                                     {'loss': 0.0607, 'grad_norm': 4.2892069816589355, 'learning_rate': 7.4627118644067795e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [51:17<2:18:28,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [51:19<2:17:53,  1.88s/it]                                                     {'loss': 0.2408, 'grad_norm': 6.881213665008545, 'learning_rate': 7.461016949152543e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [51:19<2:17:53,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [51:21<2:17:28,  1.87s/it]                                                     {'loss': 0.1727, 'grad_norm': 10.838958740234375, 'learning_rate': 7.459322033898305e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [51:21<2:17:28,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [51:23<2:18:12,  1.88s/it]                                                     {'loss': 0.08, 'grad_norm': 3.8149547576904297, 'learning_rate': 7.4576271186440685e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [51:23<2:18:12,  1.88s/it][2025-11-11 22:44:38,635] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600
[2025-11-11 22:44:38,642] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:44:38,946] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [51:25<2:35:39,  2.12s/it]                                                     {'loss': 0.0182, 'grad_norm': 2.8645455837249756, 'learning_rate': 7.455932203389831e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [51:25<2:35:39,  2.12s/it] 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [51:27<2:33:25,  2.09s/it]                                                     {'loss': 0.1145, 'grad_norm': 8.446782112121582, 'learning_rate': 7.454237288135594e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [51:27<2:33:25,  2.09s/it] 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [51:29<2:30:46,  2.06s/it]                                                     {'loss': 0.0472, 'grad_norm': 4.396223068237305, 'learning_rate': 7.452542372881356e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [51:29<2:30:46,  2.06s/it] 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [51:32<2:33:22,  2.09s/it]                                                     {'loss': 0.1256, 'grad_norm': 6.723392963409424, 'learning_rate': 7.45084745762712e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [51:32<2:33:22,  2.09s/it] 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [51:34<2:32:08,  2.08s/it]                                                     {'loss': 0.0558, 'grad_norm': 3.5800557136535645, 'learning_rate': 7.4491525423728815e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [51:34<2:32:08,  2.08s/it] 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [51:35<2:26:43,  2.00s/it]                                                     {'loss': 0.0143, 'grad_norm': 1.617849588394165, 'learning_rate': 7.447457627118645e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [51:35<2:26:43,  2.00s/it] 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [51:37<2:23:45,  1.96s/it]                                                     {'loss': 0.0203, 'grad_norm': 2.223422050476074, 'learning_rate': 7.445762711864407e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [51:37<2:23:45,  1.96s/it] 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [51:39<2:24:44,  1.98s/it]                                                     {'loss': 0.1337, 'grad_norm': 6.961744785308838, 'learning_rate': 7.4440677966101704e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [51:39<2:24:44,  1.98s/it] 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [51:41<2:22:14,  1.94s/it]                                                     {'loss': 0.0877, 'grad_norm': 8.505824089050293, 'learning_rate': 7.442372881355933e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [51:41<2:22:14,  1.94s/it] 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [51:43<2:20:31,  1.92s/it]                                                     {'loss': 0.0259, 'grad_norm': 4.516302108764648, 'learning_rate': 7.440677966101696e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [51:43<2:20:31,  1.92s/it] 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [51:45<2:19:53,  1.91s/it]                                                     {'loss': 0.0658, 'grad_norm': 5.072999954223633, 'learning_rate': 7.438983050847458e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [51:45<2:19:53,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [51:47<2:18:22,  1.89s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.03196626901626587, 'learning_rate': 7.437288135593221e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [51:47<2:18:22,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [51:49<2:17:11,  1.88s/it]                                                     {'loss': 0.1885, 'grad_norm': 11.173739433288574, 'learning_rate': 7.435593220338983e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [51:49<2:17:11,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [51:51<2:18:09,  1.89s/it]                                                     {'loss': 0.118, 'grad_norm': 6.743349075317383, 'learning_rate': 7.433898305084747e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [51:51<2:18:09,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [51:52<2:17:21,  1.88s/it]                                                     {'loss': 0.0624, 'grad_norm': 4.907603740692139, 'learning_rate': 7.432203389830509e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [51:52<2:17:21,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [51:54<2:18:18,  1.89s/it]                                                     {'loss': 0.037, 'grad_norm': 2.770414352416992, 'learning_rate': 7.430508474576272e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [51:54<2:18:18,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [51:56<2:20:17,  1.92s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.06300389021635056, 'learning_rate': 7.428813559322035e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [51:56<2:20:17,  1.92s/it] 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [51:58<2:21:16,  1.93s/it]                                                     {'loss': 0.0266, 'grad_norm': 2.841888427734375, 'learning_rate': 7.427118644067796e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [51:58<2:21:16,  1.93s/it] 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [52:00<2:20:44,  1.93s/it]                                                     {'loss': 0.0233, 'grad_norm': 3.2216250896453857, 'learning_rate': 7.42542372881356e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [52:00<2:20:44,  1.93s/it] 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [52:02<2:20:38,  1.93s/it]                                                     {'loss': 0.0465, 'grad_norm': 3.694786310195923, 'learning_rate': 7.423728813559322e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [52:02<2:20:38,  1.93s/it] 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [52:04<2:22:33,  1.95s/it]                                                     {'loss': 0.0795, 'grad_norm': 7.669760704040527, 'learning_rate': 7.422033898305085e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [52:04<2:22:33,  1.95s/it] 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [52:06<2:19:43,  1.91s/it]                                                     {'loss': 0.1326, 'grad_norm': 9.858285903930664, 'learning_rate': 7.420338983050848e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [52:06<2:19:43,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [52:08<2:19:20,  1.91s/it]                                                     {'loss': 0.0731, 'grad_norm': 7.60205078125, 'learning_rate': 7.418644067796611e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [52:08<2:19:20,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [52:10<2:18:56,  1.91s/it]                                                     {'loss': 0.1477, 'grad_norm': 8.005661964416504, 'learning_rate': 7.4169491525423735e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [52:10<2:18:56,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [52:12<2:18:46,  1.90s/it]                                                     {'loss': 0.0398, 'grad_norm': 2.1014902591705322, 'learning_rate': 7.415254237288137e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [52:12<2:18:46,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [52:14<2:17:50,  1.89s/it]                                                     {'loss': 0.0202, 'grad_norm': 1.7717784643173218, 'learning_rate': 7.413559322033898e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [52:14<2:17:50,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [52:15<2:17:25,  1.89s/it]                                                     {'loss': 0.0217, 'grad_norm': 2.0953280925750732, 'learning_rate': 7.411864406779662e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [52:15<2:17:25,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [52:17<2:18:42,  1.90s/it]                                                     {'loss': 0.0804, 'grad_norm': 7.8629021644592285, 'learning_rate': 7.410169491525424e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [52:17<2:18:42,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [52:19<2:18:27,  1.90s/it]                                                     {'loss': 0.0541, 'grad_norm': 6.756565093994141, 'learning_rate': 7.408474576271187e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [52:19<2:18:27,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [52:21<2:18:53,  1.91s/it]                                                     {'loss': 0.1922, 'grad_norm': 8.903708457946777, 'learning_rate': 7.40677966101695e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [52:21<2:18:53,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [52:23<2:19:50,  1.92s/it]                                                     {'loss': 0.1258, 'grad_norm': 9.225951194763184, 'learning_rate': 7.405084745762713e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [52:23<2:19:50,  1.92s/it] 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [52:25<2:18:24,  1.90s/it]                                                     {'loss': 0.134, 'grad_norm': 9.815528869628906, 'learning_rate': 7.4033898305084754e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [52:25<2:18:24,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [52:27<2:16:51,  1.88s/it]                                                     {'loss': 0.0997, 'grad_norm': 5.309406757354736, 'learning_rate': 7.401694915254239e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [52:27<2:16:51,  1.88s/it] 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [52:29<2:16:15,  1.87s/it]                                                     {'loss': 0.1664, 'grad_norm': 7.346115589141846, 'learning_rate': 7.4e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [52:29<2:16:15,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [52:31<2:19:20,  1.92s/it]                                                     {'loss': 0.1394, 'grad_norm': 11.587061882019043, 'learning_rate': 7.3983050847457636e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [52:31<2:19:20,  1.92s/it] 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [52:33<2:19:32,  1.92s/it]                                                     {'loss': 0.1365, 'grad_norm': 9.796624183654785, 'learning_rate': 7.396610169491526e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [52:33<2:19:32,  1.92s/it] 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [52:34<2:18:50,  1.91s/it]                                                     {'loss': 0.0591, 'grad_norm': 5.606431484222412, 'learning_rate': 7.394915254237289e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [52:34<2:18:50,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [52:36<2:17:57,  1.90s/it]                                                     {'loss': 0.0161, 'grad_norm': 2.170722723007202, 'learning_rate': 7.393220338983052e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [52:36<2:17:57,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [52:38<2:17:47,  1.90s/it]                                                     {'loss': 0.0106, 'grad_norm': 0.8133485913276672, 'learning_rate': 7.391525423728813e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [52:38<2:17:47,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [52:40<2:17:05,  1.89s/it]                                                     {'loss': 0.0958, 'grad_norm': 6.863161087036133, 'learning_rate': 7.3898305084745766e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [52:40<2:17:05,  1.89s/it] 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [52:42<2:18:50,  1.91s/it]                                                     {'loss': 0.0945, 'grad_norm': 6.263362407684326, 'learning_rate': 7.388135593220339e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [52:42<2:18:50,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [52:44<2:17:49,  1.90s/it]                                                     {'loss': 0.074, 'grad_norm': 6.664921283721924, 'learning_rate': 7.386440677966102e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [52:44<2:17:49,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [52:46<2:20:41,  1.94s/it]                                                     {'loss': 0.1709, 'grad_norm': 11.150327682495117, 'learning_rate': 7.384745762711865e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [52:46<2:20:41,  1.94s/it] 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [52:48<2:18:28,  1.91s/it]                                                     {'loss': 0.0352, 'grad_norm': 3.1070268154144287, 'learning_rate': 7.383050847457628e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [52:48<2:18:28,  1.91s/it] 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [52:50<2:17:38,  1.90s/it]                                                     {'loss': 0.0325, 'grad_norm': 3.429520845413208, 'learning_rate': 7.38135593220339e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [52:50<2:17:38,  1.90s/it] 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [52:51<2:15:38,  1.87s/it]                                                     {'loss': 0.387, 'grad_norm': 12.98579216003418, 'learning_rate': 7.379661016949154e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [52:51<2:15:38,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [52:53<2:15:27,  1.87s/it]                                                     {'loss': 0.0405, 'grad_norm': 6.377885818481445, 'learning_rate': 7.377966101694915e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [52:53<2:15:27,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [52:55<2:15:47,  1.87s/it]                                                     {'loss': 0.484, 'grad_norm': 8.365787506103516, 'learning_rate': 7.3762711864406785e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [52:55<2:15:47,  1.87s/it] 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [52:57<2:15:13,  1.86s/it]                                                     {'loss': 0.1223, 'grad_norm': 6.210747241973877, 'learning_rate': 7.374576271186441e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [52:57<2:15:13,  1.86s/it] 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [52:59<2:15:34,  1.87s/it]                                                     {'loss': 0.1779, 'grad_norm': 7.898908615112305, 'learning_rate': 7.372881355932204e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [52:59<2:15:34,  1.87s/it][2025-11-11 22:46:14,871] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1650
[2025-11-11 22:46:14,878] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:46:15,171] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1650/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [53:02<2:31:54,  2.10s/it]                                                     {'loss': 0.0253, 'grad_norm': 5.313301086425781, 'learning_rate': 7.371186440677967e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [53:02<2:31:54,  2.10s/it] 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [53:04<2:33:12,  2.11s/it]                                                     {'loss': 0.001, 'grad_norm': 0.152251198887825, 'learning_rate': 7.36949152542373e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [53:04<2:33:12,  2.11s/it] 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [53:06<2:28:08,  2.04s/it]                                                     {'loss': 0.224, 'grad_norm': 9.255502700805664, 'learning_rate': 7.367796610169492e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [53:06<2:28:08,  2.04s/it] 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [53:08<2:24:47,  2.00s/it]                                                     {'loss': 0.014, 'grad_norm': 2.478030204772949, 'learning_rate': 7.366101694915256e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [53:08<2:24:47,  2.00s/it] 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [53:09<2:23:54,  1.99s/it]                                                     {'loss': 0.0123, 'grad_norm': 1.3197822570800781, 'learning_rate': 7.364406779661017e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [53:09<2:23:54,  1.99s/it] 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [53:11<2:22:17,  1.97s/it]                                                     {'loss': 0.0145, 'grad_norm': 1.805470585823059, 'learning_rate': 7.3627118644067805e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [53:11<2:22:17,  1.97s/it] 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [53:13<2:21:31,  1.96s/it]                                                     {'loss': 0.0089, 'grad_norm': 1.1115529537200928, 'learning_rate': 7.361016949152543e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [53:13<2:21:31,  1.96s/it] 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [53:15<2:18:38,  1.92s/it]                                                     {'loss': 0.0673, 'grad_norm': 4.4799981117248535, 'learning_rate': 7.359322033898306e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [53:15<2:18:38,  1.92s/it] 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [53:18<2:28:25,  2.05s/it]                                                     {'loss': 0.1077, 'grad_norm': 9.438989639282227, 'learning_rate': 7.357627118644069e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [53:18<2:28:25,  2.05s/it] 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [53:19<2:25:13,  2.01s/it]                                                     {'loss': 0.1225, 'grad_norm': 6.793837070465088, 'learning_rate': 7.355932203389831e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [53:19<2:25:13,  2.01s/it] 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [53:21<2:22:20,  1.97s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.5936311483383179, 'learning_rate': 7.354237288135594e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [53:21<2:22:20,  1.97s/it] 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [53:23<2:20:32,  1.94s/it]                                                     {'loss': 0.0971, 'grad_norm': 6.7459306716918945, 'learning_rate': 7.352542372881356e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [53:23<2:20:32,  1.94s/it] 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [53:25<2:18:44,  1.92s/it]                                                     {'loss': 0.0477, 'grad_norm': 10.077528953552246, 'learning_rate': 7.350847457627119e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [53:25<2:18:44,  1.92s/it] 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [53:27<2:18:38,  1.92s/it]                                                     {'loss': 0.0756, 'grad_norm': 7.2488813400268555, 'learning_rate': 7.3491525423728816e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [53:27<2:18:38,  1.92s/it] 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [53:29<2:17:13,  1.90s/it]                                                     {'loss': 0.072, 'grad_norm': 4.126979827880859, 'learning_rate': 7.347457627118645e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [53:29<2:17:13,  1.90s/it] 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [53:31<2:17:53,  1.91s/it]                                                     {'loss': 0.033, 'grad_norm': 4.441445350646973, 'learning_rate': 7.345762711864407e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [53:31<2:17:53,  1.91s/it] 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [53:33<2:19:19,  1.93s/it]                                                     {'loss': 0.0109, 'grad_norm': 1.8678580522537231, 'learning_rate': 7.3440677966101705e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [53:33<2:19:19,  1.93s/it] 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [53:35<2:18:19,  1.92s/it]                                                     {'loss': 0.0669, 'grad_norm': 7.350969314575195, 'learning_rate': 7.342372881355932e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [53:35<2:18:19,  1.92s/it] 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [53:36<2:17:36,  1.91s/it]                                                     {'loss': 0.0049, 'grad_norm': 0.6777001619338989, 'learning_rate': 7.340677966101695e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [53:36<2:17:36,  1.91s/it] 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [53:38<2:16:03,  1.89s/it]                                                     {'loss': 0.3027, 'grad_norm': 11.271199226379395, 'learning_rate': 7.338983050847458e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [53:38<2:16:03,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [53:40<2:15:13,  1.87s/it]                                                     {'loss': 0.0686, 'grad_norm': 3.945516347885132, 'learning_rate': 7.337288135593221e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [53:40<2:15:13,  1.87s/it] 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [53:42<2:17:12,  1.90s/it]                                                     {'loss': 0.1301, 'grad_norm': 10.142789840698242, 'learning_rate': 7.3355932203389835e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [53:42<2:17:12,  1.90s/it] 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [53:44<2:16:11,  1.89s/it]                                                     {'loss': 0.0263, 'grad_norm': 2.5844078063964844, 'learning_rate': 7.333898305084747e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [53:44<2:16:11,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [53:46<2:16:34,  1.89s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.8138673305511475, 'learning_rate': 7.332203389830509e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [53:46<2:16:34,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [53:48<2:16:43,  1.90s/it]                                                     {'loss': 0.0829, 'grad_norm': 4.231626510620117, 'learning_rate': 7.3305084745762725e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [53:48<2:16:43,  1.90s/it] 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [53:50<2:15:36,  1.88s/it]                                                     {'loss': 0.0142, 'grad_norm': 2.004892110824585, 'learning_rate': 7.328813559322034e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [53:50<2:15:36,  1.88s/it] 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [53:52<2:14:58,  1.87s/it]                                                     {'loss': 0.0106, 'grad_norm': 1.0712074041366577, 'learning_rate': 7.327118644067797e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [53:52<2:14:58,  1.87s/it] 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [53:53<2:14:03,  1.86s/it]                                                     {'loss': 0.0874, 'grad_norm': 7.929945468902588, 'learning_rate': 7.32542372881356e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [53:53<2:14:03,  1.86s/it] 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [53:56<2:20:58,  1.96s/it]                                                     {'loss': 0.003, 'grad_norm': 0.41987693309783936, 'learning_rate': 7.323728813559322e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [53:56<2:20:58,  1.96s/it] 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [53:57<2:19:32,  1.94s/it]                                                     {'loss': 0.0294, 'grad_norm': 4.0304718017578125, 'learning_rate': 7.3220338983050855e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [53:57<2:19:32,  1.94s/it] 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [53:59<2:17:45,  1.91s/it]                                                     {'loss': 0.1155, 'grad_norm': 6.468949317932129, 'learning_rate': 7.320338983050848e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [53:59<2:17:45,  1.91s/it] 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [54:01<2:16:14,  1.89s/it]                                                     {'loss': 0.0066, 'grad_norm': 0.9052649736404419, 'learning_rate': 7.318644067796611e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [54:01<2:16:14,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [54:03<2:15:18,  1.88s/it]                                                     {'loss': 0.0127, 'grad_norm': 1.9296053647994995, 'learning_rate': 7.316949152542373e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [54:03<2:15:18,  1.88s/it] 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [54:05<2:15:24,  1.88s/it]                                                     {'loss': 0.0471, 'grad_norm': 5.440042018890381, 'learning_rate': 7.315254237288136e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [54:05<2:15:24,  1.88s/it] 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [54:07<2:15:35,  1.89s/it]                                                     {'loss': 0.0409, 'grad_norm': 5.073184967041016, 'learning_rate': 7.3135593220338985e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [54:07<2:15:35,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [54:09<2:15:36,  1.89s/it]                                                     {'loss': 0.0079, 'grad_norm': 1.336902141571045, 'learning_rate': 7.311864406779662e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [54:09<2:15:36,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [54:11<2:22:34,  1.98s/it]                                                     {'loss': 0.0544, 'grad_norm': 5.669973373413086, 'learning_rate': 7.310169491525424e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [54:11<2:22:34,  1.98s/it] 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [54:13<2:20:20,  1.95s/it]                                                     {'loss': 0.1337, 'grad_norm': 6.958963871002197, 'learning_rate': 7.3084745762711874e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [54:13<2:20:20,  1.95s/it] 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [54:15<2:19:20,  1.94s/it]                                                     {'loss': 0.0278, 'grad_norm': 2.0140724182128906, 'learning_rate': 7.30677966101695e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [54:15<2:19:20,  1.94s/it] 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [54:17<2:18:56,  1.93s/it]                                                     {'loss': 0.2028, 'grad_norm': 10.10360050201416, 'learning_rate': 7.305084745762713e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [54:17<2:18:56,  1.93s/it] 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [54:18<2:18:13,  1.92s/it]                                                     {'loss': 0.0087, 'grad_norm': 1.1705878973007202, 'learning_rate': 7.303389830508475e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [54:18<2:18:13,  1.92s/it] 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [54:20<2:19:09,  1.94s/it]                                                     {'loss': 0.0503, 'grad_norm': 4.116386890411377, 'learning_rate': 7.301694915254238e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [54:20<2:19:09,  1.94s/it] 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [54:22<2:20:01,  1.95s/it]                                                     {'loss': 0.1986, 'grad_norm': 7.836158275604248, 'learning_rate': 7.3e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [54:22<2:20:01,  1.95s/it] 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [54:24<2:18:49,  1.93s/it]                                                     {'loss': 0.1029, 'grad_norm': 6.926269054412842, 'learning_rate': 7.298305084745764e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [54:24<2:18:49,  1.93s/it] 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [54:26<2:18:30,  1.93s/it]                                                     {'loss': 0.0206, 'grad_norm': 2.6977920532226562, 'learning_rate': 7.296610169491526e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [54:26<2:18:30,  1.93s/it] 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [54:28<2:16:55,  1.91s/it]                                                     {'loss': 0.1205, 'grad_norm': 4.502592086791992, 'learning_rate': 7.294915254237289e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [54:28<2:16:55,  1.91s/it] 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [54:30<2:16:03,  1.90s/it]                                                     {'loss': 0.1318, 'grad_norm': 4.808676719665527, 'learning_rate': 7.293220338983051e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [54:30<2:16:03,  1.90s/it] 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [54:32<2:19:12,  1.94s/it]                                                     {'loss': 0.2198, 'grad_norm': 10.367490768432617, 'learning_rate': 7.291525423728815e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [54:32<2:19:12,  1.94s/it] 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [54:34<2:17:34,  1.92s/it]                                                     {'loss': 0.0913, 'grad_norm': 9.190055847167969, 'learning_rate': 7.289830508474577e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [54:34<2:17:34,  1.92s/it] 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [54:36<2:16:12,  1.90s/it]                                                     {'loss': 0.0638, 'grad_norm': 5.056413650512695, 'learning_rate': 7.288135593220339e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [54:36<2:16:12,  1.90s/it][2025-11-11 22:47:51,637] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700
[2025-11-11 22:47:51,644] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:47:51,928] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [54:38<2:32:42,  2.13s/it]                                                     {'loss': 0.3058, 'grad_norm': 8.911266326904297, 'learning_rate': 7.286440677966102e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [54:38<2:32:42,  2.13s/it] 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [54:40<2:27:32,  2.06s/it]                                                     {'loss': 0.0123, 'grad_norm': 1.6310811042785645, 'learning_rate': 7.284745762711865e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [54:40<2:27:32,  2.06s/it] 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [54:42<2:24:35,  2.02s/it]                                                     {'loss': 0.3616, 'grad_norm': 11.915262222290039, 'learning_rate': 7.283050847457628e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [54:42<2:24:35,  2.02s/it] 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [54:44<2:21:56,  1.98s/it]                                                     {'loss': 0.4113, 'grad_norm': 8.674554824829102, 'learning_rate': 7.28135593220339e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [54:44<2:21:56,  1.98s/it] 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [54:46<2:19:00,  1.94s/it]                                                     {'loss': 0.0785, 'grad_norm': 5.245792865753174, 'learning_rate': 7.279661016949153e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [54:46<2:19:00,  1.94s/it] 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [54:48<2:16:32,  1.91s/it]                                                     {'loss': 0.0394, 'grad_norm': 4.754879474639893, 'learning_rate': 7.277966101694915e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [54:48<2:16:32,  1.91s/it] 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [54:50<2:16:18,  1.91s/it]                                                     {'loss': 0.0104, 'grad_norm': 1.7385817766189575, 'learning_rate': 7.276271186440679e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [54:50<2:16:18,  1.91s/it] 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [54:52<2:16:09,  1.90s/it]                                                     {'loss': 0.0112, 'grad_norm': 1.4281656742095947, 'learning_rate': 7.274576271186441e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [54:52<2:16:09,  1.90s/it] 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [54:53<2:15:09,  1.89s/it]                                                     {'loss': 0.0681, 'grad_norm': 5.377915859222412, 'learning_rate': 7.272881355932204e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [54:53<2:15:09,  1.89s/it] 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [54:55<2:14:45,  1.88s/it]                                                     {'loss': 0.0299, 'grad_norm': 5.010319709777832, 'learning_rate': 7.271186440677967e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [54:55<2:14:45,  1.88s/it] 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [54:57<2:14:40,  1.88s/it]                                                     {'loss': 0.0021, 'grad_norm': 0.2732713222503662, 'learning_rate': 7.26949152542373e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [54:57<2:14:40,  1.88s/it] 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [54:59<2:14:29,  1.88s/it]                                                     {'loss': 0.0327, 'grad_norm': 2.3234996795654297, 'learning_rate': 7.267796610169492e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [54:59<2:14:29,  1.88s/it] 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [55:01<2:13:57,  1.87s/it]                                                     {'loss': 0.0162, 'grad_norm': 1.7083150148391724, 'learning_rate': 7.266101694915255e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [55:01<2:13:57,  1.87s/it] 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [55:03<2:16:25,  1.91s/it]                                                     {'loss': 0.0167, 'grad_norm': 0.9914003610610962, 'learning_rate': 7.264406779661017e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [55:03<2:16:25,  1.91s/it] 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [55:05<2:16:57,  1.92s/it]                                                     {'loss': 0.0234, 'grad_norm': 2.907120943069458, 'learning_rate': 7.2627118644067806e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [55:05<2:16:57,  1.92s/it] 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [55:07<2:15:49,  1.90s/it]                                                     {'loss': 0.1062, 'grad_norm': 6.687580585479736, 'learning_rate': 7.261016949152543e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [55:07<2:15:49,  1.90s/it] 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [55:09<2:17:31,  1.93s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.05404643714427948, 'learning_rate': 7.259322033898306e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [55:09<2:17:31,  1.93s/it] 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [55:11<2:16:05,  1.91s/it]                                                     {'loss': 0.0743, 'grad_norm': 3.7650933265686035, 'learning_rate': 7.257627118644069e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [55:11<2:16:05,  1.91s/it] 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [55:12<2:15:27,  1.90s/it]                                                     {'loss': 0.0198, 'grad_norm': 5.770760536193848, 'learning_rate': 7.255932203389832e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [55:12<2:15:27,  1.90s/it] 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [55:14<2:14:11,  1.88s/it]                                                     {'loss': 0.1014, 'grad_norm': 7.588797092437744, 'learning_rate': 7.2542372881355936e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [55:14<2:14:11,  1.88s/it] 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [55:16<2:14:35,  1.89s/it]                                                     {'loss': 0.0461, 'grad_norm': 6.5487518310546875, 'learning_rate': 7.252542372881356e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [55:16<2:14:35,  1.89s/it] 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [55:18<2:14:45,  1.89s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.9054081439971924, 'learning_rate': 7.250847457627119e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [55:18<2:14:45,  1.89s/it] 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [55:20<2:15:00,  1.89s/it]                                                     {'loss': 0.0622, 'grad_norm': 5.93595027923584, 'learning_rate': 7.249152542372882e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [55:20<2:15:00,  1.89s/it] 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [55:22<2:14:55,  1.89s/it]                                                     {'loss': 0.1067, 'grad_norm': 3.934671401977539, 'learning_rate': 7.247457627118645e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [55:22<2:14:55,  1.89s/it] 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [55:24<2:14:00,  1.88s/it]                                                     {'loss': 0.1242, 'grad_norm': 8.540142059326172, 'learning_rate': 7.2457627118644065e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [55:24<2:14:00,  1.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [55:26<2:13:05,  1.87s/it]                                                     {'loss': 0.0579, 'grad_norm': 8.06393051147461, 'learning_rate': 7.244067796610171e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [55:26<2:13:05,  1.87s/it] 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [55:27<2:13:30,  1.87s/it]                                                     {'loss': 0.0208, 'grad_norm': 2.5792438983917236, 'learning_rate': 7.242372881355932e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [55:27<2:13:30,  1.87s/it] 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [55:29<2:13:49,  1.88s/it]                                                     {'loss': 0.0267, 'grad_norm': 3.8257391452789307, 'learning_rate': 7.2406779661016955e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [55:29<2:13:49,  1.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [55:31<2:14:24,  1.89s/it]                                                     {'loss': 0.1029, 'grad_norm': 6.236942768096924, 'learning_rate': 7.238983050847458e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [55:31<2:14:24,  1.89s/it] 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [55:33<2:14:08,  1.88s/it]                                                     {'loss': 0.0251, 'grad_norm': 2.0198917388916016, 'learning_rate': 7.237288135593221e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [55:33<2:14:08,  1.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [55:35<2:13:58,  1.88s/it]                                                     {'loss': 0.0267, 'grad_norm': 2.5584304332733154, 'learning_rate': 7.235593220338984e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [55:35<2:13:58,  1.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [55:37<2:14:25,  1.89s/it]                                                     {'loss': 0.0049, 'grad_norm': 0.4216642677783966, 'learning_rate': 7.233898305084747e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [55:37<2:14:25,  1.89s/it] 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [55:39<2:18:07,  1.94s/it]                                                     {'loss': 0.0048, 'grad_norm': 0.4550379812717438, 'learning_rate': 7.2322033898305085e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [55:39<2:18:07,  1.94s/it] 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [55:41<2:16:23,  1.92s/it]                                                     {'loss': 0.147, 'grad_norm': 9.668127059936523, 'learning_rate': 7.230508474576272e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [55:41<2:16:23,  1.92s/it] 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [55:43<2:16:33,  1.92s/it]                                                     {'loss': 0.0205, 'grad_norm': 2.6849896907806396, 'learning_rate': 7.228813559322034e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [55:43<2:16:33,  1.92s/it] 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [55:45<2:16:24,  1.92s/it]                                                     {'loss': 0.0095, 'grad_norm': 0.9645645022392273, 'learning_rate': 7.2271186440677975e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [55:45<2:16:24,  1.92s/it] 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [55:47<2:16:57,  1.93s/it]                                                     {'loss': 0.0108, 'grad_norm': 1.2392770051956177, 'learning_rate': 7.22542372881356e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [55:47<2:16:57,  1.93s/it] 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [55:49<2:16:31,  1.92s/it]                                                     {'loss': 0.0155, 'grad_norm': 2.432514190673828, 'learning_rate': 7.223728813559323e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [55:49<2:16:31,  1.92s/it] 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [55:51<2:18:11,  1.95s/it]                                                     {'loss': 0.2003, 'grad_norm': 8.249276161193848, 'learning_rate': 7.222033898305086e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [55:51<2:18:11,  1.95s/it] 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [55:53<2:19:06,  1.96s/it]                                                     {'loss': 0.0512, 'grad_norm': 6.5120415687561035, 'learning_rate': 7.220338983050849e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [55:53<2:19:06,  1.96s/it] 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [55:54<2:16:54,  1.93s/it]                                                     {'loss': 0.0065, 'grad_norm': 1.33393394947052, 'learning_rate': 7.2186440677966104e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [55:54<2:16:54,  1.93s/it] 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [55:56<2:15:46,  1.91s/it]                                                     {'loss': 0.1418, 'grad_norm': 6.48919677734375, 'learning_rate': 7.216949152542373e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [55:56<2:15:46,  1.91s/it] 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [55:58<2:15:09,  1.90s/it]                                                     {'loss': 0.2782, 'grad_norm': 13.128546714782715, 'learning_rate': 7.215254237288136e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [55:58<2:15:09,  1.90s/it] 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [56:00<2:15:16,  1.91s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.93285071849823, 'learning_rate': 7.2135593220338986e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [56:00<2:15:16,  1.91s/it] 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [56:02<2:14:31,  1.90s/it]                                                     {'loss': 0.0349, 'grad_norm': 2.1642963886260986, 'learning_rate': 7.211864406779662e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [56:02<2:14:31,  1.90s/it] 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [56:04<2:13:06,  1.88s/it]                                                     {'loss': 0.0033, 'grad_norm': 0.6506669521331787, 'learning_rate': 7.210169491525424e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [56:04<2:13:06,  1.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [56:06<2:12:49,  1.87s/it]                                                     {'loss': 0.0076, 'grad_norm': 1.5318931341171265, 'learning_rate': 7.2084745762711875e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [56:06<2:12:49,  1.87s/it] 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [56:07<2:12:22,  1.87s/it]                                                     {'loss': 0.0696, 'grad_norm': 5.6418070793151855, 'learning_rate': 7.206779661016949e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [56:07<2:12:22,  1.87s/it] 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [56:09<2:13:17,  1.88s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.21947874128818512, 'learning_rate': 7.205084745762712e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [56:09<2:13:17,  1.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [56:11<2:16:17,  1.92s/it]                                                     {'loss': 0.0369, 'grad_norm': 4.343766212463379, 'learning_rate': 7.203389830508475e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [56:11<2:16:17,  1.92s/it][2025-11-11 22:49:27,348] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1750
[2025-11-11 22:49:27,355] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:49:27,650] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1750/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [56:14<2:34:22,  2.18s/it]                                                     {'loss': 0.0541, 'grad_norm': 6.724704742431641, 'learning_rate': 7.201694915254238e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [56:14<2:34:22,  2.18s/it] 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [56:16<2:28:07,  2.09s/it]                                                     {'loss': 0.1604, 'grad_norm': 11.604266166687012, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [56:16<2:28:07,  2.09s/it] 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [56:18<2:22:46,  2.02s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.7941166758537292, 'learning_rate': 7.198305084745764e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [56:18<2:22:46,  2.02s/it] 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [56:20<2:19:22,  1.97s/it]                                                     {'loss': 0.0251, 'grad_norm': 2.9854109287261963, 'learning_rate': 7.196610169491526e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [56:20<2:19:22,  1.97s/it] 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [56:22<2:18:43,  1.96s/it]                                                     {'loss': 0.0153, 'grad_norm': 2.894843578338623, 'learning_rate': 7.1949152542372895e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [56:22<2:18:43,  1.96s/it] 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [56:24<2:17:11,  1.94s/it]                                                     {'loss': 0.0055, 'grad_norm': 1.073736310005188, 'learning_rate': 7.193220338983051e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [56:24<2:17:11,  1.94s/it] 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [56:25<2:14:39,  1.90s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.5276146531105042, 'learning_rate': 7.191525423728814e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [56:25<2:14:39,  1.90s/it] 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [56:27<2:15:06,  1.91s/it]                                                     {'loss': 0.004, 'grad_norm': 0.8306780457496643, 'learning_rate': 7.189830508474577e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [56:27<2:15:06,  1.91s/it] 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [56:29<2:14:41,  1.91s/it]                                                     {'loss': 0.2598, 'grad_norm': 12.667745590209961, 'learning_rate': 7.18813559322034e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [56:29<2:14:41,  1.91s/it] 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [56:31<2:14:22,  1.90s/it]                                                     {'loss': 0.2099, 'grad_norm': 10.108646392822266, 'learning_rate': 7.1864406779661025e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [56:31<2:14:22,  1.90s/it] 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [56:33<2:13:26,  1.89s/it]                                                     {'loss': 0.029, 'grad_norm': 3.3344693183898926, 'learning_rate': 7.184745762711866e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [56:33<2:13:26,  1.89s/it] 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [56:35<2:16:18,  1.93s/it]                                                     {'loss': 0.0058, 'grad_norm': 0.6650492548942566, 'learning_rate': 7.183050847457627e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [56:35<2:16:18,  1.93s/it] 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [56:37<2:15:34,  1.92s/it]                                                     {'loss': 0.0888, 'grad_norm': 5.919118404388428, 'learning_rate': 7.18135593220339e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [56:37<2:15:34,  1.92s/it] 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [56:39<2:23:04,  2.03s/it]                                                     {'loss': 0.2461, 'grad_norm': 10.124448776245117, 'learning_rate': 7.179661016949153e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [56:39<2:23:04,  2.03s/it] 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [56:42<2:31:00,  2.14s/it]                                                     {'loss': 0.1646, 'grad_norm': 11.765844345092773, 'learning_rate': 7.1779661016949155e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [56:42<2:31:00,  2.14s/it] 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [56:44<2:25:51,  2.07s/it]                                                     {'loss': 0.0346, 'grad_norm': 2.065241813659668, 'learning_rate': 7.176271186440679e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [56:44<2:25:51,  2.07s/it] 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [56:45<2:23:11,  2.03s/it]                                                     {'loss': 0.001, 'grad_norm': 0.1064891666173935, 'learning_rate': 7.174576271186441e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [56:45<2:23:11,  2.03s/it] 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [56:48<2:26:54,  2.08s/it]                                                     {'loss': 0.0912, 'grad_norm': 7.9632673263549805, 'learning_rate': 7.1728813559322044e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [56:48<2:26:54,  2.08s/it] 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [56:50<2:21:57,  2.01s/it]                                                     {'loss': 0.0309, 'grad_norm': 5.173349857330322, 'learning_rate': 7.171186440677966e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [56:50<2:21:57,  2.01s/it] 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [56:51<2:19:55,  1.98s/it]                                                     {'loss': 0.0824, 'grad_norm': 5.107574939727783, 'learning_rate': 7.169491525423729e-06, 'epoch': 0.29}
 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [56:51<2:19:55,  1.98s/it] 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [56:53<2:19:02,  1.97s/it]                                                     {'loss': 0.0447, 'grad_norm': 5.93034029006958, 'learning_rate': 7.167796610169492e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [56:53<2:19:02,  1.97s/it] 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [56:55<2:17:22,  1.95s/it]                                                     {'loss': 0.3367, 'grad_norm': 13.342385292053223, 'learning_rate': 7.166101694915255e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [56:55<2:17:22,  1.95s/it] 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [56:57<2:14:56,  1.92s/it]                                                     {'loss': 0.1429, 'grad_norm': 30.261394500732422, 'learning_rate': 7.164406779661017e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [56:57<2:14:56,  1.92s/it] 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [56:59<2:14:44,  1.91s/it]                                                     {'loss': 0.0496, 'grad_norm': 4.619941711425781, 'learning_rate': 7.162711864406781e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [56:59<2:14:44,  1.91s/it] 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [57:01<2:14:47,  1.91s/it]                                                     {'loss': 0.0867, 'grad_norm': 8.149629592895508, 'learning_rate': 7.161016949152543e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [57:01<2:14:47,  1.91s/it] 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [57:03<2:13:01,  1.89s/it]                                                     {'loss': 0.0566, 'grad_norm': 2.12085223197937, 'learning_rate': 7.159322033898306e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [57:03<2:13:01,  1.89s/it] 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [57:05<2:15:44,  1.93s/it]                                                     {'loss': 0.0435, 'grad_norm': 3.9538285732269287, 'learning_rate': 7.157627118644068e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [57:05<2:15:44,  1.93s/it] 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [57:07<2:16:18,  1.94s/it]                                                     {'loss': 0.1317, 'grad_norm': 9.362136840820312, 'learning_rate': 7.155932203389831e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [57:07<2:16:18,  1.94s/it] 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [57:09<2:14:55,  1.92s/it]                                                     {'loss': 0.033, 'grad_norm': 2.813567876815796, 'learning_rate': 7.154237288135594e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [57:09<2:14:55,  1.92s/it] 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [57:11<2:14:19,  1.91s/it]                                                     {'loss': 0.0313, 'grad_norm': 2.7601795196533203, 'learning_rate': 7.152542372881357e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [57:11<2:14:19,  1.91s/it] 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [57:12<2:13:49,  1.90s/it]                                                     {'loss': 0.015, 'grad_norm': 2.357300281524658, 'learning_rate': 7.150847457627119e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [57:12<2:13:49,  1.90s/it] 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [57:14<2:14:21,  1.91s/it]                                                     {'loss': 0.0379, 'grad_norm': 1.6850900650024414, 'learning_rate': 7.149152542372883e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [57:14<2:14:21,  1.91s/it] 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [57:16<2:13:42,  1.90s/it]                                                     {'loss': 0.0068, 'grad_norm': 0.872364342212677, 'learning_rate': 7.147457627118645e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [57:16<2:13:42,  1.90s/it] 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [57:18<2:13:25,  1.90s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.31323400139808655, 'learning_rate': 7.145762711864407e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [57:18<2:13:25,  1.90s/it] 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [57:20<2:12:38,  1.89s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.9342650771141052, 'learning_rate': 7.14406779661017e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [57:20<2:12:38,  1.89s/it] 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [57:22<2:14:15,  1.91s/it]                                                     {'loss': 0.0801, 'grad_norm': 7.136538505554199, 'learning_rate': 7.142372881355932e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [57:22<2:14:15,  1.91s/it] 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [57:24<2:13:17,  1.90s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.6010213494300842, 'learning_rate': 7.140677966101696e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [57:24<2:13:17,  1.90s/it] 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [57:26<2:12:33,  1.89s/it]                                                     {'loss': 0.0377, 'grad_norm': 4.348280429840088, 'learning_rate': 7.138983050847458e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [57:26<2:12:33,  1.89s/it] 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [57:28<2:11:57,  1.88s/it]                                                     {'loss': 0.0799, 'grad_norm': 6.300746917724609, 'learning_rate': 7.137288135593221e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [57:28<2:11:57,  1.88s/it] 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [57:29<2:11:26,  1.87s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.3831091821193695, 'learning_rate': 7.135593220338983e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [57:29<2:11:26,  1.87s/it] 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [57:31<2:11:18,  1.87s/it]                                                     {'loss': 0.0373, 'grad_norm': 3.8236069679260254, 'learning_rate': 7.133898305084746e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [57:31<2:11:18,  1.87s/it] 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [57:33<2:12:12,  1.89s/it]                                                     {'loss': 0.1551, 'grad_norm': 9.35285758972168, 'learning_rate': 7.132203389830509e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [57:33<2:12:12,  1.89s/it] 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [57:35<2:15:47,  1.94s/it]                                                     {'loss': 0.0148, 'grad_norm': 1.932766318321228, 'learning_rate': 7.130508474576272e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [57:35<2:15:47,  1.94s/it] 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [57:37<2:14:23,  1.92s/it]                                                     {'loss': 0.074, 'grad_norm': 9.534438133239746, 'learning_rate': 7.128813559322034e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [57:37<2:14:23,  1.92s/it] 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [57:39<2:13:44,  1.91s/it]                                                     {'loss': 0.0586, 'grad_norm': 6.922045707702637, 'learning_rate': 7.1271186440677976e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [57:39<2:13:44,  1.91s/it] 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [57:41<2:13:25,  1.90s/it]                                                     {'loss': 0.0254, 'grad_norm': 4.616891860961914, 'learning_rate': 7.12542372881356e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [57:41<2:13:25,  1.90s/it] 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [57:43<2:12:42,  1.89s/it]                                                     {'loss': 0.0118, 'grad_norm': 1.135602355003357, 'learning_rate': 7.123728813559323e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [57:43<2:12:42,  1.89s/it] 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [57:45<2:12:04,  1.89s/it]                                                     {'loss': 0.0333, 'grad_norm': 4.049034595489502, 'learning_rate': 7.122033898305085e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [57:45<2:12:04,  1.89s/it] 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [57:47<2:12:30,  1.89s/it]                                                     {'loss': 0.023, 'grad_norm': 1.0899996757507324, 'learning_rate': 7.120338983050848e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [57:47<2:12:30,  1.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [57:49<2:16:20,  1.95s/it]                                                     {'loss': 0.0075, 'grad_norm': 0.8748311996459961, 'learning_rate': 7.1186440677966106e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [57:49<2:16:20,  1.95s/it][2025-11-11 22:51:04,511] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800
[2025-11-11 22:51:04,518] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:51:04,803] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [57:51<2:30:54,  2.16s/it]                                                     {'loss': 0.0927, 'grad_norm': 10.405275344848633, 'learning_rate': 7.116949152542374e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [57:51<2:30:54,  2.16s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [57:53<2:25:04,  2.07s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.5217069983482361, 'learning_rate': 7.115254237288136e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [57:53<2:25:04,  2.07s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [57:55<2:21:24,  2.02s/it]                                                     {'loss': 0.0545, 'grad_norm': 5.530025482177734, 'learning_rate': 7.1135593220338995e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [57:55<2:21:24,  2.02s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [57:57<2:19:11,  1.99s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.11315790563821793, 'learning_rate': 7.111864406779662e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [57:57<2:19:11,  1.99s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [57:59<2:16:55,  1.96s/it]                                                     {'loss': 0.189, 'grad_norm': 9.088285446166992, 'learning_rate': 7.1101694915254235e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [57:59<2:16:55,  1.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [58:01<2:14:29,  1.92s/it]                                                     {'loss': 0.0805, 'grad_norm': 8.507142066955566, 'learning_rate': 7.108474576271187e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [58:01<2:14:29,  1.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [58:03<2:13:28,  1.91s/it]                                                     {'loss': 0.1838, 'grad_norm': 7.32870626449585, 'learning_rate': 7.106779661016949e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [58:03<2:13:28,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [58:04<2:13:16,  1.91s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.7145736217498779, 'learning_rate': 7.1050847457627125e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [58:04<2:13:16,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [58:06<2:13:10,  1.91s/it]                                                     {'loss': 0.1802, 'grad_norm': 5.870330333709717, 'learning_rate': 7.103389830508475e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [58:06<2:13:10,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [58:08<2:14:28,  1.93s/it]                                                     {'loss': 0.0444, 'grad_norm': 4.571284294128418, 'learning_rate': 7.101694915254238e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [58:08<2:14:28,  1.93s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [58:10<2:13:02,  1.91s/it]                                                     {'loss': 0.0307, 'grad_norm': 3.148298501968384, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [58:10<2:13:02,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [58:12<2:12:33,  1.90s/it]                                                     {'loss': 0.1225, 'grad_norm': 7.413522720336914, 'learning_rate': 7.098305084745764e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [58:12<2:12:33,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [58:14<2:12:33,  1.90s/it]                                                     {'loss': 0.1295, 'grad_norm': 7.6481547355651855, 'learning_rate': 7.0966101694915255e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [58:14<2:12:33,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [58:16<2:12:41,  1.90s/it]                                                     {'loss': 0.0395, 'grad_norm': 4.663239002227783, 'learning_rate': 7.094915254237289e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [58:16<2:12:41,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [58:18<2:12:14,  1.90s/it]                                                     {'loss': 0.0153, 'grad_norm': 3.398822784423828, 'learning_rate': 7.093220338983051e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [58:18<2:12:14,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [58:20<2:12:13,  1.90s/it]                                                     {'loss': 0.194, 'grad_norm': 10.880813598632812, 'learning_rate': 7.0915254237288145e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [58:20<2:12:13,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [58:22<2:11:36,  1.89s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.4059329032897949, 'learning_rate': 7.089830508474577e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [58:22<2:11:36,  1.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [58:23<2:11:56,  1.89s/it]                                                     {'loss': 0.0494, 'grad_norm': 5.4038591384887695, 'learning_rate': 7.08813559322034e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [58:23<2:11:56,  1.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [58:25<2:13:24,  1.91s/it]                                                     {'loss': 0.2516, 'grad_norm': 8.19530963897705, 'learning_rate': 7.086440677966102e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [58:25<2:13:24,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [58:27<2:12:55,  1.91s/it]                                                     {'loss': 0.1102, 'grad_norm': 5.047336578369141, 'learning_rate': 7.084745762711865e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [58:27<2:12:55,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [58:29<2:11:34,  1.89s/it]                                                     {'loss': 0.1331, 'grad_norm': 8.418458938598633, 'learning_rate': 7.0830508474576274e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [58:29<2:11:34,  1.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [58:31<2:11:59,  1.90s/it]                                                     {'loss': 0.1231, 'grad_norm': 8.347722053527832, 'learning_rate': 7.081355932203391e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [58:31<2:11:59,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [58:33<2:11:54,  1.89s/it]                                                     {'loss': 0.0319, 'grad_norm': 2.7256100177764893, 'learning_rate': 7.079661016949153e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [58:33<2:11:54,  1.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [58:35<2:11:27,  1.89s/it]                                                     {'loss': 0.0375, 'grad_norm': 3.6926307678222656, 'learning_rate': 7.077966101694916e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [58:35<2:11:27,  1.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [58:37<2:13:04,  1.91s/it]                                                     {'loss': 0.0504, 'grad_norm': 3.029763698577881, 'learning_rate': 7.076271186440679e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [58:37<2:13:04,  1.91s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [58:39<2:12:09,  1.90s/it]                                                     {'loss': 0.0349, 'grad_norm': 5.789200305938721, 'learning_rate': 7.07457627118644e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [58:39<2:12:09,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [58:41<2:13:21,  1.92s/it]                                                     {'loss': 0.0159, 'grad_norm': 2.968052625656128, 'learning_rate': 7.072881355932204e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [58:41<2:13:21,  1.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [58:42<2:12:20,  1.90s/it]                                                     {'loss': 0.1277, 'grad_norm': 8.133001327514648, 'learning_rate': 7.071186440677966e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [58:42<2:12:20,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [58:44<2:12:02,  1.90s/it]                                                     {'loss': 0.0224, 'grad_norm': 2.3203513622283936, 'learning_rate': 7.069491525423729e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [58:44<2:12:02,  1.90s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [58:46<2:14:51,  1.94s/it]                                                     {'loss': 0.0411, 'grad_norm': 5.496929168701172, 'learning_rate': 7.067796610169492e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [58:46<2:14:51,  1.94s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [58:48<2:14:08,  1.93s/it]                                                     {'loss': 0.0585, 'grad_norm': 6.433787822723389, 'learning_rate': 7.066101694915255e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [58:48<2:14:08,  1.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [58:50<2:13:41,  1.92s/it]                                                     {'loss': 0.0332, 'grad_norm': 5.167464733123779, 'learning_rate': 7.0644067796610175e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [58:50<2:13:41,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [58:52<2:13:06,  1.92s/it]                                                     {'loss': 0.0811, 'grad_norm': 5.3257646560668945, 'learning_rate': 7.062711864406781e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [58:52<2:13:06,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [58:54<2:10:59,  1.89s/it]                                                     {'loss': 0.0199, 'grad_norm': 1.9408553838729858, 'learning_rate': 7.061016949152542e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [58:54<2:10:59,  1.89s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [58:56<2:10:42,  1.88s/it]                                                     {'loss': 0.0039, 'grad_norm': 0.5237458944320679, 'learning_rate': 7.059322033898306e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [58:56<2:10:42,  1.88s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [58:58<2:11:22,  1.89s/it]                                                     {'loss': 0.0139, 'grad_norm': 2.413590908050537, 'learning_rate': 7.057627118644068e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [58:58<2:11:22,  1.89s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [59:00<2:11:59,  1.90s/it]                                                     {'loss': 0.0203, 'grad_norm': 1.9408563375473022, 'learning_rate': 7.055932203389831e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [59:00<2:11:59,  1.90s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [59:02<2:11:49,  1.90s/it]                                                     {'loss': 0.0113, 'grad_norm': 1.445927619934082, 'learning_rate': 7.054237288135594e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [59:02<2:11:49,  1.90s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [59:03<2:12:07,  1.91s/it]                                                     {'loss': 0.0189, 'grad_norm': 2.205411911010742, 'learning_rate': 7.052542372881357e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [59:03<2:12:07,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [59:05<2:14:15,  1.94s/it]                                                     {'loss': 0.0878, 'grad_norm': 7.897795677185059, 'learning_rate': 7.0508474576271195e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [59:05<2:14:15,  1.94s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [59:07<2:13:43,  1.93s/it]                                                     {'loss': 0.399, 'grad_norm': 10.596771240234375, 'learning_rate': 7.049152542372883e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [59:07<2:13:43,  1.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [59:09<2:13:23,  1.92s/it]                                                     {'loss': 0.0509, 'grad_norm': 5.555030345916748, 'learning_rate': 7.047457627118644e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [59:09<2:13:23,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [59:11<2:13:30,  1.93s/it]                                                     {'loss': 0.0248, 'grad_norm': 2.7039573192596436, 'learning_rate': 7.045762711864408e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [59:11<2:13:30,  1.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [59:13<2:12:16,  1.91s/it]                                                     {'loss': 0.0191, 'grad_norm': 2.38191819190979, 'learning_rate': 7.04406779661017e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [59:13<2:12:16,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [59:15<2:13:14,  1.92s/it]                                                     {'loss': 0.0948, 'grad_norm': 5.702704429626465, 'learning_rate': 7.042372881355933e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [59:15<2:13:14,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [59:17<2:13:17,  1.93s/it]                                                     {'loss': 0.0899, 'grad_norm': 6.972128868103027, 'learning_rate': 7.040677966101696e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [59:17<2:13:17,  1.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [59:19<2:12:23,  1.91s/it]                                                     {'loss': 0.2422, 'grad_norm': 7.193845748901367, 'learning_rate': 7.038983050847457e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [59:19<2:12:23,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [59:21<2:11:26,  1.90s/it]                                                     {'loss': 0.0066, 'grad_norm': 0.9895797967910767, 'learning_rate': 7.037288135593221e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [59:21<2:11:26,  1.90s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [59:23<2:11:59,  1.91s/it]                                                     {'loss': 0.0429, 'grad_norm': 3.4688878059387207, 'learning_rate': 7.035593220338983e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [59:23<2:11:59,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [59:25<2:18:38,  2.00s/it]                                                     {'loss': 0.0603, 'grad_norm': 4.3461785316467285, 'learning_rate': 7.033898305084746e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [59:25<2:18:38,  2.00s/it][2025-11-11 22:52:40,802] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1850
[2025-11-11 22:52:40,809] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:52:41,083] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1850/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [59:28<2:31:28,  2.19s/it]                                                     {'loss': 0.1382, 'grad_norm': 9.081565856933594, 'learning_rate': 7.032203389830509e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [59:28<2:31:28,  2.19s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [59:29<2:24:41,  2.09s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.24681416153907776, 'learning_rate': 7.030508474576272e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [59:29<2:24:41,  2.09s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [59:31<2:20:04,  2.03s/it]                                                     {'loss': 0.1039, 'grad_norm': 3.69584321975708, 'learning_rate': 7.028813559322034e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [59:31<2:20:04,  2.03s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [59:33<2:16:07,  1.97s/it]                                                     {'loss': 0.3953, 'grad_norm': 9.824633598327637, 'learning_rate': 7.027118644067798e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [59:33<2:16:07,  1.97s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [59:35<2:13:48,  1.94s/it]                                                     {'loss': 0.0246, 'grad_norm': 2.7149434089660645, 'learning_rate': 7.025423728813559e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [59:35<2:13:48,  1.94s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [59:37<2:12:35,  1.92s/it]                                                     {'loss': 0.082, 'grad_norm': 7.16348934173584, 'learning_rate': 7.0237288135593225e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [59:37<2:12:35,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [59:39<2:19:47,  2.02s/it]                                                     {'loss': 0.0894, 'grad_norm': 7.88869047164917, 'learning_rate': 7.022033898305085e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [59:39<2:19:47,  2.02s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [59:41<2:16:01,  1.97s/it]                                                     {'loss': 0.0337, 'grad_norm': 3.7170910835266113, 'learning_rate': 7.020338983050848e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [59:41<2:16:01,  1.97s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [59:43<2:17:59,  2.00s/it]                                                     {'loss': 0.0108, 'grad_norm': 1.2318590879440308, 'learning_rate': 7.018644067796611e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [59:43<2:17:59,  2.00s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [59:45<2:15:33,  1.96s/it]                                                     {'loss': 0.0635, 'grad_norm': 4.650075435638428, 'learning_rate': 7.016949152542374e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [59:45<2:15:33,  1.96s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [59:47<2:13:49,  1.94s/it]                                                     {'loss': 0.0919, 'grad_norm': 8.574305534362793, 'learning_rate': 7.015254237288136e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [59:47<2:13:49,  1.94s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [59:49<2:19:17,  2.02s/it]                                                     {'loss': 0.0403, 'grad_norm': 5.0319085121154785, 'learning_rate': 7.0135593220339e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [59:49<2:19:17,  2.02s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [59:51<2:16:22,  1.98s/it]                                                     {'loss': 0.0341, 'grad_norm': 4.980693817138672, 'learning_rate': 7.011864406779661e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [59:51<2:16:22,  1.98s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [59:53<2:14:12,  1.95s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.533771812915802, 'learning_rate': 7.0101694915254245e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [59:53<2:14:12,  1.95s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [59:55<2:11:55,  1.91s/it]                                                     {'loss': 0.2474, 'grad_norm': 6.086267471313477, 'learning_rate': 7.008474576271187e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [59:55<2:11:55,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [59:57<2:13:06,  1.93s/it]                                                     {'loss': 0.0115, 'grad_norm': 1.2996171712875366, 'learning_rate': 7.006779661016949e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [59:57<2:13:06,  1.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [59:59<2:13:44,  1.94s/it]                                                     {'loss': 0.0401, 'grad_norm': 5.40092658996582, 'learning_rate': 7.005084745762713e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [59:59<2:13:44,  1.94s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:00:00<2:12:12,  1.92s/it]                                                       {'loss': 0.114, 'grad_norm': 10.450092315673828, 'learning_rate': 7.003389830508475e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:00:00<2:12:12,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:00:02<2:14:01,  1.95s/it]                                                       {'loss': 0.0675, 'grad_norm': 4.469884872436523, 'learning_rate': 7.001694915254238e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:00:02<2:14:01,  1.95s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:00:04<2:12:28,  1.92s/it]                                                       {'loss': 0.0831, 'grad_norm': 5.717063903808594, 'learning_rate': 7e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:00:04<2:12:28,  1.92s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:00:06<2:11:28,  1.91s/it]                                                       {'loss': 0.2699, 'grad_norm': 12.996861457824707, 'learning_rate': 6.998305084745763e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:00:06<2:11:28,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:00:08<2:14:27,  1.95s/it]                                                       {'loss': 0.0706, 'grad_norm': 4.310051441192627, 'learning_rate': 6.996610169491526e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:00:08<2:14:27,  1.95s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:00:10<2:14:32,  1.96s/it]                                                       {'loss': 0.2665, 'grad_norm': 10.514254570007324, 'learning_rate': 6.994915254237289e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:00:10<2:14:32,  1.96s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:00:12<2:13:47,  1.95s/it]                                                       {'loss': 0.0935, 'grad_norm': 6.98429536819458, 'learning_rate': 6.993220338983051e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:00:12<2:13:47,  1.95s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:00:14<2:12:32,  1.93s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.053653597831726, 'learning_rate': 6.9915254237288146e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:00:14<2:12:32,  1.93s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:00:16<2:13:53,  1.95s/it]                                                       {'loss': 0.1166, 'grad_norm': 5.645236492156982, 'learning_rate': 6.989830508474576e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:00:16<2:13:53,  1.95s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:00:18<2:13:32,  1.94s/it]                                                       {'loss': 0.007, 'grad_norm': 0.7446833252906799, 'learning_rate': 6.98813559322034e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:00:18<2:13:32,  1.94s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:00:20<2:11:23,  1.91s/it]                                                       {'loss': 0.0233, 'grad_norm': 3.3318958282470703, 'learning_rate': 6.986440677966102e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:00:20<2:11:23,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:00:22<2:11:04,  1.91s/it]                                                       {'loss': 0.0368, 'grad_norm': 1.7915351390838623, 'learning_rate': 6.984745762711865e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:00:22<2:11:04,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:00:24<2:11:16,  1.91s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.5606366991996765, 'learning_rate': 6.9830508474576275e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:00:24<2:11:16,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:00:25<2:10:21,  1.90s/it]                                                       {'loss': 0.0297, 'grad_norm': 3.105558395385742, 'learning_rate': 6.981355932203391e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:00:25<2:10:21,  1.90s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:00:27<2:09:00,  1.88s/it]                                                       {'loss': 0.0495, 'grad_norm': 4.007018089294434, 'learning_rate': 6.979661016949153e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:00:27<2:09:00,  1.88s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:00:29<2:08:38,  1.87s/it]                                                       {'loss': 0.0673, 'grad_norm': 5.616512775421143, 'learning_rate': 6.9779661016949165e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:00:29<2:08:38,  1.87s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:00:31<2:08:36,  1.87s/it]                                                       {'loss': 0.0362, 'grad_norm': 6.203693866729736, 'learning_rate': 6.976271186440678e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:00:31<2:08:36,  1.87s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:00:33<2:11:06,  1.91s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.3656009435653687, 'learning_rate': 6.974576271186441e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:00:33<2:11:06,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:00:35<2:10:43,  1.91s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.38057181239128113, 'learning_rate': 6.972881355932204e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:00:35<2:10:43,  1.91s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:00:37<2:09:38,  1.89s/it]                                                       {'loss': 0.0711, 'grad_norm': 4.166467666625977, 'learning_rate': 6.971186440677966e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:00:37<2:09:38,  1.89s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:00:39<2:08:51,  1.88s/it]                                                       {'loss': 0.0249, 'grad_norm': 3.0758635997772217, 'learning_rate': 6.9694915254237295e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:00:39<2:08:51,  1.88s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:00:41<2:11:08,  1.91s/it]                                                       {'loss': 0.0773, 'grad_norm': 3.9776647090911865, 'learning_rate': 6.967796610169492e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:00:41<2:11:08,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:00:42<2:10:50,  1.91s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.1025607585906982, 'learning_rate': 6.966101694915255e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:00:42<2:10:50,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:00:44<2:10:34,  1.91s/it]                                                       {'loss': 0.0216, 'grad_norm': 1.6975857019424438, 'learning_rate': 6.964406779661017e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:00:44<2:10:34,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:00:46<2:10:02,  1.90s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.2607795000076294, 'learning_rate': 6.96271186440678e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:00:46<2:10:02,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:00:48<2:09:36,  1.89s/it]                                                       {'loss': 0.0491, 'grad_norm': 11.420456886291504, 'learning_rate': 6.9610169491525425e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:00:48<2:09:36,  1.89s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:00:50<2:09:43,  1.90s/it]                                                       {'loss': 0.0223, 'grad_norm': 2.940225124359131, 'learning_rate': 6.959322033898306e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:00:50<2:09:43,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:00:52<2:14:20,  1.96s/it]                                                       {'loss': 0.0423, 'grad_norm': 3.7750275135040283, 'learning_rate': 6.957627118644068e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:00:52<2:14:20,  1.96s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:00:54<2:11:55,  1.93s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.24416810274124146, 'learning_rate': 6.9559322033898315e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:00:54<2:11:55,  1.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:00:56<2:10:14,  1.90s/it]                                                       {'loss': 0.1281, 'grad_norm': 9.298547744750977, 'learning_rate': 6.954237288135594e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:00:56<2:10:14,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:00:58<2:09:37,  1.90s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.394731283187866, 'learning_rate': 6.952542372881357e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:00:58<2:09:37,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:01:00<2:09:39,  1.90s/it]                                                       {'loss': 0.2111, 'grad_norm': 11.403932571411133, 'learning_rate': 6.950847457627119e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:01:00<2:09:39,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:01:02<2:09:17,  1.89s/it]                                                       {'loss': 0.1224, 'grad_norm': 8.038960456848145, 'learning_rate': 6.949152542372882e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:01:02<2:09:17,  1.89s/it][2025-11-11 22:54:17,437] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900
[2025-11-11 22:54:17,444] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:54:17,730] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:01:04<2:25:39,  2.13s/it]                                                       {'loss': 0.007, 'grad_norm': 0.8652234673500061, 'learning_rate': 6.9474576271186444e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:01:04<2:25:39,  2.13s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:01:07<2:30:09,  2.20s/it]                                                       {'loss': 0.0198, 'grad_norm': 2.2831602096557617, 'learning_rate': 6.945762711864408e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:01:07<2:30:09,  2.20s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:01:08<2:23:37,  2.10s/it]                                                       {'loss': 0.0878, 'grad_norm': 2.901710271835327, 'learning_rate': 6.94406779661017e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:01:08<2:23:37,  2.10s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:01:10<2:22:14,  2.08s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.5144213438034058, 'learning_rate': 6.942372881355933e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:01:10<2:22:14,  2.08s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:01:12<2:19:57,  2.05s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.4253644943237305, 'learning_rate': 6.940677966101696e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:01:12<2:19:57,  2.05s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:01:14<2:16:15,  2.00s/it]                                                       {'loss': 0.1456, 'grad_norm': 8.637223243713379, 'learning_rate': 6.938983050847459e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:01:14<2:16:15,  2.00s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:01:16<2:14:21,  1.97s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.3681727647781372, 'learning_rate': 6.937288135593221e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:01:16<2:14:21,  1.97s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:01:18<2:11:38,  1.93s/it]                                                       {'loss': 0.0978, 'grad_norm': 6.756633281707764, 'learning_rate': 6.935593220338983e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:01:18<2:11:38,  1.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:01:20<2:09:49,  1.90s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.9713239669799805, 'learning_rate': 6.933898305084746e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:01:20<2:09:49,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:01:22<2:09:43,  1.90s/it]                                                       {'loss': 0.0156, 'grad_norm': 1.9997621774673462, 'learning_rate': 6.932203389830509e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:01:22<2:09:43,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:01:24<2:09:12,  1.90s/it]                                                       {'loss': 0.0231, 'grad_norm': 4.750179290771484, 'learning_rate': 6.930508474576272e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:01:24<2:09:12,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:01:26<2:08:16,  1.88s/it]                                                       {'loss': 0.1155, 'grad_norm': 8.0457181930542, 'learning_rate': 6.928813559322034e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:01:26<2:08:16,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:01:27<2:08:12,  1.88s/it]                                                       {'loss': 0.1751, 'grad_norm': 8.663183212280273, 'learning_rate': 6.927118644067797e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:01:27<2:08:12,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:01:29<2:08:07,  1.88s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5731452703475952, 'learning_rate': 6.925423728813559e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:01:29<2:08:07,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:01:31<2:07:53,  1.88s/it]                                                       {'loss': 0.0892, 'grad_norm': 6.214114665985107, 'learning_rate': 6.923728813559323e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:01:31<2:07:53,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:01:33<2:07:45,  1.88s/it]                                                       {'loss': 0.0674, 'grad_norm': 6.503092288970947, 'learning_rate': 6.922033898305085e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:01:33<2:07:45,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:01:35<2:07:48,  1.88s/it]                                                       {'loss': 0.155, 'grad_norm': 8.232769966125488, 'learning_rate': 6.920338983050848e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:01:35<2:07:48,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:01:37<2:08:05,  1.88s/it]                                                       {'loss': 0.0257, 'grad_norm': 3.221802234649658, 'learning_rate': 6.918644067796611e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:01:37<2:08:05,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:01:39<2:09:57,  1.91s/it]                                                       {'loss': 0.1123, 'grad_norm': 2.985970973968506, 'learning_rate': 6.916949152542374e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:01:39<2:09:57,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:01:41<2:09:31,  1.90s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.6192671656608582, 'learning_rate': 6.915254237288136e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:01:41<2:09:31,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:01:43<2:08:51,  1.90s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.17203110456466675, 'learning_rate': 6.913559322033899e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:01:43<2:08:51,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:01:44<2:07:45,  1.88s/it]                                                       {'loss': 0.2547, 'grad_norm': 7.921536922454834, 'learning_rate': 6.911864406779661e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:01:44<2:07:45,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:01:46<2:07:00,  1.87s/it]                                                       {'loss': 0.136, 'grad_norm': 4.1870598793029785, 'learning_rate': 6.910169491525425e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:01:46<2:07:00,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:01:48<2:08:20,  1.89s/it]                                                       {'loss': 0.001, 'grad_norm': 0.16740566492080688, 'learning_rate': 6.908474576271187e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:01:48<2:08:20,  1.89s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:01:50<2:07:52,  1.88s/it]                                                       {'loss': 0.0577, 'grad_norm': 5.591084003448486, 'learning_rate': 6.90677966101695e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:01:50<2:07:52,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:01:52<2:06:45,  1.87s/it]                                                       {'loss': 0.0968, 'grad_norm': 6.013800144195557, 'learning_rate': 6.905084745762713e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:01:52<2:06:45,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:01:54<2:07:27,  1.88s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.579163074493408, 'learning_rate': 6.903389830508476e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:01:54<2:07:27,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:01:56<2:06:56,  1.87s/it]                                                       {'loss': 0.1608, 'grad_norm': 8.069537162780762, 'learning_rate': 6.901694915254238e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:01:56<2:06:56,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:01:58<2:06:36,  1.87s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.0709556341171265, 'learning_rate': 6.9e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:01:58<2:06:36,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:01:59<2:07:48,  1.88s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.48342952132225037, 'learning_rate': 6.898305084745763e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:01:59<2:07:48,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:02:01<2:09:05,  1.90s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.9928898811340332, 'learning_rate': 6.896610169491526e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:02:01<2:09:05,  1.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:02:03<2:07:42,  1.88s/it]                                                       {'loss': 0.0298, 'grad_norm': 5.264959812164307, 'learning_rate': 6.894915254237289e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:02:03<2:07:42,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:02:05<2:07:34,  1.88s/it]                                                       {'loss': 0.0328, 'grad_norm': 1.9748855829238892, 'learning_rate': 6.893220338983051e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:02:05<2:07:34,  1.88s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:02:07<2:06:31,  1.87s/it]                                                       {'loss': 0.0232, 'grad_norm': 4.095223426818848, 'learning_rate': 6.891525423728815e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:02:07<2:06:31,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:02:09<2:07:00,  1.87s/it]                                                       {'loss': 0.0762, 'grad_norm': 6.230794429779053, 'learning_rate': 6.889830508474576e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:02:09<2:07:00,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:02:11<2:06:47,  1.87s/it]                                                       {'loss': 0.0904, 'grad_norm': 7.217899322509766, 'learning_rate': 6.8881355932203395e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:02:11<2:06:47,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:02:13<2:06:24,  1.87s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.752757728099823, 'learning_rate': 6.886440677966102e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:02:13<2:06:24,  1.87s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:02:15<2:09:15,  1.91s/it]                                                       {'loss': 0.0537, 'grad_norm': 5.513638496398926, 'learning_rate': 6.884745762711865e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:02:15<2:09:15,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:02:16<2:09:04,  1.91s/it]                                                       {'loss': 0.1094, 'grad_norm': 9.79830551147461, 'learning_rate': 6.883050847457628e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:02:16<2:09:04,  1.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:02:19<2:12:12,  1.95s/it]                                                       {'loss': 0.05, 'grad_norm': 6.094807147979736, 'learning_rate': 6.881355932203391e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:02:19<2:12:12,  1.95s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:02:20<2:09:56,  1.92s/it]                                                       {'loss': 0.177, 'grad_norm': 9.220199584960938, 'learning_rate': 6.8796610169491525e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:02:20<2:09:56,  1.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:02:22<2:09:31,  1.92s/it]                                                       {'loss': 0.132, 'grad_norm': 7.173938274383545, 'learning_rate': 6.877966101694916e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:02:22<2:09:31,  1.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:02:24<2:12:13,  1.96s/it]                                                       {'loss': 0.0087, 'grad_norm': 0.9446308612823486, 'learning_rate': 6.876271186440678e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:02:24<2:12:13,  1.96s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:02:26<2:12:08,  1.95s/it]                                                       {'loss': 0.0929, 'grad_norm': 10.599682807922363, 'learning_rate': 6.8745762711864415e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:02:26<2:12:08,  1.95s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:02:28<2:12:23,  1.96s/it]                                                       {'loss': 0.0246, 'grad_norm': 4.172806739807129, 'learning_rate': 6.872881355932204e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:02:28<2:12:23,  1.96s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:02:30<2:10:08,  1.93s/it]                                                       {'loss': 0.0295, 'grad_norm': 4.615167140960693, 'learning_rate': 6.871186440677967e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:02:30<2:10:08,  1.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:02:32<2:09:25,  1.92s/it]                                                       {'loss': 0.1379, 'grad_norm': 5.679447174072266, 'learning_rate': 6.86949152542373e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:02:32<2:09:25,  1.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:02:34<2:09:44,  1.92s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.7214109897613525, 'learning_rate': 6.867796610169493e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:02:34<2:09:44,  1.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:02:36<2:11:24,  1.95s/it]                                                       {'loss': 0.0209, 'grad_norm': 2.348454713821411, 'learning_rate': 6.8661016949152545e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:02:36<2:11:24,  1.95s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:02:38<2:09:12,  1.91s/it]                                                       {'loss': 0.015, 'grad_norm': 1.8251817226409912, 'learning_rate': 6.864406779661017e-06, 'epoch': 0.33}
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:02:38<2:09:12,  1.91s/it][2025-11-11 22:55:53,666] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1950
[2025-11-11 22:55:53,673] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:55:53,964] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1950/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:02:40<2:25:50,  2.16s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.3672221004962921, 'learning_rate': 6.86271186440678e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:02:40<2:25:50,  2.16s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:02:42<2:20:13,  2.08s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.392656087875366, 'learning_rate': 6.861016949152543e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:02:42<2:20:13,  2.08s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:02:44<2:15:49,  2.01s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.2372344732284546, 'learning_rate': 6.859322033898306e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:02:44<2:15:49,  2.01s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:02:46<2:13:15,  1.98s/it]                                                       {'loss': 0.0724, 'grad_norm': 8.535648345947266, 'learning_rate': 6.857627118644068e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:02:46<2:13:15,  1.98s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:02:48<2:10:38,  1.94s/it]                                                       {'loss': 0.0708, 'grad_norm': 6.455820560455322, 'learning_rate': 6.8559322033898316e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:02:48<2:10:38,  1.94s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:02:50<2:09:30,  1.92s/it]                                                       {'loss': 0.025, 'grad_norm': 2.321005344390869, 'learning_rate': 6.854237288135593e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:02:50<2:09:30,  1.92s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:02:52<2:08:21,  1.90s/it]                                                       {'loss': 0.072, 'grad_norm': 3.84556245803833, 'learning_rate': 6.852542372881356e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:02:52<2:08:21,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:02:54<2:07:04,  1.89s/it]                                                       {'loss': 0.0556, 'grad_norm': 5.360810279846191, 'learning_rate': 6.850847457627119e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:02:54<2:07:04,  1.89s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:02:56<2:08:31,  1.91s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.9960600733757019, 'learning_rate': 6.849152542372882e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:02:56<2:08:31,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:02:57<2:08:48,  1.91s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.4681371450424194, 'learning_rate': 6.8474576271186445e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:02:57<2:08:48,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:02:59<2:07:34,  1.90s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.011968731880188, 'learning_rate': 6.845762711864408e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:02:59<2:07:34,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:03:01<2:08:49,  1.91s/it]                                                       {'loss': 0.2189, 'grad_norm': 10.558069229125977, 'learning_rate': 6.84406779661017e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:03:01<2:08:49,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:03:03<2:07:53,  1.90s/it]                                                       {'loss': 0.0666, 'grad_norm': 4.82235860824585, 'learning_rate': 6.8423728813559335e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:03:03<2:07:53,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:03:05<2:06:50,  1.89s/it]                                                       {'loss': 0.059, 'grad_norm': 3.50688099861145, 'learning_rate': 6.840677966101695e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:03:05<2:06:50,  1.89s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:03:07<2:06:19,  1.88s/it]                                                       {'loss': 0.0689, 'grad_norm': 5.67396879196167, 'learning_rate': 6.838983050847458e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:03:07<2:06:19,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:03:09<2:10:45,  1.94s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.42961049079895, 'learning_rate': 6.837288135593221e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:03:09<2:10:45,  1.94s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:03:11<2:09:06,  1.92s/it]                                                       {'loss': 0.0635, 'grad_norm': 4.891056537628174, 'learning_rate': 6.835593220338984e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:03:11<2:09:06,  1.92s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:03:13<2:08:35,  1.91s/it]                                                       {'loss': 0.0307, 'grad_norm': 3.6584243774414062, 'learning_rate': 6.8338983050847465e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:03:13<2:08:35,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:03:15<2:08:09,  1.91s/it]                                                       {'loss': 0.0463, 'grad_norm': 3.66921067237854, 'learning_rate': 6.83220338983051e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:03:15<2:08:09,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:03:17<2:09:34,  1.93s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06366664171218872, 'learning_rate': 6.830508474576271e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:03:17<2:09:34,  1.93s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:03:18<2:07:59,  1.91s/it]                                                       {'loss': 0.0322, 'grad_norm': 3.330615997314453, 'learning_rate': 6.828813559322034e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:03:18<2:07:59,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:03:20<2:07:25,  1.90s/it]                                                       {'loss': 0.0286, 'grad_norm': 2.8137404918670654, 'learning_rate': 6.827118644067797e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:03:20<2:07:25,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:03:22<2:06:29,  1.88s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5889558792114258, 'learning_rate': 6.8254237288135595e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:03:22<2:06:29,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:03:24<2:06:46,  1.89s/it]                                                       {'loss': 0.0351, 'grad_norm': 3.1254472732543945, 'learning_rate': 6.823728813559323e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:03:24<2:06:46,  1.89s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:03:26<2:06:25,  1.88s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5841214060783386, 'learning_rate': 6.822033898305085e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:03:26<2:06:25,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:03:28<2:04:44,  1.86s/it]                                                       {'loss': 0.1169, 'grad_norm': 6.513051509857178, 'learning_rate': 6.8203389830508485e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:03:28<2:04:44,  1.86s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:03:30<2:05:47,  1.88s/it]                                                       {'loss': 0.0207, 'grad_norm': 1.4375442266464233, 'learning_rate': 6.81864406779661e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:03:30<2:05:47,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:03:32<2:06:08,  1.88s/it]                                                       {'loss': 0.0128, 'grad_norm': 2.8299405574798584, 'learning_rate': 6.816949152542373e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:03:32<2:06:08,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:03:33<2:05:35,  1.87s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.2450780868530273, 'learning_rate': 6.815254237288136e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:03:33<2:05:35,  1.87s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:03:35<2:05:42,  1.88s/it]                                                       {'loss': 0.0394, 'grad_norm': 2.729984998703003, 'learning_rate': 6.813559322033899e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:03:35<2:05:42,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:03:37<2:05:00,  1.87s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.6487149596214294, 'learning_rate': 6.8118644067796614e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:03:37<2:05:00,  1.87s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:03:39<2:05:43,  1.88s/it]                                                       {'loss': 0.2273, 'grad_norm': 12.512347221374512, 'learning_rate': 6.810169491525425e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:03:39<2:05:43,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:03:41<2:06:52,  1.90s/it]                                                       {'loss': 0.2171, 'grad_norm': 12.55199909210205, 'learning_rate': 6.808474576271187e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:03:41<2:06:52,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:03:43<2:08:58,  1.93s/it]                                                       {'loss': 0.0739, 'grad_norm': 7.01810359954834, 'learning_rate': 6.80677966101695e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:03:43<2:08:58,  1.93s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:03:45<2:07:42,  1.91s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.1135222911834717, 'learning_rate': 6.805084745762712e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:03:45<2:07:42,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:03:47<2:08:21,  1.92s/it]                                                       {'loss': 0.1926, 'grad_norm': 9.791879653930664, 'learning_rate': 6.803389830508475e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:03:47<2:08:21,  1.92s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:03:49<2:07:48,  1.91s/it]                                                       {'loss': 0.0373, 'grad_norm': 5.583468437194824, 'learning_rate': 6.801694915254238e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:03:49<2:07:48,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:03:51<2:07:09,  1.90s/it]                                                       {'loss': 0.07, 'grad_norm': 7.815532207489014, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:03:51<2:07:09,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:03:52<2:07:51,  1.91s/it]                                                       {'loss': 0.0309, 'grad_norm': 3.6594014167785645, 'learning_rate': 6.798305084745763e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:03:52<2:07:51,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:03:54<2:06:42,  1.90s/it]                                                       {'loss': 0.0834, 'grad_norm': 7.168667316436768, 'learning_rate': 6.796610169491527e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:03:54<2:06:42,  1.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:03:56<2:05:44,  1.88s/it]                                                       {'loss': 0.0782, 'grad_norm': 5.102385520935059, 'learning_rate': 6.794915254237289e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:03:56<2:05:44,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:03:58<2:04:53,  1.87s/it]                                                       {'loss': 0.0587, 'grad_norm': 4.956046104431152, 'learning_rate': 6.793220338983051e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:03:58<2:04:53,  1.87s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:04:00<2:04:49,  1.87s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.510035514831543, 'learning_rate': 6.791525423728814e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:04:00<2:04:49,  1.87s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:04:02<2:04:14,  1.86s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.39747974276542664, 'learning_rate': 6.789830508474576e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:04:02<2:04:14,  1.86s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:04:04<2:05:07,  1.87s/it]                                                       {'loss': 0.1856, 'grad_norm': 10.293380737304688, 'learning_rate': 6.78813559322034e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:04:04<2:05:07,  1.87s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:04:06<2:05:16,  1.88s/it]                                                       {'loss': 0.0228, 'grad_norm': 2.0354080200195312, 'learning_rate': 6.786440677966102e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:04:06<2:05:16,  1.88s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:04:07<2:06:19,  1.89s/it]                                                       {'loss': 0.1313, 'grad_norm': 9.157170295715332, 'learning_rate': 6.784745762711865e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:04:07<2:06:19,  1.89s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:04:09<2:05:52,  1.89s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.3489803671836853, 'learning_rate': 6.783050847457627e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:04:09<2:05:52,  1.89s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:04:11<2:08:33,  1.93s/it]                                                       {'loss': 0.1252, 'grad_norm': 8.53345775604248, 'learning_rate': 6.78135593220339e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:04:11<2:08:33,  1.93s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:04:13<2:10:10,  1.95s/it]                                                       {'loss': 0.0151, 'grad_norm': 2.157609462738037, 'learning_rate': 6.779661016949153e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:04:13<2:10:10,  1.95s/it][2025-11-11 22:57:29,286] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000
[2025-11-11 22:57:29,293] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:57:29,577] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:04:16<2:24:49,  2.17s/it]                                                       {'loss': 0.0483, 'grad_norm': 4.446298122406006, 'learning_rate': 6.777966101694916e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:04:16<2:24:49,  2.17s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:04:18<2:18:41,  2.08s/it]                                                       {'loss': 0.1186, 'grad_norm': 7.2059431076049805, 'learning_rate': 6.776271186440678e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:04:18<2:18:41,  2.08s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:04:20<2:13:41,  2.01s/it]                                                       {'loss': 0.0576, 'grad_norm': 5.321775436401367, 'learning_rate': 6.774576271186442e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:04:20<2:13:41,  2.01s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:04:22<2:11:10,  1.97s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.8655561208724976, 'learning_rate': 6.772881355932204e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:04:22<2:11:10,  1.97s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:04:24<2:09:59,  1.95s/it]                                                       {'loss': 0.0079, 'grad_norm': 2.359004259109497, 'learning_rate': 6.771186440677967e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:04:24<2:09:59,  1.95s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:04:25<2:09:40,  1.95s/it]                                                       {'loss': 0.0532, 'grad_norm': 2.8421785831451416, 'learning_rate': 6.769491525423729e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:04:25<2:09:40,  1.95s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:04:27<2:08:47,  1.94s/it]                                                       {'loss': 0.0112, 'grad_norm': 2.8107998371124268, 'learning_rate': 6.767796610169492e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:04:27<2:08:47,  1.94s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:04:29<2:07:14,  1.91s/it]                                                       {'loss': 0.1103, 'grad_norm': 5.399996280670166, 'learning_rate': 6.766101694915255e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:04:29<2:07:14,  1.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:04:31<2:05:53,  1.89s/it]                                                       {'loss': 0.0706, 'grad_norm': 8.0310640335083, 'learning_rate': 6.764406779661018e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:04:31<2:05:53,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:04:33<2:08:34,  1.93s/it]                                                       {'loss': 0.1377, 'grad_norm': 9.196752548217773, 'learning_rate': 6.76271186440678e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:04:33<2:08:34,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:04:35<2:07:44,  1.92s/it]                                                       {'loss': 0.283, 'grad_norm': 13.863116264343262, 'learning_rate': 6.7610169491525436e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:04:35<2:07:44,  1.92s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:04:37<2:05:33,  1.89s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.49707305431365967, 'learning_rate': 6.759322033898306e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:04:37<2:05:33,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:04:39<2:05:28,  1.89s/it]                                                       {'loss': 0.2511, 'grad_norm': 9.295517921447754, 'learning_rate': 6.7576271186440676e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:04:39<2:05:28,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:04:41<2:04:57,  1.88s/it]                                                       {'loss': 0.0249, 'grad_norm': 4.008556842803955, 'learning_rate': 6.755932203389831e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:04:41<2:04:57,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:04:43<2:07:57,  1.93s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.056244928389787674, 'learning_rate': 6.754237288135593e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:04:43<2:07:57,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:04:45<2:07:30,  1.92s/it]                                                       {'loss': 0.059, 'grad_norm': 5.62782096862793, 'learning_rate': 6.7525423728813565e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:04:45<2:07:30,  1.92s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:04:46<2:06:48,  1.91s/it]                                                       {'loss': 0.0089, 'grad_norm': 2.0597918033599854, 'learning_rate': 6.750847457627119e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:04:46<2:06:48,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:04:48<2:06:01,  1.90s/it]                                                       {'loss': 0.0335, 'grad_norm': 10.281282424926758, 'learning_rate': 6.749152542372882e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:04:48<2:06:01,  1.90s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:04:50<2:06:38,  1.91s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.510091543197632, 'learning_rate': 6.747457627118645e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:04:50<2:06:38,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:04:52<2:11:08,  1.98s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.32826635241508484, 'learning_rate': 6.745762711864408e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:04:52<2:11:08,  1.98s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:04:54<2:07:51,  1.93s/it]                                                       {'loss': 0.1299, 'grad_norm': 8.603778839111328, 'learning_rate': 6.7440677966101695e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:04:54<2:07:51,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:04:56<2:06:20,  1.91s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.3242270946502686, 'learning_rate': 6.742372881355933e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:04:56<2:06:20,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:04:58<2:05:34,  1.89s/it]                                                       {'loss': 0.0685, 'grad_norm': 5.7686614990234375, 'learning_rate': 6.740677966101695e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:04:58<2:05:34,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:05:00<2:04:39,  1.88s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5194731950759888, 'learning_rate': 6.7389830508474585e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:05:00<2:04:39,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:05:02<2:04:20,  1.88s/it]                                                       {'loss': 0.0793, 'grad_norm': 6.661243915557861, 'learning_rate': 6.737288135593221e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:05:02<2:04:20,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:05:04<2:04:52,  1.89s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.6965196132659912, 'learning_rate': 6.735593220338984e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:05:04<2:04:52,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:05:05<2:04:42,  1.88s/it]                                                       {'loss': 0.0325, 'grad_norm': 3.6558756828308105, 'learning_rate': 6.733898305084746e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:05:05<2:04:42,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:05:07<2:04:19,  1.88s/it]                                                       {'loss': 0.2004, 'grad_norm': 9.613434791564941, 'learning_rate': 6.73220338983051e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:05:07<2:04:19,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:05:09<2:05:07,  1.89s/it]                                                       {'loss': 0.2692, 'grad_norm': 9.86318302154541, 'learning_rate': 6.7305084745762715e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:05:09<2:05:07,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:05:11<2:09:30,  1.96s/it]                                                       {'loss': 0.14, 'grad_norm': 7.458211421966553, 'learning_rate': 6.728813559322035e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:05:11<2:09:30,  1.96s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:05:13<2:07:25,  1.93s/it]                                                       {'loss': 0.066, 'grad_norm': 5.8699727058410645, 'learning_rate': 6.727118644067797e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:05:13<2:07:25,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:05:15<2:06:37,  1.91s/it]                                                       {'loss': 0.0189, 'grad_norm': 4.951675891876221, 'learning_rate': 6.7254237288135604e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:05:15<2:06:37,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:05:17<2:06:24,  1.91s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.4562132358551025, 'learning_rate': 6.723728813559323e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:05:17<2:06:24,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:05:19<2:06:24,  1.91s/it]                                                       {'loss': 0.0324, 'grad_norm': 10.703964233398438, 'learning_rate': 6.7220338983050844e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:05:19<2:06:24,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:05:21<2:07:43,  1.93s/it]                                                       {'loss': 0.0405, 'grad_norm': 3.716634750366211, 'learning_rate': 6.720338983050848e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:05:21<2:07:43,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:05:23<2:07:37,  1.93s/it]                                                       {'loss': 0.2259, 'grad_norm': 15.369301795959473, 'learning_rate': 6.71864406779661e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:05:23<2:07:37,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:05:25<2:06:15,  1.91s/it]                                                       {'loss': 0.0157, 'grad_norm': 3.0117886066436768, 'learning_rate': 6.716949152542373e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:05:25<2:06:15,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:05:27<2:05:40,  1.90s/it]                                                       {'loss': 0.0166, 'grad_norm': 2.5223464965820312, 'learning_rate': 6.715254237288136e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:05:27<2:05:40,  1.90s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:05:28<2:04:24,  1.88s/it]                                                       {'loss': 0.0323, 'grad_norm': 4.034184455871582, 'learning_rate': 6.713559322033899e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:05:28<2:04:24,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:05:30<2:05:25,  1.90s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.2467795610427856, 'learning_rate': 6.7118644067796615e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:05:30<2:05:25,  1.90s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:05:32<2:04:07,  1.88s/it]                                                       {'loss': 0.0713, 'grad_norm': 7.844702243804932, 'learning_rate': 6.710169491525425e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:05:32<2:04:07,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:05:34<2:03:26,  1.87s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.22761023044586182, 'learning_rate': 6.708474576271186e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:05:34<2:03:26,  1.87s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [1:05:36<2:03:13,  1.87s/it]                                                       {'loss': 0.016, 'grad_norm': 1.8836750984191895, 'learning_rate': 6.70677966101695e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [1:05:36<2:03:13,  1.87s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [1:05:38<2:03:55,  1.88s/it]                                                       {'loss': 0.1168, 'grad_norm': 8.030017852783203, 'learning_rate': 6.705084745762712e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [1:05:38<2:03:55,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [1:05:40<2:02:52,  1.86s/it]                                                       {'loss': 0.0515, 'grad_norm': 3.2663586139678955, 'learning_rate': 6.703389830508475e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [1:05:40<2:02:52,  1.86s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [1:05:41<2:03:59,  1.88s/it]                                                       {'loss': 0.0204, 'grad_norm': 4.276438236236572, 'learning_rate': 6.701694915254238e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [1:05:41<2:03:59,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [1:05:43<2:04:42,  1.89s/it]                                                       {'loss': 0.0507, 'grad_norm': 5.993630409240723, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [1:05:43<2:04:42,  1.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [1:05:45<2:05:04,  1.90s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.373364806175232, 'learning_rate': 6.6983050847457635e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [1:05:45<2:05:04,  1.90s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [1:05:47<2:03:33,  1.88s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.495881050825119, 'learning_rate': 6.696610169491527e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [1:05:47<2:03:33,  1.88s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [1:05:49<2:03:22,  1.87s/it]                                                       {'loss': 0.1916, 'grad_norm': 9.140591621398926, 'learning_rate': 6.694915254237288e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [1:05:49<2:03:22,  1.87s/it][2025-11-11 22:59:04,929] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2050
[2025-11-11 22:59:04,936] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 22:59:05,215] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2050/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [1:05:52<2:18:44,  2.11s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.7514166831970215, 'learning_rate': 6.693220338983052e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [1:05:52<2:18:44,  2.11s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [1:05:54<2:15:39,  2.06s/it]                                                       {'loss': 0.1978, 'grad_norm': 6.6836628913879395, 'learning_rate': 6.691525423728814e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [1:05:54<2:15:39,  2.06s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [1:05:56<2:12:24,  2.01s/it]                                                       {'loss': 0.0303, 'grad_norm': 5.873040199279785, 'learning_rate': 6.6898305084745765e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [1:05:56<2:12:24,  2.01s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [1:05:57<2:09:28,  1.97s/it]                                                       {'loss': 0.0269, 'grad_norm': 2.4833710193634033, 'learning_rate': 6.68813559322034e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [1:05:57<2:09:28,  1.97s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [1:05:59<2:08:29,  1.95s/it]                                                       {'loss': 0.2426, 'grad_norm': 8.347076416015625, 'learning_rate': 6.686440677966101e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [1:05:59<2:08:29,  1.95s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [1:06:01<2:06:12,  1.92s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.320430874824524, 'learning_rate': 6.6847457627118655e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [1:06:01<2:06:12,  1.92s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [1:06:03<2:11:32,  2.00s/it]                                                       {'loss': 0.1151, 'grad_norm': 7.009212017059326, 'learning_rate': 6.683050847457627e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [1:06:03<2:11:32,  2.00s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [1:06:05<2:09:06,  1.97s/it]                                                       {'loss': 0.0162, 'grad_norm': 2.148125648498535, 'learning_rate': 6.68135593220339e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [1:06:05<2:09:06,  1.97s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [1:06:07<2:07:15,  1.94s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.711735963821411, 'learning_rate': 6.679661016949153e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [1:06:07<2:07:15,  1.94s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [1:06:09<2:06:36,  1.93s/it]                                                       {'loss': 0.0172, 'grad_norm': 3.717076063156128, 'learning_rate': 6.677966101694916e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [1:06:09<2:06:36,  1.93s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [1:06:11<2:05:24,  1.91s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.255969762802124, 'learning_rate': 6.6762711864406784e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [1:06:11<2:05:24,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [1:06:13<2:05:25,  1.91s/it]                                                       {'loss': 0.1598, 'grad_norm': 7.125630855560303, 'learning_rate': 6.674576271186442e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [1:06:13<2:05:25,  1.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [1:06:15<2:04:38,  1.90s/it]                                                       {'loss': 0.0953, 'grad_norm': 6.59138822555542, 'learning_rate': 6.672881355932203e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [1:06:15<2:04:38,  1.90s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [1:06:17<2:04:30,  1.90s/it]                                                       {'loss': 0.0242, 'grad_norm': 1.617494821548462, 'learning_rate': 6.6711864406779666e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [1:06:17<2:04:30,  1.90s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [1:06:19<2:05:44,  1.92s/it]                                                       {'loss': 0.0706, 'grad_norm': 5.294250965118408, 'learning_rate': 6.669491525423729e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [1:06:19<2:05:44,  1.92s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [1:06:21<2:09:01,  1.97s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11414875835180283, 'learning_rate': 6.667796610169492e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [1:06:21<2:09:01,  1.97s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [1:06:22<2:07:33,  1.95s/it]                                                       {'loss': 0.2145, 'grad_norm': 8.170388221740723, 'learning_rate': 6.666101694915255e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [1:06:22<2:07:33,  1.95s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [1:06:24<2:05:54,  1.92s/it]                                                       {'loss': 0.0449, 'grad_norm': 5.3589091300964355, 'learning_rate': 6.664406779661018e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [1:06:24<2:05:54,  1.92s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [1:06:27<2:11:26,  2.01s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9376469850540161, 'learning_rate': 6.66271186440678e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [1:06:27<2:11:26,  2.01s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [1:06:28<2:09:15,  1.97s/it]                                                       {'loss': 0.2926, 'grad_norm': 9.960829734802246, 'learning_rate': 6.661016949152544e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [1:06:28<2:09:15,  1.97s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [1:06:30<2:07:31,  1.95s/it]                                                       {'loss': 0.0927, 'grad_norm': 6.8286519050598145, 'learning_rate': 6.659322033898305e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [1:06:30<2:07:31,  1.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [1:06:32<2:05:53,  1.92s/it]                                                       {'loss': 0.0887, 'grad_norm': 4.974594593048096, 'learning_rate': 6.6576271186440685e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [1:06:32<2:05:53,  1.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [1:06:34<2:03:59,  1.89s/it]                                                       {'loss': 0.0332, 'grad_norm': 1.4826619625091553, 'learning_rate': 6.655932203389831e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [1:06:34<2:03:59,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [1:06:36<2:04:33,  1.90s/it]                                                       {'loss': 0.0539, 'grad_norm': 5.781294822692871, 'learning_rate': 6.654237288135593e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [1:06:36<2:04:33,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [1:06:38<2:04:33,  1.90s/it]                                                       {'loss': 0.1478, 'grad_norm': 7.521300792694092, 'learning_rate': 6.652542372881357e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [1:06:38<2:04:33,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [1:06:40<2:03:21,  1.89s/it]                                                       {'loss': 0.0805, 'grad_norm': 6.615351676940918, 'learning_rate': 6.650847457627119e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [1:06:40<2:03:21,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [1:06:42<2:03:25,  1.89s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3090185821056366, 'learning_rate': 6.649152542372882e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [1:06:42<2:03:25,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [1:06:43<2:03:13,  1.89s/it]                                                       {'loss': 0.1811, 'grad_norm': 6.393954753875732, 'learning_rate': 6.647457627118644e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [1:06:43<2:03:13,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [1:06:45<2:02:48,  1.88s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.37574502825737, 'learning_rate': 6.645762711864407e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [1:06:45<2:02:48,  1.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [1:06:47<2:02:51,  1.88s/it]                                                       {'loss': 0.1133, 'grad_norm': 10.809059143066406, 'learning_rate': 6.64406779661017e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [1:06:47<2:02:51,  1.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [1:06:49<2:02:36,  1.88s/it]                                                       {'loss': 0.1525, 'grad_norm': 8.990596771240234, 'learning_rate': 6.642372881355933e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [1:06:49<2:02:36,  1.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [1:06:51<2:02:49,  1.88s/it]                                                       {'loss': 0.0436, 'grad_norm': 4.191655158996582, 'learning_rate': 6.640677966101695e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [1:06:51<2:02:49,  1.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [1:06:53<2:01:23,  1.86s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.8235331773757935, 'learning_rate': 6.638983050847459e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [1:06:53<2:01:23,  1.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [1:06:55<2:00:45,  1.85s/it]                                                       {'loss': 0.096, 'grad_norm': 8.306325912475586, 'learning_rate': 6.637288135593221e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [1:06:55<2:00:45,  1.85s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [1:06:57<2:02:15,  1.87s/it]                                                       {'loss': 0.0368, 'grad_norm': 4.910345554351807, 'learning_rate': 6.635593220338984e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [1:06:57<2:02:15,  1.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [1:06:58<2:02:52,  1.88s/it]                                                       {'loss': 0.056, 'grad_norm': 6.521452903747559, 'learning_rate': 6.633898305084746e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [1:06:58<2:02:52,  1.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [1:07:00<2:04:27,  1.91s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.0017170906066895, 'learning_rate': 6.632203389830509e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [1:07:00<2:04:27,  1.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [1:07:02<2:03:31,  1.89s/it]                                                       {'loss': 0.104, 'grad_norm': 6.7478556632995605, 'learning_rate': 6.6305084745762716e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [1:07:02<2:03:31,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [1:07:04<2:02:13,  1.87s/it]                                                       {'loss': 0.1654, 'grad_norm': 7.86976432800293, 'learning_rate': 6.628813559322035e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [1:07:04<2:02:13,  1.87s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [1:07:06<2:04:24,  1.91s/it]                                                       {'loss': 0.1291, 'grad_norm': 7.0670857429504395, 'learning_rate': 6.627118644067797e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [1:07:06<2:04:24,  1.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [1:07:08<2:03:32,  1.90s/it]                                                       {'loss': 0.0293, 'grad_norm': 2.602125883102417, 'learning_rate': 6.6254237288135605e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [1:07:08<2:03:32,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [1:07:10<2:03:29,  1.90s/it]                                                       {'loss': 0.0717, 'grad_norm': 6.975285530090332, 'learning_rate': 6.623728813559322e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [1:07:10<2:03:29,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [1:07:12<2:03:21,  1.89s/it]                                                       {'loss': 0.0816, 'grad_norm': 7.525257110595703, 'learning_rate': 6.622033898305085e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [1:07:12<2:03:21,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [1:07:14<2:03:19,  1.89s/it]                                                       {'loss': 0.007, 'grad_norm': 1.3850603103637695, 'learning_rate': 6.620338983050848e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [1:07:14<2:03:19,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [1:07:16<2:05:44,  1.93s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.9985964298248291, 'learning_rate': 6.61864406779661e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [1:07:16<2:05:44,  1.93s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [1:07:18<2:04:41,  1.92s/it]                                                       {'loss': 0.0355, 'grad_norm': 1.9634582996368408, 'learning_rate': 6.6169491525423735e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [1:07:18<2:04:41,  1.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [1:07:20<2:05:43,  1.93s/it]                                                       {'loss': 0.0313, 'grad_norm': 3.441221237182617, 'learning_rate': 6.615254237288136e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [1:07:20<2:05:43,  1.93s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [1:07:21<2:04:41,  1.92s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.09509395062923431, 'learning_rate': 6.613559322033899e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [1:07:21<2:04:41,  1.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [1:07:23<2:07:38,  1.96s/it]                                                       {'loss': 0.0817, 'grad_norm': 6.770503044128418, 'learning_rate': 6.611864406779661e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [1:07:23<2:07:38,  1.96s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [1:07:25<2:06:27,  1.95s/it]                                                       {'loss': 0.1812, 'grad_norm': 9.781623840332031, 'learning_rate': 6.610169491525424e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [1:07:25<2:06:27,  1.95s/it][2025-11-11 23:00:41,294] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100
[2025-11-11 23:00:41,301] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:00:41,587] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [1:07:28<2:20:15,  2.16s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.026970863342285, 'learning_rate': 6.6084745762711865e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [1:07:28<2:20:15,  2.16s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [1:07:30<2:14:01,  2.06s/it]                                                       {'loss': 0.0211, 'grad_norm': 1.3033604621887207, 'learning_rate': 6.60677966101695e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [1:07:30<2:14:01,  2.06s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [1:07:32<2:09:41,  2.00s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.6789681315422058, 'learning_rate': 6.605084745762712e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [1:07:32<2:09:41,  2.00s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [1:07:34<2:07:21,  1.96s/it]                                                       {'loss': 0.1319, 'grad_norm': 8.6281156539917, 'learning_rate': 6.6033898305084755e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [1:07:34<2:07:21,  1.96s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [1:07:36<2:06:46,  1.95s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.1226004883646965, 'learning_rate': 6.601694915254238e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [1:07:36<2:06:46,  1.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [1:07:37<2:04:16,  1.91s/it]                                                       {'loss': 0.1044, 'grad_norm': 9.187101364135742, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [1:07:37<2:04:16,  1.91s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [1:07:39<2:03:06,  1.90s/it]                                                       {'loss': 0.0363, 'grad_norm': 2.7459497451782227, 'learning_rate': 6.598305084745763e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [1:07:39<2:03:06,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [1:07:41<2:02:47,  1.89s/it]                                                       {'loss': 0.1219, 'grad_norm': 10.204936981201172, 'learning_rate': 6.596610169491526e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [1:07:41<2:02:47,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [1:07:43<2:03:07,  1.90s/it]                                                       {'loss': 0.2092, 'grad_norm': 9.03985595703125, 'learning_rate': 6.5949152542372885e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [1:07:43<2:03:07,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [1:07:45<2:06:04,  1.94s/it]                                                       {'loss': 0.1285, 'grad_norm': 8.773136138916016, 'learning_rate': 6.593220338983052e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [1:07:45<2:06:04,  1.94s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [1:07:47<2:04:59,  1.93s/it]                                                       {'loss': 0.0496, 'grad_norm': 5.242101192474365, 'learning_rate': 6.591525423728814e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [1:07:47<2:04:59,  1.93s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [1:07:49<2:05:12,  1.93s/it]                                                       {'loss': 0.2546, 'grad_norm': 11.614792823791504, 'learning_rate': 6.5898305084745774e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [1:07:49<2:05:12,  1.93s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [1:07:51<2:04:24,  1.92s/it]                                                       {'loss': 0.0323, 'grad_norm': 1.79739248752594, 'learning_rate': 6.58813559322034e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [1:07:51<2:04:24,  1.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [1:07:53<2:03:08,  1.90s/it]                                                       {'loss': 0.0557, 'grad_norm': 4.933679103851318, 'learning_rate': 6.586440677966103e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [1:07:53<2:03:08,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [1:07:55<2:02:25,  1.89s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.9699228405952454, 'learning_rate': 6.584745762711865e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [1:07:55<2:02:25,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [1:07:56<2:02:28,  1.89s/it]                                                       {'loss': 0.0789, 'grad_norm': 8.113176345825195, 'learning_rate': 6.583050847457627e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [1:07:56<2:02:28,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [1:07:58<2:02:14,  1.89s/it]                                                       {'loss': 0.4434, 'grad_norm': 9.046320915222168, 'learning_rate': 6.58135593220339e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [1:07:58<2:02:14,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [1:08:00<2:02:08,  1.89s/it]                                                       {'loss': 0.0975, 'grad_norm': 9.170018196105957, 'learning_rate': 6.579661016949153e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [1:08:00<2:02:08,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [1:08:02<2:02:38,  1.90s/it]                                                       {'loss': 0.018, 'grad_norm': 1.3612474203109741, 'learning_rate': 6.577966101694916e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [1:08:02<2:02:38,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [1:08:04<2:02:17,  1.89s/it]                                                       {'loss': 0.0371, 'grad_norm': 2.8493101596832275, 'learning_rate': 6.576271186440678e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [1:08:04<2:02:17,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [1:08:06<2:01:39,  1.88s/it]                                                       {'loss': 0.1177, 'grad_norm': 8.479186058044434, 'learning_rate': 6.574576271186441e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [1:08:06<2:01:39,  1.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [1:08:08<2:05:16,  1.94s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.947032928466797, 'learning_rate': 6.572881355932203e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [1:08:08<2:05:16,  1.94s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [1:08:10<2:04:44,  1.93s/it]                                                       {'loss': 0.12, 'grad_norm': 7.728894233703613, 'learning_rate': 6.571186440677967e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [1:08:10<2:04:44,  1.93s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [1:08:12<2:03:02,  1.90s/it]                                                       {'loss': 0.1124, 'grad_norm': 5.210111141204834, 'learning_rate': 6.569491525423729e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [1:08:12<2:03:02,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [1:08:13<2:01:58,  1.89s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.3648386001586914, 'learning_rate': 6.567796610169492e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [1:08:13<2:01:58,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [1:08:15<2:02:12,  1.89s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.071164131164551, 'learning_rate': 6.566101694915255e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [1:08:15<2:02:12,  1.89s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [1:08:17<2:02:27,  1.90s/it]                                                       {'loss': 0.0532, 'grad_norm': 3.2869341373443604, 'learning_rate': 6.564406779661018e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [1:08:17<2:02:27,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [1:08:19<2:02:23,  1.90s/it]                                                       {'loss': 0.2339, 'grad_norm': 9.912132263183594, 'learning_rate': 6.56271186440678e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [1:08:19<2:02:23,  1.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [1:08:21<2:02:07,  1.89s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.5421577095985413, 'learning_rate': 6.561016949152543e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [1:08:21<2:02:07,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [1:08:23<2:01:34,  1.88s/it]                                                       {'loss': 0.1252, 'grad_norm': 8.365571022033691, 'learning_rate': 6.559322033898305e-06, 'epoch': 0.35}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [1:08:23<2:01:34,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [1:08:25<2:00:47,  1.87s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05855454131960869, 'learning_rate': 6.557627118644069e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [1:08:25<2:00:47,  1.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [1:08:27<2:00:34,  1.87s/it]                                                       {'loss': 0.0336, 'grad_norm': 3.5506649017333984, 'learning_rate': 6.555932203389831e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [1:08:27<2:00:34,  1.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [1:08:29<2:02:40,  1.90s/it]                                                       {'loss': 0.1972, 'grad_norm': 12.848689079284668, 'learning_rate': 6.554237288135594e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [1:08:29<2:02:40,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [1:08:30<2:01:37,  1.89s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.9408032894134521, 'learning_rate': 6.552542372881357e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [1:08:30<2:01:37,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [1:08:32<2:01:07,  1.88s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.054213285446167, 'learning_rate': 6.55084745762712e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [1:08:32<2:01:07,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [1:08:34<2:02:49,  1.91s/it]                                                       {'loss': 0.046, 'grad_norm': 8.610991477966309, 'learning_rate': 6.549152542372882e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [1:08:34<2:02:49,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [1:08:36<2:02:21,  1.90s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.995019555091858, 'learning_rate': 6.547457627118644e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [1:08:36<2:02:21,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [1:08:38<2:01:15,  1.88s/it]                                                       {'loss': 0.0161, 'grad_norm': 3.2197415828704834, 'learning_rate': 6.545762711864407e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [1:08:38<2:01:15,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [1:08:40<2:00:45,  1.88s/it]                                                       {'loss': 0.0226, 'grad_norm': 3.0202107429504395, 'learning_rate': 6.54406779661017e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [1:08:40<2:00:45,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [1:08:42<2:00:39,  1.88s/it]                                                       {'loss': 0.4033, 'grad_norm': 10.644668579101562, 'learning_rate': 6.542372881355933e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [1:08:42<2:00:39,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [1:08:44<2:00:31,  1.87s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9932901263237, 'learning_rate': 6.5406779661016954e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [1:08:44<2:00:31,  1.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [1:08:46<2:01:14,  1.89s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.7229192852973938, 'learning_rate': 6.538983050847459e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [1:08:46<2:01:14,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [1:08:48<2:02:05,  1.90s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.7564483880996704, 'learning_rate': 6.53728813559322e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [1:08:48<2:02:05,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [1:08:49<2:02:08,  1.90s/it]                                                       {'loss': 0.1231, 'grad_norm': 8.288152694702148, 'learning_rate': 6.5355932203389836e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [1:08:49<2:02:08,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [1:08:51<2:01:47,  1.90s/it]                                                       {'loss': 0.1816, 'grad_norm': 7.608947277069092, 'learning_rate': 6.533898305084746e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [1:08:51<2:01:47,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [1:08:53<2:02:06,  1.90s/it]                                                       {'loss': 0.0449, 'grad_norm': 7.742860317230225, 'learning_rate': 6.532203389830509e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [1:08:53<2:02:06,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [1:08:55<2:02:05,  1.90s/it]                                                       {'loss': 0.1079, 'grad_norm': 7.717440605163574, 'learning_rate': 6.530508474576272e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [1:08:55<2:02:05,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [1:08:57<2:02:13,  1.90s/it]                                                       {'loss': 0.3068, 'grad_norm': 11.427563667297363, 'learning_rate': 6.528813559322035e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [1:08:57<2:02:13,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [1:08:59<2:01:36,  1.89s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.39887991547584534, 'learning_rate': 6.5271186440677965e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [1:08:59<2:01:36,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [1:09:01<2:00:58,  1.89s/it]                                                       {'loss': 0.1804, 'grad_norm': 8.184850692749023, 'learning_rate': 6.52542372881356e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [1:09:01<2:00:58,  1.89s/it][2025-11-11 23:02:16,671] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2150
[2025-11-11 23:02:16,678] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:02:16,966] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2150/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [1:09:04<2:20:19,  2.19s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.210798740386963, 'learning_rate': 6.523728813559322e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [1:09:04<2:20:19,  2.19s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [1:09:05<2:13:15,  2.08s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2736014425754547, 'learning_rate': 6.5220338983050855e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [1:09:05<2:13:15,  2.08s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [1:09:07<2:09:41,  2.02s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.3539694547653198, 'learning_rate': 6.520338983050848e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [1:09:07<2:09:41,  2.02s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [1:09:09<2:07:27,  1.99s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.9246196746826172, 'learning_rate': 6.518644067796611e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [1:09:09<2:07:27,  1.99s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [1:09:11<2:04:52,  1.95s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.8593766093254089, 'learning_rate': 6.516949152542374e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [1:09:11<2:04:52,  1.95s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [1:09:13<2:03:33,  1.93s/it]                                                       {'loss': 0.1232, 'grad_norm': 7.9701924324035645, 'learning_rate': 6.515254237288137e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [1:09:13<2:03:33,  1.93s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [1:09:15<2:02:59,  1.92s/it]                                                       {'loss': 0.0168, 'grad_norm': 0.9743632078170776, 'learning_rate': 6.5135593220338985e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [1:09:15<2:02:59,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [1:09:17<2:02:04,  1.91s/it]                                                       {'loss': 0.0395, 'grad_norm': 4.18583869934082, 'learning_rate': 6.511864406779661e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [1:09:17<2:02:04,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [1:09:19<2:01:44,  1.90s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.657508909702301, 'learning_rate': 6.510169491525424e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [1:09:19<2:01:44,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [1:09:21<2:00:55,  1.89s/it]                                                       {'loss': 0.032, 'grad_norm': 3.425469160079956, 'learning_rate': 6.508474576271187e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [1:09:21<2:00:55,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [1:09:22<2:01:16,  1.90s/it]                                                       {'loss': 0.1007, 'grad_norm': 8.598620414733887, 'learning_rate': 6.50677966101695e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [1:09:22<2:01:16,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [1:09:24<2:00:24,  1.88s/it]                                                       {'loss': 0.094, 'grad_norm': 7.707302570343018, 'learning_rate': 6.505084745762712e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [1:09:24<2:00:24,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [1:09:26<2:06:29,  1.98s/it]                                                       {'loss': 0.1472, 'grad_norm': 9.338767051696777, 'learning_rate': 6.503389830508476e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [1:09:26<2:06:29,  1.98s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [1:09:28<2:04:05,  1.94s/it]                                                       {'loss': 0.0978, 'grad_norm': 4.338802814483643, 'learning_rate': 6.501694915254237e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [1:09:28<2:04:05,  1.94s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [1:09:30<2:03:10,  1.93s/it]                                                       {'loss': 0.094, 'grad_norm': 6.504905700683594, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [1:09:30<2:03:10,  1.93s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [1:09:32<2:01:48,  1.91s/it]                                                       {'loss': 0.2693, 'grad_norm': 12.80496883392334, 'learning_rate': 6.498305084745763e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [1:09:32<2:01:48,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [1:09:34<2:01:05,  1.90s/it]                                                       {'loss': 0.0139, 'grad_norm': 3.0922744274139404, 'learning_rate': 6.496610169491526e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [1:09:34<2:01:05,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [1:09:36<2:01:27,  1.90s/it]                                                       {'loss': 0.0259, 'grad_norm': 2.6426219940185547, 'learning_rate': 6.4949152542372886e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [1:09:36<2:01:27,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [1:09:38<2:00:51,  1.89s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.0734232664108276, 'learning_rate': 6.493220338983052e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [1:09:38<2:00:51,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [1:09:40<2:00:03,  1.88s/it]                                                       {'loss': 0.0624, 'grad_norm': 5.453270435333252, 'learning_rate': 6.491525423728814e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [1:09:40<2:00:03,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [1:09:41<1:59:47,  1.88s/it]                                                       {'loss': 0.0822, 'grad_norm': 5.31887674331665, 'learning_rate': 6.4898305084745775e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [1:09:41<1:59:47,  1.88s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [1:09:43<2:01:38,  1.91s/it]                                                       {'loss': 0.0218, 'grad_norm': 1.7483508586883545, 'learning_rate': 6.488135593220339e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [1:09:43<2:01:38,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [1:09:45<2:01:39,  1.91s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.5374690294265747, 'learning_rate': 6.486440677966102e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [1:09:45<2:01:39,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [1:09:47<2:02:42,  1.92s/it]                                                       {'loss': 0.0587, 'grad_norm': 5.751148223876953, 'learning_rate': 6.484745762711865e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [1:09:47<2:02:42,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [1:09:49<2:02:00,  1.91s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06763153523206711, 'learning_rate': 6.483050847457628e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [1:09:49<2:02:00,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [1:09:51<2:01:43,  1.91s/it]                                                       {'loss': 0.0713, 'grad_norm': 5.043251991271973, 'learning_rate': 6.4813559322033905e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [1:09:51<2:01:43,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [1:09:53<2:00:22,  1.89s/it]                                                       {'loss': 0.1677, 'grad_norm': 11.040116310119629, 'learning_rate': 6.479661016949154e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [1:09:53<2:00:22,  1.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [1:09:55<2:01:25,  1.91s/it]                                                       {'loss': 0.0277, 'grad_norm': 3.162719964981079, 'learning_rate': 6.477966101694915e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [1:09:55<2:01:25,  1.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [1:09:57<2:01:07,  1.90s/it]                                                       {'loss': 0.0917, 'grad_norm': 6.8558244705200195, 'learning_rate': 6.476271186440678e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [1:09:57<2:01:07,  1.90s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [1:09:59<2:02:33,  1.92s/it]                                                       {'loss': 0.0276, 'grad_norm': 1.979552984237671, 'learning_rate': 6.474576271186441e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [1:09:59<2:02:33,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [1:10:01<2:02:00,  1.92s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.03365159034729, 'learning_rate': 6.4728813559322035e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [1:10:01<2:02:00,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [1:10:03<2:02:31,  1.93s/it]                                                       {'loss': 0.0401, 'grad_norm': 6.739684104919434, 'learning_rate': 6.471186440677967e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [1:10:03<2:02:31,  1.93s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [1:10:05<2:05:36,  1.97s/it]                                                       {'loss': 0.0514, 'grad_norm': 5.700076103210449, 'learning_rate': 6.469491525423729e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [1:10:05<2:05:36,  1.97s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [1:10:07<2:03:18,  1.94s/it]                                                       {'loss': 0.1017, 'grad_norm': 6.143406867980957, 'learning_rate': 6.4677966101694925e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [1:10:07<2:03:18,  1.94s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [1:10:08<2:02:18,  1.92s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.443290114402771, 'learning_rate': 6.466101694915254e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [1:10:08<2:02:18,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [1:10:10<2:02:04,  1.92s/it]                                                       {'loss': 0.085, 'grad_norm': 8.288113594055176, 'learning_rate': 6.464406779661017e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [1:10:10<2:02:04,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [1:10:12<2:02:19,  1.92s/it]                                                       {'loss': 0.1481, 'grad_norm': 12.583986282348633, 'learning_rate': 6.46271186440678e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [1:10:12<2:02:19,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [1:10:14<2:01:52,  1.92s/it]                                                       {'loss': 0.1345, 'grad_norm': 7.138499736785889, 'learning_rate': 6.461016949152543e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [1:10:14<2:01:52,  1.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [1:10:16<2:07:22,  2.01s/it]                                                       {'loss': 0.0994, 'grad_norm': 7.898542404174805, 'learning_rate': 6.4593220338983055e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [1:10:16<2:07:22,  2.01s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [1:10:18<2:05:20,  1.97s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.3636717796325684, 'learning_rate': 6.457627118644069e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [1:10:18<2:05:20,  1.97s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [1:10:20<2:03:07,  1.94s/it]                                                       {'loss': 0.2836, 'grad_norm': 9.340210914611816, 'learning_rate': 6.455932203389831e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [1:10:20<2:03:07,  1.94s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [1:10:22<2:02:13,  1.93s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3568556010723114, 'learning_rate': 6.4542372881355944e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [1:10:22<2:02:13,  1.93s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [1:10:24<2:00:11,  1.89s/it]                                                       {'loss': 0.107, 'grad_norm': 7.238171100616455, 'learning_rate': 6.452542372881356e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [1:10:24<2:00:11,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [1:10:26<2:00:43,  1.90s/it]                                                       {'loss': 0.0225, 'grad_norm': 4.0406599044799805, 'learning_rate': 6.450847457627119e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [1:10:26<2:00:43,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [1:10:28<1:59:59,  1.89s/it]                                                       {'loss': 0.1012, 'grad_norm': 7.080071449279785, 'learning_rate': 6.449152542372882e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [1:10:28<1:59:59,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [1:10:30<2:00:58,  1.91s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.789512038230896, 'learning_rate': 6.447457627118645e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [1:10:30<2:00:58,  1.91s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [1:10:31<1:59:26,  1.88s/it]                                                       {'loss': 0.0289, 'grad_norm': 3.2316031455993652, 'learning_rate': 6.445762711864407e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [1:10:31<1:59:26,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [1:10:33<1:59:01,  1.88s/it]                                                       {'loss': 0.0567, 'grad_norm': 5.045865058898926, 'learning_rate': 6.444067796610171e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [1:10:33<1:59:01,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [1:10:35<2:00:09,  1.90s/it]                                                       {'loss': 0.252, 'grad_norm': 11.993398666381836, 'learning_rate': 6.442372881355933e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [1:10:35<2:00:09,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [1:10:37<2:02:01,  1.93s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4067995846271515, 'learning_rate': 6.440677966101695e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [1:10:37<2:02:01,  1.93s/it][2025-11-11 23:03:53,190] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200
[2025-11-11 23:03:53,197] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:03:53,484] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [1:10:40<2:17:29,  2.17s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.68968266248703, 'learning_rate': 6.438983050847458e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [1:10:40<2:17:29,  2.17s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [1:10:42<2:11:04,  2.07s/it]                                                       {'loss': 0.0865, 'grad_norm': 3.730397939682007, 'learning_rate': 6.43728813559322e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [1:10:42<2:11:04,  2.07s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [1:10:44<2:07:51,  2.02s/it]                                                       {'loss': 0.0372, 'grad_norm': 5.816250801086426, 'learning_rate': 6.435593220338984e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [1:10:44<2:07:51,  2.02s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [1:10:46<2:04:56,  1.97s/it]                                                       {'loss': 0.0983, 'grad_norm': 9.045940399169922, 'learning_rate': 6.433898305084746e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [1:10:46<2:04:56,  1.97s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [1:10:47<2:03:21,  1.95s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.29749953746795654, 'learning_rate': 6.432203389830509e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [1:10:48<2:03:21,  1.95s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [1:10:50<2:08:47,  2.04s/it]                                                       {'loss': 0.0729, 'grad_norm': 4.020331859588623, 'learning_rate': 6.430508474576271e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [1:10:50<2:08:47,  2.04s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [1:10:52<2:06:22,  2.00s/it]                                                       {'loss': 0.0409, 'grad_norm': 4.929338455200195, 'learning_rate': 6.428813559322035e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [1:10:52<2:06:22,  2.00s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [1:10:54<2:04:28,  1.97s/it]                                                       {'loss': 0.6013, 'grad_norm': 14.035977363586426, 'learning_rate': 6.427118644067797e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [1:10:54<2:04:28,  1.97s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [1:10:55<2:01:55,  1.93s/it]                                                       {'loss': 0.0627, 'grad_norm': 7.305790424346924, 'learning_rate': 6.42542372881356e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [1:10:55<2:01:55,  1.93s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [1:10:57<2:00:33,  1.91s/it]                                                       {'loss': 0.0311, 'grad_norm': 3.1360526084899902, 'learning_rate': 6.423728813559322e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [1:10:57<2:00:33,  1.91s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [1:10:59<1:59:37,  1.89s/it]                                                       {'loss': 0.0268, 'grad_norm': 4.454568862915039, 'learning_rate': 6.422033898305086e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [1:10:59<1:59:37,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [1:11:01<2:00:10,  1.90s/it]                                                       {'loss': 0.0212, 'grad_norm': 2.594019889831543, 'learning_rate': 6.420338983050848e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [1:11:01<2:00:10,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [1:11:03<1:59:48,  1.90s/it]                                                       {'loss': 0.1052, 'grad_norm': 9.230646133422852, 'learning_rate': 6.418644067796611e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [1:11:03<1:59:48,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [1:11:05<1:58:35,  1.88s/it]                                                       {'loss': 0.0959, 'grad_norm': 6.92710018157959, 'learning_rate': 6.416949152542373e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [1:11:05<1:58:35,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [1:11:07<1:58:07,  1.87s/it]                                                       {'loss': 0.0205, 'grad_norm': 3.364537477493286, 'learning_rate': 6.415254237288136e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [1:11:07<1:58:07,  1.87s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [1:11:09<1:59:39,  1.90s/it]                                                       {'loss': 0.0936, 'grad_norm': 7.327199935913086, 'learning_rate': 6.413559322033899e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [1:11:09<1:59:39,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [1:11:10<1:59:24,  1.89s/it]                                                       {'loss': 0.1946, 'grad_norm': 8.626782417297363, 'learning_rate': 6.411864406779662e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [1:11:10<1:59:24,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [1:11:12<1:58:24,  1.88s/it]                                                       {'loss': 0.2902, 'grad_norm': 14.833313941955566, 'learning_rate': 6.410169491525424e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [1:11:12<1:58:24,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [1:11:14<1:58:11,  1.88s/it]                                                       {'loss': 0.0206, 'grad_norm': 1.7441651821136475, 'learning_rate': 6.408474576271188e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [1:11:14<1:58:11,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [1:11:16<1:58:01,  1.87s/it]                                                       {'loss': 0.0483, 'grad_norm': 5.814007759094238, 'learning_rate': 6.40677966101695e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [1:11:16<1:58:01,  1.87s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [1:11:18<1:59:12,  1.89s/it]                                                       {'loss': 0.0131, 'grad_norm': 2.221954584121704, 'learning_rate': 6.405084745762712e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [1:11:18<1:59:12,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [1:11:20<2:00:05,  1.91s/it]                                                       {'loss': 0.0582, 'grad_norm': 6.191925525665283, 'learning_rate': 6.403389830508475e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [1:11:20<2:00:05,  1.91s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [1:11:22<2:00:40,  1.92s/it]                                                       {'loss': 0.0131, 'grad_norm': 2.243170738220215, 'learning_rate': 6.401694915254237e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [1:11:22<2:00:40,  1.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [1:11:24<1:59:46,  1.90s/it]                                                       {'loss': 0.0208, 'grad_norm': 3.075411081314087, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [1:11:24<1:59:46,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [1:11:26<1:58:20,  1.88s/it]                                                       {'loss': 0.0136, 'grad_norm': 2.166822671890259, 'learning_rate': 6.398305084745763e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [1:11:26<1:58:20,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [1:11:27<1:57:21,  1.87s/it]                                                       {'loss': 0.2173, 'grad_norm': 11.616552352905273, 'learning_rate': 6.396610169491526e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [1:11:27<1:57:21,  1.87s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [1:11:29<1:57:41,  1.87s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.2545695304870605, 'learning_rate': 6.394915254237289e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [1:11:29<1:57:41,  1.87s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [1:11:31<1:58:23,  1.88s/it]                                                       {'loss': 0.0197, 'grad_norm': 2.8537757396698, 'learning_rate': 6.393220338983052e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [1:11:31<1:58:23,  1.88s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [1:11:33<1:57:42,  1.87s/it]                                                       {'loss': 0.0172, 'grad_norm': 2.7904839515686035, 'learning_rate': 6.3915254237288135e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [1:11:33<1:57:42,  1.87s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [1:11:35<1:59:38,  1.90s/it]                                                       {'loss': 0.0297, 'grad_norm': 4.23838472366333, 'learning_rate': 6.389830508474577e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [1:11:35<1:59:38,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [1:11:37<1:59:22,  1.90s/it]                                                       {'loss': 0.0326, 'grad_norm': 2.7673611640930176, 'learning_rate': 6.388135593220339e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [1:11:37<1:59:22,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [1:11:39<1:59:43,  1.91s/it]                                                       {'loss': 0.1175, 'grad_norm': 7.66937780380249, 'learning_rate': 6.3864406779661025e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [1:11:39<1:59:43,  1.91s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [1:11:41<1:58:31,  1.89s/it]                                                       {'loss': 0.1042, 'grad_norm': 8.516104698181152, 'learning_rate': 6.384745762711865e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [1:11:41<1:58:31,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [1:11:43<2:01:18,  1.93s/it]                                                       {'loss': 0.031, 'grad_norm': 2.3383750915527344, 'learning_rate': 6.383050847457628e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [1:11:43<2:01:18,  1.93s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [1:11:45<2:00:14,  1.92s/it]                                                       {'loss': 0.2505, 'grad_norm': 11.430638313293457, 'learning_rate': 6.381355932203391e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [1:11:45<2:00:14,  1.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [1:11:46<1:58:58,  1.90s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5212059020996094, 'learning_rate': 6.379661016949154e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [1:11:46<1:58:58,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [1:11:48<1:59:03,  1.90s/it]                                                       {'loss': 0.1396, 'grad_norm': 7.359229564666748, 'learning_rate': 6.3779661016949155e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [1:11:48<1:59:03,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [1:11:50<1:59:19,  1.90s/it]                                                       {'loss': 0.0541, 'grad_norm': 6.20282506942749, 'learning_rate': 6.376271186440679e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [1:11:50<1:59:19,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [1:11:52<1:58:20,  1.89s/it]                                                       {'loss': 0.1599, 'grad_norm': 8.985786437988281, 'learning_rate': 6.374576271186441e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [1:11:52<1:58:20,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [1:11:54<1:58:35,  1.89s/it]                                                       {'loss': 0.0858, 'grad_norm': 6.315949440002441, 'learning_rate': 6.372881355932204e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [1:11:54<1:58:35,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [1:11:56<1:58:36,  1.89s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.4462223052978516, 'learning_rate': 6.371186440677967e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [1:11:56<1:58:36,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [1:11:58<2:00:20,  1.92s/it]                                                       {'loss': 0.0048, 'grad_norm': 1.270361304283142, 'learning_rate': 6.3694915254237285e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [1:11:58<2:00:20,  1.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [1:12:00<2:01:42,  1.94s/it]                                                       {'loss': 0.0239, 'grad_norm': 2.2136101722717285, 'learning_rate': 6.367796610169492e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [1:12:00<2:01:42,  1.94s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [1:12:02<2:00:39,  1.93s/it]                                                       {'loss': 0.2265, 'grad_norm': 9.801465034484863, 'learning_rate': 6.366101694915254e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [1:12:02<2:00:39,  1.93s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [1:12:04<2:00:12,  1.92s/it]                                                       {'loss': 0.0932, 'grad_norm': 8.336969375610352, 'learning_rate': 6.3644067796610174e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [1:12:04<2:00:12,  1.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [1:12:05<1:58:33,  1.90s/it]                                                       {'loss': 0.0568, 'grad_norm': 5.846672534942627, 'learning_rate': 6.36271186440678e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [1:12:06<1:58:33,  1.90s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [1:12:07<1:58:15,  1.89s/it]                                                       {'loss': 0.0492, 'grad_norm': 5.487404823303223, 'learning_rate': 6.361016949152543e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [1:12:07<1:58:15,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [1:12:09<1:58:03,  1.89s/it]                                                       {'loss': 0.0776, 'grad_norm': 3.425220251083374, 'learning_rate': 6.3593220338983056e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [1:12:09<1:58:03,  1.89s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [1:12:11<1:59:46,  1.92s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5055669546127319, 'learning_rate': 6.357627118644069e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [1:12:11<1:59:46,  1.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [1:12:13<1:59:27,  1.91s/it]                                                       {'loss': 0.049, 'grad_norm': 6.716928958892822, 'learning_rate': 6.3559322033898304e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [1:12:13<1:59:27,  1.91s/it][2025-11-11 23:05:29,063] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2250
[2025-11-11 23:05:29,070] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:05:29,352] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2250/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [1:12:16<2:13:53,  2.14s/it]                                                       {'loss': 0.0958, 'grad_norm': 10.41954517364502, 'learning_rate': 6.354237288135594e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [1:12:16<2:13:53,  2.14s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [1:12:18<2:08:35,  2.06s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.2244583368301392, 'learning_rate': 6.352542372881356e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [1:12:18<2:08:35,  2.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [1:12:20<2:05:58,  2.02s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.453987956047058, 'learning_rate': 6.350847457627119e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [1:12:20<2:05:58,  2.02s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [1:12:22<2:09:57,  2.08s/it]                                                       {'loss': 0.0441, 'grad_norm': 3.590766191482544, 'learning_rate': 6.349152542372882e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [1:12:22<2:09:57,  2.08s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [1:12:24<2:05:46,  2.02s/it]                                                       {'loss': 0.0796, 'grad_norm': 6.328973293304443, 'learning_rate': 6.347457627118645e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [1:12:24<2:05:46,  2.02s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [1:12:26<2:03:00,  1.97s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.22914719581604, 'learning_rate': 6.3457627118644075e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [1:12:26<2:03:00,  1.97s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [1:12:27<2:01:35,  1.95s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.23244112730026245, 'learning_rate': 6.344067796610171e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [1:12:27<2:01:35,  1.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [1:12:29<2:00:12,  1.93s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.6999191641807556, 'learning_rate': 6.342372881355932e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [1:12:29<2:00:12,  1.93s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [1:12:31<1:58:57,  1.91s/it]                                                       {'loss': 0.1067, 'grad_norm': 6.7361626625061035, 'learning_rate': 6.340677966101696e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [1:12:31<1:58:57,  1.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [1:12:33<1:58:37,  1.90s/it]                                                       {'loss': 0.1818, 'grad_norm': 10.649335861206055, 'learning_rate': 6.338983050847458e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [1:12:33<1:58:37,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [1:12:35<2:02:44,  1.97s/it]                                                       {'loss': 0.0441, 'grad_norm': 4.932217121124268, 'learning_rate': 6.3372881355932205e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [1:12:35<2:02:44,  1.97s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [1:12:37<2:04:27,  2.00s/it]                                                       {'loss': 0.084, 'grad_norm': 3.9901065826416016, 'learning_rate': 6.335593220338984e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [1:12:37<2:04:27,  2.00s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [1:12:39<2:03:16,  1.98s/it]                                                       {'loss': 0.2145, 'grad_norm': 8.236855506896973, 'learning_rate': 6.333898305084746e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [1:12:39<2:03:16,  1.98s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [1:12:41<2:03:07,  1.98s/it]                                                       {'loss': 0.0551, 'grad_norm': 8.106995582580566, 'learning_rate': 6.3322033898305095e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [1:12:41<2:03:07,  1.98s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [1:12:43<2:01:43,  1.96s/it]                                                       {'loss': 0.0389, 'grad_norm': 4.238369464874268, 'learning_rate': 6.330508474576271e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [1:12:43<2:01:43,  1.96s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [1:12:45<2:00:45,  1.94s/it]                                                       {'loss': 0.0501, 'grad_norm': 5.492412567138672, 'learning_rate': 6.328813559322034e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [1:12:45<2:00:45,  1.94s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [1:12:47<1:59:34,  1.92s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.21143633127212524, 'learning_rate': 6.327118644067797e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [1:12:47<1:59:34,  1.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [1:12:49<1:58:46,  1.91s/it]                                                       {'loss': 0.0429, 'grad_norm': 5.268057346343994, 'learning_rate': 6.32542372881356e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [1:12:49<1:58:46,  1.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [1:12:51<1:58:34,  1.91s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.44858425855636597, 'learning_rate': 6.3237288135593225e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [1:12:51<1:58:34,  1.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [1:12:53<2:00:56,  1.95s/it]                                                       {'loss': 0.0276, 'grad_norm': 3.0076427459716797, 'learning_rate': 6.322033898305086e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [1:12:53<2:00:56,  1.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [1:12:55<1:59:15,  1.92s/it]                                                       {'loss': 0.0631, 'grad_norm': 5.935217380523682, 'learning_rate': 6.320338983050847e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [1:12:55<1:59:15,  1.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [1:12:56<1:57:52,  1.90s/it]                                                       {'loss': 0.019, 'grad_norm': 2.149669647216797, 'learning_rate': 6.318644067796611e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [1:12:56<1:57:52,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [1:12:58<1:57:19,  1.89s/it]                                                       {'loss': 0.0714, 'grad_norm': 6.108550548553467, 'learning_rate': 6.316949152542373e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [1:12:58<1:57:19,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [1:13:00<1:56:53,  1.88s/it]                                                       {'loss': 0.0595, 'grad_norm': 6.450336456298828, 'learning_rate': 6.315254237288136e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [1:13:00<1:56:53,  1.88s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [1:13:02<1:58:08,  1.90s/it]                                                       {'loss': 0.1595, 'grad_norm': 8.941995620727539, 'learning_rate': 6.313559322033899e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [1:13:02<1:58:08,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [1:13:04<1:58:49,  1.91s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.7656391859054565, 'learning_rate': 6.311864406779662e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [1:13:04<1:58:49,  1.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [1:13:06<1:57:42,  1.90s/it]                                                       {'loss': 0.2424, 'grad_norm': 10.84505558013916, 'learning_rate': 6.310169491525424e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [1:13:06<1:57:42,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [1:13:08<1:56:56,  1.89s/it]                                                       {'loss': 0.0783, 'grad_norm': 7.207603931427002, 'learning_rate': 6.308474576271188e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [1:13:08<1:56:56,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [1:13:10<1:56:11,  1.87s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.3098044395446777, 'learning_rate': 6.306779661016949e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [1:13:10<1:56:11,  1.87s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [1:13:12<1:58:04,  1.90s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.0185405015945435, 'learning_rate': 6.3050847457627125e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [1:13:12<1:58:04,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [1:13:13<1:58:04,  1.90s/it]                                                       {'loss': 0.1447, 'grad_norm': 8.356291770935059, 'learning_rate': 6.303389830508475e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [1:13:13<1:58:04,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [1:13:15<1:57:44,  1.90s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.2432135343551636, 'learning_rate': 6.301694915254237e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [1:13:15<1:57:44,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [1:13:17<1:57:32,  1.90s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.9026973843574524, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [1:13:17<1:57:32,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [1:13:19<1:56:36,  1.88s/it]                                                       {'loss': 0.0391, 'grad_norm': 4.759585857391357, 'learning_rate': 6.298305084745763e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [1:13:19<1:56:36,  1.88s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [1:13:21<1:57:05,  1.89s/it]                                                       {'loss': 0.0796, 'grad_norm': 6.082381248474121, 'learning_rate': 6.296610169491526e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [1:13:21<1:57:05,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [1:13:23<1:56:48,  1.89s/it]                                                       {'loss': 0.088, 'grad_norm': 15.278022766113281, 'learning_rate': 6.294915254237288e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [1:13:23<1:56:48,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [1:13:25<1:57:24,  1.90s/it]                                                       {'loss': 0.0075, 'grad_norm': 2.152810573577881, 'learning_rate': 6.293220338983051e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [1:13:25<1:57:24,  1.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [1:13:27<1:56:46,  1.89s/it]                                                       {'loss': 0.1749, 'grad_norm': 8.381734848022461, 'learning_rate': 6.291525423728814e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [1:13:27<1:56:46,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [1:13:29<1:56:40,  1.89s/it]                                                       {'loss': 0.1687, 'grad_norm': 5.910739421844482, 'learning_rate': 6.289830508474577e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [1:13:29<1:56:40,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [1:13:31<1:59:05,  1.93s/it]                                                       {'loss': 0.0556, 'grad_norm': 5.246788024902344, 'learning_rate': 6.288135593220339e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [1:13:31<1:59:05,  1.93s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [1:13:32<1:57:05,  1.89s/it]                                                       {'loss': 0.0137, 'grad_norm': 1.6957967281341553, 'learning_rate': 6.286440677966103e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [1:13:32<1:57:05,  1.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [1:13:34<1:55:56,  1.88s/it]                                                       {'loss': 0.0464, 'grad_norm': 6.350121974945068, 'learning_rate': 6.284745762711865e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [1:13:34<1:55:56,  1.88s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [1:13:36<1:55:40,  1.87s/it]                                                       {'loss': 0.1105, 'grad_norm': 2.937387228012085, 'learning_rate': 6.283050847457628e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [1:13:36<1:55:40,  1.87s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [1:13:38<1:55:55,  1.88s/it]                                                       {'loss': 0.0262, 'grad_norm': 2.89290189743042, 'learning_rate': 6.28135593220339e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [1:13:38<1:55:55,  1.88s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [1:13:40<1:56:21,  1.88s/it]                                                       {'loss': 0.0357, 'grad_norm': 2.5029380321502686, 'learning_rate': 6.279661016949153e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [1:13:40<1:56:21,  1.88s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [1:13:42<1:58:12,  1.91s/it]                                                       {'loss': 0.1606, 'grad_norm': 7.706364631652832, 'learning_rate': 6.277966101694916e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [1:13:42<1:58:12,  1.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [1:13:44<1:59:00,  1.93s/it]                                                       {'loss': 0.0264, 'grad_norm': 2.8328335285186768, 'learning_rate': 6.276271186440679e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [1:13:44<1:59:00,  1.93s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [1:13:46<2:05:16,  2.03s/it]                                                       {'loss': 0.0126, 'grad_norm': 2.064887285232544, 'learning_rate': 6.274576271186441e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [1:13:46<2:05:16,  2.03s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [1:13:48<2:02:38,  1.99s/it]                                                       {'loss': 0.0474, 'grad_norm': 3.702514171600342, 'learning_rate': 6.2728813559322046e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [1:13:48<2:02:38,  1.99s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [1:13:50<1:59:42,  1.94s/it]                                                       {'loss': 0.0939, 'grad_norm': 5.325675964355469, 'learning_rate': 6.271186440677966e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [1:13:50<1:59:42,  1.94s/it][2025-11-11 23:07:05,744] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300
[2025-11-11 23:07:05,750] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:07:06,026] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [1:13:52<2:12:50,  2.15s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.5567402243614197, 'learning_rate': 6.2694915254237294e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [1:13:52<2:12:50,  2.15s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [1:13:54<2:06:39,  2.06s/it]                                                       {'loss': 0.0156, 'grad_norm': 3.212869644165039, 'learning_rate': 6.267796610169492e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [1:13:54<2:06:39,  2.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [1:13:56<2:02:24,  1.99s/it]                                                       {'loss': 0.066, 'grad_norm': 6.436663627624512, 'learning_rate': 6.266101694915254e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [1:13:56<2:02:24,  1.99s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [1:13:58<2:00:13,  1.95s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.09990845620632172, 'learning_rate': 6.2644067796610176e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [1:13:58<2:00:13,  1.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [1:14:00<1:58:33,  1.93s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.0097293853759766, 'learning_rate': 6.26271186440678e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [1:14:00<1:58:33,  1.93s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [1:14:02<1:57:35,  1.91s/it]                                                       {'loss': 0.0087, 'grad_norm': 0.7229985594749451, 'learning_rate': 6.261016949152543e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [1:14:02<1:57:35,  1.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [1:14:04<2:00:18,  1.95s/it]                                                       {'loss': 0.0337, 'grad_norm': 4.973300457000732, 'learning_rate': 6.259322033898305e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [1:14:04<2:00:18,  1.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [1:14:06<1:59:27,  1.94s/it]                                                       {'loss': 0.0349, 'grad_norm': 2.6415510177612305, 'learning_rate': 6.257627118644068e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [1:14:06<1:59:27,  1.94s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [1:14:08<1:58:03,  1.92s/it]                                                       {'loss': 0.1613, 'grad_norm': 11.917248725891113, 'learning_rate': 6.2559322033898305e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [1:14:08<1:58:03,  1.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [1:14:09<1:57:30,  1.91s/it]                                                       {'loss': 0.1042, 'grad_norm': 6.146481513977051, 'learning_rate': 6.254237288135594e-06, 'epoch': 0.39}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [1:14:09<1:57:30,  1.91s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [1:14:11<1:56:30,  1.89s/it]                                                       {'loss': 0.0337, 'grad_norm': 3.7366697788238525, 'learning_rate': 6.252542372881356e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [1:14:11<1:56:30,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [1:14:13<1:56:08,  1.89s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.0860648155212402, 'learning_rate': 6.2508474576271195e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [1:14:13<1:56:08,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [1:14:15<1:56:19,  1.89s/it]                                                       {'loss': 0.0151, 'grad_norm': 1.664036750793457, 'learning_rate': 6.249152542372882e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [1:14:15<1:56:19,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [1:14:17<1:59:03,  1.94s/it]                                                       {'loss': 0.0976, 'grad_norm': 7.181051731109619, 'learning_rate': 6.247457627118645e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [1:14:17<1:59:03,  1.94s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [1:14:19<1:58:24,  1.93s/it]                                                       {'loss': 0.0299, 'grad_norm': 3.5023694038391113, 'learning_rate': 6.245762711864407e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [1:14:19<1:58:24,  1.93s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [1:14:21<1:57:04,  1.91s/it]                                                       {'loss': 0.0142, 'grad_norm': 1.7693133354187012, 'learning_rate': 6.24406779661017e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [1:14:21<1:57:04,  1.91s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [1:14:23<1:55:24,  1.88s/it]                                                       {'loss': 0.3031, 'grad_norm': 11.631160736083984, 'learning_rate': 6.2423728813559325e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [1:14:23<1:55:24,  1.88s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [1:14:25<1:56:24,  1.90s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.559455394744873, 'learning_rate': 6.240677966101696e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [1:14:25<1:56:24,  1.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [1:14:27<1:56:06,  1.89s/it]                                                       {'loss': 0.1466, 'grad_norm': 7.212705135345459, 'learning_rate': 6.238983050847458e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [1:14:27<1:56:06,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [1:14:28<1:56:21,  1.90s/it]                                                       {'loss': 0.0684, 'grad_norm': 6.576175689697266, 'learning_rate': 6.2372881355932215e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [1:14:28<1:56:21,  1.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [1:14:30<1:55:40,  1.89s/it]                                                       {'loss': 0.163, 'grad_norm': 11.718451499938965, 'learning_rate': 6.235593220338984e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [1:14:30<1:55:40,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [1:14:32<1:54:58,  1.88s/it]                                                       {'loss': 0.0284, 'grad_norm': 3.146542549133301, 'learning_rate': 6.233898305084747e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [1:14:32<1:54:58,  1.88s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [1:14:34<1:54:49,  1.87s/it]                                                       {'loss': 0.1183, 'grad_norm': 7.096210479736328, 'learning_rate': 6.232203389830509e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [1:14:34<1:54:49,  1.87s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [1:14:36<1:55:33,  1.89s/it]                                                       {'loss': 0.1009, 'grad_norm': 6.679514408111572, 'learning_rate': 6.230508474576271e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [1:14:36<1:55:33,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [1:14:38<1:55:13,  1.88s/it]                                                       {'loss': 0.0485, 'grad_norm': 4.056513786315918, 'learning_rate': 6.2288135593220344e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [1:14:38<1:55:13,  1.88s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [1:14:40<1:54:40,  1.87s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.8410134315490723, 'learning_rate': 6.227118644067797e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [1:14:40<1:54:40,  1.87s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [1:14:42<1:54:10,  1.87s/it]                                                       {'loss': 0.1191, 'grad_norm': 8.088701248168945, 'learning_rate': 6.22542372881356e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [1:14:42<1:54:10,  1.87s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [1:14:43<1:53:38,  1.86s/it]                                                       {'loss': 0.3666, 'grad_norm': 14.309508323669434, 'learning_rate': 6.223728813559322e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [1:14:43<1:53:38,  1.86s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [1:14:46<2:06:19,  2.06s/it]                                                       {'loss': 0.1559, 'grad_norm': 11.274505615234375, 'learning_rate': 6.222033898305085e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [1:14:46<2:06:19,  2.06s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [1:14:48<2:02:38,  2.01s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.320467233657837, 'learning_rate': 6.2203389830508474e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [1:14:48<2:02:38,  2.01s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [1:14:50<1:59:54,  1.96s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.5337127447128296, 'learning_rate': 6.218644067796611e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [1:14:50<1:59:54,  1.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [1:14:51<1:57:54,  1.93s/it]                                                       {'loss': 0.0481, 'grad_norm': 4.044766902923584, 'learning_rate': 6.216949152542373e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [1:14:51<1:57:54,  1.93s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [1:14:53<1:57:00,  1.91s/it]                                                       {'loss': 0.0206, 'grad_norm': 2.8187754154205322, 'learning_rate': 6.215254237288136e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [1:14:53<1:57:00,  1.91s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [1:14:55<1:56:03,  1.90s/it]                                                       {'loss': 0.1149, 'grad_norm': 6.711629390716553, 'learning_rate': 6.213559322033899e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [1:14:55<1:56:03,  1.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [1:14:57<1:54:58,  1.88s/it]                                                       {'loss': 0.0132, 'grad_norm': 2.871988534927368, 'learning_rate': 6.211864406779662e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [1:14:57<1:54:58,  1.88s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [1:14:59<1:54:39,  1.88s/it]                                                       {'loss': 0.1258, 'grad_norm': 6.755917549133301, 'learning_rate': 6.210169491525424e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [1:14:59<1:54:39,  1.88s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [1:15:01<1:56:15,  1.90s/it]                                                       {'loss': 0.0284, 'grad_norm': 3.474851608276367, 'learning_rate': 6.208474576271187e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [1:15:01<1:56:15,  1.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [1:15:03<1:59:20,  1.96s/it]                                                       {'loss': 0.0637, 'grad_norm': 3.773925304412842, 'learning_rate': 6.206779661016949e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [1:15:03<1:59:20,  1.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [1:15:05<1:57:23,  1.92s/it]                                                       {'loss': 0.0291, 'grad_norm': 3.0998666286468506, 'learning_rate': 6.205084745762713e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [1:15:05<1:57:23,  1.92s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [1:15:07<1:56:05,  1.90s/it]                                                       {'loss': 0.0803, 'grad_norm': 7.617692470550537, 'learning_rate': 6.203389830508475e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [1:15:07<1:56:05,  1.90s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [1:15:09<1:55:10,  1.89s/it]                                                       {'loss': 0.0462, 'grad_norm': 4.437222957611084, 'learning_rate': 6.201694915254238e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [1:15:09<1:55:10,  1.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [1:15:11<1:58:39,  1.95s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.650604009628296, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [1:15:11<1:58:39,  1.95s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [1:15:13<2:01:19,  1.99s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.43072542548179626, 'learning_rate': 6.198305084745764e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [1:15:13<2:01:19,  1.99s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [1:15:15<1:59:47,  1.97s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.43110141158103943, 'learning_rate': 6.196610169491526e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [1:15:15<1:59:47,  1.97s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [1:15:16<1:58:15,  1.94s/it]                                                       {'loss': 0.0261, 'grad_norm': 4.377838134765625, 'learning_rate': 6.194915254237288e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [1:15:17<1:58:15,  1.94s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [1:15:18<1:57:03,  1.92s/it]                                                       {'loss': 0.3289, 'grad_norm': 11.96169376373291, 'learning_rate': 6.193220338983051e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [1:15:18<1:57:03,  1.92s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [1:15:20<1:57:33,  1.93s/it]                                                       {'loss': 0.0535, 'grad_norm': 7.66372537612915, 'learning_rate': 6.191525423728814e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [1:15:20<1:57:33,  1.93s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [1:15:22<1:57:12,  1.93s/it]                                                       {'loss': 0.009, 'grad_norm': 1.2868491411209106, 'learning_rate': 6.189830508474577e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [1:15:22<1:57:12,  1.93s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [1:15:24<1:58:23,  1.95s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.37534305453300476, 'learning_rate': 6.1881355932203395e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [1:15:24<1:58:23,  1.95s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [1:15:26<1:58:48,  1.95s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.8562091588973999, 'learning_rate': 6.186440677966103e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [1:15:26<1:58:48,  1.95s/it][2025-11-11 23:08:42,124] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2350
[2025-11-11 23:08:42,131] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:08:42,418] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2350/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [1:15:29<2:11:55,  2.17s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.7577521800994873, 'learning_rate': 6.184745762711864e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [1:15:29<2:11:55,  2.17s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [1:15:31<2:06:58,  2.09s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08015584200620651, 'learning_rate': 6.183050847457628e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [1:15:31<2:06:58,  2.09s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [1:15:33<2:05:46,  2.07s/it]                                                       {'loss': 0.1731, 'grad_norm': 10.42957592010498, 'learning_rate': 6.18135593220339e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [1:15:33<2:05:46,  2.07s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [1:15:35<2:03:22,  2.03s/it]                                                       {'loss': 0.2236, 'grad_norm': 10.4310941696167, 'learning_rate': 6.179661016949153e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [1:15:35<2:03:22,  2.03s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [1:15:37<2:03:21,  2.03s/it]                                                       {'loss': 0.0298, 'grad_norm': 2.7348625659942627, 'learning_rate': 6.177966101694916e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [1:15:37<2:03:21,  2.03s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [1:15:39<2:02:15,  2.01s/it]                                                       {'loss': 0.1016, 'grad_norm': 8.414022445678711, 'learning_rate': 6.176271186440679e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [1:15:39<2:02:15,  2.01s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [1:15:41<2:00:07,  1.98s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05101046338677406, 'learning_rate': 6.1745762711864406e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [1:15:41<2:00:07,  1.98s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [1:15:43<1:57:57,  1.94s/it]                                                       {'loss': 0.0164, 'grad_norm': 1.3803412914276123, 'learning_rate': 6.172881355932205e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [1:15:43<1:57:57,  1.94s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [1:15:44<1:57:31,  1.94s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.955451726913452, 'learning_rate': 6.171186440677966e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [1:15:44<1:57:31,  1.94s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [1:15:46<1:57:54,  1.94s/it]                                                       {'loss': 0.1113, 'grad_norm': 7.330634593963623, 'learning_rate': 6.1694915254237295e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [1:15:46<1:57:54,  1.94s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [1:15:48<2:00:08,  1.98s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.38247111439704895, 'learning_rate': 6.167796610169492e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [1:15:48<2:00:08,  1.98s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [1:15:50<1:58:59,  1.96s/it]                                                       {'loss': 0.0503, 'grad_norm': 3.6315505504608154, 'learning_rate': 6.166101694915255e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [1:15:50<1:58:59,  1.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [1:15:52<1:58:32,  1.96s/it]                                                       {'loss': 0.0031, 'grad_norm': 3.4282948970794678, 'learning_rate': 6.164406779661018e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [1:15:52<1:58:32,  1.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [1:15:54<1:58:12,  1.95s/it]                                                       {'loss': 0.0855, 'grad_norm': 6.056138038635254, 'learning_rate': 6.162711864406781e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [1:15:54<1:58:12,  1.95s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [1:15:56<1:58:43,  1.96s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.46524110436439514, 'learning_rate': 6.1610169491525425e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [1:15:56<1:58:43,  1.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [1:15:58<1:58:13,  1.95s/it]                                                       {'loss': 0.0767, 'grad_norm': 6.941844463348389, 'learning_rate': 6.159322033898305e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [1:15:58<1:58:13,  1.95s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [1:16:00<1:57:07,  1.93s/it]                                                       {'loss': 0.0443, 'grad_norm': 4.636537551879883, 'learning_rate': 6.157627118644068e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [1:16:00<1:57:07,  1.93s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [1:16:02<1:56:43,  1.93s/it]                                                       {'loss': 0.003, 'grad_norm': 0.38962239027023315, 'learning_rate': 6.155932203389831e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [1:16:02<1:56:43,  1.93s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [1:16:04<1:56:18,  1.92s/it]                                                       {'loss': 0.0113, 'grad_norm': 0.9939330220222473, 'learning_rate': 6.154237288135594e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [1:16:04<1:56:18,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [1:16:06<1:56:02,  1.92s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.9902802109718323, 'learning_rate': 6.152542372881356e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [1:16:06<1:56:02,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [1:16:08<1:54:41,  1.90s/it]                                                       {'loss': 0.0283, 'grad_norm': 4.6608405113220215, 'learning_rate': 6.15084745762712e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [1:16:08<1:54:41,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [1:16:10<1:54:26,  1.89s/it]                                                       {'loss': 0.2125, 'grad_norm': 12.438983917236328, 'learning_rate': 6.149152542372881e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [1:16:10<1:54:26,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [1:16:11<1:55:02,  1.90s/it]                                                       {'loss': 0.0705, 'grad_norm': 2.6151673793792725, 'learning_rate': 6.1474576271186445e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [1:16:11<1:55:02,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [1:16:13<1:54:39,  1.90s/it]                                                       {'loss': 0.0811, 'grad_norm': 6.504010200500488, 'learning_rate': 6.145762711864407e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [1:16:13<1:54:39,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [1:16:15<1:54:42,  1.90s/it]                                                       {'loss': 0.1601, 'grad_norm': 7.331669807434082, 'learning_rate': 6.14406779661017e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [1:16:15<1:54:42,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [1:16:17<1:55:07,  1.91s/it]                                                       {'loss': 0.0326, 'grad_norm': 4.947814464569092, 'learning_rate': 6.142372881355933e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [1:16:17<1:55:07,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [1:16:19<1:55:04,  1.91s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.5332615971565247, 'learning_rate': 6.140677966101696e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [1:16:19<1:55:04,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [1:16:21<1:55:03,  1.91s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.40068963170051575, 'learning_rate': 6.138983050847458e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [1:16:21<1:55:03,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [1:16:23<1:54:26,  1.90s/it]                                                       {'loss': 0.1589, 'grad_norm': 14.300116539001465, 'learning_rate': 6.1372881355932216e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [1:16:23<1:54:26,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [1:16:25<1:54:06,  1.89s/it]                                                       {'loss': 0.0487, 'grad_norm': 4.672207355499268, 'learning_rate': 6.135593220338983e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [1:16:25<1:54:06,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [1:16:27<1:54:09,  1.89s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.5720456838607788, 'learning_rate': 6.1338983050847464e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [1:16:27<1:54:09,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [1:16:29<1:54:50,  1.90s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07463696599006653, 'learning_rate': 6.132203389830509e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [1:16:29<1:54:50,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [1:16:30<1:54:02,  1.89s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.3822779655456543, 'learning_rate': 6.130508474576272e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [1:16:30<1:54:02,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [1:16:32<1:53:23,  1.88s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.41904962062835693, 'learning_rate': 6.1288135593220346e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [1:16:32<1:53:23,  1.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [1:16:34<1:52:51,  1.87s/it]                                                       {'loss': 0.1695, 'grad_norm': 11.117094993591309, 'learning_rate': 6.127118644067798e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [1:16:34<1:52:51,  1.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [1:16:36<1:52:50,  1.87s/it]                                                       {'loss': 0.0596, 'grad_norm': 5.99057149887085, 'learning_rate': 6.12542372881356e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [1:16:36<1:52:50,  1.87s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [1:16:38<1:54:10,  1.90s/it]                                                       {'loss': 0.1101, 'grad_norm': 6.747008800506592, 'learning_rate': 6.123728813559322e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [1:16:38<1:54:10,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [1:16:40<1:54:20,  1.90s/it]                                                       {'loss': 0.25, 'grad_norm': 9.947896003723145, 'learning_rate': 6.122033898305085e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [1:16:40<1:54:20,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [1:16:42<1:56:42,  1.94s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.7432739734649658, 'learning_rate': 6.1203389830508475e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [1:16:42<1:56:42,  1.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [1:16:44<1:56:50,  1.94s/it]                                                       {'loss': 0.0507, 'grad_norm': 4.780032634735107, 'learning_rate': 6.118644067796611e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [1:16:44<1:56:50,  1.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [1:16:46<1:55:55,  1.93s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.7281508445739746, 'learning_rate': 6.116949152542373e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [1:16:46<1:55:55,  1.93s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [1:16:48<1:55:37,  1.92s/it]                                                       {'loss': 0.079, 'grad_norm': 6.663483619689941, 'learning_rate': 6.1152542372881365e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [1:16:48<1:55:37,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [1:16:49<1:54:21,  1.90s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.8597625494003296, 'learning_rate': 6.113559322033898e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [1:16:49<1:54:21,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [1:16:51<1:54:22,  1.90s/it]                                                       {'loss': 0.0906, 'grad_norm': 5.000295639038086, 'learning_rate': 6.111864406779661e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [1:16:51<1:54:22,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [1:16:53<1:52:51,  1.88s/it]                                                       {'loss': 0.0582, 'grad_norm': 6.768104076385498, 'learning_rate': 6.110169491525424e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [1:16:53<1:52:51,  1.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [1:16:55<1:53:33,  1.89s/it]                                                       {'loss': 0.0157, 'grad_norm': 1.4963170289993286, 'learning_rate': 6.108474576271187e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [1:16:55<1:53:33,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [1:16:57<1:53:39,  1.89s/it]                                                       {'loss': 0.0511, 'grad_norm': 4.821958065032959, 'learning_rate': 6.1067796610169495e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [1:16:57<1:53:39,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [1:16:59<1:53:35,  1.89s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.8748517036437988, 'learning_rate': 6.105084745762713e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [1:16:59<1:53:35,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [1:17:01<1:53:29,  1.89s/it]                                                       {'loss': 0.1113, 'grad_norm': 4.503695964813232, 'learning_rate': 6.103389830508475e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [1:17:01<1:53:29,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [1:17:03<1:52:38,  1.88s/it]                                                       {'loss': 0.039, 'grad_norm': 6.013289928436279, 'learning_rate': 6.1016949152542385e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [1:17:03<1:52:38,  1.88s/it][2025-11-11 23:10:18,579] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400
[2025-11-11 23:10:18,586] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:10:18,964] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [1:17:05<2:08:59,  2.15s/it]                                                       {'loss': 0.007, 'grad_norm': 0.6170423030853271, 'learning_rate': 6.1e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [1:17:05<2:08:59,  2.15s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [1:17:07<2:05:53,  2.10s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1690487265586853, 'learning_rate': 6.098305084745763e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [1:17:07<2:05:53,  2.10s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [1:17:09<2:02:21,  2.04s/it]                                                       {'loss': 0.0891, 'grad_norm': 7.366464138031006, 'learning_rate': 6.096610169491526e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [1:17:09<2:02:21,  2.04s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [1:17:11<1:59:35,  2.00s/it]                                                       {'loss': 0.0418, 'grad_norm': 2.6344268321990967, 'learning_rate': 6.094915254237289e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [1:17:11<1:59:35,  2.00s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [1:17:13<1:57:34,  1.96s/it]                                                       {'loss': 0.0421, 'grad_norm': 5.7615509033203125, 'learning_rate': 6.0932203389830514e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [1:17:13<1:57:34,  1.96s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [1:17:15<1:56:26,  1.94s/it]                                                       {'loss': 0.1127, 'grad_norm': 8.252415657043457, 'learning_rate': 6.091525423728814e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [1:17:15<1:56:26,  1.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [1:17:17<1:54:58,  1.92s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5007279515266418, 'learning_rate': 6.089830508474577e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [1:17:17<1:54:58,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [1:17:19<1:54:24,  1.91s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.20237722992897034, 'learning_rate': 6.088135593220339e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [1:17:19<1:54:24,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [1:17:21<1:53:01,  1.89s/it]                                                       {'loss': 0.0336, 'grad_norm': 4.7876787185668945, 'learning_rate': 6.086440677966102e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [1:17:21<1:53:01,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [1:17:22<1:53:05,  1.89s/it]                                                       {'loss': 0.0711, 'grad_norm': 6.367847919464111, 'learning_rate': 6.084745762711864e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [1:17:22<1:53:05,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [1:17:24<1:52:44,  1.88s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.2808942198753357, 'learning_rate': 6.083050847457628e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [1:17:24<1:52:44,  1.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [1:17:26<1:55:00,  1.92s/it]                                                       {'loss': 0.001, 'grad_norm': 0.21695925295352936, 'learning_rate': 6.08135593220339e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [1:17:26<1:55:00,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [1:17:28<1:54:34,  1.92s/it]                                                       {'loss': 0.1212, 'grad_norm': 7.9361348152160645, 'learning_rate': 6.079661016949153e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [1:17:28<1:54:34,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [1:17:30<1:53:41,  1.90s/it]                                                       {'loss': 0.1676, 'grad_norm': 8.64182186126709, 'learning_rate': 6.077966101694916e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [1:17:30<1:53:41,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [1:17:32<1:54:06,  1.91s/it]                                                       {'loss': 0.0894, 'grad_norm': 7.722733497619629, 'learning_rate': 6.076271186440679e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [1:17:32<1:54:06,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [1:17:34<1:53:23,  1.90s/it]                                                       {'loss': 0.0393, 'grad_norm': 4.981986045837402, 'learning_rate': 6.074576271186441e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [1:17:34<1:53:23,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [1:17:36<1:53:49,  1.91s/it]                                                       {'loss': 0.0429, 'grad_norm': 4.122446537017822, 'learning_rate': 6.072881355932204e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [1:17:36<1:53:49,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [1:17:38<1:52:47,  1.89s/it]                                                       {'loss': 0.2035, 'grad_norm': 10.070377349853516, 'learning_rate': 6.071186440677966e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [1:17:38<1:52:47,  1.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [1:17:40<1:53:20,  1.90s/it]                                                       {'loss': 0.0272, 'grad_norm': 4.015952110290527, 'learning_rate': 6.06949152542373e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [1:17:40<1:53:20,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [1:17:42<1:55:28,  1.94s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.6371676921844482, 'learning_rate': 6.067796610169492e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [1:17:42<1:55:28,  1.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [1:17:44<1:54:41,  1.92s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.516355037689209, 'learning_rate': 6.066101694915255e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [1:17:44<1:54:41,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [1:17:46<1:57:03,  1.96s/it]                                                       {'loss': 0.0582, 'grad_norm': 5.734574794769287, 'learning_rate': 6.064406779661017e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [1:17:46<1:57:03,  1.96s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [1:17:47<1:54:50,  1.93s/it]                                                       {'loss': 0.1165, 'grad_norm': 15.852144241333008, 'learning_rate': 6.06271186440678e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [1:17:47<1:54:50,  1.93s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [1:17:49<1:53:40,  1.91s/it]                                                       {'loss': 0.2925, 'grad_norm': 14.657746315002441, 'learning_rate': 6.061016949152543e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [1:17:49<1:53:40,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [1:17:51<1:54:36,  1.92s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.24613948166370392, 'learning_rate': 6.059322033898306e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [1:17:51<1:54:36,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [1:17:53<1:53:46,  1.91s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.649360656738281, 'learning_rate': 6.057627118644068e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [1:17:53<1:53:46,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [1:17:55<1:53:34,  1.91s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.4106025695800781, 'learning_rate': 6.055932203389831e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [1:17:55<1:53:34,  1.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [1:17:57<1:53:24,  1.90s/it]                                                       {'loss': 0.0466, 'grad_norm': 3.50671124458313, 'learning_rate': 6.054237288135594e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [1:17:57<1:53:24,  1.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [1:17:59<1:54:05,  1.92s/it]                                                       {'loss': 0.0133, 'grad_norm': 10.515374183654785, 'learning_rate': 6.052542372881356e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [1:17:59<1:54:05,  1.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [1:18:01<1:54:30,  1.92s/it]                                                       {'loss': 0.1011, 'grad_norm': 34.39180374145508, 'learning_rate': 6.050847457627119e-06, 'epoch': 0.41}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [1:18:01<1:54:30,  1.92s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [1:18:03<1:54:35,  1.93s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0334877148270607, 'learning_rate': 6.049152542372881e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [1:18:03<1:54:35,  1.93s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [1:18:05<1:53:02,  1.90s/it]                                                       {'loss': 0.0556, 'grad_norm': 5.7111358642578125, 'learning_rate': 6.047457627118645e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [1:18:05<1:53:02,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [1:18:06<1:52:43,  1.90s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1614512801170349, 'learning_rate': 6.045762711864407e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [1:18:07<1:52:43,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [1:18:08<1:53:38,  1.91s/it]                                                       {'loss': 0.0105, 'grad_norm': 0.6561967134475708, 'learning_rate': 6.04406779661017e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [1:18:08<1:53:38,  1.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [1:18:10<1:53:08,  1.90s/it]                                                       {'loss': 0.0394, 'grad_norm': 5.278377056121826, 'learning_rate': 6.042372881355933e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [1:18:10<1:53:08,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [1:18:12<1:52:05,  1.89s/it]                                                       {'loss': 0.0755, 'grad_norm': 5.145429611206055, 'learning_rate': 6.040677966101696e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [1:18:12<1:52:05,  1.89s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [1:18:14<1:51:06,  1.87s/it]                                                       {'loss': 0.014, 'grad_norm': 2.254518508911133, 'learning_rate': 6.0389830508474576e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [1:18:14<1:51:06,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [1:18:16<1:51:36,  1.88s/it]                                                       {'loss': 0.0636, 'grad_norm': 5.769624710083008, 'learning_rate': 6.037288135593221e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [1:18:16<1:51:36,  1.88s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [1:18:18<1:53:24,  1.91s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.8015404343605042, 'learning_rate': 6.035593220338983e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [1:18:18<1:53:24,  1.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [1:18:20<1:52:36,  1.90s/it]                                                       {'loss': 0.0509, 'grad_norm': 3.55928373336792, 'learning_rate': 6.0338983050847465e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [1:18:20<1:52:36,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [1:18:22<1:54:47,  1.94s/it]                                                       {'loss': 0.0176, 'grad_norm': 1.8080964088439941, 'learning_rate': 6.032203389830509e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [1:18:22<1:54:47,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [1:18:24<1:53:03,  1.91s/it]                                                       {'loss': 0.0246, 'grad_norm': 3.385395050048828, 'learning_rate': 6.030508474576272e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [1:18:24<1:53:03,  1.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [1:18:26<1:52:37,  1.90s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.3011177778244019, 'learning_rate': 6.028813559322035e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [1:18:26<1:52:37,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [1:18:27<1:51:21,  1.88s/it]                                                       {'loss': 0.2516, 'grad_norm': 9.16540813446045, 'learning_rate': 6.027118644067798e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [1:18:27<1:51:21,  1.88s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [1:18:29<1:52:29,  1.90s/it]                                                       {'loss': 0.0442, 'grad_norm': 3.2208969593048096, 'learning_rate': 6.0254237288135595e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [1:18:29<1:52:29,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [1:18:31<1:52:43,  1.90s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.221169352531433, 'learning_rate': 6.023728813559323e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [1:18:31<1:52:43,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [1:18:33<1:52:33,  1.90s/it]                                                       {'loss': 0.0218, 'grad_norm': 2.686011791229248, 'learning_rate': 6.022033898305085e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [1:18:33<1:52:33,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [1:18:35<1:53:24,  1.92s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1717459112405777, 'learning_rate': 6.020338983050848e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [1:18:35<1:53:24,  1.92s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [1:18:37<1:52:20,  1.90s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.12911805510520935, 'learning_rate': 6.018644067796611e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [1:18:37<1:52:20,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [1:18:39<1:51:34,  1.89s/it]                                                       {'loss': 0.1067, 'grad_norm': 8.6438570022583, 'learning_rate': 6.0169491525423725e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [1:18:39<1:51:34,  1.89s/it][2025-11-11 23:11:54,680] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2450
[2025-11-11 23:11:54,687] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:11:54,982] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2450/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [1:18:41<2:04:45,  2.11s/it]                                                       {'loss': 0.0316, 'grad_norm': 3.800295352935791, 'learning_rate': 6.015254237288136e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [1:18:41<2:04:45,  2.11s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [1:18:43<2:00:22,  2.04s/it]                                                       {'loss': 0.1133, 'grad_norm': 5.073452472686768, 'learning_rate': 6.013559322033898e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [1:18:43<2:00:22,  2.04s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [1:18:45<1:58:29,  2.00s/it]                                                       {'loss': 0.1977, 'grad_norm': 8.098052978515625, 'learning_rate': 6.0118644067796615e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [1:18:45<1:58:29,  2.00s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [1:18:47<1:55:46,  1.96s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.6944080591201782, 'learning_rate': 6.010169491525424e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [1:18:47<1:55:46,  1.96s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [1:18:49<1:54:34,  1.94s/it]                                                       {'loss': 0.064, 'grad_norm': 4.861069679260254, 'learning_rate': 6.008474576271187e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [1:18:49<1:54:34,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [1:18:51<1:53:52,  1.93s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.707226037979126, 'learning_rate': 6.00677966101695e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [1:18:51<1:53:52,  1.93s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [1:18:53<1:52:59,  1.91s/it]                                                       {'loss': 0.0848, 'grad_norm': 5.339653491973877, 'learning_rate': 6.005084745762713e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [1:18:53<1:52:59,  1.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [1:18:55<1:54:43,  1.94s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08132411539554596, 'learning_rate': 6.0033898305084745e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [1:18:55<1:54:43,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [1:18:57<1:56:01,  1.97s/it]                                                       {'loss': 0.0417, 'grad_norm': 6.111300945281982, 'learning_rate': 6.001694915254238e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [1:18:57<1:56:01,  1.97s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [1:18:59<1:54:16,  1.94s/it]                                                       {'loss': 0.0921, 'grad_norm': 6.8169074058532715, 'learning_rate': 6e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [1:18:59<1:54:16,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [1:19:01<1:54:40,  1.94s/it]                                                       {'loss': 0.0442, 'grad_norm': 1.8981853723526, 'learning_rate': 5.9983050847457634e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [1:19:01<1:54:40,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [1:19:02<1:53:25,  1.92s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.9308667182922363, 'learning_rate': 5.996610169491526e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [1:19:02<1:53:25,  1.92s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [1:19:04<1:52:59,  1.92s/it]                                                       {'loss': 0.0788, 'grad_norm': 6.8538689613342285, 'learning_rate': 5.994915254237289e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [1:19:04<1:52:59,  1.92s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [1:19:06<1:52:26,  1.91s/it]                                                       {'loss': 0.1769, 'grad_norm': 9.43789291381836, 'learning_rate': 5.9932203389830516e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [1:19:06<1:52:26,  1.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [1:19:08<1:54:05,  1.94s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.0920422077178955, 'learning_rate': 5.991525423728815e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [1:19:08<1:54:05,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [1:19:10<1:53:16,  1.92s/it]                                                       {'loss': 0.003, 'grad_norm': 0.7170596122741699, 'learning_rate': 5.989830508474576e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [1:19:10<1:53:16,  1.92s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [1:19:12<1:51:37,  1.90s/it]                                                       {'loss': 0.022, 'grad_norm': 2.9193310737609863, 'learning_rate': 5.98813559322034e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [1:19:12<1:51:37,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [1:19:14<1:51:06,  1.89s/it]                                                       {'loss': 0.0535, 'grad_norm': 4.2625627517700195, 'learning_rate': 5.986440677966102e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [1:19:14<1:51:06,  1.89s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [1:19:16<1:49:47,  1.87s/it]                                                       {'loss': 0.0675, 'grad_norm': 7.419461250305176, 'learning_rate': 5.9847457627118645e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [1:19:16<1:49:47,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [1:19:18<1:49:30,  1.86s/it]                                                       {'loss': 0.1193, 'grad_norm': 6.58085298538208, 'learning_rate': 5.983050847457628e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [1:19:18<1:49:30,  1.86s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [1:19:19<1:49:32,  1.86s/it]                                                       {'loss': 0.0307, 'grad_norm': 2.303781270980835, 'learning_rate': 5.98135593220339e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [1:19:19<1:49:32,  1.86s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [1:19:21<1:49:32,  1.86s/it]                                                       {'loss': 0.2784, 'grad_norm': 18.537569046020508, 'learning_rate': 5.9796610169491535e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [1:19:21<1:49:32,  1.86s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [1:19:23<1:49:25,  1.86s/it]                                                       {'loss': 0.2123, 'grad_norm': 9.524127960205078, 'learning_rate': 5.977966101694915e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [1:19:23<1:49:25,  1.86s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [1:19:25<1:49:41,  1.87s/it]                                                       {'loss': 0.1489, 'grad_norm': 6.037777423858643, 'learning_rate': 5.976271186440678e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [1:19:25<1:49:41,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [1:19:27<1:49:15,  1.86s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.9505600929260254, 'learning_rate': 5.974576271186441e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [1:19:27<1:49:15,  1.86s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [1:19:29<1:50:03,  1.87s/it]                                                       {'loss': 0.1341, 'grad_norm': 6.085363388061523, 'learning_rate': 5.972881355932204e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [1:19:29<1:50:03,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [1:19:31<1:49:58,  1.87s/it]                                                       {'loss': 0.1606, 'grad_norm': 9.704246520996094, 'learning_rate': 5.9711864406779665e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [1:19:31<1:49:58,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [1:19:32<1:49:58,  1.87s/it]                                                       {'loss': 0.0353, 'grad_norm': 4.152342796325684, 'learning_rate': 5.96949152542373e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [1:19:32<1:49:58,  1.87s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [1:19:34<1:50:09,  1.88s/it]                                                       {'loss': 0.0704, 'grad_norm': 8.321687698364258, 'learning_rate': 5.967796610169491e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [1:19:34<1:50:09,  1.88s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [1:19:36<1:51:15,  1.90s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.22160452604293823, 'learning_rate': 5.9661016949152555e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [1:19:36<1:51:15,  1.90s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [1:19:38<1:50:44,  1.89s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.8087114095687866, 'learning_rate': 5.964406779661017e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [1:19:38<1:50:44,  1.89s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [1:19:40<1:50:01,  1.88s/it]                                                       {'loss': 0.043, 'grad_norm': 5.753751754760742, 'learning_rate': 5.96271186440678e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [1:19:40<1:50:01,  1.88s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [1:19:42<1:52:24,  1.92s/it]                                                       {'loss': 0.0722, 'grad_norm': 3.2622101306915283, 'learning_rate': 5.961016949152543e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [1:19:42<1:52:24,  1.92s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [1:19:44<1:54:34,  1.96s/it]                                                       {'loss': 0.4104, 'grad_norm': 10.643440246582031, 'learning_rate': 5.959322033898306e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [1:19:44<1:54:34,  1.96s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [1:19:46<1:53:38,  1.94s/it]                                                       {'loss': 0.0454, 'grad_norm': 5.155913352966309, 'learning_rate': 5.9576271186440684e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [1:19:46<1:53:38,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [1:19:48<1:53:15,  1.93s/it]                                                       {'loss': 0.0208, 'grad_norm': 2.682573080062866, 'learning_rate': 5.955932203389832e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [1:19:48<1:53:15,  1.93s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [1:19:50<1:53:10,  1.93s/it]                                                       {'loss': 0.0515, 'grad_norm': 3.857259511947632, 'learning_rate': 5.954237288135593e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [1:19:50<1:53:10,  1.93s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [1:19:52<1:53:06,  1.93s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6612639427185059, 'learning_rate': 5.9525423728813566e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [1:19:52<1:53:06,  1.93s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [1:19:54<1:51:59,  1.91s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.783486843109131, 'learning_rate': 5.950847457627119e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [1:19:54<1:51:59,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [1:19:56<1:52:29,  1.92s/it]                                                       {'loss': 0.0774, 'grad_norm': 4.834009647369385, 'learning_rate': 5.949152542372881e-06, 'epoch': 0.41}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [1:19:56<1:52:29,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [1:19:57<1:52:16,  1.92s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.0223203897476196, 'learning_rate': 5.947457627118645e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [1:19:57<1:52:16,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [1:19:59<1:51:37,  1.91s/it]                                                       {'loss': 0.1262, 'grad_norm': 9.343645095825195, 'learning_rate': 5.945762711864407e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [1:19:59<1:51:37,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [1:20:01<1:50:36,  1.89s/it]                                                       {'loss': 0.1644, 'grad_norm': 7.32483434677124, 'learning_rate': 5.94406779661017e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [1:20:01<1:50:36,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [1:20:03<1:51:04,  1.90s/it]                                                       {'loss': 0.2309, 'grad_norm': 12.060039520263672, 'learning_rate': 5.942372881355932e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [1:20:03<1:51:04,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [1:20:05<1:52:41,  1.93s/it]                                                       {'loss': 0.1109, 'grad_norm': 7.329113960266113, 'learning_rate': 5.940677966101695e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [1:20:05<1:52:41,  1.93s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [1:20:07<1:53:33,  1.94s/it]                                                       {'loss': 0.002, 'grad_norm': 0.22163164615631104, 'learning_rate': 5.938983050847458e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [1:20:07<1:53:33,  1.94s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [1:20:09<1:53:32,  1.94s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3919256329536438, 'learning_rate': 5.937288135593221e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [1:20:09<1:53:32,  1.94s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [1:20:11<1:54:20,  1.96s/it]                                                       {'loss': 0.1694, 'grad_norm': 9.422685623168945, 'learning_rate': 5.935593220338983e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [1:20:11<1:54:20,  1.96s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [1:20:13<1:52:09,  1.92s/it]                                                       {'loss': 0.0675, 'grad_norm': 7.112026691436768, 'learning_rate': 5.933898305084747e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [1:20:13<1:52:09,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [1:20:15<1:51:37,  1.91s/it]                                                       {'loss': 0.0228, 'grad_norm': 4.306712627410889, 'learning_rate': 5.932203389830509e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [1:20:15<1:51:37,  1.91s/it][2025-11-11 23:13:30,697] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500
[2025-11-11 23:13:30,704] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:13:30,999] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [1:20:17<2:05:17,  2.15s/it]                                                       {'loss': 0.0456, 'grad_norm': 3.8665578365325928, 'learning_rate': 5.930508474576272e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [1:20:17<2:05:17,  2.15s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [1:20:19<1:59:59,  2.06s/it]                                                       {'loss': 0.3102, 'grad_norm': 12.122336387634277, 'learning_rate': 5.928813559322034e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [1:20:19<1:59:59,  2.06s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [1:20:21<1:56:32,  2.00s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.11528309434652328, 'learning_rate': 5.927118644067797e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [1:20:21<1:56:32,  2.00s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [1:20:23<1:54:26,  1.96s/it]                                                       {'loss': 0.3074, 'grad_norm': 9.900674819946289, 'learning_rate': 5.92542372881356e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [1:20:23<1:54:26,  1.96s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [1:20:25<1:56:28,  2.00s/it]                                                       {'loss': 0.1236, 'grad_norm': 7.861959934234619, 'learning_rate': 5.923728813559323e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [1:20:25<1:56:28,  2.00s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [1:20:27<1:54:48,  1.97s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.14551503956317902, 'learning_rate': 5.922033898305085e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [1:20:27<1:54:48,  1.97s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [1:20:29<1:52:47,  1.94s/it]                                                       {'loss': 0.0257, 'grad_norm': 1.4585494995117188, 'learning_rate': 5.920338983050849e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [1:20:29<1:52:47,  1.94s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [1:20:31<1:51:02,  1.91s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.017056727781891823, 'learning_rate': 5.91864406779661e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [1:20:31<1:51:02,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [1:20:33<1:50:24,  1.90s/it]                                                       {'loss': 0.2525, 'grad_norm': 9.451760292053223, 'learning_rate': 5.916949152542374e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [1:20:33<1:50:24,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [1:20:35<1:50:56,  1.91s/it]                                                       {'loss': 0.008, 'grad_norm': 0.84430992603302, 'learning_rate': 5.915254237288136e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [1:20:35<1:50:56,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [1:20:37<1:52:04,  1.93s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2132561057806015, 'learning_rate': 5.913559322033898e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [1:20:37<1:52:04,  1.93s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [1:20:38<1:50:45,  1.91s/it]                                                       {'loss': 0.007, 'grad_norm': 0.7458147406578064, 'learning_rate': 5.911864406779662e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [1:20:38<1:50:45,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [1:20:40<1:50:12,  1.90s/it]                                                       {'loss': 0.0248, 'grad_norm': 3.370889663696289, 'learning_rate': 5.910169491525424e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [1:20:40<1:50:12,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [1:20:42<1:50:00,  1.89s/it]                                                       {'loss': 0.1668, 'grad_norm': 8.591519355773926, 'learning_rate': 5.908474576271187e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [1:20:42<1:50:00,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [1:20:44<1:50:31,  1.90s/it]                                                       {'loss': 0.3544, 'grad_norm': 10.513671875, 'learning_rate': 5.906779661016949e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [1:20:44<1:50:31,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [1:20:46<1:50:27,  1.90s/it]                                                       {'loss': 0.1055, 'grad_norm': 8.107293128967285, 'learning_rate': 5.905084745762712e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [1:20:46<1:50:27,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [1:20:48<1:51:32,  1.92s/it]                                                       {'loss': 0.1338, 'grad_norm': 10.56250286102295, 'learning_rate': 5.9033898305084746e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [1:20:48<1:51:32,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [1:20:50<1:50:22,  1.90s/it]                                                       {'loss': 0.1176, 'grad_norm': 11.470239639282227, 'learning_rate': 5.901694915254238e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [1:20:50<1:50:22,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [1:20:52<1:49:36,  1.89s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.714078664779663, 'learning_rate': 5.9e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [1:20:52<1:49:36,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [1:20:54<1:49:35,  1.89s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.5230538845062256, 'learning_rate': 5.8983050847457635e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [1:20:54<1:49:35,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [1:20:55<1:49:27,  1.89s/it]                                                       {'loss': 0.0444, 'grad_norm': 6.264676570892334, 'learning_rate': 5.896610169491526e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [1:20:55<1:49:27,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [1:20:57<1:51:53,  1.93s/it]                                                       {'loss': 0.0428, 'grad_norm': 4.550413608551025, 'learning_rate': 5.894915254237289e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [1:20:57<1:51:53,  1.93s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [1:20:59<1:50:57,  1.91s/it]                                                       {'loss': 0.1868, 'grad_norm': 8.085293769836426, 'learning_rate': 5.893220338983051e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [1:20:59<1:50:57,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [1:21:01<1:49:42,  1.89s/it]                                                       {'loss': 0.0162, 'grad_norm': 2.031322956085205, 'learning_rate': 5.891525423728814e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [1:21:01<1:49:42,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [1:21:03<1:49:56,  1.90s/it]                                                       {'loss': 0.3055, 'grad_norm': 20.718896865844727, 'learning_rate': 5.8898305084745765e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [1:21:03<1:49:56,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [1:21:05<1:53:43,  1.96s/it]                                                       {'loss': 0.0387, 'grad_norm': 3.818063497543335, 'learning_rate': 5.88813559322034e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [1:21:05<1:53:43,  1.96s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [1:21:07<1:54:31,  1.98s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.9440128803253174, 'learning_rate': 5.886440677966102e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [1:21:07<1:54:31,  1.98s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [1:21:09<1:53:16,  1.96s/it]                                                       {'loss': 0.1696, 'grad_norm': 6.4202470779418945, 'learning_rate': 5.8847457627118655e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [1:21:09<1:53:16,  1.96s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [1:21:11<1:52:15,  1.94s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.6676716804504395, 'learning_rate': 5.883050847457628e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [1:21:11<1:52:15,  1.94s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [1:21:13<1:51:54,  1.94s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6115752458572388, 'learning_rate': 5.881355932203391e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [1:21:13<1:51:54,  1.94s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [1:21:15<1:51:06,  1.92s/it]                                                       {'loss': 0.0411, 'grad_norm': 3.6563689708709717, 'learning_rate': 5.879661016949153e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [1:21:15<1:51:06,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [1:21:17<1:53:22,  1.96s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4801323115825653, 'learning_rate': 5.877966101694915e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [1:21:17<1:53:22,  1.96s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [1:21:19<1:52:12,  1.94s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.23353473842144012, 'learning_rate': 5.8762711864406785e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [1:21:19<1:52:12,  1.94s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [1:21:21<1:51:23,  1.93s/it]                                                       {'loss': 0.036, 'grad_norm': 4.863333702087402, 'learning_rate': 5.874576271186441e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [1:21:21<1:51:23,  1.93s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [1:21:23<1:50:31,  1.91s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.6758925914764404, 'learning_rate': 5.872881355932204e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [1:21:23<1:50:31,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [1:21:24<1:50:09,  1.91s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.188520073890686, 'learning_rate': 5.871186440677966e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [1:21:24<1:50:09,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [1:21:26<1:49:38,  1.90s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.7965220808982849, 'learning_rate': 5.86949152542373e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [1:21:26<1:49:38,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [1:21:28<1:49:44,  1.90s/it]                                                       {'loss': 0.0704, 'grad_norm': 9.608453750610352, 'learning_rate': 5.8677966101694915e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [1:21:28<1:49:44,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [1:21:30<1:49:23,  1.90s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.8730148673057556, 'learning_rate': 5.866101694915255e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [1:21:30<1:49:23,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [1:21:32<1:49:55,  1.91s/it]                                                       {'loss': 0.1422, 'grad_norm': 7.930703639984131, 'learning_rate': 5.864406779661017e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [1:21:32<1:49:55,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [1:21:34<1:49:32,  1.90s/it]                                                       {'loss': 0.0581, 'grad_norm': 6.1682233810424805, 'learning_rate': 5.8627118644067804e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [1:21:34<1:49:32,  1.90s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [1:21:36<1:48:34,  1.88s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.8188875913619995, 'learning_rate': 5.861016949152543e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [1:21:36<1:48:34,  1.88s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [1:21:38<1:48:39,  1.89s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.1562488079071045, 'learning_rate': 5.859322033898306e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [1:21:38<1:48:39,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [1:21:40<1:48:42,  1.89s/it]                                                       {'loss': 0.0356, 'grad_norm': 2.2944986820220947, 'learning_rate': 5.857627118644068e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [1:21:40<1:48:42,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [1:21:41<1:48:38,  1.89s/it]                                                       {'loss': 0.0679, 'grad_norm': 6.427162170410156, 'learning_rate': 5.855932203389831e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [1:21:41<1:48:38,  1.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [1:21:43<1:49:40,  1.91s/it]                                                       {'loss': 0.0737, 'grad_norm': 3.8820855617523193, 'learning_rate': 5.854237288135593e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [1:21:43<1:49:40,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [1:21:45<1:50:16,  1.92s/it]                                                       {'loss': 0.043, 'grad_norm': 4.29502534866333, 'learning_rate': 5.852542372881357e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [1:21:45<1:50:16,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [1:21:47<1:50:20,  1.92s/it]                                                       {'loss': 0.3154, 'grad_norm': 10.631393432617188, 'learning_rate': 5.850847457627119e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [1:21:47<1:50:20,  1.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [1:21:49<1:49:50,  1.91s/it]                                                       {'loss': 0.0173, 'grad_norm': 2.26358962059021, 'learning_rate': 5.849152542372882e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [1:21:49<1:49:50,  1.91s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [1:21:51<1:49:20,  1.90s/it]                                                       {'loss': 0.1776, 'grad_norm': 9.577119827270508, 'learning_rate': 5.847457627118645e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [1:21:51<1:49:20,  1.90s/it][2025-11-11 23:15:06,966] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2550
[2025-11-11 23:15:06,973] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:15:07,281] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2550/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [1:21:54<2:03:15,  2.14s/it]                                                       {'loss': 0.1987, 'grad_norm': 11.583292961120605, 'learning_rate': 5.845762711864408e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [1:21:54<2:03:15,  2.14s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [1:21:56<1:58:52,  2.07s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.9464401006698608, 'learning_rate': 5.84406779661017e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [1:21:56<1:58:52,  2.07s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [1:21:58<1:55:35,  2.01s/it]                                                       {'loss': 0.0428, 'grad_norm': 3.2179174423217773, 'learning_rate': 5.842372881355932e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [1:21:58<1:55:35,  2.01s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [1:22:00<1:55:20,  2.01s/it]                                                       {'loss': 0.0338, 'grad_norm': 3.440589189529419, 'learning_rate': 5.840677966101695e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [1:22:00<1:55:20,  2.01s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [1:22:01<1:52:45,  1.96s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5791534781455994, 'learning_rate': 5.838983050847458e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [1:22:01<1:52:45,  1.96s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [1:22:03<1:51:18,  1.94s/it]                                                       {'loss': 0.1213, 'grad_norm': 7.627776145935059, 'learning_rate': 5.837288135593221e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [1:22:03<1:51:18,  1.94s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [1:22:05<1:50:11,  1.92s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.6230692267417908, 'learning_rate': 5.8355932203389835e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [1:22:05<1:50:11,  1.92s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [1:22:07<1:49:21,  1.91s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.7280038595199585, 'learning_rate': 5.833898305084747e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [1:22:07<1:49:21,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [1:22:09<1:48:46,  1.90s/it]                                                       {'loss': 0.1783, 'grad_norm': 7.230185508728027, 'learning_rate': 5.832203389830508e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [1:22:09<1:48:46,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [1:22:11<1:48:12,  1.89s/it]                                                       {'loss': 0.0227, 'grad_norm': 2.384761333465576, 'learning_rate': 5.830508474576272e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [1:22:11<1:48:12,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [1:22:13<1:48:20,  1.89s/it]                                                       {'loss': 0.0561, 'grad_norm': 6.0034871101379395, 'learning_rate': 5.828813559322034e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [1:22:13<1:48:20,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [1:22:15<1:49:12,  1.91s/it]                                                       {'loss': 0.0735, 'grad_norm': 5.0441179275512695, 'learning_rate': 5.827118644067797e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [1:22:15<1:49:12,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [1:22:16<1:48:27,  1.89s/it]                                                       {'loss': 0.1657, 'grad_norm': 7.362552642822266, 'learning_rate': 5.82542372881356e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [1:22:16<1:48:27,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [1:22:18<1:49:20,  1.91s/it]                                                       {'loss': 0.0385, 'grad_norm': 3.838433265686035, 'learning_rate': 5.823728813559323e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [1:22:18<1:49:20,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [1:22:20<1:47:36,  1.88s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5142024159431458, 'learning_rate': 5.8220338983050854e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [1:22:20<1:47:36,  1.88s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [1:22:22<1:47:27,  1.88s/it]                                                       {'loss': 0.3174, 'grad_norm': 9.141399383544922, 'learning_rate': 5.820338983050849e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [1:22:22<1:47:27,  1.88s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [1:22:24<1:48:38,  1.90s/it]                                                       {'loss': 0.0496, 'grad_norm': 9.162002563476562, 'learning_rate': 5.81864406779661e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [1:22:24<1:48:38,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [1:22:26<1:49:19,  1.91s/it]                                                       {'loss': 0.0278, 'grad_norm': 2.9213461875915527, 'learning_rate': 5.8169491525423736e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [1:22:26<1:49:19,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [1:22:28<1:49:30,  1.91s/it]                                                       {'loss': 0.1413, 'grad_norm': 11.223461151123047, 'learning_rate': 5.815254237288136e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [1:22:28<1:49:30,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [1:22:30<1:48:54,  1.91s/it]                                                       {'loss': 0.0755, 'grad_norm': 5.144726276397705, 'learning_rate': 5.813559322033899e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [1:22:30<1:48:54,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [1:22:32<1:48:10,  1.89s/it]                                                       {'loss': 0.027, 'grad_norm': 2.56172513961792, 'learning_rate': 5.811864406779662e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [1:22:32<1:48:10,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [1:22:34<1:48:02,  1.89s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.9908459782600403, 'learning_rate': 5.810169491525425e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [1:22:34<1:48:02,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [1:22:35<1:46:58,  1.87s/it]                                                       {'loss': 0.058, 'grad_norm': 6.452486038208008, 'learning_rate': 5.8084745762711865e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [1:22:35<1:46:58,  1.87s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [1:22:37<1:47:00,  1.87s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.0472934246063232, 'learning_rate': 5.806779661016949e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [1:22:37<1:47:00,  1.87s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [1:22:39<1:47:55,  1.89s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.5431949496269226, 'learning_rate': 5.805084745762712e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [1:22:39<1:47:55,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [1:22:41<1:47:33,  1.88s/it]                                                       {'loss': 0.0588, 'grad_norm': 8.833938598632812, 'learning_rate': 5.803389830508475e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [1:22:41<1:47:33,  1.88s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [1:22:43<1:48:02,  1.89s/it]                                                       {'loss': 0.0816, 'grad_norm': 5.930996417999268, 'learning_rate': 5.801694915254238e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [1:22:43<1:48:02,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [1:22:45<1:48:32,  1.90s/it]                                                       {'loss': 0.1222, 'grad_norm': 9.821131706237793, 'learning_rate': 5.8e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [1:22:45<1:48:32,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [1:22:47<1:48:07,  1.90s/it]                                                       {'loss': 0.0166, 'grad_norm': 3.079665184020996, 'learning_rate': 5.798305084745764e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [1:22:47<1:48:07,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [1:22:49<1:48:49,  1.91s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6761288642883301, 'learning_rate': 5.796610169491525e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [1:22:49<1:48:49,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [1:22:51<1:48:54,  1.91s/it]                                                       {'loss': 0.1068, 'grad_norm': 7.75174617767334, 'learning_rate': 5.7949152542372885e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [1:22:51<1:48:54,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [1:22:53<1:49:36,  1.92s/it]                                                       {'loss': 0.3168, 'grad_norm': 13.16046142578125, 'learning_rate': 5.793220338983051e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [1:22:53<1:49:36,  1.92s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [1:22:54<1:48:40,  1.91s/it]                                                       {'loss': 0.235, 'grad_norm': 9.904598236083984, 'learning_rate': 5.791525423728814e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [1:22:54<1:48:40,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [1:22:56<1:48:00,  1.90s/it]                                                       {'loss': 0.2141, 'grad_norm': 7.613056182861328, 'learning_rate': 5.789830508474577e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [1:22:56<1:48:00,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [1:22:58<1:47:48,  1.89s/it]                                                       {'loss': 0.114, 'grad_norm': 3.988356590270996, 'learning_rate': 5.78813559322034e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [1:22:58<1:47:48,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [1:23:00<1:50:06,  1.94s/it]                                                       {'loss': 0.1956, 'grad_norm': 8.042777061462402, 'learning_rate': 5.786440677966102e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [1:23:00<1:50:06,  1.94s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [1:23:02<1:48:23,  1.91s/it]                                                       {'loss': 0.0639, 'grad_norm': 7.073698997497559, 'learning_rate': 5.784745762711866e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [1:23:02<1:48:23,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [1:23:04<1:50:34,  1.94s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08633995801210403, 'learning_rate': 5.783050847457627e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [1:23:04<1:50:34,  1.94s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [1:23:06<1:49:27,  1.93s/it]                                                       {'loss': 0.0182, 'grad_norm': 2.4909884929656982, 'learning_rate': 5.7813559322033905e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [1:23:06<1:49:27,  1.93s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [1:23:08<1:48:55,  1.92s/it]                                                       {'loss': 0.0175, 'grad_norm': 1.0231996774673462, 'learning_rate': 5.779661016949153e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [1:23:08<1:48:55,  1.92s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [1:23:10<1:48:44,  1.91s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.21102508902549744, 'learning_rate': 5.777966101694916e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [1:23:10<1:48:44,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [1:23:12<1:47:49,  1.90s/it]                                                       {'loss': 0.2063, 'grad_norm': 13.914586067199707, 'learning_rate': 5.776271186440679e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [1:23:12<1:47:49,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [1:23:14<1:47:10,  1.89s/it]                                                       {'loss': 0.0232, 'grad_norm': 2.4546139240264893, 'learning_rate': 5.774576271186441e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [1:23:14<1:47:10,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [1:23:15<1:46:26,  1.88s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.4652788639068604, 'learning_rate': 5.772881355932204e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [1:23:15<1:46:26,  1.88s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [1:23:17<1:47:27,  1.89s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.45260608196258545, 'learning_rate': 5.771186440677966e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [1:23:17<1:47:27,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [1:23:19<1:48:04,  1.91s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.046099141240119934, 'learning_rate': 5.769491525423729e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [1:23:19<1:48:04,  1.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [1:23:21<1:48:01,  1.90s/it]                                                       {'loss': 0.1121, 'grad_norm': 7.405091762542725, 'learning_rate': 5.7677966101694916e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [1:23:21<1:48:01,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [1:23:23<1:47:15,  1.89s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.41575148701667786, 'learning_rate': 5.766101694915255e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [1:23:23<1:47:15,  1.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [1:23:25<1:47:27,  1.90s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.5921502113342285, 'learning_rate': 5.764406779661017e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [1:23:25<1:47:27,  1.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [1:23:27<1:47:02,  1.89s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.1480591297149658, 'learning_rate': 5.7627118644067805e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [1:23:27<1:47:02,  1.89s/it][2025-11-11 23:16:42,692] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600
[2025-11-11 23:16:42,700] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:16:42,980] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [1:23:30<2:02:51,  2.17s/it]                                                       {'loss': 0.197, 'grad_norm': 9.134499549865723, 'learning_rate': 5.761016949152542e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [1:23:30<2:02:51,  2.17s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [1:23:31<1:57:55,  2.08s/it]                                                       {'loss': 0.0433, 'grad_norm': 4.35854959487915, 'learning_rate': 5.759322033898305e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [1:23:31<1:57:55,  2.08s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [1:23:33<1:55:14,  2.04s/it]                                                       {'loss': 0.0746, 'grad_norm': 4.365592956542969, 'learning_rate': 5.757627118644068e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [1:23:33<1:55:14,  2.04s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [1:23:35<1:53:03,  2.00s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.0640093088150024, 'learning_rate': 5.755932203389831e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [1:23:35<1:53:03,  2.00s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [1:23:37<1:51:08,  1.96s/it]                                                       {'loss': 0.0799, 'grad_norm': 4.786599636077881, 'learning_rate': 5.7542372881355935e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [1:23:37<1:51:08,  1.96s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [1:23:39<1:49:42,  1.94s/it]                                                       {'loss': 0.0279, 'grad_norm': 1.886677622795105, 'learning_rate': 5.752542372881357e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [1:23:39<1:49:42,  1.94s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [1:23:41<1:48:58,  1.93s/it]                                                       {'loss': 0.0286, 'grad_norm': 3.220975637435913, 'learning_rate': 5.750847457627119e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [1:23:41<1:48:58,  1.93s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [1:23:43<1:48:30,  1.92s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.44612932205200195, 'learning_rate': 5.7491525423728825e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [1:23:43<1:48:30,  1.92s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [1:23:45<1:48:03,  1.91s/it]                                                       {'loss': 0.0216, 'grad_norm': 4.5926971435546875, 'learning_rate': 5.747457627118644e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [1:23:45<1:48:03,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [1:23:47<1:49:58,  1.95s/it]                                                       {'loss': 0.0563, 'grad_norm': 6.721621990203857, 'learning_rate': 5.745762711864407e-06, 'epoch': 0.43}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [1:23:47<1:49:58,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [1:23:49<1:49:15,  1.93s/it]                                                       {'loss': 0.1349, 'grad_norm': 7.669739723205566, 'learning_rate': 5.74406779661017e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [1:23:49<1:49:15,  1.93s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [1:23:51<1:47:13,  1.90s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.023214058950543404, 'learning_rate': 5.742372881355933e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [1:23:51<1:47:13,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [1:23:53<1:49:09,  1.93s/it]                                                       {'loss': 0.0469, 'grad_norm': 4.105461120605469, 'learning_rate': 5.7406779661016955e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [1:23:53<1:49:09,  1.93s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [1:23:54<1:48:09,  1.92s/it]                                                       {'loss': 0.0592, 'grad_norm': 4.515573024749756, 'learning_rate': 5.738983050847458e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [1:23:54<1:48:09,  1.92s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [1:23:56<1:46:55,  1.90s/it]                                                       {'loss': 0.1173, 'grad_norm': 6.449240684509277, 'learning_rate': 5.737288135593221e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [1:23:56<1:46:55,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [1:23:58<1:46:49,  1.89s/it]                                                       {'loss': 0.2241, 'grad_norm': 8.5927095413208, 'learning_rate': 5.735593220338983e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [1:23:58<1:46:49,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [1:24:00<1:45:54,  1.88s/it]                                                       {'loss': 0.0454, 'grad_norm': 5.334017276763916, 'learning_rate': 5.733898305084746e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [1:24:00<1:45:54,  1.88s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [1:24:02<1:46:23,  1.89s/it]                                                       {'loss': 0.1438, 'grad_norm': 9.039969444274902, 'learning_rate': 5.7322033898305084e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [1:24:02<1:46:23,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [1:24:04<1:47:34,  1.91s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.6062419414520264, 'learning_rate': 5.730508474576272e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [1:24:04<1:47:34,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [1:24:06<1:48:31,  1.93s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.3995351791381836, 'learning_rate': 5.728813559322034e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [1:24:06<1:48:31,  1.93s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [1:24:08<1:48:14,  1.92s/it]                                                       {'loss': 0.0356, 'grad_norm': 3.1344187259674072, 'learning_rate': 5.727118644067797e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [1:24:08<1:48:14,  1.92s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [1:24:10<1:47:13,  1.90s/it]                                                       {'loss': 0.1166, 'grad_norm': 7.620205879211426, 'learning_rate': 5.72542372881356e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [1:24:10<1:47:13,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [1:24:11<1:46:11,  1.89s/it]                                                       {'loss': 0.0508, 'grad_norm': 6.250650882720947, 'learning_rate': 5.723728813559323e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [1:24:11<1:46:11,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [1:24:13<1:46:20,  1.89s/it]                                                       {'loss': 0.0216, 'grad_norm': 4.12721061706543, 'learning_rate': 5.722033898305085e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [1:24:13<1:46:20,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [1:24:15<1:46:06,  1.89s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.8272550106048584, 'learning_rate': 5.720338983050848e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [1:24:15<1:46:06,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [1:24:17<1:47:09,  1.91s/it]                                                       {'loss': 0.1394, 'grad_norm': 9.087100982666016, 'learning_rate': 5.71864406779661e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [1:24:17<1:47:09,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [1:24:19<1:47:02,  1.90s/it]                                                       {'loss': 0.1544, 'grad_norm': 6.8316497802734375, 'learning_rate': 5.716949152542374e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [1:24:19<1:47:02,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [1:24:21<1:46:17,  1.89s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05862855166196823, 'learning_rate': 5.715254237288136e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [1:24:21<1:46:17,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [1:24:23<1:46:43,  1.90s/it]                                                       {'loss': 0.0108, 'grad_norm': 1.5649601221084595, 'learning_rate': 5.713559322033899e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [1:24:23<1:46:43,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [1:24:25<1:46:18,  1.89s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.3900150954723358, 'learning_rate': 5.711864406779661e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [1:24:25<1:46:18,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [1:24:27<1:46:25,  1.90s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.3023674488067627, 'learning_rate': 5.710169491525425e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [1:24:27<1:46:25,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [1:24:29<1:46:21,  1.89s/it]                                                       {'loss': 0.1592, 'grad_norm': 7.755952835083008, 'learning_rate': 5.708474576271187e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [1:24:29<1:46:21,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [1:24:30<1:45:34,  1.88s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.3027265071868896, 'learning_rate': 5.70677966101695e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [1:24:30<1:45:34,  1.88s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [1:24:32<1:46:19,  1.90s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6108911037445068, 'learning_rate': 5.705084745762712e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [1:24:32<1:46:19,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [1:24:34<1:46:50,  1.91s/it]                                                       {'loss': 0.0603, 'grad_norm': 7.761716365814209, 'learning_rate': 5.703389830508475e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [1:24:34<1:46:50,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [1:24:36<1:52:32,  2.01s/it]                                                       {'loss': 0.0462, 'grad_norm': 3.599780321121216, 'learning_rate': 5.701694915254238e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [1:24:36<1:52:32,  2.01s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [1:24:38<1:50:53,  1.98s/it]                                                       {'loss': 0.1222, 'grad_norm': 4.682008743286133, 'learning_rate': 5.7e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [1:24:38<1:50:53,  1.98s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [1:24:40<1:49:37,  1.96s/it]                                                       {'loss': 0.079, 'grad_norm': 5.147441864013672, 'learning_rate': 5.698305084745763e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [1:24:40<1:49:37,  1.96s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [1:24:42<1:49:08,  1.95s/it]                                                       {'loss': 0.0249, 'grad_norm': 2.5574235916137695, 'learning_rate': 5.696610169491525e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [1:24:42<1:49:08,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [1:24:44<1:48:56,  1.95s/it]                                                       {'loss': 0.1289, 'grad_norm': 8.691394805908203, 'learning_rate': 5.694915254237289e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [1:24:44<1:48:56,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [1:24:46<1:50:23,  1.97s/it]                                                       {'loss': 0.0973, 'grad_norm': 8.04227066040039, 'learning_rate': 5.693220338983051e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [1:24:46<1:50:23,  1.97s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [1:24:48<1:48:55,  1.95s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.43699216842651367, 'learning_rate': 5.691525423728814e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [1:24:48<1:48:55,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [1:24:50<1:48:20,  1.94s/it]                                                       {'loss': 0.0478, 'grad_norm': 5.960174560546875, 'learning_rate': 5.689830508474577e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [1:24:50<1:48:20,  1.94s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [1:24:52<1:46:59,  1.91s/it]                                                       {'loss': 0.1399, 'grad_norm': 8.413007736206055, 'learning_rate': 5.68813559322034e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [1:24:52<1:46:59,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [1:24:54<1:46:36,  1.91s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.343888282775879, 'learning_rate': 5.686440677966102e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [1:24:54<1:46:36,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [1:24:56<1:45:31,  1.89s/it]                                                       {'loss': 0.0358, 'grad_norm': 4.319506645202637, 'learning_rate': 5.684745762711865e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [1:24:56<1:45:31,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [1:24:57<1:45:32,  1.89s/it]                                                       {'loss': 0.0842, 'grad_norm': 6.501047611236572, 'learning_rate': 5.683050847457627e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [1:24:57<1:45:32,  1.89s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [1:24:59<1:44:19,  1.87s/it]                                                       {'loss': 0.1863, 'grad_norm': 8.291337966918945, 'learning_rate': 5.6813559322033906e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [1:24:59<1:44:19,  1.87s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [1:25:01<1:44:33,  1.87s/it]                                                       {'loss': 0.0814, 'grad_norm': 5.358748435974121, 'learning_rate': 5.679661016949153e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [1:25:01<1:44:33,  1.87s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [1:25:03<1:44:48,  1.88s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.4836161136627197, 'learning_rate': 5.677966101694916e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [1:25:03<1:44:48,  1.88s/it][2025-11-11 23:18:18,990] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2650
[2025-11-11 23:18:18,997] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:18:19,284] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2650/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [1:25:06<1:57:53,  2.11s/it]                                                       {'loss': 0.0258, 'grad_norm': 2.9960672855377197, 'learning_rate': 5.676271186440679e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [1:25:06<1:57:53,  2.11s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [1:25:08<1:55:01,  2.06s/it]                                                       {'loss': 0.1067, 'grad_norm': 8.419716835021973, 'learning_rate': 5.674576271186442e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [1:25:08<1:55:01,  2.06s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [1:25:10<1:55:20,  2.07s/it]                                                       {'loss': 0.0597, 'grad_norm': 3.121786117553711, 'learning_rate': 5.6728813559322035e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [1:25:10<1:55:20,  2.07s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [1:25:12<1:51:59,  2.01s/it]                                                       {'loss': 0.0355, 'grad_norm': 2.635232448577881, 'learning_rate': 5.671186440677967e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [1:25:12<1:51:59,  2.01s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [1:25:13<1:49:41,  1.97s/it]                                                       {'loss': 0.1023, 'grad_norm': 10.81379508972168, 'learning_rate': 5.669491525423729e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [1:25:14<1:49:41,  1.97s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [1:25:15<1:47:37,  1.93s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1574743688106537, 'learning_rate': 5.667796610169492e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [1:25:15<1:47:37,  1.93s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [1:25:17<1:48:48,  1.95s/it]                                                       {'loss': 0.1047, 'grad_norm': 6.89003849029541, 'learning_rate': 5.666101694915255e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [1:25:17<1:48:48,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [1:25:19<1:47:04,  1.92s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.5202747583389282, 'learning_rate': 5.6644067796610165e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [1:25:19<1:47:04,  1.92s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [1:25:21<1:48:23,  1.95s/it]                                                       {'loss': 0.0601, 'grad_norm': 3.381132125854492, 'learning_rate': 5.662711864406781e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [1:25:21<1:48:23,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [1:25:23<1:49:23,  1.97s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7011489868164062, 'learning_rate': 5.661016949152542e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [1:25:23<1:49:23,  1.97s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [1:25:25<1:48:08,  1.94s/it]                                                       {'loss': 0.1284, 'grad_norm': 10.925956726074219, 'learning_rate': 5.6593220338983055e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [1:25:25<1:48:08,  1.94s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [1:25:27<1:46:55,  1.92s/it]                                                       {'loss': 0.0289, 'grad_norm': 3.312838077545166, 'learning_rate': 5.657627118644068e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [1:25:27<1:46:55,  1.92s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [1:25:29<1:45:56,  1.90s/it]                                                       {'loss': 0.0829, 'grad_norm': 4.967729568481445, 'learning_rate': 5.655932203389831e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [1:25:29<1:45:56,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [1:25:31<1:45:27,  1.90s/it]                                                       {'loss': 0.0359, 'grad_norm': 5.16994571685791, 'learning_rate': 5.654237288135594e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [1:25:31<1:45:27,  1.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [1:25:33<1:46:20,  1.91s/it]                                                       {'loss': 0.0469, 'grad_norm': 2.580312967300415, 'learning_rate': 5.652542372881357e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [1:25:33<1:46:20,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [1:25:35<1:46:04,  1.91s/it]                                                       {'loss': 0.0867, 'grad_norm': 6.269325256347656, 'learning_rate': 5.6508474576271185e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [1:25:35<1:46:04,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [1:25:36<1:46:19,  1.91s/it]                                                       {'loss': 0.001, 'grad_norm': 0.308118999004364, 'learning_rate': 5.649152542372882e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [1:25:36<1:46:19,  1.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [1:25:39<1:49:38,  1.97s/it]                                                       {'loss': 0.0449, 'grad_norm': 4.761082649230957, 'learning_rate': 5.647457627118644e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [1:25:39<1:49:38,  1.97s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [1:25:40<1:48:03,  1.95s/it]                                                       {'loss': 0.0152, 'grad_norm': 3.370309591293335, 'learning_rate': 5.6457627118644075e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [1:25:40<1:48:03,  1.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [1:25:42<1:47:12,  1.93s/it]                                                       {'loss': 0.1477, 'grad_norm': 7.151129245758057, 'learning_rate': 5.64406779661017e-06, 'epoch': 0.45}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [1:25:42<1:47:12,  1.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [1:25:44<1:46:10,  1.91s/it]                                                       {'loss': 0.0244, 'grad_norm': 5.27297306060791, 'learning_rate': 5.642372881355933e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [1:25:44<1:46:10,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [1:25:46<1:46:16,  1.92s/it]                                                       {'loss': 0.1326, 'grad_norm': 6.279393672943115, 'learning_rate': 5.640677966101696e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [1:25:46<1:46:16,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [1:25:48<1:45:31,  1.90s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.4771793782711029, 'learning_rate': 5.638983050847459e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [1:25:48<1:45:31,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [1:25:50<1:45:12,  1.90s/it]                                                       {'loss': 0.0212, 'grad_norm': 1.4912406206130981, 'learning_rate': 5.6372881355932204e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [1:25:50<1:45:12,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [1:25:52<1:46:07,  1.91s/it]                                                       {'loss': 0.0989, 'grad_norm': 5.590883731842041, 'learning_rate': 5.635593220338984e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [1:25:52<1:46:07,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [1:25:54<1:44:50,  1.89s/it]                                                       {'loss': 0.0815, 'grad_norm': 6.026375770568848, 'learning_rate': 5.633898305084746e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [1:25:54<1:44:50,  1.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [1:25:56<1:44:55,  1.89s/it]                                                       {'loss': 0.0597, 'grad_norm': 5.657584190368652, 'learning_rate': 5.6322033898305086e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [1:25:56<1:44:55,  1.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [1:25:58<1:45:51,  1.91s/it]                                                       {'loss': 0.055, 'grad_norm': 8.078890800476074, 'learning_rate': 5.630508474576272e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [1:25:58<1:45:51,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [1:25:59<1:45:15,  1.90s/it]                                                       {'loss': 0.0799, 'grad_norm': 8.909924507141113, 'learning_rate': 5.628813559322034e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [1:25:59<1:45:15,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [1:26:01<1:46:22,  1.92s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.609491229057312, 'learning_rate': 5.6271186440677975e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [1:26:01<1:46:22,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [1:26:03<1:45:20,  1.90s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.6115933060646057, 'learning_rate': 5.625423728813559e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [1:26:03<1:45:20,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [1:26:05<1:45:10,  1.90s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.13583515584468842, 'learning_rate': 5.623728813559322e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [1:26:05<1:45:10,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [1:26:07<1:44:52,  1.90s/it]                                                       {'loss': 0.0913, 'grad_norm': 9.810762405395508, 'learning_rate': 5.622033898305085e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [1:26:07<1:44:52,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [1:26:09<1:43:50,  1.88s/it]                                                       {'loss': 0.4845, 'grad_norm': 13.343958854675293, 'learning_rate': 5.620338983050848e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [1:26:09<1:43:50,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [1:26:11<1:43:15,  1.87s/it]                                                       {'loss': 0.0516, 'grad_norm': 4.640167713165283, 'learning_rate': 5.6186440677966105e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [1:26:11<1:43:15,  1.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [1:26:13<1:43:25,  1.87s/it]                                                       {'loss': 0.087, 'grad_norm': 3.6178390979766846, 'learning_rate': 5.616949152542374e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [1:26:13<1:43:25,  1.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [1:26:15<1:46:16,  1.92s/it]                                                       {'loss': 0.0462, 'grad_norm': 4.3306565284729, 'learning_rate': 5.615254237288136e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [1:26:15<1:46:16,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [1:26:17<1:46:00,  1.92s/it]                                                       {'loss': 0.0757, 'grad_norm': 6.24953556060791, 'learning_rate': 5.6135593220338995e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [1:26:17<1:46:00,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [1:26:18<1:44:39,  1.90s/it]                                                       {'loss': 0.0304, 'grad_norm': 5.2648539543151855, 'learning_rate': 5.611864406779661e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [1:26:18<1:44:39,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [1:26:20<1:43:37,  1.88s/it]                                                       {'loss': 0.1657, 'grad_norm': 8.948265075683594, 'learning_rate': 5.610169491525424e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [1:26:20<1:43:37,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [1:26:22<1:43:38,  1.88s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.2766210436820984, 'learning_rate': 5.608474576271187e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [1:26:22<1:43:38,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [1:26:24<1:43:48,  1.88s/it]                                                       {'loss': 0.0555, 'grad_norm': 6.879940032958984, 'learning_rate': 5.60677966101695e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [1:26:24<1:43:48,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [1:26:26<1:43:50,  1.88s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.2115404605865479, 'learning_rate': 5.6050847457627125e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [1:26:26<1:43:50,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [1:26:28<1:45:06,  1.91s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.017377639189362526, 'learning_rate': 5.603389830508476e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [1:26:28<1:45:06,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [1:26:30<1:46:04,  1.93s/it]                                                       {'loss': 0.0444, 'grad_norm': 6.958879470825195, 'learning_rate': 5.601694915254237e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [1:26:30<1:46:04,  1.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [1:26:32<1:47:27,  1.95s/it]                                                       {'loss': 0.2194, 'grad_norm': 9.862813949584961, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [1:26:32<1:47:27,  1.95s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [1:26:34<1:46:33,  1.94s/it]                                                       {'loss': 0.0411, 'grad_norm': 4.22774076461792, 'learning_rate': 5.598305084745763e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [1:26:34<1:46:33,  1.94s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [1:26:36<1:45:55,  1.92s/it]                                                       {'loss': 0.0703, 'grad_norm': 2.8788254261016846, 'learning_rate': 5.5966101694915254e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [1:26:36<1:45:55,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [1:26:38<1:45:33,  1.92s/it]                                                       {'loss': 0.012, 'grad_norm': 1.8654119968414307, 'learning_rate': 5.594915254237289e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [1:26:38<1:45:33,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [1:26:39<1:44:40,  1.90s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.44438689947128296, 'learning_rate': 5.593220338983051e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [1:26:39<1:44:40,  1.90s/it][2025-11-11 23:19:55,369] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700
[2025-11-11 23:19:55,376] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:19:55,694] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [1:26:42<1:59:14,  2.17s/it]                                                       {'loss': 0.0892, 'grad_norm': 7.9160237312316895, 'learning_rate': 5.591525423728814e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [1:26:42<1:59:14,  2.17s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [1:26:44<1:57:11,  2.13s/it]                                                       {'loss': 0.015, 'grad_norm': 2.7255125045776367, 'learning_rate': 5.589830508474576e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [1:26:44<1:57:11,  2.13s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [1:26:46<1:53:04,  2.06s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.6727523803710938, 'learning_rate': 5.588135593220339e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [1:26:46<1:53:04,  2.06s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [1:26:48<1:50:34,  2.01s/it]                                                       {'loss': 0.1155, 'grad_norm': 9.147875785827637, 'learning_rate': 5.586440677966102e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [1:26:48<1:50:34,  2.01s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [1:26:50<1:48:59,  1.98s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.1904231309890747, 'learning_rate': 5.584745762711865e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [1:26:50<1:48:59,  1.98s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [1:26:52<1:46:33,  1.94s/it]                                                       {'loss': 0.2838, 'grad_norm': 12.587485313415527, 'learning_rate': 5.583050847457627e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [1:26:52<1:46:33,  1.94s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [1:26:54<1:45:42,  1.93s/it]                                                       {'loss': 0.0533, 'grad_norm': 5.054994583129883, 'learning_rate': 5.581355932203391e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [1:26:54<1:45:42,  1.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [1:26:56<1:45:58,  1.93s/it]                                                       {'loss': 0.054, 'grad_norm': 6.202396869659424, 'learning_rate': 5.579661016949153e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [1:26:56<1:45:58,  1.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [1:26:58<1:46:35,  1.94s/it]                                                       {'loss': 0.0948, 'grad_norm': 8.526212692260742, 'learning_rate': 5.577966101694916e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [1:26:58<1:46:35,  1.94s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [1:27:00<1:45:57,  1.93s/it]                                                       {'loss': 0.0505, 'grad_norm': 4.0849785804748535, 'learning_rate': 5.576271186440678e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [1:27:00<1:45:57,  1.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [1:27:01<1:45:47,  1.93s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3049640357494354, 'learning_rate': 5.574576271186441e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [1:27:01<1:45:47,  1.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [1:27:03<1:45:21,  1.92s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.2607132196426392, 'learning_rate': 5.572881355932204e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [1:27:03<1:45:21,  1.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [1:27:05<1:44:14,  1.90s/it]                                                       {'loss': 0.0153, 'grad_norm': 1.3876283168792725, 'learning_rate': 5.571186440677967e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [1:27:05<1:44:14,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [1:27:07<1:43:53,  1.90s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.5974347591400146, 'learning_rate': 5.569491525423729e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [1:27:07<1:43:53,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [1:27:09<1:43:57,  1.90s/it]                                                       {'loss': 0.1044, 'grad_norm': 7.514491558074951, 'learning_rate': 5.567796610169493e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [1:27:09<1:43:57,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [1:27:11<1:44:41,  1.91s/it]                                                       {'loss': 0.2765, 'grad_norm': 12.259620666503906, 'learning_rate': 5.566101694915255e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [1:27:11<1:44:41,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [1:27:13<1:43:47,  1.90s/it]                                                       {'loss': 0.0289, 'grad_norm': 2.4698731899261475, 'learning_rate': 5.564406779661018e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [1:27:13<1:43:47,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [1:27:15<1:42:50,  1.88s/it]                                                       {'loss': 0.0919, 'grad_norm': 6.845045566558838, 'learning_rate': 5.56271186440678e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [1:27:15<1:42:50,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [1:27:17<1:43:01,  1.88s/it]                                                       {'loss': 0.1245, 'grad_norm': 6.181467056274414, 'learning_rate': 5.561016949152542e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [1:27:17<1:43:01,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [1:27:19<1:44:17,  1.91s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.2728464603424072, 'learning_rate': 5.559322033898306e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [1:27:19<1:44:17,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [1:27:20<1:44:11,  1.91s/it]                                                       {'loss': 0.0725, 'grad_norm': 6.652263641357422, 'learning_rate': 5.557627118644068e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [1:27:20<1:44:11,  1.91s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [1:27:22<1:44:01,  1.90s/it]                                                       {'loss': 0.087, 'grad_norm': 6.774404048919678, 'learning_rate': 5.555932203389831e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [1:27:22<1:44:01,  1.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [1:27:24<1:43:25,  1.89s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07711642235517502, 'learning_rate': 5.554237288135593e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [1:27:24<1:43:25,  1.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [1:27:26<1:42:39,  1.88s/it]                                                       {'loss': 0.0497, 'grad_norm': 4.00511360168457, 'learning_rate': 5.552542372881356e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [1:27:26<1:42:39,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [1:27:28<1:42:58,  1.89s/it]                                                       {'loss': 0.0537, 'grad_norm': 6.952962875366211, 'learning_rate': 5.550847457627119e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [1:27:28<1:42:58,  1.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [1:27:30<1:42:58,  1.89s/it]                                                       {'loss': 0.0371, 'grad_norm': 6.222910404205322, 'learning_rate': 5.549152542372882e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [1:27:30<1:42:58,  1.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [1:27:32<1:42:41,  1.88s/it]                                                       {'loss': 0.0891, 'grad_norm': 7.1764960289001465, 'learning_rate': 5.547457627118644e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [1:27:32<1:42:41,  1.88s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [1:27:34<1:41:58,  1.87s/it]                                                       {'loss': 0.0492, 'grad_norm': 3.7475056648254395, 'learning_rate': 5.5457627118644076e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [1:27:34<1:41:58,  1.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [1:27:35<1:42:38,  1.88s/it]                                                       {'loss': 0.0314, 'grad_norm': 4.513000965118408, 'learning_rate': 5.54406779661017e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [1:27:35<1:42:38,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [1:27:37<1:41:50,  1.87s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.44098958373069763, 'learning_rate': 5.542372881355933e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [1:27:37<1:41:50,  1.87s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [1:27:39<1:41:38,  1.87s/it]                                                       {'loss': 0.01, 'grad_norm': 1.7695666551589966, 'learning_rate': 5.540677966101695e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [1:27:39<1:41:38,  1.87s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [1:27:41<1:41:38,  1.87s/it]                                                       {'loss': 0.0274, 'grad_norm': 3.052135467529297, 'learning_rate': 5.538983050847458e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [1:27:41<1:41:38,  1.87s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [1:27:43<1:41:28,  1.86s/it]                                                       {'loss': 0.2217, 'grad_norm': 12.471324920654297, 'learning_rate': 5.5372881355932205e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [1:27:43<1:41:28,  1.86s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [1:27:45<1:42:56,  1.89s/it]                                                       {'loss': 0.0109, 'grad_norm': 2.552137851715088, 'learning_rate': 5.535593220338984e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [1:27:45<1:42:56,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [1:27:47<1:42:50,  1.89s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.028536796569824, 'learning_rate': 5.533898305084746e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [1:27:47<1:42:50,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [1:27:49<1:43:30,  1.90s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.5112237930297852, 'learning_rate': 5.5322033898305095e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [1:27:49<1:43:30,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [1:27:51<1:43:26,  1.90s/it]                                                       {'loss': 0.1589, 'grad_norm': 9.606343269348145, 'learning_rate': 5.530508474576272e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [1:27:51<1:43:26,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [1:27:52<1:43:01,  1.90s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2212662547826767, 'learning_rate': 5.528813559322035e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [1:27:52<1:43:01,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [1:27:54<1:43:55,  1.91s/it]                                                       {'loss': 0.0078, 'grad_norm': 2.2604010105133057, 'learning_rate': 5.527118644067797e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [1:27:54<1:43:55,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [1:27:56<1:43:20,  1.90s/it]                                                       {'loss': 0.0508, 'grad_norm': 6.481237411499023, 'learning_rate': 5.525423728813559e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [1:27:56<1:43:20,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [1:27:58<1:43:20,  1.90s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.3729195594787598, 'learning_rate': 5.5237288135593225e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [1:27:58<1:43:20,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [1:28:00<1:42:06,  1.88s/it]                                                       {'loss': 0.1298, 'grad_norm': 7.25595235824585, 'learning_rate': 5.522033898305085e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [1:28:00<1:42:06,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [1:28:02<1:41:29,  1.87s/it]                                                       {'loss': 0.057, 'grad_norm': 3.670111894607544, 'learning_rate': 5.520338983050848e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [1:28:02<1:41:29,  1.87s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [1:28:04<1:41:07,  1.86s/it]                                                       {'loss': 0.0756, 'grad_norm': 6.5576934814453125, 'learning_rate': 5.518644067796611e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [1:28:04<1:41:07,  1.86s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [1:28:06<1:42:27,  1.89s/it]                                                       {'loss': 0.1155, 'grad_norm': 9.363404273986816, 'learning_rate': 5.516949152542374e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [1:28:06<1:42:27,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [1:28:08<1:44:27,  1.93s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.9950287938117981, 'learning_rate': 5.5152542372881355e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [1:28:08<1:44:27,  1.93s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [1:28:10<1:45:25,  1.94s/it]                                                       {'loss': 0.116, 'grad_norm': 7.767194747924805, 'learning_rate': 5.513559322033899e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [1:28:10<1:45:25,  1.94s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [1:28:11<1:43:59,  1.92s/it]                                                       {'loss': 0.1395, 'grad_norm': 5.300068378448486, 'learning_rate': 5.511864406779661e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [1:28:11<1:43:59,  1.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [1:28:13<1:42:45,  1.90s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.1186084747314453, 'learning_rate': 5.5101694915254245e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [1:28:13<1:42:45,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [1:28:15<1:44:29,  1.93s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.17509716749191284, 'learning_rate': 5.508474576271187e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [1:28:15<1:44:29,  1.93s/it][2025-11-11 23:21:31,264] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2750
[2025-11-11 23:21:31,271] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:21:31,557] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2750/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [1:28:18<1:56:17,  2.15s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.8476698994636536, 'learning_rate': 5.50677966101695e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [1:28:18<1:56:17,  2.15s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [1:28:20<1:51:49,  2.07s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.33245980739593506, 'learning_rate': 5.505084745762712e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [1:28:20<1:51:49,  2.07s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [1:28:22<1:48:36,  2.01s/it]                                                       {'loss': 0.1548, 'grad_norm': 6.354735851287842, 'learning_rate': 5.503389830508475e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [1:28:22<1:48:36,  2.01s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [1:28:24<1:48:19,  2.00s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.22234821319580078, 'learning_rate': 5.5016949152542374e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [1:28:24<1:48:19,  2.00s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [1:28:26<1:47:09,  1.98s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1059568002820015, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [1:28:26<1:47:09,  1.98s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [1:28:28<1:47:04,  1.98s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.6910936832427979, 'learning_rate': 5.498305084745763e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [1:28:28<1:47:04,  1.98s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [1:28:30<1:45:35,  1.95s/it]                                                       {'loss': 0.1038, 'grad_norm': 7.413970947265625, 'learning_rate': 5.496610169491526e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [1:28:30<1:45:35,  1.95s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [1:28:31<1:43:28,  1.92s/it]                                                       {'loss': 0.028, 'grad_norm': 2.7240047454833984, 'learning_rate': 5.494915254237289e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [1:28:31<1:43:28,  1.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [1:28:33<1:44:30,  1.93s/it]                                                       {'loss': 0.1609, 'grad_norm': 8.328690528869629, 'learning_rate': 5.493220338983052e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [1:28:33<1:44:30,  1.93s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [1:28:35<1:43:30,  1.92s/it]                                                       {'loss': 0.05, 'grad_norm': 1.9204964637756348, 'learning_rate': 5.491525423728814e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [1:28:35<1:43:30,  1.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [1:28:37<1:43:12,  1.91s/it]                                                       {'loss': 0.1676, 'grad_norm': 9.333917617797852, 'learning_rate': 5.489830508474576e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [1:28:37<1:43:12,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [1:28:39<1:44:57,  1.94s/it]                                                       {'loss': 0.2328, 'grad_norm': 11.122428894042969, 'learning_rate': 5.488135593220339e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [1:28:39<1:44:57,  1.94s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [1:28:41<1:43:54,  1.93s/it]                                                       {'loss': 0.1706, 'grad_norm': 8.389391899108887, 'learning_rate': 5.486440677966102e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [1:28:41<1:43:54,  1.93s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [1:28:43<1:43:19,  1.92s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.5957653522491455, 'learning_rate': 5.484745762711865e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [1:28:43<1:43:19,  1.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [1:28:45<1:43:02,  1.91s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.1543673276901245, 'learning_rate': 5.4830508474576275e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [1:28:45<1:43:02,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [1:28:47<1:42:10,  1.90s/it]                                                       {'loss': 0.0128, 'grad_norm': 2.358672857284546, 'learning_rate': 5.481355932203391e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [1:28:47<1:42:10,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [1:28:49<1:43:12,  1.92s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2748768925666809, 'learning_rate': 5.479661016949152e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [1:28:49<1:43:12,  1.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [1:28:51<1:42:52,  1.91s/it]                                                       {'loss': 0.013, 'grad_norm': 2.0781915187835693, 'learning_rate': 5.477966101694916e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [1:28:51<1:42:52,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [1:28:52<1:43:03,  1.91s/it]                                                       {'loss': 0.2234, 'grad_norm': 8.61312484741211, 'learning_rate': 5.476271186440678e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [1:28:52<1:43:03,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [1:28:54<1:41:59,  1.89s/it]                                                       {'loss': 0.039, 'grad_norm': 4.573265552520752, 'learning_rate': 5.474576271186441e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [1:28:54<1:41:59,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [1:28:56<1:41:40,  1.89s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.5496532917022705, 'learning_rate': 5.472881355932204e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [1:28:56<1:41:40,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [1:28:58<1:41:56,  1.89s/it]                                                       {'loss': 0.003, 'grad_norm': 0.45529770851135254, 'learning_rate': 5.471186440677967e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [1:28:58<1:41:56,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [1:29:00<1:44:49,  1.95s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.505841851234436, 'learning_rate': 5.4694915254237295e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [1:29:00<1:44:49,  1.95s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [1:29:02<1:43:35,  1.93s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.6600712537765503, 'learning_rate': 5.467796610169493e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [1:29:02<1:43:35,  1.93s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [1:29:04<1:42:23,  1.91s/it]                                                       {'loss': 0.1019, 'grad_norm': 6.1896162033081055, 'learning_rate': 5.466101694915254e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [1:29:04<1:42:23,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [1:29:06<1:42:14,  1.90s/it]                                                       {'loss': 0.0493, 'grad_norm': 3.2837469577789307, 'learning_rate': 5.464406779661018e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [1:29:06<1:42:14,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [1:29:08<1:41:14,  1.88s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.0845221281051636, 'learning_rate': 5.46271186440678e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [1:29:08<1:41:14,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [1:29:10<1:41:17,  1.89s/it]                                                       {'loss': 0.2001, 'grad_norm': 10.751927375793457, 'learning_rate': 5.461016949152543e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [1:29:10<1:41:17,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [1:29:11<1:41:09,  1.88s/it]                                                       {'loss': 0.0295, 'grad_norm': 3.1561617851257324, 'learning_rate': 5.459322033898306e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [1:29:11<1:41:09,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [1:29:13<1:41:11,  1.89s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.6484400033950806, 'learning_rate': 5.457627118644067e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [1:29:13<1:41:11,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [1:29:15<1:42:21,  1.91s/it]                                                       {'loss': 0.1374, 'grad_norm': 9.839639663696289, 'learning_rate': 5.4559322033898306e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [1:29:15<1:42:21,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [1:29:17<1:41:21,  1.89s/it]                                                       {'loss': 0.015, 'grad_norm': 1.395947813987732, 'learning_rate': 5.454237288135593e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [1:29:17<1:41:21,  1.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [1:29:19<1:40:31,  1.88s/it]                                                       {'loss': 0.004, 'grad_norm': 0.37075963616371155, 'learning_rate': 5.452542372881356e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [1:29:19<1:40:31,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [1:29:21<1:41:00,  1.88s/it]                                                       {'loss': 0.0273, 'grad_norm': 2.2140510082244873, 'learning_rate': 5.450847457627119e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [1:29:21<1:41:00,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [1:29:23<1:42:21,  1.91s/it]                                                       {'loss': 0.025, 'grad_norm': 3.445542335510254, 'learning_rate': 5.449152542372882e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [1:29:23<1:42:21,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [1:29:25<1:42:35,  1.92s/it]                                                       {'loss': 0.0358, 'grad_norm': 4.033475875854492, 'learning_rate': 5.447457627118644e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [1:29:25<1:42:35,  1.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [1:29:27<1:42:23,  1.91s/it]                                                       {'loss': 0.1388, 'grad_norm': 9.6824312210083, 'learning_rate': 5.445762711864408e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [1:29:27<1:42:23,  1.91s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [1:29:29<1:41:52,  1.90s/it]                                                       {'loss': 0.1961, 'grad_norm': 6.865598201751709, 'learning_rate': 5.444067796610169e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [1:29:29<1:41:52,  1.90s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [1:29:30<1:40:31,  1.88s/it]                                                       {'loss': 0.1406, 'grad_norm': 9.410715103149414, 'learning_rate': 5.4423728813559325e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [1:29:30<1:40:31,  1.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [1:29:32<1:40:34,  1.88s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.16772624850273132, 'learning_rate': 5.440677966101695e-06, 'epoch': 0.47}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [1:29:32<1:40:34,  1.88s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [1:29:34<1:40:41,  1.88s/it]                                                       {'loss': 0.004, 'grad_norm': 0.5919016003608704, 'learning_rate': 5.438983050847458e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [1:29:34<1:40:41,  1.88s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [1:29:36<1:40:27,  1.88s/it]                                                       {'loss': 0.1106, 'grad_norm': 7.739843368530273, 'learning_rate': 5.437288135593221e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [1:29:36<1:40:27,  1.88s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [1:29:38<1:40:24,  1.88s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.27519816160202026, 'learning_rate': 5.435593220338984e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [1:29:38<1:40:24,  1.88s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [1:29:40<1:42:16,  1.91s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.1035341024398804, 'learning_rate': 5.433898305084746e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [1:29:40<1:42:16,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [1:29:42<1:41:33,  1.90s/it]                                                       {'loss': 0.124, 'grad_norm': 8.090702056884766, 'learning_rate': 5.43220338983051e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [1:29:42<1:41:33,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [1:29:44<1:40:42,  1.89s/it]                                                       {'loss': 0.2335, 'grad_norm': 12.18001651763916, 'learning_rate': 5.430508474576271e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [1:29:44<1:40:42,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [1:29:45<1:40:58,  1.89s/it]                                                       {'loss': 0.0264, 'grad_norm': 2.5034399032592773, 'learning_rate': 5.4288135593220345e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [1:29:46<1:40:58,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [1:29:47<1:40:45,  1.89s/it]                                                       {'loss': 0.1103, 'grad_norm': 5.077794551849365, 'learning_rate': 5.427118644067797e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [1:29:47<1:40:45,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [1:29:49<1:40:42,  1.89s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12928101420402527, 'learning_rate': 5.42542372881356e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [1:29:49<1:40:42,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [1:29:51<1:40:06,  1.88s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.42315053939819336, 'learning_rate': 5.423728813559323e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [1:29:51<1:40:06,  1.88s/it][2025-11-11 23:23:07,035] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800
[2025-11-11 23:23:07,042] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:23:07,326] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [1:29:54<1:53:24,  2.13s/it]                                                       {'loss': 0.1091, 'grad_norm': 5.455670356750488, 'learning_rate': 5.422033898305085e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [1:29:54<1:53:24,  2.13s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [1:29:56<1:49:06,  2.05s/it]                                                       {'loss': 0.0432, 'grad_norm': 3.2539494037628174, 'learning_rate': 5.420338983050848e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [1:29:56<1:49:06,  2.05s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [1:29:58<1:46:29,  2.00s/it]                                                       {'loss': 0.0201, 'grad_norm': 1.994471549987793, 'learning_rate': 5.41864406779661e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [1:29:58<1:46:29,  2.00s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [1:29:59<1:44:42,  1.97s/it]                                                       {'loss': 0.0941, 'grad_norm': 6.065803050994873, 'learning_rate': 5.416949152542373e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [1:29:59<1:44:42,  1.97s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [1:30:01<1:44:30,  1.96s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05277007445693016, 'learning_rate': 5.415254237288136e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [1:30:01<1:44:30,  1.96s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [1:30:03<1:42:47,  1.93s/it]                                                       {'loss': 0.0568, 'grad_norm': 5.415638446807861, 'learning_rate': 5.413559322033899e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [1:30:03<1:42:47,  1.93s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [1:30:05<1:42:20,  1.92s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05744345113635063, 'learning_rate': 5.411864406779661e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [1:30:05<1:42:20,  1.92s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [1:30:07<1:41:32,  1.91s/it]                                                       {'loss': 0.0697, 'grad_norm': 3.200676202774048, 'learning_rate': 5.4101694915254246e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [1:30:07<1:41:32,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [1:30:09<1:41:22,  1.91s/it]                                                       {'loss': 0.1428, 'grad_norm': 8.452795028686523, 'learning_rate': 5.408474576271186e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [1:30:09<1:41:22,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [1:30:11<1:44:04,  1.96s/it]                                                       {'loss': 0.0243, 'grad_norm': 3.766921281814575, 'learning_rate': 5.40677966101695e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [1:30:11<1:44:04,  1.96s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [1:30:13<1:43:24,  1.95s/it]                                                       {'loss': 0.1508, 'grad_norm': 11.114500045776367, 'learning_rate': 5.405084745762712e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [1:30:13<1:43:24,  1.95s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [1:30:15<1:41:34,  1.91s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.2972465753555298, 'learning_rate': 5.403389830508475e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [1:30:15<1:41:34,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [1:30:17<1:41:26,  1.91s/it]                                                       {'loss': 0.0294, 'grad_norm': 3.8233399391174316, 'learning_rate': 5.4016949152542375e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [1:30:17<1:41:26,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [1:30:19<1:40:45,  1.90s/it]                                                       {'loss': 0.1193, 'grad_norm': 7.918126106262207, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [1:30:19<1:40:45,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [1:30:20<1:40:32,  1.89s/it]                                                       {'loss': 0.0157, 'grad_norm': 3.093191623687744, 'learning_rate': 5.398305084745763e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [1:30:20<1:40:32,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [1:30:22<1:40:04,  1.89s/it]                                                       {'loss': 0.079, 'grad_norm': 3.8170018196105957, 'learning_rate': 5.3966101694915265e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [1:30:22<1:40:04,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [1:30:24<1:41:39,  1.92s/it]                                                       {'loss': 0.1071, 'grad_norm': 7.7655720710754395, 'learning_rate': 5.394915254237288e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [1:30:24<1:41:39,  1.92s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [1:30:26<1:41:51,  1.92s/it]                                                       {'loss': 0.282, 'grad_norm': 10.162277221679688, 'learning_rate': 5.393220338983051e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [1:30:26<1:41:51,  1.92s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [1:30:28<1:41:23,  1.91s/it]                                                       {'loss': 0.0276, 'grad_norm': 2.5996313095092773, 'learning_rate': 5.391525423728814e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [1:30:28<1:41:23,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [1:30:30<1:46:04,  2.00s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.4606833457946777, 'learning_rate': 5.389830508474577e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [1:30:30<1:46:04,  2.00s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [1:30:32<1:44:34,  1.97s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.9220567941665649, 'learning_rate': 5.3881355932203395e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [1:30:32<1:44:34,  1.97s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [1:30:34<1:42:18,  1.93s/it]                                                       {'loss': 0.0765, 'grad_norm': 3.9849016666412354, 'learning_rate': 5.386440677966102e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [1:30:34<1:42:18,  1.93s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [1:30:36<1:40:56,  1.91s/it]                                                       {'loss': 0.1099, 'grad_norm': 6.865970134735107, 'learning_rate': 5.384745762711865e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [1:30:36<1:40:56,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [1:30:38<1:40:32,  1.90s/it]                                                       {'loss': 0.0601, 'grad_norm': 7.872927188873291, 'learning_rate': 5.383050847457627e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [1:30:38<1:40:32,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [1:30:40<1:40:41,  1.90s/it]                                                       {'loss': 0.0438, 'grad_norm': 4.775554656982422, 'learning_rate': 5.38135593220339e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [1:30:40<1:40:41,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [1:30:42<1:40:07,  1.89s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.5832257866859436, 'learning_rate': 5.3796610169491525e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [1:30:42<1:40:07,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [1:30:43<1:40:26,  1.90s/it]                                                       {'loss': 0.0791, 'grad_norm': 5.186689853668213, 'learning_rate': 5.377966101694916e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [1:30:43<1:40:26,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [1:30:45<1:39:33,  1.88s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.6042650938034058, 'learning_rate': 5.376271186440678e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [1:30:45<1:39:33,  1.88s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [1:30:47<1:39:42,  1.89s/it]                                                       {'loss': 0.2468, 'grad_norm': 12.017406463623047, 'learning_rate': 5.3745762711864414e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [1:30:47<1:39:42,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [1:30:49<1:40:24,  1.90s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.2835930287837982, 'learning_rate': 5.372881355932204e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [1:30:49<1:40:24,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [1:30:51<1:43:00,  1.95s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16675437986850739, 'learning_rate': 5.371186440677967e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [1:30:51<1:43:00,  1.95s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [1:30:53<1:41:15,  1.92s/it]                                                       {'loss': 0.0222, 'grad_norm': 1.9932483434677124, 'learning_rate': 5.369491525423729e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [1:30:53<1:41:15,  1.92s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [1:30:55<1:40:43,  1.91s/it]                                                       {'loss': 0.0513, 'grad_norm': 5.2198333740234375, 'learning_rate': 5.367796610169492e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [1:30:55<1:40:43,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [1:30:57<1:39:57,  1.89s/it]                                                       {'loss': 0.0599, 'grad_norm': 3.9443798065185547, 'learning_rate': 5.3661016949152544e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [1:30:57<1:39:57,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [1:30:59<1:40:27,  1.90s/it]                                                       {'loss': 0.1234, 'grad_norm': 15.32840347290039, 'learning_rate': 5.364406779661018e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [1:30:59<1:40:27,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [1:31:01<1:40:03,  1.90s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.6825554966926575, 'learning_rate': 5.36271186440678e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [1:31:01<1:40:03,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [1:31:03<1:39:47,  1.89s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05973260477185249, 'learning_rate': 5.361016949152543e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [1:31:03<1:39:47,  1.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [1:31:05<1:42:07,  1.94s/it]                                                       {'loss': 0.0601, 'grad_norm': 6.430136680603027, 'learning_rate': 5.359322033898306e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [1:31:05<1:42:07,  1.94s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [1:31:06<1:40:28,  1.91s/it]                                                       {'loss': 0.041, 'grad_norm': 5.878055095672607, 'learning_rate': 5.357627118644069e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [1:31:06<1:40:28,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [1:31:08<1:40:12,  1.90s/it]                                                       {'loss': 0.0843, 'grad_norm': 6.315786361694336, 'learning_rate': 5.355932203389831e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [1:31:08<1:40:12,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [1:31:10<1:39:51,  1.90s/it]                                                       {'loss': 0.1337, 'grad_norm': 10.734861373901367, 'learning_rate': 5.354237288135594e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [1:31:10<1:39:51,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [1:31:12<1:40:46,  1.91s/it]                                                       {'loss': 0.0413, 'grad_norm': 2.713837146759033, 'learning_rate': 5.352542372881356e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [1:31:12<1:40:46,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [1:31:14<1:41:55,  1.94s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.464257836341858, 'learning_rate': 5.350847457627119e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [1:31:14<1:41:55,  1.94s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [1:31:16<1:40:28,  1.91s/it]                                                       {'loss': 0.1131, 'grad_norm': 6.14171838760376, 'learning_rate': 5.349152542372882e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [1:31:16<1:40:28,  1.91s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [1:31:18<1:39:57,  1.90s/it]                                                       {'loss': 0.0597, 'grad_norm': 4.503146171569824, 'learning_rate': 5.347457627118644e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [1:31:18<1:39:57,  1.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [1:31:20<1:42:22,  1.95s/it]                                                       {'loss': 0.1304, 'grad_norm': 7.442882537841797, 'learning_rate': 5.345762711864407e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [1:31:20<1:42:22,  1.95s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [1:31:22<1:41:29,  1.93s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11856411397457123, 'learning_rate': 5.344067796610169e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [1:31:22<1:41:29,  1.93s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [1:31:24<1:43:03,  1.96s/it]                                                       {'loss': 0.0149, 'grad_norm': 0.9724478125572205, 'learning_rate': 5.342372881355933e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [1:31:24<1:43:03,  1.96s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [1:31:26<1:42:34,  1.95s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.23755303025245667, 'learning_rate': 5.340677966101695e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [1:31:26<1:42:34,  1.95s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [1:31:28<1:40:53,  1.92s/it]                                                       {'loss': 0.0226, 'grad_norm': 4.052926540374756, 'learning_rate': 5.338983050847458e-06, 'epoch': 0.47}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [1:31:28<1:40:53,  1.92s/it][2025-11-11 23:24:43,529] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2850
[2025-11-11 23:24:43,536] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:24:43,806] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2850/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [1:31:30<1:52:36,  2.15s/it]                                                       {'loss': 0.0572, 'grad_norm': 8.220429420471191, 'learning_rate': 5.337288135593221e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [1:31:30<1:52:36,  2.15s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [1:31:32<1:48:24,  2.07s/it]                                                       {'loss': 0.1395, 'grad_norm': 5.630031585693359, 'learning_rate': 5.335593220338984e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [1:31:32<1:48:24,  2.07s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [1:31:34<1:45:00,  2.00s/it]                                                       {'loss': 0.0618, 'grad_norm': 6.413153171539307, 'learning_rate': 5.333898305084746e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [1:31:34<1:45:00,  2.00s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [1:31:36<1:44:25,  1.99s/it]                                                       {'loss': 0.0291, 'grad_norm': 3.113718271255493, 'learning_rate': 5.332203389830509e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [1:31:36<1:44:25,  1.99s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [1:31:38<1:42:16,  1.95s/it]                                                       {'loss': 0.1105, 'grad_norm': 8.218542098999023, 'learning_rate': 5.330508474576271e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [1:31:38<1:42:16,  1.95s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [1:31:40<1:41:15,  1.93s/it]                                                       {'loss': 0.0405, 'grad_norm': 3.325458288192749, 'learning_rate': 5.328813559322035e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [1:31:40<1:41:15,  1.93s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [1:31:42<1:39:35,  1.90s/it]                                                       {'loss': 0.3069, 'grad_norm': 11.190129280090332, 'learning_rate': 5.327118644067797e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [1:31:42<1:39:35,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [1:31:43<1:39:17,  1.90s/it]                                                       {'loss': 0.1496, 'grad_norm': 9.179977416992188, 'learning_rate': 5.32542372881356e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [1:31:43<1:39:17,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [1:31:45<1:38:54,  1.89s/it]                                                       {'loss': 0.1009, 'grad_norm': 7.50012731552124, 'learning_rate': 5.323728813559323e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [1:31:45<1:38:54,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [1:31:47<1:40:05,  1.91s/it]                                                       {'loss': 0.0644, 'grad_norm': 3.5129215717315674, 'learning_rate': 5.322033898305086e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [1:31:47<1:40:05,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [1:31:49<1:40:09,  1.91s/it]                                                       {'loss': 0.0279, 'grad_norm': 4.069975852966309, 'learning_rate': 5.3203389830508476e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [1:31:49<1:40:09,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [1:31:51<1:39:22,  1.90s/it]                                                       {'loss': 0.23, 'grad_norm': 9.02785587310791, 'learning_rate': 5.318644067796611e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [1:31:51<1:39:22,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [1:31:53<1:38:39,  1.89s/it]                                                       {'loss': 0.0223, 'grad_norm': 1.9100089073181152, 'learning_rate': 5.316949152542373e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [1:31:53<1:38:39,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [1:31:55<1:37:59,  1.87s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.2781572341918945, 'learning_rate': 5.315254237288136e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [1:31:55<1:37:59,  1.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [1:31:57<1:38:22,  1.88s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.1686125993728638, 'learning_rate': 5.313559322033899e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [1:31:57<1:38:22,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [1:31:59<1:38:29,  1.89s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.43185165524482727, 'learning_rate': 5.311864406779661e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [1:31:59<1:38:29,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [1:32:00<1:37:58,  1.88s/it]                                                       {'loss': 0.0254, 'grad_norm': 3.2860774993896484, 'learning_rate': 5.310169491525425e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [1:32:00<1:37:58,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [1:32:02<1:38:48,  1.89s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.926927387714386, 'learning_rate': 5.308474576271186e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [1:32:02<1:38:48,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [1:32:04<1:38:55,  1.90s/it]                                                       {'loss': 0.0875, 'grad_norm': 7.929043769836426, 'learning_rate': 5.3067796610169495e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [1:32:04<1:38:55,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [1:32:06<1:37:50,  1.88s/it]                                                       {'loss': 0.0177, 'grad_norm': 2.376692056655884, 'learning_rate': 5.305084745762712e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [1:32:06<1:37:50,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [1:32:08<1:37:42,  1.87s/it]                                                       {'loss': 0.1165, 'grad_norm': 8.066726684570312, 'learning_rate': 5.303389830508475e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [1:32:08<1:37:42,  1.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [1:32:10<1:37:54,  1.88s/it]                                                       {'loss': 0.0343, 'grad_norm': 4.355515480041504, 'learning_rate': 5.301694915254238e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [1:32:10<1:37:54,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [1:32:12<1:37:22,  1.87s/it]                                                       {'loss': 0.1326, 'grad_norm': 7.432626247406006, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [1:32:12<1:37:22,  1.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [1:32:14<1:37:26,  1.87s/it]                                                       {'loss': 0.0774, 'grad_norm': 8.314640045166016, 'learning_rate': 5.2983050847457625e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [1:32:14<1:37:26,  1.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [1:32:15<1:36:44,  1.86s/it]                                                       {'loss': 0.0196, 'grad_norm': 2.8196959495544434, 'learning_rate': 5.296610169491526e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [1:32:15<1:36:44,  1.86s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [1:32:17<1:37:40,  1.88s/it]                                                       {'loss': 0.0691, 'grad_norm': 9.500163078308105, 'learning_rate': 5.294915254237288e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [1:32:17<1:37:40,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [1:32:19<1:37:58,  1.88s/it]                                                       {'loss': 0.1006, 'grad_norm': 9.014678001403809, 'learning_rate': 5.2932203389830515e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [1:32:19<1:37:58,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [1:32:21<1:37:50,  1.88s/it]                                                       {'loss': 0.0733, 'grad_norm': 4.374722480773926, 'learning_rate': 5.291525423728814e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [1:32:21<1:37:50,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [1:32:23<1:37:12,  1.87s/it]                                                       {'loss': 0.1017, 'grad_norm': 5.657933235168457, 'learning_rate': 5.289830508474577e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [1:32:23<1:37:12,  1.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [1:32:25<1:39:17,  1.91s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.6584184765815735, 'learning_rate': 5.28813559322034e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [1:32:25<1:39:17,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [1:32:27<1:38:13,  1.89s/it]                                                       {'loss': 0.1147, 'grad_norm': 8.071205139160156, 'learning_rate': 5.286440677966103e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [1:32:27<1:38:13,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [1:32:29<1:38:48,  1.90s/it]                                                       {'loss': 0.0206, 'grad_norm': 3.4502086639404297, 'learning_rate': 5.2847457627118645e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [1:32:29<1:38:48,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [1:32:31<1:38:28,  1.90s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5799224972724915, 'learning_rate': 5.283050847457628e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [1:32:31<1:38:28,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [1:32:32<1:38:03,  1.89s/it]                                                       {'loss': 0.0281, 'grad_norm': 3.6283020973205566, 'learning_rate': 5.28135593220339e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [1:32:32<1:38:03,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [1:32:35<1:43:35,  2.00s/it]                                                       {'loss': 0.049, 'grad_norm': 3.308051347732544, 'learning_rate': 5.279661016949153e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [1:32:35<1:43:35,  2.00s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [1:32:37<1:41:43,  1.96s/it]                                                       {'loss': 0.0325, 'grad_norm': 3.192415475845337, 'learning_rate': 5.277966101694916e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [1:32:37<1:41:43,  1.96s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [1:32:38<1:40:56,  1.95s/it]                                                       {'loss': 0.0664, 'grad_norm': 5.546507358551025, 'learning_rate': 5.276271186440678e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [1:32:38<1:40:56,  1.95s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [1:32:40<1:40:13,  1.93s/it]                                                       {'loss': 0.0729, 'grad_norm': 6.745453834533691, 'learning_rate': 5.2745762711864416e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [1:32:40<1:40:13,  1.93s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [1:32:42<1:38:55,  1.91s/it]                                                       {'loss': 0.0048, 'grad_norm': 1.001657247543335, 'learning_rate': 5.272881355932203e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [1:32:42<1:38:55,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [1:32:44<1:38:25,  1.90s/it]                                                       {'loss': 0.0358, 'grad_norm': 4.525075912475586, 'learning_rate': 5.271186440677966e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [1:32:44<1:38:25,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [1:32:46<1:38:42,  1.90s/it]                                                       {'loss': 0.1674, 'grad_norm': 8.133964538574219, 'learning_rate': 5.269491525423729e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [1:32:46<1:38:42,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [1:32:48<1:38:13,  1.90s/it]                                                       {'loss': 0.4623, 'grad_norm': 9.665215492248535, 'learning_rate': 5.267796610169492e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [1:32:48<1:38:13,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [1:32:50<1:38:42,  1.91s/it]                                                       {'loss': 0.1649, 'grad_norm': 12.28199291229248, 'learning_rate': 5.2661016949152545e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [1:32:50<1:38:42,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [1:32:52<1:37:44,  1.89s/it]                                                       {'loss': 0.0736, 'grad_norm': 7.261797904968262, 'learning_rate': 5.264406779661018e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [1:32:52<1:37:44,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [1:32:54<1:37:34,  1.89s/it]                                                       {'loss': 0.0157, 'grad_norm': 1.9341408014297485, 'learning_rate': 5.26271186440678e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [1:32:54<1:37:34,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [1:32:56<1:38:40,  1.91s/it]                                                       {'loss': 0.0974, 'grad_norm': 4.950283050537109, 'learning_rate': 5.2610169491525435e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [1:32:56<1:38:40,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [1:32:57<1:38:07,  1.90s/it]                                                       {'loss': 0.0287, 'grad_norm': 2.853023052215576, 'learning_rate': 5.259322033898305e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [1:32:57<1:38:07,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [1:32:59<1:37:25,  1.88s/it]                                                       {'loss': 0.1364, 'grad_norm': 6.861473560333252, 'learning_rate': 5.257627118644068e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [1:32:59<1:37:25,  1.88s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [1:33:01<1:36:24,  1.87s/it]                                                       {'loss': 0.009, 'grad_norm': 0.8495952486991882, 'learning_rate': 5.255932203389831e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [1:33:01<1:36:24,  1.87s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [1:33:03<1:35:50,  1.85s/it]                                                       {'loss': 0.0954, 'grad_norm': 8.995671272277832, 'learning_rate': 5.254237288135594e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [1:33:03<1:35:50,  1.85s/it][2025-11-11 23:26:18,816] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2900
[2025-11-11 23:26:18,822] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:26:19,093] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [1:33:06<1:49:10,  2.11s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.8848769664764404, 'learning_rate': 5.2525423728813565e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [1:33:06<1:49:10,  2.11s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [1:33:08<1:45:55,  2.05s/it]                                                       {'loss': 0.2851, 'grad_norm': 8.726985931396484, 'learning_rate': 5.25084745762712e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [1:33:08<1:45:55,  2.05s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [1:33:09<1:42:28,  1.99s/it]                                                       {'loss': 0.0489, 'grad_norm': 5.1159257888793945, 'learning_rate': 5.249152542372881e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [1:33:09<1:42:28,  1.99s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [1:33:11<1:40:11,  1.94s/it]                                                       {'loss': 0.04, 'grad_norm': 6.4608154296875, 'learning_rate': 5.247457627118645e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [1:33:11<1:40:11,  1.94s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [1:33:13<1:38:26,  1.91s/it]                                                       {'loss': 0.0265, 'grad_norm': 1.997213363647461, 'learning_rate': 5.245762711864407e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [1:33:13<1:38:26,  1.91s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [1:33:15<1:37:30,  1.89s/it]                                                       {'loss': 0.0878, 'grad_norm': 6.5014142990112305, 'learning_rate': 5.2440677966101695e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [1:33:15<1:37:30,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [1:33:17<1:39:17,  1.93s/it]                                                       {'loss': 0.1316, 'grad_norm': 9.984504699707031, 'learning_rate': 5.242372881355933e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [1:33:17<1:39:17,  1.93s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [1:33:19<1:37:50,  1.90s/it]                                                       {'loss': 0.0355, 'grad_norm': 2.931398630142212, 'learning_rate': 5.240677966101695e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [1:33:19<1:37:50,  1.90s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [1:33:21<1:37:11,  1.89s/it]                                                       {'loss': 0.121, 'grad_norm': 8.593193054199219, 'learning_rate': 5.2389830508474584e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [1:33:21<1:37:11,  1.89s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [1:33:22<1:37:11,  1.89s/it]                                                       {'loss': 0.1338, 'grad_norm': 6.7667460441589355, 'learning_rate': 5.23728813559322e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [1:33:22<1:37:11,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [1:33:24<1:37:22,  1.89s/it]                                                       {'loss': 0.004, 'grad_norm': 0.396173894405365, 'learning_rate': 5.235593220338983e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [1:33:24<1:37:22,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [1:33:26<1:36:32,  1.88s/it]                                                       {'loss': 0.11, 'grad_norm': 8.44606876373291, 'learning_rate': 5.233898305084746e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [1:33:26<1:36:32,  1.88s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [1:33:28<1:39:05,  1.93s/it]                                                       {'loss': 0.0943, 'grad_norm': 3.2594258785247803, 'learning_rate': 5.232203389830509e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [1:33:28<1:39:05,  1.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [1:33:30<1:38:20,  1.91s/it]                                                       {'loss': 0.08, 'grad_norm': 3.8924977779388428, 'learning_rate': 5.2305084745762714e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [1:33:30<1:38:20,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [1:33:32<1:38:33,  1.92s/it]                                                       {'loss': 0.4393, 'grad_norm': 12.504900932312012, 'learning_rate': 5.228813559322035e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [1:33:32<1:38:33,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [1:33:34<1:42:45,  2.00s/it]                                                       {'loss': 0.0656, 'grad_norm': 8.656116485595703, 'learning_rate': 5.227118644067797e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [1:33:34<1:42:45,  2.00s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [1:33:36<1:40:33,  1.96s/it]                                                       {'loss': 0.169, 'grad_norm': 6.482748985290527, 'learning_rate': 5.22542372881356e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [1:33:36<1:40:33,  1.96s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [1:33:38<1:39:41,  1.94s/it]                                                       {'loss': 0.0117, 'grad_norm': 2.0982868671417236, 'learning_rate': 5.223728813559322e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [1:33:38<1:39:41,  1.94s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [1:33:40<1:38:55,  1.93s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.1030899286270142, 'learning_rate': 5.222033898305085e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [1:33:40<1:38:55,  1.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [1:33:42<1:38:19,  1.92s/it]                                                       {'loss': 0.1085, 'grad_norm': 8.05381965637207, 'learning_rate': 5.220338983050848e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [1:33:42<1:38:19,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [1:33:44<1:37:12,  1.89s/it]                                                       {'loss': 0.0568, 'grad_norm': 3.7297210693359375, 'learning_rate': 5.218644067796611e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [1:33:44<1:37:12,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [1:33:45<1:36:32,  1.88s/it]                                                       {'loss': 0.0901, 'grad_norm': 8.868766784667969, 'learning_rate': 5.216949152542373e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [1:33:45<1:36:32,  1.88s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [1:33:48<1:49:24,  2.13s/it]                                                       {'loss': 0.0808, 'grad_norm': 5.789541721343994, 'learning_rate': 5.215254237288137e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [1:33:48<1:49:24,  2.13s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [1:33:50<1:47:52,  2.10s/it]                                                       {'loss': 0.1108, 'grad_norm': 7.116850852966309, 'learning_rate': 5.213559322033899e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [1:33:50<1:47:52,  2.10s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [1:33:52<1:44:29,  2.04s/it]                                                       {'loss': 0.004, 'grad_norm': 0.744327962398529, 'learning_rate': 5.211864406779662e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [1:33:52<1:44:29,  2.04s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [1:33:54<1:42:01,  1.99s/it]                                                       {'loss': 0.0372, 'grad_norm': 4.685173034667969, 'learning_rate': 5.210169491525424e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [1:33:54<1:42:01,  1.99s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [1:33:56<1:40:49,  1.97s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.9355928897857666, 'learning_rate': 5.208474576271186e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [1:33:56<1:40:49,  1.97s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [1:33:58<1:40:24,  1.96s/it]                                                       {'loss': 0.0886, 'grad_norm': 6.956392288208008, 'learning_rate': 5.20677966101695e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [1:33:58<1:40:24,  1.96s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [1:34:00<1:41:01,  1.97s/it]                                                       {'loss': 0.1316, 'grad_norm': 10.69626235961914, 'learning_rate': 5.205084745762712e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [1:34:00<1:41:01,  1.97s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [1:34:02<1:40:24,  1.96s/it]                                                       {'loss': 0.1023, 'grad_norm': 9.594152450561523, 'learning_rate': 5.203389830508475e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [1:34:02<1:40:24,  1.96s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [1:34:04<1:39:02,  1.94s/it]                                                       {'loss': 0.1008, 'grad_norm': 9.039981842041016, 'learning_rate': 5.201694915254237e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [1:34:04<1:39:02,  1.94s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [1:34:06<1:38:41,  1.93s/it]                                                       {'loss': 0.0843, 'grad_norm': 6.941896438598633, 'learning_rate': 5.2e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [1:34:06<1:38:41,  1.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [1:34:08<1:38:58,  1.94s/it]                                                       {'loss': 0.2328, 'grad_norm': 9.108311653137207, 'learning_rate': 5.198305084745763e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [1:34:08<1:38:58,  1.94s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [1:34:09<1:37:59,  1.92s/it]                                                       {'loss': 0.063, 'grad_norm': 6.576999187469482, 'learning_rate': 5.196610169491526e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [1:34:09<1:37:59,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [1:34:11<1:37:48,  1.91s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.4966044425964355, 'learning_rate': 5.194915254237288e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [1:34:11<1:37:48,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [1:34:13<1:37:54,  1.92s/it]                                                       {'loss': 0.0358, 'grad_norm': 2.3321852684020996, 'learning_rate': 5.193220338983052e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [1:34:13<1:37:54,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [1:34:15<1:38:43,  1.93s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.2871124744415283, 'learning_rate': 5.191525423728814e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [1:34:15<1:38:43,  1.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [1:34:17<1:38:10,  1.92s/it]                                                       {'loss': 0.0131, 'grad_norm': 2.398160696029663, 'learning_rate': 5.189830508474577e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [1:34:17<1:38:10,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [1:34:19<1:37:56,  1.92s/it]                                                       {'loss': 0.0519, 'grad_norm': 3.9958338737487793, 'learning_rate': 5.188135593220339e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [1:34:19<1:37:56,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [1:34:21<1:37:08,  1.90s/it]                                                       {'loss': 0.0906, 'grad_norm': 6.402129173278809, 'learning_rate': 5.186440677966102e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [1:34:21<1:37:08,  1.90s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [1:34:23<1:36:45,  1.90s/it]                                                       {'loss': 0.1042, 'grad_norm': 6.688680171966553, 'learning_rate': 5.1847457627118646e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [1:34:23<1:36:45,  1.90s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [1:34:25<1:37:43,  1.92s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.32866284251213074, 'learning_rate': 5.183050847457628e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [1:34:25<1:37:43,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [1:34:27<1:37:24,  1.91s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.7164794206619263, 'learning_rate': 5.18135593220339e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [1:34:27<1:37:24,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [1:34:29<1:37:15,  1.91s/it]                                                       {'loss': 0.0568, 'grad_norm': 6.484532833099365, 'learning_rate': 5.1796610169491535e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [1:34:29<1:37:15,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [1:34:30<1:36:23,  1.89s/it]                                                       {'loss': 0.3614, 'grad_norm': 11.552443504333496, 'learning_rate': 5.177966101694916e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [1:34:30<1:36:23,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [1:34:32<1:35:24,  1.87s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11224185675382614, 'learning_rate': 5.176271186440679e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [1:34:32<1:35:24,  1.87s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [1:34:34<1:35:58,  1.89s/it]                                                       {'loss': 0.0697, 'grad_norm': 3.6806304454803467, 'learning_rate': 5.174576271186441e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [1:34:34<1:35:58,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [1:34:36<1:36:19,  1.89s/it]                                                       {'loss': 0.0249, 'grad_norm': 2.972306251525879, 'learning_rate': 5.172881355932203e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [1:34:36<1:36:19,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [1:34:38<1:35:32,  1.88s/it]                                                       {'loss': 0.0548, 'grad_norm': 4.296395778656006, 'learning_rate': 5.1711864406779665e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [1:34:38<1:35:32,  1.88s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [1:34:40<1:35:39,  1.88s/it]                                                       {'loss': 0.0257, 'grad_norm': 2.6621036529541016, 'learning_rate': 5.169491525423729e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [1:34:40<1:35:39,  1.88s/it][2025-11-11 23:27:55,720] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2950
[2025-11-11 23:27:55,727] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:27:56,015] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2950/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [1:34:42<1:47:21,  2.11s/it]                                                       {'loss': 0.0295, 'grad_norm': 2.766047239303589, 'learning_rate': 5.167796610169492e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [1:34:42<1:47:21,  2.11s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [1:34:44<1:43:55,  2.05s/it]                                                       {'loss': 0.0418, 'grad_norm': 4.240243434906006, 'learning_rate': 5.166101694915255e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [1:34:44<1:43:55,  2.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [1:34:46<1:41:04,  1.99s/it]                                                       {'loss': 0.0764, 'grad_norm': 6.603028297424316, 'learning_rate': 5.164406779661018e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [1:34:46<1:41:04,  1.99s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [1:34:48<1:39:18,  1.96s/it]                                                       {'loss': 0.049, 'grad_norm': 4.809639930725098, 'learning_rate': 5.1627118644067795e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [1:34:48<1:39:18,  1.96s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [1:34:50<1:37:36,  1.92s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.18305276334285736, 'learning_rate': 5.161016949152543e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [1:34:50<1:37:36,  1.92s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [1:34:52<1:36:06,  1.89s/it]                                                       {'loss': 0.0282, 'grad_norm': 1.9734277725219727, 'learning_rate': 5.159322033898305e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [1:34:52<1:36:06,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [1:34:54<1:35:37,  1.89s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.5658760070800781, 'learning_rate': 5.1576271186440685e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [1:34:54<1:35:37,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [1:34:56<1:35:45,  1.89s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.25717753171920776, 'learning_rate': 5.155932203389831e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [1:34:56<1:35:45,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [1:34:57<1:36:25,  1.90s/it]                                                       {'loss': 0.0453, 'grad_norm': 6.0752458572387695, 'learning_rate': 5.154237288135594e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [1:34:57<1:36:25,  1.90s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [1:34:59<1:36:45,  1.91s/it]                                                       {'loss': 0.1152, 'grad_norm': 9.31849193572998, 'learning_rate': 5.152542372881356e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [1:34:59<1:36:45,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [1:35:01<1:36:47,  1.91s/it]                                                       {'loss': 0.2956, 'grad_norm': 11.752151489257812, 'learning_rate': 5.15084745762712e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [1:35:01<1:36:47,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [1:35:03<1:36:46,  1.91s/it]                                                       {'loss': 0.0538, 'grad_norm': 4.72885274887085, 'learning_rate': 5.1491525423728815e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [1:35:03<1:36:46,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [1:35:05<1:37:34,  1.93s/it]                                                       {'loss': 0.0178, 'grad_norm': 2.532996892929077, 'learning_rate': 5.147457627118645e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [1:35:05<1:37:34,  1.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [1:35:07<1:36:43,  1.91s/it]                                                       {'loss': 0.1311, 'grad_norm': 6.128368377685547, 'learning_rate': 5.145762711864407e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [1:35:07<1:36:43,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [1:35:09<1:36:02,  1.90s/it]                                                       {'loss': 0.0331, 'grad_norm': 1.7221368551254272, 'learning_rate': 5.1440677966101704e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [1:35:09<1:36:02,  1.90s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [1:35:11<1:36:43,  1.91s/it]                                                       {'loss': 0.131, 'grad_norm': 8.20226764678955, 'learning_rate': 5.142372881355933e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [1:35:11<1:36:43,  1.91s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [1:35:13<1:35:58,  1.90s/it]                                                       {'loss': 0.01, 'grad_norm': 2.1183576583862305, 'learning_rate': 5.1406779661016944e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [1:35:13<1:35:58,  1.90s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [1:35:15<1:35:25,  1.89s/it]                                                       {'loss': 0.0254, 'grad_norm': 2.6029393672943115, 'learning_rate': 5.138983050847458e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [1:35:15<1:35:25,  1.89s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [1:35:16<1:35:39,  1.89s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.26425403356552124, 'learning_rate': 5.13728813559322e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [1:35:16<1:35:39,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [1:35:18<1:34:46,  1.88s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3992386758327484, 'learning_rate': 5.135593220338983e-06, 'epoch': 0.49}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [1:35:18<1:34:46,  1.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [1:35:20<1:34:59,  1.88s/it]                                                       {'loss': 0.1922, 'grad_norm': 11.813790321350098, 'learning_rate': 5.133898305084746e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [1:35:20<1:34:59,  1.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [1:35:22<1:34:48,  1.88s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.576291024684906, 'learning_rate': 5.132203389830509e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [1:35:22<1:34:48,  1.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [1:35:24<1:35:35,  1.89s/it]                                                       {'loss': 0.0171, 'grad_norm': 3.0180740356445312, 'learning_rate': 5.1305084745762715e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [1:35:24<1:35:35,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [1:35:26<1:35:21,  1.89s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.481555223464966, 'learning_rate': 5.128813559322035e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [1:35:26<1:35:21,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [1:35:28<1:36:02,  1.91s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.2456054389476776, 'learning_rate': 5.127118644067796e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [1:35:28<1:36:02,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [1:35:30<1:36:54,  1.92s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.4876484870910645, 'learning_rate': 5.12542372881356e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [1:35:30<1:36:54,  1.92s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [1:35:32<1:37:32,  1.94s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.30127906799316406, 'learning_rate': 5.123728813559322e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [1:35:32<1:37:32,  1.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [1:35:34<1:36:58,  1.93s/it]                                                       {'loss': 0.1123, 'grad_norm': 6.251964569091797, 'learning_rate': 5.122033898305085e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [1:35:34<1:36:58,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [1:35:36<1:36:32,  1.92s/it]                                                       {'loss': 0.1194, 'grad_norm': 8.141793251037598, 'learning_rate': 5.120338983050848e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [1:35:36<1:36:32,  1.92s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [1:35:38<1:37:48,  1.94s/it]                                                       {'loss': 0.0792, 'grad_norm': 4.619657039642334, 'learning_rate': 5.118644067796611e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [1:35:38<1:37:48,  1.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [1:35:39<1:36:55,  1.93s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.7670103907585144, 'learning_rate': 5.1169491525423735e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [1:35:39<1:36:55,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [1:35:41<1:36:56,  1.93s/it]                                                       {'loss': 0.041, 'grad_norm': 4.220000743865967, 'learning_rate': 5.115254237288137e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [1:35:41<1:36:56,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [1:35:43<1:36:10,  1.91s/it]                                                       {'loss': 0.0392, 'grad_norm': 4.481232643127441, 'learning_rate': 5.113559322033898e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [1:35:43<1:36:10,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [1:35:45<1:34:56,  1.89s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.890857219696045, 'learning_rate': 5.111864406779662e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [1:35:45<1:34:56,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [1:35:47<1:36:52,  1.93s/it]                                                       {'loss': 0.0544, 'grad_norm': 6.458165645599365, 'learning_rate': 5.110169491525424e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [1:35:47<1:36:52,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [1:35:49<1:37:03,  1.93s/it]                                                       {'loss': 0.0196, 'grad_norm': 2.686457633972168, 'learning_rate': 5.108474576271187e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [1:35:49<1:37:03,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [1:35:51<1:35:51,  1.91s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5878514647483826, 'learning_rate': 5.10677966101695e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [1:35:51<1:35:51,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [1:35:53<1:36:35,  1.92s/it]                                                       {'loss': 0.1399, 'grad_norm': 7.703895568847656, 'learning_rate': 5.105084745762711e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [1:35:53<1:36:35,  1.92s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [1:35:55<1:35:36,  1.91s/it]                                                       {'loss': 0.018, 'grad_norm': 1.758880615234375, 'learning_rate': 5.1033898305084754e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [1:35:55<1:35:36,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [1:35:57<1:39:31,  1.98s/it]                                                       {'loss': 0.097, 'grad_norm': 6.979137420654297, 'learning_rate': 5.101694915254237e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [1:35:57<1:39:31,  1.98s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [1:35:59<1:37:37,  1.95s/it]                                                       {'loss': 0.0665, 'grad_norm': 2.90981125831604, 'learning_rate': 5.1e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [1:35:59<1:37:37,  1.95s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [1:36:01<1:36:44,  1.93s/it]                                                       {'loss': 0.2103, 'grad_norm': 11.135431289672852, 'learning_rate': 5.098305084745763e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [1:36:01<1:36:44,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [1:36:03<1:37:17,  1.94s/it]                                                       {'loss': 0.1354, 'grad_norm': 11.20843505859375, 'learning_rate': 5.096610169491526e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [1:36:03<1:37:17,  1.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [1:36:04<1:35:45,  1.91s/it]                                                       {'loss': 0.2451, 'grad_norm': 17.331247329711914, 'learning_rate': 5.0949152542372884e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [1:36:04<1:35:45,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [1:36:06<1:35:04,  1.90s/it]                                                       {'loss': 0.4295, 'grad_norm': 14.021756172180176, 'learning_rate': 5.093220338983052e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [1:36:06<1:35:04,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [1:36:08<1:35:58,  1.92s/it]                                                       {'loss': 0.0112, 'grad_norm': 0.8599164485931396, 'learning_rate': 5.091525423728813e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [1:36:08<1:35:58,  1.92s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [1:36:10<1:35:36,  1.91s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.7484797239303589, 'learning_rate': 5.0898305084745766e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [1:36:10<1:35:36,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [1:36:12<1:35:34,  1.91s/it]                                                       {'loss': 0.3344, 'grad_norm': 12.465764045715332, 'learning_rate': 5.088135593220339e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [1:36:12<1:35:34,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [1:36:14<1:37:06,  1.94s/it]                                                       {'loss': 0.0576, 'grad_norm': 5.19563102722168, 'learning_rate': 5.086440677966102e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [1:36:14<1:37:06,  1.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [1:36:16<1:36:12,  1.92s/it]                                                       {'loss': 0.0302, 'grad_norm': 3.3655924797058105, 'learning_rate': 5.084745762711865e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [1:36:16<1:36:12,  1.92s/it][2025-11-11 23:29:31,922] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3000
[2025-11-11 23:29:31,929] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:29:32,211] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [1:36:19<1:48:08,  2.16s/it]                                                       {'loss': 0.2206, 'grad_norm': 8.882335662841797, 'learning_rate': 5.083050847457628e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [1:36:19<1:48:08,  2.16s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [1:36:21<1:43:19,  2.07s/it]                                                       {'loss': 0.1075, 'grad_norm': 6.030533313751221, 'learning_rate': 5.08135593220339e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [1:36:21<1:43:19,  2.07s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [1:36:23<1:42:47,  2.06s/it]                                                       {'loss': 0.0328, 'grad_norm': 3.543861150741577, 'learning_rate': 5.079661016949154e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [1:36:23<1:42:47,  2.06s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [1:36:24<1:39:38,  2.00s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.3873132467269897, 'learning_rate': 5.077966101694915e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [1:36:24<1:39:38,  2.00s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [1:36:26<1:38:30,  1.97s/it]                                                       {'loss': 0.0504, 'grad_norm': 5.015148639678955, 'learning_rate': 5.0762711864406785e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [1:36:26<1:38:30,  1.97s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [1:36:28<1:37:55,  1.96s/it]                                                       {'loss': 0.0422, 'grad_norm': 3.8007750511169434, 'learning_rate': 5.074576271186441e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [1:36:28<1:37:55,  1.96s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [1:36:30<1:37:52,  1.96s/it]                                                       {'loss': 0.062, 'grad_norm': 3.94343638420105, 'learning_rate': 5.072881355932204e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [1:36:30<1:37:52,  1.96s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [1:36:32<1:36:17,  1.93s/it]                                                       {'loss': 0.0549, 'grad_norm': 8.873970985412598, 'learning_rate': 5.071186440677967e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [1:36:32<1:36:17,  1.93s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [1:36:34<1:35:41,  1.92s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.776841938495636, 'learning_rate': 5.069491525423729e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [1:36:34<1:35:41,  1.92s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [1:36:36<1:35:13,  1.91s/it]                                                       {'loss': 0.2018, 'grad_norm': 9.15870475769043, 'learning_rate': 5.067796610169492e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [1:36:36<1:35:13,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [1:36:38<1:34:10,  1.89s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.824840545654297, 'learning_rate': 5.066101694915254e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [1:36:38<1:34:10,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [1:36:40<1:33:55,  1.89s/it]                                                       {'loss': 0.2526, 'grad_norm': 8.852466583251953, 'learning_rate': 5.064406779661017e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [1:36:40<1:33:55,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [1:36:42<1:34:30,  1.90s/it]                                                       {'loss': 0.0459, 'grad_norm': 4.3626251220703125, 'learning_rate': 5.06271186440678e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [1:36:42<1:34:30,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [1:36:43<1:34:43,  1.90s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.26986363530158997, 'learning_rate': 5.061016949152543e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [1:36:43<1:34:43,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [1:36:45<1:34:00,  1.89s/it]                                                       {'loss': 0.1392, 'grad_norm': 8.540212631225586, 'learning_rate': 5.059322033898305e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [1:36:45<1:34:00,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [1:36:47<1:33:57,  1.89s/it]                                                       {'loss': 0.0935, 'grad_norm': 7.094175338745117, 'learning_rate': 5.057627118644069e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [1:36:47<1:33:57,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [1:36:49<1:34:34,  1.90s/it]                                                       {'loss': 0.1123, 'grad_norm': 11.207158088684082, 'learning_rate': 5.055932203389831e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [1:36:49<1:34:34,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [1:36:51<1:34:35,  1.90s/it]                                                       {'loss': 0.0442, 'grad_norm': 5.490949630737305, 'learning_rate': 5.054237288135594e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [1:36:51<1:34:35,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [1:36:53<1:34:48,  1.91s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4784059226512909, 'learning_rate': 5.052542372881356e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [1:36:53<1:34:48,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [1:36:55<1:34:01,  1.89s/it]                                                       {'loss': 0.1405, 'grad_norm': 6.765958786010742, 'learning_rate': 5.050847457627119e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [1:36:55<1:34:01,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [1:36:57<1:33:41,  1.89s/it]                                                       {'loss': 0.1099, 'grad_norm': 5.724127292633057, 'learning_rate': 5.0491525423728816e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [1:36:57<1:33:41,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [1:36:59<1:33:39,  1.89s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19244253635406494, 'learning_rate': 5.047457627118645e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [1:36:59<1:33:39,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [1:37:01<1:35:10,  1.92s/it]                                                       {'loss': 0.0933, 'grad_norm': 8.305413246154785, 'learning_rate': 5.045762711864407e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [1:37:01<1:35:10,  1.92s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [1:37:02<1:34:44,  1.91s/it]                                                       {'loss': 0.2771, 'grad_norm': 8.734198570251465, 'learning_rate': 5.0440677966101705e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [1:37:02<1:34:44,  1.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [1:37:04<1:34:02,  1.90s/it]                                                       {'loss': 0.284, 'grad_norm': 9.838842391967773, 'learning_rate': 5.042372881355932e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [1:37:04<1:34:02,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [1:37:06<1:34:07,  1.90s/it]                                                       {'loss': 0.0687, 'grad_norm': 4.879006385803223, 'learning_rate': 5.040677966101695e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [1:37:06<1:34:07,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [1:37:08<1:33:30,  1.89s/it]                                                       {'loss': 0.1363, 'grad_norm': 6.18409538269043, 'learning_rate': 5.038983050847458e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [1:37:08<1:33:30,  1.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [1:37:10<1:34:15,  1.90s/it]                                                       {'loss': 0.0272, 'grad_norm': 2.4264309406280518, 'learning_rate': 5.037288135593221e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [1:37:10<1:34:15,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [1:37:12<1:33:58,  1.90s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.4437930583953857, 'learning_rate': 5.0355932203389835e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [1:37:12<1:33:58,  1.90s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [1:37:14<1:33:29,  1.89s/it]                                                       {'loss': 0.0621, 'grad_norm': 4.755753993988037, 'learning_rate': 5.033898305084746e-06, 'epoch': 0.51}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [1:37:14<1:33:29,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [1:37:16<1:33:57,  1.90s/it]                                                       {'loss': 0.0269, 'grad_norm': 1.1806083917617798, 'learning_rate': 5.032203389830509e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [1:37:16<1:33:57,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [1:37:18<1:34:02,  1.90s/it]                                                       {'loss': 0.0172, 'grad_norm': 2.988208293914795, 'learning_rate': 5.030508474576271e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [1:37:18<1:34:02,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [1:37:19<1:33:31,  1.89s/it]                                                       {'loss': 0.2571, 'grad_norm': 8.38104248046875, 'learning_rate': 5.028813559322034e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [1:37:20<1:33:31,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [1:37:21<1:33:53,  1.90s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5697249174118042, 'learning_rate': 5.0271186440677965e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [1:37:21<1:33:53,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [1:37:23<1:33:59,  1.90s/it]                                                       {'loss': 0.051, 'grad_norm': 4.645261287689209, 'learning_rate': 5.02542372881356e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [1:37:23<1:33:59,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [1:37:25<1:33:12,  1.89s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1238851472735405, 'learning_rate': 5.023728813559322e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [1:37:25<1:33:12,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [1:37:27<1:32:45,  1.88s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05515724793076515, 'learning_rate': 5.0220338983050855e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [1:37:27<1:32:45,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [1:37:29<1:32:24,  1.87s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.27764642238616943, 'learning_rate': 5.020338983050848e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [1:37:29<1:32:24,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [1:37:31<1:31:50,  1.86s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5009373426437378, 'learning_rate': 5.018644067796611e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [1:37:31<1:31:50,  1.86s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [1:37:33<1:32:21,  1.87s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.30282682180404663, 'learning_rate': 5.016949152542373e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [1:37:33<1:32:21,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [1:37:34<1:32:14,  1.87s/it]                                                       {'loss': 0.0269, 'grad_norm': 1.504250168800354, 'learning_rate': 5.015254237288136e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [1:37:34<1:32:14,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [1:37:36<1:31:38,  1.86s/it]                                                       {'loss': 0.002, 'grad_norm': 0.21612189710140228, 'learning_rate': 5.0135593220338985e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [1:37:36<1:31:38,  1.86s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [1:37:38<1:32:20,  1.87s/it]                                                       {'loss': 0.1272, 'grad_norm': 9.300409317016602, 'learning_rate': 5.011864406779662e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [1:37:38<1:32:20,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [1:37:40<1:32:11,  1.87s/it]                                                       {'loss': 0.0224, 'grad_norm': 2.070716142654419, 'learning_rate': 5.010169491525424e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [1:37:40<1:32:11,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [1:37:42<1:32:45,  1.88s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.0586102269589901, 'learning_rate': 5.0084745762711874e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [1:37:42<1:32:45,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [1:37:44<1:33:28,  1.90s/it]                                                       {'loss': 0.2467, 'grad_norm': 10.834460258483887, 'learning_rate': 5.00677966101695e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [1:37:44<1:33:28,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [1:37:46<1:32:41,  1.88s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.6709342002868652, 'learning_rate': 5.005084745762713e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [1:37:46<1:32:41,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [1:37:48<1:33:52,  1.91s/it]                                                       {'loss': 0.1084, 'grad_norm': 6.057619571685791, 'learning_rate': 5.003389830508475e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [1:37:48<1:33:52,  1.91s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [1:37:50<1:34:48,  1.93s/it]                                                       {'loss': 0.0285, 'grad_norm': 4.258131504058838, 'learning_rate': 5.001694915254238e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [1:37:50<1:34:48,  1.93s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [1:37:52<1:34:23,  1.92s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.38858574628829956, 'learning_rate': 5e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [1:37:52<1:34:23,  1.92s/it][2025-11-11 23:31:07,553] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3050
[2025-11-11 23:31:07,560] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:31:07,833] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3050/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [1:37:54<1:47:34,  2.19s/it]                                                       {'loss': 0.3973, 'grad_norm': 13.549947738647461, 'learning_rate': 4.998305084745763e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [1:37:54<1:47:34,  2.19s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [1:37:56<1:44:08,  2.12s/it]                                                       {'loss': 0.1022, 'grad_norm': 6.502121925354004, 'learning_rate': 4.996610169491526e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [1:37:56<1:44:08,  2.12s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [1:37:58<1:40:45,  2.05s/it]                                                       {'loss': 0.009, 'grad_norm': 1.0065699815750122, 'learning_rate': 4.9949152542372885e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [1:37:58<1:40:45,  2.05s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [1:38:00<1:37:40,  1.99s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3470269739627838, 'learning_rate': 4.993220338983051e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [1:38:00<1:37:40,  1.99s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [1:38:02<1:36:22,  1.96s/it]                                                       {'loss': 0.1542, 'grad_norm': 7.856698989868164, 'learning_rate': 4.991525423728814e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [1:38:02<1:36:22,  1.96s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [1:38:04<1:35:02,  1.94s/it]                                                       {'loss': 0.0215, 'grad_norm': 3.8005716800689697, 'learning_rate': 4.989830508474577e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [1:38:04<1:35:02,  1.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [1:38:06<1:34:07,  1.92s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.7209501266479492, 'learning_rate': 4.98813559322034e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [1:38:06<1:34:07,  1.92s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [1:38:08<1:33:15,  1.90s/it]                                                       {'loss': 0.0491, 'grad_norm': 5.077178955078125, 'learning_rate': 4.986440677966102e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [1:38:08<1:33:15,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [1:38:10<1:36:34,  1.97s/it]                                                       {'loss': 0.0378, 'grad_norm': 4.789212226867676, 'learning_rate': 4.984745762711865e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [1:38:10<1:36:34,  1.97s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [1:38:12<1:38:27,  2.01s/it]                                                       {'loss': 0.0246, 'grad_norm': 2.7427139282226562, 'learning_rate': 4.983050847457628e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [1:38:12<1:38:27,  2.01s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [1:38:14<1:36:14,  1.96s/it]                                                       {'loss': 0.0541, 'grad_norm': 5.701213836669922, 'learning_rate': 4.98135593220339e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [1:38:14<1:36:14,  1.96s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [1:38:16<1:34:29,  1.93s/it]                                                       {'loss': 0.0346, 'grad_norm': 2.763909339904785, 'learning_rate': 4.979661016949153e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [1:38:16<1:34:29,  1.93s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [1:38:17<1:33:37,  1.91s/it]                                                       {'loss': 0.0551, 'grad_norm': 4.661586284637451, 'learning_rate': 4.977966101694915e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [1:38:17<1:33:37,  1.91s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [1:38:19<1:35:08,  1.94s/it]                                                       {'loss': 0.0416, 'grad_norm': 7.038130760192871, 'learning_rate': 4.976271186440678e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [1:38:19<1:35:08,  1.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [1:38:21<1:34:42,  1.94s/it]                                                       {'loss': 0.1436, 'grad_norm': 7.475614547729492, 'learning_rate': 4.974576271186441e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [1:38:21<1:34:42,  1.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [1:38:23<1:33:35,  1.91s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.7849950790405273, 'learning_rate': 4.9728813559322035e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [1:38:23<1:33:35,  1.91s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [1:38:25<1:32:20,  1.89s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5415327548980713, 'learning_rate': 4.971186440677967e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [1:38:25<1:32:20,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [1:38:27<1:32:10,  1.89s/it]                                                       {'loss': 0.0408, 'grad_norm': 4.058322906494141, 'learning_rate': 4.969491525423729e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [1:38:27<1:32:10,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [1:38:29<1:32:18,  1.89s/it]                                                       {'loss': 0.1558, 'grad_norm': 10.620769500732422, 'learning_rate': 4.967796610169492e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [1:38:29<1:32:18,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [1:38:31<1:32:35,  1.90s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.18816252052783966, 'learning_rate': 4.966101694915255e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [1:38:31<1:32:35,  1.90s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [1:38:33<1:31:59,  1.88s/it]                                                       {'loss': 0.0404, 'grad_norm': 4.324185371398926, 'learning_rate': 4.964406779661017e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [1:38:33<1:31:59,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [1:38:34<1:31:14,  1.87s/it]                                                       {'loss': 0.0398, 'grad_norm': 4.1485466957092285, 'learning_rate': 4.96271186440678e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [1:38:34<1:31:14,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [1:38:37<1:33:26,  1.92s/it]                                                       {'loss': 0.0134, 'grad_norm': 3.4514808654785156, 'learning_rate': 4.961016949152543e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [1:38:37<1:33:26,  1.92s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [1:38:38<1:33:43,  1.92s/it]                                                       {'loss': 0.4339, 'grad_norm': 11.65751838684082, 'learning_rate': 4.9593220338983054e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [1:38:38<1:33:43,  1.92s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [1:38:40<1:35:04,  1.95s/it]                                                       {'loss': 0.1272, 'grad_norm': 5.839968204498291, 'learning_rate': 4.957627118644069e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [1:38:40<1:35:04,  1.95s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [1:38:42<1:35:47,  1.97s/it]                                                       {'loss': 0.1026, 'grad_norm': 5.729981899261475, 'learning_rate': 4.955932203389831e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [1:38:42<1:35:47,  1.97s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [1:38:44<1:34:38,  1.94s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.688615083694458, 'learning_rate': 4.9542372881355936e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [1:38:44<1:34:38,  1.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [1:38:46<1:33:27,  1.92s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.0141637325286865, 'learning_rate': 4.952542372881357e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [1:38:46<1:33:27,  1.92s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [1:38:48<1:32:13,  1.89s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.6123392581939697, 'learning_rate': 4.950847457627119e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [1:38:48<1:32:13,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [1:38:50<1:31:59,  1.89s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.23222704231739044, 'learning_rate': 4.949152542372882e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [1:38:50<1:31:59,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [1:38:52<1:31:49,  1.89s/it]                                                       {'loss': 0.126, 'grad_norm': 6.864755153656006, 'learning_rate': 4.947457627118645e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [1:38:52<1:31:49,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [1:38:54<1:31:29,  1.88s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.5820582509040833, 'learning_rate': 4.9457627118644065e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [1:38:54<1:31:29,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [1:38:56<1:31:33,  1.88s/it]                                                       {'loss': 0.0345, 'grad_norm': 2.227072238922119, 'learning_rate': 4.94406779661017e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [1:38:56<1:31:33,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [1:38:57<1:31:56,  1.89s/it]                                                       {'loss': 0.116, 'grad_norm': 8.22624683380127, 'learning_rate': 4.942372881355932e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [1:38:57<1:31:56,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [1:38:59<1:31:45,  1.89s/it]                                                       {'loss': 0.1365, 'grad_norm': 21.033681869506836, 'learning_rate': 4.9406779661016955e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [1:38:59<1:31:45,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [1:39:01<1:31:43,  1.89s/it]                                                       {'loss': 0.0411, 'grad_norm': 5.273149490356445, 'learning_rate': 4.938983050847458e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [1:39:01<1:31:43,  1.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [1:39:03<1:31:07,  1.88s/it]                                                       {'loss': 0.035, 'grad_norm': 3.5118558406829834, 'learning_rate': 4.93728813559322e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [1:39:03<1:31:07,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [1:39:05<1:31:26,  1.88s/it]                                                       {'loss': 0.2189, 'grad_norm': 12.513673782348633, 'learning_rate': 4.935593220338984e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [1:39:05<1:31:26,  1.88s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [1:39:07<1:31:15,  1.88s/it]                                                       {'loss': 0.2107, 'grad_norm': 12.450315475463867, 'learning_rate': 4.933898305084746e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [1:39:07<1:31:15,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [1:39:09<1:32:25,  1.91s/it]                                                       {'loss': 0.0672, 'grad_norm': 7.466416358947754, 'learning_rate': 4.9322033898305085e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [1:39:09<1:32:25,  1.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [1:39:11<1:31:19,  1.88s/it]                                                       {'loss': 0.2201, 'grad_norm': 10.339373588562012, 'learning_rate': 4.930508474576272e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [1:39:11<1:31:19,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [1:39:13<1:31:22,  1.89s/it]                                                       {'loss': 0.1889, 'grad_norm': 10.282014846801758, 'learning_rate': 4.928813559322034e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [1:39:13<1:31:22,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [1:39:14<1:30:43,  1.87s/it]                                                       {'loss': 0.0397, 'grad_norm': 4.281642913818359, 'learning_rate': 4.9271186440677975e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [1:39:14<1:30:43,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [1:39:16<1:32:53,  1.92s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.1517136096954346, 'learning_rate': 4.92542372881356e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [1:39:16<1:32:53,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [1:39:18<1:32:12,  1.90s/it]                                                       {'loss': 0.0128, 'grad_norm': 2.5219767093658447, 'learning_rate': 4.923728813559322e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [1:39:18<1:32:12,  1.90s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [1:39:20<1:31:07,  1.88s/it]                                                       {'loss': 0.0553, 'grad_norm': 3.407771110534668, 'learning_rate': 4.922033898305086e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [1:39:20<1:31:07,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [1:39:22<1:31:16,  1.89s/it]                                                       {'loss': 0.2429, 'grad_norm': 11.911978721618652, 'learning_rate': 4.920338983050848e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [1:39:22<1:31:16,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [1:39:24<1:31:04,  1.88s/it]                                                       {'loss': 0.011, 'grad_norm': 1.4468046426773071, 'learning_rate': 4.9186440677966104e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [1:39:24<1:31:04,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [1:39:26<1:30:34,  1.87s/it]                                                       {'loss': 0.0184, 'grad_norm': 1.026645302772522, 'learning_rate': 4.916949152542374e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [1:39:26<1:30:34,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [1:39:28<1:30:38,  1.88s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1456771045923233, 'learning_rate': 4.915254237288136e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [1:39:28<1:30:38,  1.88s/it][2025-11-11 23:32:43,549] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3100
[2025-11-11 23:32:43,556] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:32:43,842] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [1:39:30<1:42:24,  2.12s/it]                                                       {'loss': 0.0438, 'grad_norm': 1.9071365594863892, 'learning_rate': 4.9135593220338986e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [1:39:30<1:42:24,  2.12s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [1:39:32<1:38:33,  2.04s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.063686303794384, 'learning_rate': 4.911864406779661e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [1:39:32<1:38:33,  2.04s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [1:39:34<1:36:13,  1.99s/it]                                                       {'loss': 0.2645, 'grad_norm': 13.802767753601074, 'learning_rate': 4.910169491525424e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [1:39:34<1:36:13,  1.99s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [1:39:36<1:34:23,  1.96s/it]                                                       {'loss': 0.1766, 'grad_norm': 7.323697566986084, 'learning_rate': 4.908474576271187e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [1:39:36<1:34:23,  1.96s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [1:39:38<1:33:14,  1.93s/it]                                                       {'loss': 0.1205, 'grad_norm': 5.520546913146973, 'learning_rate': 4.906779661016949e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [1:39:38<1:33:14,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [1:39:40<1:34:53,  1.97s/it]                                                       {'loss': 0.0678, 'grad_norm': 5.880688667297363, 'learning_rate': 4.905084745762712e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [1:39:40<1:34:53,  1.97s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [1:39:42<1:33:02,  1.93s/it]                                                       {'loss': 0.0373, 'grad_norm': 4.745672225952148, 'learning_rate': 4.903389830508475e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [1:39:42<1:33:02,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [1:39:44<1:32:12,  1.91s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.709627628326416, 'learning_rate': 4.901694915254237e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [1:39:44<1:32:12,  1.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [1:39:45<1:31:42,  1.90s/it]                                                       {'loss': 0.012, 'grad_norm': 1.667612075805664, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [1:39:45<1:31:42,  1.90s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [1:39:47<1:31:50,  1.91s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.91469144821167, 'learning_rate': 4.898305084745763e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [1:39:47<1:31:50,  1.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [1:39:49<1:31:05,  1.89s/it]                                                       {'loss': 0.0737, 'grad_norm': 9.990687370300293, 'learning_rate': 4.896610169491525e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [1:39:49<1:31:05,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [1:39:51<1:31:55,  1.91s/it]                                                       {'loss': 0.1561, 'grad_norm': 10.14953899383545, 'learning_rate': 4.894915254237289e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [1:39:51<1:31:55,  1.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [1:39:53<1:30:55,  1.89s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.7897955179214478, 'learning_rate': 4.893220338983051e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [1:39:53<1:30:55,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [1:39:55<1:30:43,  1.89s/it]                                                       {'loss': 0.008, 'grad_norm': 1.2647747993469238, 'learning_rate': 4.891525423728814e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [1:39:55<1:30:43,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [1:39:57<1:30:53,  1.89s/it]                                                       {'loss': 0.2317, 'grad_norm': 8.535623550415039, 'learning_rate': 4.889830508474577e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [1:39:57<1:30:53,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [1:39:59<1:32:07,  1.92s/it]                                                       {'loss': 0.0316, 'grad_norm': 2.8486762046813965, 'learning_rate': 4.888135593220339e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [1:39:59<1:32:07,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [1:40:01<1:31:27,  1.90s/it]                                                       {'loss': 0.0462, 'grad_norm': 4.827833652496338, 'learning_rate': 4.8864406779661025e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [1:40:01<1:31:27,  1.90s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [1:40:03<1:32:27,  1.92s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.6167789101600647, 'learning_rate': 4.884745762711865e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [1:40:03<1:32:27,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [1:40:05<1:32:52,  1.93s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.598252534866333, 'learning_rate': 4.883050847457627e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [1:40:05<1:32:52,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [1:40:06<1:32:18,  1.92s/it]                                                       {'loss': 0.0256, 'grad_norm': 2.0549933910369873, 'learning_rate': 4.881355932203391e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [1:40:06<1:32:18,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [1:40:08<1:32:22,  1.93s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.930139183998108, 'learning_rate': 4.879661016949153e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [1:40:08<1:32:22,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [1:40:10<1:32:21,  1.93s/it]                                                       {'loss': 0.0306, 'grad_norm': 3.496994733810425, 'learning_rate': 4.877966101694916e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [1:40:10<1:32:21,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [1:40:12<1:32:08,  1.92s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.23356732726097107, 'learning_rate': 4.876271186440678e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [1:40:12<1:32:08,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [1:40:14<1:32:29,  1.93s/it]                                                       {'loss': 0.0474, 'grad_norm': 5.677845478057861, 'learning_rate': 4.874576271186441e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [1:40:14<1:32:29,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [1:40:16<1:31:47,  1.92s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.9100415110588074, 'learning_rate': 4.872881355932204e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [1:40:16<1:31:47,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [1:40:18<1:30:20,  1.89s/it]                                                       {'loss': 0.2098, 'grad_norm': 7.86304235458374, 'learning_rate': 4.871186440677966e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [1:40:18<1:30:20,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [1:40:20<1:30:01,  1.88s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.672893762588501, 'learning_rate': 4.869491525423729e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [1:40:20<1:30:01,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [1:40:22<1:29:53,  1.88s/it]                                                       {'loss': 0.0351, 'grad_norm': 2.1934659481048584, 'learning_rate': 4.867796610169492e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [1:40:22<1:29:53,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [1:40:24<1:31:27,  1.91s/it]                                                       {'loss': 0.0691, 'grad_norm': 7.3112006187438965, 'learning_rate': 4.866101694915254e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [1:40:24<1:31:27,  1.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [1:40:25<1:30:44,  1.90s/it]                                                       {'loss': 0.175, 'grad_norm': 9.452360153198242, 'learning_rate': 4.864406779661017e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [1:40:25<1:30:44,  1.90s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [1:40:27<1:30:38,  1.90s/it]                                                       {'loss': 0.0357, 'grad_norm': 4.079971790313721, 'learning_rate': 4.86271186440678e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [1:40:27<1:30:38,  1.90s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [1:40:29<1:29:32,  1.87s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.454035758972168, 'learning_rate': 4.861016949152543e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [1:40:29<1:29:32,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [1:40:31<1:29:16,  1.87s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.6871399879455566, 'learning_rate': 4.8593220338983055e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [1:40:31<1:29:16,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [1:40:33<1:31:20,  1.91s/it]                                                       {'loss': 0.2004, 'grad_norm': 11.858162879943848, 'learning_rate': 4.857627118644068e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [1:40:33<1:31:20,  1.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [1:40:35<1:31:45,  1.92s/it]                                                       {'loss': 0.053, 'grad_norm': 6.002294540405273, 'learning_rate': 4.855932203389831e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [1:40:35<1:31:45,  1.92s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [1:40:37<1:32:20,  1.93s/it]                                                       {'loss': 0.244, 'grad_norm': 8.399698257446289, 'learning_rate': 4.854237288135594e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [1:40:37<1:32:20,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [1:40:39<1:33:36,  1.96s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.11734379827976227, 'learning_rate': 4.852542372881356e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [1:40:39<1:33:36,  1.96s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [1:40:41<1:33:30,  1.96s/it]                                                       {'loss': 0.0623, 'grad_norm': 5.694538116455078, 'learning_rate': 4.850847457627119e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [1:40:41<1:33:30,  1.96s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [1:40:43<1:31:49,  1.93s/it]                                                       {'loss': 0.0222, 'grad_norm': 3.5034284591674805, 'learning_rate': 4.849152542372882e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [1:40:43<1:31:49,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [1:40:45<1:30:35,  1.90s/it]                                                       {'loss': 0.0268, 'grad_norm': 2.120806932449341, 'learning_rate': 4.847457627118645e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [1:40:45<1:30:35,  1.90s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [1:40:46<1:29:48,  1.88s/it]                                                       {'loss': 0.0187, 'grad_norm': 2.017174482345581, 'learning_rate': 4.8457627118644075e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [1:40:46<1:29:48,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [1:40:48<1:29:32,  1.88s/it]                                                       {'loss': 0.046, 'grad_norm': 4.316342353820801, 'learning_rate': 4.84406779661017e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [1:40:48<1:29:32,  1.88s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [1:40:50<1:29:00,  1.87s/it]                                                       {'loss': 0.1731, 'grad_norm': 8.903919219970703, 'learning_rate': 4.842372881355933e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [1:40:50<1:29:00,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [1:40:52<1:28:59,  1.87s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3395720422267914, 'learning_rate': 4.840677966101695e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [1:40:52<1:28:59,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [1:40:54<1:29:42,  1.89s/it]                                                       {'loss': 0.1282, 'grad_norm': 8.419026374816895, 'learning_rate': 4.838983050847458e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [1:40:54<1:29:42,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [1:40:56<1:29:39,  1.89s/it]                                                       {'loss': 0.0266, 'grad_norm': 2.77317476272583, 'learning_rate': 4.8372881355932205e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [1:40:56<1:29:39,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [1:40:58<1:28:57,  1.87s/it]                                                       {'loss': 0.0257, 'grad_norm': 2.822690963745117, 'learning_rate': 4.835593220338983e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [1:40:58<1:28:57,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [1:41:00<1:28:54,  1.87s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.9530308246612549, 'learning_rate': 4.833898305084746e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [1:41:00<1:28:54,  1.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [1:41:02<1:29:55,  1.89s/it]                                                       {'loss': 0.0455, 'grad_norm': 4.080803871154785, 'learning_rate': 4.832203389830509e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [1:41:02<1:29:55,  1.89s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [1:41:03<1:29:36,  1.89s/it]                                                       {'loss': 0.0806, 'grad_norm': 6.839541435241699, 'learning_rate': 4.830508474576272e-06, 'epoch': 0.53}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [1:41:03<1:29:36,  1.89s/it][2025-11-11 23:34:19,322] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3150
[2025-11-11 23:34:19,330] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:34:19,644] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3150/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [1:41:06<1:41:22,  2.13s/it]                                                       {'loss': 0.008, 'grad_norm': 1.6172406673431396, 'learning_rate': 4.828813559322034e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [1:41:06<1:41:22,  2.13s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [1:41:08<1:37:24,  2.05s/it]                                                       {'loss': 0.0337, 'grad_norm': 4.5116400718688965, 'learning_rate': 4.827118644067797e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [1:41:08<1:37:24,  2.05s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [1:41:10<1:34:25,  1.99s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.126091480255127, 'learning_rate': 4.82542372881356e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [1:41:10<1:34:25,  1.99s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [1:41:12<1:32:47,  1.96s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1939067542552948, 'learning_rate': 4.823728813559322e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [1:41:12<1:32:47,  1.96s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [1:41:14<1:33:15,  1.97s/it]                                                       {'loss': 0.1294, 'grad_norm': 5.325940132141113, 'learning_rate': 4.822033898305085e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [1:41:14<1:33:15,  1.97s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [1:41:16<1:31:47,  1.94s/it]                                                       {'loss': 0.0488, 'grad_norm': 5.251304626464844, 'learning_rate': 4.820338983050848e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [1:41:16<1:31:47,  1.94s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [1:41:17<1:30:59,  1.92s/it]                                                       {'loss': 0.084, 'grad_norm': 3.910184144973755, 'learning_rate': 4.8186440677966105e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [1:41:17<1:30:59,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [1:41:19<1:30:43,  1.92s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.8909759521484375, 'learning_rate': 4.816949152542373e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [1:41:19<1:30:43,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [1:41:21<1:30:31,  1.91s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.8636519908905029, 'learning_rate': 4.815254237288136e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [1:41:21<1:30:31,  1.91s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [1:41:23<1:31:43,  1.94s/it]                                                       {'loss': 0.1449, 'grad_norm': 9.535919189453125, 'learning_rate': 4.813559322033899e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [1:41:23<1:31:43,  1.94s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [1:41:25<1:31:46,  1.94s/it]                                                       {'loss': 0.0419, 'grad_norm': 5.593985080718994, 'learning_rate': 4.811864406779662e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [1:41:25<1:31:46,  1.94s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [1:41:27<1:31:10,  1.93s/it]                                                       {'loss': 0.1856, 'grad_norm': 10.014718055725098, 'learning_rate': 4.810169491525424e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [1:41:27<1:31:10,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [1:41:29<1:30:32,  1.91s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.8171409368515015, 'learning_rate': 4.808474576271187e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [1:41:29<1:30:32,  1.91s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [1:41:31<1:31:06,  1.93s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.699761152267456, 'learning_rate': 4.80677966101695e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [1:41:31<1:31:06,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [1:41:33<1:29:50,  1.90s/it]                                                       {'loss': 0.0534, 'grad_norm': 3.867724657058716, 'learning_rate': 4.805084745762712e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [1:41:33<1:29:50,  1.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [1:41:35<1:30:09,  1.91s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4127630591392517, 'learning_rate': 4.803389830508475e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [1:41:35<1:30:09,  1.91s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [1:41:37<1:29:22,  1.89s/it]                                                       {'loss': 0.1967, 'grad_norm': 8.353548049926758, 'learning_rate': 4.801694915254237e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [1:41:37<1:29:22,  1.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [1:41:38<1:29:48,  1.90s/it]                                                       {'loss': 0.2429, 'grad_norm': 12.212874412536621, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [1:41:38<1:29:48,  1.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [1:41:40<1:29:18,  1.89s/it]                                                       {'loss': 0.0544, 'grad_norm': 4.228067398071289, 'learning_rate': 4.798305084745763e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [1:41:40<1:29:18,  1.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [1:41:42<1:29:26,  1.90s/it]                                                       {'loss': 0.014, 'grad_norm': 1.8234244585037231, 'learning_rate': 4.7966101694915255e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [1:41:42<1:29:26,  1.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [1:41:44<1:30:58,  1.93s/it]                                                       {'loss': 0.0137, 'grad_norm': 1.9950861930847168, 'learning_rate': 4.794915254237289e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [1:41:44<1:30:58,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [1:41:46<1:32:26,  1.96s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.6596134901046753, 'learning_rate': 4.793220338983051e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [1:41:46<1:32:26,  1.96s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [1:41:48<1:32:34,  1.96s/it]                                                       {'loss': 0.0511, 'grad_norm': 3.080294132232666, 'learning_rate': 4.791525423728814e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [1:41:48<1:32:34,  1.96s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [1:41:50<1:31:01,  1.93s/it]                                                       {'loss': 0.1945, 'grad_norm': 6.855611324310303, 'learning_rate': 4.789830508474577e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [1:41:50<1:31:01,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [1:41:52<1:31:10,  1.94s/it]                                                       {'loss': 0.0339, 'grad_norm': 4.404405117034912, 'learning_rate': 4.788135593220339e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [1:41:52<1:31:10,  1.94s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [1:41:54<1:30:28,  1.92s/it]                                                       {'loss': 0.0587, 'grad_norm': 6.73514461517334, 'learning_rate': 4.786440677966102e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [1:41:54<1:30:28,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [1:41:56<1:30:43,  1.93s/it]                                                       {'loss': 0.0129, 'grad_norm': 2.491083860397339, 'learning_rate': 4.784745762711865e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [1:41:56<1:30:43,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [1:41:58<1:31:21,  1.94s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.139200448989868, 'learning_rate': 4.7830508474576274e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [1:41:58<1:31:21,  1.94s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [1:42:00<1:30:18,  1.92s/it]                                                       {'loss': 0.0435, 'grad_norm': 4.649046897888184, 'learning_rate': 4.781355932203391e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [1:42:00<1:30:18,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [1:42:02<1:30:10,  1.92s/it]                                                       {'loss': 0.143, 'grad_norm': 9.106444358825684, 'learning_rate': 4.779661016949153e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [1:42:02<1:30:10,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [1:42:04<1:30:18,  1.92s/it]                                                       {'loss': 0.0895, 'grad_norm': 7.759448051452637, 'learning_rate': 4.7779661016949156e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [1:42:04<1:30:18,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [1:42:05<1:29:50,  1.91s/it]                                                       {'loss': 0.2339, 'grad_norm': 11.622971534729004, 'learning_rate': 4.776271186440679e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [1:42:05<1:29:50,  1.91s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [1:42:07<1:29:20,  1.90s/it]                                                       {'loss': 0.019, 'grad_norm': 2.303480625152588, 'learning_rate': 4.774576271186441e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [1:42:07<1:29:20,  1.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [1:42:09<1:29:42,  1.91s/it]                                                       {'loss': 0.0575, 'grad_norm': 4.647321701049805, 'learning_rate': 4.772881355932204e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [1:42:09<1:29:42,  1.91s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [1:42:11<1:29:08,  1.90s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3561498522758484, 'learning_rate': 4.771186440677967e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [1:42:11<1:29:08,  1.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [1:42:13<1:28:25,  1.89s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.7002586126327515, 'learning_rate': 4.7694915254237285e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [1:42:13<1:28:25,  1.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [1:42:15<1:27:53,  1.87s/it]                                                       {'loss': 0.0409, 'grad_norm': 4.657588481903076, 'learning_rate': 4.767796610169492e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [1:42:15<1:27:53,  1.87s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [1:42:17<1:28:04,  1.88s/it]                                                       {'loss': 0.2318, 'grad_norm': 10.733613967895508, 'learning_rate': 4.766101694915254e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [1:42:17<1:28:04,  1.88s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [1:42:19<1:28:02,  1.88s/it]                                                       {'loss': 0.0624, 'grad_norm': 8.031256675720215, 'learning_rate': 4.7644067796610175e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [1:42:19<1:28:02,  1.88s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [1:42:21<1:29:48,  1.92s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.3223614692687988, 'learning_rate': 4.76271186440678e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [1:42:21<1:29:48,  1.92s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [1:42:23<1:29:16,  1.91s/it]                                                       {'loss': 0.022, 'grad_norm': 3.8034846782684326, 'learning_rate': 4.761016949152542e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [1:42:23<1:29:16,  1.91s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [1:42:24<1:28:21,  1.89s/it]                                                       {'loss': 0.0909, 'grad_norm': 6.881255626678467, 'learning_rate': 4.759322033898306e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [1:42:24<1:28:21,  1.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [1:42:26<1:27:50,  1.88s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.8232038021087646, 'learning_rate': 4.757627118644068e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [1:42:26<1:27:50,  1.88s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [1:42:28<1:27:35,  1.87s/it]                                                       {'loss': 0.0701, 'grad_norm': 6.926822185516357, 'learning_rate': 4.7559322033898305e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [1:42:28<1:27:35,  1.87s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [1:42:30<1:27:29,  1.87s/it]                                                       {'loss': 0.0185, 'grad_norm': 2.0398383140563965, 'learning_rate': 4.754237288135594e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [1:42:30<1:27:29,  1.87s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [1:42:32<1:26:44,  1.86s/it]                                                       {'loss': 0.0863, 'grad_norm': 6.255141735076904, 'learning_rate': 4.752542372881356e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [1:42:32<1:26:44,  1.86s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [1:42:34<1:27:06,  1.86s/it]                                                       {'loss': 0.0857, 'grad_norm': 7.77131462097168, 'learning_rate': 4.7508474576271195e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [1:42:34<1:27:06,  1.86s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [1:42:36<1:27:11,  1.87s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.8962610960006714, 'learning_rate': 4.749152542372882e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [1:42:36<1:27:11,  1.87s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [1:42:37<1:27:34,  1.88s/it]                                                       {'loss': 0.0496, 'grad_norm': 5.24381160736084, 'learning_rate': 4.747457627118644e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [1:42:37<1:27:34,  1.88s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [1:42:39<1:27:47,  1.88s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.2403852939605713, 'learning_rate': 4.745762711864408e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [1:42:39<1:27:47,  1.88s/it][2025-11-11 23:35:55,241] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3200
[2025-11-11 23:35:55,248] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:35:55,528] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [1:42:42<1:38:39,  2.11s/it]                                                       {'loss': 0.0196, 'grad_norm': 1.8624695539474487, 'learning_rate': 4.74406779661017e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [1:42:42<1:38:39,  2.11s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [1:42:44<1:35:17,  2.04s/it]                                                       {'loss': 0.0757, 'grad_norm': 5.726362705230713, 'learning_rate': 4.7423728813559325e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [1:42:44<1:35:17,  2.04s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [1:42:46<1:32:57,  1.99s/it]                                                       {'loss': 0.1615, 'grad_norm': 9.239121437072754, 'learning_rate': 4.740677966101696e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [1:42:46<1:32:57,  1.99s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [1:42:48<1:31:13,  1.96s/it]                                                       {'loss': 0.0356, 'grad_norm': 2.3305253982543945, 'learning_rate': 4.738983050847458e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [1:42:48<1:31:13,  1.96s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [1:42:49<1:30:02,  1.93s/it]                                                       {'loss': 0.0306, 'grad_norm': 1.824256181716919, 'learning_rate': 4.737288135593221e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [1:42:49<1:30:02,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [1:42:52<1:33:05,  2.00s/it]                                                       {'loss': 0.0998, 'grad_norm': 5.088897228240967, 'learning_rate': 4.735593220338983e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [1:42:52<1:33:05,  2.00s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [1:42:54<1:31:17,  1.96s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.1678428649902344, 'learning_rate': 4.733898305084746e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [1:42:54<1:31:17,  1.96s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [1:42:55<1:30:42,  1.95s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.002328395843506, 'learning_rate': 4.732203389830509e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [1:42:55<1:30:42,  1.95s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [1:42:57<1:31:51,  1.97s/it]                                                       {'loss': 0.1352, 'grad_norm': 7.906916618347168, 'learning_rate': 4.730508474576271e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [1:42:57<1:31:51,  1.97s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [1:42:59<1:31:17,  1.96s/it]                                                       {'loss': 0.016, 'grad_norm': 2.8335633277893066, 'learning_rate': 4.728813559322034e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [1:42:59<1:31:17,  1.96s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [1:43:01<1:30:38,  1.95s/it]                                                       {'loss': 0.0648, 'grad_norm': 7.093982696533203, 'learning_rate': 4.727118644067797e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [1:43:01<1:30:38,  1.95s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [1:43:03<1:29:41,  1.93s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.27459716796875, 'learning_rate': 4.725423728813559e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [1:43:03<1:29:41,  1.93s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [1:43:05<1:30:07,  1.94s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6282197833061218, 'learning_rate': 4.7237288135593225e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [1:43:05<1:30:07,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [1:43:07<1:29:56,  1.94s/it]                                                       {'loss': 0.0447, 'grad_norm': 1.3896762132644653, 'learning_rate': 4.722033898305085e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [1:43:07<1:29:56,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [1:43:09<1:31:05,  1.96s/it]                                                       {'loss': 0.0259, 'grad_norm': 2.600057363510132, 'learning_rate': 4.720338983050848e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [1:43:09<1:31:05,  1.96s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [1:43:11<1:30:04,  1.94s/it]                                                       {'loss': 0.0856, 'grad_norm': 8.52932357788086, 'learning_rate': 4.718644067796611e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [1:43:11<1:30:04,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [1:43:13<1:30:29,  1.95s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.7878674864768982, 'learning_rate': 4.716949152542373e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [1:43:13<1:30:29,  1.95s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [1:43:15<1:29:52,  1.94s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.22010214626789093, 'learning_rate': 4.715254237288136e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [1:43:15<1:29:52,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [1:43:17<1:29:21,  1.93s/it]                                                       {'loss': 0.0378, 'grad_norm': 3.152301073074341, 'learning_rate': 4.713559322033899e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [1:43:17<1:29:21,  1.93s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [1:43:19<1:28:14,  1.90s/it]                                                       {'loss': 0.0391, 'grad_norm': 2.506613254547119, 'learning_rate': 4.711864406779661e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [1:43:19<1:28:14,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [1:43:21<1:27:45,  1.89s/it]                                                       {'loss': 0.0161, 'grad_norm': 1.7142263650894165, 'learning_rate': 4.7101694915254245e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [1:43:21<1:27:45,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [1:43:22<1:27:32,  1.89s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.2354272603988647, 'learning_rate': 4.708474576271187e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [1:43:22<1:27:32,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [1:43:24<1:27:44,  1.90s/it]                                                       {'loss': 0.0726, 'grad_norm': 6.720046520233154, 'learning_rate': 4.706779661016949e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [1:43:24<1:27:44,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [1:43:26<1:28:21,  1.91s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.22972211241722107, 'learning_rate': 4.705084745762713e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [1:43:26<1:28:21,  1.91s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [1:43:28<1:27:40,  1.90s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.2952824831008911, 'learning_rate': 4.703389830508475e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [1:43:28<1:27:40,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [1:43:30<1:27:39,  1.90s/it]                                                       {'loss': 0.0447, 'grad_norm': 5.145893096923828, 'learning_rate': 4.701694915254238e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [1:43:30<1:27:39,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [1:43:32<1:27:32,  1.89s/it]                                                       {'loss': 0.0133, 'grad_norm': 2.128472089767456, 'learning_rate': 4.7e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [1:43:32<1:27:32,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [1:43:34<1:27:21,  1.89s/it]                                                       {'loss': 0.2886, 'grad_norm': 11.385433197021484, 'learning_rate': 4.698305084745763e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [1:43:34<1:27:21,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [1:43:36<1:26:43,  1.88s/it]                                                       {'loss': 0.064, 'grad_norm': 7.080270290374756, 'learning_rate': 4.696610169491526e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [1:43:36<1:26:43,  1.88s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [1:43:38<1:27:28,  1.89s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.4041815996170044, 'learning_rate': 4.694915254237288e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [1:43:38<1:27:28,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [1:43:39<1:27:31,  1.90s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2804962694644928, 'learning_rate': 4.693220338983051e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [1:43:39<1:27:31,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [1:43:41<1:27:31,  1.90s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.3557628393173218, 'learning_rate': 4.691525423728814e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [1:43:41<1:27:31,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [1:43:43<1:26:31,  1.88s/it]                                                       {'loss': 0.0357, 'grad_norm': 6.253480434417725, 'learning_rate': 4.689830508474576e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [1:43:43<1:26:31,  1.88s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [1:43:45<1:26:19,  1.87s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.0929189920425415, 'learning_rate': 4.688135593220339e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [1:43:45<1:26:19,  1.87s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [1:43:47<1:26:25,  1.88s/it]                                                       {'loss': 0.483, 'grad_norm': 12.538698196411133, 'learning_rate': 4.686440677966102e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [1:43:47<1:26:25,  1.88s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [1:43:49<1:27:35,  1.90s/it]                                                       {'loss': 0.1163, 'grad_norm': 4.703419208526611, 'learning_rate': 4.684745762711865e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [1:43:49<1:27:35,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [1:43:51<1:26:52,  1.89s/it]                                                       {'loss': 0.017, 'grad_norm': 2.939528703689575, 'learning_rate': 4.6830508474576275e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [1:43:51<1:26:52,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [1:43:53<1:29:19,  1.94s/it]                                                       {'loss': 0.0737, 'grad_norm': 3.735106945037842, 'learning_rate': 4.68135593220339e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [1:43:53<1:29:19,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [1:43:55<1:28:54,  1.93s/it]                                                       {'loss': 0.0295, 'grad_norm': 5.059165954589844, 'learning_rate': 4.679661016949153e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [1:43:55<1:28:54,  1.93s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [1:43:57<1:28:09,  1.92s/it]                                                       {'loss': 0.1169, 'grad_norm': 8.98880672454834, 'learning_rate': 4.677966101694916e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [1:43:57<1:28:09,  1.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [1:43:59<1:28:07,  1.92s/it]                                                       {'loss': 0.1319, 'grad_norm': 11.049321174621582, 'learning_rate': 4.676271186440678e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [1:43:59<1:28:07,  1.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [1:44:00<1:28:29,  1.92s/it]                                                       {'loss': 0.0209, 'grad_norm': 4.027344226837158, 'learning_rate': 4.674576271186441e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [1:44:00<1:28:29,  1.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [1:44:02<1:27:58,  1.91s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5772725343704224, 'learning_rate': 4.672881355932204e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [1:44:02<1:27:58,  1.91s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [1:44:05<1:33:39,  2.04s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.1522607803344727, 'learning_rate': 4.671186440677967e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [1:44:05<1:33:39,  2.04s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [1:44:07<1:32:45,  2.02s/it]                                                       {'loss': 0.0332, 'grad_norm': 2.9426801204681396, 'learning_rate': 4.6694915254237295e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [1:44:07<1:32:45,  2.02s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [1:44:09<1:31:22,  1.99s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.5339617729187012, 'learning_rate': 4.667796610169492e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [1:44:09<1:31:22,  1.99s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [1:44:10<1:29:29,  1.95s/it]                                                       {'loss': 0.103, 'grad_norm': 7.3620758056640625, 'learning_rate': 4.666101694915255e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [1:44:10<1:29:29,  1.95s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [1:44:12<1:28:34,  1.93s/it]                                                       {'loss': 0.168, 'grad_norm': 12.620170593261719, 'learning_rate': 4.664406779661017e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [1:44:12<1:28:34,  1.93s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [1:44:14<1:27:26,  1.91s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4699050784111023, 'learning_rate': 4.66271186440678e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [1:44:14<1:27:26,  1.91s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [1:44:16<1:27:11,  1.90s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.365616798400879, 'learning_rate': 4.6610169491525425e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [1:44:16<1:27:11,  1.90s/it][2025-11-11 23:37:31,997] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3250
[2025-11-11 23:37:32,004] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:37:32,287] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3250/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [1:44:19<1:38:18,  2.15s/it]                                                       {'loss': 0.0378, 'grad_norm': 2.6347014904022217, 'learning_rate': 4.659322033898305e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [1:44:19<1:38:18,  2.15s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [1:44:21<1:34:03,  2.05s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.0371662378311157, 'learning_rate': 4.657627118644068e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [1:44:21<1:34:03,  2.05s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [1:44:23<1:31:52,  2.01s/it]                                                       {'loss': 0.1127, 'grad_norm': 7.713767051696777, 'learning_rate': 4.655932203389831e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [1:44:23<1:31:52,  2.01s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [1:44:24<1:29:34,  1.96s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.414936900138855, 'learning_rate': 4.654237288135594e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [1:44:24<1:29:34,  1.96s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [1:44:26<1:28:41,  1.94s/it]                                                       {'loss': 0.0433, 'grad_norm': 3.268557071685791, 'learning_rate': 4.652542372881356e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [1:44:26<1:28:41,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [1:44:28<1:27:45,  1.92s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12153997272253036, 'learning_rate': 4.650847457627119e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [1:44:28<1:27:45,  1.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [1:44:30<1:29:31,  1.96s/it]                                                       {'loss': 0.0467, 'grad_norm': 3.0355160236358643, 'learning_rate': 4.649152542372882e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [1:44:30<1:29:31,  1.96s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [1:44:32<1:28:51,  1.94s/it]                                                       {'loss': 0.0258, 'grad_norm': 3.548091173171997, 'learning_rate': 4.6474576271186444e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [1:44:32<1:28:51,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [1:44:34<1:28:47,  1.94s/it]                                                       {'loss': 0.0469, 'grad_norm': 6.472467422485352, 'learning_rate': 4.645762711864407e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [1:44:34<1:28:47,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [1:44:36<1:29:20,  1.96s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.9475734829902649, 'learning_rate': 4.64406779661017e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [1:44:36<1:29:20,  1.96s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [1:44:38<1:28:23,  1.94s/it]                                                       {'loss': 0.0114, 'grad_norm': 2.4482579231262207, 'learning_rate': 4.6423728813559326e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [1:44:38<1:28:23,  1.94s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [1:44:40<1:27:50,  1.92s/it]                                                       {'loss': 0.1187, 'grad_norm': 7.510730266571045, 'learning_rate': 4.640677966101695e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [1:44:40<1:27:50,  1.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [1:44:42<1:27:07,  1.91s/it]                                                       {'loss': 0.0147, 'grad_norm': 2.137826442718506, 'learning_rate': 4.638983050847458e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [1:44:42<1:27:07,  1.91s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [1:44:44<1:26:31,  1.90s/it]                                                       {'loss': 0.0624, 'grad_norm': 5.453495025634766, 'learning_rate': 4.637288135593221e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [1:44:44<1:26:31,  1.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [1:44:45<1:26:22,  1.89s/it]                                                       {'loss': 0.0538, 'grad_norm': 3.6819608211517334, 'learning_rate': 4.635593220338984e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [1:44:45<1:26:22,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [1:44:47<1:25:58,  1.89s/it]                                                       {'loss': 0.0835, 'grad_norm': 9.03892993927002, 'learning_rate': 4.633898305084746e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [1:44:47<1:25:58,  1.89s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [1:44:49<1:25:04,  1.87s/it]                                                       {'loss': 0.0228, 'grad_norm': 1.5710445642471313, 'learning_rate': 4.632203389830509e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [1:44:49<1:25:04,  1.87s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [1:44:51<1:24:58,  1.87s/it]                                                       {'loss': 0.4486, 'grad_norm': 13.76077651977539, 'learning_rate': 4.630508474576272e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [1:44:51<1:24:58,  1.87s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [1:44:53<1:24:54,  1.87s/it]                                                       {'loss': 0.0835, 'grad_norm': 7.285123348236084, 'learning_rate': 4.628813559322034e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [1:44:53<1:24:54,  1.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [1:44:55<1:24:51,  1.86s/it]                                                       {'loss': 0.2025, 'grad_norm': 11.245272636413574, 'learning_rate': 4.627118644067797e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [1:44:55<1:24:51,  1.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [1:44:57<1:25:18,  1.88s/it]                                                       {'loss': 0.0426, 'grad_norm': 4.428213119506836, 'learning_rate': 4.625423728813559e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [1:44:57<1:25:18,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [1:44:59<1:25:42,  1.89s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.7402796149253845, 'learning_rate': 4.623728813559323e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [1:44:59<1:25:42,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [1:45:00<1:26:33,  1.90s/it]                                                       {'loss': 0.0676, 'grad_norm': 3.8504154682159424, 'learning_rate': 4.622033898305085e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [1:45:00<1:26:33,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [1:45:02<1:25:33,  1.88s/it]                                                       {'loss': 0.0369, 'grad_norm': 4.018238067626953, 'learning_rate': 4.6203389830508475e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [1:45:02<1:25:33,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [1:45:04<1:26:46,  1.91s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7323393225669861, 'learning_rate': 4.618644067796611e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [1:45:04<1:26:46,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [1:45:06<1:25:41,  1.89s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2838971018791199, 'learning_rate': 4.616949152542373e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [1:45:06<1:25:41,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [1:45:08<1:24:42,  1.87s/it]                                                       {'loss': 0.1214, 'grad_norm': 7.91292142868042, 'learning_rate': 4.615254237288136e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [1:45:08<1:24:42,  1.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [1:45:10<1:24:10,  1.86s/it]                                                       {'loss': 0.0772, 'grad_norm': 2.41823410987854, 'learning_rate': 4.613559322033899e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [1:45:10<1:24:10,  1.86s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [1:45:12<1:26:16,  1.90s/it]                                                       {'loss': 0.0185, 'grad_norm': 2.086033821105957, 'learning_rate': 4.611864406779661e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [1:45:12<1:26:16,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [1:45:14<1:25:33,  1.89s/it]                                                       {'loss': 0.0289, 'grad_norm': 4.92551851272583, 'learning_rate': 4.610169491525424e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [1:45:14<1:25:33,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [1:45:16<1:25:40,  1.89s/it]                                                       {'loss': 0.0652, 'grad_norm': 4.7180047035217285, 'learning_rate': 4.608474576271187e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [1:45:16<1:25:40,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [1:45:17<1:25:44,  1.89s/it]                                                       {'loss': 0.0406, 'grad_norm': 6.010718822479248, 'learning_rate': 4.6067796610169495e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [1:45:17<1:25:44,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [1:45:19<1:26:00,  1.90s/it]                                                       {'loss': 0.2573, 'grad_norm': 14.157633781433105, 'learning_rate': 4.605084745762713e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [1:45:19<1:26:00,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [1:45:21<1:25:22,  1.89s/it]                                                       {'loss': 0.0297, 'grad_norm': 4.534502029418945, 'learning_rate': 4.603389830508475e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [1:45:21<1:25:22,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [1:45:23<1:24:54,  1.88s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.7192994952201843, 'learning_rate': 4.601694915254238e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [1:45:23<1:24:54,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [1:45:25<1:26:44,  1.92s/it]                                                       {'loss': 0.0219, 'grad_norm': 2.2926108837127686, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [1:45:25<1:26:44,  1.92s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [1:45:27<1:26:59,  1.92s/it]                                                       {'loss': 0.1377, 'grad_norm': 6.449911594390869, 'learning_rate': 4.598305084745763e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [1:45:27<1:26:59,  1.92s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [1:45:29<1:25:59,  1.90s/it]                                                       {'loss': 0.0599, 'grad_norm': 5.735498428344727, 'learning_rate': 4.596610169491526e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [1:45:29<1:25:59,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [1:45:31<1:27:03,  1.93s/it]                                                       {'loss': 0.0717, 'grad_norm': 6.498157024383545, 'learning_rate': 4.594915254237288e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [1:45:31<1:27:03,  1.93s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [1:45:33<1:26:18,  1.91s/it]                                                       {'loss': 0.1213, 'grad_norm': 4.350037574768066, 'learning_rate': 4.5932203389830506e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [1:45:33<1:26:18,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [1:45:35<1:26:38,  1.92s/it]                                                       {'loss': 0.1304, 'grad_norm': 8.53618335723877, 'learning_rate': 4.591525423728814e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [1:45:35<1:26:38,  1.92s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [1:45:37<1:26:20,  1.91s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1418950855731964, 'learning_rate': 4.589830508474576e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [1:45:37<1:26:20,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [1:45:38<1:25:58,  1.91s/it]                                                       {'loss': 0.01, 'grad_norm': 1.5561407804489136, 'learning_rate': 4.5881355932203395e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [1:45:38<1:25:58,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [1:45:40<1:25:45,  1.90s/it]                                                       {'loss': 0.0343, 'grad_norm': 2.204864501953125, 'learning_rate': 4.586440677966102e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [1:45:40<1:25:45,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [1:45:42<1:25:31,  1.90s/it]                                                       {'loss': 0.0231, 'grad_norm': 2.594550848007202, 'learning_rate': 4.584745762711864e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [1:45:42<1:25:31,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [1:45:44<1:25:00,  1.89s/it]                                                       {'loss': 0.0348, 'grad_norm': 3.3633596897125244, 'learning_rate': 4.583050847457628e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [1:45:44<1:25:00,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [1:45:46<1:24:20,  1.87s/it]                                                       {'loss': 0.0151, 'grad_norm': 2.731104612350464, 'learning_rate': 4.58135593220339e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [1:45:46<1:24:20,  1.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [1:45:48<1:25:14,  1.89s/it]                                                       {'loss': 0.0575, 'grad_norm': 5.839365482330322, 'learning_rate': 4.5796610169491525e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [1:45:48<1:25:14,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [1:45:50<1:25:04,  1.89s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3223453760147095, 'learning_rate': 4.577966101694916e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [1:45:50<1:25:04,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [1:45:52<1:25:32,  1.90s/it]                                                       {'loss': 0.1904, 'grad_norm': 9.44039535522461, 'learning_rate': 4.576271186440678e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [1:45:52<1:25:32,  1.90s/it][2025-11-11 23:39:07,594] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3300
[2025-11-11 23:39:07,601] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:39:07,885] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [1:45:54<1:36:00,  2.13s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.12164607644081116, 'learning_rate': 4.5745762711864415e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [1:45:54<1:36:00,  2.13s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [1:45:56<1:31:50,  2.04s/it]                                                       {'loss': 0.1505, 'grad_norm': 7.463842391967773, 'learning_rate': 4.572881355932204e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [1:45:56<1:31:50,  2.04s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [1:45:58<1:29:41,  2.00s/it]                                                       {'loss': 0.1082, 'grad_norm': 6.780543327331543, 'learning_rate': 4.571186440677966e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [1:45:58<1:29:41,  2.00s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [1:46:00<1:27:44,  1.95s/it]                                                       {'loss': 0.0283, 'grad_norm': 3.87077260017395, 'learning_rate': 4.56949152542373e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [1:46:00<1:27:44,  1.95s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [1:46:02<1:26:46,  1.93s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.10105714946985245, 'learning_rate': 4.567796610169492e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [1:46:02<1:26:46,  1.93s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [1:46:04<1:25:56,  1.91s/it]                                                       {'loss': 0.3095, 'grad_norm': 13.662322044372559, 'learning_rate': 4.5661016949152545e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [1:46:04<1:25:56,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [1:46:06<1:25:09,  1.90s/it]                                                       {'loss': 0.154, 'grad_norm': 7.0256733894348145, 'learning_rate': 4.564406779661018e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [1:46:06<1:25:09,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [1:46:07<1:24:25,  1.88s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.6842339038848877, 'learning_rate': 4.56271186440678e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [1:46:07<1:24:25,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [1:46:09<1:24:49,  1.89s/it]                                                       {'loss': 0.005, 'grad_norm': 1.2480159997940063, 'learning_rate': 4.561016949152543e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [1:46:09<1:24:49,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [1:46:11<1:24:38,  1.89s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.2731006145477295, 'learning_rate': 4.559322033898305e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [1:46:11<1:24:38,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [1:46:13<1:24:40,  1.89s/it]                                                       {'loss': 0.1017, 'grad_norm': 4.979398250579834, 'learning_rate': 4.557627118644068e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [1:46:13<1:24:40,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [1:46:15<1:25:15,  1.90s/it]                                                       {'loss': 0.1231, 'grad_norm': 5.686219215393066, 'learning_rate': 4.555932203389831e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [1:46:15<1:25:15,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [1:46:17<1:24:18,  1.88s/it]                                                       {'loss': 0.0959, 'grad_norm': 8.556612014770508, 'learning_rate': 4.554237288135593e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [1:46:17<1:24:18,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [1:46:19<1:25:41,  1.91s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.0607562065124512, 'learning_rate': 4.552542372881356e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [1:46:19<1:25:41,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [1:46:21<1:25:21,  1.91s/it]                                                       {'loss': 0.024, 'grad_norm': 3.164933919906616, 'learning_rate': 4.550847457627119e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [1:46:21<1:25:21,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [1:46:23<1:24:31,  1.89s/it]                                                       {'loss': 0.1089, 'grad_norm': 8.369071006774902, 'learning_rate': 4.549152542372881e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [1:46:23<1:24:31,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [1:46:24<1:23:42,  1.87s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.1318705081939697, 'learning_rate': 4.5474576271186445e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [1:46:24<1:23:42,  1.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [1:46:26<1:23:45,  1.87s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.596951425075531, 'learning_rate': 4.545762711864407e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [1:46:26<1:23:45,  1.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [1:46:28<1:26:36,  1.94s/it]                                                       {'loss': 0.0628, 'grad_norm': 6.267826080322266, 'learning_rate': 4.54406779661017e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [1:46:28<1:26:36,  1.94s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [1:46:30<1:25:35,  1.92s/it]                                                       {'loss': 0.4073, 'grad_norm': 12.45609188079834, 'learning_rate': 4.542372881355933e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [1:46:30<1:25:35,  1.92s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [1:46:32<1:25:16,  1.91s/it]                                                       {'loss': 0.3617, 'grad_norm': 13.711962699890137, 'learning_rate': 4.540677966101695e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [1:46:32<1:25:16,  1.91s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [1:46:34<1:24:46,  1.90s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.964184045791626, 'learning_rate': 4.538983050847458e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [1:46:34<1:24:46,  1.90s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [1:46:36<1:24:20,  1.89s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.1740169525146484, 'learning_rate': 4.537288135593221e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [1:46:36<1:24:20,  1.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [1:46:38<1:23:59,  1.88s/it]                                                       {'loss': 0.0363, 'grad_norm': 5.406764507293701, 'learning_rate': 4.535593220338983e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [1:46:38<1:23:59,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [1:46:40<1:23:59,  1.88s/it]                                                       {'loss': 0.0169, 'grad_norm': 1.3860632181167603, 'learning_rate': 4.5338983050847465e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [1:46:40<1:23:59,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [1:46:41<1:23:51,  1.88s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.5262318849563599, 'learning_rate': 4.532203389830509e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [1:46:41<1:23:51,  1.88s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [1:46:44<1:27:15,  1.96s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.3919174671173096, 'learning_rate': 4.530508474576271e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [1:46:44<1:27:15,  1.96s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [1:46:45<1:25:31,  1.92s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.9537562131881714, 'learning_rate': 4.528813559322035e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [1:46:45<1:25:31,  1.92s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [1:46:47<1:25:18,  1.92s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.4912631511688232, 'learning_rate': 4.527118644067797e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [1:46:47<1:25:18,  1.92s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [1:46:49<1:24:48,  1.91s/it]                                                       {'loss': 0.015, 'grad_norm': 1.2404574155807495, 'learning_rate': 4.52542372881356e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [1:46:49<1:24:48,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [1:46:51<1:24:06,  1.89s/it]                                                       {'loss': 0.0521, 'grad_norm': 5.6993608474731445, 'learning_rate': 4.523728813559322e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [1:46:51<1:24:06,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [1:46:53<1:23:19,  1.87s/it]                                                       {'loss': 0.0294, 'grad_norm': 2.173618793487549, 'learning_rate': 4.522033898305085e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [1:46:53<1:23:19,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [1:46:55<1:23:30,  1.88s/it]                                                       {'loss': 0.0633, 'grad_norm': 3.640061378479004, 'learning_rate': 4.520338983050848e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [1:46:55<1:23:30,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [1:46:57<1:23:08,  1.87s/it]                                                       {'loss': 0.085, 'grad_norm': 7.284539699554443, 'learning_rate': 4.51864406779661e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [1:46:57<1:23:08,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [1:46:59<1:24:32,  1.90s/it]                                                       {'loss': 0.0913, 'grad_norm': 3.432563304901123, 'learning_rate': 4.516949152542373e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [1:46:59<1:24:32,  1.90s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [1:47:01<1:25:31,  1.93s/it]                                                       {'loss': 0.142, 'grad_norm': 8.431173324584961, 'learning_rate': 4.515254237288136e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [1:47:01<1:25:31,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [1:47:03<1:24:51,  1.91s/it]                                                       {'loss': 0.0281, 'grad_norm': 4.1310343742370605, 'learning_rate': 4.513559322033898e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [1:47:03<1:24:51,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [1:47:04<1:23:32,  1.88s/it]                                                       {'loss': 0.0498, 'grad_norm': 5.306405544281006, 'learning_rate': 4.5118644067796614e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [1:47:04<1:23:32,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [1:47:06<1:23:36,  1.89s/it]                                                       {'loss': 0.046, 'grad_norm': 5.700615406036377, 'learning_rate': 4.510169491525424e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [1:47:06<1:23:36,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [1:47:08<1:23:27,  1.88s/it]                                                       {'loss': 0.0552, 'grad_norm': 8.76232624053955, 'learning_rate': 4.508474576271187e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [1:47:08<1:23:27,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [1:47:10<1:22:54,  1.87s/it]                                                       {'loss': 0.0348, 'grad_norm': 3.911322832107544, 'learning_rate': 4.5067796610169496e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [1:47:10<1:22:54,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [1:47:12<1:22:28,  1.86s/it]                                                       {'loss': 0.1462, 'grad_norm': 6.325724124908447, 'learning_rate': 4.505084745762712e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [1:47:12<1:22:28,  1.86s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [1:47:14<1:22:44,  1.87s/it]                                                       {'loss': 0.0714, 'grad_norm': 4.5768513679504395, 'learning_rate': 4.503389830508475e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [1:47:14<1:22:44,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [1:47:16<1:22:41,  1.87s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.9075602293014526, 'learning_rate': 4.501694915254238e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [1:47:16<1:22:41,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [1:47:17<1:22:47,  1.87s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.963614821434021, 'learning_rate': 4.5e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [1:47:17<1:22:47,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [1:47:19<1:24:17,  1.91s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.1106661558151245, 'learning_rate': 4.498305084745763e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [1:47:19<1:24:17,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [1:47:21<1:25:37,  1.94s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.14151467382907867, 'learning_rate': 4.496610169491526e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [1:47:21<1:25:37,  1.94s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [1:47:23<1:25:00,  1.92s/it]                                                       {'loss': 0.1286, 'grad_norm': 6.003974914550781, 'learning_rate': 4.494915254237289e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [1:47:23<1:25:00,  1.92s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [1:47:25<1:24:08,  1.90s/it]                                                       {'loss': 0.2895, 'grad_norm': 10.116804122924805, 'learning_rate': 4.4932203389830515e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [1:47:25<1:24:08,  1.90s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [1:47:27<1:24:03,  1.90s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.13859596848487854, 'learning_rate': 4.491525423728814e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [1:47:27<1:24:03,  1.90s/it][2025-11-11 23:40:42,986] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3350
[2025-11-11 23:40:42,993] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:40:43,265] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3350/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [1:47:30<1:35:08,  2.15s/it]                                                       {'loss': 0.0266, 'grad_norm': 3.2729344367980957, 'learning_rate': 4.489830508474577e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [1:47:30<1:35:08,  2.15s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [1:47:32<1:31:45,  2.08s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.6551296710968018, 'learning_rate': 4.488135593220339e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [1:47:32<1:31:45,  2.08s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [1:47:34<1:29:25,  2.03s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5957320928573608, 'learning_rate': 4.486440677966102e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [1:47:34<1:29:25,  2.03s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [1:47:35<1:26:58,  1.97s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.623636782169342, 'learning_rate': 4.4847457627118645e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [1:47:35<1:26:58,  1.97s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [1:47:37<1:25:31,  1.94s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.8108440041542053, 'learning_rate': 4.483050847457627e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [1:47:37<1:25:31,  1.94s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [1:47:39<1:24:49,  1.92s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.378261923789978, 'learning_rate': 4.48135593220339e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [1:47:39<1:24:49,  1.92s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [1:47:41<1:25:59,  1.95s/it]                                                       {'loss': 0.0824, 'grad_norm': 6.713559627532959, 'learning_rate': 4.479661016949153e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [1:47:41<1:25:59,  1.95s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [1:47:43<1:25:18,  1.94s/it]                                                       {'loss': 0.1014, 'grad_norm': 10.845351219177246, 'learning_rate': 4.477966101694916e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [1:47:43<1:25:18,  1.94s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [1:47:45<1:25:04,  1.93s/it]                                                       {'loss': 0.0842, 'grad_norm': 6.220871925354004, 'learning_rate': 4.476271186440678e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [1:47:45<1:25:04,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [1:47:47<1:24:55,  1.93s/it]                                                       {'loss': 0.0505, 'grad_norm': 6.764194011688232, 'learning_rate': 4.474576271186441e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [1:47:47<1:24:55,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [1:47:49<1:25:45,  1.95s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.2993123531341553, 'learning_rate': 4.472881355932204e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [1:47:49<1:25:45,  1.95s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [1:47:51<1:24:09,  1.91s/it]                                                       {'loss': 0.0582, 'grad_norm': 3.1201817989349365, 'learning_rate': 4.4711864406779664e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [1:47:51<1:24:09,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [1:47:53<1:23:43,  1.91s/it]                                                       {'loss': 0.1379, 'grad_norm': 7.784250736236572, 'learning_rate': 4.469491525423729e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [1:47:53<1:23:43,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [1:47:55<1:22:56,  1.89s/it]                                                       {'loss': 0.2251, 'grad_norm': 9.507505416870117, 'learning_rate': 4.467796610169492e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [1:47:55<1:22:56,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [1:47:56<1:23:00,  1.89s/it]                                                       {'loss': 0.2145, 'grad_norm': 11.62929630279541, 'learning_rate': 4.4661016949152546e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [1:47:56<1:23:00,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [1:47:58<1:22:41,  1.88s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.12717387080192566, 'learning_rate': 4.464406779661018e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [1:47:58<1:22:41,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [1:48:00<1:22:43,  1.89s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.9394034147262573, 'learning_rate': 4.46271186440678e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [1:48:00<1:22:43,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [1:48:02<1:22:28,  1.88s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5773623585700989, 'learning_rate': 4.461016949152543e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [1:48:02<1:22:28,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [1:48:04<1:21:48,  1.87s/it]                                                       {'loss': 0.127, 'grad_norm': 8.565418243408203, 'learning_rate': 4.459322033898306e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [1:48:04<1:21:48,  1.87s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [1:48:06<1:22:40,  1.89s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.2624759674072266, 'learning_rate': 4.457627118644068e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [1:48:06<1:22:40,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [1:48:08<1:29:27,  2.04s/it]                                                       {'loss': 0.1133, 'grad_norm': 7.011075496673584, 'learning_rate': 4.455932203389831e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [1:48:08<1:29:27,  2.04s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [1:48:10<1:27:26,  2.00s/it]                                                       {'loss': 0.0887, 'grad_norm': 4.595667839050293, 'learning_rate': 4.454237288135594e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [1:48:10<1:27:26,  2.00s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [1:48:12<1:25:48,  1.96s/it]                                                       {'loss': 0.0647, 'grad_norm': 3.467036247253418, 'learning_rate': 4.452542372881356e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [1:48:12<1:25:48,  1.96s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [1:48:14<1:24:09,  1.92s/it]                                                       {'loss': 0.0637, 'grad_norm': 8.629962921142578, 'learning_rate': 4.450847457627119e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [1:48:14<1:24:09,  1.92s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [1:48:16<1:24:25,  1.93s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.8882999420166016, 'learning_rate': 4.449152542372881e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [1:48:16<1:24:25,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [1:48:18<1:23:34,  1.91s/it]                                                       {'loss': 0.006, 'grad_norm': 0.6347520351409912, 'learning_rate': 4.447457627118645e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [1:48:18<1:23:34,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [1:48:20<1:23:36,  1.91s/it]                                                       {'loss': 0.0303, 'grad_norm': 3.861579656600952, 'learning_rate': 4.445762711864407e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [1:48:20<1:23:36,  1.91s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [1:48:22<1:26:00,  1.97s/it]                                                       {'loss': 0.029, 'grad_norm': 2.694460153579712, 'learning_rate': 4.4440677966101695e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [1:48:22<1:26:00,  1.97s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [1:48:23<1:24:12,  1.93s/it]                                                       {'loss': 0.1455, 'grad_norm': 7.536661148071289, 'learning_rate': 4.442372881355933e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [1:48:23<1:24:12,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [1:48:25<1:23:02,  1.90s/it]                                                       {'loss': 0.1322, 'grad_norm': 7.196535587310791, 'learning_rate': 4.440677966101695e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [1:48:25<1:23:02,  1.90s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [1:48:27<1:22:47,  1.90s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.7917695045471191, 'learning_rate': 4.438983050847458e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [1:48:27<1:22:47,  1.90s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [1:48:29<1:26:16,  1.98s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.6769975423812866, 'learning_rate': 4.437288135593221e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [1:48:29<1:26:16,  1.98s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [1:48:31<1:24:53,  1.95s/it]                                                       {'loss': 0.239, 'grad_norm': 10.706076622009277, 'learning_rate': 4.435593220338983e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [1:48:31<1:24:53,  1.95s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [1:48:33<1:23:45,  1.92s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2049371749162674, 'learning_rate': 4.433898305084746e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [1:48:33<1:23:45,  1.92s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [1:48:35<1:23:53,  1.92s/it]                                                       {'loss': 0.0347, 'grad_norm': 5.244629859924316, 'learning_rate': 4.432203389830509e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [1:48:35<1:23:53,  1.92s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [1:48:37<1:22:45,  1.90s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.7771183252334595, 'learning_rate': 4.4305084745762715e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [1:48:37<1:22:45,  1.90s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [1:48:39<1:22:35,  1.90s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.0871196985244751, 'learning_rate': 4.428813559322035e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [1:48:39<1:22:35,  1.90s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [1:48:41<1:22:07,  1.89s/it]                                                       {'loss': 0.2538, 'grad_norm': 8.984975814819336, 'learning_rate': 4.427118644067797e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [1:48:41<1:22:07,  1.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [1:48:43<1:21:48,  1.88s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5657405853271484, 'learning_rate': 4.42542372881356e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [1:48:43<1:21:48,  1.88s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [1:48:44<1:21:41,  1.88s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.15402747690677643, 'learning_rate': 4.423728813559323e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [1:48:44<1:21:41,  1.88s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [1:48:46<1:23:05,  1.91s/it]                                                       {'loss': 0.1991, 'grad_norm': 10.339404106140137, 'learning_rate': 4.422033898305085e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [1:48:46<1:23:05,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [1:48:48<1:23:30,  1.92s/it]                                                       {'loss': 0.1628, 'grad_norm': 8.724650382995605, 'learning_rate': 4.420338983050848e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [1:48:48<1:23:30,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [1:48:50<1:23:07,  1.91s/it]                                                       {'loss': 0.0271, 'grad_norm': 2.1642508506774902, 'learning_rate': 4.41864406779661e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [1:48:50<1:23:07,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [1:48:52<1:22:04,  1.89s/it]                                                       {'loss': 0.009, 'grad_norm': 1.5284324884414673, 'learning_rate': 4.416949152542373e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [1:48:52<1:22:04,  1.89s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [1:48:54<1:26:09,  1.98s/it]                                                       {'loss': 0.0451, 'grad_norm': 1.152642011642456, 'learning_rate': 4.415254237288136e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [1:48:54<1:26:09,  1.98s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [1:48:56<1:25:08,  1.96s/it]                                                       {'loss': 0.0727, 'grad_norm': 6.944561958312988, 'learning_rate': 4.413559322033898e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [1:48:56<1:25:08,  1.96s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [1:48:58<1:23:54,  1.93s/it]                                                       {'loss': 0.1632, 'grad_norm': 9.086236000061035, 'learning_rate': 4.4118644067796615e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [1:48:58<1:23:54,  1.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [1:49:00<1:23:15,  1.92s/it]                                                       {'loss': 0.0882, 'grad_norm': 8.656047821044922, 'learning_rate': 4.410169491525424e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [1:49:00<1:23:15,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [1:49:02<1:22:58,  1.91s/it]                                                       {'loss': 0.0754, 'grad_norm': 6.142855644226074, 'learning_rate': 4.408474576271186e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [1:49:02<1:22:58,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [1:49:04<1:24:04,  1.94s/it]                                                       {'loss': 0.0391, 'grad_norm': 6.263513088226318, 'learning_rate': 4.40677966101695e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [1:49:04<1:24:04,  1.94s/it][2025-11-11 23:42:19,738] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3400
[2025-11-11 23:42:19,744] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:42:20,039] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [1:49:07<1:36:05,  2.22s/it]                                                       {'loss': 0.2048, 'grad_norm': 10.129745483398438, 'learning_rate': 4.405084745762712e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [1:49:07<1:36:05,  2.22s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [1:49:09<1:31:47,  2.12s/it]                                                       {'loss': 0.0615, 'grad_norm': 6.454185485839844, 'learning_rate': 4.4033898305084745e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [1:49:09<1:31:47,  2.12s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [1:49:10<1:28:05,  2.04s/it]                                                       {'loss': 0.073, 'grad_norm': 7.497313976287842, 'learning_rate': 4.401694915254238e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [1:49:10<1:28:05,  2.04s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [1:49:12<1:26:15,  1.99s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.026050163432955742, 'learning_rate': 4.4e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [1:49:12<1:26:15,  1.99s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [1:49:14<1:24:24,  1.95s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.25236591696739197, 'learning_rate': 4.3983050847457635e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [1:49:14<1:24:24,  1.95s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [1:49:16<1:22:56,  1.92s/it]                                                       {'loss': 0.0342, 'grad_norm': 4.152338981628418, 'learning_rate': 4.396610169491526e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [1:49:16<1:22:56,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [1:49:18<1:22:57,  1.92s/it]                                                       {'loss': 0.1606, 'grad_norm': 6.862827777862549, 'learning_rate': 4.394915254237288e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [1:49:18<1:22:57,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [1:49:20<1:27:33,  2.03s/it]                                                       {'loss': 0.0604, 'grad_norm': 6.296872615814209, 'learning_rate': 4.393220338983052e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [1:49:20<1:27:33,  2.03s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [1:49:22<1:25:53,  1.99s/it]                                                       {'loss': 0.1953, 'grad_norm': 10.858482360839844, 'learning_rate': 4.391525423728814e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [1:49:22<1:25:53,  1.99s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [1:49:24<1:24:11,  1.95s/it]                                                       {'loss': 0.0256, 'grad_norm': 4.138322830200195, 'learning_rate': 4.3898305084745765e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [1:49:24<1:24:11,  1.95s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [1:49:26<1:23:13,  1.93s/it]                                                       {'loss': 0.0565, 'grad_norm': 5.090572357177734, 'learning_rate': 4.38813559322034e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [1:49:26<1:23:13,  1.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [1:49:28<1:23:04,  1.93s/it]                                                       {'loss': 0.099, 'grad_norm': 5.479979038238525, 'learning_rate': 4.386440677966102e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [1:49:28<1:23:04,  1.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [1:49:30<1:22:22,  1.91s/it]                                                       {'loss': 0.0914, 'grad_norm': 8.915407180786133, 'learning_rate': 4.384745762711865e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [1:49:30<1:22:22,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [1:49:32<1:22:06,  1.90s/it]                                                       {'loss': 0.1057, 'grad_norm': 8.566376686096191, 'learning_rate': 4.383050847457627e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [1:49:32<1:22:06,  1.90s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [1:49:33<1:22:32,  1.92s/it]                                                       {'loss': 0.0524, 'grad_norm': 4.231132507324219, 'learning_rate': 4.38135593220339e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [1:49:33<1:22:32,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [1:49:35<1:22:23,  1.91s/it]                                                       {'loss': 0.1482, 'grad_norm': 9.33790397644043, 'learning_rate': 4.379661016949153e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [1:49:35<1:22:23,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [1:49:37<1:22:34,  1.92s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.921118974685669, 'learning_rate': 4.377966101694915e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [1:49:37<1:22:34,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [1:49:39<1:22:26,  1.92s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.39961251616477966, 'learning_rate': 4.3762711864406784e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [1:49:39<1:22:26,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [1:49:41<1:22:24,  1.92s/it]                                                       {'loss': 0.023, 'grad_norm': 4.51468563079834, 'learning_rate': 4.374576271186441e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [1:49:41<1:22:24,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [1:49:43<1:22:01,  1.91s/it]                                                       {'loss': 0.0635, 'grad_norm': 7.716395854949951, 'learning_rate': 4.372881355932203e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [1:49:43<1:22:01,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [1:49:45<1:22:55,  1.93s/it]                                                       {'loss': 0.0962, 'grad_norm': 7.076475620269775, 'learning_rate': 4.3711864406779666e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [1:49:45<1:22:55,  1.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [1:49:47<1:22:35,  1.92s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.7716642618179321, 'learning_rate': 4.369491525423729e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [1:49:47<1:22:35,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [1:49:49<1:24:31,  1.97s/it]                                                       {'loss': 0.3283, 'grad_norm': 8.88825511932373, 'learning_rate': 4.367796610169492e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [1:49:49<1:24:31,  1.97s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [1:49:51<1:24:19,  1.96s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3765416145324707, 'learning_rate': 4.366101694915255e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [1:49:51<1:24:19,  1.96s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [1:49:53<1:23:08,  1.94s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.16002726554870605, 'learning_rate': 4.364406779661017e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [1:49:53<1:23:08,  1.94s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [1:49:55<1:22:39,  1.93s/it]                                                       {'loss': 0.196, 'grad_norm': 9.943894386291504, 'learning_rate': 4.36271186440678e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [1:49:55<1:22:39,  1.93s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [1:49:57<1:22:16,  1.92s/it]                                                       {'loss': 0.0216, 'grad_norm': 1.3183717727661133, 'learning_rate': 4.361016949152543e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [1:49:57<1:22:16,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [1:49:59<1:21:54,  1.91s/it]                                                       {'loss': 0.1393, 'grad_norm': 8.818288803100586, 'learning_rate': 4.359322033898305e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [1:49:59<1:21:54,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [1:50:00<1:21:27,  1.90s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.9536244869232178, 'learning_rate': 4.3576271186440685e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [1:50:00<1:21:27,  1.90s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [1:50:02<1:20:33,  1.88s/it]                                                       {'loss': 0.2397, 'grad_norm': 10.267596244812012, 'learning_rate': 4.355932203389831e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [1:50:02<1:20:33,  1.88s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [1:50:04<1:21:40,  1.91s/it]                                                       {'loss': 0.0447, 'grad_norm': 4.88086462020874, 'learning_rate': 4.354237288135593e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [1:50:04<1:21:40,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [1:50:06<1:21:35,  1.91s/it]                                                       {'loss': 0.0842, 'grad_norm': 4.54701566696167, 'learning_rate': 4.352542372881357e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [1:50:06<1:21:35,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [1:50:08<1:22:03,  1.92s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.4163697957992554, 'learning_rate': 4.350847457627119e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [1:50:08<1:22:03,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [1:50:10<1:21:25,  1.90s/it]                                                       {'loss': 0.0367, 'grad_norm': 5.418718338012695, 'learning_rate': 4.349152542372882e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [1:50:10<1:21:25,  1.90s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [1:50:12<1:23:19,  1.95s/it]                                                       {'loss': 0.0319, 'grad_norm': 4.179945468902588, 'learning_rate': 4.347457627118644e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [1:50:12<1:23:19,  1.95s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [1:50:14<1:22:43,  1.94s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4106273353099823, 'learning_rate': 4.345762711864407e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [1:50:14<1:22:43,  1.94s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [1:50:16<1:24:22,  1.98s/it]                                                       {'loss': 0.0341, 'grad_norm': 3.233707904815674, 'learning_rate': 4.34406779661017e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [1:50:16<1:24:22,  1.98s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [1:50:18<1:23:32,  1.96s/it]                                                       {'loss': 0.008, 'grad_norm': 1.759095311164856, 'learning_rate': 4.342372881355932e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [1:50:18<1:23:32,  1.96s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [1:50:20<1:24:59,  1.99s/it]                                                       {'loss': 0.0775, 'grad_norm': 6.426742076873779, 'learning_rate': 4.340677966101695e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [1:50:20<1:24:59,  1.99s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [1:50:22<1:23:33,  1.96s/it]                                                       {'loss': 0.1361, 'grad_norm': 8.190625190734863, 'learning_rate': 4.338983050847458e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [1:50:22<1:23:33,  1.96s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [1:50:24<1:22:41,  1.94s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.4615887701511383, 'learning_rate': 4.33728813559322e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [1:50:24<1:22:41,  1.94s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [1:50:26<1:21:52,  1.92s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4568374752998352, 'learning_rate': 4.3355932203389834e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [1:50:26<1:21:52,  1.92s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [1:50:27<1:21:25,  1.91s/it]                                                       {'loss': 0.0178, 'grad_norm': 2.261345624923706, 'learning_rate': 4.333898305084746e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [1:50:27<1:21:25,  1.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [1:50:29<1:20:44,  1.90s/it]                                                       {'loss': 0.1041, 'grad_norm': 7.605556964874268, 'learning_rate': 4.332203389830509e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [1:50:29<1:20:44,  1.90s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [1:50:31<1:19:50,  1.87s/it]                                                       {'loss': 0.0363, 'grad_norm': 4.143406867980957, 'learning_rate': 4.3305084745762716e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [1:50:31<1:19:50,  1.87s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [1:50:33<1:20:49,  1.90s/it]                                                       {'loss': 0.0251, 'grad_norm': 2.830552816390991, 'learning_rate': 4.328813559322034e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [1:50:33<1:20:49,  1.90s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [1:50:35<1:20:22,  1.89s/it]                                                       {'loss': 0.0549, 'grad_norm': 2.155606269836426, 'learning_rate': 4.327118644067797e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [1:50:35<1:20:22,  1.89s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [1:50:37<1:20:11,  1.89s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.673598527908325, 'learning_rate': 4.32542372881356e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [1:50:37<1:20:11,  1.89s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [1:50:39<1:20:01,  1.88s/it]                                                       {'loss': 0.0573, 'grad_norm': 4.676086902618408, 'learning_rate': 4.323728813559322e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [1:50:39<1:20:01,  1.88s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [1:50:41<1:21:30,  1.92s/it]                                                       {'loss': 0.0707, 'grad_norm': 10.039043426513672, 'learning_rate': 4.322033898305085e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [1:50:41<1:21:30,  1.92s/it][2025-11-11 23:43:56,640] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3450
[2025-11-11 23:43:56,647] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:43:56,926] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3450/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [1:50:43<1:31:15,  2.15s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.29768115282058716, 'learning_rate': 4.320338983050848e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [1:50:43<1:31:15,  2.15s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [1:50:45<1:29:21,  2.10s/it]                                                       {'loss': 0.0306, 'grad_norm': 5.254209041595459, 'learning_rate': 4.318644067796611e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [1:50:45<1:29:21,  2.10s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [1:50:47<1:26:44,  2.04s/it]                                                       {'loss': 0.1514, 'grad_norm': 6.464588642120361, 'learning_rate': 4.3169491525423735e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [1:50:47<1:26:44,  2.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [1:50:49<1:24:31,  1.99s/it]                                                       {'loss': 0.0321, 'grad_norm': 4.344780445098877, 'learning_rate': 4.315254237288136e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [1:50:49<1:24:31,  1.99s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [1:50:51<1:24:48,  2.00s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.061950311064720154, 'learning_rate': 4.313559322033899e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [1:50:51<1:24:48,  2.00s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [1:50:53<1:23:27,  1.97s/it]                                                       {'loss': 0.001, 'grad_norm': 0.21175329387187958, 'learning_rate': 4.311864406779661e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [1:50:53<1:23:27,  1.97s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [1:50:55<1:22:01,  1.94s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.15731985867023468, 'learning_rate': 4.310169491525424e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [1:50:55<1:22:01,  1.94s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [1:50:57<1:20:41,  1.90s/it]                                                       {'loss': 0.018, 'grad_norm': 3.608360767364502, 'learning_rate': 4.3084745762711865e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [1:50:57<1:20:41,  1.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [1:50:59<1:20:17,  1.90s/it]                                                       {'loss': 0.0372, 'grad_norm': 3.645587682723999, 'learning_rate': 4.306779661016949e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [1:50:59<1:20:17,  1.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [1:51:01<1:19:35,  1.88s/it]                                                       {'loss': 0.0468, 'grad_norm': 7.349947452545166, 'learning_rate': 4.305084745762712e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [1:51:01<1:19:35,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [1:51:02<1:19:23,  1.88s/it]                                                       {'loss': 0.2917, 'grad_norm': 11.011048316955566, 'learning_rate': 4.303389830508475e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [1:51:02<1:19:23,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [1:51:04<1:18:59,  1.87s/it]                                                       {'loss': 0.0224, 'grad_norm': 4.250320911407471, 'learning_rate': 4.301694915254238e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [1:51:04<1:18:59,  1.87s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [1:51:06<1:19:26,  1.88s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.697021007537842, 'learning_rate': 4.3e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [1:51:06<1:19:26,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [1:51:08<1:19:43,  1.89s/it]                                                       {'loss': 0.0336, 'grad_norm': 3.9486241340637207, 'learning_rate': 4.298305084745763e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [1:51:08<1:19:43,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [1:51:10<1:19:24,  1.88s/it]                                                       {'loss': 0.0167, 'grad_norm': 3.371065855026245, 'learning_rate': 4.296610169491526e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [1:51:10<1:19:24,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [1:51:12<1:19:23,  1.88s/it]                                                       {'loss': 0.0312, 'grad_norm': 4.781872749328613, 'learning_rate': 4.2949152542372885e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [1:51:12<1:19:23,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [1:51:14<1:18:43,  1.86s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.9956486225128174, 'learning_rate': 4.293220338983051e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [1:51:14<1:18:43,  1.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [1:51:16<1:19:43,  1.89s/it]                                                       {'loss': 0.0293, 'grad_norm': 5.3416948318481445, 'learning_rate': 4.291525423728814e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [1:51:16<1:19:43,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [1:51:18<1:21:15,  1.93s/it]                                                       {'loss': 0.1963, 'grad_norm': 10.754149436950684, 'learning_rate': 4.289830508474577e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [1:51:18<1:21:15,  1.93s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [1:51:19<1:20:53,  1.92s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.9195266962051392, 'learning_rate': 4.28813559322034e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [1:51:19<1:20:53,  1.92s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [1:51:21<1:19:55,  1.90s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.17803062498569489, 'learning_rate': 4.286440677966102e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [1:51:21<1:19:55,  1.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [1:51:23<1:19:11,  1.88s/it]                                                       {'loss': 0.0248, 'grad_norm': 3.150163173675537, 'learning_rate': 4.284745762711865e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [1:51:23<1:19:11,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [1:51:25<1:19:11,  1.88s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.24157901108264923, 'learning_rate': 4.283050847457628e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [1:51:25<1:19:11,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [1:51:27<1:19:31,  1.89s/it]                                                       {'loss': 0.0198, 'grad_norm': 1.7336500883102417, 'learning_rate': 4.28135593220339e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [1:51:27<1:19:31,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [1:51:29<1:19:21,  1.89s/it]                                                       {'loss': 0.0681, 'grad_norm': 5.583244800567627, 'learning_rate': 4.279661016949153e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [1:51:29<1:19:21,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [1:51:31<1:19:14,  1.88s/it]                                                       {'loss': 0.0113, 'grad_norm': 2.0751593112945557, 'learning_rate': 4.277966101694915e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [1:51:31<1:19:14,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [1:51:33<1:19:54,  1.90s/it]                                                       {'loss': 0.0892, 'grad_norm': 6.961008548736572, 'learning_rate': 4.276271186440678e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [1:51:33<1:19:54,  1.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [1:51:35<1:19:29,  1.89s/it]                                                       {'loss': 0.0284, 'grad_norm': 4.4836201667785645, 'learning_rate': 4.274576271186441e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [1:51:35<1:19:29,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [1:51:36<1:19:34,  1.89s/it]                                                       {'loss': 0.0209, 'grad_norm': 3.00754451751709, 'learning_rate': 4.272881355932203e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [1:51:36<1:19:34,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [1:51:38<1:20:21,  1.91s/it]                                                       {'loss': 0.322, 'grad_norm': 10.52892780303955, 'learning_rate': 4.271186440677967e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [1:51:38<1:20:21,  1.91s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [1:51:40<1:19:25,  1.89s/it]                                                       {'loss': 0.0474, 'grad_norm': 4.245447635650635, 'learning_rate': 4.269491525423729e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [1:51:40<1:19:25,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [1:51:42<1:19:11,  1.89s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.4055014848709106, 'learning_rate': 4.2677966101694915e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [1:51:42<1:19:11,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [1:51:44<1:18:53,  1.88s/it]                                                       {'loss': 0.0195, 'grad_norm': 3.224717855453491, 'learning_rate': 4.266101694915255e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [1:51:44<1:18:53,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [1:51:46<1:20:40,  1.92s/it]                                                       {'loss': 0.0501, 'grad_norm': 5.87125301361084, 'learning_rate': 4.264406779661017e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [1:51:46<1:20:40,  1.92s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [1:51:48<1:20:58,  1.93s/it]                                                       {'loss': 0.0151, 'grad_norm': 1.5337588787078857, 'learning_rate': 4.26271186440678e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [1:51:48<1:20:58,  1.93s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [1:51:50<1:20:01,  1.91s/it]                                                       {'loss': 0.0639, 'grad_norm': 6.071427822113037, 'learning_rate': 4.261016949152543e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [1:51:50<1:20:01,  1.91s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [1:51:52<1:19:51,  1.91s/it]                                                       {'loss': 0.0794, 'grad_norm': 7.651951313018799, 'learning_rate': 4.259322033898305e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [1:51:52<1:19:51,  1.91s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [1:51:54<1:19:52,  1.91s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.6297590732574463, 'learning_rate': 4.257627118644068e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [1:51:54<1:19:52,  1.91s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [1:51:55<1:18:53,  1.89s/it]                                                       {'loss': 0.0862, 'grad_norm': 8.644125938415527, 'learning_rate': 4.255932203389831e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [1:51:55<1:18:53,  1.89s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [1:51:57<1:18:15,  1.87s/it]                                                       {'loss': 0.1024, 'grad_norm': 3.5057666301727295, 'learning_rate': 4.2542372881355935e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [1:51:57<1:18:15,  1.87s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [1:51:59<1:17:44,  1.86s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.6818625330924988, 'learning_rate': 4.252542372881357e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [1:51:59<1:17:44,  1.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [1:52:01<1:17:51,  1.86s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.077424168586731, 'learning_rate': 4.250847457627119e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [1:52:01<1:17:51,  1.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [1:52:03<1:17:50,  1.86s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.4990822076797485, 'learning_rate': 4.249152542372882e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [1:52:03<1:17:50,  1.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [1:52:05<1:17:32,  1.86s/it]                                                       {'loss': 0.0411, 'grad_norm': 4.633686542510986, 'learning_rate': 4.247457627118645e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [1:52:05<1:17:32,  1.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [1:52:07<1:17:59,  1.87s/it]                                                       {'loss': 0.0635, 'grad_norm': 6.8551177978515625, 'learning_rate': 4.245762711864407e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [1:52:07<1:17:59,  1.87s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [1:52:08<1:17:52,  1.87s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.340435266494751, 'learning_rate': 4.24406779661017e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [1:52:08<1:17:52,  1.87s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [1:52:10<1:17:25,  1.86s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.8988473415374756, 'learning_rate': 4.242372881355932e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [1:52:10<1:17:25,  1.86s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [1:52:12<1:19:05,  1.90s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.7432093620300293, 'learning_rate': 4.2406779661016954e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [1:52:12<1:19:05,  1.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [1:52:14<1:19:33,  1.91s/it]                                                       {'loss': 0.1342, 'grad_norm': 9.773554801940918, 'learning_rate': 4.238983050847458e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [1:52:14<1:19:33,  1.91s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [1:52:16<1:19:33,  1.91s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.47436049580574036, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [1:52:16<1:19:33,  1.91s/it][2025-11-11 23:45:32,014] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3500
[2025-11-11 23:45:32,021] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:45:32,297] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [1:52:19<1:29:18,  2.14s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.5773289203643799, 'learning_rate': 4.2355932203389836e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [1:52:19<1:29:18,  2.14s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [1:52:21<1:25:42,  2.06s/it]                                                       {'loss': 0.0843, 'grad_norm': 9.163606643676758, 'learning_rate': 4.233898305084746e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [1:52:21<1:25:42,  2.06s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [1:52:23<1:23:27,  2.01s/it]                                                       {'loss': 0.0298, 'grad_norm': 3.1462700366973877, 'learning_rate': 4.232203389830508e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [1:52:23<1:23:27,  2.01s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [1:52:24<1:21:33,  1.96s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.6813287734985352, 'learning_rate': 4.230508474576272e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [1:52:24<1:21:33,  1.96s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [1:52:26<1:20:41,  1.94s/it]                                                       {'loss': 0.1679, 'grad_norm': 8.879709243774414, 'learning_rate': 4.228813559322034e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [1:52:26<1:20:41,  1.94s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [1:52:28<1:20:18,  1.93s/it]                                                       {'loss': 0.0247, 'grad_norm': 3.1705446243286133, 'learning_rate': 4.2271186440677965e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [1:52:28<1:20:18,  1.93s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [1:52:30<1:19:45,  1.92s/it]                                                       {'loss': 0.0572, 'grad_norm': 3.0038344860076904, 'learning_rate': 4.22542372881356e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [1:52:30<1:19:45,  1.92s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [1:52:32<1:19:07,  1.90s/it]                                                       {'loss': 0.051, 'grad_norm': 1.9551273584365845, 'learning_rate': 4.223728813559322e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [1:52:32<1:19:07,  1.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [1:52:34<1:18:04,  1.88s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.40150800347328186, 'learning_rate': 4.2220338983050855e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [1:52:34<1:18:04,  1.88s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [1:52:36<1:20:30,  1.94s/it]                                                       {'loss': 0.0327, 'grad_norm': 6.08506441116333, 'learning_rate': 4.220338983050848e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [1:52:36<1:20:30,  1.94s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [1:52:38<1:20:37,  1.94s/it]                                                       {'loss': 0.046, 'grad_norm': 4.115272045135498, 'learning_rate': 4.21864406779661e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [1:52:38<1:20:37,  1.94s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [1:52:40<1:19:52,  1.93s/it]                                                       {'loss': 0.0285, 'grad_norm': 2.6762633323669434, 'learning_rate': 4.216949152542374e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [1:52:40<1:19:52,  1.93s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [1:52:42<1:19:41,  1.92s/it]                                                       {'loss': 0.1897, 'grad_norm': 9.888946533203125, 'learning_rate': 4.215254237288136e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [1:52:42<1:19:41,  1.92s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [1:52:44<1:19:54,  1.93s/it]                                                       {'loss': 0.0232, 'grad_norm': 4.0451483726501465, 'learning_rate': 4.2135593220338985e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [1:52:44<1:19:54,  1.93s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [1:52:45<1:19:13,  1.91s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.2276113033294678, 'learning_rate': 4.211864406779662e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [1:52:45<1:19:13,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [1:52:47<1:18:42,  1.90s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.9993042945861816, 'learning_rate': 4.210169491525424e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [1:52:47<1:18:42,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [1:52:49<1:19:05,  1.91s/it]                                                       {'loss': 0.0641, 'grad_norm': 7.4813337326049805, 'learning_rate': 4.2084745762711875e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [1:52:49<1:19:05,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [1:52:51<1:18:14,  1.89s/it]                                                       {'loss': 0.4989, 'grad_norm': 11.085952758789062, 'learning_rate': 4.206779661016949e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [1:52:51<1:18:14,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [1:52:53<1:18:36,  1.90s/it]                                                       {'loss': 0.2365, 'grad_norm': 8.010351181030273, 'learning_rate': 4.205084745762712e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [1:52:53<1:18:36,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [1:52:55<1:18:55,  1.91s/it]                                                       {'loss': 0.1174, 'grad_norm': 7.691112995147705, 'learning_rate': 4.203389830508475e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [1:52:55<1:18:55,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [1:52:57<1:18:31,  1.90s/it]                                                       {'loss': 0.2226, 'grad_norm': 7.114292144775391, 'learning_rate': 4.201694915254237e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [1:52:57<1:18:31,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [1:52:59<1:22:14,  1.99s/it]                                                       {'loss': 0.007, 'grad_norm': 0.4965559244155884, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [1:52:59<1:22:14,  1.99s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [1:53:01<1:20:23,  1.95s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.10067220032215118, 'learning_rate': 4.198305084745763e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [1:53:01<1:20:23,  1.95s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [1:53:03<1:19:33,  1.93s/it]                                                       {'loss': 0.0481, 'grad_norm': 3.0488173961639404, 'learning_rate': 4.196610169491525e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [1:53:03<1:19:33,  1.93s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [1:53:05<1:18:56,  1.91s/it]                                                       {'loss': 0.1425, 'grad_norm': 7.517323017120361, 'learning_rate': 4.1949152542372886e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [1:53:05<1:18:56,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [1:53:07<1:18:36,  1.91s/it]                                                       {'loss': 0.2204, 'grad_norm': 9.661920547485352, 'learning_rate': 4.193220338983051e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [1:53:07<1:18:36,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [1:53:08<1:17:56,  1.89s/it]                                                       {'loss': 0.032, 'grad_norm': 2.000462293624878, 'learning_rate': 4.191525423728814e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [1:53:08<1:17:56,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [1:53:10<1:17:21,  1.88s/it]                                                       {'loss': 0.0526, 'grad_norm': 3.31801438331604, 'learning_rate': 4.189830508474577e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [1:53:10<1:17:21,  1.88s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [1:53:12<1:18:07,  1.90s/it]                                                       {'loss': 0.0462, 'grad_norm': 3.019333600997925, 'learning_rate': 4.188135593220339e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [1:53:12<1:18:07,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [1:53:14<1:17:33,  1.88s/it]                                                       {'loss': 0.1064, 'grad_norm': 10.323616027832031, 'learning_rate': 4.186440677966102e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [1:53:14<1:17:33,  1.88s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [1:53:16<1:17:20,  1.88s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.6741372346878052, 'learning_rate': 4.184745762711865e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [1:53:16<1:17:20,  1.88s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [1:53:18<1:16:41,  1.86s/it]                                                       {'loss': 0.0448, 'grad_norm': 3.3800885677337646, 'learning_rate': 4.183050847457627e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [1:53:18<1:16:41,  1.86s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [1:53:20<1:17:03,  1.87s/it]                                                       {'loss': 0.0505, 'grad_norm': 6.08879280090332, 'learning_rate': 4.1813559322033905e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [1:53:20<1:17:03,  1.87s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [1:53:22<1:17:34,  1.89s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.648274302482605, 'learning_rate': 4.179661016949153e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [1:53:22<1:17:34,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [1:53:23<1:17:44,  1.89s/it]                                                       {'loss': 0.0577, 'grad_norm': 4.859724998474121, 'learning_rate': 4.177966101694915e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [1:53:23<1:17:44,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [1:53:25<1:18:01,  1.90s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.33913612365722656, 'learning_rate': 4.176271186440679e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [1:53:25<1:18:01,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [1:53:27<1:18:02,  1.90s/it]                                                       {'loss': 0.2154, 'grad_norm': 10.134966850280762, 'learning_rate': 4.174576271186441e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [1:53:27<1:18:02,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [1:53:29<1:18:02,  1.90s/it]                                                       {'loss': 0.3775, 'grad_norm': 11.287362098693848, 'learning_rate': 4.172881355932204e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [1:53:29<1:18:02,  1.90s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [1:53:31<1:17:28,  1.89s/it]                                                       {'loss': 0.0191, 'grad_norm': 2.790487289428711, 'learning_rate': 4.171186440677966e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [1:53:31<1:17:28,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [1:53:33<1:17:21,  1.89s/it]                                                       {'loss': 0.018, 'grad_norm': 3.15187668800354, 'learning_rate': 4.169491525423729e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [1:53:33<1:17:21,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [1:53:35<1:17:04,  1.88s/it]                                                       {'loss': 0.2475, 'grad_norm': 7.50260591506958, 'learning_rate': 4.167796610169492e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [1:53:35<1:17:04,  1.88s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [1:53:37<1:17:23,  1.89s/it]                                                       {'loss': 0.1995, 'grad_norm': 8.171649932861328, 'learning_rate': 4.166101694915254e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [1:53:37<1:17:23,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [1:53:39<1:17:29,  1.89s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.9675710797309875, 'learning_rate': 4.164406779661017e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [1:53:39<1:17:29,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [1:53:40<1:17:23,  1.89s/it]                                                       {'loss': 0.3086, 'grad_norm': 10.071158409118652, 'learning_rate': 4.16271186440678e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [1:53:40<1:17:23,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [1:53:42<1:16:43,  1.88s/it]                                                       {'loss': 0.0154, 'grad_norm': 1.5636297464370728, 'learning_rate': 4.161016949152543e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [1:53:42<1:16:43,  1.88s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [1:53:44<1:18:03,  1.91s/it]                                                       {'loss': 0.1024, 'grad_norm': 7.1104841232299805, 'learning_rate': 4.1593220338983055e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [1:53:44<1:18:03,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [1:53:46<1:18:07,  1.91s/it]                                                       {'loss': 0.2371, 'grad_norm': 10.433709144592285, 'learning_rate': 4.157627118644068e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [1:53:46<1:18:07,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [1:53:48<1:17:18,  1.89s/it]                                                       {'loss': 0.0317, 'grad_norm': 4.671299457550049, 'learning_rate': 4.155932203389831e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [1:53:48<1:17:18,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [1:53:50<1:17:00,  1.89s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.922384262084961, 'learning_rate': 4.154237288135594e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [1:53:50<1:17:00,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [1:53:52<1:16:36,  1.88s/it]                                                       {'loss': 0.0443, 'grad_norm': 3.65908145904541, 'learning_rate': 4.152542372881356e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [1:53:52<1:16:36,  1.88s/it][2025-11-11 23:47:07,686] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3550
[2025-11-11 23:47:07,693] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:47:07,986] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3550/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [1:53:55<1:30:57,  2.23s/it]                                                       {'loss': 0.0642, 'grad_norm': 4.067967414855957, 'learning_rate': 4.150847457627119e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [1:53:55<1:30:57,  2.23s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [1:53:57<1:27:36,  2.15s/it]                                                       {'loss': 0.0405, 'grad_norm': 3.2060067653656006, 'learning_rate': 4.149152542372882e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [1:53:57<1:27:36,  2.15s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [1:53:59<1:24:41,  2.08s/it]                                                       {'loss': 0.012, 'grad_norm': 1.649749517440796, 'learning_rate': 4.147457627118644e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [1:53:59<1:24:41,  2.08s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [1:54:01<1:21:46,  2.01s/it]                                                       {'loss': 0.0307, 'grad_norm': 3.0832407474517822, 'learning_rate': 4.145762711864407e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [1:54:01<1:21:46,  2.01s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [1:54:02<1:20:21,  1.97s/it]                                                       {'loss': 0.2006, 'grad_norm': 10.820964813232422, 'learning_rate': 4.14406779661017e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [1:54:02<1:20:21,  1.97s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [1:54:04<1:19:24,  1.95s/it]                                                       {'loss': 0.0946, 'grad_norm': 7.391118049621582, 'learning_rate': 4.142372881355933e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [1:54:04<1:19:24,  1.95s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [1:54:06<1:18:36,  1.93s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.9656646847724915, 'learning_rate': 4.1406779661016955e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [1:54:06<1:18:36,  1.93s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [1:54:08<1:17:44,  1.91s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03163253515958786, 'learning_rate': 4.138983050847458e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [1:54:08<1:17:44,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [1:54:10<1:17:36,  1.91s/it]                                                       {'loss': 0.179, 'grad_norm': 8.027732849121094, 'learning_rate': 4.13728813559322e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [1:54:10<1:17:36,  1.91s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [1:54:12<1:16:38,  1.88s/it]                                                       {'loss': 0.0467, 'grad_norm': 5.999890327453613, 'learning_rate': 4.135593220338983e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [1:54:12<1:16:38,  1.88s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [1:54:14<1:16:11,  1.87s/it]                                                       {'loss': 0.0163, 'grad_norm': 2.050840377807617, 'learning_rate': 4.133898305084746e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [1:54:14<1:16:11,  1.87s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [1:54:16<1:16:07,  1.87s/it]                                                       {'loss': 0.0328, 'grad_norm': 2.3773906230926514, 'learning_rate': 4.1322033898305085e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [1:54:16<1:16:07,  1.87s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [1:54:17<1:16:39,  1.89s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.18527694046497345, 'learning_rate': 4.130508474576271e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [1:54:17<1:16:39,  1.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [1:54:19<1:18:05,  1.92s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.8025404214859009, 'learning_rate': 4.128813559322034e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [1:54:19<1:18:05,  1.92s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [1:54:21<1:17:47,  1.92s/it]                                                       {'loss': 0.0338, 'grad_norm': 4.069724082946777, 'learning_rate': 4.127118644067797e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [1:54:21<1:17:47,  1.92s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [1:54:23<1:19:46,  1.97s/it]                                                       {'loss': 0.0384, 'grad_norm': 4.556813716888428, 'learning_rate': 4.12542372881356e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [1:54:23<1:19:46,  1.97s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [1:54:25<1:18:21,  1.93s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2645503282546997, 'learning_rate': 4.123728813559322e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [1:54:25<1:18:21,  1.93s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [1:54:27<1:18:26,  1.94s/it]                                                       {'loss': 0.1211, 'grad_norm': 4.7755889892578125, 'learning_rate': 4.122033898305085e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [1:54:27<1:18:26,  1.94s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [1:54:29<1:17:38,  1.92s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.9820549488067627, 'learning_rate': 4.120338983050848e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [1:54:29<1:17:38,  1.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [1:54:31<1:16:59,  1.90s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.1335301399230957, 'learning_rate': 4.1186440677966105e-06, 'epoch': 0.59}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [1:54:31<1:16:59,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [1:54:33<1:16:33,  1.89s/it]                                                       {'loss': 0.066, 'grad_norm': 2.7428786754608154, 'learning_rate': 4.116949152542373e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [1:54:33<1:16:33,  1.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [1:54:35<1:16:50,  1.90s/it]                                                       {'loss': 0.0551, 'grad_norm': 5.074374198913574, 'learning_rate': 4.115254237288136e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [1:54:35<1:16:50,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [1:54:37<1:16:37,  1.89s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.5174795389175415, 'learning_rate': 4.113559322033899e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [1:54:37<1:16:37,  1.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [1:54:39<1:18:04,  1.93s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.055224895477295, 'learning_rate': 4.111864406779662e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [1:54:39<1:18:04,  1.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [1:54:41<1:20:46,  2.00s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.1970362663269043, 'learning_rate': 4.110169491525424e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [1:54:41<1:20:46,  2.00s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [1:54:43<1:19:05,  1.96s/it]                                                       {'loss': 0.0533, 'grad_norm': 5.261322975158691, 'learning_rate': 4.108474576271187e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [1:54:43<1:19:05,  1.96s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [1:54:45<1:18:38,  1.95s/it]                                                       {'loss': 0.042, 'grad_norm': 3.8434805870056152, 'learning_rate': 4.10677966101695e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [1:54:45<1:18:38,  1.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [1:54:46<1:17:44,  1.93s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.6789266467094421, 'learning_rate': 4.1050847457627124e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [1:54:46<1:17:44,  1.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [1:54:48<1:17:03,  1.91s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.4805145263671875, 'learning_rate': 4.103389830508475e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [1:54:48<1:17:03,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [1:54:50<1:16:46,  1.90s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.859959840774536, 'learning_rate': 4.101694915254237e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [1:54:50<1:16:46,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [1:54:52<1:17:53,  1.93s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.36444890499115, 'learning_rate': 4.1e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [1:54:52<1:17:53,  1.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [1:54:54<1:19:50,  1.98s/it]                                                       {'loss': 0.1709, 'grad_norm': 7.655721664428711, 'learning_rate': 4.098305084745763e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [1:54:54<1:19:50,  1.98s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [1:54:56<1:18:58,  1.96s/it]                                                       {'loss': 0.1973, 'grad_norm': 10.258182525634766, 'learning_rate': 4.096610169491525e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [1:54:56<1:18:58,  1.96s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [1:54:58<1:18:17,  1.94s/it]                                                       {'loss': 0.073, 'grad_norm': 7.128273010253906, 'learning_rate': 4.094915254237289e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [1:54:58<1:18:17,  1.94s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [1:55:00<1:17:17,  1.92s/it]                                                       {'loss': 0.091, 'grad_norm': 6.643340110778809, 'learning_rate': 4.093220338983051e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [1:55:00<1:17:17,  1.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [1:55:02<1:16:35,  1.90s/it]                                                       {'loss': 0.1687, 'grad_norm': 6.0350141525268555, 'learning_rate': 4.0915254237288135e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [1:55:02<1:16:35,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [1:55:04<1:15:45,  1.88s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.5648536682128906, 'learning_rate': 4.089830508474577e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [1:55:04<1:15:45,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [1:55:06<1:15:43,  1.88s/it]                                                       {'loss': 0.135, 'grad_norm': 7.37259578704834, 'learning_rate': 4.088135593220339e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [1:55:06<1:15:43,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [1:55:07<1:15:39,  1.88s/it]                                                       {'loss': 0.0905, 'grad_norm': 4.448651313781738, 'learning_rate': 4.086440677966102e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [1:55:07<1:15:39,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [1:55:09<1:15:30,  1.88s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.433359146118164, 'learning_rate': 4.084745762711865e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [1:55:09<1:15:30,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [1:55:11<1:15:16,  1.88s/it]                                                       {'loss': 0.0946, 'grad_norm': 5.660299301147461, 'learning_rate': 4.083050847457627e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [1:55:11<1:15:16,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [1:55:13<1:15:05,  1.87s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.6478754281997681, 'learning_rate': 4.081355932203391e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [1:55:13<1:15:05,  1.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [1:55:15<1:14:53,  1.87s/it]                                                       {'loss': 0.2707, 'grad_norm': 8.210248947143555, 'learning_rate': 4.079661016949153e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [1:55:15<1:14:53,  1.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [1:55:17<1:16:48,  1.92s/it]                                                       {'loss': 0.1194, 'grad_norm': 6.705435276031494, 'learning_rate': 4.0779661016949155e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [1:55:17<1:16:48,  1.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [1:55:19<1:16:37,  1.91s/it]                                                       {'loss': 0.1592, 'grad_norm': 4.925863265991211, 'learning_rate': 4.076271186440679e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [1:55:19<1:16:37,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [1:55:21<1:16:33,  1.91s/it]                                                       {'loss': 0.0102, 'grad_norm': 0.9945361018180847, 'learning_rate': 4.074576271186441e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [1:55:21<1:16:33,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [1:55:23<1:16:08,  1.90s/it]                                                       {'loss': 0.0282, 'grad_norm': 4.803757190704346, 'learning_rate': 4.072881355932204e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [1:55:23<1:16:08,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [1:55:25<1:16:08,  1.90s/it]                                                       {'loss': 0.1773, 'grad_norm': 9.027191162109375, 'learning_rate': 4.071186440677967e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [1:55:25<1:16:08,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [1:55:26<1:15:13,  1.88s/it]                                                       {'loss': 0.0188, 'grad_norm': 2.8546950817108154, 'learning_rate': 4.069491525423729e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [1:55:26<1:15:13,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [1:55:28<1:14:39,  1.87s/it]                                                       {'loss': 0.0162, 'grad_norm': 3.1490142345428467, 'learning_rate': 4.067796610169492e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [1:55:28<1:14:39,  1.87s/it][2025-11-11 23:48:44,131] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3600
[2025-11-11 23:48:44,138] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:48:44,414] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [1:55:31<1:24:55,  2.12s/it]                                                       {'loss': 0.09, 'grad_norm': 6.474798679351807, 'learning_rate': 4.066101694915254e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [1:55:31<1:24:55,  2.12s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [1:55:33<1:22:07,  2.05s/it]                                                       {'loss': 0.1143, 'grad_norm': 8.782639503479004, 'learning_rate': 4.0644067796610174e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [1:55:33<1:22:07,  2.05s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [1:55:35<1:19:49,  2.00s/it]                                                       {'loss': 0.0614, 'grad_norm': 6.437349319458008, 'learning_rate': 4.06271186440678e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [1:55:35<1:19:49,  2.00s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [1:55:37<1:18:08,  1.96s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.3750766515731812, 'learning_rate': 4.061016949152542e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [1:55:37<1:18:08,  1.96s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [1:55:38<1:17:08,  1.93s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012331010773777962, 'learning_rate': 4.0593220338983056e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [1:55:38<1:17:08,  1.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [1:55:40<1:16:25,  1.92s/it]                                                       {'loss': 0.0776, 'grad_norm': 2.813239336013794, 'learning_rate': 4.057627118644068e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [1:55:40<1:16:25,  1.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [1:55:42<1:15:59,  1.91s/it]                                                       {'loss': 0.1101, 'grad_norm': 8.764814376831055, 'learning_rate': 4.0559322033898304e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [1:55:42<1:15:59,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [1:55:44<1:15:33,  1.90s/it]                                                       {'loss': 0.2147, 'grad_norm': 8.145735740661621, 'learning_rate': 4.054237288135594e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [1:55:44<1:15:33,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [1:55:46<1:19:19,  1.99s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.9674415588378906, 'learning_rate': 4.052542372881356e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [1:55:46<1:19:19,  1.99s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [1:55:49<1:22:19,  2.07s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.4791004955768585, 'learning_rate': 4.0508474576271186e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [1:55:49<1:22:19,  2.07s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [1:55:50<1:20:27,  2.02s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.14118298888206482, 'learning_rate': 4.049152542372882e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [1:55:50<1:20:27,  2.02s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [1:55:52<1:19:05,  1.99s/it]                                                       {'loss': 0.1151, 'grad_norm': 6.764239311218262, 'learning_rate': 4.047457627118644e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [1:55:52<1:19:05,  1.99s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [1:55:54<1:17:39,  1.95s/it]                                                       {'loss': 0.001, 'grad_norm': 0.17943111062049866, 'learning_rate': 4.0457627118644075e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [1:55:54<1:17:39,  1.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [1:55:56<1:17:23,  1.95s/it]                                                       {'loss': 0.0724, 'grad_norm': 5.974977016448975, 'learning_rate': 4.04406779661017e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [1:55:56<1:17:23,  1.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [1:55:58<1:16:39,  1.93s/it]                                                       {'loss': 0.1772, 'grad_norm': 6.826094150543213, 'learning_rate': 4.042372881355932e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [1:55:58<1:16:39,  1.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [1:56:00<1:16:07,  1.92s/it]                                                       {'loss': 0.2188, 'grad_norm': 10.883502006530762, 'learning_rate': 4.040677966101696e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [1:56:00<1:16:07,  1.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [1:56:02<1:15:36,  1.90s/it]                                                       {'loss': 0.0368, 'grad_norm': 4.537410736083984, 'learning_rate': 4.038983050847458e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [1:56:02<1:15:36,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [1:56:04<1:14:56,  1.89s/it]                                                       {'loss': 0.0235, 'grad_norm': 3.615814685821533, 'learning_rate': 4.0372881355932205e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [1:56:04<1:14:56,  1.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [1:56:06<1:15:44,  1.91s/it]                                                       {'loss': 0.101, 'grad_norm': 7.210826873779297, 'learning_rate': 4.035593220338984e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [1:56:06<1:15:44,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [1:56:07<1:15:31,  1.90s/it]                                                       {'loss': 0.0175, 'grad_norm': 3.108011484146118, 'learning_rate': 4.033898305084746e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [1:56:07<1:15:31,  1.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [1:56:09<1:15:48,  1.91s/it]                                                       {'loss': 0.1656, 'grad_norm': 8.078863143920898, 'learning_rate': 4.0322033898305095e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [1:56:09<1:15:48,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [1:56:11<1:15:38,  1.91s/it]                                                       {'loss': 0.1713, 'grad_norm': 7.049652576446533, 'learning_rate': 4.030508474576271e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [1:56:11<1:15:38,  1.91s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [1:56:13<1:14:47,  1.89s/it]                                                       {'loss': 0.003, 'grad_norm': 0.761942446231842, 'learning_rate': 4.028813559322034e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [1:56:13<1:14:47,  1.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [1:56:15<1:14:15,  1.88s/it]                                                       {'loss': 0.2018, 'grad_norm': 8.573074340820312, 'learning_rate': 4.027118644067797e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [1:56:15<1:14:15,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [1:56:17<1:14:02,  1.87s/it]                                                       {'loss': 0.2239, 'grad_norm': 9.507664680480957, 'learning_rate': 4.025423728813559e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [1:56:17<1:14:02,  1.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [1:56:19<1:14:02,  1.87s/it]                                                       {'loss': 0.1119, 'grad_norm': 10.408824920654297, 'learning_rate': 4.0237288135593225e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [1:56:19<1:14:02,  1.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [1:56:21<1:14:07,  1.87s/it]                                                       {'loss': 0.001, 'grad_norm': 0.19714227318763733, 'learning_rate': 4.022033898305085e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [1:56:21<1:14:07,  1.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [1:56:22<1:13:28,  1.86s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.255254864692688, 'learning_rate': 4.020338983050847e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [1:56:22<1:13:28,  1.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [1:56:24<1:14:12,  1.88s/it]                                                       {'loss': 0.038, 'grad_norm': 5.101129531860352, 'learning_rate': 4.018644067796611e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [1:56:24<1:14:12,  1.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [1:56:26<1:13:58,  1.87s/it]                                                       {'loss': 0.3375, 'grad_norm': 8.644840240478516, 'learning_rate': 4.016949152542373e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [1:56:26<1:13:58,  1.87s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [1:56:28<1:14:17,  1.88s/it]                                                       {'loss': 0.1574, 'grad_norm': 7.453180313110352, 'learning_rate': 4.015254237288136e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [1:56:28<1:14:17,  1.88s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [1:56:30<1:14:16,  1.88s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.13439679145813, 'learning_rate': 4.013559322033899e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [1:56:30<1:14:16,  1.88s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [1:56:32<1:18:48,  2.00s/it]                                                       {'loss': 0.2822, 'grad_norm': 11.37768268585205, 'learning_rate': 4.011864406779661e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [1:56:32<1:18:48,  2.00s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [1:56:34<1:16:56,  1.95s/it]                                                       {'loss': 0.0695, 'grad_norm': 6.7819671630859375, 'learning_rate': 4.010169491525424e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [1:56:34<1:16:56,  1.95s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [1:56:36<1:15:58,  1.93s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3349851667881012, 'learning_rate': 4.008474576271187e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [1:56:36<1:15:58,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [1:56:38<1:15:32,  1.92s/it]                                                       {'loss': 0.0236, 'grad_norm': 3.0422873497009277, 'learning_rate': 4.006779661016949e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [1:56:38<1:15:32,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [1:56:40<1:15:35,  1.92s/it]                                                       {'loss': 0.0543, 'grad_norm': 3.0058786869049072, 'learning_rate': 4.0050847457627125e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [1:56:40<1:15:35,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [1:56:42<1:14:58,  1.90s/it]                                                       {'loss': 0.0378, 'grad_norm': 5.749691963195801, 'learning_rate': 4.003389830508475e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [1:56:42<1:14:58,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [1:56:44<1:14:37,  1.90s/it]                                                       {'loss': 0.1434, 'grad_norm': 8.273313522338867, 'learning_rate': 4.001694915254237e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [1:56:44<1:14:37,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [1:56:45<1:14:37,  1.90s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.6684669256210327, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [1:56:45<1:14:37,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [1:56:47<1:14:29,  1.89s/it]                                                       {'loss': 0.131, 'grad_norm': 10.465603828430176, 'learning_rate': 3.998305084745763e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [1:56:47<1:14:29,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [1:56:49<1:14:18,  1.89s/it]                                                       {'loss': 0.0941, 'grad_norm': 4.118143558502197, 'learning_rate': 3.996610169491526e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [1:56:49<1:14:18,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [1:56:51<1:15:29,  1.92s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.18287774920463562, 'learning_rate': 3.994915254237288e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [1:56:51<1:15:29,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [1:56:53<1:14:24,  1.89s/it]                                                       {'loss': 0.001, 'grad_norm': 0.18472811579704285, 'learning_rate': 3.993220338983051e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [1:56:53<1:14:24,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [1:56:55<1:14:34,  1.90s/it]                                                       {'loss': 0.313, 'grad_norm': 13.371052742004395, 'learning_rate': 3.991525423728814e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [1:56:55<1:14:34,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [1:56:57<1:14:43,  1.90s/it]                                                       {'loss': 0.1457, 'grad_norm': 9.231965065002441, 'learning_rate': 3.989830508474576e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [1:56:57<1:14:43,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [1:56:59<1:16:27,  1.95s/it]                                                       {'loss': 0.0459, 'grad_norm': 3.3157806396484375, 'learning_rate': 3.988135593220339e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [1:56:59<1:16:27,  1.95s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [1:57:01<1:15:34,  1.93s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.0380678176879883, 'learning_rate': 3.986440677966102e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [1:57:01<1:15:34,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [1:57:03<1:15:07,  1.92s/it]                                                       {'loss': 0.0419, 'grad_norm': 3.7548305988311768, 'learning_rate': 3.984745762711865e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [1:57:03<1:15:07,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [1:57:05<1:14:22,  1.90s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.8772884011268616, 'learning_rate': 3.9830508474576275e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [1:57:05<1:14:22,  1.90s/it][2025-11-11 23:50:20,484] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3650
[2025-11-11 23:50:20,491] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:50:20,760] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3650/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [1:57:07<1:23:48,  2.14s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.0957039594650269, 'learning_rate': 3.98135593220339e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [1:57:07<1:23:48,  2.14s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [1:57:09<1:20:31,  2.06s/it]                                                       {'loss': 0.0224, 'grad_norm': 2.6055171489715576, 'learning_rate': 3.979661016949153e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [1:57:09<1:20:31,  2.06s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [1:57:11<1:18:25,  2.00s/it]                                                       {'loss': 0.0732, 'grad_norm': 7.123297691345215, 'learning_rate': 3.977966101694916e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [1:57:11<1:18:25,  2.00s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [1:57:13<1:16:24,  1.95s/it]                                                       {'loss': 0.0433, 'grad_norm': 5.535369396209717, 'learning_rate': 3.976271186440678e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [1:57:13<1:16:24,  1.95s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [1:57:15<1:15:46,  1.94s/it]                                                       {'loss': 0.0798, 'grad_norm': 8.920989036560059, 'learning_rate': 3.974576271186441e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [1:57:15<1:15:46,  1.94s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [1:57:17<1:14:26,  1.91s/it]                                                       {'loss': 0.2673, 'grad_norm': 11.102088928222656, 'learning_rate': 3.972881355932204e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [1:57:17<1:14:26,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [1:57:18<1:13:49,  1.89s/it]                                                       {'loss': 0.0442, 'grad_norm': 4.737386703491211, 'learning_rate': 3.971186440677966e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [1:57:18<1:13:49,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [1:57:20<1:13:39,  1.89s/it]                                                       {'loss': 0.0705, 'grad_norm': 5.934854030609131, 'learning_rate': 3.9694915254237294e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [1:57:20<1:13:39,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [1:57:22<1:15:03,  1.92s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.9601123929023743, 'learning_rate': 3.967796610169492e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [1:57:22<1:15:03,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [1:57:24<1:14:49,  1.92s/it]                                                       {'loss': 0.1948, 'grad_norm': 13.520952224731445, 'learning_rate': 3.966101694915255e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [1:57:24<1:14:49,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [1:57:26<1:14:08,  1.90s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.726550817489624, 'learning_rate': 3.9644067796610176e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [1:57:26<1:14:08,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [1:57:28<1:13:29,  1.89s/it]                                                       {'loss': 0.0438, 'grad_norm': 4.5416340827941895, 'learning_rate': 3.96271186440678e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [1:57:28<1:13:29,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [1:57:30<1:13:07,  1.88s/it]                                                       {'loss': 0.1058, 'grad_norm': 6.9882917404174805, 'learning_rate': 3.961016949152542e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [1:57:30<1:13:07,  1.88s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [1:57:32<1:12:43,  1.87s/it]                                                       {'loss': 0.0345, 'grad_norm': 1.827161192893982, 'learning_rate': 3.959322033898305e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [1:57:32<1:12:43,  1.87s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [1:57:34<1:15:11,  1.93s/it]                                                       {'loss': 0.0171, 'grad_norm': 1.6547290086746216, 'learning_rate': 3.957627118644068e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [1:57:34<1:15:11,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [1:57:36<1:16:47,  1.97s/it]                                                       {'loss': 0.1103, 'grad_norm': 4.4792704582214355, 'learning_rate': 3.9559322033898305e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [1:57:36<1:16:47,  1.97s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [1:57:38<1:15:35,  1.94s/it]                                                       {'loss': 0.0537, 'grad_norm': 4.510586738586426, 'learning_rate': 3.954237288135593e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [1:57:38<1:15:35,  1.94s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [1:57:40<1:14:56,  1.93s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.9270163774490356, 'learning_rate': 3.952542372881356e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [1:57:40<1:14:56,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [1:57:41<1:14:31,  1.92s/it]                                                       {'loss': 0.1369, 'grad_norm': 9.25907039642334, 'learning_rate': 3.950847457627119e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [1:57:41<1:14:31,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [1:57:43<1:15:13,  1.94s/it]                                                       {'loss': 0.1159, 'grad_norm': 6.721365928649902, 'learning_rate': 3.949152542372882e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [1:57:43<1:15:13,  1.94s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [1:57:45<1:14:01,  1.91s/it]                                                       {'loss': 0.0218, 'grad_norm': 2.939268112182617, 'learning_rate': 3.947457627118644e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [1:57:45<1:14:01,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [1:57:47<1:13:55,  1.91s/it]                                                       {'loss': 0.113, 'grad_norm': 7.357498645782471, 'learning_rate': 3.945762711864407e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [1:57:47<1:13:55,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [1:57:49<1:13:45,  1.90s/it]                                                       {'loss': 0.1653, 'grad_norm': 7.81227970123291, 'learning_rate': 3.94406779661017e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [1:57:49<1:13:45,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [1:57:51<1:14:07,  1.91s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.10287760943174362, 'learning_rate': 3.9423728813559325e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [1:57:51<1:14:07,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [1:57:53<1:14:27,  1.92s/it]                                                       {'loss': 0.0503, 'grad_norm': 4.957663536071777, 'learning_rate': 3.940677966101695e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [1:57:53<1:14:27,  1.92s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [1:57:55<1:14:03,  1.91s/it]                                                       {'loss': 0.0389, 'grad_norm': 5.912240505218506, 'learning_rate': 3.938983050847458e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [1:57:55<1:14:03,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [1:57:57<1:13:44,  1.90s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.8459587097167969, 'learning_rate': 3.937288135593221e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [1:57:57<1:13:44,  1.90s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [1:57:59<1:12:53,  1.88s/it]                                                       {'loss': 0.0671, 'grad_norm': 2.4567339420318604, 'learning_rate': 3.935593220338984e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [1:57:59<1:12:53,  1.88s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [1:58:00<1:12:38,  1.88s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.7403939366340637, 'learning_rate': 3.933898305084746e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [1:58:00<1:12:38,  1.88s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [1:58:02<1:13:15,  1.89s/it]                                                       {'loss': 0.0815, 'grad_norm': 9.393465995788574, 'learning_rate': 3.932203389830509e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [1:58:02<1:13:15,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [1:58:04<1:13:13,  1.89s/it]                                                       {'loss': 0.1029, 'grad_norm': 7.025169849395752, 'learning_rate': 3.930508474576272e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [1:58:04<1:13:13,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [1:58:06<1:13:04,  1.89s/it]                                                       {'loss': 0.0829, 'grad_norm': 7.022507667541504, 'learning_rate': 3.9288135593220344e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [1:58:06<1:13:04,  1.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [1:58:08<1:14:30,  1.93s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.07576862722635269, 'learning_rate': 3.927118644067797e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [1:58:08<1:14:30,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [1:58:10<1:13:50,  1.91s/it]                                                       {'loss': 0.0338, 'grad_norm': 4.231088161468506, 'learning_rate': 3.925423728813559e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [1:58:10<1:13:50,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [1:58:12<1:14:18,  1.93s/it]                                                       {'loss': 0.0643, 'grad_norm': 6.4987287521362305, 'learning_rate': 3.923728813559322e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [1:58:12<1:14:18,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [1:58:14<1:13:44,  1.91s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.055094651877880096, 'learning_rate': 3.922033898305085e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [1:58:14<1:13:44,  1.91s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [1:58:16<1:14:52,  1.94s/it]                                                       {'loss': 0.2415, 'grad_norm': 12.620264053344727, 'learning_rate': 3.920338983050847e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [1:58:16<1:14:52,  1.94s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [1:58:18<1:14:29,  1.93s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.6045677661895752, 'learning_rate': 3.918644067796611e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [1:58:18<1:14:29,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [1:58:20<1:14:04,  1.92s/it]                                                       {'loss': 0.0182, 'grad_norm': 2.62546968460083, 'learning_rate': 3.916949152542373e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [1:58:20<1:14:04,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [1:58:22<1:14:16,  1.93s/it]                                                       {'loss': 0.0181, 'grad_norm': 2.542149066925049, 'learning_rate': 3.9152542372881355e-06, 'epoch': 0.61}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [1:58:22<1:14:16,  1.93s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [1:58:23<1:13:24,  1.91s/it]                                                       {'loss': 0.0719, 'grad_norm': 5.444449424743652, 'learning_rate': 3.913559322033899e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [1:58:23<1:13:24,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [1:58:25<1:13:13,  1.90s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.36600619554519653, 'learning_rate': 3.911864406779661e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [1:58:25<1:13:13,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [1:58:27<1:12:53,  1.90s/it]                                                       {'loss': 0.0713, 'grad_norm': 6.107472896575928, 'learning_rate': 3.910169491525424e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [1:58:27<1:12:53,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [1:58:29<1:13:36,  1.92s/it]                                                       {'loss': 0.0212, 'grad_norm': 3.172543525695801, 'learning_rate': 3.908474576271187e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [1:58:29<1:13:36,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [1:58:31<1:13:29,  1.91s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.634187936782837, 'learning_rate': 3.906779661016949e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [1:58:31<1:13:29,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [1:58:33<1:13:21,  1.91s/it]                                                       {'loss': 0.0147, 'grad_norm': 2.146106719970703, 'learning_rate': 3.905084745762713e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [1:58:33<1:13:21,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [1:58:35<1:13:14,  1.91s/it]                                                       {'loss': 0.0563, 'grad_norm': 7.148696422576904, 'learning_rate': 3.903389830508475e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [1:58:35<1:13:14,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [1:58:37<1:15:22,  1.96s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.0646147727966309, 'learning_rate': 3.9016949152542375e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [1:58:37<1:15:22,  1.96s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [1:58:39<1:15:29,  1.97s/it]                                                       {'loss': 0.0151, 'grad_norm': 1.108127474784851, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [1:58:39<1:15:29,  1.97s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [1:58:41<1:15:08,  1.96s/it]                                                       {'loss': 0.1015, 'grad_norm': 7.066277980804443, 'learning_rate': 3.898305084745763e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [1:58:41<1:15:08,  1.96s/it][2025-11-11 23:51:56,877] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3700
[2025-11-11 23:51:56,885] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:51:57,171] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [1:58:44<1:23:36,  2.18s/it]                                                       {'loss': 0.0824, 'grad_norm': 3.759023427963257, 'learning_rate': 3.896610169491526e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [1:58:44<1:23:36,  2.18s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [1:58:46<1:19:55,  2.09s/it]                                                       {'loss': 0.0436, 'grad_norm': 6.068986892700195, 'learning_rate': 3.894915254237289e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [1:58:46<1:19:55,  2.09s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [1:58:47<1:17:24,  2.02s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4079594314098358, 'learning_rate': 3.893220338983051e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [1:58:47<1:17:24,  2.02s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [1:58:49<1:16:03,  1.99s/it]                                                       {'loss': 0.0132, 'grad_norm': 2.593804121017456, 'learning_rate': 3.891525423728814e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [1:58:49<1:16:03,  1.99s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [1:58:51<1:15:06,  1.96s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.4474886655807495, 'learning_rate': 3.889830508474576e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [1:58:51<1:15:06,  1.96s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [1:58:53<1:15:21,  1.97s/it]                                                       {'loss': 0.0456, 'grad_norm': 6.369780540466309, 'learning_rate': 3.8881355932203395e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [1:58:53<1:15:21,  1.97s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [1:58:55<1:13:47,  1.93s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.023738376796245575, 'learning_rate': 3.886440677966102e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [1:58:55<1:13:47,  1.93s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [1:58:57<1:12:56,  1.91s/it]                                                       {'loss': 0.082, 'grad_norm': 10.612646102905273, 'learning_rate': 3.884745762711864e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [1:58:57<1:12:56,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [1:58:59<1:12:21,  1.89s/it]                                                       {'loss': 0.0309, 'grad_norm': 4.488709449768066, 'learning_rate': 3.883050847457628e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [1:58:59<1:12:21,  1.89s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [1:59:01<1:12:08,  1.89s/it]                                                       {'loss': 0.0835, 'grad_norm': 5.821815490722656, 'learning_rate': 3.88135593220339e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [1:59:01<1:12:08,  1.89s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [1:59:03<1:11:53,  1.88s/it]                                                       {'loss': 0.2015, 'grad_norm': 9.1627836227417, 'learning_rate': 3.8796610169491524e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [1:59:03<1:11:53,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [1:59:04<1:11:41,  1.88s/it]                                                       {'loss': 0.0339, 'grad_norm': 5.865411281585693, 'learning_rate': 3.877966101694916e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [1:59:04<1:11:41,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [1:59:06<1:11:29,  1.88s/it]                                                       {'loss': 0.059, 'grad_norm': 5.263491630554199, 'learning_rate': 3.876271186440678e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [1:59:06<1:11:29,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [1:59:08<1:12:01,  1.89s/it]                                                       {'loss': 0.1397, 'grad_norm': 3.8304364681243896, 'learning_rate': 3.8745762711864406e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [1:59:08<1:12:01,  1.89s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [1:59:10<1:11:52,  1.89s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.9783021211624146, 'learning_rate': 3.872881355932204e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [1:59:10<1:11:52,  1.89s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [1:59:12<1:11:16,  1.87s/it]                                                       {'loss': 0.0362, 'grad_norm': 5.889329433441162, 'learning_rate': 3.871186440677966e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [1:59:12<1:11:16,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [1:59:14<1:11:36,  1.88s/it]                                                       {'loss': 0.1067, 'grad_norm': 6.383127689361572, 'learning_rate': 3.8694915254237295e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [1:59:14<1:11:36,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [1:59:16<1:11:35,  1.88s/it]                                                       {'loss': 0.0498, 'grad_norm': 2.6609108448028564, 'learning_rate': 3.867796610169492e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [1:59:16<1:11:35,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [1:59:18<1:12:31,  1.91s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.53375506401062, 'learning_rate': 3.866101694915254e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [1:59:18<1:12:31,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [1:59:20<1:12:02,  1.90s/it]                                                       {'loss': 0.1003, 'grad_norm': 6.229413032531738, 'learning_rate': 3.864406779661018e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [1:59:20<1:12:02,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [1:59:21<1:12:11,  1.90s/it]                                                       {'loss': 0.077, 'grad_norm': 6.313090801239014, 'learning_rate': 3.86271186440678e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [1:59:21<1:12:11,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [1:59:23<1:13:04,  1.92s/it]                                                       {'loss': 0.003, 'grad_norm': 0.6263321042060852, 'learning_rate': 3.8610169491525425e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [1:59:23<1:13:04,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [1:59:25<1:12:15,  1.90s/it]                                                       {'loss': 0.0143, 'grad_norm': 2.8275647163391113, 'learning_rate': 3.859322033898306e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [1:59:25<1:12:15,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [1:59:27<1:13:27,  1.94s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.528006911277771, 'learning_rate': 3.857627118644068e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [1:59:27<1:13:27,  1.94s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [1:59:29<1:13:19,  1.93s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08797003328800201, 'learning_rate': 3.8559322033898315e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [1:59:29<1:13:19,  1.93s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [1:59:31<1:13:29,  1.94s/it]                                                       {'loss': 0.1823, 'grad_norm': 7.032646179199219, 'learning_rate': 3.854237288135593e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [1:59:31<1:13:29,  1.94s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [1:59:33<1:12:48,  1.92s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011258243583142757, 'learning_rate': 3.852542372881356e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [1:59:33<1:12:48,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [1:59:35<1:13:12,  1.93s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.1873779296875, 'learning_rate': 3.850847457627119e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [1:59:35<1:13:12,  1.93s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [1:59:37<1:12:26,  1.91s/it]                                                       {'loss': 0.0541, 'grad_norm': 7.019322872161865, 'learning_rate': 3.849152542372881e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [1:59:37<1:12:26,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [1:59:39<1:13:29,  1.94s/it]                                                       {'loss': 0.0569, 'grad_norm': 3.291971206665039, 'learning_rate': 3.8474576271186445e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [1:59:39<1:13:29,  1.94s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [1:59:41<1:12:31,  1.92s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.17057816684246063, 'learning_rate': 3.845762711864407e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [1:59:41<1:12:31,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [1:59:43<1:12:23,  1.92s/it]                                                       {'loss': 0.0384, 'grad_norm': 9.840399742126465, 'learning_rate': 3.844067796610169e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [1:59:43<1:12:23,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [1:59:45<1:13:40,  1.95s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.060030024498701096, 'learning_rate': 3.842372881355933e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [1:59:45<1:13:40,  1.95s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [1:59:47<1:13:25,  1.94s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.9062345027923584, 'learning_rate': 3.840677966101695e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [1:59:47<1:13:25,  1.94s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [1:59:49<1:14:52,  1.98s/it]                                                       {'loss': 0.0827, 'grad_norm': 3.8065335750579834, 'learning_rate': 3.838983050847458e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [1:59:49<1:14:52,  1.98s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [1:59:51<1:13:37,  1.95s/it]                                                       {'loss': 0.1049, 'grad_norm': 7.189023971557617, 'learning_rate': 3.837288135593221e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [1:59:51<1:13:37,  1.95s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [1:59:52<1:12:36,  1.92s/it]                                                       {'loss': 0.0885, 'grad_norm': 7.956143379211426, 'learning_rate': 3.835593220338983e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [1:59:52<1:12:36,  1.92s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [1:59:54<1:12:03,  1.91s/it]                                                       {'loss': 0.0765, 'grad_norm': 4.476170063018799, 'learning_rate': 3.8338983050847464e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [1:59:54<1:12:03,  1.91s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [1:59:56<1:11:32,  1.90s/it]                                                       {'loss': 0.0522, 'grad_norm': 3.9206132888793945, 'learning_rate': 3.832203389830509e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [1:59:56<1:11:32,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [1:59:58<1:10:50,  1.88s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2032279223203659, 'learning_rate': 3.830508474576271e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [1:59:58<1:10:50,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [2:00:00<1:10:35,  1.87s/it]                                                       {'loss': 0.1471, 'grad_norm': 6.685340404510498, 'learning_rate': 3.8288135593220346e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [2:00:00<1:10:35,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [2:00:02<1:10:28,  1.87s/it]                                                       {'loss': 0.1722, 'grad_norm': 12.085177421569824, 'learning_rate': 3.827118644067797e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [2:00:02<1:10:28,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [2:00:04<1:10:17,  1.87s/it]                                                       {'loss': 0.0153, 'grad_norm': 1.975324034690857, 'learning_rate': 3.82542372881356e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [2:00:04<1:10:17,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [2:00:05<1:10:18,  1.87s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3054088056087494, 'learning_rate': 3.823728813559323e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [2:00:05<1:10:18,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [2:00:07<1:10:14,  1.87s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4558229446411133, 'learning_rate': 3.822033898305085e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [2:00:07<1:10:14,  1.87s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [2:00:09<1:11:24,  1.90s/it]                                                       {'loss': 0.0344, 'grad_norm': 5.359244346618652, 'learning_rate': 3.8203389830508475e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [2:00:09<1:11:24,  1.90s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [2:00:11<1:10:45,  1.88s/it]                                                       {'loss': 0.0125, 'grad_norm': 2.2747137546539307, 'learning_rate': 3.81864406779661e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [2:00:11<1:10:45,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [2:00:13<1:10:28,  1.88s/it]                                                       {'loss': 0.0265, 'grad_norm': 4.587846279144287, 'learning_rate': 3.816949152542373e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [2:00:13<1:10:28,  1.88s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [2:00:15<1:09:44,  1.86s/it]                                                       {'loss': 0.0897, 'grad_norm': 7.7669219970703125, 'learning_rate': 3.815254237288136e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [2:00:15<1:09:44,  1.86s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [2:00:17<1:10:07,  1.87s/it]                                                       {'loss': 0.057, 'grad_norm': 6.48729944229126, 'learning_rate': 3.8135593220338985e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [2:00:17<1:10:07,  1.87s/it][2025-11-11 23:53:32,639] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3750
[2025-11-11 23:53:32,646] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:53:32,917] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3750/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [2:00:19<1:18:47,  2.10s/it]                                                       {'loss': 0.0125, 'grad_norm': 2.620352029800415, 'learning_rate': 3.8118644067796614e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [2:00:19<1:18:47,  2.10s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [2:00:21<1:16:14,  2.04s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.6381477117538452, 'learning_rate': 3.8101694915254238e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [2:00:21<1:16:14,  2.04s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [2:00:23<1:14:05,  1.98s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.6786390542984009, 'learning_rate': 3.8084745762711866e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [2:00:23<1:14:05,  1.98s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [2:00:25<1:13:03,  1.95s/it]                                                       {'loss': 0.0544, 'grad_norm': 5.049952030181885, 'learning_rate': 3.8067796610169495e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [2:00:25<1:13:03,  1.95s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [2:00:27<1:12:16,  1.93s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.1362874507904053, 'learning_rate': 3.8050847457627123e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [2:00:27<1:12:16,  1.93s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [2:00:29<1:11:19,  1.91s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.5871543884277344, 'learning_rate': 3.8033898305084748e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [2:00:29<1:11:19,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [2:00:31<1:11:33,  1.91s/it]                                                       {'loss': 0.0589, 'grad_norm': 6.49215030670166, 'learning_rate': 3.8016949152542376e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [2:00:31<1:11:33,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [2:00:33<1:11:13,  1.91s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.1527812480926514, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [2:00:33<1:11:13,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [2:00:34<1:11:00,  1.90s/it]                                                       {'loss': 0.0301, 'grad_norm': 3.35520601272583, 'learning_rate': 3.798305084745763e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [2:00:34<1:11:00,  1.90s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [2:00:36<1:10:36,  1.89s/it]                                                       {'loss': 0.2884, 'grad_norm': 8.924742698669434, 'learning_rate': 3.7966101694915257e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [2:00:36<1:10:36,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [2:00:38<1:10:03,  1.88s/it]                                                       {'loss': 0.0504, 'grad_norm': 2.6525847911834717, 'learning_rate': 3.7949152542372886e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [2:00:38<1:10:03,  1.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [2:00:40<1:10:28,  1.89s/it]                                                       {'loss': 0.0942, 'grad_norm': 5.442224025726318, 'learning_rate': 3.7932203389830514e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [2:00:40<1:10:28,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [2:00:42<1:10:15,  1.88s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.9182251691818237, 'learning_rate': 3.791525423728814e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [2:00:42<1:10:15,  1.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [2:00:44<1:09:54,  1.88s/it]                                                       {'loss': 0.0715, 'grad_norm': 6.467141151428223, 'learning_rate': 3.7898305084745767e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [2:00:44<1:09:54,  1.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [2:00:46<1:09:55,  1.88s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6391561031341553, 'learning_rate': 3.7881355932203396e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [2:00:46<1:09:55,  1.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [2:00:48<1:10:36,  1.90s/it]                                                       {'loss': 0.0424, 'grad_norm': 4.9257073402404785, 'learning_rate': 3.7864406779661024e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [2:00:48<1:10:36,  1.90s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [2:00:49<1:10:11,  1.89s/it]                                                       {'loss': 0.0291, 'grad_norm': 4.309189319610596, 'learning_rate': 3.7847457627118644e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [2:00:49<1:10:11,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [2:00:51<1:10:03,  1.88s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.21507862210273743, 'learning_rate': 3.7830508474576273e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [2:00:51<1:10:03,  1.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [2:00:53<1:09:42,  1.87s/it]                                                       {'loss': 0.0138, 'grad_norm': 2.7429308891296387, 'learning_rate': 3.78135593220339e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [2:00:53<1:09:42,  1.87s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [2:00:55<1:09:25,  1.87s/it]                                                       {'loss': 0.097, 'grad_norm': 7.172658920288086, 'learning_rate': 3.7796610169491525e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [2:00:55<1:09:25,  1.87s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [2:00:57<1:10:10,  1.89s/it]                                                       {'loss': 0.0726, 'grad_norm': 8.204328536987305, 'learning_rate': 3.7779661016949154e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [2:00:57<1:10:10,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [2:00:59<1:10:46,  1.91s/it]                                                       {'loss': 0.1907, 'grad_norm': 6.955834865570068, 'learning_rate': 3.7762711864406782e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [2:00:59<1:10:46,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [2:01:01<1:10:43,  1.91s/it]                                                       {'loss': 0.0445, 'grad_norm': 2.2059640884399414, 'learning_rate': 3.7745762711864407e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [2:01:01<1:10:43,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [2:01:03<1:14:20,  2.00s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.769340991973877, 'learning_rate': 3.7728813559322035e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [2:01:03<1:14:20,  2.00s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [2:01:05<1:12:34,  1.96s/it]                                                       {'loss': 0.0928, 'grad_norm': 7.920280933380127, 'learning_rate': 3.7711864406779664e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [2:01:05<1:12:34,  1.96s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [2:01:07<1:11:47,  1.94s/it]                                                       {'loss': 0.034, 'grad_norm': 4.159674167633057, 'learning_rate': 3.7694915254237292e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [2:01:07<1:11:47,  1.94s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [2:01:09<1:10:51,  1.91s/it]                                                       {'loss': 0.126, 'grad_norm': 11.171320915222168, 'learning_rate': 3.7677966101694917e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [2:01:09<1:10:51,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [2:01:10<1:09:53,  1.89s/it]                                                       {'loss': 0.1074, 'grad_norm': 6.474851608276367, 'learning_rate': 3.7661016949152545e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [2:01:10<1:09:53,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [2:01:12<1:09:51,  1.89s/it]                                                       {'loss': 0.0434, 'grad_norm': 4.063255310058594, 'learning_rate': 3.7644067796610174e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [2:01:12<1:09:51,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [2:01:14<1:09:06,  1.87s/it]                                                       {'loss': 0.1182, 'grad_norm': 9.078213691711426, 'learning_rate': 3.76271186440678e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [2:01:14<1:09:06,  1.87s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [2:01:16<1:09:44,  1.89s/it]                                                       {'loss': 0.0212, 'grad_norm': 1.5639920234680176, 'learning_rate': 3.7610169491525426e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [2:01:16<1:09:44,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [2:01:18<1:09:47,  1.89s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.2338755130767822, 'learning_rate': 3.7593220338983055e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [2:01:18<1:09:47,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [2:01:20<1:09:51,  1.89s/it]                                                       {'loss': 0.0301, 'grad_norm': 3.2379648685455322, 'learning_rate': 3.7576271186440683e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [2:01:20<1:09:51,  1.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [2:01:22<1:09:18,  1.88s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0712897852063179, 'learning_rate': 3.755932203389831e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [2:01:22<1:09:18,  1.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [2:01:24<1:10:39,  1.91s/it]                                                       {'loss': 0.052, 'grad_norm': 4.669092178344727, 'learning_rate': 3.7542372881355936e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [2:01:24<1:10:39,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [2:01:26<1:10:51,  1.92s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.706470251083374, 'learning_rate': 3.7525423728813565e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [2:01:26<1:10:51,  1.92s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [2:01:28<1:11:29,  1.94s/it]                                                       {'loss': 0.0425, 'grad_norm': 5.362048625946045, 'learning_rate': 3.7508474576271193e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [2:01:28<1:11:29,  1.94s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [2:01:30<1:11:07,  1.93s/it]                                                       {'loss': 0.1688, 'grad_norm': 6.641403675079346, 'learning_rate': 3.7491525423728813e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [2:01:30<1:11:07,  1.93s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [2:01:32<1:11:26,  1.94s/it]                                                       {'loss': 0.0488, 'grad_norm': 3.926497220993042, 'learning_rate': 3.747457627118644e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [2:01:32<1:11:26,  1.94s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [2:01:33<1:11:16,  1.93s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03692801669239998, 'learning_rate': 3.745762711864407e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [2:01:33<1:11:16,  1.93s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [2:01:36<1:13:29,  2.00s/it]                                                       {'loss': 0.2102, 'grad_norm': 9.98612117767334, 'learning_rate': 3.7440677966101694e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [2:01:36<1:13:29,  2.00s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [2:01:38<1:13:25,  2.00s/it]                                                       {'loss': 0.0852, 'grad_norm': 5.226957321166992, 'learning_rate': 3.7423728813559323e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [2:01:38<1:13:25,  2.00s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [2:01:39<1:12:02,  1.96s/it]                                                       {'loss': 0.0611, 'grad_norm': 4.43299674987793, 'learning_rate': 3.740677966101695e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [2:01:39<1:12:02,  1.96s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [2:01:41<1:11:31,  1.95s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.2078638076782227, 'learning_rate': 3.738983050847458e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [2:01:41<1:11:31,  1.95s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [2:01:43<1:10:24,  1.92s/it]                                                       {'loss': 0.1034, 'grad_norm': 3.4055933952331543, 'learning_rate': 3.7372881355932204e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [2:01:43<1:10:24,  1.92s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [2:01:45<1:11:06,  1.94s/it]                                                       {'loss': 0.0472, 'grad_norm': 6.992197513580322, 'learning_rate': 3.7355932203389833e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [2:01:45<1:11:06,  1.94s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [2:01:47<1:10:13,  1.91s/it]                                                       {'loss': 0.0198, 'grad_norm': 2.407649278640747, 'learning_rate': 3.733898305084746e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [2:01:47<1:10:13,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [2:01:49<1:09:58,  1.91s/it]                                                       {'loss': 0.108, 'grad_norm': 11.714898109436035, 'learning_rate': 3.732203389830509e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [2:01:49<1:09:58,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [2:01:51<1:09:34,  1.90s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.6143888235092163, 'learning_rate': 3.7305084745762714e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [2:01:51<1:09:34,  1.90s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [2:01:53<1:09:11,  1.89s/it]                                                       {'loss': 0.1081, 'grad_norm': 7.012845039367676, 'learning_rate': 3.7288135593220342e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [2:01:53<1:09:11,  1.89s/it][2025-11-11 23:55:08,628] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3800
[2025-11-11 23:55:08,635] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:55:08,907] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [2:01:55<1:17:53,  2.13s/it]                                                       {'loss': 0.0405, 'grad_norm': 3.8991546630859375, 'learning_rate': 3.727118644067797e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [2:01:55<1:17:53,  2.13s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [2:01:57<1:15:00,  2.05s/it]                                                       {'loss': 0.19, 'grad_norm': 10.311193466186523, 'learning_rate': 3.72542372881356e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [2:01:57<1:15:00,  2.05s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [2:01:59<1:13:05,  2.00s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.9778354167938232, 'learning_rate': 3.7237288135593224e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [2:01:59<1:13:05,  2.00s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [2:02:01<1:11:52,  1.96s/it]                                                       {'loss': 0.0383, 'grad_norm': 2.7485263347625732, 'learning_rate': 3.7220338983050852e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [2:02:01<1:11:52,  1.96s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [2:02:03<1:12:23,  1.98s/it]                                                       {'loss': 0.0126, 'grad_norm': 2.087865114212036, 'learning_rate': 3.720338983050848e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [2:02:03<1:12:23,  1.98s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [2:02:05<1:11:14,  1.95s/it]                                                       {'loss': 0.0828, 'grad_norm': 5.527604103088379, 'learning_rate': 3.7186440677966105e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [2:02:05<1:11:14,  1.95s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [2:02:07<1:10:03,  1.92s/it]                                                       {'loss': 0.1011, 'grad_norm': 5.412714004516602, 'learning_rate': 3.7169491525423733e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [2:02:07<1:10:03,  1.92s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [2:02:09<1:09:38,  1.91s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02075154148042202, 'learning_rate': 3.715254237288136e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [2:02:09<1:09:38,  1.91s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [2:02:11<1:13:42,  2.02s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.166135549545288, 'learning_rate': 3.713559322033898e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [2:02:11<1:13:42,  2.02s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [2:02:13<1:11:58,  1.97s/it]                                                       {'loss': 0.0895, 'grad_norm': 6.876204490661621, 'learning_rate': 3.711864406779661e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [2:02:13<1:11:58,  1.97s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [2:02:15<1:10:46,  1.94s/it]                                                       {'loss': 0.0491, 'grad_norm': 5.101048946380615, 'learning_rate': 3.710169491525424e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [2:02:15<1:10:46,  1.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [2:02:17<1:10:38,  1.94s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.19603422284126282, 'learning_rate': 3.7084745762711867e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [2:02:17<1:10:38,  1.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [2:02:18<1:10:24,  1.93s/it]                                                       {'loss': 0.0274, 'grad_norm': 3.492708206176758, 'learning_rate': 3.706779661016949e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [2:02:18<1:10:24,  1.93s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [2:02:20<1:10:12,  1.93s/it]                                                       {'loss': 0.0375, 'grad_norm': 4.249381065368652, 'learning_rate': 3.705084745762712e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [2:02:20<1:10:12,  1.93s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [2:02:22<1:09:44,  1.92s/it]                                                       {'loss': 0.0145, 'grad_norm': 2.615963935852051, 'learning_rate': 3.703389830508475e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [2:02:22<1:09:44,  1.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [2:02:24<1:08:45,  1.89s/it]                                                       {'loss': 0.1255, 'grad_norm': 6.9080071449279785, 'learning_rate': 3.7016949152542377e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [2:02:24<1:08:45,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [2:02:26<1:08:58,  1.90s/it]                                                       {'loss': 0.141, 'grad_norm': 11.328859329223633, 'learning_rate': 3.7e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [2:02:26<1:08:58,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [2:02:28<1:08:35,  1.89s/it]                                                       {'loss': 0.0456, 'grad_norm': 3.8322248458862305, 'learning_rate': 3.698305084745763e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [2:02:28<1:08:35,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [2:02:30<1:08:21,  1.88s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.7340688705444336, 'learning_rate': 3.696610169491526e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [2:02:30<1:08:21,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [2:02:32<1:08:13,  1.88s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10469899326562881, 'learning_rate': 3.6949152542372883e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [2:02:32<1:08:13,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [2:02:34<1:08:22,  1.88s/it]                                                       {'loss': 0.0515, 'grad_norm': 1.7552917003631592, 'learning_rate': 3.693220338983051e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [2:02:34<1:08:22,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [2:02:35<1:08:26,  1.89s/it]                                                       {'loss': 0.1213, 'grad_norm': 4.978272438049316, 'learning_rate': 3.691525423728814e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [2:02:35<1:08:26,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [2:02:37<1:09:00,  1.90s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.8123676776885986, 'learning_rate': 3.689830508474577e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [2:02:37<1:09:00,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [2:02:39<1:08:45,  1.90s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.1469571441411972, 'learning_rate': 3.6881355932203393e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [2:02:39<1:08:45,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [2:02:41<1:08:43,  1.90s/it]                                                       {'loss': 0.0896, 'grad_norm': 5.494831562042236, 'learning_rate': 3.686440677966102e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [2:02:41<1:08:43,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [2:02:43<1:08:09,  1.88s/it]                                                       {'loss': 0.1304, 'grad_norm': 8.844012260437012, 'learning_rate': 3.684745762711865e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [2:02:43<1:08:09,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [2:02:45<1:08:11,  1.88s/it]                                                       {'loss': 0.1146, 'grad_norm': 7.8753156661987305, 'learning_rate': 3.683050847457628e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [2:02:45<1:08:11,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [2:02:47<1:08:05,  1.88s/it]                                                       {'loss': 0.071, 'grad_norm': 4.290650367736816, 'learning_rate': 3.6813559322033902e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [2:02:47<1:08:05,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [2:02:49<1:08:02,  1.88s/it]                                                       {'loss': 0.0541, 'grad_norm': 3.4908957481384277, 'learning_rate': 3.679661016949153e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [2:02:49<1:08:02,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [2:02:51<1:08:02,  1.88s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.3069749176502228, 'learning_rate': 3.6779661016949155e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [2:02:51<1:08:02,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [2:02:52<1:08:10,  1.89s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2475113421678543, 'learning_rate': 3.676271186440678e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [2:02:52<1:08:10,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [2:02:54<1:08:10,  1.89s/it]                                                       {'loss': 0.0896, 'grad_norm': 7.629817485809326, 'learning_rate': 3.6745762711864408e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [2:02:54<1:08:10,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [2:02:56<1:09:15,  1.92s/it]                                                       {'loss': 0.0137, 'grad_norm': 1.8812661170959473, 'learning_rate': 3.6728813559322036e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [2:02:56<1:09:15,  1.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [2:02:58<1:08:32,  1.90s/it]                                                       {'loss': 0.1108, 'grad_norm': 8.956351280212402, 'learning_rate': 3.671186440677966e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [2:02:58<1:08:32,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [2:03:00<1:09:56,  1.94s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7453577518463135, 'learning_rate': 3.669491525423729e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [2:03:00<1:09:56,  1.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [2:03:02<1:08:53,  1.91s/it]                                                       {'loss': 0.0695, 'grad_norm': 3.232391834259033, 'learning_rate': 3.6677966101694918e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [2:03:02<1:08:53,  1.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [2:03:04<1:08:13,  1.89s/it]                                                       {'loss': 0.1612, 'grad_norm': 9.52982234954834, 'learning_rate': 3.6661016949152546e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [2:03:04<1:08:13,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [2:03:06<1:07:37,  1.88s/it]                                                       {'loss': 0.0757, 'grad_norm': 8.545207023620605, 'learning_rate': 3.664406779661017e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [2:03:06<1:07:37,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [2:03:08<1:08:24,  1.90s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.859282374382019, 'learning_rate': 3.66271186440678e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [2:03:08<1:08:24,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [2:03:10<1:07:45,  1.88s/it]                                                       {'loss': 0.1008, 'grad_norm': 5.7122931480407715, 'learning_rate': 3.6610169491525427e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [2:03:10<1:07:45,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [2:03:12<1:09:08,  1.92s/it]                                                       {'loss': 0.1543, 'grad_norm': 10.872429847717285, 'learning_rate': 3.6593220338983056e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [2:03:12<1:09:08,  1.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [2:03:13<1:09:25,  1.93s/it]                                                       {'loss': 0.175, 'grad_norm': 10.44396686553955, 'learning_rate': 3.657627118644068e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [2:03:13<1:09:25,  1.93s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [2:03:15<1:08:37,  1.91s/it]                                                       {'loss': 0.1074, 'grad_norm': 6.5969414710998535, 'learning_rate': 3.655932203389831e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [2:03:15<1:08:37,  1.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [2:03:17<1:08:36,  1.91s/it]                                                       {'loss': 0.2763, 'grad_norm': 8.30981159210205, 'learning_rate': 3.6542372881355937e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [2:03:17<1:08:36,  1.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [2:03:19<1:08:36,  1.91s/it]                                                       {'loss': 0.1086, 'grad_norm': 9.276451110839844, 'learning_rate': 3.6525423728813566e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [2:03:19<1:08:36,  1.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [2:03:21<1:09:37,  1.94s/it]                                                       {'loss': 0.1419, 'grad_norm': 9.912030220031738, 'learning_rate': 3.650847457627119e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [2:03:21<1:09:37,  1.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [2:03:23<1:08:45,  1.92s/it]                                                       {'loss': 0.0293, 'grad_norm': 2.7980270385742188, 'learning_rate': 3.649152542372882e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [2:03:23<1:08:45,  1.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [2:03:25<1:08:02,  1.90s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.6927787661552429, 'learning_rate': 3.6474576271186447e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [2:03:25<1:08:02,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [2:03:27<1:07:23,  1.88s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07536230236291885, 'learning_rate': 3.6457627118644075e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [2:03:27<1:07:23,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [2:03:29<1:08:02,  1.90s/it]                                                       {'loss': 0.1666, 'grad_norm': 7.1312408447265625, 'learning_rate': 3.6440677966101695e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [2:03:29<1:08:02,  1.90s/it][2025-11-11 23:56:44,579] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3850
[2025-11-11 23:56:44,586] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:56:44,877] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3850/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [2:03:31<1:17:08,  2.15s/it]                                                       {'loss': 0.074, 'grad_norm': 6.839187145233154, 'learning_rate': 3.6423728813559324e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [2:03:31<1:17:08,  2.15s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [2:03:33<1:14:38,  2.08s/it]                                                       {'loss': 0.024, 'grad_norm': 2.0559699535369873, 'learning_rate': 3.640677966101695e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [2:03:33<1:14:38,  2.08s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [2:03:35<1:12:16,  2.02s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.47116586565971375, 'learning_rate': 3.6389830508474577e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [2:03:35<1:12:16,  2.02s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [2:03:37<1:10:40,  1.98s/it]                                                       {'loss': 0.1141, 'grad_norm': 10.375950813293457, 'learning_rate': 3.6372881355932205e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [2:03:37<1:10:40,  1.98s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [2:03:39<1:10:10,  1.96s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.6974772214889526, 'learning_rate': 3.6355932203389834e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [2:03:39<1:10:10,  1.96s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [2:03:41<1:09:41,  1.95s/it]                                                       {'loss': 0.2572, 'grad_norm': 10.80655574798584, 'learning_rate': 3.633898305084746e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [2:03:41<1:09:41,  1.95s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [2:03:43<1:08:43,  1.92s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08603167533874512, 'learning_rate': 3.6322033898305086e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [2:03:43<1:08:43,  1.92s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [2:03:45<1:08:05,  1.91s/it]                                                       {'loss': 0.0901, 'grad_norm': 5.068120002746582, 'learning_rate': 3.6305084745762715e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [2:03:45<1:08:05,  1.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [2:03:47<1:08:05,  1.91s/it]                                                       {'loss': 0.0971, 'grad_norm': 12.35423755645752, 'learning_rate': 3.6288135593220343e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [2:03:47<1:08:05,  1.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [2:03:48<1:07:06,  1.88s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.4053997993469238, 'learning_rate': 3.6271186440677968e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [2:03:48<1:07:06,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [2:03:50<1:07:13,  1.89s/it]                                                       {'loss': 0.2322, 'grad_norm': 8.57600212097168, 'learning_rate': 3.6254237288135596e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [2:03:50<1:07:13,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [2:03:52<1:06:54,  1.88s/it]                                                       {'loss': 0.1169, 'grad_norm': 6.710795879364014, 'learning_rate': 3.6237288135593225e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [2:03:52<1:06:54,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [2:03:54<1:07:28,  1.89s/it]                                                       {'loss': 0.0446, 'grad_norm': 4.515286445617676, 'learning_rate': 3.6220338983050853e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [2:03:54<1:07:28,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [2:03:56<1:07:38,  1.90s/it]                                                       {'loss': 0.1273, 'grad_norm': 7.330775260925293, 'learning_rate': 3.6203389830508478e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [2:03:56<1:07:38,  1.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [2:03:58<1:07:03,  1.88s/it]                                                       {'loss': 0.0212, 'grad_norm': 2.715674638748169, 'learning_rate': 3.6186440677966106e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [2:03:58<1:07:03,  1.88s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [2:04:00<1:07:05,  1.89s/it]                                                       {'loss': 0.06, 'grad_norm': 5.271995544433594, 'learning_rate': 3.6169491525423735e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [2:04:00<1:07:05,  1.89s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [2:04:02<1:14:26,  2.09s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.27195537090301514, 'learning_rate': 3.615254237288136e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [2:04:02<1:14:26,  2.09s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [2:04:04<1:12:21,  2.04s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.613498866558075, 'learning_rate': 3.6135593220338987e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [2:04:04<1:12:21,  2.04s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [2:04:06<1:10:24,  1.98s/it]                                                       {'loss': 0.0318, 'grad_norm': 4.147412300109863, 'learning_rate': 3.6118644067796616e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [2:04:06<1:10:24,  1.98s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [2:04:08<1:09:19,  1.95s/it]                                                       {'loss': 0.0232, 'grad_norm': 2.657651901245117, 'learning_rate': 3.6101694915254244e-06, 'epoch': 0.65}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [2:04:08<1:09:19,  1.95s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [2:04:10<1:08:27,  1.93s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.241852045059204, 'learning_rate': 3.6084745762711864e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [2:04:10<1:08:27,  1.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [2:04:12<1:07:37,  1.91s/it]                                                       {'loss': 0.0875, 'grad_norm': 8.488836288452148, 'learning_rate': 3.6067796610169493e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [2:04:12<1:07:37,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [2:04:14<1:07:20,  1.90s/it]                                                       {'loss': 0.0301, 'grad_norm': 2.2886433601379395, 'learning_rate': 3.605084745762712e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [2:04:14<1:07:20,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [2:04:15<1:06:42,  1.88s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.0868055820465088, 'learning_rate': 3.6033898305084746e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [2:04:15<1:06:42,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [2:04:17<1:06:31,  1.88s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.6370075941085815, 'learning_rate': 3.6016949152542374e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [2:04:17<1:06:31,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [2:04:19<1:06:37,  1.88s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.5161599516868591, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [2:04:19<1:06:37,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [2:04:21<1:06:15,  1.87s/it]                                                       {'loss': 0.1204, 'grad_norm': 7.992040157318115, 'learning_rate': 3.598305084745763e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [2:04:21<1:06:15,  1.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [2:04:23<1:07:36,  1.91s/it]                                                       {'loss': 0.0167, 'grad_norm': 2.7320332527160645, 'learning_rate': 3.5966101694915255e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [2:04:23<1:07:36,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [2:04:25<1:07:05,  1.90s/it]                                                       {'loss': 0.0359, 'grad_norm': 2.7427735328674316, 'learning_rate': 3.5949152542372884e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [2:04:25<1:07:05,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [2:04:27<1:08:05,  1.93s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.061065636575222015, 'learning_rate': 3.5932203389830512e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [2:04:27<1:08:05,  1.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [2:04:29<1:08:01,  1.93s/it]                                                       {'loss': 0.2244, 'grad_norm': 11.393919944763184, 'learning_rate': 3.5915254237288137e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [2:04:29<1:08:01,  1.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [2:04:31<1:07:07,  1.90s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.0234811305999756, 'learning_rate': 3.5898305084745765e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [2:04:31<1:07:07,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [2:04:33<1:07:49,  1.92s/it]                                                       {'loss': 0.1303, 'grad_norm': 6.682537078857422, 'learning_rate': 3.5881355932203394e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [2:04:33<1:07:49,  1.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [2:04:34<1:07:13,  1.91s/it]                                                       {'loss': 0.0809, 'grad_norm': 7.181453704833984, 'learning_rate': 3.5864406779661022e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [2:04:34<1:07:13,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [2:04:36<1:07:22,  1.91s/it]                                                       {'loss': 0.044, 'grad_norm': 3.014528751373291, 'learning_rate': 3.5847457627118646e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [2:04:36<1:07:22,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [2:04:38<1:06:34,  1.89s/it]                                                       {'loss': 0.002, 'grad_norm': 0.31595563888549805, 'learning_rate': 3.5830508474576275e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [2:04:38<1:06:34,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [2:04:40<1:07:29,  1.92s/it]                                                       {'loss': 0.191, 'grad_norm': 8.681923866271973, 'learning_rate': 3.5813559322033903e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [2:04:40<1:07:29,  1.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [2:04:42<1:09:06,  1.96s/it]                                                       {'loss': 0.1209, 'grad_norm': 7.673933029174805, 'learning_rate': 3.579661016949153e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [2:04:42<1:09:06,  1.96s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [2:04:44<1:09:34,  1.98s/it]                                                       {'loss': 0.1198, 'grad_norm': 7.402773380279541, 'learning_rate': 3.5779661016949156e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [2:04:44<1:09:34,  1.98s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [2:04:46<1:08:38,  1.95s/it]                                                       {'loss': 0.0279, 'grad_norm': 4.501003265380859, 'learning_rate': 3.5762711864406785e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [2:04:46<1:08:38,  1.95s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [2:04:48<1:07:46,  1.93s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.472960352897644, 'learning_rate': 3.5745762711864413e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [2:04:48<1:07:46,  1.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [2:04:50<1:07:12,  1.91s/it]                                                       {'loss': 0.2255, 'grad_norm': 10.882059097290039, 'learning_rate': 3.5728813559322033e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [2:04:50<1:07:12,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [2:04:52<1:07:36,  1.93s/it]                                                       {'loss': 0.0361, 'grad_norm': 3.62253737449646, 'learning_rate': 3.571186440677966e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [2:04:52<1:07:36,  1.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [2:04:54<1:07:15,  1.92s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.12424398213624954, 'learning_rate': 3.569491525423729e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [2:04:54<1:07:15,  1.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [2:04:56<1:06:44,  1.90s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.0273202657699585, 'learning_rate': 3.5677966101694914e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [2:04:56<1:06:44,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [2:04:58<1:06:27,  1.90s/it]                                                       {'loss': 0.0398, 'grad_norm': 5.177497863769531, 'learning_rate': 3.5661016949152543e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [2:04:58<1:06:27,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [2:04:59<1:05:48,  1.88s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.451364278793335, 'learning_rate': 3.564406779661017e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [2:04:59<1:05:48,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [2:05:01<1:05:53,  1.88s/it]                                                       {'loss': 0.0557, 'grad_norm': 6.872875690460205, 'learning_rate': 3.56271186440678e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [2:05:01<1:05:53,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [2:05:03<1:05:36,  1.87s/it]                                                       {'loss': 0.1715, 'grad_norm': 8.121698379516602, 'learning_rate': 3.5610169491525424e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [2:05:03<1:05:36,  1.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [2:05:05<1:05:44,  1.88s/it]                                                       {'loss': 0.0473, 'grad_norm': 4.130033493041992, 'learning_rate': 3.5593220338983053e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [2:05:05<1:05:44,  1.88s/it][2025-11-11 23:58:20,937] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3900
[2025-11-11 23:58:20,944] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:58:21,226] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [2:05:08<1:14:49,  2.14s/it]                                                       {'loss': 0.4139, 'grad_norm': 12.237391471862793, 'learning_rate': 3.557627118644068e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [2:05:08<1:14:49,  2.14s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [2:05:10<1:11:58,  2.06s/it]                                                       {'loss': 0.1028, 'grad_norm': 7.086118221282959, 'learning_rate': 3.555932203389831e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [2:05:10<1:11:58,  2.06s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [2:05:11<1:09:41,  1.99s/it]                                                       {'loss': 0.192, 'grad_norm': 7.084402084350586, 'learning_rate': 3.5542372881355934e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [2:05:11<1:09:41,  1.99s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [2:05:13<1:08:29,  1.96s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.9736161231994629, 'learning_rate': 3.5525423728813563e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [2:05:13<1:08:29,  1.96s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [2:05:15<1:07:21,  1.93s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.16135533154010773, 'learning_rate': 3.550847457627119e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [2:05:15<1:07:21,  1.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [2:05:17<1:06:53,  1.92s/it]                                                       {'loss': 0.0655, 'grad_norm': 4.6319146156311035, 'learning_rate': 3.549152542372882e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [2:05:17<1:06:53,  1.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [2:05:19<1:06:25,  1.90s/it]                                                       {'loss': 0.0879, 'grad_norm': 8.154207229614258, 'learning_rate': 3.5474576271186444e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [2:05:19<1:06:25,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [2:05:21<1:05:51,  1.89s/it]                                                       {'loss': 0.1107, 'grad_norm': 5.413740158081055, 'learning_rate': 3.5457627118644072e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [2:05:21<1:05:51,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [2:05:23<1:05:26,  1.88s/it]                                                       {'loss': 0.0619, 'grad_norm': 4.915811061859131, 'learning_rate': 3.54406779661017e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [2:05:23<1:05:26,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [2:05:25<1:04:46,  1.86s/it]                                                       {'loss': 0.0638, 'grad_norm': 6.6693315505981445, 'learning_rate': 3.5423728813559325e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [2:05:25<1:04:46,  1.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [2:05:26<1:04:36,  1.86s/it]                                                       {'loss': 0.076, 'grad_norm': 4.519235134124756, 'learning_rate': 3.5406779661016954e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [2:05:26<1:04:36,  1.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [2:05:28<1:05:00,  1.87s/it]                                                       {'loss': 0.1385, 'grad_norm': 8.21192455291748, 'learning_rate': 3.538983050847458e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [2:05:28<1:05:00,  1.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [2:05:30<1:05:10,  1.87s/it]                                                       {'loss': 0.0097, 'grad_norm': 2.1070749759674072, 'learning_rate': 3.53728813559322e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [2:05:30<1:05:10,  1.87s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [2:05:32<1:04:29,  1.86s/it]                                                       {'loss': 0.0468, 'grad_norm': 2.763009786605835, 'learning_rate': 3.535593220338983e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [2:05:32<1:04:29,  1.86s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [2:05:34<1:05:56,  1.90s/it]                                                       {'loss': 0.1539, 'grad_norm': 10.524812698364258, 'learning_rate': 3.533898305084746e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [2:05:34<1:05:56,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [2:05:36<1:05:46,  1.89s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.3035688400268555, 'learning_rate': 3.5322033898305088e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [2:05:36<1:05:46,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [2:05:38<1:05:24,  1.88s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3203658163547516, 'learning_rate': 3.530508474576271e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [2:05:38<1:05:24,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [2:05:40<1:05:37,  1.89s/it]                                                       {'loss': 0.0272, 'grad_norm': 5.0989460945129395, 'learning_rate': 3.528813559322034e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [2:05:40<1:05:37,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [2:05:41<1:05:20,  1.88s/it]                                                       {'loss': 0.2242, 'grad_norm': 8.458404541015625, 'learning_rate': 3.527118644067797e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [2:05:41<1:05:20,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [2:05:43<1:05:11,  1.88s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07808895409107208, 'learning_rate': 3.5254237288135597e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [2:05:43<1:05:11,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [2:05:45<1:05:09,  1.88s/it]                                                       {'loss': 0.0481, 'grad_norm': 2.0850906372070312, 'learning_rate': 3.523728813559322e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [2:05:45<1:05:09,  1.88s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [2:05:47<1:05:29,  1.89s/it]                                                       {'loss': 0.0491, 'grad_norm': 2.104259967803955, 'learning_rate': 3.522033898305085e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [2:05:47<1:05:29,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [2:05:49<1:05:55,  1.90s/it]                                                       {'loss': 0.0691, 'grad_norm': 5.625559329986572, 'learning_rate': 3.520338983050848e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [2:05:49<1:05:55,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [2:05:51<1:05:28,  1.89s/it]                                                       {'loss': 0.0386, 'grad_norm': 3.8749117851257324, 'learning_rate': 3.5186440677966103e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [2:05:51<1:05:28,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [2:05:53<1:06:05,  1.91s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5706214308738708, 'learning_rate': 3.516949152542373e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [2:05:53<1:06:05,  1.91s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [2:05:55<1:06:16,  1.92s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.026212777942419052, 'learning_rate': 3.515254237288136e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [2:05:55<1:06:16,  1.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [2:05:57<1:05:38,  1.90s/it]                                                       {'loss': 0.0784, 'grad_norm': 5.879687786102295, 'learning_rate': 3.513559322033899e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [2:05:57<1:05:38,  1.90s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [2:05:59<1:05:07,  1.89s/it]                                                       {'loss': 0.011, 'grad_norm': 1.750259280204773, 'learning_rate': 3.5118644067796613e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [2:05:59<1:05:07,  1.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [2:06:01<1:06:02,  1.91s/it]                                                       {'loss': 0.0431, 'grad_norm': 4.647675514221191, 'learning_rate': 3.510169491525424e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [2:06:01<1:06:02,  1.91s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [2:06:02<1:05:22,  1.89s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.067741870880127, 'learning_rate': 3.508474576271187e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [2:06:02<1:05:22,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [2:06:04<1:05:19,  1.89s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9551370143890381, 'learning_rate': 3.50677966101695e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [2:06:04<1:05:19,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [2:06:06<1:06:14,  1.92s/it]                                                       {'loss': 0.1186, 'grad_norm': 8.7145357131958, 'learning_rate': 3.5050847457627122e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [2:06:06<1:06:14,  1.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [2:06:08<1:05:34,  1.90s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.7650136351585388, 'learning_rate': 3.5033898305084747e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [2:06:08<1:05:34,  1.90s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [2:06:10<1:05:17,  1.90s/it]                                                       {'loss': 0.1728, 'grad_norm': 9.246142387390137, 'learning_rate': 3.5016949152542375e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [2:06:10<1:05:17,  1.90s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [2:06:12<1:05:04,  1.89s/it]                                                       {'loss': 0.0349, 'grad_norm': 3.795358180999756, 'learning_rate': 3.5e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [2:06:12<1:05:04,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [2:06:14<1:04:45,  1.88s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.4386122226715088, 'learning_rate': 3.498305084745763e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [2:06:14<1:04:45,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [2:06:16<1:04:58,  1.89s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.8509789705276489, 'learning_rate': 3.4966101694915256e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [2:06:16<1:04:58,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [2:06:17<1:04:38,  1.88s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.048146456480026245, 'learning_rate': 3.494915254237288e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [2:06:17<1:04:38,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [2:06:19<1:04:47,  1.89s/it]                                                       {'loss': 0.0999, 'grad_norm': 11.294386863708496, 'learning_rate': 3.493220338983051e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [2:06:19<1:04:47,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [2:06:21<1:04:19,  1.87s/it]                                                       {'loss': 0.0769, 'grad_norm': 4.481810569763184, 'learning_rate': 3.4915254237288138e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [2:06:21<1:04:19,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [2:06:23<1:04:38,  1.88s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.11757514625787735, 'learning_rate': 3.4898305084745766e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [2:06:23<1:04:38,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [2:06:25<1:04:33,  1.88s/it]                                                       {'loss': 0.24, 'grad_norm': 10.29510498046875, 'learning_rate': 3.488135593220339e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [2:06:25<1:04:33,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [2:06:27<1:04:48,  1.89s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.014691188000142574, 'learning_rate': 3.486440677966102e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [2:06:27<1:04:48,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [2:06:29<1:04:09,  1.87s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.3551907539367676, 'learning_rate': 3.4847457627118648e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [2:06:29<1:04:09,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [2:06:31<1:03:49,  1.86s/it]                                                       {'loss': 0.1683, 'grad_norm': 11.364198684692383, 'learning_rate': 3.4830508474576276e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [2:06:31<1:03:49,  1.86s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [2:06:32<1:03:45,  1.86s/it]                                                       {'loss': 0.0594, 'grad_norm': 5.4949140548706055, 'learning_rate': 3.48135593220339e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [2:06:32<1:03:45,  1.86s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [2:06:34<1:03:31,  1.86s/it]                                                       {'loss': 0.0612, 'grad_norm': 7.32425594329834, 'learning_rate': 3.479661016949153e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [2:06:34<1:03:31,  1.86s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [2:06:36<1:03:20,  1.85s/it]                                                       {'loss': 0.0126, 'grad_norm': 2.3054628372192383, 'learning_rate': 3.4779661016949157e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [2:06:36<1:03:20,  1.85s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [2:06:38<1:04:01,  1.87s/it]                                                       {'loss': 0.0824, 'grad_norm': 5.448208808898926, 'learning_rate': 3.4762711864406786e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [2:06:38<1:04:01,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [2:06:40<1:03:45,  1.87s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.8295536637306213, 'learning_rate': 3.474576271186441e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [2:06:40<1:03:45,  1.87s/it][2025-11-11 23:59:55,835] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3950
[2025-11-11 23:59:55,842] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-11 23:59:56,124] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3950/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [2:06:43<1:12:09,  2.11s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.5532742142677307, 'learning_rate': 3.472881355932204e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [2:06:43<1:12:09,  2.11s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [2:06:44<1:09:28,  2.04s/it]                                                       {'loss': 0.0534, 'grad_norm': 5.926016807556152, 'learning_rate': 3.4711864406779667e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [2:06:44<1:09:28,  2.04s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [2:06:46<1:07:39,  1.98s/it]                                                       {'loss': 0.0319, 'grad_norm': 2.481943130493164, 'learning_rate': 3.4694915254237296e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [2:06:46<1:07:39,  1.98s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [2:06:48<1:06:46,  1.96s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.2301360368728638, 'learning_rate': 3.4677966101694916e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [2:06:48<1:06:46,  1.96s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [2:06:50<1:07:39,  1.99s/it]                                                       {'loss': 0.0436, 'grad_norm': 3.934147834777832, 'learning_rate': 3.4661016949152544e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [2:06:50<1:07:39,  1.99s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [2:06:52<1:06:56,  1.97s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.2976505756378174, 'learning_rate': 3.464406779661017e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [2:06:52<1:06:56,  1.97s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [2:06:54<1:06:40,  1.96s/it]                                                       {'loss': 0.0247, 'grad_norm': 3.9340755939483643, 'learning_rate': 3.4627118644067797e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [2:06:54<1:06:40,  1.96s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [2:06:56<1:05:59,  1.94s/it]                                                       {'loss': 0.0422, 'grad_norm': 2.481475591659546, 'learning_rate': 3.4610169491525425e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [2:06:56<1:05:59,  1.94s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [2:06:58<1:05:12,  1.92s/it]                                                       {'loss': 0.0388, 'grad_norm': 5.732201099395752, 'learning_rate': 3.4593220338983054e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [2:06:58<1:05:12,  1.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [2:07:00<1:04:58,  1.91s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3009265959262848, 'learning_rate': 3.457627118644068e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [2:07:00<1:04:58,  1.91s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [2:07:02<1:04:31,  1.90s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3579232692718506, 'learning_rate': 3.4559322033898307e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [2:07:02<1:04:31,  1.90s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [2:07:04<1:04:17,  1.89s/it]                                                       {'loss': 0.184, 'grad_norm': 10.07541561126709, 'learning_rate': 3.4542372881355935e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [2:07:04<1:04:17,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [2:07:05<1:03:42,  1.88s/it]                                                       {'loss': 0.14, 'grad_norm': 8.737546920776367, 'learning_rate': 3.4525423728813564e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [2:07:05<1:03:42,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [2:07:07<1:03:33,  1.87s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.8446885347366333, 'learning_rate': 3.450847457627119e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [2:07:07<1:03:33,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [2:07:09<1:03:39,  1.88s/it]                                                       {'loss': 0.1198, 'grad_norm': 8.400108337402344, 'learning_rate': 3.4491525423728816e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [2:07:09<1:03:39,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [2:07:11<1:03:21,  1.87s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5141010880470276, 'learning_rate': 3.4474576271186445e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [2:07:11<1:03:21,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [2:07:13<1:03:17,  1.87s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.19021418690681458, 'learning_rate': 3.4457627118644073e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [2:07:13<1:03:17,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [2:07:15<1:03:50,  1.89s/it]                                                       {'loss': 0.0801, 'grad_norm': 5.079336166381836, 'learning_rate': 3.4440677966101698e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [2:07:15<1:03:50,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [2:07:17<1:03:23,  1.87s/it]                                                       {'loss': 0.4317, 'grad_norm': 9.676807403564453, 'learning_rate': 3.4423728813559326e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [2:07:17<1:03:23,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [2:07:19<1:05:02,  1.92s/it]                                                       {'loss': 0.3623, 'grad_norm': 8.27645492553711, 'learning_rate': 3.4406779661016955e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [2:07:19<1:05:02,  1.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [2:07:21<1:05:02,  1.92s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3106161653995514, 'learning_rate': 3.438983050847458e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [2:07:21<1:05:02,  1.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [2:07:22<1:04:18,  1.90s/it]                                                       {'loss': 0.0429, 'grad_norm': 2.504040479660034, 'learning_rate': 3.4372881355932207e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [2:07:22<1:04:18,  1.90s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [2:07:24<1:04:26,  1.91s/it]                                                       {'loss': 0.0394, 'grad_norm': 3.9876229763031006, 'learning_rate': 3.4355932203389836e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [2:07:24<1:04:26,  1.91s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [2:07:26<1:03:33,  1.88s/it]                                                       {'loss': 0.0547, 'grad_norm': 4.210385799407959, 'learning_rate': 3.4338983050847464e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [2:07:26<1:03:33,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [2:07:28<1:03:49,  1.89s/it]                                                       {'loss': 0.0563, 'grad_norm': 5.638676643371582, 'learning_rate': 3.4322033898305084e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [2:07:28<1:03:49,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [2:07:30<1:03:47,  1.89s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.026847951114177704, 'learning_rate': 3.4305084745762713e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [2:07:30<1:03:47,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [2:07:32<1:03:52,  1.89s/it]                                                       {'loss': 0.006, 'grad_norm': 1.588945984840393, 'learning_rate': 3.428813559322034e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [2:07:32<1:03:52,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [2:07:34<1:03:18,  1.88s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.8816471099853516, 'learning_rate': 3.4271186440677966e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [2:07:34<1:03:18,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [2:07:36<1:03:19,  1.88s/it]                                                       {'loss': 0.0865, 'grad_norm': 5.469764232635498, 'learning_rate': 3.4254237288135594e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [2:07:36<1:03:19,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [2:07:37<1:03:04,  1.87s/it]                                                       {'loss': 0.17, 'grad_norm': 8.963869094848633, 'learning_rate': 3.4237288135593223e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [2:07:37<1:03:04,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [2:07:39<1:02:44,  1.86s/it]                                                       {'loss': 0.0715, 'grad_norm': 5.536758899688721, 'learning_rate': 3.422033898305085e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [2:07:39<1:02:44,  1.86s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [2:07:41<1:02:39,  1.86s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.210411787033081, 'learning_rate': 3.4203389830508476e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [2:07:41<1:02:39,  1.86s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [2:07:43<1:03:10,  1.88s/it]                                                       {'loss': 0.0378, 'grad_norm': 6.247272491455078, 'learning_rate': 3.4186440677966104e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [2:07:43<1:03:10,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [2:07:45<1:02:50,  1.87s/it]                                                       {'loss': 0.0738, 'grad_norm': 3.9071764945983887, 'learning_rate': 3.4169491525423733e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [2:07:45<1:02:50,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [2:07:47<1:02:50,  1.87s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5727217793464661, 'learning_rate': 3.4152542372881357e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [2:07:47<1:02:50,  1.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [2:07:49<1:03:09,  1.88s/it]                                                       {'loss': 0.0602, 'grad_norm': 2.139225959777832, 'learning_rate': 3.4135593220338985e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [2:07:49<1:03:09,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [2:07:51<1:03:32,  1.89s/it]                                                       {'loss': 0.0279, 'grad_norm': 2.186992883682251, 'learning_rate': 3.4118644067796614e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [2:07:51<1:03:32,  1.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [2:07:52<1:03:08,  1.88s/it]                                                       {'loss': 0.1376, 'grad_norm': 6.808410167694092, 'learning_rate': 3.4101694915254242e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [2:07:52<1:03:08,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [2:07:54<1:03:08,  1.88s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.25952020287513733, 'learning_rate': 3.4084745762711867e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [2:07:54<1:03:08,  1.88s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [2:07:56<1:03:21,  1.89s/it]                                                       {'loss': 0.0332, 'grad_norm': 3.597853422164917, 'learning_rate': 3.4067796610169495e-06, 'epoch': 0.67}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [2:07:56<1:03:21,  1.89s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [2:07:58<1:02:45,  1.87s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4707784354686737, 'learning_rate': 3.4050847457627124e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [2:07:58<1:02:45,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [2:08:00<1:02:40,  1.87s/it]                                                       {'loss': 0.0173, 'grad_norm': 3.237910747528076, 'learning_rate': 3.403389830508475e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [2:08:00<1:02:40,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [2:08:02<1:02:49,  1.88s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.5963964462280273, 'learning_rate': 3.4016949152542376e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [2:08:02<1:02:49,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [2:08:04<1:06:31,  1.99s/it]                                                       {'loss': 0.0181, 'grad_norm': 3.099491596221924, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [2:08:04<1:06:31,  1.99s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [2:08:06<1:05:32,  1.96s/it]                                                       {'loss': 0.0618, 'grad_norm': 5.009790897369385, 'learning_rate': 3.3983050847457633e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [2:08:06<1:05:32,  1.96s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [2:08:08<1:04:05,  1.92s/it]                                                       {'loss': 0.0605, 'grad_norm': 2.0778262615203857, 'learning_rate': 3.3966101694915253e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [2:08:08<1:04:05,  1.92s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [2:08:10<1:03:34,  1.90s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.5260058641433716, 'learning_rate': 3.394915254237288e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [2:08:10<1:03:34,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [2:08:12<1:03:01,  1.89s/it]                                                       {'loss': 0.0158, 'grad_norm': 3.7210469245910645, 'learning_rate': 3.393220338983051e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [2:08:12<1:03:01,  1.89s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [2:08:13<1:02:58,  1.89s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.10541711002588272, 'learning_rate': 3.3915254237288135e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [2:08:13<1:02:58,  1.89s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [2:08:15<1:02:51,  1.89s/it]                                                       {'loss': 0.15, 'grad_norm': 9.752911567687988, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [2:08:15<1:02:51,  1.89s/it][2025-11-12 00:01:31,248] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4000
[2025-11-12 00:01:31,255] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:01:31,539] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [2:08:18<1:10:35,  2.12s/it]                                                       {'loss': 0.0766, 'grad_norm': 8.171238899230957, 'learning_rate': 3.388135593220339e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [2:08:18<1:10:35,  2.12s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [2:08:20<1:07:59,  2.04s/it]                                                       {'loss': 0.0222, 'grad_norm': 1.899624228477478, 'learning_rate': 3.386440677966102e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [2:08:20<1:07:59,  2.04s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [2:08:22<1:06:12,  1.99s/it]                                                       {'loss': 0.1539, 'grad_norm': 8.468689918518066, 'learning_rate': 3.3847457627118644e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [2:08:22<1:06:12,  1.99s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [2:08:24<1:05:11,  1.96s/it]                                                       {'loss': 0.0045, 'grad_norm': 1.1642248630523682, 'learning_rate': 3.3830508474576273e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [2:08:24<1:05:11,  1.96s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [2:08:25<1:04:07,  1.93s/it]                                                       {'loss': 0.0854, 'grad_norm': 3.3444502353668213, 'learning_rate': 3.38135593220339e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [2:08:25<1:04:07,  1.93s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [2:08:27<1:03:12,  1.90s/it]                                                       {'loss': 0.0363, 'grad_norm': 3.6956872940063477, 'learning_rate': 3.379661016949153e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [2:08:27<1:03:12,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [2:08:29<1:02:45,  1.89s/it]                                                       {'loss': 0.0331, 'grad_norm': 2.5726418495178223, 'learning_rate': 3.3779661016949154e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [2:08:29<1:02:45,  1.89s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [2:08:31<1:02:16,  1.88s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.0443075895309448, 'learning_rate': 3.3762711864406783e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [2:08:31<1:02:16,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [2:08:33<1:02:00,  1.87s/it]                                                       {'loss': 0.1769, 'grad_norm': 9.890461921691895, 'learning_rate': 3.374576271186441e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [2:08:33<1:02:00,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [2:08:35<1:02:11,  1.88s/it]                                                       {'loss': 0.0325, 'grad_norm': 4.501620292663574, 'learning_rate': 3.372881355932204e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [2:08:35<1:02:11,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [2:08:37<1:02:22,  1.88s/it]                                                       {'loss': 0.0375, 'grad_norm': 5.5161967277526855, 'learning_rate': 3.3711864406779664e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [2:08:37<1:02:22,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [2:08:39<1:02:05,  1.87s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5082658529281616, 'learning_rate': 3.3694915254237292e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [2:08:39<1:02:05,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [2:08:40<1:01:56,  1.87s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0595703199505806, 'learning_rate': 3.367796610169492e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [2:08:40<1:01:56,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [2:08:42<1:01:39,  1.86s/it]                                                       {'loss': 0.1871, 'grad_norm': 12.248576164245605, 'learning_rate': 3.366101694915255e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [2:08:42<1:01:39,  1.86s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [2:08:44<1:01:43,  1.87s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.6229149699211121, 'learning_rate': 3.3644067796610174e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [2:08:44<1:01:43,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [2:08:46<1:01:43,  1.87s/it]                                                       {'loss': 0.1527, 'grad_norm': 7.409161567687988, 'learning_rate': 3.3627118644067802e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [2:08:46<1:01:43,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [2:08:48<1:01:44,  1.87s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.252996802330017, 'learning_rate': 3.3610169491525422e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [2:08:48<1:01:44,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [2:08:50<1:01:45,  1.87s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.2346512079238892, 'learning_rate': 3.359322033898305e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [2:08:50<1:01:45,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [2:08:52<1:01:45,  1.87s/it]                                                       {'loss': 0.0132, 'grad_norm': 2.5498759746551514, 'learning_rate': 3.357627118644068e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [2:08:52<1:01:45,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [2:08:53<1:01:49,  1.87s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.044177293777466, 'learning_rate': 3.3559322033898308e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [2:08:53<1:01:49,  1.87s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [2:08:55<1:01:26,  1.86s/it]                                                       {'loss': 0.0809, 'grad_norm': 6.944630146026611, 'learning_rate': 3.354237288135593e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [2:08:55<1:01:26,  1.86s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [2:08:58<1:05:03,  1.97s/it]                                                       {'loss': 0.0157, 'grad_norm': 1.9758384227752686, 'learning_rate': 3.352542372881356e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [2:08:58<1:05:03,  1.97s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [2:08:59<1:04:16,  1.95s/it]                                                       {'loss': 0.1352, 'grad_norm': 8.09278392791748, 'learning_rate': 3.350847457627119e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [2:08:59<1:04:16,  1.95s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [2:09:02<1:06:50,  2.03s/it]                                                       {'loss': 0.0333, 'grad_norm': 2.209766387939453, 'learning_rate': 3.3491525423728817e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [2:09:02<1:06:50,  2.03s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [2:09:04<1:05:27,  1.99s/it]                                                       {'loss': 0.347, 'grad_norm': 8.920419692993164, 'learning_rate': 3.347457627118644e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [2:09:04<1:05:27,  1.99s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [2:09:05<1:04:22,  1.96s/it]                                                       {'loss': 0.0388, 'grad_norm': 4.756067752838135, 'learning_rate': 3.345762711864407e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [2:09:05<1:04:22,  1.96s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [2:09:08<1:06:23,  2.02s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1292107105255127, 'learning_rate': 3.34406779661017e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [2:09:08<1:06:23,  2.02s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [2:09:09<1:05:06,  1.98s/it]                                                       {'loss': 0.063, 'grad_norm': 5.851461410522461, 'learning_rate': 3.3423728813559327e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [2:09:09<1:05:06,  1.98s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [2:09:11<1:04:03,  1.95s/it]                                                       {'loss': 0.2357, 'grad_norm': 9.864286422729492, 'learning_rate': 3.340677966101695e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [2:09:11<1:04:03,  1.95s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [2:09:13<1:03:10,  1.92s/it]                                                       {'loss': 0.1567, 'grad_norm': 8.437456130981445, 'learning_rate': 3.338983050847458e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [2:09:13<1:03:10,  1.92s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [2:09:15<1:02:24,  1.90s/it]                                                       {'loss': 0.0502, 'grad_norm': 1.9857045412063599, 'learning_rate': 3.337288135593221e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [2:09:15<1:02:24,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [2:09:17<1:02:19,  1.90s/it]                                                       {'loss': 0.0206, 'grad_norm': 2.0981242656707764, 'learning_rate': 3.3355932203389833e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [2:09:17<1:02:19,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [2:09:19<1:03:49,  1.95s/it]                                                       {'loss': 0.034, 'grad_norm': 2.4482734203338623, 'learning_rate': 3.333898305084746e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [2:09:19<1:03:49,  1.95s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [2:09:21<1:02:33,  1.91s/it]                                                       {'loss': 0.0254, 'grad_norm': 2.428553342819214, 'learning_rate': 3.332203389830509e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [2:09:21<1:02:33,  1.91s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [2:09:23<1:02:53,  1.92s/it]                                                       {'loss': 0.0692, 'grad_norm': 4.686002731323242, 'learning_rate': 3.330508474576272e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [2:09:23<1:02:53,  1.92s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [2:09:25<1:02:05,  1.90s/it]                                                       {'loss': 0.1078, 'grad_norm': 5.8087873458862305, 'learning_rate': 3.3288135593220343e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [2:09:25<1:02:05,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [2:09:26<1:01:37,  1.88s/it]                                                       {'loss': 0.0701, 'grad_norm': 3.2384893894195557, 'learning_rate': 3.3271186440677967e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [2:09:26<1:01:37,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [2:09:28<1:02:25,  1.91s/it]                                                       {'loss': 0.0291, 'grad_norm': 4.721405982971191, 'learning_rate': 3.3254237288135595e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [2:09:28<1:02:25,  1.91s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [2:09:30<1:02:25,  1.91s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.8440120220184326, 'learning_rate': 3.323728813559322e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [2:09:30<1:02:25,  1.91s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [2:09:32<1:02:19,  1.91s/it]                                                       {'loss': 0.0087, 'grad_norm': 0.6763403415679932, 'learning_rate': 3.322033898305085e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [2:09:32<1:02:19,  1.91s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [2:09:34<1:03:02,  1.93s/it]                                                       {'loss': 0.1574, 'grad_norm': 8.150748252868652, 'learning_rate': 3.3203389830508477e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [2:09:34<1:03:02,  1.93s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [2:09:36<1:02:19,  1.91s/it]                                                       {'loss': 0.0791, 'grad_norm': 8.796957015991211, 'learning_rate': 3.3186440677966105e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [2:09:36<1:02:19,  1.91s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [2:09:38<1:02:48,  1.93s/it]                                                       {'loss': 0.0611, 'grad_norm': 6.705878734588623, 'learning_rate': 3.316949152542373e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [2:09:38<1:02:48,  1.93s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [2:09:40<1:01:59,  1.90s/it]                                                       {'loss': 0.0223, 'grad_norm': 3.0428264141082764, 'learning_rate': 3.3152542372881358e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [2:09:40<1:01:59,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [2:09:42<1:01:41,  1.89s/it]                                                       {'loss': 0.0255, 'grad_norm': 2.879246234893799, 'learning_rate': 3.3135593220338986e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [2:09:42<1:01:41,  1.89s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [2:09:44<1:01:17,  1.88s/it]                                                       {'loss': 0.0372, 'grad_norm': 6.292774677276611, 'learning_rate': 3.311864406779661e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [2:09:44<1:01:17,  1.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [2:09:46<1:01:45,  1.90s/it]                                                       {'loss': 0.1618, 'grad_norm': 7.8526716232299805, 'learning_rate': 3.310169491525424e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [2:09:46<1:01:45,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [2:09:47<1:01:49,  1.90s/it]                                                       {'loss': 0.0847, 'grad_norm': 6.6327314376831055, 'learning_rate': 3.3084745762711868e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [2:09:47<1:01:49,  1.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [2:09:50<1:02:58,  1.94s/it]                                                       {'loss': 0.2077, 'grad_norm': 8.28707504272461, 'learning_rate': 3.3067796610169496e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [2:09:50<1:02:58,  1.94s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [2:09:51<1:02:24,  1.92s/it]                                                       {'loss': 0.2144, 'grad_norm': 9.262310028076172, 'learning_rate': 3.305084745762712e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [2:09:51<1:02:24,  1.92s/it][2025-11-12 00:03:07,304] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4050
[2025-11-12 00:03:07,311] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:03:07,603] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4050/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [2:09:54<1:09:29,  2.14s/it]                                                       {'loss': 0.2444, 'grad_norm': 11.08176040649414, 'learning_rate': 3.303389830508475e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [2:09:54<1:09:29,  2.14s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [2:09:56<1:06:47,  2.06s/it]                                                       {'loss': 0.1195, 'grad_norm': 6.901538372039795, 'learning_rate': 3.3016949152542377e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [2:09:56<1:06:47,  2.06s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [2:09:58<1:06:04,  2.04s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.8788199424743652, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [2:09:58<1:06:04,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [2:10:00<1:04:48,  2.00s/it]                                                       {'loss': 0.1797, 'grad_norm': 8.363964080810547, 'learning_rate': 3.298305084745763e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [2:10:00<1:04:48,  2.00s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [2:10:02<1:04:00,  1.97s/it]                                                       {'loss': 0.0739, 'grad_norm': 3.813720226287842, 'learning_rate': 3.296610169491526e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [2:10:02<1:04:00,  1.97s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [2:10:04<1:03:36,  1.96s/it]                                                       {'loss': 0.1632, 'grad_norm': 7.677737236022949, 'learning_rate': 3.2949152542372887e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [2:10:04<1:03:36,  1.96s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [2:10:05<1:02:22,  1.93s/it]                                                       {'loss': 0.0443, 'grad_norm': 4.255885601043701, 'learning_rate': 3.2932203389830516e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [2:10:05<1:02:22,  1.93s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [2:10:07<1:01:49,  1.91s/it]                                                       {'loss': 0.0284, 'grad_norm': 3.4202191829681396, 'learning_rate': 3.2915254237288136e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [2:10:07<1:01:49,  1.91s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [2:10:09<1:01:27,  1.90s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.520642042160034, 'learning_rate': 3.2898305084745764e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [2:10:09<1:01:27,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [2:10:11<1:01:16,  1.90s/it]                                                       {'loss': 0.1719, 'grad_norm': 7.642816543579102, 'learning_rate': 3.288135593220339e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [2:10:11<1:01:16,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [2:10:13<1:01:16,  1.90s/it]                                                       {'loss': 0.1982, 'grad_norm': 10.516013145446777, 'learning_rate': 3.2864406779661017e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [2:10:13<1:01:16,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [2:10:15<1:00:40,  1.88s/it]                                                       {'loss': 0.1857, 'grad_norm': 12.879091262817383, 'learning_rate': 3.2847457627118645e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [2:10:15<1:00:40,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [2:10:17<1:02:32,  1.94s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.4588353633880615, 'learning_rate': 3.2830508474576274e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [2:10:17<1:02:32,  1.94s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [2:10:19<1:01:45,  1.91s/it]                                                       {'loss': 0.0675, 'grad_norm': 6.98817777633667, 'learning_rate': 3.28135593220339e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [2:10:19<1:01:45,  1.91s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [2:10:21<1:03:06,  1.96s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.6612077951431274, 'learning_rate': 3.2796610169491527e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [2:10:21<1:03:06,  1.96s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [2:10:23<1:02:10,  1.93s/it]                                                       {'loss': 0.0524, 'grad_norm': 6.421847820281982, 'learning_rate': 3.2779661016949155e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [2:10:23<1:02:10,  1.93s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [2:10:25<1:01:41,  1.92s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.7267577648162842, 'learning_rate': 3.2762711864406784e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [2:10:25<1:01:41,  1.92s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [2:10:26<1:01:07,  1.90s/it]                                                       {'loss': 0.0783, 'grad_norm': 6.870275497436523, 'learning_rate': 3.274576271186441e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [2:10:26<1:01:07,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [2:10:28<1:01:00,  1.90s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.337369918823242, 'learning_rate': 3.2728813559322037e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [2:10:28<1:01:00,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [2:10:30<1:00:52,  1.89s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.9791965484619141, 'learning_rate': 3.2711864406779665e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [2:10:30<1:00:52,  1.89s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [2:10:32<1:00:50,  1.89s/it]                                                       {'loss': 0.0956, 'grad_norm': 7.9992170333862305, 'learning_rate': 3.2694915254237294e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [2:10:32<1:00:50,  1.89s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [2:10:34<1:01:08,  1.90s/it]                                                       {'loss': 0.0311, 'grad_norm': 3.6823720932006836, 'learning_rate': 3.2677966101694918e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [2:10:34<1:01:08,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [2:10:36<1:01:19,  1.91s/it]                                                       {'loss': 0.0357, 'grad_norm': 4.921313762664795, 'learning_rate': 3.2661016949152546e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [2:10:36<1:01:19,  1.91s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [2:10:38<1:01:10,  1.91s/it]                                                       {'loss': 0.3368, 'grad_norm': 10.889180183410645, 'learning_rate': 3.2644067796610175e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [2:10:38<1:01:10,  1.91s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [2:10:40<1:00:32,  1.89s/it]                                                       {'loss': 0.0512, 'grad_norm': 5.16140604019165, 'learning_rate': 3.26271186440678e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [2:10:40<1:00:32,  1.89s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [2:10:42<1:01:28,  1.92s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4903675317764282, 'learning_rate': 3.2610169491525428e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [2:10:42<1:01:28,  1.92s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [2:10:44<1:01:16,  1.91s/it]                                                       {'loss': 0.027, 'grad_norm': 3.9390289783477783, 'learning_rate': 3.2593220338983056e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [2:10:44<1:01:16,  1.91s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [2:10:46<1:01:18,  1.91s/it]                                                       {'loss': 0.0821, 'grad_norm': 8.269644737243652, 'learning_rate': 3.2576271186440685e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [2:10:46<1:01:18,  1.91s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [2:10:47<1:00:52,  1.90s/it]                                                       {'loss': 0.1732, 'grad_norm': 7.6563215255737305, 'learning_rate': 3.2559322033898305e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [2:10:47<1:00:52,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [2:10:49<1:00:24,  1.89s/it]                                                       {'loss': 0.1529, 'grad_norm': 10.887850761413574, 'learning_rate': 3.2542372881355933e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [2:10:49<1:00:24,  1.89s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [2:10:51<1:00:54,  1.90s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.3103802502155304, 'learning_rate': 3.252542372881356e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [2:10:51<1:00:54,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [2:10:53<1:00:53,  1.90s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3567278981208801, 'learning_rate': 3.2508474576271186e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [2:10:53<1:00:53,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [2:10:55<1:00:19,  1.89s/it]                                                       {'loss': 0.0753, 'grad_norm': 3.407961368560791, 'learning_rate': 3.2491525423728814e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [2:10:55<1:00:19,  1.89s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [2:10:57<1:01:25,  1.92s/it]                                                       {'loss': 0.0286, 'grad_norm': 4.790449142456055, 'learning_rate': 3.2474576271186443e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [2:10:57<1:01:25,  1.92s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [2:10:59<1:00:35,  1.90s/it]                                                       {'loss': 0.0516, 'grad_norm': 4.5001139640808105, 'learning_rate': 3.245762711864407e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [2:10:59<1:00:35,  1.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [2:11:01<59:52,  1.88s/it]                                                       {'loss': 0.1382, 'grad_norm': 7.992878437042236, 'learning_rate': 3.2440677966101696e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [2:11:01<59:52,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [2:11:03<59:51,  1.88s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.042776599526405334, 'learning_rate': 3.2423728813559324e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [2:11:03<59:51,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [2:11:04<1:00:17,  1.89s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.8836946487426758, 'learning_rate': 3.2406779661016953e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [2:11:04<1:00:17,  1.89s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [2:11:06<1:00:01,  1.88s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.5035087466239929, 'learning_rate': 3.2389830508474577e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [2:11:06<1:00:01,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [2:11:08<59:53,  1.88s/it]                                                       {'loss': 0.038, 'grad_norm': 1.9759294986724854, 'learning_rate': 3.2372881355932205e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [2:11:08<59:53,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [2:11:10<59:35,  1.87s/it]                                                     {'loss': 0.0101, 'grad_norm': 1.9948621988296509, 'learning_rate': 3.2355932203389834e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [2:11:10<59:35,  1.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [2:11:12<59:11,  1.86s/it]                                                     {'loss': 0.0691, 'grad_norm': 8.397421836853027, 'learning_rate': 3.2338983050847462e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [2:11:12<59:11,  1.86s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [2:11:14<58:56,  1.85s/it]                                                     {'loss': 0.0207, 'grad_norm': 2.622191905975342, 'learning_rate': 3.2322033898305087e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [2:11:14<58:56,  1.85s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [2:11:16<58:59,  1.86s/it]                                                     {'loss': 0.1028, 'grad_norm': 10.225741386413574, 'learning_rate': 3.2305084745762715e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [2:11:16<58:59,  1.86s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [2:11:17<59:21,  1.87s/it]                                                     {'loss': 0.1019, 'grad_norm': 8.399105072021484, 'learning_rate': 3.2288135593220344e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [2:11:17<59:21,  1.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [2:11:19<59:17,  1.87s/it]                                                     {'loss': 0.0846, 'grad_norm': 4.869932651519775, 'learning_rate': 3.2271186440677972e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [2:11:19<59:17,  1.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [2:11:21<59:17,  1.87s/it]                                                     {'loss': 0.0469, 'grad_norm': 6.017409801483154, 'learning_rate': 3.2254237288135596e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [2:11:21<59:17,  1.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [2:11:23<59:43,  1.88s/it]                                                     {'loss': 0.2244, 'grad_norm': 10.84686279296875, 'learning_rate': 3.2237288135593225e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [2:11:23<59:43,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [2:11:25<59:37,  1.88s/it]                                                     {'loss': 0.139, 'grad_norm': 9.94991397857666, 'learning_rate': 3.2220338983050853e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [2:11:25<59:37,  1.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [2:11:27<1:01:09,  1.93s/it]                                                       {'loss': 0.0452, 'grad_norm': 4.895066261291504, 'learning_rate': 3.2203389830508473e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [2:11:27<1:01:09,  1.93s/it][2025-11-12 00:04:42,954] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4100
[2025-11-12 00:04:42,960] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:04:43,232] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [2:11:30<1:07:38,  2.14s/it]                                                       {'loss': 0.0857, 'grad_norm': 5.731234073638916, 'learning_rate': 3.21864406779661e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [2:11:30<1:07:38,  2.14s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [2:11:32<1:05:28,  2.07s/it]                                                       {'loss': 0.0587, 'grad_norm': 8.65264892578125, 'learning_rate': 3.216949152542373e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [2:11:32<1:05:28,  2.07s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [2:11:34<1:04:48,  2.05s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.9575284719467163, 'learning_rate': 3.2152542372881355e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [2:11:34<1:04:48,  2.05s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [2:11:36<1:04:32,  2.04s/it]                                                       {'loss': 0.0669, 'grad_norm': 8.140213966369629, 'learning_rate': 3.2135593220338983e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [2:11:36<1:04:32,  2.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [2:11:37<1:03:02,  2.00s/it]                                                       {'loss': 0.0282, 'grad_norm': 3.8397412300109863, 'learning_rate': 3.211864406779661e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [2:11:37<1:03:02,  2.00s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [2:11:39<1:03:11,  2.00s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.6100573539733887, 'learning_rate': 3.210169491525424e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [2:11:39<1:03:11,  2.00s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [2:11:41<1:01:58,  1.96s/it]                                                       {'loss': 0.1045, 'grad_norm': 6.729700088500977, 'learning_rate': 3.2084745762711865e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [2:11:41<1:01:58,  1.96s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [2:11:43<1:00:40,  1.92s/it]                                                       {'loss': 0.138, 'grad_norm': 7.2753376960754395, 'learning_rate': 3.2067796610169493e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [2:11:43<1:00:40,  1.92s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [2:11:45<1:01:51,  1.96s/it]                                                       {'loss': 0.049, 'grad_norm': 4.1001386642456055, 'learning_rate': 3.205084745762712e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [2:11:45<1:01:51,  1.96s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [2:11:47<1:00:52,  1.93s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.37069201469421387, 'learning_rate': 3.203389830508475e-06, 'epoch': 0.69}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [2:11:47<1:00:52,  1.93s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [2:11:49<1:00:26,  1.92s/it]                                                       {'loss': 0.0819, 'grad_norm': 7.69507360458374, 'learning_rate': 3.2016949152542374e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [2:11:49<1:00:26,  1.92s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [2:11:51<59:51,  1.90s/it]                                                       {'loss': 0.0198, 'grad_norm': 3.968336582183838, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [2:11:51<59:51,  1.90s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [2:11:53<1:01:01,  1.94s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.010374083183705807, 'learning_rate': 3.198305084745763e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [2:11:53<1:01:01,  1.94s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [2:11:55<1:00:24,  1.92s/it]                                                       {'loss': 0.0542, 'grad_norm': 4.4779462814331055, 'learning_rate': 3.196610169491526e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [2:11:55<1:00:24,  1.92s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [2:11:57<59:59,  1.91s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5855438113212585, 'learning_rate': 3.1949152542372884e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [2:11:57<59:59,  1.91s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [2:11:59<59:39,  1.90s/it]                                                     {'loss': 0.1589, 'grad_norm': 12.122331619262695, 'learning_rate': 3.1932203389830513e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [2:11:59<59:39,  1.90s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [2:12:00<1:00:13,  1.92s/it]                                                       {'loss': 0.026, 'grad_norm': 2.0173840522766113, 'learning_rate': 3.191525423728814e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [2:12:01<1:00:13,  1.92s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [2:12:02<59:08,  1.89s/it]                                                       {'loss': 0.1288, 'grad_norm': 11.491912841796875, 'learning_rate': 3.189830508474577e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [2:12:02<59:08,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [2:12:04<59:21,  1.89s/it]                                                     {'loss': 0.0954, 'grad_norm': 8.090787887573242, 'learning_rate': 3.1881355932203394e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [2:12:04<59:21,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [2:12:06<59:05,  1.89s/it]                                                     {'loss': 0.0077, 'grad_norm': 0.8732943534851074, 'learning_rate': 3.186440677966102e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [2:12:06<59:05,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [2:12:08<58:55,  1.88s/it]                                                     {'loss': 0.2441, 'grad_norm': 11.588775634765625, 'learning_rate': 3.1847457627118642e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [2:12:08<58:55,  1.88s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [2:12:10<59:04,  1.89s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.30346977710723877, 'learning_rate': 3.183050847457627e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [2:12:10<59:04,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [2:12:12<59:01,  1.89s/it]                                                     {'loss': 0.0089, 'grad_norm': 1.1615118980407715, 'learning_rate': 3.18135593220339e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [2:12:12<59:01,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [2:12:14<58:28,  1.87s/it]                                                     {'loss': 0.0362, 'grad_norm': 3.979539394378662, 'learning_rate': 3.1796610169491528e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [2:12:14<58:28,  1.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [2:12:15<58:30,  1.87s/it]                                                     {'loss': 0.0255, 'grad_norm': 3.091728448867798, 'learning_rate': 3.1779661016949152e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [2:12:15<58:30,  1.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [2:12:17<58:15,  1.87s/it]                                                     {'loss': 0.0914, 'grad_norm': 6.554347991943359, 'learning_rate': 3.176271186440678e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [2:12:17<58:15,  1.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [2:12:19<58:11,  1.86s/it]                                                     {'loss': 0.1353, 'grad_norm': 7.345538139343262, 'learning_rate': 3.174576271186441e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [2:12:19<58:11,  1.86s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [2:12:21<59:04,  1.89s/it]                                                     {'loss': 0.012, 'grad_norm': 1.6709786653518677, 'learning_rate': 3.1728813559322038e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [2:12:21<59:04,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [2:12:23<58:27,  1.87s/it]                                                     {'loss': 0.2752, 'grad_norm': 8.141143798828125, 'learning_rate': 3.171186440677966e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [2:12:23<58:27,  1.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [2:12:25<58:23,  1.87s/it]                                                     {'loss': 0.1572, 'grad_norm': 9.02763557434082, 'learning_rate': 3.169491525423729e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [2:12:25<58:23,  1.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [2:12:27<59:58,  1.93s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.048567406833171844, 'learning_rate': 3.167796610169492e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [2:12:27<59:58,  1.93s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [2:12:29<58:59,  1.89s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.6657487154006958, 'learning_rate': 3.1661016949152547e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [2:12:29<58:59,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [2:12:31<1:01:24,  1.97s/it]                                                       {'loss': 0.0403, 'grad_norm': 4.361271858215332, 'learning_rate': 3.164406779661017e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [2:12:31<1:01:24,  1.97s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [2:12:33<1:00:20,  1.94s/it]                                                       {'loss': 0.4631, 'grad_norm': 12.699975967407227, 'learning_rate': 3.16271186440678e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [2:12:33<1:00:20,  1.94s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [2:12:35<59:19,  1.91s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.3389538526535034, 'learning_rate': 3.161016949152543e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [2:12:35<59:19,  1.91s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [2:12:37<1:03:09,  2.03s/it]                                                       {'loss': 0.0443, 'grad_norm': 4.921267986297607, 'learning_rate': 3.1593220338983053e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [2:12:37<1:03:09,  2.03s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [2:12:39<1:05:22,  2.11s/it]                                                       {'loss': 0.0349, 'grad_norm': 2.011408567428589, 'learning_rate': 3.157627118644068e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [2:12:39<1:05:22,  2.11s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [2:12:41<1:03:11,  2.04s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.801894187927246, 'learning_rate': 3.155932203389831e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [2:12:41<1:03:11,  2.04s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [2:12:43<1:01:21,  1.98s/it]                                                       {'loss': 0.1963, 'grad_norm': 10.559846878051758, 'learning_rate': 3.154237288135594e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [2:12:43<1:01:21,  1.98s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [2:12:45<1:00:46,  1.96s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.579237937927246, 'learning_rate': 3.1525423728813563e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [2:12:45<1:00:46,  1.96s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [2:12:47<59:57,  1.93s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.124759741127491, 'learning_rate': 3.1508474576271187e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [2:12:47<59:57,  1.93s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [2:12:49<59:14,  1.91s/it]                                                     {'loss': 0.0473, 'grad_norm': 6.616283893585205, 'learning_rate': 3.1491525423728815e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [2:12:49<59:14,  1.91s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [2:12:50<59:09,  1.91s/it]                                                     {'loss': 0.2116, 'grad_norm': 10.979036331176758, 'learning_rate': 3.147457627118644e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [2:12:50<59:09,  1.91s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [2:12:52<59:17,  1.92s/it]                                                     {'loss': 0.0424, 'grad_norm': 5.792741775512695, 'learning_rate': 3.145762711864407e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [2:12:52<59:17,  1.92s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [2:12:54<58:38,  1.90s/it]                                                     {'loss': 0.0416, 'grad_norm': 1.859162449836731, 'learning_rate': 3.1440677966101697e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [2:12:54<58:38,  1.90s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [2:12:56<59:09,  1.91s/it]                                                     {'loss': 0.0254, 'grad_norm': 4.568106174468994, 'learning_rate': 3.1423728813559325e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [2:12:56<59:09,  1.91s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [2:12:58<58:39,  1.90s/it]                                                     {'loss': 0.0116, 'grad_norm': 2.5107436180114746, 'learning_rate': 3.140677966101695e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [2:12:58<58:39,  1.90s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [2:13:00<58:03,  1.88s/it]                                                     {'loss': 0.0478, 'grad_norm': 4.985353946685791, 'learning_rate': 3.138983050847458e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [2:13:00<58:03,  1.88s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [2:13:02<57:39,  1.87s/it]                                                     {'loss': 0.005, 'grad_norm': 1.1601163148880005, 'learning_rate': 3.1372881355932207e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [2:13:02<57:39,  1.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [2:13:04<57:29,  1.86s/it]                                                     {'loss': 0.0744, 'grad_norm': 4.773179531097412, 'learning_rate': 3.135593220338983e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [2:13:04<57:29,  1.86s/it][2025-11-12 00:06:19,483] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4150
[2025-11-12 00:06:19,490] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:06:19,788] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4150/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [2:13:06<1:05:32,  2.13s/it]                                                       {'loss': 0.0338, 'grad_norm': 5.149833679199219, 'learning_rate': 3.133898305084746e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [2:13:06<1:05:32,  2.13s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [2:13:08<1:03:17,  2.05s/it]                                                       {'loss': 0.002, 'grad_norm': 0.33534273505210876, 'learning_rate': 3.1322033898305088e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [2:13:08<1:03:17,  2.05s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [2:13:10<1:01:21,  1.99s/it]                                                       {'loss': 0.0221, 'grad_norm': 2.6711339950561523, 'learning_rate': 3.1305084745762716e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [2:13:10<1:01:21,  1.99s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [2:13:12<1:01:55,  2.01s/it]                                                       {'loss': 0.2172, 'grad_norm': 9.658719062805176, 'learning_rate': 3.128813559322034e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [2:13:12<1:01:55,  2.01s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [2:13:14<1:01:06,  1.99s/it]                                                       {'loss': 0.0703, 'grad_norm': 8.7036771774292, 'learning_rate': 3.127118644067797e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [2:13:14<1:01:06,  1.99s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [2:13:16<1:00:36,  1.97s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.69651460647583, 'learning_rate': 3.1254237288135598e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [2:13:16<1:00:36,  1.97s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [2:13:18<1:00:04,  1.96s/it]                                                       {'loss': 0.1396, 'grad_norm': 9.366217613220215, 'learning_rate': 3.1237288135593226e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [2:13:18<1:00:04,  1.96s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [2:13:20<1:00:14,  1.96s/it]                                                       {'loss': 0.0677, 'grad_norm': 6.210792541503906, 'learning_rate': 3.122033898305085e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [2:13:20<1:00:14,  1.96s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [2:13:22<59:46,  1.95s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.8422256112098694, 'learning_rate': 3.120338983050848e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [2:13:22<59:46,  1.95s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [2:13:24<58:47,  1.92s/it]                                                     {'loss': 0.0365, 'grad_norm': 5.538363933563232, 'learning_rate': 3.1186440677966107e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [2:13:24<58:47,  1.92s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [2:13:25<58:16,  1.90s/it]                                                     {'loss': 0.0939, 'grad_norm': 6.073685646057129, 'learning_rate': 3.1169491525423736e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [2:13:25<58:16,  1.90s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [2:13:27<57:52,  1.89s/it]                                                     {'loss': 0.1294, 'grad_norm': 8.140108108520508, 'learning_rate': 3.1152542372881356e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [2:13:27<57:52,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [2:13:29<57:28,  1.88s/it]                                                     {'loss': 0.0728, 'grad_norm': 4.723461151123047, 'learning_rate': 3.1135593220338984e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [2:13:29<57:28,  1.88s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [2:13:31<57:45,  1.89s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.2606154680252075, 'learning_rate': 3.111864406779661e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [2:13:31<57:45,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [2:13:33<57:35,  1.88s/it]                                                     {'loss': 0.0393, 'grad_norm': 2.5659995079040527, 'learning_rate': 3.1101694915254237e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [2:13:33<57:35,  1.88s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [2:13:35<57:38,  1.89s/it]                                                     {'loss': 0.0679, 'grad_norm': 6.761517524719238, 'learning_rate': 3.1084745762711866e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [2:13:35<57:38,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [2:13:37<57:37,  1.89s/it]                                                     {'loss': 0.0753, 'grad_norm': 6.514450550079346, 'learning_rate': 3.1067796610169494e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [2:13:37<57:37,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [2:13:39<57:40,  1.89s/it]                                                     {'loss': 0.1514, 'grad_norm': 8.282297134399414, 'learning_rate': 3.105084745762712e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [2:13:39<57:40,  1.89s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [2:13:41<1:00:12,  1.97s/it]                                                       {'loss': 0.0087, 'grad_norm': 0.9929766654968262, 'learning_rate': 3.1033898305084747e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [2:13:41<1:00:12,  1.97s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [2:13:43<59:27,  1.95s/it]                                                       {'loss': 0.001, 'grad_norm': 0.16641363501548767, 'learning_rate': 3.1016949152542375e-06, 'epoch': 0.69}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [2:13:43<59:27,  1.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [2:13:45<59:55,  1.97s/it]                                                     {'loss': 0.2809, 'grad_norm': 9.755191802978516, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [2:13:45<59:55,  1.97s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [2:13:47<59:18,  1.95s/it]                                                     {'loss': 0.132, 'grad_norm': 5.313683986663818, 'learning_rate': 3.098305084745763e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [2:13:47<59:18,  1.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [2:13:49<58:53,  1.93s/it]                                                     {'loss': 0.0936, 'grad_norm': 5.735678195953369, 'learning_rate': 3.0966101694915257e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [2:13:49<58:53,  1.93s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [2:13:50<58:32,  1.92s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.4570239186286926, 'learning_rate': 3.0949152542372885e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [2:13:50<58:32,  1.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [2:13:52<58:18,  1.92s/it]                                                     {'loss': 0.0184, 'grad_norm': 1.8777952194213867, 'learning_rate': 3.0932203389830514e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [2:13:52<58:18,  1.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [2:13:54<57:41,  1.90s/it]                                                     {'loss': 0.0849, 'grad_norm': 5.203719139099121, 'learning_rate': 3.091525423728814e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [2:13:54<57:41,  1.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [2:13:56<57:24,  1.89s/it]                                                     {'loss': 0.0113, 'grad_norm': 2.849876880645752, 'learning_rate': 3.0898305084745766e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [2:13:56<57:24,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [2:13:58<57:02,  1.88s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.4736573100090027, 'learning_rate': 3.0881355932203395e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [2:13:58<57:02,  1.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [2:14:00<56:50,  1.87s/it]                                                     {'loss': 0.1587, 'grad_norm': 9.724143981933594, 'learning_rate': 3.0864406779661023e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [2:14:00<56:50,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [2:14:02<57:53,  1.91s/it]                                                     {'loss': 0.024, 'grad_norm': 2.6889069080352783, 'learning_rate': 3.0847457627118648e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [2:14:02<57:53,  1.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [2:14:04<57:15,  1.89s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.7373875975608826, 'learning_rate': 3.0830508474576276e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [2:14:04<57:15,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [2:14:05<56:42,  1.87s/it]                                                     {'loss': 0.001, 'grad_norm': 0.140561044216156, 'learning_rate': 3.0813559322033905e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [2:14:05<56:42,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [2:14:07<56:39,  1.87s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.21506357192993164, 'learning_rate': 3.0796610169491525e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [2:14:07<56:39,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [2:14:09<56:39,  1.87s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.03933045640587807, 'learning_rate': 3.0779661016949153e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [2:14:09<56:39,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [2:14:11<56:25,  1.87s/it]                                                     {'loss': 0.3925, 'grad_norm': 8.64859390258789, 'learning_rate': 3.076271186440678e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [2:14:11<56:25,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [2:14:13<56:09,  1.86s/it]                                                     {'loss': 0.0244, 'grad_norm': 1.9689252376556396, 'learning_rate': 3.0745762711864406e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [2:14:13<56:09,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [2:14:15<56:09,  1.86s/it]                                                     {'loss': 0.0151, 'grad_norm': 1.2519714832305908, 'learning_rate': 3.0728813559322034e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [2:14:15<56:09,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [2:14:17<56:19,  1.86s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.24973110854625702, 'learning_rate': 3.0711864406779663e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [2:14:17<56:19,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [2:14:19<57:06,  1.89s/it]                                                     {'loss': 0.0384, 'grad_norm': 5.282790660858154, 'learning_rate': 3.069491525423729e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [2:14:19<57:06,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [2:14:20<57:00,  1.89s/it]                                                     {'loss': 0.1217, 'grad_norm': 7.49388313293457, 'learning_rate': 3.0677966101694916e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [2:14:20<57:00,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [2:14:22<56:54,  1.89s/it]                                                     {'loss': 0.0355, 'grad_norm': 3.4922103881835938, 'learning_rate': 3.0661016949152544e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [2:14:22<56:54,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [2:14:24<57:01,  1.89s/it]                                                     {'loss': 0.0118, 'grad_norm': 2.0697994232177734, 'learning_rate': 3.0644067796610173e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [2:14:24<57:01,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [2:14:26<56:46,  1.89s/it]                                                     {'loss': 0.0651, 'grad_norm': 5.958796977996826, 'learning_rate': 3.06271186440678e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [2:14:26<56:46,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [2:14:28<56:51,  1.89s/it]                                                     {'loss': 0.1128, 'grad_norm': 9.593888282775879, 'learning_rate': 3.0610169491525426e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [2:14:28<56:51,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [2:14:30<56:37,  1.88s/it]                                                     {'loss': 0.008, 'grad_norm': 1.3451672792434692, 'learning_rate': 3.0593220338983054e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [2:14:30<56:37,  1.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [2:14:32<56:19,  1.87s/it]                                                     {'loss': 0.0608, 'grad_norm': 1.4403177499771118, 'learning_rate': 3.0576271186440683e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [2:14:32<56:19,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [2:14:34<56:13,  1.87s/it]                                                     {'loss': 0.0914, 'grad_norm': 7.09043550491333, 'learning_rate': 3.0559322033898307e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [2:14:34<56:13,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [2:14:35<55:57,  1.86s/it]                                                     {'loss': 0.1695, 'grad_norm': 10.093454360961914, 'learning_rate': 3.0542372881355935e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [2:14:35<55:57,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [2:14:37<55:48,  1.86s/it]                                                     {'loss': 0.0848, 'grad_norm': 8.83568000793457, 'learning_rate': 3.0525423728813564e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [2:14:37<55:48,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [2:14:39<55:52,  1.86s/it]                                                     {'loss': 0.13, 'grad_norm': 9.784106254577637, 'learning_rate': 3.0508474576271192e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [2:14:39<55:52,  1.86s/it][2025-11-12 00:07:55,061] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4200
[2025-11-12 00:07:55,068] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:07:55,362] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [2:14:42<1:03:23,  2.11s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.9762262105941772, 'learning_rate': 3.0491525423728817e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [2:14:42<1:03:23,  2.11s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [2:14:44<1:01:40,  2.06s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.052677035331726, 'learning_rate': 3.0474576271186445e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [2:14:44<1:01:40,  2.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [2:14:46<59:58,  2.00s/it]                                                       {'loss': 0.0333, 'grad_norm': 4.073822498321533, 'learning_rate': 3.045762711864407e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [2:14:46<59:58,  2.00s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [2:14:48<58:44,  1.96s/it]                                                     {'loss': 0.0263, 'grad_norm': 1.2327079772949219, 'learning_rate': 3.0440677966101694e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [2:14:48<58:44,  1.96s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [2:14:49<57:53,  1.94s/it]                                                     {'loss': 0.0425, 'grad_norm': 3.4261679649353027, 'learning_rate': 3.042372881355932e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [2:14:49<57:53,  1.94s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [2:14:51<57:21,  1.92s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.34340035915374756, 'learning_rate': 3.040677966101695e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [2:14:51<57:21,  1.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [2:14:53<56:53,  1.90s/it]                                                     {'loss': 0.0878, 'grad_norm': 7.570441722869873, 'learning_rate': 3.038983050847458e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [2:14:53<56:53,  1.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [2:14:55<56:27,  1.89s/it]                                                     {'loss': 0.1129, 'grad_norm': 7.494455814361572, 'learning_rate': 3.0372881355932203e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [2:14:55<56:27,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [2:14:57<56:23,  1.89s/it]                                                     {'loss': 0.0284, 'grad_norm': 4.385270118713379, 'learning_rate': 3.035593220338983e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [2:14:57<56:23,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [2:14:59<55:53,  1.87s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.28191739320755005, 'learning_rate': 3.033898305084746e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [2:14:59<55:53,  1.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [2:15:01<56:10,  1.88s/it]                                                     {'loss': 0.0649, 'grad_norm': 5.282832622528076, 'learning_rate': 3.0322033898305085e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [2:15:01<56:10,  1.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [2:15:03<57:25,  1.93s/it]                                                     {'loss': 0.0091, 'grad_norm': 1.9900546073913574, 'learning_rate': 3.0305084745762713e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [2:15:03<57:25,  1.93s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [2:15:05<57:06,  1.92s/it]                                                     {'loss': 0.0056, 'grad_norm': 1.3824512958526611, 'learning_rate': 3.028813559322034e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [2:15:05<57:06,  1.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [2:15:06<56:16,  1.89s/it]                                                     {'loss': 0.0433, 'grad_norm': 1.8860554695129395, 'learning_rate': 3.027118644067797e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [2:15:06<56:16,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [2:15:08<56:39,  1.90s/it]                                                     {'loss': 0.0075, 'grad_norm': 1.4451113939285278, 'learning_rate': 3.0254237288135594e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [2:15:08<56:39,  1.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [2:15:10<56:14,  1.89s/it]                                                     {'loss': 0.3104, 'grad_norm': 10.723958015441895, 'learning_rate': 3.0237288135593223e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [2:15:10<56:14,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [2:15:12<56:21,  1.90s/it]                                                     {'loss': 0.0139, 'grad_norm': 1.817926287651062, 'learning_rate': 3.022033898305085e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [2:15:12<56:21,  1.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [2:15:14<56:01,  1.89s/it]                                                     {'loss': 0.0279, 'grad_norm': 3.639786720275879, 'learning_rate': 3.020338983050848e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [2:15:14<56:01,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [2:15:16<55:52,  1.88s/it]                                                     {'loss': 0.0076, 'grad_norm': 0.9176477789878845, 'learning_rate': 3.0186440677966104e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [2:15:16<55:52,  1.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [2:15:18<55:19,  1.86s/it]                                                     {'loss': 0.0647, 'grad_norm': 5.962759017944336, 'learning_rate': 3.0169491525423733e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [2:15:18<55:19,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [2:15:19<55:10,  1.86s/it]                                                     {'loss': 0.1019, 'grad_norm': 7.157217025756836, 'learning_rate': 3.015254237288136e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [2:15:19<55:10,  1.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [2:15:21<56:08,  1.89s/it]                                                     {'loss': 0.1311, 'grad_norm': 6.775406837463379, 'learning_rate': 3.013559322033899e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [2:15:21<56:08,  1.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [2:15:23<56:27,  1.91s/it]                                                     {'loss': 0.1307, 'grad_norm': 10.259848594665527, 'learning_rate': 3.0118644067796614e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [2:15:23<56:27,  1.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [2:15:25<56:48,  1.92s/it]                                                     {'loss': 0.0928, 'grad_norm': 7.887641429901123, 'learning_rate': 3.010169491525424e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [2:15:25<56:48,  1.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [2:15:27<58:07,  1.96s/it]                                                     {'loss': 0.1675, 'grad_norm': 8.396547317504883, 'learning_rate': 3.0084745762711862e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [2:15:27<58:07,  1.96s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [2:15:30<1:01:10,  2.07s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.38228222727775574, 'learning_rate': 3.006779661016949e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [2:15:30<1:01:10,  2.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [2:15:32<59:19,  2.01s/it]                                                       {'loss': 0.0411, 'grad_norm': 4.591978073120117, 'learning_rate': 3.005084745762712e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [2:15:32<59:19,  2.01s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [2:15:34<58:38,  1.99s/it]                                                     {'loss': 0.0054, 'grad_norm': 0.8053670525550842, 'learning_rate': 3.003389830508475e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [2:15:34<58:38,  1.99s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [2:15:35<57:41,  1.95s/it]                                                     {'loss': 0.0192, 'grad_norm': 4.278484344482422, 'learning_rate': 3.0016949152542372e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [2:15:35<57:41,  1.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [2:15:37<57:53,  1.96s/it]                                                     {'loss': 0.0845, 'grad_norm': 8.222015380859375, 'learning_rate': 3e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [2:15:37<57:53,  1.96s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [2:15:39<58:04,  1.97s/it]                                                     {'loss': 0.0134, 'grad_norm': 1.6948810815811157, 'learning_rate': 2.998305084745763e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [2:15:39<58:04,  1.97s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [2:15:41<57:15,  1.94s/it]                                                     {'loss': 0.0495, 'grad_norm': 4.781840801239014, 'learning_rate': 2.9966101694915258e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [2:15:41<57:15,  1.94s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [2:15:43<56:39,  1.92s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.7215411067008972, 'learning_rate': 2.994915254237288e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [2:15:43<56:39,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [2:15:45<56:08,  1.91s/it]                                                     {'loss': 0.0278, 'grad_norm': 3.3237645626068115, 'learning_rate': 2.993220338983051e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [2:15:45<56:08,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [2:15:47<55:37,  1.89s/it]                                                     {'loss': 0.0401, 'grad_norm': 3.590128183364868, 'learning_rate': 2.991525423728814e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [2:15:47<55:37,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [2:15:49<55:23,  1.88s/it]                                                     {'loss': 0.0242, 'grad_norm': 2.8859260082244873, 'learning_rate': 2.9898305084745768e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [2:15:49<55:23,  1.88s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [2:15:51<56:21,  1.92s/it]                                                     {'loss': 0.0198, 'grad_norm': 3.583097457885742, 'learning_rate': 2.988135593220339e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [2:15:51<56:21,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [2:15:53<55:51,  1.90s/it]                                                     {'loss': 0.0618, 'grad_norm': 5.358537673950195, 'learning_rate': 2.986440677966102e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [2:15:53<55:51,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [2:15:54<55:23,  1.89s/it]                                                     {'loss': 0.0068, 'grad_norm': 1.0410754680633545, 'learning_rate': 2.984745762711865e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [2:15:54<55:23,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [2:15:56<55:18,  1.89s/it]                                                     {'loss': 0.0462, 'grad_norm': 2.107215166091919, 'learning_rate': 2.9830508474576277e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [2:15:56<55:18,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [2:15:58<55:36,  1.90s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.6076553463935852, 'learning_rate': 2.98135593220339e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [2:15:58<55:36,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [2:16:00<55:19,  1.89s/it]                                                     {'loss': 0.01, 'grad_norm': 1.1944814920425415, 'learning_rate': 2.979661016949153e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [2:16:00<55:19,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [2:16:02<56:34,  1.93s/it]                                                     {'loss': 0.1255, 'grad_norm': 5.423423767089844, 'learning_rate': 2.977966101694916e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [2:16:02<56:34,  1.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [2:16:04<58:53,  2.01s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.1997790336608887, 'learning_rate': 2.9762711864406783e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [2:16:04<58:53,  2.01s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [2:16:06<57:36,  1.97s/it]                                                     {'loss': 0.0497, 'grad_norm': 4.887557029724121, 'learning_rate': 2.9745762711864407e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [2:16:06<57:36,  1.97s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [2:16:08<57:29,  1.97s/it]                                                     {'loss': 0.0295, 'grad_norm': 4.426457405090332, 'learning_rate': 2.9728813559322036e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [2:16:08<57:29,  1.97s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [2:16:10<56:42,  1.94s/it]                                                     {'loss': 0.0992, 'grad_norm': 5.520530700683594, 'learning_rate': 2.971186440677966e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [2:16:10<56:42,  1.94s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [2:16:12<56:13,  1.93s/it]                                                     {'loss': 0.0245, 'grad_norm': 4.419660568237305, 'learning_rate': 2.969491525423729e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [2:16:12<56:13,  1.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [2:16:14<55:45,  1.91s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.2258996069431305, 'learning_rate': 2.9677966101694917e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [2:16:14<55:45,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [2:16:16<56:02,  1.92s/it]                                                     {'loss': 0.1996, 'grad_norm': 11.596123695373535, 'learning_rate': 2.9661016949152545e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [2:16:16<56:02,  1.92s/it][2025-11-12 00:09:31,690] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4250
[2025-11-12 00:09:31,698] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:09:31,977] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4250/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [2:16:18<1:02:36,  2.15s/it]                                                       {'loss': 0.0448, 'grad_norm': 2.9864134788513184, 'learning_rate': 2.964406779661017e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [2:16:18<1:02:36,  2.15s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [2:16:20<1:00:31,  2.08s/it]                                                       {'loss': 0.008, 'grad_norm': 1.8265267610549927, 'learning_rate': 2.96271186440678e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [2:16:20<1:00:31,  2.08s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [2:16:22<59:55,  2.06s/it]                                                       {'loss': 0.137, 'grad_norm': 11.195032119750977, 'learning_rate': 2.9610169491525427e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [2:16:22<59:55,  2.06s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [2:16:24<59:48,  2.06s/it]                                                     {'loss': 0.0726, 'grad_norm': 4.356672286987305, 'learning_rate': 2.959322033898305e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [2:16:24<59:48,  2.06s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [2:16:26<57:58,  1.99s/it]                                                     {'loss': 0.0596, 'grad_norm': 3.0871050357818604, 'learning_rate': 2.957627118644068e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [2:16:26<57:58,  1.99s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [2:16:28<56:38,  1.95s/it]                                                     {'loss': 0.0412, 'grad_norm': 3.8696796894073486, 'learning_rate': 2.955932203389831e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [2:16:28<56:38,  1.95s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [2:16:30<55:43,  1.92s/it]                                                     {'loss': 0.0104, 'grad_norm': 3.536775827407837, 'learning_rate': 2.9542372881355936e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [2:16:30<55:43,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [2:16:32<55:17,  1.90s/it]                                                     {'loss': 0.1115, 'grad_norm': 6.309952259063721, 'learning_rate': 2.952542372881356e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [2:16:32<55:17,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [2:16:34<54:42,  1.89s/it]                                                     {'loss': 0.0541, 'grad_norm': 5.378725051879883, 'learning_rate': 2.950847457627119e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [2:16:34<54:42,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [2:16:36<54:50,  1.89s/it]                                                     {'loss': 0.036, 'grad_norm': 4.125606060028076, 'learning_rate': 2.9491525423728818e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [2:16:36<54:50,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [2:16:38<55:17,  1.91s/it]                                                     {'loss': 0.1807, 'grad_norm': 7.748003005981445, 'learning_rate': 2.9474576271186446e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [2:16:38<55:17,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [2:16:39<55:04,  1.90s/it]                                                     {'loss': 0.0138, 'grad_norm': 1.8102701902389526, 'learning_rate': 2.945762711864407e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [2:16:39<55:04,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [2:16:41<55:56,  1.93s/it]                                                     {'loss': 0.1577, 'grad_norm': 10.156864166259766, 'learning_rate': 2.94406779661017e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [2:16:41<55:56,  1.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [2:16:43<55:48,  1.93s/it]                                                     {'loss': 0.0723, 'grad_norm': 5.058908462524414, 'learning_rate': 2.9423728813559327e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [2:16:43<55:48,  1.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [2:16:45<55:32,  1.92s/it]                                                     {'loss': 0.0123, 'grad_norm': 1.2886983156204224, 'learning_rate': 2.9406779661016956e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [2:16:45<55:32,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [2:16:47<55:00,  1.90s/it]                                                     {'loss': 0.1218, 'grad_norm': 9.647703170776367, 'learning_rate': 2.9389830508474576e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [2:16:47<55:00,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [2:16:49<54:52,  1.90s/it]                                                     {'loss': 0.0084, 'grad_norm': 0.8926864266395569, 'learning_rate': 2.9372881355932204e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [2:16:49<54:52,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [2:16:51<54:45,  1.90s/it]                                                     {'loss': 0.005, 'grad_norm': 1.242177963256836, 'learning_rate': 2.935593220338983e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [2:16:51<54:45,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [2:16:53<54:20,  1.88s/it]                                                     {'loss': 0.0579, 'grad_norm': 5.753373622894287, 'learning_rate': 2.9338983050847457e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [2:16:53<54:20,  1.88s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [2:16:55<55:15,  1.92s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.10390190035104752, 'learning_rate': 2.9322033898305086e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [2:16:55<55:15,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [2:16:57<56:14,  1.95s/it]                                                     {'loss': 0.073, 'grad_norm': 5.18665885925293, 'learning_rate': 2.9305084745762714e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [2:16:57<56:14,  1.95s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [2:16:59<55:22,  1.92s/it]                                                     {'loss': 0.0114, 'grad_norm': 1.8898324966430664, 'learning_rate': 2.928813559322034e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [2:16:59<55:22,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [2:17:01<54:59,  1.91s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.18524932861328125, 'learning_rate': 2.9271186440677967e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [2:17:01<54:59,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [2:17:02<54:40,  1.90s/it]                                                     {'loss': 0.0665, 'grad_norm': 8.95080852508545, 'learning_rate': 2.9254237288135596e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [2:17:02<54:40,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [2:17:04<55:09,  1.92s/it]                                                     {'loss': 0.1772, 'grad_norm': 7.0831427574157715, 'learning_rate': 2.9237288135593224e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [2:17:04<55:09,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [2:17:06<55:05,  1.92s/it]                                                     {'loss': 0.0668, 'grad_norm': 6.5850324630737305, 'learning_rate': 2.922033898305085e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [2:17:06<55:05,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [2:17:08<56:35,  1.97s/it]                                                     {'loss': 0.0192, 'grad_norm': 2.50724196434021, 'learning_rate': 2.9203389830508477e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [2:17:08<56:35,  1.97s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [2:17:10<56:20,  1.96s/it]                                                     {'loss': 0.1424, 'grad_norm': 12.755757331848145, 'learning_rate': 2.9186440677966105e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [2:17:10<56:20,  1.96s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [2:17:12<55:19,  1.93s/it]                                                     {'loss': 0.057, 'grad_norm': 5.910182476043701, 'learning_rate': 2.9169491525423734e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [2:17:12<55:19,  1.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [2:17:14<55:00,  1.92s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.20038415491580963, 'learning_rate': 2.915254237288136e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [2:17:14<55:00,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [2:17:16<54:34,  1.91s/it]                                                     {'loss': 0.2905, 'grad_norm': 11.56983470916748, 'learning_rate': 2.9135593220338987e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [2:17:16<54:34,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [2:17:18<54:14,  1.89s/it]                                                     {'loss': 0.0143, 'grad_norm': 2.41611647605896, 'learning_rate': 2.9118644067796615e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [2:17:18<54:14,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [2:17:20<54:09,  1.89s/it]                                                     {'loss': 0.0234, 'grad_norm': 2.843798875808716, 'learning_rate': 2.9101694915254244e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [2:17:20<54:09,  1.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [2:17:22<55:32,  1.94s/it]                                                     {'loss': 0.1538, 'grad_norm': 9.322285652160645, 'learning_rate': 2.9084745762711868e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [2:17:22<55:32,  1.94s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [2:17:24<54:33,  1.91s/it]                                                     {'loss': 0.0187, 'grad_norm': 2.929858684539795, 'learning_rate': 2.9067796610169496e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [2:17:24<54:33,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [2:17:26<54:51,  1.92s/it]                                                     {'loss': 0.0201, 'grad_norm': 2.8429911136627197, 'learning_rate': 2.9050847457627125e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [2:17:26<54:51,  1.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [2:17:27<54:33,  1.91s/it]                                                     {'loss': 0.0257, 'grad_norm': 3.2593929767608643, 'learning_rate': 2.9033898305084745e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [2:17:27<54:33,  1.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [2:17:29<54:17,  1.90s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.16142195463180542, 'learning_rate': 2.9016949152542373e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [2:17:29<54:17,  1.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [2:17:31<53:54,  1.89s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.36784765124320984, 'learning_rate': 2.9e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [2:17:31<53:54,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [2:17:33<53:40,  1.88s/it]                                                     {'loss': 0.0711, 'grad_norm': 6.604763507843018, 'learning_rate': 2.8983050847457626e-06, 'epoch': 0.71}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [2:17:33<53:40,  1.88s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [2:17:35<53:37,  1.88s/it]                                                     {'loss': 0.0224, 'grad_norm': 1.6961758136749268, 'learning_rate': 2.8966101694915255e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [2:17:35<53:37,  1.88s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [2:17:37<54:54,  1.93s/it]                                                     {'loss': 0.0075, 'grad_norm': 1.5043151378631592, 'learning_rate': 2.8949152542372883e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [2:17:37<54:54,  1.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [2:17:39<54:34,  1.92s/it]                                                     {'loss': 0.0861, 'grad_norm': 7.696094512939453, 'learning_rate': 2.893220338983051e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [2:17:39<54:34,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [2:17:41<53:53,  1.90s/it]                                                     {'loss': 0.0574, 'grad_norm': 9.063657760620117, 'learning_rate': 2.8915254237288136e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [2:17:41<53:53,  1.90s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [2:17:43<53:43,  1.89s/it]                                                     {'loss': 0.0337, 'grad_norm': 3.3801486492156982, 'learning_rate': 2.8898305084745764e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [2:17:43<53:43,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [2:17:45<54:22,  1.91s/it]                                                     {'loss': 0.2946, 'grad_norm': 10.780660629272461, 'learning_rate': 2.8881355932203393e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [2:17:45<54:22,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [2:17:46<54:18,  1.91s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.4492447078227997, 'learning_rate': 2.886440677966102e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [2:17:46<54:18,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [2:17:48<55:34,  1.96s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.2347891479730606, 'learning_rate': 2.8847457627118646e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [2:17:48<55:34,  1.96s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [2:17:50<54:40,  1.93s/it]                                                     {'loss': 0.024, 'grad_norm': 2.3651819229125977, 'learning_rate': 2.8830508474576274e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [2:17:50<54:40,  1.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [2:17:52<54:11,  1.91s/it]                                                     {'loss': 0.0253, 'grad_norm': 1.796702265739441, 'learning_rate': 2.8813559322033903e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [2:17:52<54:11,  1.91s/it][2025-11-12 00:11:08,137] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4300
[2025-11-12 00:11:08,144] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:11:08,435] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [2:17:55<1:00:58,  2.15s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.1822892725467682, 'learning_rate': 2.8796610169491527e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [2:17:55<1:00:58,  2.15s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [2:17:57<58:32,  2.07s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.22722654044628143, 'learning_rate': 2.8779661016949155e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [2:17:57<58:32,  2.07s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [2:17:59<56:44,  2.01s/it]                                                     {'loss': 0.0093, 'grad_norm': 1.784172773361206, 'learning_rate': 2.8762711864406784e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [2:17:59<56:44,  2.01s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [2:18:01<56:08,  1.99s/it]                                                     {'loss': 0.0043, 'grad_norm': 0.7622190117835999, 'learning_rate': 2.8745762711864412e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [2:18:01<56:08,  1.99s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [2:18:02<55:13,  1.95s/it]                                                     {'loss': 0.2124, 'grad_norm': 9.574979782104492, 'learning_rate': 2.8728813559322037e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [2:18:02<55:13,  1.95s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [2:18:05<55:50,  1.98s/it]                                                     {'loss': 0.0169, 'grad_norm': 2.185746192932129, 'learning_rate': 2.8711864406779665e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [2:18:05<55:50,  1.98s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [2:18:06<54:56,  1.95s/it]                                                     {'loss': 0.1145, 'grad_norm': 7.224626064300537, 'learning_rate': 2.869491525423729e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [2:18:06<54:56,  1.95s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [2:18:08<54:34,  1.94s/it]                                                     {'loss': 0.0218, 'grad_norm': 2.57450008392334, 'learning_rate': 2.8677966101694914e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [2:18:08<54:34,  1.94s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [2:18:10<53:42,  1.91s/it]                                                     {'loss': 0.0736, 'grad_norm': 4.475052356719971, 'learning_rate': 2.8661016949152542e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [2:18:10<53:42,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [2:18:12<53:14,  1.89s/it]                                                     {'loss': 0.0364, 'grad_norm': 6.20247220993042, 'learning_rate': 2.864406779661017e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [2:18:12<53:14,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [2:18:14<53:12,  1.89s/it]                                                     {'loss': 0.4059, 'grad_norm': 11.90971851348877, 'learning_rate': 2.86271186440678e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [2:18:14<53:12,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [2:18:16<53:50,  1.91s/it]                                                     {'loss': 0.0213, 'grad_norm': 3.2485835552215576, 'learning_rate': 2.8610169491525424e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [2:18:16<53:50,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [2:18:18<53:36,  1.91s/it]                                                     {'loss': 0.0074, 'grad_norm': 0.7002481818199158, 'learning_rate': 2.859322033898305e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [2:18:18<53:36,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [2:18:20<53:02,  1.89s/it]                                                     {'loss': 0.0697, 'grad_norm': 7.3841447830200195, 'learning_rate': 2.857627118644068e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [2:18:20<53:02,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [2:18:22<54:38,  1.95s/it]                                                     {'loss': 0.1214, 'grad_norm': 7.57207727432251, 'learning_rate': 2.8559322033898305e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [2:18:22<54:38,  1.95s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [2:18:24<54:49,  1.95s/it]                                                     {'loss': 0.0818, 'grad_norm': 4.771989822387695, 'learning_rate': 2.8542372881355933e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [2:18:24<54:49,  1.95s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [2:18:26<54:17,  1.94s/it]                                                     {'loss': 0.0099, 'grad_norm': 1.4439481496810913, 'learning_rate': 2.852542372881356e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [2:18:26<54:17,  1.94s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [2:18:27<53:49,  1.92s/it]                                                     {'loss': 0.0113, 'grad_norm': 1.180728793144226, 'learning_rate': 2.850847457627119e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [2:18:27<53:49,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [2:18:29<53:26,  1.91s/it]                                                     {'loss': 0.1601, 'grad_norm': 8.08369255065918, 'learning_rate': 2.8491525423728815e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [2:18:29<53:26,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [2:18:31<53:11,  1.90s/it]                                                     {'loss': 0.1182, 'grad_norm': 6.858178615570068, 'learning_rate': 2.8474576271186443e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [2:18:31<53:11,  1.90s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [2:18:33<53:33,  1.91s/it]                                                     {'loss': 0.1598, 'grad_norm': 8.660470962524414, 'learning_rate': 2.845762711864407e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [2:18:33<53:33,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [2:18:35<53:23,  1.91s/it]                                                     {'loss': 0.1609, 'grad_norm': 8.199836730957031, 'learning_rate': 2.84406779661017e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [2:18:35<53:23,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [2:18:37<53:03,  1.90s/it]                                                     {'loss': 0.0073, 'grad_norm': 0.9738423228263855, 'learning_rate': 2.8423728813559324e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [2:18:37<53:03,  1.90s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [2:18:39<52:54,  1.89s/it]                                                     {'loss': 0.0109, 'grad_norm': 2.098022699356079, 'learning_rate': 2.8406779661016953e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [2:18:39<52:54,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [2:18:41<53:17,  1.91s/it]                                                     {'loss': 0.0797, 'grad_norm': 7.51292610168457, 'learning_rate': 2.838983050847458e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [2:18:41<53:17,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [2:18:43<53:57,  1.93s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.12550480663776398, 'learning_rate': 2.837288135593221e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [2:18:43<53:57,  1.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [2:18:45<53:17,  1.91s/it]                                                     {'loss': 0.0926, 'grad_norm': 5.97120475769043, 'learning_rate': 2.8355932203389834e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [2:18:45<53:17,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [2:18:47<54:21,  1.95s/it]                                                     {'loss': 0.0301, 'grad_norm': 2.8792731761932373, 'learning_rate': 2.833898305084746e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [2:18:47<54:21,  1.95s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [2:18:48<53:31,  1.92s/it]                                                     {'loss': 0.1963, 'grad_norm': 4.972379684448242, 'learning_rate': 2.8322033898305083e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [2:18:48<53:31,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [2:18:50<53:08,  1.91s/it]                                                     {'loss': 0.0648, 'grad_norm': 4.615418434143066, 'learning_rate': 2.830508474576271e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [2:18:50<53:08,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [2:18:52<53:42,  1.93s/it]                                                     {'loss': 0.0491, 'grad_norm': 4.803483963012695, 'learning_rate': 2.828813559322034e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [2:18:52<53:42,  1.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [2:18:54<53:15,  1.92s/it]                                                     {'loss': 0.0948, 'grad_norm': 6.488746643066406, 'learning_rate': 2.827118644067797e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [2:18:54<53:15,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [2:18:56<53:31,  1.93s/it]                                                     {'loss': 0.0427, 'grad_norm': 4.994815349578857, 'learning_rate': 2.8254237288135592e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [2:18:56<53:31,  1.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [2:18:58<53:16,  1.92s/it]                                                     {'loss': 0.021, 'grad_norm': 1.5506948232650757, 'learning_rate': 2.823728813559322e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [2:18:58<53:16,  1.92s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [2:19:00<53:03,  1.91s/it]                                                     {'loss': 0.0383, 'grad_norm': 3.9853413105010986, 'learning_rate': 2.822033898305085e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [2:19:00<53:03,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [2:19:02<52:52,  1.91s/it]                                                     {'loss': 0.0439, 'grad_norm': 3.970355272293091, 'learning_rate': 2.820338983050848e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [2:19:02<52:52,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [2:19:04<52:28,  1.89s/it]                                                     {'loss': 0.0503, 'grad_norm': 4.478076457977295, 'learning_rate': 2.8186440677966102e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [2:19:04<52:28,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [2:19:06<51:54,  1.87s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.3333713114261627, 'learning_rate': 2.816949152542373e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [2:19:06<51:54,  1.87s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [2:19:07<51:44,  1.87s/it]                                                     {'loss': 0.1481, 'grad_norm': 9.19391918182373, 'learning_rate': 2.815254237288136e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [2:19:07<51:44,  1.87s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [2:19:09<51:17,  1.85s/it]                                                     {'loss': 0.0235, 'grad_norm': 2.940192699432373, 'learning_rate': 2.8135593220338988e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [2:19:09<51:17,  1.85s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [2:19:11<51:39,  1.87s/it]                                                     {'loss': 0.0565, 'grad_norm': 8.463835716247559, 'learning_rate': 2.811864406779661e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [2:19:11<51:39,  1.87s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [2:19:13<51:56,  1.88s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.03353092819452286, 'learning_rate': 2.810169491525424e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [2:19:13<51:56,  1.88s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [2:19:15<52:08,  1.89s/it]                                                     {'loss': 0.0156, 'grad_norm': 2.8970372676849365, 'learning_rate': 2.808474576271187e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [2:19:15<52:08,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [2:19:17<52:26,  1.90s/it]                                                     {'loss': 0.1518, 'grad_norm': 6.812790393829346, 'learning_rate': 2.8067796610169497e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [2:19:17<52:26,  1.90s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [2:19:19<52:33,  1.91s/it]                                                     {'loss': 0.2311, 'grad_norm': 9.793798446655273, 'learning_rate': 2.805084745762712e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [2:19:19<52:33,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [2:19:21<52:28,  1.90s/it]                                                     {'loss': 0.0165, 'grad_norm': 4.604381561279297, 'learning_rate': 2.803389830508475e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [2:19:21<52:28,  1.90s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [2:19:23<52:02,  1.89s/it]                                                     {'loss': 0.0695, 'grad_norm': 6.203699111938477, 'learning_rate': 2.801694915254238e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [2:19:23<52:02,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [2:19:24<52:29,  1.91s/it]                                                     {'loss': 0.012, 'grad_norm': 2.5927696228027344, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [2:19:24<52:29,  1.91s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [2:19:26<52:02,  1.89s/it]                                                     {'loss': 0.0663, 'grad_norm': 7.785555839538574, 'learning_rate': 2.7983050847457627e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [2:19:26<52:02,  1.89s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [2:19:28<52:13,  1.90s/it]                                                     {'loss': 0.0246, 'grad_norm': 2.0061450004577637, 'learning_rate': 2.7966101694915256e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [2:19:28<52:13,  1.90s/it][2025-11-12 00:12:44,175] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4350
[2025-11-12 00:12:44,182] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:12:44,471] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4350/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [2:19:31<58:58,  2.15s/it]                                                     {'loss': 0.0657, 'grad_norm': 7.671802043914795, 'learning_rate': 2.794915254237288e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [2:19:31<58:58,  2.15s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [2:19:33<56:57,  2.07s/it]                                                     {'loss': 0.029, 'grad_norm': 2.986712694168091, 'learning_rate': 2.793220338983051e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [2:19:33<56:57,  2.07s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [2:19:35<55:12,  2.01s/it]                                                     {'loss': 0.0049, 'grad_norm': 0.9404610395431519, 'learning_rate': 2.7915254237288137e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [2:19:35<55:12,  2.01s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [2:19:37<53:57,  1.97s/it]                                                     {'loss': 0.0456, 'grad_norm': 5.597259998321533, 'learning_rate': 2.7898305084745766e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [2:19:37<53:57,  1.97s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [2:19:38<53:08,  1.94s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.34190839529037476, 'learning_rate': 2.788135593220339e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [2:19:38<53:08,  1.94s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [2:19:40<53:38,  1.96s/it]                                                     {'loss': 0.0122, 'grad_norm': 2.133423328399658, 'learning_rate': 2.786440677966102e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [2:19:40<53:38,  1.96s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [2:19:42<52:56,  1.93s/it]                                                     {'loss': 0.001, 'grad_norm': 0.13627979159355164, 'learning_rate': 2.7847457627118647e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [2:19:42<52:56,  1.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [2:19:44<52:28,  1.92s/it]                                                     {'loss': 0.4584, 'grad_norm': 8.938912391662598, 'learning_rate': 2.7830508474576275e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [2:19:44<52:28,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [2:19:46<51:48,  1.89s/it]                                                     {'loss': 0.0333, 'grad_norm': 4.13133430480957, 'learning_rate': 2.78135593220339e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [2:19:46<51:48,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [2:19:48<51:57,  1.90s/it]                                                     {'loss': 0.0057, 'grad_norm': 0.5686888098716736, 'learning_rate': 2.779661016949153e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [2:19:48<51:57,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [2:19:50<51:44,  1.89s/it]                                                     {'loss': 0.0937, 'grad_norm': 7.264813423156738, 'learning_rate': 2.7779661016949157e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [2:19:50<51:44,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [2:19:52<51:25,  1.88s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.18367382884025574, 'learning_rate': 2.776271186440678e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [2:19:52<51:25,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [2:19:54<51:53,  1.90s/it]                                                     {'loss': 0.0764, 'grad_norm': 5.130061626434326, 'learning_rate': 2.774576271186441e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [2:19:54<51:53,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [2:19:56<51:47,  1.90s/it]                                                     {'loss': 0.0109, 'grad_norm': 2.491715669631958, 'learning_rate': 2.7728813559322038e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [2:19:56<51:47,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [2:19:57<51:35,  1.89s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.3445603847503662, 'learning_rate': 2.7711864406779666e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [2:19:57<51:35,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [2:19:59<51:36,  1.90s/it]                                                     {'loss': 0.0118, 'grad_norm': 0.7853704690933228, 'learning_rate': 2.769491525423729e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [2:19:59<51:36,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [2:20:01<51:26,  1.89s/it]                                                     {'loss': 0.0016, 'grad_norm': 0.14019809663295746, 'learning_rate': 2.767796610169492e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [2:20:01<51:26,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [2:20:03<51:01,  1.88s/it]                                                     {'loss': 0.0493, 'grad_norm': 6.546966075897217, 'learning_rate': 2.7661016949152548e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [2:20:03<51:01,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [2:20:05<50:54,  1.87s/it]                                                     {'loss': 0.1995, 'grad_norm': 8.83193588256836, 'learning_rate': 2.7644067796610176e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [2:20:05<50:54,  1.87s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [2:20:07<51:02,  1.88s/it]                                                     {'loss': 0.1529, 'grad_norm': 8.618492126464844, 'learning_rate': 2.7627118644067796e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [2:20:07<51:02,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [2:20:09<52:32,  1.94s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.35698288679122925, 'learning_rate': 2.7610169491525425e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [2:20:09<52:32,  1.94s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [2:20:11<52:04,  1.92s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.33886605501174927, 'learning_rate': 2.7593220338983053e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [2:20:11<52:04,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [2:20:13<52:21,  1.93s/it]                                                     {'loss': 0.0283, 'grad_norm': 2.436922550201416, 'learning_rate': 2.7576271186440677e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [2:20:13<52:21,  1.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [2:20:15<52:12,  1.93s/it]                                                     {'loss': 0.0308, 'grad_norm': 2.8750412464141846, 'learning_rate': 2.7559322033898306e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [2:20:15<52:12,  1.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [2:20:17<51:44,  1.91s/it]                                                     {'loss': 0.077, 'grad_norm': 5.923288822174072, 'learning_rate': 2.7542372881355934e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [2:20:17<51:44,  1.91s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [2:20:18<51:58,  1.92s/it]                                                     {'loss': 0.063, 'grad_norm': 3.764169931411743, 'learning_rate': 2.752542372881356e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [2:20:18<51:58,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [2:20:20<52:10,  1.93s/it]                                                     {'loss': 0.0278, 'grad_norm': 3.2163760662078857, 'learning_rate': 2.7508474576271187e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [2:20:20<52:10,  1.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [2:20:22<51:53,  1.92s/it]                                                     {'loss': 0.0366, 'grad_norm': 4.0919904708862305, 'learning_rate': 2.7491525423728816e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [2:20:22<51:53,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [2:20:24<51:44,  1.92s/it]                                                     {'loss': 0.0241, 'grad_norm': 1.935988426208496, 'learning_rate': 2.7474576271186444e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [2:20:24<51:44,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [2:20:26<51:10,  1.90s/it]                                                     {'loss': 0.0304, 'grad_norm': 5.86305570602417, 'learning_rate': 2.745762711864407e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [2:20:26<51:10,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [2:20:28<50:52,  1.89s/it]                                                     {'loss': 0.1203, 'grad_norm': 6.611097812652588, 'learning_rate': 2.7440677966101697e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [2:20:28<50:52,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [2:20:30<50:42,  1.88s/it]                                                     {'loss': 0.2102, 'grad_norm': 9.713706970214844, 'learning_rate': 2.7423728813559325e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [2:20:30<50:42,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [2:20:32<50:57,  1.89s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.13037706911563873, 'learning_rate': 2.7406779661016954e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [2:20:32<50:57,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [2:20:34<50:31,  1.88s/it]                                                     {'loss': 0.009, 'grad_norm': 1.5798368453979492, 'learning_rate': 2.738983050847458e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [2:20:34<50:31,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [2:20:35<50:26,  1.87s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.11934348940849304, 'learning_rate': 2.7372881355932207e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [2:20:35<50:26,  1.87s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [2:20:38<52:36,  1.96s/it]                                                     {'loss': 0.1703, 'grad_norm': 11.816301345825195, 'learning_rate': 2.7355932203389835e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [2:20:38<52:36,  1.96s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [2:20:39<52:09,  1.94s/it]                                                     {'loss': 0.0279, 'grad_norm': 2.695049524307251, 'learning_rate': 2.7338983050847464e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [2:20:39<52:09,  1.94s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [2:20:41<51:40,  1.92s/it]                                                     {'loss': 0.0185, 'grad_norm': 3.2891907691955566, 'learning_rate': 2.732203389830509e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [2:20:41<51:40,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [2:20:43<52:21,  1.95s/it]                                                     {'loss': 0.0193, 'grad_norm': 1.888403058052063, 'learning_rate': 2.7305084745762716e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [2:20:43<52:21,  1.95s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [2:20:45<51:56,  1.94s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.0781746432185173, 'learning_rate': 2.7288135593220336e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [2:20:45<51:56,  1.94s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [2:20:47<51:47,  1.93s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.017086803913116455, 'learning_rate': 2.7271186440677965e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [2:20:47<51:47,  1.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [2:20:49<51:40,  1.93s/it]                                                     {'loss': 0.012, 'grad_norm': 1.8014442920684814, 'learning_rate': 2.7254237288135593e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [2:20:49<51:40,  1.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [2:20:51<51:15,  1.91s/it]                                                     {'loss': 0.0097, 'grad_norm': 1.067805528640747, 'learning_rate': 2.723728813559322e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [2:20:51<51:15,  1.91s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [2:20:53<50:48,  1.90s/it]                                                     {'loss': 0.2706, 'grad_norm': 9.102209091186523, 'learning_rate': 2.7220338983050846e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [2:20:53<50:48,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [2:20:55<50:18,  1.88s/it]                                                     {'loss': 0.2413, 'grad_norm': 9.850323677062988, 'learning_rate': 2.7203389830508475e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [2:20:55<50:18,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [2:20:57<49:46,  1.86s/it]                                                     {'loss': 0.0273, 'grad_norm': 3.1125214099884033, 'learning_rate': 2.7186440677966103e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [2:20:57<49:46,  1.86s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [2:20:58<50:34,  1.89s/it]                                                     {'loss': 0.0128, 'grad_norm': 2.1271908283233643, 'learning_rate': 2.716949152542373e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [2:20:58<50:34,  1.89s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [2:21:00<50:07,  1.88s/it]                                                     {'loss': 0.0881, 'grad_norm': 5.259032726287842, 'learning_rate': 2.7152542372881356e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [2:21:00<50:07,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [2:21:02<49:57,  1.87s/it]                                                     {'loss': 0.3064, 'grad_norm': 9.488250732421875, 'learning_rate': 2.7135593220338985e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [2:21:02<49:57,  1.87s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [2:21:04<49:46,  1.87s/it]                                                     {'loss': 0.0021, 'grad_norm': 0.37864720821380615, 'learning_rate': 2.7118644067796613e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [2:21:04<49:46,  1.87s/it][2025-11-12 00:14:19,959] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4400
[2025-11-12 00:14:19,966] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:14:20,252] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [2:21:07<57:26,  2.16s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.3101955056190491, 'learning_rate': 2.710169491525424e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [2:21:07<57:26,  2.16s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [2:21:09<55:19,  2.08s/it]                                                     {'loss': 0.0649, 'grad_norm': 5.725858211517334, 'learning_rate': 2.7084745762711866e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [2:21:09<55:19,  2.08s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [2:21:11<53:30,  2.01s/it]                                                     {'loss': 0.0437, 'grad_norm': 4.697664737701416, 'learning_rate': 2.7067796610169494e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [2:21:11<53:30,  2.01s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [2:21:13<52:46,  1.98s/it]                                                     {'loss': 0.0158, 'grad_norm': 1.1632601022720337, 'learning_rate': 2.7050847457627123e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [2:21:13<52:46,  1.98s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [2:21:14<51:51,  1.95s/it]                                                     {'loss': 0.0671, 'grad_norm': 6.694408893585205, 'learning_rate': 2.703389830508475e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [2:21:14<51:51,  1.95s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [2:21:16<50:55,  1.92s/it]                                                     {'loss': 0.0266, 'grad_norm': 5.235415458679199, 'learning_rate': 2.7016949152542376e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [2:21:16<50:55,  1.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [2:21:18<50:27,  1.90s/it]                                                     {'loss': 0.018, 'grad_norm': 2.7989580631256104, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [2:21:18<50:27,  1.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [2:21:20<49:52,  1.88s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.8291969299316406, 'learning_rate': 2.6983050847457633e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [2:21:20<49:52,  1.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [2:21:22<49:56,  1.88s/it]                                                     {'loss': 0.0154, 'grad_norm': 1.684830665588379, 'learning_rate': 2.6966101694915257e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [2:21:22<49:56,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [2:21:24<49:27,  1.87s/it]                                                     {'loss': 0.1061, 'grad_norm': 8.181596755981445, 'learning_rate': 2.6949152542372885e-06, 'epoch': 0.73}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [2:21:24<49:27,  1.87s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [2:21:26<49:17,  1.86s/it]                                                     {'loss': 0.0067, 'grad_norm': 1.1371172666549683, 'learning_rate': 2.693220338983051e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [2:21:26<49:17,  1.86s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [2:21:27<49:02,  1.85s/it]                                                     {'loss': 0.0761, 'grad_norm': 5.196810722351074, 'learning_rate': 2.6915254237288134e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [2:21:27<49:02,  1.85s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [2:21:29<48:57,  1.85s/it]                                                     {'loss': 0.0859, 'grad_norm': 6.639292240142822, 'learning_rate': 2.6898305084745762e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [2:21:29<48:57,  1.85s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [2:21:31<49:29,  1.87s/it]                                                     {'loss': 0.0366, 'grad_norm': 5.580012321472168, 'learning_rate': 2.688135593220339e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [2:21:31<49:29,  1.87s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [2:21:33<49:31,  1.87s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.07393073290586472, 'learning_rate': 2.686440677966102e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [2:21:33<49:31,  1.87s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [2:21:35<49:38,  1.88s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.38266029953956604, 'learning_rate': 2.6847457627118644e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [2:21:35<49:38,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [2:21:37<50:07,  1.90s/it]                                                     {'loss': 0.3134, 'grad_norm': 13.446379661560059, 'learning_rate': 2.6830508474576272e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [2:21:37<50:07,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [2:21:39<49:54,  1.89s/it]                                                     {'loss': 0.1971, 'grad_norm': 11.482075691223145, 'learning_rate': 2.68135593220339e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [2:21:39<49:54,  1.89s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [2:21:41<49:27,  1.88s/it]                                                     {'loss': 0.0044, 'grad_norm': 0.3790680766105652, 'learning_rate': 2.679661016949153e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [2:21:41<49:27,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [2:21:42<49:13,  1.87s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.2893586754798889, 'learning_rate': 2.6779661016949153e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [2:21:42<49:13,  1.87s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [2:21:44<48:52,  1.86s/it]                                                     {'loss': 0.0084, 'grad_norm': 1.8985077142715454, 'learning_rate': 2.676271186440678e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [2:21:44<48:52,  1.86s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [2:21:46<49:04,  1.87s/it]                                                     {'loss': 0.0035, 'grad_norm': 0.4803074598312378, 'learning_rate': 2.674576271186441e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [2:21:46<49:04,  1.87s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [2:21:48<48:38,  1.85s/it]                                                     {'loss': 0.094, 'grad_norm': 9.885100364685059, 'learning_rate': 2.6728813559322035e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [2:21:48<48:38,  1.85s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [2:21:50<50:08,  1.91s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.212860107421875, 'learning_rate': 2.6711864406779663e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [2:21:50<50:08,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [2:21:52<49:51,  1.90s/it]                                                     {'loss': 0.1685, 'grad_norm': 7.599536418914795, 'learning_rate': 2.669491525423729e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [2:21:52<49:51,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [2:21:54<49:18,  1.88s/it]                                                     {'loss': 0.0588, 'grad_norm': 7.127164840698242, 'learning_rate': 2.667796610169492e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [2:21:54<49:18,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [2:21:56<49:31,  1.89s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.04931984096765518, 'learning_rate': 2.6661016949152544e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [2:21:56<49:31,  1.89s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [2:21:57<49:19,  1.88s/it]                                                     {'loss': 0.0165, 'grad_norm': 1.8369828462600708, 'learning_rate': 2.6644067796610173e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [2:21:57<49:19,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [2:21:59<49:21,  1.88s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.26484739780426025, 'learning_rate': 2.66271186440678e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [2:21:59<49:21,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [2:22:01<49:12,  1.88s/it]                                                     {'loss': 0.023, 'grad_norm': 3.858351707458496, 'learning_rate': 2.661016949152543e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [2:22:01<49:12,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [2:22:03<49:43,  1.90s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.127200648188591, 'learning_rate': 2.6593220338983054e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [2:22:03<49:43,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [2:22:05<49:39,  1.90s/it]                                                     {'loss': 0.0263, 'grad_norm': 4.02152156829834, 'learning_rate': 2.657627118644068e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [2:22:05<49:39,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [2:22:07<49:48,  1.91s/it]                                                     {'loss': 0.0143, 'grad_norm': 2.2199840545654297, 'learning_rate': 2.6559322033898307e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [2:22:07<49:48,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [2:22:09<49:32,  1.90s/it]                                                     {'loss': 0.0171, 'grad_norm': 1.3557852506637573, 'learning_rate': 2.654237288135593e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [2:22:09<49:32,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [2:22:11<49:21,  1.89s/it]                                                     {'loss': 0.002, 'grad_norm': 0.2230471968650818, 'learning_rate': 2.652542372881356e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [2:22:11<49:21,  1.89s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [2:22:13<49:08,  1.89s/it]                                                     {'loss': 0.0132, 'grad_norm': 1.078383445739746, 'learning_rate': 2.650847457627119e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [2:22:13<49:08,  1.89s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [2:22:15<49:32,  1.90s/it]                                                     {'loss': 0.0133, 'grad_norm': 2.0210888385772705, 'learning_rate': 2.6491525423728813e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [2:22:15<49:32,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [2:22:16<49:22,  1.90s/it]                                                     {'loss': 0.0366, 'grad_norm': 3.047945737838745, 'learning_rate': 2.647457627118644e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [2:22:16<49:22,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [2:22:18<49:45,  1.91s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.34819674491882324, 'learning_rate': 2.645762711864407e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [2:22:18<49:45,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [2:22:20<49:16,  1.90s/it]                                                     {'loss': 0.1367, 'grad_norm': 7.965125560760498, 'learning_rate': 2.64406779661017e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [2:22:20<49:16,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [2:22:22<48:50,  1.88s/it]                                                     {'loss': 0.1346, 'grad_norm': 8.107354164123535, 'learning_rate': 2.6423728813559322e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [2:22:22<48:50,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [2:22:24<48:56,  1.88s/it]                                                     {'loss': 0.0186, 'grad_norm': 2.487154245376587, 'learning_rate': 2.640677966101695e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [2:22:24<48:56,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [2:22:26<49:07,  1.89s/it]                                                     {'loss': 0.0021, 'grad_norm': 0.21781332790851593, 'learning_rate': 2.638983050847458e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [2:22:26<49:07,  1.89s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [2:22:28<48:47,  1.88s/it]                                                     {'loss': 0.039, 'grad_norm': 4.927790641784668, 'learning_rate': 2.6372881355932208e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [2:22:28<48:47,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [2:22:30<48:43,  1.88s/it]                                                     {'loss': 0.0398, 'grad_norm': 4.350406646728516, 'learning_rate': 2.635593220338983e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [2:22:30<48:43,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [2:22:32<49:21,  1.91s/it]                                                     {'loss': 0.0086, 'grad_norm': 1.2428494691848755, 'learning_rate': 2.633898305084746e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [2:22:32<49:21,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [2:22:34<49:21,  1.91s/it]                                                     {'loss': 0.0261, 'grad_norm': 4.03680419921875, 'learning_rate': 2.632203389830509e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [2:22:34<49:21,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [2:22:35<48:53,  1.89s/it]                                                     {'loss': 0.0717, 'grad_norm': 2.452190637588501, 'learning_rate': 2.6305084745762718e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [2:22:35<48:53,  1.89s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [2:22:37<48:41,  1.88s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.5158937573432922, 'learning_rate': 2.628813559322034e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [2:22:37<48:41,  1.88s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [2:22:39<49:03,  1.90s/it]                                                     {'loss': 0.0174, 'grad_norm': 2.646724224090576, 'learning_rate': 2.627118644067797e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [2:22:39<49:03,  1.90s/it][2025-11-12 00:15:55,085] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4450
[2025-11-12 00:15:55,092] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:15:55,378] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4450/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [2:22:42<57:57,  2.25s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.21954268217086792, 'learning_rate': 2.62542372881356e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [2:22:42<57:57,  2.25s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [2:22:44<56:39,  2.20s/it]                                                     {'loss': 0.3651, 'grad_norm': 12.356152534484863, 'learning_rate': 2.6237288135593223e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [2:22:44<56:39,  2.20s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [2:22:46<54:55,  2.13s/it]                                                     {'loss': 0.0183, 'grad_norm': 1.9984428882598877, 'learning_rate': 2.6220338983050847e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [2:22:46<54:55,  2.13s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [2:22:48<52:48,  2.05s/it]                                                     {'loss': 0.0694, 'grad_norm': 5.060109615325928, 'learning_rate': 2.6203389830508476e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [2:22:48<52:48,  2.05s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [2:22:50<51:17,  1.99s/it]                                                     {'loss': 0.0677, 'grad_norm': 5.158950328826904, 'learning_rate': 2.61864406779661e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [2:22:50<51:17,  1.99s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [2:22:52<50:16,  1.95s/it]                                                     {'loss': 0.0051, 'grad_norm': 1.1666022539138794, 'learning_rate': 2.616949152542373e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [2:22:52<50:16,  1.95s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [2:22:54<49:39,  1.93s/it]                                                     {'loss': 0.0219, 'grad_norm': 1.1153695583343506, 'learning_rate': 2.6152542372881357e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [2:22:54<49:39,  1.93s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [2:22:56<49:11,  1.91s/it]                                                     {'loss': 0.0079, 'grad_norm': 0.9636085033416748, 'learning_rate': 2.6135593220338986e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [2:22:56<49:11,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [2:22:58<49:51,  1.94s/it]                                                     {'loss': 0.0277, 'grad_norm': 4.1416707038879395, 'learning_rate': 2.611864406779661e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [2:22:58<49:51,  1.94s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [2:22:59<48:59,  1.91s/it]                                                     {'loss': 0.0135, 'grad_norm': 2.484437942504883, 'learning_rate': 2.610169491525424e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [2:22:59<48:59,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [2:23:01<49:36,  1.93s/it]                                                     {'loss': 0.1049, 'grad_norm': 6.761132717132568, 'learning_rate': 2.6084745762711867e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [2:23:01<49:36,  1.93s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [2:23:03<49:07,  1.92s/it]                                                     {'loss': 0.0898, 'grad_norm': 6.859314441680908, 'learning_rate': 2.6067796610169495e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [2:23:03<49:07,  1.92s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [2:23:05<49:24,  1.93s/it]                                                     {'loss': 0.1578, 'grad_norm': 9.328536033630371, 'learning_rate': 2.605084745762712e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [2:23:05<49:24,  1.93s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [2:23:07<49:03,  1.92s/it]                                                     {'loss': 0.0079, 'grad_norm': 1.3619173765182495, 'learning_rate': 2.603389830508475e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [2:23:07<49:03,  1.92s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [2:23:09<49:06,  1.92s/it]                                                     {'loss': 0.0157, 'grad_norm': 1.690431833267212, 'learning_rate': 2.6016949152542377e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [2:23:09<49:06,  1.92s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [2:23:11<49:01,  1.92s/it]                                                     {'loss': 0.02, 'grad_norm': 2.4080660343170166, 'learning_rate': 2.6e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [2:23:11<49:01,  1.92s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [2:23:13<49:19,  1.93s/it]                                                     {'loss': 0.1823, 'grad_norm': 12.906407356262207, 'learning_rate': 2.598305084745763e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [2:23:13<49:19,  1.93s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [2:23:15<48:53,  1.91s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.2355484664440155, 'learning_rate': 2.596610169491526e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [2:23:15<48:53,  1.91s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [2:23:17<48:22,  1.90s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.4801064431667328, 'learning_rate': 2.5949152542372886e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [2:23:17<48:22,  1.90s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [2:23:19<47:56,  1.88s/it]                                                     {'loss': 0.0168, 'grad_norm': 6.586775779724121, 'learning_rate': 2.593220338983051e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [2:23:19<47:56,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [2:23:20<48:00,  1.88s/it]                                                     {'loss': 0.0719, 'grad_norm': 7.1707844734191895, 'learning_rate': 2.591525423728814e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [2:23:20<48:00,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [2:23:22<47:49,  1.88s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.5099072456359863, 'learning_rate': 2.5898305084745768e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [2:23:22<47:49,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [2:23:24<47:50,  1.88s/it]                                                     {'loss': 0.1716, 'grad_norm': 10.461745262145996, 'learning_rate': 2.5881355932203396e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [2:23:24<47:50,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [2:23:26<48:05,  1.89s/it]                                                     {'loss': 0.3924, 'grad_norm': 13.207783699035645, 'learning_rate': 2.5864406779661016e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [2:23:26<48:05,  1.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [2:23:28<47:54,  1.89s/it]                                                     {'loss': 0.1264, 'grad_norm': 6.390016078948975, 'learning_rate': 2.5847457627118645e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [2:23:28<47:54,  1.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [2:23:30<48:49,  1.92s/it]                                                     {'loss': 0.0074, 'grad_norm': 0.8530114889144897, 'learning_rate': 2.5830508474576273e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [2:23:30<48:49,  1.92s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [2:23:32<50:06,  1.97s/it]                                                     {'loss': 0.2733, 'grad_norm': 8.428484916687012, 'learning_rate': 2.5813559322033898e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [2:23:32<50:06,  1.97s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [2:23:34<49:53,  1.97s/it]                                                     {'loss': 0.1839, 'grad_norm': 12.308874130249023, 'learning_rate': 2.5796610169491526e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [2:23:34<49:53,  1.97s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [2:23:36<51:56,  2.05s/it]                                                     {'loss': 0.0968, 'grad_norm': 6.9773712158203125, 'learning_rate': 2.5779661016949155e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [2:23:36<51:56,  2.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [2:23:38<50:27,  1.99s/it]                                                     {'loss': 0.0079, 'grad_norm': 1.489197015762329, 'learning_rate': 2.576271186440678e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [2:23:38<50:27,  1.99s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [2:23:40<49:24,  1.95s/it]                                                     {'loss': 0.027, 'grad_norm': 3.2536513805389404, 'learning_rate': 2.5745762711864407e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [2:23:40<49:24,  1.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [2:23:42<49:17,  1.95s/it]                                                     {'loss': 0.0105, 'grad_norm': 1.4626755714416504, 'learning_rate': 2.5728813559322036e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [2:23:42<49:17,  1.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [2:23:44<48:27,  1.92s/it]                                                     {'loss': 0.2208, 'grad_norm': 7.608088493347168, 'learning_rate': 2.5711864406779664e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [2:23:44<48:27,  1.92s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [2:23:46<48:21,  1.91s/it]                                                     {'loss': 0.0188, 'grad_norm': 3.399336814880371, 'learning_rate': 2.569491525423729e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [2:23:46<48:21,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [2:23:48<49:00,  1.94s/it]                                                     {'loss': 0.001, 'grad_norm': 0.12205474823713303, 'learning_rate': 2.5677966101694917e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [2:23:48<49:00,  1.94s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [2:23:49<48:02,  1.90s/it]                                                     {'loss': 0.0066, 'grad_norm': 0.5976777672767639, 'learning_rate': 2.5661016949152546e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [2:23:49<48:02,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [2:23:51<48:17,  1.92s/it]                                                     {'loss': 0.2502, 'grad_norm': 8.538162231445312, 'learning_rate': 2.5644067796610174e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [2:23:51<48:17,  1.92s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [2:23:53<48:05,  1.91s/it]                                                     {'loss': 0.0351, 'grad_norm': 3.2536306381225586, 'learning_rate': 2.56271186440678e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [2:23:53<48:05,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [2:23:55<48:31,  1.93s/it]                                                     {'loss': 0.0829, 'grad_norm': 4.527866363525391, 'learning_rate': 2.5610169491525427e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [2:23:55<48:31,  1.93s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [2:23:57<48:06,  1.91s/it]                                                     {'loss': 0.1132, 'grad_norm': 9.787359237670898, 'learning_rate': 2.5593220338983055e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [2:23:57<48:06,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [2:23:59<48:33,  1.93s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.006149096414446831, 'learning_rate': 2.5576271186440684e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [2:23:59<48:33,  1.93s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [2:24:01<48:02,  1.91s/it]                                                     {'loss': 0.0191, 'grad_norm': 2.5671041011810303, 'learning_rate': 2.555932203389831e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [2:24:01<48:02,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [2:24:03<47:40,  1.90s/it]                                                     {'loss': 0.0275, 'grad_norm': 3.0194644927978516, 'learning_rate': 2.5542372881355937e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [2:24:03<47:40,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [2:24:05<47:39,  1.90s/it]                                                     {'loss': 0.0982, 'grad_norm': 5.699566841125488, 'learning_rate': 2.5525423728813557e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [2:24:05<47:39,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [2:24:07<47:04,  1.88s/it]                                                     {'loss': 0.0039, 'grad_norm': 0.45279625058174133, 'learning_rate': 2.5508474576271185e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [2:24:07<47:04,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [2:24:08<47:04,  1.88s/it]                                                     {'loss': 0.1203, 'grad_norm': 5.171749114990234, 'learning_rate': 2.5491525423728814e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [2:24:08<47:04,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [2:24:10<46:53,  1.87s/it]                                                     {'loss': 0.0129, 'grad_norm': 1.482720136642456, 'learning_rate': 2.5474576271186442e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [2:24:10<46:53,  1.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [2:24:12<46:49,  1.87s/it]                                                     {'loss': 0.0208, 'grad_norm': 2.4868624210357666, 'learning_rate': 2.5457627118644066e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [2:24:12<46:49,  1.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [2:24:14<46:51,  1.87s/it]                                                     {'loss': 0.2421, 'grad_norm': 6.637341022491455, 'learning_rate': 2.5440677966101695e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [2:24:14<46:51,  1.87s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [2:24:16<46:56,  1.88s/it]                                                     {'loss': 0.0964, 'grad_norm': 6.846352577209473, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [2:24:16<46:56,  1.88s/it][2025-11-12 00:17:31,896] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4500
[2025-11-12 00:17:31,903] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:17:32,204] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [2:24:19<53:23,  2.14s/it]                                                     {'loss': 0.0283, 'grad_norm': 2.3562138080596924, 'learning_rate': 2.540677966101695e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [2:24:19<53:23,  2.14s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [2:24:21<51:52,  2.08s/it]                                                     {'loss': 0.2739, 'grad_norm': 12.973411560058594, 'learning_rate': 2.5389830508474576e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [2:24:21<51:52,  2.08s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [2:24:23<50:32,  2.03s/it]                                                     {'loss': 0.2858, 'grad_norm': 10.953756332397461, 'learning_rate': 2.5372881355932205e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [2:24:23<50:32,  2.03s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [2:24:24<49:14,  1.98s/it]                                                     {'loss': 0.0043, 'grad_norm': 0.4987325072288513, 'learning_rate': 2.5355932203389833e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [2:24:24<49:14,  1.98s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [2:24:26<48:29,  1.95s/it]                                                     {'loss': 0.1241, 'grad_norm': 7.776920318603516, 'learning_rate': 2.533898305084746e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [2:24:26<48:29,  1.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [2:24:28<48:00,  1.93s/it]                                                     {'loss': 0.021, 'grad_norm': 1.463582992553711, 'learning_rate': 2.5322033898305086e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [2:24:28<48:00,  1.93s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [2:24:30<47:32,  1.91s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.40061506628990173, 'learning_rate': 2.5305084745762714e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [2:24:30<47:32,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [2:24:32<47:23,  1.91s/it]                                                     {'loss': 0.0473, 'grad_norm': 5.242393970489502, 'learning_rate': 2.5288135593220343e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [2:24:32<47:23,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [2:24:34<47:20,  1.91s/it]                                                     {'loss': 0.3025, 'grad_norm': 9.184919357299805, 'learning_rate': 2.527118644067797e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [2:24:34<47:20,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [2:24:36<47:19,  1.91s/it]                                                     {'loss': 0.002, 'grad_norm': 0.26026996970176697, 'learning_rate': 2.5254237288135596e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [2:24:36<47:19,  1.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [2:24:38<47:08,  1.90s/it]                                                     {'loss': 0.0358, 'grad_norm': 4.47850227355957, 'learning_rate': 2.5237288135593224e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [2:24:38<47:08,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [2:24:40<46:48,  1.89s/it]                                                     {'loss': 0.0157, 'grad_norm': 1.8604824542999268, 'learning_rate': 2.5220338983050853e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [2:24:40<46:48,  1.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [2:24:42<48:01,  1.94s/it]                                                     {'loss': 0.0659, 'grad_norm': 6.879972457885742, 'learning_rate': 2.5203389830508477e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [2:24:42<48:01,  1.94s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [2:24:43<47:06,  1.90s/it]                                                     {'loss': 0.0399, 'grad_norm': 4.966492176055908, 'learning_rate': 2.5186440677966105e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [2:24:43<47:06,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [2:24:45<47:34,  1.92s/it]                                                     {'loss': 0.0134, 'grad_norm': 2.5748250484466553, 'learning_rate': 2.516949152542373e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [2:24:45<47:34,  1.92s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [2:24:47<46:58,  1.90s/it]                                                     {'loss': 0.0785, 'grad_norm': 9.350302696228027, 'learning_rate': 2.5152542372881354e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [2:24:47<46:58,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [2:24:49<46:35,  1.88s/it]                                                     {'loss': 0.006, 'grad_norm': 1.0995972156524658, 'learning_rate': 2.5135593220338983e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [2:24:49<46:35,  1.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [2:24:51<46:33,  1.89s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.40842866897583, 'learning_rate': 2.511864406779661e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [2:24:51<46:33,  1.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [2:24:53<46:49,  1.90s/it]                                                     {'loss': 0.1583, 'grad_norm': 7.330870628356934, 'learning_rate': 2.510169491525424e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [2:24:53<46:49,  1.90s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [2:24:55<48:01,  1.95s/it]                                                     {'loss': 0.0059, 'grad_norm': 1.4172507524490356, 'learning_rate': 2.5084745762711864e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [2:24:55<48:01,  1.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [2:24:57<47:14,  1.92s/it]                                                     {'loss': 0.3481, 'grad_norm': 10.268532752990723, 'learning_rate': 2.5067796610169492e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [2:24:57<47:14,  1.92s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [2:24:59<49:04,  1.99s/it]                                                     {'loss': 0.0148, 'grad_norm': 1.5909926891326904, 'learning_rate': 2.505084745762712e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [2:24:59<49:04,  1.99s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [2:25:01<48:14,  1.96s/it]                                                     {'loss': 0.0653, 'grad_norm': 9.520763397216797, 'learning_rate': 2.503389830508475e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [2:25:01<48:14,  1.96s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [2:25:03<51:47,  2.11s/it]                                                     {'loss': 0.0985, 'grad_norm': 4.197288990020752, 'learning_rate': 2.5016949152542374e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [2:25:03<51:47,  2.11s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [2:25:05<50:20,  2.05s/it]                                                     {'loss': 0.1327, 'grad_norm': 5.631267070770264, 'learning_rate': 2.5e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [2:25:05<50:20,  2.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [2:25:07<49:15,  2.00s/it]                                                     {'loss': 0.0062, 'grad_norm': 0.6760509014129639, 'learning_rate': 2.498305084745763e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [2:25:07<49:15,  2.00s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [2:25:09<52:12,  2.13s/it]                                                     {'loss': 0.1357, 'grad_norm': 5.828057765960693, 'learning_rate': 2.4966101694915255e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [2:25:09<52:12,  2.13s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [2:25:11<50:34,  2.06s/it]                                                     {'loss': 0.3599, 'grad_norm': 9.21433162689209, 'learning_rate': 2.4949152542372883e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [2:25:11<50:34,  2.06s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [2:25:13<49:05,  2.00s/it]                                                     {'loss': 0.2851, 'grad_norm': 11.12790298461914, 'learning_rate': 2.493220338983051e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [2:25:13<49:05,  2.00s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [2:25:15<48:14,  1.97s/it]                                                     {'loss': 0.0614, 'grad_norm': 7.235795497894287, 'learning_rate': 2.491525423728814e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [2:25:15<48:14,  1.97s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [2:25:17<47:27,  1.94s/it]                                                     {'loss': 0.016, 'grad_norm': 2.1820549964904785, 'learning_rate': 2.4898305084745765e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [2:25:17<47:27,  1.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [2:25:19<46:57,  1.92s/it]                                                     {'loss': 0.0328, 'grad_norm': 3.9771556854248047, 'learning_rate': 2.488135593220339e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [2:25:19<46:57,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [2:25:21<46:22,  1.90s/it]                                                     {'loss': 0.068, 'grad_norm': 7.302000522613525, 'learning_rate': 2.4864406779661017e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [2:25:21<46:22,  1.90s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [2:25:23<47:30,  1.94s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.053345780819654465, 'learning_rate': 2.4847457627118646e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [2:25:23<47:30,  1.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [2:25:25<47:28,  1.94s/it]                                                     {'loss': 0.1633, 'grad_norm': 7.074650287628174, 'learning_rate': 2.4830508474576274e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [2:25:25<47:28,  1.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [2:25:27<47:38,  1.95s/it]                                                     {'loss': 0.0593, 'grad_norm': 5.027320384979248, 'learning_rate': 2.48135593220339e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [2:25:27<47:38,  1.95s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [2:25:29<47:17,  1.94s/it]                                                     {'loss': 0.1451, 'grad_norm': 10.539237976074219, 'learning_rate': 2.4796610169491527e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [2:25:29<47:17,  1.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [2:25:30<46:47,  1.92s/it]                                                     {'loss': 0.0149, 'grad_norm': 1.870003342628479, 'learning_rate': 2.4779661016949156e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [2:25:31<46:47,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [2:25:32<46:36,  1.91s/it]                                                     {'loss': 0.0581, 'grad_norm': 3.8252973556518555, 'learning_rate': 2.4762711864406784e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [2:25:32<46:36,  1.91s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [2:25:34<46:48,  1.92s/it]                                                     {'loss': 0.0967, 'grad_norm': 6.9884161949157715, 'learning_rate': 2.474576271186441e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [2:25:34<46:48,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [2:25:37<48:51,  2.01s/it]                                                     {'loss': 0.0194, 'grad_norm': 2.5195276737213135, 'learning_rate': 2.4728813559322033e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [2:25:37<48:51,  2.01s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [2:25:38<47:33,  1.96s/it]                                                     {'loss': 0.0735, 'grad_norm': 6.072596549987793, 'learning_rate': 2.471186440677966e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [2:25:38<47:33,  1.96s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [2:25:40<46:54,  1.93s/it]                                                     {'loss': 0.0439, 'grad_norm': 4.752813339233398, 'learning_rate': 2.469491525423729e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [2:25:40<46:54,  1.93s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [2:25:42<46:18,  1.91s/it]                                                     {'loss': 0.0153, 'grad_norm': 1.8752071857452393, 'learning_rate': 2.467796610169492e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [2:25:42<46:18,  1.91s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [2:25:44<45:57,  1.90s/it]                                                     {'loss': 0.0361, 'grad_norm': 2.5129854679107666, 'learning_rate': 2.4661016949152542e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [2:25:44<45:57,  1.90s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [2:25:46<46:37,  1.92s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.10216356068849564, 'learning_rate': 2.464406779661017e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [2:25:46<46:37,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [2:25:48<46:34,  1.92s/it]                                                     {'loss': 0.0069, 'grad_norm': 1.6121509075164795, 'learning_rate': 2.46271186440678e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [2:25:48<46:34,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [2:25:50<46:18,  1.91s/it]                                                     {'loss': 0.0159, 'grad_norm': 1.969138503074646, 'learning_rate': 2.461016949152543e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [2:25:50<46:18,  1.91s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [2:25:52<45:33,  1.88s/it]                                                     {'loss': 0.0073, 'grad_norm': 0.9157091975212097, 'learning_rate': 2.4593220338983052e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [2:25:52<45:33,  1.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [2:25:53<45:35,  1.89s/it]                                                     {'loss': 0.003, 'grad_norm': 0.37627702951431274, 'learning_rate': 2.457627118644068e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [2:25:53<45:35,  1.89s/it][2025-11-12 00:19:09,405] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4550
[2025-11-12 00:19:09,412] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:19:09,685] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4550/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [2:25:56<51:15,  2.12s/it]                                                     {'loss': 0.0828, 'grad_norm': 7.175497531890869, 'learning_rate': 2.4559322033898305e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [2:25:56<51:15,  2.12s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [2:25:58<50:12,  2.08s/it]                                                     {'loss': 0.0061, 'grad_norm': 1.047999620437622, 'learning_rate': 2.4542372881355933e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [2:25:58<50:12,  2.08s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [2:26:00<48:50,  2.03s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.4131336510181427, 'learning_rate': 2.452542372881356e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [2:26:00<48:50,  2.03s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [2:26:02<48:19,  2.01s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.16073599457740784, 'learning_rate': 2.4508474576271186e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [2:26:02<48:19,  2.01s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [2:26:04<47:26,  1.97s/it]                                                     {'loss': 0.0123, 'grad_norm': 2.279744863510132, 'learning_rate': 2.4491525423728815e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [2:26:04<47:26,  1.97s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [2:26:06<46:53,  1.95s/it]                                                     {'loss': 0.0382, 'grad_norm': 2.1087663173675537, 'learning_rate': 2.4474576271186443e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [2:26:06<46:53,  1.95s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [2:26:08<48:49,  2.03s/it]                                                     {'loss': 0.004, 'grad_norm': 0.5350339412689209, 'learning_rate': 2.445762711864407e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [2:26:08<48:49,  2.03s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [2:26:10<47:47,  1.99s/it]                                                     {'loss': 0.2779, 'grad_norm': 7.872264385223389, 'learning_rate': 2.4440677966101696e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [2:26:10<47:47,  1.99s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [2:26:12<46:50,  1.95s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.385080486536026, 'learning_rate': 2.4423728813559324e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [2:26:12<46:50,  1.95s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [2:26:14<46:07,  1.92s/it]                                                     {'loss': 0.1201, 'grad_norm': 5.62855339050293, 'learning_rate': 2.4406779661016953e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [2:26:14<46:07,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [2:26:16<46:00,  1.92s/it]                                                     {'loss': 0.0086, 'grad_norm': 1.146669864654541, 'learning_rate': 2.438983050847458e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [2:26:16<46:00,  1.92s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [2:26:17<45:37,  1.90s/it]                                                     {'loss': 0.0416, 'grad_norm': 5.873323917388916, 'learning_rate': 2.4372881355932206e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [2:26:17<45:37,  1.90s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [2:26:19<45:16,  1.89s/it]                                                     {'loss': 0.0227, 'grad_norm': 3.709259033203125, 'learning_rate': 2.435593220338983e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [2:26:19<45:16,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [2:26:21<45:10,  1.89s/it]                                                     {'loss': 0.017, 'grad_norm': 2.899080991744995, 'learning_rate': 2.433898305084746e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [2:26:21<45:10,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [2:26:23<44:49,  1.87s/it]                                                     {'loss': 0.027, 'grad_norm': 1.5151457786560059, 'learning_rate': 2.4322033898305087e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [2:26:23<44:49,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [2:26:25<44:37,  1.87s/it]                                                     {'loss': 0.0162, 'grad_norm': 2.0442278385162354, 'learning_rate': 2.4305084745762716e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [2:26:25<44:37,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [2:26:27<45:10,  1.89s/it]                                                     {'loss': 0.0139, 'grad_norm': 1.808412790298462, 'learning_rate': 2.428813559322034e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [2:26:27<45:10,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [2:26:29<45:10,  1.89s/it]                                                     {'loss': 0.0439, 'grad_norm': 4.2845048904418945, 'learning_rate': 2.427118644067797e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [2:26:29<45:10,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [2:26:30<44:37,  1.87s/it]                                                     {'loss': 0.0511, 'grad_norm': 5.533475875854492, 'learning_rate': 2.4254237288135597e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [2:26:30<44:37,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [2:26:32<44:25,  1.86s/it]                                                     {'loss': 0.0423, 'grad_norm': 3.155916929244995, 'learning_rate': 2.4237288135593225e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [2:26:32<44:25,  1.86s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [2:26:34<44:14,  1.86s/it]                                                     {'loss': 0.0054, 'grad_norm': 1.3229353427886963, 'learning_rate': 2.422033898305085e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [2:26:34<44:14,  1.86s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [2:26:36<44:14,  1.86s/it]                                                     {'loss': 0.2099, 'grad_norm': 8.336201667785645, 'learning_rate': 2.4203389830508474e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [2:26:36<44:14,  1.86s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [2:26:38<44:06,  1.85s/it]                                                     {'loss': 0.0036, 'grad_norm': 0.3490391969680786, 'learning_rate': 2.4186440677966102e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [2:26:38<44:06,  1.85s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [2:26:40<44:03,  1.85s/it]                                                     {'loss': 0.3312, 'grad_norm': 8.513005256652832, 'learning_rate': 2.416949152542373e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [2:26:40<44:03,  1.85s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [2:26:42<44:24,  1.87s/it]                                                     {'loss': 0.0516, 'grad_norm': 6.43690824508667, 'learning_rate': 2.415254237288136e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [2:26:42<44:24,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [2:26:44<44:23,  1.87s/it]                                                     {'loss': 0.1098, 'grad_norm': 5.810468673706055, 'learning_rate': 2.4135593220338984e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [2:26:44<44:23,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [2:26:45<44:37,  1.88s/it]                                                     {'loss': 0.0054, 'grad_norm': 1.1576459407806396, 'learning_rate': 2.411864406779661e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [2:26:45<44:37,  1.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [2:26:47<44:40,  1.89s/it]                                                     {'loss': 0.1589, 'grad_norm': 9.319393157958984, 'learning_rate': 2.410169491525424e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [2:26:47<44:40,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [2:26:49<44:31,  1.88s/it]                                                     {'loss': 0.0132, 'grad_norm': 2.1986162662506104, 'learning_rate': 2.4084745762711865e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [2:26:49<44:31,  1.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [2:26:51<44:18,  1.87s/it]                                                     {'loss': 0.0135, 'grad_norm': 1.264357566833496, 'learning_rate': 2.4067796610169493e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [2:26:51<44:18,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [2:26:53<44:01,  1.86s/it]                                                     {'loss': 0.0057, 'grad_norm': 0.5259925127029419, 'learning_rate': 2.405084745762712e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [2:26:53<44:01,  1.86s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [2:26:55<43:58,  1.86s/it]                                                     {'loss': 0.1936, 'grad_norm': 11.513185501098633, 'learning_rate': 2.403389830508475e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [2:26:55<43:58,  1.86s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [2:26:57<44:07,  1.87s/it]                                                     {'loss': 0.1071, 'grad_norm': 5.756270885467529, 'learning_rate': 2.4016949152542375e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [2:26:57<44:07,  1.87s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [2:26:59<45:07,  1.91s/it]                                                     {'loss': 0.0571, 'grad_norm': 3.2910258769989014, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [2:26:59<45:07,  1.91s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [2:27:00<44:40,  1.89s/it]                                                     {'loss': 0.166, 'grad_norm': 8.185989379882812, 'learning_rate': 2.3983050847457627e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [2:27:00<44:40,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [2:27:02<44:22,  1.88s/it]                                                     {'loss': 0.0036, 'grad_norm': 0.7384999394416809, 'learning_rate': 2.3966101694915256e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [2:27:02<44:22,  1.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [2:27:04<44:42,  1.90s/it]                                                     {'loss': 0.0039, 'grad_norm': 0.7078431844711304, 'learning_rate': 2.3949152542372884e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [2:27:04<44:42,  1.90s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [2:27:06<44:22,  1.89s/it]                                                     {'loss': 0.2353, 'grad_norm': 8.240752220153809, 'learning_rate': 2.393220338983051e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [2:27:06<44:22,  1.89s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [2:27:08<44:07,  1.88s/it]                                                     {'loss': 0.2243, 'grad_norm': 5.586704730987549, 'learning_rate': 2.3915254237288137e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [2:27:08<44:07,  1.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [2:27:10<43:53,  1.87s/it]                                                     {'loss': 0.0054, 'grad_norm': 0.8263084292411804, 'learning_rate': 2.3898305084745766e-06, 'epoch': 0.77}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [2:27:10<43:53,  1.87s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [2:27:12<43:53,  1.87s/it]                                                     {'loss': 0.0233, 'grad_norm': 2.4365339279174805, 'learning_rate': 2.3881355932203394e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [2:27:12<43:53,  1.87s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [2:27:14<44:11,  1.88s/it]                                                     {'loss': 0.0147, 'grad_norm': 2.3151848316192627, 'learning_rate': 2.386440677966102e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [2:27:14<44:11,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [2:27:16<44:33,  1.90s/it]                                                     {'loss': 0.0444, 'grad_norm': 6.096771717071533, 'learning_rate': 2.3847457627118643e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [2:27:16<44:33,  1.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [2:27:17<44:09,  1.88s/it]                                                     {'loss': 0.0288, 'grad_norm': 3.0792336463928223, 'learning_rate': 2.383050847457627e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [2:27:17<44:09,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [2:27:19<44:13,  1.89s/it]                                                     {'loss': 0.0323, 'grad_norm': 2.512410879135132, 'learning_rate': 2.38135593220339e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [2:27:19<44:13,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [2:27:21<43:57,  1.88s/it]                                                     {'loss': 0.0269, 'grad_norm': 3.6235928535461426, 'learning_rate': 2.379661016949153e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [2:27:21<43:57,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [2:27:23<45:49,  1.96s/it]                                                     {'loss': 0.0255, 'grad_norm': 3.1909561157226562, 'learning_rate': 2.3779661016949152e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [2:27:23<45:49,  1.96s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [2:27:25<45:10,  1.93s/it]                                                     {'loss': 0.1692, 'grad_norm': 9.201330184936523, 'learning_rate': 2.376271186440678e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [2:27:25<45:10,  1.93s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [2:27:27<44:40,  1.91s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.2888801097869873, 'learning_rate': 2.374576271186441e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [2:27:27<44:40,  1.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [2:27:29<44:20,  1.90s/it]                                                     {'loss': 0.0555, 'grad_norm': 2.6611573696136475, 'learning_rate': 2.372881355932204e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [2:27:29<44:20,  1.90s/it][2025-11-12 00:20:44,844] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4600
[2025-11-12 00:20:44,851] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:20:45,144] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [2:27:32<50:12,  2.15s/it]                                                     {'loss': 0.0478, 'grad_norm': 4.006895065307617, 'learning_rate': 2.3711864406779662e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [2:27:32<50:12,  2.15s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [2:27:34<48:08,  2.07s/it]                                                     {'loss': 0.1324, 'grad_norm': 9.656416893005371, 'learning_rate': 2.369491525423729e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [2:27:34<48:08,  2.07s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [2:27:35<46:44,  2.01s/it]                                                     {'loss': 0.0171, 'grad_norm': 1.9076106548309326, 'learning_rate': 2.3677966101694915e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [2:27:35<46:44,  2.01s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [2:27:37<45:53,  1.97s/it]                                                     {'loss': 0.0888, 'grad_norm': 8.16085147857666, 'learning_rate': 2.3661016949152544e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [2:27:37<45:53,  1.97s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [2:27:39<45:14,  1.95s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.7638918161392212, 'learning_rate': 2.364406779661017e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [2:27:39<45:14,  1.95s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [2:27:41<44:28,  1.91s/it]                                                     {'loss': 0.086, 'grad_norm': 6.405916690826416, 'learning_rate': 2.3627118644067796e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [2:27:41<44:28,  1.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [2:27:43<43:57,  1.89s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.4847475588321686, 'learning_rate': 2.3610169491525425e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [2:27:43<43:57,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [2:27:45<43:33,  1.88s/it]                                                     {'loss': 0.0109, 'grad_norm': 1.6330815553665161, 'learning_rate': 2.3593220338983053e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [2:27:45<43:33,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [2:27:47<47:29,  2.05s/it]                                                     {'loss': 0.1474, 'grad_norm': 11.918641090393066, 'learning_rate': 2.357627118644068e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [2:27:47<47:29,  2.05s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [2:27:49<46:32,  2.01s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.3973056375980377, 'learning_rate': 2.3559322033898306e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [2:27:49<46:32,  2.01s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [2:27:51<47:57,  2.07s/it]                                                     {'loss': 0.0121, 'grad_norm': 2.4451215267181396, 'learning_rate': 2.3542372881355935e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [2:27:51<47:57,  2.07s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [2:27:53<46:34,  2.01s/it]                                                     {'loss': 0.0067, 'grad_norm': 1.0179082155227661, 'learning_rate': 2.3525423728813563e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [2:27:53<46:34,  2.01s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [2:27:55<46:41,  2.02s/it]                                                     {'loss': 0.1727, 'grad_norm': 7.168313503265381, 'learning_rate': 2.350847457627119e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [2:27:55<46:41,  2.02s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [2:27:57<45:35,  1.97s/it]                                                     {'loss': 0.0252, 'grad_norm': 3.705989360809326, 'learning_rate': 2.3491525423728816e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [2:27:57<45:35,  1.97s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [2:27:59<45:52,  1.99s/it]                                                     {'loss': 0.0611, 'grad_norm': 5.271000385284424, 'learning_rate': 2.347457627118644e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [2:27:59<45:52,  1.99s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [2:28:01<45:13,  1.96s/it]                                                     {'loss': 0.0393, 'grad_norm': 3.1941330432891846, 'learning_rate': 2.345762711864407e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [2:28:01<45:13,  1.96s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [2:28:03<44:59,  1.95s/it]                                                     {'loss': 0.0216, 'grad_norm': 2.989375591278076, 'learning_rate': 2.3440677966101697e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [2:28:03<44:59,  1.95s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [2:28:05<44:17,  1.92s/it]                                                     {'loss': 0.007, 'grad_norm': 1.3561880588531494, 'learning_rate': 2.3423728813559326e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [2:28:05<44:17,  1.92s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [2:28:07<44:18,  1.93s/it]                                                     {'loss': 0.0284, 'grad_norm': 4.8725786209106445, 'learning_rate': 2.340677966101695e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [2:28:07<44:18,  1.93s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [2:28:09<43:58,  1.91s/it]                                                     {'loss': 0.0212, 'grad_norm': 2.337446928024292, 'learning_rate': 2.338983050847458e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [2:28:09<43:58,  1.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [2:28:10<43:34,  1.90s/it]                                                     {'loss': 0.1843, 'grad_norm': 6.623636245727539, 'learning_rate': 2.3372881355932207e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [2:28:10<43:34,  1.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [2:28:12<43:27,  1.89s/it]                                                     {'loss': 0.033, 'grad_norm': 4.389824867248535, 'learning_rate': 2.3355932203389835e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [2:28:12<43:27,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [2:28:14<44:00,  1.92s/it]                                                     {'loss': 0.0227, 'grad_norm': 3.1737258434295654, 'learning_rate': 2.333898305084746e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [2:28:14<44:00,  1.92s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [2:28:16<43:46,  1.91s/it]                                                     {'loss': 0.1648, 'grad_norm': 9.23568058013916, 'learning_rate': 2.3322033898305084e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [2:28:16<43:46,  1.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [2:28:18<43:29,  1.90s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.07342331856489182, 'learning_rate': 2.3305084745762712e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [2:28:18<43:29,  1.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [2:28:20<43:01,  1.88s/it]                                                     {'loss': 0.0737, 'grad_norm': 6.806808948516846, 'learning_rate': 2.328813559322034e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [2:28:20<43:01,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [2:28:22<42:55,  1.88s/it]                                                     {'loss': 0.0831, 'grad_norm': 4.563846111297607, 'learning_rate': 2.327118644067797e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [2:28:22<42:55,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [2:28:24<42:59,  1.88s/it]                                                     {'loss': 0.0222, 'grad_norm': 1.9084806442260742, 'learning_rate': 2.3254237288135594e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [2:28:24<42:59,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [2:28:26<43:44,  1.91s/it]                                                     {'loss': 0.1711, 'grad_norm': 11.516487121582031, 'learning_rate': 2.3237288135593222e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [2:28:26<43:44,  1.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [2:28:28<44:22,  1.94s/it]                                                     {'loss': 0.0108, 'grad_norm': 1.2244607210159302, 'learning_rate': 2.322033898305085e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [2:28:28<44:22,  1.94s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [2:28:30<44:10,  1.94s/it]                                                     {'loss': 0.1447, 'grad_norm': 5.351984977722168, 'learning_rate': 2.3203389830508475e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [2:28:30<44:10,  1.94s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [2:28:31<43:41,  1.92s/it]                                                     {'loss': 0.2062, 'grad_norm': 14.5595064163208, 'learning_rate': 2.3186440677966103e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [2:28:31<43:41,  1.92s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [2:28:33<43:02,  1.89s/it]                                                     {'loss': 0.0233, 'grad_norm': 2.5764002799987793, 'learning_rate': 2.316949152542373e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [2:28:33<43:02,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [2:28:35<42:59,  1.89s/it]                                                     {'loss': 0.0965, 'grad_norm': 7.268319606781006, 'learning_rate': 2.315254237288136e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [2:28:35<42:59,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [2:28:37<42:51,  1.88s/it]                                                     {'loss': 0.0868, 'grad_norm': 5.271420478820801, 'learning_rate': 2.3135593220338985e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [2:28:37<42:51,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [2:28:39<42:36,  1.87s/it]                                                     {'loss': 0.0335, 'grad_norm': 2.6220672130584717, 'learning_rate': 2.3118644067796613e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [2:28:39<42:36,  1.87s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [2:28:41<42:38,  1.88s/it]                                                     {'loss': 0.0071, 'grad_norm': 1.5468409061431885, 'learning_rate': 2.3101694915254237e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [2:28:41<42:38,  1.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [2:28:43<43:58,  1.94s/it]                                                     {'loss': 0.002, 'grad_norm': 0.2543451189994812, 'learning_rate': 2.3084745762711866e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [2:28:43<43:58,  1.94s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [2:28:45<43:10,  1.90s/it]                                                     {'loss': 0.1072, 'grad_norm': 7.792176246643066, 'learning_rate': 2.3067796610169494e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [2:28:45<43:10,  1.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [2:28:47<42:51,  1.89s/it]                                                     {'loss': 0.0252, 'grad_norm': 3.108940601348877, 'learning_rate': 2.305084745762712e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [2:28:47<42:51,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [2:28:48<43:05,  1.90s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.1723697930574417, 'learning_rate': 2.3033898305084747e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [2:28:48<43:05,  1.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [2:28:50<42:40,  1.89s/it]                                                     {'loss': 0.034, 'grad_norm': 4.670889377593994, 'learning_rate': 2.3016949152542376e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [2:28:50<42:40,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [2:28:52<43:23,  1.92s/it]                                                     {'loss': 0.0071, 'grad_norm': 1.1305570602416992, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [2:28:52<43:23,  1.92s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [2:28:54<43:06,  1.91s/it]                                                     {'loss': 0.0452, 'grad_norm': 5.028623104095459, 'learning_rate': 2.298305084745763e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [2:28:54<43:06,  1.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [2:28:56<42:41,  1.89s/it]                                                     {'loss': 0.0504, 'grad_norm': 5.361422061920166, 'learning_rate': 2.2966101694915253e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [2:28:56<42:41,  1.89s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [2:28:58<42:08,  1.87s/it]                                                     {'loss': 0.0095, 'grad_norm': 0.9559944868087769, 'learning_rate': 2.294915254237288e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [2:28:58<42:08,  1.87s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [2:29:00<42:14,  1.87s/it]                                                     {'loss': 0.0688, 'grad_norm': 7.77177095413208, 'learning_rate': 2.293220338983051e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [2:29:00<42:14,  1.87s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [2:29:02<42:51,  1.90s/it]                                                     {'loss': 0.0729, 'grad_norm': 7.154904365539551, 'learning_rate': 2.291525423728814e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [2:29:02<42:51,  1.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [2:29:04<42:57,  1.91s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.05584954097867012, 'learning_rate': 2.2898305084745763e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [2:29:04<42:57,  1.91s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [2:29:06<42:44,  1.90s/it]                                                     {'loss': 0.2014, 'grad_norm': 9.532431602478027, 'learning_rate': 2.288135593220339e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [2:29:06<42:44,  1.90s/it][2025-11-12 00:22:21,424] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4650
[2025-11-12 00:22:21,431] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:22:21,713] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4650/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [2:29:08<48:00,  2.14s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.6458874344825745, 'learning_rate': 2.286440677966102e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [2:29:08<48:00,  2.14s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [2:29:10<46:31,  2.07s/it]                                                     {'loss': 0.0573, 'grad_norm': 3.6239843368530273, 'learning_rate': 2.284745762711865e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [2:29:10<46:31,  2.07s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [2:29:12<44:52,  2.00s/it]                                                     {'loss': 0.0972, 'grad_norm': 8.57324504852295, 'learning_rate': 2.2830508474576272e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [2:29:12<44:52,  2.00s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [2:29:14<44:10,  1.97s/it]                                                     {'loss': 0.0219, 'grad_norm': 2.193516731262207, 'learning_rate': 2.28135593220339e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [2:29:14<44:10,  1.97s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [2:29:16<43:19,  1.93s/it]                                                     {'loss': 0.0166, 'grad_norm': 1.6469621658325195, 'learning_rate': 2.2796610169491525e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [2:29:16<43:19,  1.93s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [2:29:18<43:32,  1.94s/it]                                                     {'loss': 0.0177, 'grad_norm': 2.068582773208618, 'learning_rate': 2.2779661016949154e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [2:29:18<43:32,  1.94s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [2:29:20<42:54,  1.92s/it]                                                     {'loss': 0.1537, 'grad_norm': 9.70849609375, 'learning_rate': 2.276271186440678e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [2:29:20<42:54,  1.92s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [2:29:21<42:31,  1.90s/it]                                                     {'loss': 0.1658, 'grad_norm': 11.476675987243652, 'learning_rate': 2.2745762711864406e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [2:29:21<42:31,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [2:29:23<42:11,  1.89s/it]                                                     {'loss': 0.0358, 'grad_norm': 2.600351095199585, 'learning_rate': 2.2728813559322035e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [2:29:23<42:11,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [2:29:25<42:08,  1.89s/it]                                                     {'loss': 0.0095, 'grad_norm': 1.7003530263900757, 'learning_rate': 2.2711864406779663e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [2:29:25<42:08,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [2:29:27<41:53,  1.88s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.21090452373027802, 'learning_rate': 2.269491525423729e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [2:29:27<41:53,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [2:29:29<41:57,  1.88s/it]                                                     {'loss': 0.0293, 'grad_norm': 3.9371280670166016, 'learning_rate': 2.2677966101694916e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [2:29:29<41:57,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [2:29:31<41:48,  1.88s/it]                                                     {'loss': 0.0918, 'grad_norm': 8.017826080322266, 'learning_rate': 2.2661016949152545e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [2:29:31<41:48,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [2:29:33<41:43,  1.87s/it]                                                     {'loss': 0.1184, 'grad_norm': 8.86109733581543, 'learning_rate': 2.2644067796610173e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [2:29:33<41:43,  1.87s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [2:29:34<41:23,  1.86s/it]                                                     {'loss': 0.1074, 'grad_norm': 4.172216892242432, 'learning_rate': 2.26271186440678e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [2:29:34<41:23,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [2:29:36<41:17,  1.86s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.02557295188307762, 'learning_rate': 2.2610169491525426e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [2:29:36<41:17,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [2:29:38<41:20,  1.86s/it]                                                     {'loss': 0.0785, 'grad_norm': 5.822179317474365, 'learning_rate': 2.259322033898305e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [2:29:38<41:20,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [2:29:40<41:19,  1.86s/it]                                                     {'loss': 0.0231, 'grad_norm': 5.148306369781494, 'learning_rate': 2.257627118644068e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [2:29:40<41:19,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [2:29:42<41:11,  1.86s/it]                                                     {'loss': 0.0016, 'grad_norm': 0.17851807177066803, 'learning_rate': 2.2559322033898307e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [2:29:42<41:11,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [2:29:44<41:07,  1.85s/it]                                                     {'loss': 0.0382, 'grad_norm': 5.146261692047119, 'learning_rate': 2.2542372881355936e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [2:29:44<41:07,  1.85s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [2:29:46<41:07,  1.86s/it]                                                     {'loss': 0.2039, 'grad_norm': 6.765092372894287, 'learning_rate': 2.252542372881356e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [2:29:46<41:07,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [2:29:48<41:42,  1.88s/it]                                                     {'loss': 0.253, 'grad_norm': 11.091116905212402, 'learning_rate': 2.250847457627119e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [2:29:48<41:42,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [2:29:49<41:44,  1.89s/it]                                                     {'loss': 0.0367, 'grad_norm': 5.484828948974609, 'learning_rate': 2.2491525423728817e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [2:29:49<41:44,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [2:29:51<41:28,  1.88s/it]                                                     {'loss': 0.0646, 'grad_norm': 5.548905849456787, 'learning_rate': 2.2474576271186445e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [2:29:51<41:28,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [2:29:53<41:12,  1.87s/it]                                                     {'loss': 0.0051, 'grad_norm': 0.768419086933136, 'learning_rate': 2.245762711864407e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [2:29:53<41:12,  1.87s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [2:29:55<41:02,  1.86s/it]                                                     {'loss': 0.0992, 'grad_norm': 8.961091995239258, 'learning_rate': 2.2440677966101694e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [2:29:55<41:02,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [2:29:57<40:56,  1.86s/it]                                                     {'loss': 0.0052, 'grad_norm': 1.0534417629241943, 'learning_rate': 2.2423728813559322e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [2:29:57<40:56,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [2:29:59<40:57,  1.86s/it]                                                     {'loss': 0.0791, 'grad_norm': 5.756105899810791, 'learning_rate': 2.240677966101695e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [2:29:59<40:57,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [2:30:01<41:11,  1.87s/it]                                                     {'loss': 0.028, 'grad_norm': 3.9319591522216797, 'learning_rate': 2.238983050847458e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [2:30:01<41:11,  1.87s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [2:30:02<40:51,  1.86s/it]                                                     {'loss': 0.0403, 'grad_norm': 5.2672505378723145, 'learning_rate': 2.2372881355932204e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [2:30:02<40:51,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [2:30:04<40:42,  1.85s/it]                                                     {'loss': 0.1071, 'grad_norm': 7.135352611541748, 'learning_rate': 2.2355932203389832e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [2:30:04<40:42,  1.85s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [2:30:06<40:51,  1.86s/it]                                                     {'loss': 0.003, 'grad_norm': 0.7750925421714783, 'learning_rate': 2.233898305084746e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [2:30:06<40:51,  1.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [2:30:08<40:58,  1.87s/it]                                                     {'loss': 0.0664, 'grad_norm': 8.032938003540039, 'learning_rate': 2.232203389830509e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [2:30:08<40:58,  1.87s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [2:30:10<41:37,  1.90s/it]                                                     {'loss': 0.0218, 'grad_norm': 3.1949222087860107, 'learning_rate': 2.2305084745762714e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [2:30:10<41:37,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [2:30:12<41:39,  1.90s/it]                                                     {'loss': 0.1119, 'grad_norm': 6.749936103820801, 'learning_rate': 2.228813559322034e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [2:30:12<41:39,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [2:30:14<41:33,  1.90s/it]                                                     {'loss': 0.0314, 'grad_norm': 2.450451612472534, 'learning_rate': 2.227118644067797e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [2:30:14<41:33,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [2:30:16<41:18,  1.89s/it]                                                     {'loss': 0.1354, 'grad_norm': 6.5008440017700195, 'learning_rate': 2.2254237288135595e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [2:30:16<41:18,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [2:30:17<41:12,  1.88s/it]                                                     {'loss': 0.0879, 'grad_norm': 6.4224982261657715, 'learning_rate': 2.2237288135593223e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [2:30:18<41:12,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [2:30:19<41:29,  1.90s/it]                                                     {'loss': 0.013, 'grad_norm': 1.9034125804901123, 'learning_rate': 2.2220338983050848e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [2:30:19<41:29,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [2:30:21<41:34,  1.90s/it]                                                     {'loss': 0.0631, 'grad_norm': 6.364768981933594, 'learning_rate': 2.2203389830508476e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [2:30:21<41:34,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [2:30:23<41:18,  1.89s/it]                                                     {'loss': 0.2919, 'grad_norm': 7.533204555511475, 'learning_rate': 2.2186440677966105e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [2:30:23<41:18,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [2:30:25<40:48,  1.87s/it]                                                     {'loss': 0.0729, 'grad_norm': 2.454885721206665, 'learning_rate': 2.216949152542373e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [2:30:25<40:48,  1.87s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [2:30:27<40:58,  1.88s/it]                                                     {'loss': 0.0887, 'grad_norm': 8.23458194732666, 'learning_rate': 2.2152542372881357e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [2:30:27<40:58,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [2:30:29<41:48,  1.92s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.43883273005485535, 'learning_rate': 2.2135593220338986e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [2:30:29<41:48,  1.92s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [2:30:31<41:47,  1.92s/it]                                                     {'loss': 0.0932, 'grad_norm': 7.712136268615723, 'learning_rate': 2.2118644067796614e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [2:30:31<41:47,  1.92s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [2:30:33<41:15,  1.90s/it]                                                     {'loss': 0.0441, 'grad_norm': 3.069643020629883, 'learning_rate': 2.210169491525424e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [2:30:33<41:15,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [2:30:35<41:19,  1.90s/it]                                                     {'loss': 0.0683, 'grad_norm': 3.9032435417175293, 'learning_rate': 2.2084745762711867e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [2:30:35<41:19,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [2:30:36<41:00,  1.89s/it]                                                     {'loss': 0.0582, 'grad_norm': 4.497773170471191, 'learning_rate': 2.206779661016949e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [2:30:36<41:00,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [2:30:38<40:55,  1.89s/it]                                                     {'loss': 0.0292, 'grad_norm': 3.6053881645202637, 'learning_rate': 2.205084745762712e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [2:30:38<40:55,  1.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [2:30:40<40:59,  1.89s/it]                                                     {'loss': 0.0114, 'grad_norm': 2.056417226791382, 'learning_rate': 2.203389830508475e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [2:30:40<40:59,  1.89s/it][2025-11-12 00:23:56,196] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4700
[2025-11-12 00:23:56,203] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:23:56,486] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [2:30:43<47:27,  2.19s/it]                                                     {'loss': 0.0904, 'grad_norm': 8.029236793518066, 'learning_rate': 2.2016949152542373e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [2:30:43<47:27,  2.19s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [2:30:45<45:49,  2.12s/it]                                                     {'loss': 0.0879, 'grad_norm': 6.157009601593018, 'learning_rate': 2.2e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [2:30:45<45:49,  2.12s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [2:30:47<44:18,  2.05s/it]                                                     {'loss': 0.0378, 'grad_norm': 3.3992743492126465, 'learning_rate': 2.198305084745763e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [2:30:47<44:18,  2.05s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [2:30:49<43:13,  2.00s/it]                                                     {'loss': 0.1932, 'grad_norm': 12.42027759552002, 'learning_rate': 2.196610169491526e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [2:30:49<43:13,  2.00s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [2:30:51<42:24,  1.97s/it]                                                     {'loss': 0.1307, 'grad_norm': 7.167627811431885, 'learning_rate': 2.1949152542372882e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [2:30:51<42:24,  1.97s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [2:30:53<41:41,  1.93s/it]                                                     {'loss': 0.2569, 'grad_norm': 7.430269241333008, 'learning_rate': 2.193220338983051e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [2:30:53<41:41,  1.93s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [2:30:54<41:10,  1.91s/it]                                                     {'loss': 0.0555, 'grad_norm': 3.7024285793304443, 'learning_rate': 2.1915254237288135e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [2:30:54<41:10,  1.91s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [2:30:56<40:51,  1.90s/it]                                                     {'loss': 0.0303, 'grad_norm': 3.3873610496520996, 'learning_rate': 2.1898305084745764e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [2:30:56<40:51,  1.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [2:30:58<40:32,  1.88s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.0135957021266222, 'learning_rate': 2.1881355932203392e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [2:30:58<40:32,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [2:31:00<40:40,  1.89s/it]                                                     {'loss': 0.0611, 'grad_norm': 5.09330940246582, 'learning_rate': 2.1864406779661016e-06, 'epoch': 0.79}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [2:31:00<40:40,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [2:31:02<40:35,  1.89s/it]                                                     {'loss': 0.1367, 'grad_norm': 4.3623738288879395, 'learning_rate': 2.1847457627118645e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [2:31:02<40:35,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [2:31:04<40:49,  1.90s/it]                                                     {'loss': 0.1136, 'grad_norm': 6.278051376342773, 'learning_rate': 2.1830508474576273e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [2:31:04<40:49,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [2:31:06<40:23,  1.88s/it]                                                     {'loss': 0.0061, 'grad_norm': 1.5115914344787598, 'learning_rate': 2.18135593220339e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [2:31:06<40:23,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [2:31:08<40:50,  1.91s/it]                                                     {'loss': 0.3132, 'grad_norm': 7.571059226989746, 'learning_rate': 2.1796610169491526e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [2:31:08<40:50,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [2:31:10<40:12,  1.88s/it]                                                     {'loss': 0.0564, 'grad_norm': 7.27842903137207, 'learning_rate': 2.1779661016949155e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [2:31:10<40:12,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [2:31:11<40:03,  1.87s/it]                                                     {'loss': 0.0159, 'grad_norm': 1.537399172782898, 'learning_rate': 2.1762711864406783e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [2:31:11<40:03,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [2:31:13<40:07,  1.88s/it]                                                     {'loss': 0.0208, 'grad_norm': 2.764772415161133, 'learning_rate': 2.174576271186441e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [2:31:13<40:07,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [2:31:15<40:41,  1.90s/it]                                                     {'loss': 0.0187, 'grad_norm': 2.644604206085205, 'learning_rate': 2.1728813559322036e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [2:31:15<40:41,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [2:31:17<40:40,  1.91s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.34970295429229736, 'learning_rate': 2.171186440677966e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [2:31:17<40:40,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [2:31:19<40:26,  1.90s/it]                                                     {'loss': 0.0762, 'grad_norm': 7.75651741027832, 'learning_rate': 2.169491525423729e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [2:31:19<40:26,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [2:31:21<39:53,  1.87s/it]                                                     {'loss': 0.0476, 'grad_norm': 5.411828517913818, 'learning_rate': 2.1677966101694917e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [2:31:21<39:53,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [2:31:23<39:47,  1.87s/it]                                                     {'loss': 0.0084, 'grad_norm': 1.451258897781372, 'learning_rate': 2.1661016949152546e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [2:31:23<39:47,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [2:31:25<39:45,  1.87s/it]                                                     {'loss': 0.1239, 'grad_norm': 8.956220626831055, 'learning_rate': 2.164406779661017e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [2:31:25<39:45,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [2:31:26<39:48,  1.87s/it]                                                     {'loss': 0.0905, 'grad_norm': 9.218615531921387, 'learning_rate': 2.16271186440678e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [2:31:26<39:48,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [2:31:28<39:55,  1.88s/it]                                                     {'loss': 0.0327, 'grad_norm': 3.3749325275421143, 'learning_rate': 2.1610169491525427e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [2:31:28<39:55,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [2:31:30<40:36,  1.91s/it]                                                     {'loss': 0.1445, 'grad_norm': 9.331767082214355, 'learning_rate': 2.1593220338983056e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [2:31:30<40:36,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [2:31:32<41:12,  1.94s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.09985984861850739, 'learning_rate': 2.157627118644068e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [2:31:32<41:12,  1.94s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [2:31:34<40:41,  1.92s/it]                                                     {'loss': 0.0286, 'grad_norm': 3.325572967529297, 'learning_rate': 2.1559322033898304e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [2:31:34<40:41,  1.92s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [2:31:36<40:30,  1.91s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.4193982183933258, 'learning_rate': 2.1542372881355933e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [2:31:36<40:30,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [2:31:38<40:13,  1.90s/it]                                                     {'loss': 0.0445, 'grad_norm': 1.7733103036880493, 'learning_rate': 2.152542372881356e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [2:31:38<40:13,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [2:31:40<39:50,  1.88s/it]                                                     {'loss': 0.0141, 'grad_norm': 2.9333090782165527, 'learning_rate': 2.150847457627119e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [2:31:40<39:50,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [2:31:42<39:29,  1.87s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.3704497516155243, 'learning_rate': 2.1491525423728814e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [2:31:42<39:29,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [2:31:44<40:01,  1.90s/it]                                                     {'loss': 0.1154, 'grad_norm': 5.7540364265441895, 'learning_rate': 2.1474576271186442e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [2:31:44<40:01,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [2:31:46<40:19,  1.91s/it]                                                     {'loss': 0.1232, 'grad_norm': 8.698517799377441, 'learning_rate': 2.145762711864407e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [2:31:46<40:19,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [2:31:47<39:57,  1.90s/it]                                                     {'loss': 0.0849, 'grad_norm': 7.716458797454834, 'learning_rate': 2.14406779661017e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [2:31:47<39:57,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [2:31:49<39:41,  1.88s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.26837897300720215, 'learning_rate': 2.1423728813559324e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [2:31:49<39:41,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [2:31:51<39:46,  1.89s/it]                                                     {'loss': 0.0129, 'grad_norm': 1.7284549474716187, 'learning_rate': 2.140677966101695e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [2:31:51<39:46,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [2:31:53<40:18,  1.92s/it]                                                     {'loss': 0.0605, 'grad_norm': 2.857114315032959, 'learning_rate': 2.1389830508474576e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [2:31:53<40:18,  1.92s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [2:31:55<40:04,  1.91s/it]                                                     {'loss': 0.0178, 'grad_norm': 2.4940340518951416, 'learning_rate': 2.1372881355932205e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [2:31:55<40:04,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [2:31:57<40:05,  1.91s/it]                                                     {'loss': 0.0817, 'grad_norm': 3.461463451385498, 'learning_rate': 2.1355932203389833e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [2:31:57<40:05,  1.91s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [2:31:59<39:34,  1.89s/it]                                                     {'loss': 0.2531, 'grad_norm': 14.968460083007812, 'learning_rate': 2.1338983050847458e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [2:31:59<39:34,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [2:32:01<39:43,  1.89s/it]                                                     {'loss': 0.0338, 'grad_norm': 5.502458095550537, 'learning_rate': 2.1322033898305086e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [2:32:01<39:43,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [2:32:03<39:23,  1.88s/it]                                                     {'loss': 0.0793, 'grad_norm': 5.183692932128906, 'learning_rate': 2.1305084745762715e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [2:32:03<39:23,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [2:32:04<39:19,  1.88s/it]                                                     {'loss': 0.1382, 'grad_norm': 17.67637062072754, 'learning_rate': 2.128813559322034e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [2:32:04<39:19,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [2:32:06<39:13,  1.87s/it]                                                     {'loss': 0.131, 'grad_norm': 7.217048645019531, 'learning_rate': 2.1271186440677967e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [2:32:06<39:13,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [2:32:08<39:15,  1.88s/it]                                                     {'loss': 0.0708, 'grad_norm': 4.898775577545166, 'learning_rate': 2.1254237288135596e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [2:32:08<39:15,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [2:32:10<39:46,  1.90s/it]                                                     {'loss': 0.1825, 'grad_norm': 16.744285583496094, 'learning_rate': 2.1237288135593224e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [2:32:10<39:46,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [2:32:12<39:35,  1.90s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.4495759606361389, 'learning_rate': 2.122033898305085e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [2:32:12<39:35,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [2:32:14<39:21,  1.89s/it]                                                     {'loss': 0.0592, 'grad_norm': 5.825050354003906, 'learning_rate': 2.1203389830508477e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [2:32:14<39:21,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [2:32:16<39:09,  1.88s/it]                                                     {'loss': 0.0131, 'grad_norm': 1.6464343070983887, 'learning_rate': 2.11864406779661e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [2:32:16<39:09,  1.88s/it][2025-11-12 00:25:31,692] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4750
[2025-11-12 00:25:31,699] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:25:31,992] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4750/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [2:32:18<44:18,  2.13s/it]                                                     {'loss': 0.0051, 'grad_norm': 0.49002689123153687, 'learning_rate': 2.116949152542373e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [2:32:18<44:18,  2.13s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [2:32:20<42:38,  2.05s/it]                                                     {'loss': 0.1005, 'grad_norm': 10.449799537658691, 'learning_rate': 2.115254237288136e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [2:32:20<42:38,  2.05s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [2:32:22<41:24,  1.99s/it]                                                     {'loss': 0.0206, 'grad_norm': 2.171750783920288, 'learning_rate': 2.1135593220338983e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [2:32:22<41:24,  1.99s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [2:32:24<40:22,  1.94s/it]                                                     {'loss': 0.0192, 'grad_norm': 2.263162136077881, 'learning_rate': 2.111864406779661e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [2:32:24<40:22,  1.94s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [2:32:26<39:53,  1.92s/it]                                                     {'loss': 0.0406, 'grad_norm': 4.342869758605957, 'learning_rate': 2.110169491525424e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [2:32:26<39:53,  1.92s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [2:32:28<39:25,  1.90s/it]                                                     {'loss': 0.0341, 'grad_norm': 4.042539596557617, 'learning_rate': 2.108474576271187e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [2:32:28<39:25,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [2:32:30<39:04,  1.89s/it]                                                     {'loss': 0.0158, 'grad_norm': 3.5074563026428223, 'learning_rate': 2.1067796610169492e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [2:32:30<39:04,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [2:32:31<39:00,  1.88s/it]                                                     {'loss': 0.0757, 'grad_norm': 6.39445686340332, 'learning_rate': 2.105084745762712e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [2:32:31<39:00,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [2:32:33<39:02,  1.89s/it]                                                     {'loss': 0.0031, 'grad_norm': 0.5455936789512634, 'learning_rate': 2.1033898305084745e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [2:32:33<39:02,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [2:32:35<38:50,  1.88s/it]                                                     {'loss': 0.1695, 'grad_norm': 9.144908905029297, 'learning_rate': 2.1016949152542374e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [2:32:35<38:50,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [2:32:37<38:46,  1.88s/it]                                                     {'loss': 0.0048, 'grad_norm': 0.7808327674865723, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [2:32:37<38:46,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [2:32:39<38:56,  1.89s/it]                                                     {'loss': 0.0216, 'grad_norm': 2.6243841648101807, 'learning_rate': 2.0983050847457626e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [2:32:39<38:56,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [2:32:41<38:43,  1.88s/it]                                                     {'loss': 0.2409, 'grad_norm': 8.842251777648926, 'learning_rate': 2.0966101694915255e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [2:32:41<38:43,  1.88s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [2:32:43<39:04,  1.90s/it]                                                     {'loss': 0.0031, 'grad_norm': 0.4945051968097687, 'learning_rate': 2.0949152542372883e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [2:32:43<39:04,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [2:32:45<39:09,  1.90s/it]                                                     {'loss': 0.1651, 'grad_norm': 5.8900322914123535, 'learning_rate': 2.093220338983051e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [2:32:45<39:09,  1.90s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [2:32:47<38:55,  1.89s/it]                                                     {'loss': 0.0141, 'grad_norm': 2.864820718765259, 'learning_rate': 2.0915254237288136e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [2:32:47<38:55,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [2:32:48<38:46,  1.89s/it]                                                     {'loss': 0.1278, 'grad_norm': 9.908671379089355, 'learning_rate': 2.0898305084745765e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [2:32:48<38:46,  1.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [2:32:50<38:23,  1.87s/it]                                                     {'loss': 0.0143, 'grad_norm': 1.4227731227874756, 'learning_rate': 2.0881355932203393e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [2:32:50<38:23,  1.87s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [2:32:52<38:18,  1.87s/it]                                                     {'loss': 0.2452, 'grad_norm': 10.395125389099121, 'learning_rate': 2.086440677966102e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [2:32:52<38:18,  1.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [2:32:54<38:25,  1.87s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.6974086165428162, 'learning_rate': 2.0847457627118646e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [2:32:54<38:25,  1.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [2:32:56<38:37,  1.89s/it]                                                     {'loss': 0.0488, 'grad_norm': 7.492047309875488, 'learning_rate': 2.083050847457627e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [2:32:56<38:37,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [2:32:58<38:27,  1.88s/it]                                                     {'loss': 0.0977, 'grad_norm': 9.831625938415527, 'learning_rate': 2.08135593220339e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [2:32:58<38:27,  1.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [2:33:00<38:41,  1.89s/it]                                                     {'loss': 0.0134, 'grad_norm': 2.3651719093322754, 'learning_rate': 2.0796610169491527e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [2:33:00<38:41,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [2:33:02<38:55,  1.90s/it]                                                     {'loss': 0.0767, 'grad_norm': 3.962226152420044, 'learning_rate': 2.0779661016949156e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [2:33:02<38:55,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [2:33:04<38:44,  1.90s/it]                                                     {'loss': 0.258, 'grad_norm': 9.256488800048828, 'learning_rate': 2.076271186440678e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [2:33:04<38:44,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [2:33:05<38:39,  1.89s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.2420995831489563, 'learning_rate': 2.074576271186441e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [2:33:05<38:39,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [2:33:07<39:16,  1.93s/it]                                                     {'loss': 0.0488, 'grad_norm': 4.026146411895752, 'learning_rate': 2.0728813559322037e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [2:33:07<39:16,  1.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [2:33:09<38:53,  1.91s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.2272406667470932, 'learning_rate': 2.0711864406779666e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [2:33:09<38:53,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [2:33:12<40:26,  1.99s/it]                                                     {'loss': 0.2571, 'grad_norm': 12.14388370513916, 'learning_rate': 2.069491525423729e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [2:33:12<40:26,  1.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [2:33:14<40:43,  2.00s/it]                                                     {'loss': 0.0181, 'grad_norm': 1.7694822549819946, 'learning_rate': 2.0677966101694914e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [2:33:14<40:43,  2.00s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [2:33:16<40:26,  1.99s/it]                                                     {'loss': 0.0725, 'grad_norm': 6.051405906677246, 'learning_rate': 2.0661016949152543e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [2:33:16<40:26,  1.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [2:33:17<39:36,  1.95s/it]                                                     {'loss': 0.0031, 'grad_norm': 0.4887344241142273, 'learning_rate': 2.064406779661017e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [2:33:17<39:36,  1.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [2:33:19<39:00,  1.92s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.24079836905002594, 'learning_rate': 2.06271186440678e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [2:33:19<39:00,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [2:33:21<39:21,  1.94s/it]                                                     {'loss': 0.3051, 'grad_norm': 11.447345733642578, 'learning_rate': 2.0610169491525424e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [2:33:21<39:21,  1.94s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [2:33:23<38:41,  1.91s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.3100106120109558, 'learning_rate': 2.0593220338983052e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [2:33:23<38:41,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [2:33:25<38:29,  1.90s/it]                                                     {'loss': 0.0217, 'grad_norm': 1.9528065919876099, 'learning_rate': 2.057627118644068e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [2:33:25<38:29,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [2:33:27<38:43,  1.92s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.09281110763549805, 'learning_rate': 2.055932203389831e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [2:33:27<38:43,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [2:33:29<38:54,  1.93s/it]                                                     {'loss': 0.0066, 'grad_norm': 0.7303488850593567, 'learning_rate': 2.0542372881355934e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [2:33:29<38:54,  1.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [2:33:31<38:35,  1.91s/it]                                                     {'loss': 0.0382, 'grad_norm': 4.4275360107421875, 'learning_rate': 2.0525423728813562e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [2:33:31<38:35,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [2:33:33<38:20,  1.90s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.18426619470119476, 'learning_rate': 2.0508474576271186e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [2:33:33<38:20,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [2:33:34<38:06,  1.89s/it]                                                     {'loss': 0.0147, 'grad_norm': 1.7460747957229614, 'learning_rate': 2.0491525423728815e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [2:33:34<38:06,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [2:33:36<38:42,  1.92s/it]                                                     {'loss': 0.0358, 'grad_norm': 4.836243152618408, 'learning_rate': 2.0474576271186443e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [2:33:36<38:42,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [2:33:38<38:32,  1.92s/it]                                                     {'loss': 0.1113, 'grad_norm': 9.02478313446045, 'learning_rate': 2.0457627118644068e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [2:33:38<38:32,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [2:33:40<38:25,  1.91s/it]                                                     {'loss': 0.049, 'grad_norm': 5.598129749298096, 'learning_rate': 2.0440677966101696e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [2:33:40<38:25,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [2:33:42<38:09,  1.90s/it]                                                     {'loss': 0.0829, 'grad_norm': 7.463778495788574, 'learning_rate': 2.0423728813559325e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [2:33:42<38:09,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [2:33:44<38:11,  1.90s/it]                                                     {'loss': 0.1058, 'grad_norm': 8.35511589050293, 'learning_rate': 2.0406779661016953e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [2:33:44<38:11,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [2:33:46<38:09,  1.90s/it]                                                     {'loss': 0.0169, 'grad_norm': 2.9524245262145996, 'learning_rate': 2.0389830508474577e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [2:33:46<38:09,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [2:33:48<37:41,  1.88s/it]                                                     {'loss': 0.0717, 'grad_norm': 6.871519565582275, 'learning_rate': 2.0372881355932206e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [2:33:48<37:41,  1.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [2:33:50<38:04,  1.90s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.6555672883987427, 'learning_rate': 2.0355932203389834e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [2:33:50<38:04,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [2:33:52<37:43,  1.89s/it]                                                     {'loss': 0.0797, 'grad_norm': 1.9825830459594727, 'learning_rate': 2.033898305084746e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [2:33:52<37:43,  1.89s/it][2025-11-12 00:27:07,491] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4800
[2025-11-12 00:27:07,499] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:27:07,781] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [2:33:54<42:34,  2.13s/it]                                                     {'loss': 0.018, 'grad_norm': 2.7752857208251953, 'learning_rate': 2.0322033898305087e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [2:33:54<42:34,  2.13s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [2:33:56<42:23,  2.12s/it]                                                     {'loss': 0.0198, 'grad_norm': 3.457933187484741, 'learning_rate': 2.030508474576271e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [2:33:56<42:23,  2.12s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [2:33:58<41:13,  2.07s/it]                                                     {'loss': 0.0472, 'grad_norm': 6.020132064819336, 'learning_rate': 2.028813559322034e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [2:33:58<41:13,  2.07s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [2:34:00<40:13,  2.02s/it]                                                     {'loss': 0.0548, 'grad_norm': 2.1618125438690186, 'learning_rate': 2.027118644067797e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [2:34:00<40:13,  2.02s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [2:34:02<39:39,  1.99s/it]                                                     {'loss': 0.1233, 'grad_norm': 5.828352451324463, 'learning_rate': 2.0254237288135593e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [2:34:02<39:39,  1.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [2:34:04<38:55,  1.96s/it]                                                     {'loss': 0.0351, 'grad_norm': 5.50332498550415, 'learning_rate': 2.023728813559322e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [2:34:04<38:55,  1.96s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [2:34:06<38:46,  1.95s/it]                                                     {'loss': 0.0377, 'grad_norm': 6.7992262840271, 'learning_rate': 2.022033898305085e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [2:34:06<38:46,  1.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [2:34:08<38:05,  1.92s/it]                                                     {'loss': 0.0077, 'grad_norm': 0.9110804200172424, 'learning_rate': 2.020338983050848e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [2:34:08<38:05,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [2:34:10<37:42,  1.90s/it]                                                     {'loss': 0.0047, 'grad_norm': 0.4630908668041229, 'learning_rate': 2.0186440677966103e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [2:34:10<37:42,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [2:34:12<37:23,  1.89s/it]                                                     {'loss': 0.1482, 'grad_norm': 7.506121635437012, 'learning_rate': 2.016949152542373e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [2:34:12<37:23,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [2:34:13<37:14,  1.88s/it]                                                     {'loss': 0.0174, 'grad_norm': 1.4571517705917358, 'learning_rate': 2.0152542372881355e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [2:34:13<37:14,  1.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [2:34:15<37:22,  1.89s/it]                                                     {'loss': 0.0516, 'grad_norm': 7.048626899719238, 'learning_rate': 2.0135593220338984e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [2:34:15<37:22,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [2:34:17<37:20,  1.89s/it]                                                     {'loss': 0.0217, 'grad_norm': 2.7722554206848145, 'learning_rate': 2.0118644067796612e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [2:34:17<37:20,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [2:34:19<38:53,  1.97s/it]                                                     {'loss': 0.0117, 'grad_norm': 2.1793341636657715, 'learning_rate': 2.0101694915254237e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [2:34:19<38:53,  1.97s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [2:34:21<38:10,  1.93s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.6195541024208069, 'learning_rate': 2.0084745762711865e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [2:34:21<38:10,  1.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [2:34:23<37:35,  1.91s/it]                                                     {'loss': 0.1426, 'grad_norm': 8.008593559265137, 'learning_rate': 2.0067796610169494e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [2:34:23<37:35,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [2:34:25<37:16,  1.89s/it]                                                     {'loss': 0.0784, 'grad_norm': 7.5839643478393555, 'learning_rate': 2.005084745762712e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [2:34:25<37:16,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [2:34:27<37:49,  1.92s/it]                                                     {'loss': 0.0219, 'grad_norm': 2.883190870285034, 'learning_rate': 2.0033898305084746e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [2:34:27<37:49,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [2:34:29<37:56,  1.93s/it]                                                     {'loss': 0.0515, 'grad_norm': 5.6191558837890625, 'learning_rate': 2.0016949152542375e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [2:34:29<37:56,  1.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [2:34:31<37:43,  1.92s/it]                                                     {'loss': 0.0259, 'grad_norm': 2.909177303314209, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [2:34:31<37:43,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [2:34:33<37:34,  1.91s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.2298021912574768, 'learning_rate': 1.998305084745763e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [2:34:33<37:34,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [2:34:35<37:36,  1.92s/it]                                                     {'loss': 0.0188, 'grad_norm': 2.0265142917633057, 'learning_rate': 1.9966101694915256e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [2:34:35<37:36,  1.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [2:34:36<37:22,  1.91s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.11016968637704849, 'learning_rate': 1.994915254237288e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [2:34:36<37:22,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [2:34:38<37:07,  1.89s/it]                                                     {'loss': 0.0684, 'grad_norm': 4.507142066955566, 'learning_rate': 1.993220338983051e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [2:34:38<37:07,  1.89s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [2:34:40<37:42,  1.93s/it]                                                     {'loss': 0.0372, 'grad_norm': 3.7522494792938232, 'learning_rate': 1.9915254237288137e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [2:34:40<37:42,  1.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [2:34:42<37:20,  1.91s/it]                                                     {'loss': 0.236, 'grad_norm': 9.948668479919434, 'learning_rate': 1.9898305084745766e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [2:34:42<37:20,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [2:34:44<37:18,  1.91s/it]                                                     {'loss': 0.3473, 'grad_norm': 12.569783210754395, 'learning_rate': 1.988135593220339e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [2:34:44<37:18,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [2:34:46<37:12,  1.91s/it]                                                     {'loss': 0.0252, 'grad_norm': 3.799818515777588, 'learning_rate': 1.986440677966102e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [2:34:46<37:12,  1.91s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [2:34:48<37:04,  1.90s/it]                                                     {'loss': 0.1933, 'grad_norm': 9.044272422790527, 'learning_rate': 1.9847457627118647e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [2:34:48<37:04,  1.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [2:34:50<39:59,  2.05s/it]                                                     {'loss': 0.0094, 'grad_norm': 0.9257903695106506, 'learning_rate': 1.9830508474576276e-06, 'epoch': 0.81}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [2:34:50<39:59,  2.05s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [2:34:52<39:20,  2.02s/it]                                                     {'loss': 0.0289, 'grad_norm': 3.89216685295105, 'learning_rate': 1.98135593220339e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [2:34:52<39:20,  2.02s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [2:34:54<38:26,  1.97s/it]                                                     {'loss': 0.0312, 'grad_norm': 1.0979812145233154, 'learning_rate': 1.9796610169491524e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [2:34:54<38:26,  1.97s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [2:34:56<38:49,  2.00s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.39049866795539856, 'learning_rate': 1.9779661016949153e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [2:34:56<38:49,  2.00s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [2:34:58<38:01,  1.96s/it]                                                     {'loss': 0.0366, 'grad_norm': 5.289918422698975, 'learning_rate': 1.976271186440678e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [2:34:58<38:01,  1.96s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [2:35:00<38:48,  2.00s/it]                                                     {'loss': 0.0224, 'grad_norm': 2.1236796379089355, 'learning_rate': 1.974576271186441e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [2:35:00<38:48,  2.00s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [2:35:02<38:04,  1.96s/it]                                                     {'loss': 0.1017, 'grad_norm': 6.531042098999023, 'learning_rate': 1.9728813559322034e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [2:35:02<38:04,  1.96s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [2:35:04<37:30,  1.93s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.4699402451515198, 'learning_rate': 1.9711864406779662e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [2:35:04<37:30,  1.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [2:35:06<37:57,  1.96s/it]                                                     {'loss': 0.1, 'grad_norm': 5.716704368591309, 'learning_rate': 1.969491525423729e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [2:35:06<37:57,  1.96s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [2:35:08<40:15,  2.08s/it]                                                     {'loss': 0.1077, 'grad_norm': 7.397094249725342, 'learning_rate': 1.967796610169492e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [2:35:08<40:15,  2.08s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [2:35:10<39:04,  2.02s/it]                                                     {'loss': 0.2498, 'grad_norm': 7.139683723449707, 'learning_rate': 1.9661016949152544e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [2:35:10<39:04,  2.02s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [2:35:12<38:19,  1.98s/it]                                                     {'loss': 0.0238, 'grad_norm': 2.4389519691467285, 'learning_rate': 1.9644067796610172e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [2:35:12<38:19,  1.98s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [2:35:14<37:47,  1.96s/it]                                                     {'loss': 0.0215, 'grad_norm': 3.5110182762145996, 'learning_rate': 1.9627118644067796e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [2:35:14<37:47,  1.96s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [2:35:16<37:49,  1.96s/it]                                                     {'loss': 0.2887, 'grad_norm': 11.644316673278809, 'learning_rate': 1.9610169491525425e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [2:35:16<37:49,  1.96s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [2:35:18<37:25,  1.94s/it]                                                     {'loss': 0.0104, 'grad_norm': 2.3749570846557617, 'learning_rate': 1.9593220338983053e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [2:35:18<37:25,  1.94s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [2:35:20<37:03,  1.93s/it]                                                     {'loss': 0.3116, 'grad_norm': 9.754887580871582, 'learning_rate': 1.9576271186440678e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [2:35:20<37:03,  1.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [2:35:21<36:27,  1.90s/it]                                                     {'loss': 0.0528, 'grad_norm': 1.746699571609497, 'learning_rate': 1.9559322033898306e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [2:35:21<36:27,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [2:35:23<36:25,  1.90s/it]                                                     {'loss': 0.0212, 'grad_norm': 2.1397759914398193, 'learning_rate': 1.9542372881355935e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [2:35:23<36:25,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [2:35:25<36:15,  1.89s/it]                                                     {'loss': 0.0095, 'grad_norm': 1.545696496963501, 'learning_rate': 1.9525423728813563e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [2:35:25<36:15,  1.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [2:35:27<36:25,  1.90s/it]                                                     {'loss': 0.0583, 'grad_norm': 6.489271640777588, 'learning_rate': 1.9508474576271188e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [2:35:27<36:25,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [2:35:29<36:05,  1.88s/it]                                                     {'loss': 0.0644, 'grad_norm': 3.519667625427246, 'learning_rate': 1.9491525423728816e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [2:35:29<36:05,  1.88s/it][2025-11-12 00:28:44,913] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4850
[2025-11-12 00:28:44,921] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:28:45,208] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4850/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [2:35:32<41:17,  2.16s/it]                                                     {'loss': 0.2006, 'grad_norm': 9.350852966308594, 'learning_rate': 1.9474576271186445e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [2:35:32<41:17,  2.16s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [2:35:34<39:34,  2.07s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.13813836872577667, 'learning_rate': 1.945762711864407e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [2:35:34<39:34,  2.07s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [2:35:36<39:12,  2.05s/it]                                                     {'loss': 0.0405, 'grad_norm': 7.709936618804932, 'learning_rate': 1.9440677966101697e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [2:35:36<39:12,  2.05s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [2:35:38<38:17,  2.00s/it]                                                     {'loss': 0.3401, 'grad_norm': 13.125052452087402, 'learning_rate': 1.942372881355932e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [2:35:38<38:17,  2.00s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [2:35:39<37:57,  1.99s/it]                                                     {'loss': 0.0831, 'grad_norm': 6.239118576049805, 'learning_rate': 1.940677966101695e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [2:35:39<37:57,  1.99s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [2:35:41<37:01,  1.94s/it]                                                     {'loss': 0.0359, 'grad_norm': 5.233615875244141, 'learning_rate': 1.938983050847458e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [2:35:41<37:01,  1.94s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [2:35:43<36:27,  1.91s/it]                                                     {'loss': 0.0122, 'grad_norm': 1.7842538356781006, 'learning_rate': 1.9372881355932203e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [2:35:43<36:27,  1.91s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [2:35:45<37:10,  1.95s/it]                                                     {'loss': 0.2782, 'grad_norm': 8.701051712036133, 'learning_rate': 1.935593220338983e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [2:35:45<37:10,  1.95s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [2:35:47<37:37,  1.98s/it]                                                     {'loss': 0.0552, 'grad_norm': 5.056069850921631, 'learning_rate': 1.933898305084746e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [2:35:47<37:37,  1.98s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [2:35:49<36:44,  1.93s/it]                                                     {'loss': 0.0756, 'grad_norm': 7.392292022705078, 'learning_rate': 1.932203389830509e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [2:35:49<36:44,  1.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [2:35:51<36:23,  1.92s/it]                                                     {'loss': 0.0184, 'grad_norm': 2.8712899684906006, 'learning_rate': 1.9305084745762713e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [2:35:51<36:23,  1.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [2:35:53<36:10,  1.91s/it]                                                     {'loss': 0.0523, 'grad_norm': 5.7789459228515625, 'learning_rate': 1.928813559322034e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [2:35:53<36:10,  1.91s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [2:35:55<35:57,  1.90s/it]                                                     {'loss': 0.0851, 'grad_norm': 6.269329071044922, 'learning_rate': 1.9271186440677965e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [2:35:55<35:57,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [2:35:57<36:36,  1.93s/it]                                                     {'loss': 0.0881, 'grad_norm': 4.907283782958984, 'learning_rate': 1.9254237288135594e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [2:35:57<36:36,  1.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [2:35:59<36:36,  1.94s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.5528698563575745, 'learning_rate': 1.9237288135593222e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [2:35:59<36:36,  1.94s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [2:36:01<36:13,  1.92s/it]                                                     {'loss': 0.1015, 'grad_norm': 7.694652080535889, 'learning_rate': 1.9220338983050847e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [2:36:01<36:13,  1.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [2:36:02<35:52,  1.90s/it]                                                     {'loss': 0.0102, 'grad_norm': 1.139275312423706, 'learning_rate': 1.9203389830508475e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [2:36:02<35:52,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [2:36:04<35:46,  1.90s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.18677380681037903, 'learning_rate': 1.9186440677966104e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [2:36:04<35:46,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [2:36:06<35:48,  1.90s/it]                                                     {'loss': 0.0393, 'grad_norm': 5.797206878662109, 'learning_rate': 1.9169491525423732e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [2:36:06<35:48,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [2:36:08<35:31,  1.89s/it]                                                     {'loss': 0.0093, 'grad_norm': 1.5256116390228271, 'learning_rate': 1.9152542372881356e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [2:36:08<35:31,  1.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [2:36:10<36:12,  1.92s/it]                                                     {'loss': 0.0469, 'grad_norm': 5.679196357727051, 'learning_rate': 1.9135593220338985e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [2:36:10<36:12,  1.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [2:36:12<36:15,  1.93s/it]                                                     {'loss': 0.099, 'grad_norm': 4.317647457122803, 'learning_rate': 1.9118644067796613e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [2:36:12<36:15,  1.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [2:36:14<36:05,  1.92s/it]                                                     {'loss': 0.01, 'grad_norm': 1.2078624963760376, 'learning_rate': 1.9101694915254238e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [2:36:14<36:05,  1.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [2:36:16<36:03,  1.92s/it]                                                     {'loss': 0.0054, 'grad_norm': 1.072802186012268, 'learning_rate': 1.9084745762711866e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [2:36:16<36:03,  1.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [2:36:18<35:40,  1.90s/it]                                                     {'loss': 0.0107, 'grad_norm': 2.20119309425354, 'learning_rate': 1.9067796610169493e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [2:36:18<35:40,  1.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [2:36:20<36:21,  1.94s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.7447500228881836, 'learning_rate': 1.9050847457627119e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [2:36:20<36:21,  1.94s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [2:36:22<36:06,  1.93s/it]                                                     {'loss': 0.1366, 'grad_norm': 9.727473258972168, 'learning_rate': 1.9033898305084747e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [2:36:22<36:06,  1.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [2:36:24<35:51,  1.92s/it]                                                     {'loss': 0.0625, 'grad_norm': 6.328099727630615, 'learning_rate': 1.9016949152542374e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [2:36:24<35:51,  1.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [2:36:25<35:44,  1.91s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.35398048162460327, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [2:36:25<35:44,  1.91s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [2:36:27<35:36,  1.91s/it]                                                     {'loss': 0.0226, 'grad_norm': 3.2799148559570312, 'learning_rate': 1.8983050847457629e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [2:36:27<35:36,  1.91s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [2:36:29<35:14,  1.89s/it]                                                     {'loss': 0.0103, 'grad_norm': 1.634337067604065, 'learning_rate': 1.8966101694915257e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [2:36:29<35:14,  1.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [2:36:31<35:01,  1.88s/it]                                                     {'loss': 0.1378, 'grad_norm': 6.227133274078369, 'learning_rate': 1.8949152542372884e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [2:36:31<35:01,  1.88s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [2:36:33<34:44,  1.87s/it]                                                     {'loss': 0.1377, 'grad_norm': 6.2455220222473145, 'learning_rate': 1.8932203389830512e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [2:36:33<34:44,  1.87s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [2:36:35<34:43,  1.87s/it]                                                     {'loss': 0.3502, 'grad_norm': 9.1607666015625, 'learning_rate': 1.8915254237288136e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [2:36:35<34:43,  1.87s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [2:36:37<35:08,  1.89s/it]                                                     {'loss': 0.2827, 'grad_norm': 14.430997848510742, 'learning_rate': 1.8898305084745763e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [2:36:37<35:08,  1.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [2:36:39<35:04,  1.89s/it]                                                     {'loss': 0.123, 'grad_norm': 7.347528457641602, 'learning_rate': 1.8881355932203391e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [2:36:39<35:04,  1.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [2:36:40<35:03,  1.89s/it]                                                     {'loss': 0.0064, 'grad_norm': 0.7800816893577576, 'learning_rate': 1.8864406779661018e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [2:36:40<35:03,  1.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [2:36:42<34:54,  1.88s/it]                                                     {'loss': 0.0371, 'grad_norm': 3.706024408340454, 'learning_rate': 1.8847457627118646e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [2:36:42<34:54,  1.88s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [2:36:44<34:37,  1.87s/it]                                                     {'loss': 0.0196, 'grad_norm': 1.3400614261627197, 'learning_rate': 1.8830508474576273e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [2:36:44<34:37,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [2:36:46<34:32,  1.87s/it]                                                     {'loss': 0.3205, 'grad_norm': 16.059965133666992, 'learning_rate': 1.88135593220339e-06, 'epoch': 0.81}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [2:36:46<34:32,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [2:36:48<34:24,  1.86s/it]                                                     {'loss': 0.1564, 'grad_norm': 8.073320388793945, 'learning_rate': 1.8796610169491527e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [2:36:48<34:24,  1.86s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [2:36:50<34:29,  1.87s/it]                                                     {'loss': 0.2175, 'grad_norm': 11.251787185668945, 'learning_rate': 1.8779661016949156e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [2:36:50<34:29,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [2:36:52<34:33,  1.87s/it]                                                     {'loss': 0.0072, 'grad_norm': 0.7888177037239075, 'learning_rate': 1.8762711864406782e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [2:36:52<34:33,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [2:36:53<34:22,  1.86s/it]                                                     {'loss': 0.1367, 'grad_norm': 16.780244827270508, 'learning_rate': 1.8745762711864407e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [2:36:53<34:22,  1.86s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [2:36:55<34:25,  1.87s/it]                                                     {'loss': 0.0388, 'grad_norm': 4.293053150177002, 'learning_rate': 1.8728813559322035e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [2:36:55<34:25,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [2:36:57<34:11,  1.86s/it]                                                     {'loss': 0.0173, 'grad_norm': 0.9078096151351929, 'learning_rate': 1.8711864406779661e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [2:36:57<34:11,  1.86s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [2:36:59<34:11,  1.86s/it]                                                     {'loss': 0.0957, 'grad_norm': 4.13899564743042, 'learning_rate': 1.869491525423729e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [2:36:59<34:11,  1.86s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [2:37:01<34:18,  1.87s/it]                                                     {'loss': 0.1596, 'grad_norm': 4.345307350158691, 'learning_rate': 1.8677966101694916e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [2:37:01<34:18,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [2:37:03<34:30,  1.88s/it]                                                     {'loss': 0.1132, 'grad_norm': 8.39211654663086, 'learning_rate': 1.8661016949152545e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [2:37:03<34:30,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [2:37:05<34:57,  1.91s/it]                                                     {'loss': 0.0151, 'grad_norm': 2.4141101837158203, 'learning_rate': 1.8644067796610171e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [2:37:05<34:57,  1.91s/it][2025-11-12 00:30:20,743] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4900
[2025-11-12 00:30:20,749] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:30:21,037] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [2:37:08<39:21,  2.15s/it]                                                     {'loss': 0.0726, 'grad_norm': 4.956767559051514, 'learning_rate': 1.86271186440678e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [2:37:08<39:21,  2.15s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [2:37:09<37:51,  2.07s/it]                                                     {'loss': 0.0511, 'grad_norm': 4.61142635345459, 'learning_rate': 1.8610169491525426e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [2:37:09<37:51,  2.07s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [2:37:11<37:05,  2.03s/it]                                                     {'loss': 0.0074, 'grad_norm': 1.5659878253936768, 'learning_rate': 1.8593220338983052e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [2:37:11<37:05,  2.03s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [2:37:13<36:20,  1.99s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.2709306478500366, 'learning_rate': 1.857627118644068e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [2:37:13<36:20,  1.99s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [2:37:15<35:59,  1.97s/it]                                                     {'loss': 0.0266, 'grad_norm': 2.4084877967834473, 'learning_rate': 1.8559322033898305e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [2:37:15<35:59,  1.97s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [2:37:17<35:16,  1.93s/it]                                                     {'loss': 0.1365, 'grad_norm': 7.545217514038086, 'learning_rate': 1.8542372881355934e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [2:37:17<35:16,  1.93s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [2:37:19<34:52,  1.91s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.3614988327026367, 'learning_rate': 1.852542372881356e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [2:37:19<34:52,  1.91s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [2:37:21<34:28,  1.89s/it]                                                     {'loss': 0.2632, 'grad_norm': 9.799249649047852, 'learning_rate': 1.8508474576271189e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [2:37:21<34:28,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [2:37:23<34:19,  1.89s/it]                                                     {'loss': 0.0033, 'grad_norm': 0.2349092662334442, 'learning_rate': 1.8491525423728815e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [2:37:23<34:19,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [2:37:24<34:10,  1.88s/it]                                                     {'loss': 0.0827, 'grad_norm': 5.210388660430908, 'learning_rate': 1.8474576271186441e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [2:37:24<34:10,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [2:37:26<34:01,  1.87s/it]                                                     {'loss': 0.1838, 'grad_norm': 8.583144187927246, 'learning_rate': 1.845762711864407e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [2:37:26<34:01,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [2:37:28<33:56,  1.87s/it]                                                     {'loss': 0.0634, 'grad_norm': 2.65352463722229, 'learning_rate': 1.8440677966101696e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [2:37:28<33:56,  1.87s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [2:37:30<34:01,  1.88s/it]                                                     {'loss': 0.002, 'grad_norm': 0.38337117433547974, 'learning_rate': 1.8423728813559325e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [2:37:30<34:01,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [2:37:32<33:59,  1.88s/it]                                                     {'loss': 0.0383, 'grad_norm': 2.600640296936035, 'learning_rate': 1.8406779661016951e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [2:37:32<33:59,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [2:37:34<34:05,  1.89s/it]                                                     {'loss': 0.1019, 'grad_norm': 7.593238830566406, 'learning_rate': 1.8389830508474578e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [2:37:34<34:05,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [2:37:36<34:07,  1.89s/it]                                                     {'loss': 0.0386, 'grad_norm': 4.82729434967041, 'learning_rate': 1.8372881355932204e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [2:37:36<34:07,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [2:37:38<34:10,  1.89s/it]                                                     {'loss': 0.0268, 'grad_norm': 1.7271217107772827, 'learning_rate': 1.835593220338983e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [2:37:38<34:10,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [2:37:40<34:27,  1.91s/it]                                                     {'loss': 0.0685, 'grad_norm': 4.150020599365234, 'learning_rate': 1.8338983050847459e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [2:37:40<34:27,  1.91s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [2:37:42<34:18,  1.90s/it]                                                     {'loss': 0.0771, 'grad_norm': 6.877790451049805, 'learning_rate': 1.8322033898305085e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [2:37:42<34:18,  1.90s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [2:37:43<34:05,  1.89s/it]                                                     {'loss': 0.0216, 'grad_norm': 3.6162118911743164, 'learning_rate': 1.8305084745762714e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [2:37:43<34:05,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [2:37:45<33:58,  1.89s/it]                                                     {'loss': 0.0796, 'grad_norm': 6.592693328857422, 'learning_rate': 1.828813559322034e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [2:37:45<33:58,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [2:37:47<34:45,  1.94s/it]                                                     {'loss': 0.0403, 'grad_norm': 4.557078838348389, 'learning_rate': 1.8271186440677969e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [2:37:47<34:45,  1.94s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [2:37:49<34:26,  1.92s/it]                                                     {'loss': 0.0851, 'grad_norm': 4.42876672744751, 'learning_rate': 1.8254237288135595e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [2:37:49<34:26,  1.92s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [2:37:51<33:51,  1.89s/it]                                                     {'loss': 0.0476, 'grad_norm': 2.7241578102111816, 'learning_rate': 1.8237288135593223e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [2:37:51<33:51,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [2:37:53<34:22,  1.92s/it]                                                     {'loss': 0.0522, 'grad_norm': 3.707456588745117, 'learning_rate': 1.8220338983050848e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [2:37:53<34:22,  1.92s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [2:37:55<34:05,  1.90s/it]                                                     {'loss': 0.0305, 'grad_norm': 2.948509931564331, 'learning_rate': 1.8203389830508474e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [2:37:55<34:05,  1.90s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [2:37:57<33:46,  1.89s/it]                                                     {'loss': 0.0916, 'grad_norm': 8.608806610107422, 'learning_rate': 1.8186440677966103e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [2:37:57<33:46,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [2:37:59<34:23,  1.93s/it]                                                     {'loss': 0.2635, 'grad_norm': 13.108407974243164, 'learning_rate': 1.816949152542373e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [2:37:59<34:23,  1.93s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [2:38:01<34:10,  1.91s/it]                                                     {'loss': 0.0075, 'grad_norm': 1.3848117589950562, 'learning_rate': 1.8152542372881357e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [2:38:01<34:10,  1.91s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [2:38:02<33:35,  1.88s/it]                                                     {'loss': 0.0248, 'grad_norm': 2.8984618186950684, 'learning_rate': 1.8135593220338984e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [2:38:02<33:35,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [2:38:04<33:51,  1.90s/it]                                                     {'loss': 0.0074, 'grad_norm': 1.5588644742965698, 'learning_rate': 1.8118644067796612e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [2:38:04<33:51,  1.90s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [2:38:06<33:39,  1.89s/it]                                                     {'loss': 0.0963, 'grad_norm': 8.002005577087402, 'learning_rate': 1.8101694915254239e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [2:38:06<33:39,  1.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [2:38:08<33:21,  1.88s/it]                                                     {'loss': 0.29, 'grad_norm': 11.558228492736816, 'learning_rate': 1.8084745762711867e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [2:38:08<33:21,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [2:38:10<33:22,  1.88s/it]                                                     {'loss': 0.0982, 'grad_norm': 6.998218059539795, 'learning_rate': 1.8067796610169494e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [2:38:10<33:22,  1.88s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [2:38:12<33:42,  1.90s/it]                                                     {'loss': 0.02, 'grad_norm': 2.8624672889709473, 'learning_rate': 1.8050847457627122e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [2:38:12<33:42,  1.90s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [2:38:14<35:43,  2.02s/it]                                                     {'loss': 0.0371, 'grad_norm': 4.290267467498779, 'learning_rate': 1.8033898305084746e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [2:38:14<35:43,  2.02s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [2:38:17<37:12,  2.10s/it]                                                     {'loss': 0.0045, 'grad_norm': 0.4615859091281891, 'learning_rate': 1.8016949152542373e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [2:38:17<37:12,  2.10s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [2:38:18<36:15,  2.05s/it]                                                     {'loss': 0.0282, 'grad_norm': 6.599706172943115, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [2:38:18<36:15,  2.05s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [2:38:20<35:59,  2.04s/it]                                                     {'loss': 0.0626, 'grad_norm': 6.7002434730529785, 'learning_rate': 1.7983050847457628e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [2:38:20<35:59,  2.04s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [2:38:22<35:28,  2.01s/it]                                                     {'loss': 0.2233, 'grad_norm': 11.124551773071289, 'learning_rate': 1.7966101694915256e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [2:38:22<35:28,  2.01s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [2:38:24<34:46,  1.97s/it]                                                     {'loss': 0.0483, 'grad_norm': 5.092860221862793, 'learning_rate': 1.7949152542372883e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [2:38:24<34:46,  1.97s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [2:38:26<34:20,  1.95s/it]                                                     {'loss': 0.0134, 'grad_norm': 1.6332952976226807, 'learning_rate': 1.7932203389830511e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [2:38:26<34:20,  1.95s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [2:38:28<33:56,  1.93s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.036636244505643845, 'learning_rate': 1.7915254237288137e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [2:38:28<33:56,  1.93s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [2:38:30<33:38,  1.91s/it]                                                     {'loss': 0.1473, 'grad_norm': 10.201654434204102, 'learning_rate': 1.7898305084745766e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [2:38:30<33:38,  1.91s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [2:38:32<34:02,  1.94s/it]                                                     {'loss': 0.0162, 'grad_norm': 2.859412670135498, 'learning_rate': 1.7881355932203392e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [2:38:32<34:02,  1.94s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [2:38:34<33:46,  1.92s/it]                                                     {'loss': 0.0576, 'grad_norm': 6.146669864654541, 'learning_rate': 1.7864406779661017e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [2:38:34<33:46,  1.92s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [2:38:36<33:32,  1.91s/it]                                                     {'loss': 0.0269, 'grad_norm': 2.4557037353515625, 'learning_rate': 1.7847457627118645e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [2:38:36<33:32,  1.91s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [2:38:38<35:29,  2.02s/it]                                                     {'loss': 0.1507, 'grad_norm': 8.473688125610352, 'learning_rate': 1.7830508474576271e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [2:38:38<35:29,  2.02s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [2:38:40<34:31,  1.97s/it]                                                     {'loss': 0.0616, 'grad_norm': 6.6480536460876465, 'learning_rate': 1.78135593220339e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [2:38:40<34:31,  1.97s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [2:38:42<33:47,  1.93s/it]                                                     {'loss': 0.1262, 'grad_norm': 8.308085441589355, 'learning_rate': 1.7796610169491526e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [2:38:42<33:47,  1.93s/it][2025-11-12 00:31:57,568] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4950
[2025-11-12 00:31:57,574] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:31:57,849] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4950/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [2:38:44<38:32,  2.20s/it]                                                     {'loss': 0.0084, 'grad_norm': 1.2701504230499268, 'learning_rate': 1.7779661016949155e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [2:38:44<38:32,  2.20s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [2:38:47<37:34,  2.15s/it]                                                     {'loss': 0.1652, 'grad_norm': 10.547842025756836, 'learning_rate': 1.7762711864406781e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [2:38:47<37:34,  2.15s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [2:38:48<35:58,  2.06s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.01211851928383112, 'learning_rate': 1.774576271186441e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [2:38:48<35:58,  2.06s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [2:38:50<35:35,  2.04s/it]                                                     {'loss': 0.004, 'grad_norm': 0.5492149591445923, 'learning_rate': 1.7728813559322036e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [2:38:50<35:35,  2.04s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [2:38:52<34:46,  2.00s/it]                                                     {'loss': 0.347, 'grad_norm': 19.84674835205078, 'learning_rate': 1.7711864406779663e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [2:38:52<34:46,  2.00s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [2:38:54<34:10,  1.96s/it]                                                     {'loss': 0.0514, 'grad_norm': 7.957452774047852, 'learning_rate': 1.769491525423729e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [2:38:54<34:10,  1.96s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [2:38:56<33:59,  1.96s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.10195629298686981, 'learning_rate': 1.7677966101694915e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [2:38:56<33:59,  1.96s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [2:38:58<33:28,  1.93s/it]                                                     {'loss': 0.0599, 'grad_norm': 8.245183944702148, 'learning_rate': 1.7661016949152544e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [2:38:58<33:28,  1.93s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [2:39:00<33:44,  1.94s/it]                                                     {'loss': 0.0428, 'grad_norm': 4.732071399688721, 'learning_rate': 1.764406779661017e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [2:39:00<33:44,  1.94s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [2:39:02<33:29,  1.93s/it]                                                     {'loss': 0.0078, 'grad_norm': 1.4711545705795288, 'learning_rate': 1.7627118644067799e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [2:39:02<33:29,  1.93s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [2:39:04<33:26,  1.93s/it]                                                     {'loss': 0.0884, 'grad_norm': 8.172847747802734, 'learning_rate': 1.7610169491525425e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [2:39:04<33:26,  1.93s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [2:39:06<34:12,  1.98s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.9559406638145447, 'learning_rate': 1.7593220338983051e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [2:39:06<34:12,  1.98s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [2:39:08<33:25,  1.93s/it]                                                     {'loss': 0.187, 'grad_norm': 10.875870704650879, 'learning_rate': 1.757627118644068e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [2:39:08<33:25,  1.93s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [2:39:10<32:50,  1.90s/it]                                                     {'loss': 0.0242, 'grad_norm': 3.327171564102173, 'learning_rate': 1.7559322033898306e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [2:39:10<32:50,  1.90s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [2:39:11<32:49,  1.90s/it]                                                     {'loss': 0.0306, 'grad_norm': 7.616243362426758, 'learning_rate': 1.7542372881355935e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [2:39:11<32:49,  1.90s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [2:39:13<32:51,  1.91s/it]                                                     {'loss': 0.0092, 'grad_norm': 1.1562544107437134, 'learning_rate': 1.7525423728813561e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [2:39:13<32:51,  1.91s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [2:39:15<32:53,  1.91s/it]                                                     {'loss': 0.0543, 'grad_norm': 8.067100524902344, 'learning_rate': 1.7508474576271188e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [2:39:15<32:53,  1.91s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [2:39:17<32:34,  1.89s/it]                                                     {'loss': 0.0332, 'grad_norm': 2.6078765392303467, 'learning_rate': 1.7491525423728814e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [2:39:17<32:34,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [2:39:19<32:15,  1.88s/it]                                                     {'loss': 0.1039, 'grad_norm': 7.020289421081543, 'learning_rate': 1.747457627118644e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [2:39:19<32:15,  1.88s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [2:39:21<32:15,  1.88s/it]                                                     {'loss': 0.038, 'grad_norm': 4.8142523765563965, 'learning_rate': 1.7457627118644069e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [2:39:21<32:15,  1.88s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [2:39:23<32:08,  1.87s/it]                                                     {'loss': 0.0498, 'grad_norm': 2.8784244060516357, 'learning_rate': 1.7440677966101695e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [2:39:23<32:08,  1.87s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [2:39:25<32:07,  1.87s/it]                                                     {'loss': 0.071, 'grad_norm': 6.787693500518799, 'learning_rate': 1.7423728813559324e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [2:39:25<32:07,  1.87s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [2:39:26<32:06,  1.88s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.3219180405139923, 'learning_rate': 1.740677966101695e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [2:39:26<32:06,  1.88s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [2:39:28<32:28,  1.90s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.3345074951648712, 'learning_rate': 1.7389830508474579e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [2:39:28<32:28,  1.90s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [2:39:30<32:26,  1.90s/it]                                                     {'loss': 0.2258, 'grad_norm': 9.528877258300781, 'learning_rate': 1.7372881355932205e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [2:39:30<32:26,  1.90s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [2:39:32<32:13,  1.89s/it]                                                     {'loss': 0.0131, 'grad_norm': 1.9400243759155273, 'learning_rate': 1.7355932203389834e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [2:39:32<32:13,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [2:39:34<31:55,  1.87s/it]                                                     {'loss': 0.0072, 'grad_norm': 0.6819325089454651, 'learning_rate': 1.7338983050847458e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [2:39:34<31:55,  1.87s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [2:39:36<32:00,  1.88s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.055049363523721695, 'learning_rate': 1.7322033898305084e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [2:39:36<32:00,  1.88s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [2:39:38<32:13,  1.89s/it]                                                     {'loss': 0.0454, 'grad_norm': 3.0102198123931885, 'learning_rate': 1.7305084745762713e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [2:39:38<32:13,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [2:39:40<32:31,  1.91s/it]                                                     {'loss': 0.1297, 'grad_norm': 5.624168872833252, 'learning_rate': 1.728813559322034e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [2:39:40<32:31,  1.91s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4981/6000 [2:39:42<35:53,  2.11s/it]                                                     {'loss': 0.0649, 'grad_norm': 5.795129776000977, 'learning_rate': 1.7271186440677968e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4981/6000 [2:39:42<35:53,  2.11s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4982/6000 [2:39:44<34:38,  2.04s/it]                                                     {'loss': 0.4292, 'grad_norm': 10.074804306030273, 'learning_rate': 1.7254237288135594e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4982/6000 [2:39:44<34:38,  2.04s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4983/6000 [2:39:46<33:46,  1.99s/it]                                                     {'loss': 0.278, 'grad_norm': 7.378624439239502, 'learning_rate': 1.7237288135593222e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4983/6000 [2:39:46<33:46,  1.99s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4984/6000 [2:39:48<33:11,  1.96s/it]                                                     {'loss': 0.0203, 'grad_norm': 2.503098249435425, 'learning_rate': 1.7220338983050849e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4984/6000 [2:39:48<33:11,  1.96s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4985/6000 [2:39:50<32:53,  1.94s/it]                                                     {'loss': 0.039, 'grad_norm': 5.5187530517578125, 'learning_rate': 1.7203389830508477e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4985/6000 [2:39:50<32:53,  1.94s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4986/6000 [2:39:52<32:20,  1.91s/it]                                                     {'loss': 0.0908, 'grad_norm': 10.433673858642578, 'learning_rate': 1.7186440677966104e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4986/6000 [2:39:52<32:20,  1.91s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4987/6000 [2:39:54<31:58,  1.89s/it]                                                     {'loss': 0.0406, 'grad_norm': 4.9229631423950195, 'learning_rate': 1.7169491525423732e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4987/6000 [2:39:54<31:58,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4988/6000 [2:39:55<31:59,  1.90s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.0960250049829483, 'learning_rate': 1.7152542372881356e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4988/6000 [2:39:55<31:59,  1.90s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4989/6000 [2:39:57<31:55,  1.89s/it]                                                     {'loss': 0.0067, 'grad_norm': 1.238763689994812, 'learning_rate': 1.7135593220338983e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4989/6000 [2:39:57<31:55,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4990/6000 [2:39:59<31:48,  1.89s/it]                                                     {'loss': 0.0069, 'grad_norm': 1.281599998474121, 'learning_rate': 1.7118644067796611e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4990/6000 [2:39:59<31:48,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4991/6000 [2:40:01<31:49,  1.89s/it]                                                     {'loss': 0.0759, 'grad_norm': 5.063027858734131, 'learning_rate': 1.7101694915254238e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4991/6000 [2:40:01<31:49,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4992/6000 [2:40:03<31:47,  1.89s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.01842409186065197, 'learning_rate': 1.7084745762711866e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4992/6000 [2:40:03<31:47,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4993/6000 [2:40:05<32:10,  1.92s/it]                                                     {'loss': 0.1077, 'grad_norm': 5.073773384094238, 'learning_rate': 1.7067796610169493e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4993/6000 [2:40:05<32:10,  1.92s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4994/6000 [2:40:07<31:51,  1.90s/it]                                                     {'loss': 0.0572, 'grad_norm': 2.914294481277466, 'learning_rate': 1.7050847457627121e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4994/6000 [2:40:07<31:51,  1.90s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4995/6000 [2:40:09<31:40,  1.89s/it]                                                     {'loss': 0.0101, 'grad_norm': 1.7736961841583252, 'learning_rate': 1.7033898305084748e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4995/6000 [2:40:09<31:40,  1.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4996/6000 [2:40:11<31:20,  1.87s/it]                                                     {'loss': 0.0395, 'grad_norm': 4.73974609375, 'learning_rate': 1.7016949152542376e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4996/6000 [2:40:11<31:20,  1.87s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4997/6000 [2:40:12<31:19,  1.87s/it]                                                     {'loss': 0.0633, 'grad_norm': 6.706310749053955, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4997/6000 [2:40:12<31:19,  1.87s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4998/6000 [2:40:14<31:22,  1.88s/it]                                                     {'loss': 0.3502, 'grad_norm': 10.701343536376953, 'learning_rate': 1.6983050847457627e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4998/6000 [2:40:14<31:22,  1.88s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4999/6000 [2:40:16<31:17,  1.88s/it]                                                     {'loss': 0.0079, 'grad_norm': 1.3459057807922363, 'learning_rate': 1.6966101694915255e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4999/6000 [2:40:16<31:17,  1.88s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5000/6000 [2:40:18<31:26,  1.89s/it]                                                     {'loss': 0.0516, 'grad_norm': 5.696401596069336, 'learning_rate': 1.6949152542372882e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5000/6000 [2:40:18<31:26,  1.89s/it][2025-11-12 00:33:34,053] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5000
[2025-11-12 00:33:34,059] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:33:34,343] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5001/6000 [2:40:21<35:28,  2.13s/it]                                                     {'loss': 0.1351, 'grad_norm': 7.167257785797119, 'learning_rate': 1.693220338983051e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5001/6000 [2:40:21<35:28,  2.13s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5002/6000 [2:40:23<34:55,  2.10s/it]                                                     {'loss': 0.0151, 'grad_norm': 3.9627530574798584, 'learning_rate': 1.6915254237288136e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5002/6000 [2:40:23<34:55,  2.10s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5003/6000 [2:40:25<33:49,  2.04s/it]                                                     {'loss': 0.0498, 'grad_norm': 5.284979343414307, 'learning_rate': 1.6898305084745765e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5003/6000 [2:40:25<33:49,  2.04s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5004/6000 [2:40:27<33:29,  2.02s/it]                                                     {'loss': 0.0779, 'grad_norm': 5.954062461853027, 'learning_rate': 1.6881355932203391e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5004/6000 [2:40:27<33:29,  2.02s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5005/6000 [2:40:29<32:42,  1.97s/it]                                                     {'loss': 0.0566, 'grad_norm': 6.621374607086182, 'learning_rate': 1.686440677966102e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5005/6000 [2:40:29<32:42,  1.97s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5006/6000 [2:40:31<32:23,  1.96s/it]                                                     {'loss': 0.0386, 'grad_norm': 3.3299686908721924, 'learning_rate': 1.6847457627118646e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5006/6000 [2:40:31<32:23,  1.96s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5007/6000 [2:40:32<31:58,  1.93s/it]                                                     {'loss': 0.0763, 'grad_norm': 6.8735857009887695, 'learning_rate': 1.6830508474576275e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5007/6000 [2:40:32<31:58,  1.93s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5008/6000 [2:40:34<31:43,  1.92s/it]                                                     {'loss': 0.044, 'grad_norm': 5.785777568817139, 'learning_rate': 1.6813559322033901e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5008/6000 [2:40:34<31:43,  1.92s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5009/6000 [2:40:36<31:22,  1.90s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.03950061649084091, 'learning_rate': 1.6796610169491525e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5009/6000 [2:40:36<31:22,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5010/6000 [2:40:38<31:21,  1.90s/it]                                                     {'loss': 0.015, 'grad_norm': 1.9822543859481812, 'learning_rate': 1.6779661016949154e-06, 'epoch': 0.83}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5010/6000 [2:40:38<31:21,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5011/6000 [2:40:40<31:04,  1.88s/it]                                                     {'loss': 0.1229, 'grad_norm': 5.234802722930908, 'learning_rate': 1.676271186440678e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5011/6000 [2:40:40<31:04,  1.88s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5012/6000 [2:40:42<33:05,  2.01s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.18087665736675262, 'learning_rate': 1.6745762711864409e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5012/6000 [2:40:42<33:05,  2.01s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5013/6000 [2:40:44<32:29,  1.97s/it]                                                     {'loss': 0.0258, 'grad_norm': 4.77695894241333, 'learning_rate': 1.6728813559322035e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5013/6000 [2:40:44<32:29,  1.97s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5014/6000 [2:40:46<31:46,  1.93s/it]                                                     {'loss': 0.0264, 'grad_norm': 3.4086415767669678, 'learning_rate': 1.6711864406779664e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5014/6000 [2:40:46<31:46,  1.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5015/6000 [2:40:48<31:57,  1.95s/it]                                                     {'loss': 0.0053, 'grad_norm': 0.5686324834823608, 'learning_rate': 1.669491525423729e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5015/6000 [2:40:48<31:57,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5016/6000 [2:40:50<31:36,  1.93s/it]                                                     {'loss': 0.0644, 'grad_norm': 7.214062690734863, 'learning_rate': 1.6677966101694916e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5016/6000 [2:40:50<31:36,  1.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5017/6000 [2:40:52<31:14,  1.91s/it]                                                     {'loss': 0.001, 'grad_norm': 0.16836406290531158, 'learning_rate': 1.6661016949152545e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5017/6000 [2:40:52<31:14,  1.91s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5018/6000 [2:40:53<31:00,  1.89s/it]                                                     {'loss': 0.1064, 'grad_norm': 9.07501220703125, 'learning_rate': 1.6644067796610171e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5018/6000 [2:40:53<31:00,  1.89s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5019/6000 [2:40:56<31:54,  1.95s/it]                                                     {'loss': 0.0583, 'grad_norm': 6.618716239929199, 'learning_rate': 1.6627118644067798e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5019/6000 [2:40:56<31:54,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5020/6000 [2:40:58<32:19,  1.98s/it]                                                     {'loss': 0.0341, 'grad_norm': 3.010692834854126, 'learning_rate': 1.6610169491525424e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5020/6000 [2:40:58<32:19,  1.98s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5021/6000 [2:41:00<31:48,  1.95s/it]                                                     {'loss': 0.008, 'grad_norm': 1.713912010192871, 'learning_rate': 1.6593220338983053e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5021/6000 [2:41:00<31:48,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5022/6000 [2:41:01<31:17,  1.92s/it]                                                     {'loss': 0.1978, 'grad_norm': 7.095605373382568, 'learning_rate': 1.6576271186440679e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5022/6000 [2:41:01<31:17,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5023/6000 [2:41:03<31:42,  1.95s/it]                                                     {'loss': 0.0297, 'grad_norm': 3.9585230350494385, 'learning_rate': 1.6559322033898305e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5023/6000 [2:41:03<31:42,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5024/6000 [2:41:05<31:21,  1.93s/it]                                                     {'loss': 0.1386, 'grad_norm': 7.432584762573242, 'learning_rate': 1.6542372881355934e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5024/6000 [2:41:05<31:21,  1.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5025/6000 [2:41:07<31:13,  1.92s/it]                                                     {'loss': 0.0175, 'grad_norm': 2.0854427814483643, 'learning_rate': 1.652542372881356e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5025/6000 [2:41:07<31:13,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5026/6000 [2:41:09<31:12,  1.92s/it]                                                     {'loss': 0.0502, 'grad_norm': 6.231865406036377, 'learning_rate': 1.6508474576271189e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5026/6000 [2:41:09<31:12,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5027/6000 [2:41:11<30:45,  1.90s/it]                                                     {'loss': 0.0891, 'grad_norm': 6.990164756774902, 'learning_rate': 1.6491525423728815e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5027/6000 [2:41:11<30:45,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5028/6000 [2:41:13<31:42,  1.96s/it]                                                     {'loss': 0.0151, 'grad_norm': 2.2047228813171387, 'learning_rate': 1.6474576271186444e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5028/6000 [2:41:13<31:42,  1.96s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5029/6000 [2:41:15<31:23,  1.94s/it]                                                     {'loss': 0.0227, 'grad_norm': 3.0663843154907227, 'learning_rate': 1.6457627118644068e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5029/6000 [2:41:15<31:23,  1.94s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5030/6000 [2:41:17<30:57,  1.91s/it]                                                     {'loss': 0.0379, 'grad_norm': 3.7396364212036133, 'learning_rate': 1.6440677966101694e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5030/6000 [2:41:17<30:57,  1.91s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5031/6000 [2:41:19<30:51,  1.91s/it]                                                     {'loss': 0.0326, 'grad_norm': 1.7265229225158691, 'learning_rate': 1.6423728813559323e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5031/6000 [2:41:19<30:51,  1.91s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5032/6000 [2:41:21<30:42,  1.90s/it]                                                     {'loss': 0.0912, 'grad_norm': 4.9017229080200195, 'learning_rate': 1.640677966101695e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5032/6000 [2:41:21<30:42,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5033/6000 [2:41:23<30:58,  1.92s/it]                                                     {'loss': 0.0432, 'grad_norm': 5.399214267730713, 'learning_rate': 1.6389830508474578e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5033/6000 [2:41:23<30:58,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5034/6000 [2:41:24<30:43,  1.91s/it]                                                     {'loss': 0.2573, 'grad_norm': 10.381120681762695, 'learning_rate': 1.6372881355932204e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5034/6000 [2:41:24<30:43,  1.91s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5035/6000 [2:41:26<30:15,  1.88s/it]                                                     {'loss': 0.1501, 'grad_norm': 8.88040542602539, 'learning_rate': 1.6355932203389833e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5035/6000 [2:41:26<30:15,  1.88s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5036/6000 [2:41:28<30:45,  1.91s/it]                                                     {'loss': 0.0104, 'grad_norm': 1.8992830514907837, 'learning_rate': 1.6338983050847459e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5036/6000 [2:41:28<30:45,  1.91s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5037/6000 [2:41:30<30:54,  1.93s/it]                                                     {'loss': 0.0524, 'grad_norm': 3.130152940750122, 'learning_rate': 1.6322033898305087e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5037/6000 [2:41:30<30:54,  1.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5038/6000 [2:41:32<30:19,  1.89s/it]                                                     {'loss': 0.0307, 'grad_norm': 2.060277223587036, 'learning_rate': 1.6305084745762714e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5038/6000 [2:41:32<30:19,  1.89s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5039/6000 [2:41:34<30:09,  1.88s/it]                                                     {'loss': 0.1471, 'grad_norm': 8.222921371459961, 'learning_rate': 1.6288135593220342e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5039/6000 [2:41:34<30:09,  1.88s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5040/6000 [2:41:36<29:58,  1.87s/it]                                                     {'loss': 0.0704, 'grad_norm': 5.792318344116211, 'learning_rate': 1.6271186440677967e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5040/6000 [2:41:36<29:58,  1.87s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5041/6000 [2:41:38<29:59,  1.88s/it]                                                     {'loss': 0.0993, 'grad_norm': 5.566746711730957, 'learning_rate': 1.6254237288135593e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5041/6000 [2:41:38<29:59,  1.88s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5042/6000 [2:41:39<29:51,  1.87s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.1586221158504486, 'learning_rate': 1.6237288135593221e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5042/6000 [2:41:39<29:51,  1.87s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5043/6000 [2:41:41<30:05,  1.89s/it]                                                     {'loss': 0.0776, 'grad_norm': 6.477223873138428, 'learning_rate': 1.6220338983050848e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5043/6000 [2:41:41<30:05,  1.89s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5044/6000 [2:41:43<29:47,  1.87s/it]                                                     {'loss': 0.0449, 'grad_norm': 4.583693504333496, 'learning_rate': 1.6203389830508476e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5044/6000 [2:41:43<29:47,  1.87s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5045/6000 [2:41:45<29:43,  1.87s/it]                                                     {'loss': 0.0847, 'grad_norm': 5.906559467315674, 'learning_rate': 1.6186440677966103e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5045/6000 [2:41:45<29:43,  1.87s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5046/6000 [2:41:47<29:40,  1.87s/it]                                                     {'loss': 0.0424, 'grad_norm': 1.4631966352462769, 'learning_rate': 1.6169491525423731e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5046/6000 [2:41:47<29:40,  1.87s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5047/6000 [2:41:49<30:01,  1.89s/it]                                                     {'loss': 0.0141, 'grad_norm': 1.5712841749191284, 'learning_rate': 1.6152542372881358e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5047/6000 [2:41:49<30:01,  1.89s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5048/6000 [2:41:51<29:49,  1.88s/it]                                                     {'loss': 0.1145, 'grad_norm': 8.018975257873535, 'learning_rate': 1.6135593220338986e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5048/6000 [2:41:51<29:49,  1.88s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5049/6000 [2:41:53<29:33,  1.87s/it]                                                     {'loss': 0.0608, 'grad_norm': 5.527486324310303, 'learning_rate': 1.6118644067796612e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5049/6000 [2:41:53<29:33,  1.87s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5050/6000 [2:41:54<29:32,  1.87s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.39246702194213867, 'learning_rate': 1.6101694915254237e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5050/6000 [2:41:54<29:32,  1.87s/it][2025-11-12 00:35:10,327] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5050
[2025-11-12 00:35:10,335] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:35:10,620] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5050/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5051/6000 [2:41:57<33:40,  2.13s/it]                                                     {'loss': 0.0244, 'grad_norm': 4.54841947555542, 'learning_rate': 1.6084745762711865e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5051/6000 [2:41:57<33:40,  2.13s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5052/6000 [2:41:59<32:21,  2.05s/it]                                                     {'loss': 0.0068, 'grad_norm': 1.2293387651443481, 'learning_rate': 1.6067796610169492e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5052/6000 [2:41:59<32:21,  2.05s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5053/6000 [2:42:01<31:34,  2.00s/it]                                                     {'loss': 0.0366, 'grad_norm': 1.7701760530471802, 'learning_rate': 1.605084745762712e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5053/6000 [2:42:01<31:34,  2.00s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5054/6000 [2:42:03<31:02,  1.97s/it]                                                     {'loss': 0.0268, 'grad_norm': 4.436255931854248, 'learning_rate': 1.6033898305084747e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5054/6000 [2:42:03<31:02,  1.97s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5055/6000 [2:42:05<30:42,  1.95s/it]                                                     {'loss': 0.0225, 'grad_norm': 3.4013140201568604, 'learning_rate': 1.6016949152542375e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5055/6000 [2:42:05<30:42,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5056/6000 [2:42:07<30:26,  1.94s/it]                                                     {'loss': 0.0102, 'grad_norm': 2.3095955848693848, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5056/6000 [2:42:07<30:26,  1.94s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5057/6000 [2:42:08<30:12,  1.92s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.031753115355968475, 'learning_rate': 1.598305084745763e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5057/6000 [2:42:08<30:12,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5058/6000 [2:42:10<29:49,  1.90s/it]                                                     {'loss': 0.2068, 'grad_norm': 6.679945468902588, 'learning_rate': 1.5966101694915256e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5058/6000 [2:42:10<29:49,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5059/6000 [2:42:12<29:51,  1.90s/it]                                                     {'loss': 0.0081, 'grad_norm': 2.4586052894592285, 'learning_rate': 1.5949152542372885e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5059/6000 [2:42:12<29:51,  1.90s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5060/6000 [2:42:14<29:35,  1.89s/it]                                                     {'loss': 0.0103, 'grad_norm': 2.115488052368164, 'learning_rate': 1.593220338983051e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5060/6000 [2:42:14<29:35,  1.89s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5061/6000 [2:42:16<30:00,  1.92s/it]                                                     {'loss': 0.036, 'grad_norm': 3.986757278442383, 'learning_rate': 1.5915254237288135e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5061/6000 [2:42:16<30:00,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5062/6000 [2:42:18<29:48,  1.91s/it]                                                     {'loss': 0.0016, 'grad_norm': 0.22625797986984253, 'learning_rate': 1.5898305084745764e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5062/6000 [2:42:18<29:48,  1.91s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5063/6000 [2:42:20<30:03,  1.92s/it]                                                     {'loss': 0.0325, 'grad_norm': 5.115546226501465, 'learning_rate': 1.588135593220339e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5063/6000 [2:42:20<30:03,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5064/6000 [2:42:22<30:04,  1.93s/it]                                                     {'loss': 0.1001, 'grad_norm': 7.716263294219971, 'learning_rate': 1.5864406779661019e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5064/6000 [2:42:22<30:04,  1.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5065/6000 [2:42:24<29:50,  1.92s/it]                                                     {'loss': 0.0531, 'grad_norm': 5.610348224639893, 'learning_rate': 1.5847457627118645e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5065/6000 [2:42:24<29:50,  1.92s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5066/6000 [2:42:26<30:24,  1.95s/it]                                                     {'loss': 0.0838, 'grad_norm': 7.625721454620361, 'learning_rate': 1.5830508474576274e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5066/6000 [2:42:26<30:24,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5067/6000 [2:42:28<30:41,  1.97s/it]                                                     {'loss': 0.0051, 'grad_norm': 0.8534015417098999, 'learning_rate': 1.58135593220339e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5067/6000 [2:42:28<30:41,  1.97s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5068/6000 [2:42:30<30:17,  1.95s/it]                                                     {'loss': 0.0921, 'grad_norm': 5.96836519241333, 'learning_rate': 1.5796610169491526e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5068/6000 [2:42:30<30:17,  1.95s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5069/6000 [2:42:32<30:01,  1.93s/it]                                                     {'loss': 0.1911, 'grad_norm': 8.678986549377441, 'learning_rate': 1.5779661016949155e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5069/6000 [2:42:32<30:01,  1.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5070/6000 [2:42:33<29:39,  1.91s/it]                                                     {'loss': 0.3227, 'grad_norm': 14.856654167175293, 'learning_rate': 1.5762711864406781e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5070/6000 [2:42:33<29:39,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5071/6000 [2:42:35<29:32,  1.91s/it]                                                     {'loss': 0.2785, 'grad_norm': 10.442212104797363, 'learning_rate': 1.5745762711864408e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5071/6000 [2:42:35<29:32,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5072/6000 [2:42:37<29:15,  1.89s/it]                                                     {'loss': 0.0782, 'grad_norm': 8.54643440246582, 'learning_rate': 1.5728813559322034e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5072/6000 [2:42:37<29:15,  1.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5073/6000 [2:42:39<29:04,  1.88s/it]                                                     {'loss': 0.0546, 'grad_norm': 2.2859814167022705, 'learning_rate': 1.5711864406779663e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5073/6000 [2:42:39<29:04,  1.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5074/6000 [2:42:41<29:00,  1.88s/it]                                                     {'loss': 0.0729, 'grad_norm': 5.8741068840026855, 'learning_rate': 1.569491525423729e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5074/6000 [2:42:41<29:00,  1.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5075/6000 [2:42:43<29:14,  1.90s/it]                                                     {'loss': 0.1442, 'grad_norm': 12.625825881958008, 'learning_rate': 1.5677966101694915e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5075/6000 [2:42:43<29:14,  1.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5076/6000 [2:42:45<29:26,  1.91s/it]                                                     {'loss': 0.0712, 'grad_norm': 4.6943159103393555, 'learning_rate': 1.5661016949152544e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5076/6000 [2:42:45<29:26,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5077/6000 [2:42:47<29:07,  1.89s/it]                                                     {'loss': 0.0351, 'grad_norm': 4.466063499450684, 'learning_rate': 1.564406779661017e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5077/6000 [2:42:47<29:07,  1.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5078/6000 [2:42:49<29:53,  1.95s/it]                                                     {'loss': 0.0196, 'grad_norm': 2.584221363067627, 'learning_rate': 1.5627118644067799e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5078/6000 [2:42:49<29:53,  1.95s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5079/6000 [2:42:51<29:21,  1.91s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.039014242589473724, 'learning_rate': 1.5610169491525425e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5079/6000 [2:42:51<29:21,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5080/6000 [2:42:53<32:13,  2.10s/it]                                                     {'loss': 0.0162, 'grad_norm': 2.1485021114349365, 'learning_rate': 1.5593220338983054e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5080/6000 [2:42:53<32:13,  2.10s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5081/6000 [2:42:55<31:47,  2.08s/it]                                                     {'loss': 0.116, 'grad_norm': 9.022378921508789, 'learning_rate': 1.5576271186440678e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5081/6000 [2:42:55<31:47,  2.08s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5082/6000 [2:42:57<31:00,  2.03s/it]                                                     {'loss': 0.0499, 'grad_norm': 6.36755895614624, 'learning_rate': 1.5559322033898304e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5082/6000 [2:42:57<31:00,  2.03s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5083/6000 [2:42:59<30:25,  1.99s/it]                                                     {'loss': 0.011, 'grad_norm': 1.9631098508834839, 'learning_rate': 1.5542372881355933e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5083/6000 [2:42:59<30:25,  1.99s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5084/6000 [2:43:01<29:53,  1.96s/it]                                                     {'loss': 0.1095, 'grad_norm': 6.801589012145996, 'learning_rate': 1.552542372881356e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5084/6000 [2:43:01<29:53,  1.96s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5085/6000 [2:43:03<29:28,  1.93s/it]                                                     {'loss': 0.057, 'grad_norm': 6.012406349182129, 'learning_rate': 1.5508474576271188e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5085/6000 [2:43:03<29:28,  1.93s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5086/6000 [2:43:05<29:02,  1.91s/it]                                                     {'loss': 0.1025, 'grad_norm': 6.095765113830566, 'learning_rate': 1.5491525423728814e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5086/6000 [2:43:05<29:02,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5087/6000 [2:43:06<29:01,  1.91s/it]                                                     {'loss': 0.0117, 'grad_norm': 2.0159502029418945, 'learning_rate': 1.5474576271186443e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5087/6000 [2:43:06<29:01,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5088/6000 [2:43:08<28:56,  1.90s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.8381808996200562, 'learning_rate': 1.545762711864407e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5088/6000 [2:43:08<28:56,  1.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5089/6000 [2:43:10<29:17,  1.93s/it]                                                     {'loss': 0.054, 'grad_norm': 5.977670669555664, 'learning_rate': 1.5440677966101697e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5089/6000 [2:43:10<29:17,  1.93s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5090/6000 [2:43:12<29:02,  1.92s/it]                                                     {'loss': 0.0409, 'grad_norm': 3.8879811763763428, 'learning_rate': 1.5423728813559324e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5090/6000 [2:43:12<29:02,  1.92s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5091/6000 [2:43:14<29:05,  1.92s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.9577338695526123, 'learning_rate': 1.5406779661016952e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5091/6000 [2:43:14<29:05,  1.92s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5092/6000 [2:43:16<29:01,  1.92s/it]                                                     {'loss': 0.0069, 'grad_norm': 1.0900858640670776, 'learning_rate': 1.5389830508474577e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5092/6000 [2:43:16<29:01,  1.92s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5093/6000 [2:43:18<28:43,  1.90s/it]                                                     {'loss': 0.0955, 'grad_norm': 4.343531131744385, 'learning_rate': 1.5372881355932203e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5093/6000 [2:43:18<28:43,  1.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5094/6000 [2:43:20<28:28,  1.89s/it]                                                     {'loss': 0.0568, 'grad_norm': 6.729084491729736, 'learning_rate': 1.5355932203389832e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5094/6000 [2:43:20<28:28,  1.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5095/6000 [2:43:22<28:13,  1.87s/it]                                                     {'loss': 0.0421, 'grad_norm': 4.150041580200195, 'learning_rate': 1.5338983050847458e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5095/6000 [2:43:22<28:13,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5096/6000 [2:43:24<28:06,  1.87s/it]                                                     {'loss': 0.1742, 'grad_norm': 10.27364444732666, 'learning_rate': 1.5322033898305086e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5096/6000 [2:43:24<28:06,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5097/6000 [2:43:25<28:06,  1.87s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.7508813142776489, 'learning_rate': 1.5305084745762713e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5097/6000 [2:43:25<28:06,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5098/6000 [2:43:27<28:17,  1.88s/it]                                                     {'loss': 0.0402, 'grad_norm': 4.239792823791504, 'learning_rate': 1.5288135593220341e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5098/6000 [2:43:27<28:17,  1.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5099/6000 [2:43:29<28:23,  1.89s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.08124438673257828, 'learning_rate': 1.5271186440677968e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5099/6000 [2:43:29<28:23,  1.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5100/6000 [2:43:31<28:10,  1.88s/it]                                                     {'loss': 0.2378, 'grad_norm': 9.38196849822998, 'learning_rate': 1.5254237288135596e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5100/6000 [2:43:31<28:10,  1.88s/it][2025-11-12 00:36:46,968] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5100
[2025-11-12 00:36:46,975] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:36:47,257] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5101/6000 [2:43:34<31:51,  2.13s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.017005594447255135, 'learning_rate': 1.5237288135593223e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5101/6000 [2:43:34<31:51,  2.13s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5102/6000 [2:43:36<30:41,  2.05s/it]                                                     {'loss': 0.0472, 'grad_norm': 4.039847373962402, 'learning_rate': 1.5220338983050847e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5102/6000 [2:43:36<30:41,  2.05s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5103/6000 [2:43:37<29:46,  1.99s/it]                                                     {'loss': 0.0492, 'grad_norm': 4.667691707611084, 'learning_rate': 1.5203389830508475e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5103/6000 [2:43:37<29:46,  1.99s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5104/6000 [2:43:39<29:50,  2.00s/it]                                                     {'loss': 0.126, 'grad_norm': 9.377889633178711, 'learning_rate': 1.5186440677966102e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5104/6000 [2:43:39<29:50,  2.00s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5105/6000 [2:43:41<29:20,  1.97s/it]                                                     {'loss': 0.0709, 'grad_norm': 3.529456615447998, 'learning_rate': 1.516949152542373e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5105/6000 [2:43:41<29:20,  1.97s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5106/6000 [2:43:43<28:45,  1.93s/it]                                                     {'loss': 0.0287, 'grad_norm': 4.396018981933594, 'learning_rate': 1.5152542372881357e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5106/6000 [2:43:43<28:45,  1.93s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5107/6000 [2:43:45<28:28,  1.91s/it]                                                     {'loss': 0.0136, 'grad_norm': 1.8779258728027344, 'learning_rate': 1.5135593220338985e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5107/6000 [2:43:45<28:28,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5108/6000 [2:43:47<28:13,  1.90s/it]                                                     {'loss': 0.0149, 'grad_norm': 1.9305623769760132, 'learning_rate': 1.5118644067796611e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5108/6000 [2:43:47<28:13,  1.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5109/6000 [2:43:49<28:19,  1.91s/it]                                                     {'loss': 0.0516, 'grad_norm': 5.5974602699279785, 'learning_rate': 1.510169491525424e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5109/6000 [2:43:49<28:19,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5110/6000 [2:43:51<30:03,  2.03s/it]                                                     {'loss': 0.0232, 'grad_norm': 2.528327703475952, 'learning_rate': 1.5084745762711866e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5110/6000 [2:43:51<30:03,  2.03s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5111/6000 [2:43:53<29:23,  1.98s/it]                                                     {'loss': 0.1008, 'grad_norm': 6.600161552429199, 'learning_rate': 1.5067796610169495e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5111/6000 [2:43:53<29:23,  1.98s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5112/6000 [2:43:55<28:50,  1.95s/it]                                                     {'loss': 0.1745, 'grad_norm': 9.671748161315918, 'learning_rate': 1.505084745762712e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5112/6000 [2:43:55<28:50,  1.95s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5113/6000 [2:43:57<28:29,  1.93s/it]                                                     {'loss': 0.0905, 'grad_norm': 8.654510498046875, 'learning_rate': 1.5033898305084745e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5113/6000 [2:43:57<28:29,  1.93s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5114/6000 [2:43:59<28:08,  1.91s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.20936183631420135, 'learning_rate': 1.5016949152542374e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5114/6000 [2:43:59<28:08,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5115/6000 [2:44:01<27:48,  1.89s/it]                                                     {'loss': 0.0103, 'grad_norm': 1.666538119316101, 'learning_rate': 1.5e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5115/6000 [2:44:01<27:48,  1.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5116/6000 [2:44:02<27:34,  1.87s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.5645598769187927, 'learning_rate': 1.4983050847457629e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5116/6000 [2:44:02<27:34,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5117/6000 [2:44:04<27:28,  1.87s/it]                                                     {'loss': 0.3304, 'grad_norm': 12.662044525146484, 'learning_rate': 1.4966101694915255e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5117/6000 [2:44:04<27:28,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5118/6000 [2:44:06<27:21,  1.86s/it]                                                     {'loss': 0.0391, 'grad_norm': 4.119024753570557, 'learning_rate': 1.4949152542372884e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5118/6000 [2:44:06<27:21,  1.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5119/6000 [2:44:08<27:14,  1.85s/it]                                                     {'loss': 0.0787, 'grad_norm': 5.328338146209717, 'learning_rate': 1.493220338983051e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5119/6000 [2:44:08<27:14,  1.85s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5120/6000 [2:44:10<27:13,  1.86s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.05269644409418106, 'learning_rate': 1.4915254237288139e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5120/6000 [2:44:10<27:13,  1.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5121/6000 [2:44:12<27:13,  1.86s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.27227622270584106, 'learning_rate': 1.4898305084745765e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5121/6000 [2:44:12<27:13,  1.86s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5122/6000 [2:44:14<27:54,  1.91s/it]                                                     {'loss': 0.4364, 'grad_norm': 12.252556800842285, 'learning_rate': 1.4881355932203391e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5122/6000 [2:44:14<27:54,  1.91s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5123/6000 [2:44:15<27:35,  1.89s/it]                                                     {'loss': 0.0372, 'grad_norm': 3.7346155643463135, 'learning_rate': 1.4864406779661018e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5123/6000 [2:44:15<27:35,  1.89s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5124/6000 [2:44:17<27:26,  1.88s/it]                                                     {'loss': 0.2665, 'grad_norm': 17.2230281829834, 'learning_rate': 1.4847457627118644e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5124/6000 [2:44:17<27:26,  1.88s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5125/6000 [2:44:19<27:20,  1.87s/it]                                                     {'loss': 0.0537, 'grad_norm': 5.104217529296875, 'learning_rate': 1.4830508474576273e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5125/6000 [2:44:19<27:20,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5126/6000 [2:44:21<27:16,  1.87s/it]                                                     {'loss': 0.022, 'grad_norm': 3.206437587738037, 'learning_rate': 1.48135593220339e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5126/6000 [2:44:21<27:16,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5127/6000 [2:44:23<27:16,  1.87s/it]                                                     {'loss': 0.006, 'grad_norm': 1.2421213388442993, 'learning_rate': 1.4796610169491525e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5127/6000 [2:44:23<27:16,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5128/6000 [2:44:25<27:14,  1.87s/it]                                                     {'loss': 0.0289, 'grad_norm': 4.413120746612549, 'learning_rate': 1.4779661016949154e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5128/6000 [2:44:25<27:14,  1.87s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5129/6000 [2:44:27<26:56,  1.86s/it]                                                     {'loss': 0.0083, 'grad_norm': 0.6737622618675232, 'learning_rate': 1.476271186440678e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5129/6000 [2:44:27<26:56,  1.86s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5130/6000 [2:44:29<27:43,  1.91s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.617098867893219, 'learning_rate': 1.4745762711864409e-06, 'epoch': 0.85}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5130/6000 [2:44:29<27:43,  1.91s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5131/6000 [2:44:31<27:40,  1.91s/it]                                                     {'loss': 0.0196, 'grad_norm': 2.9591805934906006, 'learning_rate': 1.4728813559322035e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5131/6000 [2:44:31<27:40,  1.91s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5132/6000 [2:44:33<27:35,  1.91s/it]                                                     {'loss': 0.0302, 'grad_norm': 2.844583511352539, 'learning_rate': 1.4711864406779664e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5132/6000 [2:44:33<27:35,  1.91s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5133/6000 [2:44:34<27:22,  1.89s/it]                                                     {'loss': 0.0857, 'grad_norm': 6.049774169921875, 'learning_rate': 1.4694915254237288e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5133/6000 [2:44:34<27:22,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5134/6000 [2:44:36<27:07,  1.88s/it]                                                     {'loss': 0.1961, 'grad_norm': 10.426595687866211, 'learning_rate': 1.4677966101694914e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5134/6000 [2:44:36<27:07,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5135/6000 [2:44:38<27:03,  1.88s/it]                                                     {'loss': 0.0172, 'grad_norm': 3.325561285018921, 'learning_rate': 1.4661016949152543e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5135/6000 [2:44:38<27:03,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5136/6000 [2:44:40<26:49,  1.86s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.06279297918081284, 'learning_rate': 1.464406779661017e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5136/6000 [2:44:40<26:49,  1.86s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5137/6000 [2:44:42<26:56,  1.87s/it]                                                     {'loss': 0.019, 'grad_norm': 3.478139877319336, 'learning_rate': 1.4627118644067798e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5137/6000 [2:44:42<26:56,  1.87s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5138/6000 [2:44:44<27:47,  1.93s/it]                                                     {'loss': 0.4722, 'grad_norm': 12.774928092956543, 'learning_rate': 1.4610169491525424e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5138/6000 [2:44:44<27:47,  1.93s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5139/6000 [2:44:46<27:31,  1.92s/it]                                                     {'loss': 0.0457, 'grad_norm': 4.567925930023193, 'learning_rate': 1.4593220338983053e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5139/6000 [2:44:46<27:31,  1.92s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5140/6000 [2:44:48<27:17,  1.90s/it]                                                     {'loss': 0.0999, 'grad_norm': 7.358872413635254, 'learning_rate': 1.457627118644068e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5140/6000 [2:44:48<27:17,  1.90s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5141/6000 [2:44:49<26:58,  1.88s/it]                                                     {'loss': 0.0333, 'grad_norm': 2.8973729610443115, 'learning_rate': 1.4559322033898308e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5141/6000 [2:44:49<26:58,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5142/6000 [2:44:51<26:53,  1.88s/it]                                                     {'loss': 0.056, 'grad_norm': 6.25640344619751, 'learning_rate': 1.4542372881355934e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5142/6000 [2:44:51<26:53,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5143/6000 [2:44:53<26:48,  1.88s/it]                                                     {'loss': 0.052, 'grad_norm': 6.617681980133057, 'learning_rate': 1.4525423728813562e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5143/6000 [2:44:53<26:48,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5144/6000 [2:44:55<26:46,  1.88s/it]                                                     {'loss': 0.0882, 'grad_norm': 8.389975547790527, 'learning_rate': 1.4508474576271187e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5144/6000 [2:44:55<26:46,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5145/6000 [2:44:57<26:51,  1.88s/it]                                                     {'loss': 0.127, 'grad_norm': 8.744170188903809, 'learning_rate': 1.4491525423728813e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5145/6000 [2:44:57<26:51,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5146/6000 [2:44:59<27:13,  1.91s/it]                                                     {'loss': 0.0139, 'grad_norm': 2.6278538703918457, 'learning_rate': 1.4474576271186442e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5146/6000 [2:44:59<27:13,  1.91s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5147/6000 [2:45:01<27:02,  1.90s/it]                                                     {'loss': 0.1002, 'grad_norm': 11.429588317871094, 'learning_rate': 1.4457627118644068e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5147/6000 [2:45:01<27:02,  1.90s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5148/6000 [2:45:03<26:49,  1.89s/it]                                                     {'loss': 0.0171, 'grad_norm': 2.7402737140655518, 'learning_rate': 1.4440677966101696e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5148/6000 [2:45:03<26:49,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5149/6000 [2:45:05<26:51,  1.89s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.3523092269897461, 'learning_rate': 1.4423728813559323e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5149/6000 [2:45:05<26:51,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5150/6000 [2:45:06<26:38,  1.88s/it]                                                     {'loss': 0.0323, 'grad_norm': 4.277777671813965, 'learning_rate': 1.4406779661016951e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5150/6000 [2:45:06<26:38,  1.88s/it][2025-11-12 00:38:22,386] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5150
[2025-11-12 00:38:22,394] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:38:22,850] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5150/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5151/6000 [2:45:09<31:02,  2.19s/it]                                                     {'loss': 0.0235, 'grad_norm': 2.9030730724334717, 'learning_rate': 1.4389830508474578e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5151/6000 [2:45:09<31:02,  2.19s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5152/6000 [2:45:11<29:34,  2.09s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.41246676445007324, 'learning_rate': 1.4372881355932206e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5152/6000 [2:45:11<29:34,  2.09s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5153/6000 [2:45:13<28:57,  2.05s/it]                                                     {'loss': 0.1008, 'grad_norm': 5.683693885803223, 'learning_rate': 1.4355932203389833e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5153/6000 [2:45:13<28:57,  2.05s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5154/6000 [2:45:15<28:17,  2.01s/it]                                                     {'loss': 0.0483, 'grad_norm': 3.1206464767456055, 'learning_rate': 1.4338983050847457e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5154/6000 [2:45:15<28:17,  2.01s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5155/6000 [2:45:17<27:46,  1.97s/it]                                                     {'loss': 0.0472, 'grad_norm': 3.822209119796753, 'learning_rate': 1.4322033898305085e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5155/6000 [2:45:17<27:46,  1.97s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5156/6000 [2:45:19<27:27,  1.95s/it]                                                     {'loss': 0.1487, 'grad_norm': 8.969682693481445, 'learning_rate': 1.4305084745762712e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5156/6000 [2:45:19<27:27,  1.95s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5157/6000 [2:45:21<27:07,  1.93s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.027048509567975998, 'learning_rate': 1.428813559322034e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5157/6000 [2:45:21<27:07,  1.93s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5158/6000 [2:45:23<26:53,  1.92s/it]                                                     {'loss': 0.0976, 'grad_norm': 2.8394083976745605, 'learning_rate': 1.4271186440677967e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5158/6000 [2:45:23<26:53,  1.92s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5159/6000 [2:45:25<27:08,  1.94s/it]                                                     {'loss': 0.0164, 'grad_norm': 2.7517809867858887, 'learning_rate': 1.4254237288135595e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5159/6000 [2:45:25<27:08,  1.94s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5160/6000 [2:45:27<26:49,  1.92s/it]                                                     {'loss': 0.2971, 'grad_norm': 9.880889892578125, 'learning_rate': 1.4237288135593222e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5160/6000 [2:45:27<26:49,  1.92s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5161/6000 [2:45:28<26:35,  1.90s/it]                                                     {'loss': 0.3193, 'grad_norm': 10.942326545715332, 'learning_rate': 1.422033898305085e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5161/6000 [2:45:28<26:35,  1.90s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5162/6000 [2:45:30<26:23,  1.89s/it]                                                     {'loss': 0.2092, 'grad_norm': 7.168933391571045, 'learning_rate': 1.4203389830508476e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5162/6000 [2:45:30<26:23,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5163/6000 [2:45:32<26:28,  1.90s/it]                                                     {'loss': 0.1008, 'grad_norm': 6.303347110748291, 'learning_rate': 1.4186440677966105e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5163/6000 [2:45:32<26:28,  1.90s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5164/6000 [2:45:34<26:19,  1.89s/it]                                                     {'loss': 0.011, 'grad_norm': 1.4541993141174316, 'learning_rate': 1.416949152542373e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5164/6000 [2:45:34<26:19,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5165/6000 [2:45:36<26:13,  1.88s/it]                                                     {'loss': 0.0329, 'grad_norm': 3.592921495437622, 'learning_rate': 1.4152542372881356e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5165/6000 [2:45:36<26:13,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5166/6000 [2:45:38<26:13,  1.89s/it]                                                     {'loss': 0.0306, 'grad_norm': 3.235097646713257, 'learning_rate': 1.4135593220338984e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5166/6000 [2:45:38<26:13,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5167/6000 [2:45:40<26:04,  1.88s/it]                                                     {'loss': 0.0089, 'grad_norm': 1.398659586906433, 'learning_rate': 1.411864406779661e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5167/6000 [2:45:40<26:04,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5168/6000 [2:45:42<25:54,  1.87s/it]                                                     {'loss': 0.1, 'grad_norm': 8.703120231628418, 'learning_rate': 1.410169491525424e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5168/6000 [2:45:42<25:54,  1.87s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5169/6000 [2:45:43<25:46,  1.86s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.07232248038053513, 'learning_rate': 1.4084745762711865e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5169/6000 [2:45:43<25:46,  1.86s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5170/6000 [2:45:45<25:39,  1.85s/it]                                                     {'loss': 0.025, 'grad_norm': 3.1317121982574463, 'learning_rate': 1.4067796610169494e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5170/6000 [2:45:45<25:39,  1.85s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5171/6000 [2:45:47<26:08,  1.89s/it]                                                     {'loss': 0.0346, 'grad_norm': 4.861606121063232, 'learning_rate': 1.405084745762712e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5171/6000 [2:45:47<26:08,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5172/6000 [2:45:49<25:58,  1.88s/it]                                                     {'loss': 0.0074, 'grad_norm': 0.8297820687294006, 'learning_rate': 1.4033898305084749e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5172/6000 [2:45:49<25:58,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5173/6000 [2:45:51<25:52,  1.88s/it]                                                     {'loss': 0.1188, 'grad_norm': 7.857477188110352, 'learning_rate': 1.4016949152542375e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5173/6000 [2:45:51<25:52,  1.88s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5174/6000 [2:45:53<25:58,  1.89s/it]                                                     {'loss': 0.0453, 'grad_norm': 4.499740123748779, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5174/6000 [2:45:53<25:58,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5175/6000 [2:45:55<26:02,  1.89s/it]                                                     {'loss': 0.0662, 'grad_norm': 5.548707962036133, 'learning_rate': 1.3983050847457628e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5175/6000 [2:45:55<26:02,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5176/6000 [2:45:57<26:11,  1.91s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.11872927099466324, 'learning_rate': 1.3966101694915254e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5176/6000 [2:45:57<26:11,  1.91s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5177/6000 [2:45:59<26:00,  1.90s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.1309623271226883, 'learning_rate': 1.3949152542372883e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5177/6000 [2:45:59<26:00,  1.90s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5178/6000 [2:46:00<25:55,  1.89s/it]                                                     {'loss': 0.0043, 'grad_norm': 0.6800969243049622, 'learning_rate': 1.393220338983051e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5178/6000 [2:46:00<25:55,  1.89s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5179/6000 [2:46:02<25:38,  1.87s/it]                                                     {'loss': 0.1671, 'grad_norm': 7.91587495803833, 'learning_rate': 1.3915254237288138e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5179/6000 [2:46:02<25:38,  1.87s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5180/6000 [2:46:04<25:23,  1.86s/it]                                                     {'loss': 0.0491, 'grad_norm': 4.138572692871094, 'learning_rate': 1.3898305084745764e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5180/6000 [2:46:04<25:23,  1.86s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5181/6000 [2:46:06<25:22,  1.86s/it]                                                     {'loss': 0.0442, 'grad_norm': 6.330226421356201, 'learning_rate': 1.388135593220339e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5181/6000 [2:46:06<25:22,  1.86s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5182/6000 [2:46:08<25:29,  1.87s/it]                                                     {'loss': 0.0276, 'grad_norm': 4.391321182250977, 'learning_rate': 1.3864406779661019e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5182/6000 [2:46:08<25:29,  1.87s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5183/6000 [2:46:10<25:19,  1.86s/it]                                                     {'loss': 0.0465, 'grad_norm': 1.136268138885498, 'learning_rate': 1.3847457627118645e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5183/6000 [2:46:10<25:19,  1.86s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5184/6000 [2:46:12<26:06,  1.92s/it]                                                     {'loss': 0.0225, 'grad_norm': 2.6287081241607666, 'learning_rate': 1.3830508474576274e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5184/6000 [2:46:12<26:06,  1.92s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5185/6000 [2:46:14<29:24,  2.17s/it]                                                     {'loss': 0.1365, 'grad_norm': 7.022902488708496, 'learning_rate': 1.3813559322033898e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5185/6000 [2:46:14<29:24,  2.17s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5186/6000 [2:46:16<28:18,  2.09s/it]                                                     {'loss': 0.0456, 'grad_norm': 4.104947090148926, 'learning_rate': 1.3796610169491527e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5186/6000 [2:46:16<28:18,  2.09s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5187/6000 [2:46:18<27:24,  2.02s/it]                                                     {'loss': 0.0082, 'grad_norm': 1.2880271673202515, 'learning_rate': 1.3779661016949153e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5187/6000 [2:46:18<27:24,  2.02s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5188/6000 [2:46:20<26:58,  1.99s/it]                                                     {'loss': 0.0486, 'grad_norm': 6.044448375701904, 'learning_rate': 1.376271186440678e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5188/6000 [2:46:20<26:58,  1.99s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5189/6000 [2:46:22<26:28,  1.96s/it]                                                     {'loss': 0.0568, 'grad_norm': 7.493205547332764, 'learning_rate': 1.3745762711864408e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5189/6000 [2:46:22<26:28,  1.96s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5190/6000 [2:46:24<26:16,  1.95s/it]                                                     {'loss': 0.0165, 'grad_norm': 1.8386305570602417, 'learning_rate': 1.3728813559322034e-06, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5190/6000 [2:46:24<26:16,  1.95s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5191/6000 [2:46:26<25:52,  1.92s/it]                                                     {'loss': 0.0139, 'grad_norm': 1.3862295150756836, 'learning_rate': 1.3711864406779663e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5191/6000 [2:46:26<25:52,  1.92s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5192/6000 [2:46:28<25:52,  1.92s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.1321534365415573, 'learning_rate': 1.369491525423729e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5192/6000 [2:46:28<25:52,  1.92s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5193/6000 [2:46:30<25:35,  1.90s/it]                                                     {'loss': 0.3022, 'grad_norm': 12.430644989013672, 'learning_rate': 1.3677966101694918e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5193/6000 [2:46:30<25:35,  1.90s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5194/6000 [2:46:31<25:20,  1.89s/it]                                                     {'loss': 0.0322, 'grad_norm': 0.8680709004402161, 'learning_rate': 1.3661016949152544e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5194/6000 [2:46:31<25:20,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5195/6000 [2:46:33<25:11,  1.88s/it]                                                     {'loss': 0.0591, 'grad_norm': 3.3468472957611084, 'learning_rate': 1.3644067796610168e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5195/6000 [2:46:33<25:11,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5196/6000 [2:46:35<25:33,  1.91s/it]                                                     {'loss': 0.0043, 'grad_norm': 0.664138674736023, 'learning_rate': 1.3627118644067797e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5196/6000 [2:46:35<25:33,  1.91s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5197/6000 [2:46:37<25:28,  1.90s/it]                                                     {'loss': 0.0466, 'grad_norm': 3.417980432510376, 'learning_rate': 1.3610169491525423e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5197/6000 [2:46:37<25:28,  1.90s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5198/6000 [2:46:39<25:16,  1.89s/it]                                                     {'loss': 0.0207, 'grad_norm': 4.134464740753174, 'learning_rate': 1.3593220338983052e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5198/6000 [2:46:39<25:16,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5199/6000 [2:46:41<25:05,  1.88s/it]                                                     {'loss': 0.0089, 'grad_norm': 1.7251107692718506, 'learning_rate': 1.3576271186440678e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5199/6000 [2:46:41<25:05,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5200/6000 [2:46:43<25:24,  1.91s/it]                                                     {'loss': 0.1296, 'grad_norm': 8.60983943939209, 'learning_rate': 1.3559322033898307e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5200/6000 [2:46:43<25:24,  1.91s/it][2025-11-12 00:39:58,757] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5200
[2025-11-12 00:39:58,764] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:39:59,046] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5201/6000 [2:46:46<28:39,  2.15s/it]                                                     {'loss': 0.1345, 'grad_norm': 11.605622291564941, 'learning_rate': 1.3542372881355933e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5201/6000 [2:46:46<28:39,  2.15s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5202/6000 [2:46:47<27:25,  2.06s/it]                                                     {'loss': 0.0075, 'grad_norm': 1.2926065921783447, 'learning_rate': 1.3525423728813561e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5202/6000 [2:46:47<27:25,  2.06s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5203/6000 [2:46:50<28:00,  2.11s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.7735877633094788, 'learning_rate': 1.3508474576271188e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5203/6000 [2:46:50<28:00,  2.11s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5204/6000 [2:46:52<27:04,  2.04s/it]                                                     {'loss': 0.006, 'grad_norm': 1.1428874731063843, 'learning_rate': 1.3491525423728816e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5204/6000 [2:46:52<27:04,  2.04s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5205/6000 [2:46:53<26:29,  2.00s/it]                                                     {'loss': 0.0044, 'grad_norm': 0.6912204623222351, 'learning_rate': 1.3474576271186443e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5205/6000 [2:46:53<26:29,  2.00s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5206/6000 [2:46:55<25:54,  1.96s/it]                                                     {'loss': 0.2482, 'grad_norm': 13.259292602539062, 'learning_rate': 1.3457627118644067e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5206/6000 [2:46:55<25:54,  1.96s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5207/6000 [2:46:57<26:04,  1.97s/it]                                                     {'loss': 0.0571, 'grad_norm': 9.513212203979492, 'learning_rate': 1.3440677966101695e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5207/6000 [2:46:57<26:04,  1.97s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5208/6000 [2:46:59<25:37,  1.94s/it]                                                     {'loss': 0.0265, 'grad_norm': 3.926043748855591, 'learning_rate': 1.3423728813559322e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5208/6000 [2:46:59<25:37,  1.94s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5209/6000 [2:47:01<25:23,  1.93s/it]                                                     {'loss': 0.1376, 'grad_norm': 8.594029426574707, 'learning_rate': 1.340677966101695e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5209/6000 [2:47:01<25:23,  1.93s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5210/6000 [2:47:03<25:09,  1.91s/it]                                                     {'loss': 0.0316, 'grad_norm': 4.331503391265869, 'learning_rate': 1.3389830508474577e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5210/6000 [2:47:03<25:09,  1.91s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5211/6000 [2:47:05<24:55,  1.90s/it]                                                     {'loss': 0.0986, 'grad_norm': 4.853350639343262, 'learning_rate': 1.3372881355932205e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5211/6000 [2:47:05<24:55,  1.90s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5212/6000 [2:47:07<24:49,  1.89s/it]                                                     {'loss': 0.0297, 'grad_norm': 4.37257719039917, 'learning_rate': 1.3355932203389832e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5212/6000 [2:47:07<24:49,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5213/6000 [2:47:08<24:31,  1.87s/it]                                                     {'loss': 0.0537, 'grad_norm': 4.125488758087158, 'learning_rate': 1.333898305084746e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5213/6000 [2:47:08<24:31,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5214/6000 [2:47:10<24:28,  1.87s/it]                                                     {'loss': 0.0507, 'grad_norm': 7.906888484954834, 'learning_rate': 1.3322033898305086e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5214/6000 [2:47:10<24:28,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5215/6000 [2:47:12<24:26,  1.87s/it]                                                     {'loss': 0.0239, 'grad_norm': 3.122134208679199, 'learning_rate': 1.3305084745762715e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5215/6000 [2:47:12<24:26,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5216/6000 [2:47:14<24:25,  1.87s/it]                                                     {'loss': 0.1096, 'grad_norm': 8.138489723205566, 'learning_rate': 1.328813559322034e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5216/6000 [2:47:14<24:25,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5217/6000 [2:47:16<24:12,  1.85s/it]                                                     {'loss': 0.0105, 'grad_norm': 1.452826738357544, 'learning_rate': 1.3271186440677966e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5217/6000 [2:47:16<24:12,  1.85s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5218/6000 [2:47:18<24:12,  1.86s/it]                                                     {'loss': 0.1446, 'grad_norm': 8.364850044250488, 'learning_rate': 1.3254237288135594e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5218/6000 [2:47:18<24:12,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5219/6000 [2:47:20<23:55,  1.84s/it]                                                     {'loss': 0.1071, 'grad_norm': 9.518473625183105, 'learning_rate': 1.323728813559322e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5219/6000 [2:47:20<23:55,  1.84s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5220/6000 [2:47:21<24:08,  1.86s/it]                                                     {'loss': 0.0526, 'grad_norm': 6.691988945007324, 'learning_rate': 1.322033898305085e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5220/6000 [2:47:21<24:08,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5221/6000 [2:47:23<24:11,  1.86s/it]                                                     {'loss': 0.0615, 'grad_norm': 3.360133171081543, 'learning_rate': 1.3203389830508475e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5221/6000 [2:47:23<24:11,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5222/6000 [2:47:25<24:30,  1.89s/it]                                                     {'loss': 0.0053, 'grad_norm': 0.5601053833961487, 'learning_rate': 1.3186440677966104e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5222/6000 [2:47:25<24:30,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5223/6000 [2:47:27<25:08,  1.94s/it]                                                     {'loss': 0.3968, 'grad_norm': 14.215375900268555, 'learning_rate': 1.316949152542373e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5223/6000 [2:47:27<25:08,  1.94s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5224/6000 [2:47:29<24:44,  1.91s/it]                                                     {'loss': 0.0376, 'grad_norm': 5.4621968269348145, 'learning_rate': 1.3152542372881359e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5224/6000 [2:47:29<24:44,  1.91s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5225/6000 [2:47:31<24:25,  1.89s/it]                                                     {'loss': 0.0825, 'grad_norm': 7.536318302154541, 'learning_rate': 1.3135593220338985e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5225/6000 [2:47:31<24:25,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5226/6000 [2:47:33<24:13,  1.88s/it]                                                     {'loss': 0.0196, 'grad_norm': 2.4006431102752686, 'learning_rate': 1.3118644067796612e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5226/6000 [2:47:33<24:13,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5227/6000 [2:47:35<24:06,  1.87s/it]                                                     {'loss': 0.1917, 'grad_norm': 9.632532119750977, 'learning_rate': 1.3101694915254238e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5227/6000 [2:47:35<24:06,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5228/6000 [2:47:37<23:52,  1.86s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.09607760608196259, 'learning_rate': 1.3084745762711864e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5228/6000 [2:47:37<23:52,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5229/6000 [2:47:38<23:57,  1.86s/it]                                                     {'loss': 0.003, 'grad_norm': 0.48011669516563416, 'learning_rate': 1.3067796610169493e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5229/6000 [2:47:38<23:57,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5230/6000 [2:47:40<23:57,  1.87s/it]                                                     {'loss': 0.0106, 'grad_norm': 1.198474645614624, 'learning_rate': 1.305084745762712e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5230/6000 [2:47:40<23:57,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5231/6000 [2:47:42<23:54,  1.87s/it]                                                     {'loss': 0.1586, 'grad_norm': 11.063486099243164, 'learning_rate': 1.3033898305084748e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5231/6000 [2:47:42<23:54,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5232/6000 [2:47:44<23:52,  1.86s/it]                                                     {'loss': 0.004, 'grad_norm': 0.8829454779624939, 'learning_rate': 1.3016949152542374e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5232/6000 [2:47:44<23:52,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5233/6000 [2:47:46<24:03,  1.88s/it]                                                     {'loss': 0.0306, 'grad_norm': 3.5825035572052, 'learning_rate': 1.3e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5233/6000 [2:47:46<24:03,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5234/6000 [2:47:48<23:58,  1.88s/it]                                                     {'loss': 0.0486, 'grad_norm': 6.350768089294434, 'learning_rate': 1.298305084745763e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5234/6000 [2:47:48<23:58,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5235/6000 [2:47:50<23:58,  1.88s/it]                                                     {'loss': 0.1426, 'grad_norm': 8.68270206451416, 'learning_rate': 1.2966101694915255e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5235/6000 [2:47:50<23:58,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5236/6000 [2:47:52<23:52,  1.87s/it]                                                     {'loss': 0.2305, 'grad_norm': 12.47107219696045, 'learning_rate': 1.2949152542372884e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5236/6000 [2:47:52<23:52,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5237/6000 [2:47:53<23:41,  1.86s/it]                                                     {'loss': 0.2841, 'grad_norm': 9.631486892700195, 'learning_rate': 1.2932203389830508e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5237/6000 [2:47:53<23:41,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5238/6000 [2:47:55<23:42,  1.87s/it]                                                     {'loss': 0.0183, 'grad_norm': 1.2900981903076172, 'learning_rate': 1.2915254237288137e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5238/6000 [2:47:55<23:42,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5239/6000 [2:47:57<23:45,  1.87s/it]                                                     {'loss': 0.2158, 'grad_norm': 13.300745010375977, 'learning_rate': 1.2898305084745763e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5239/6000 [2:47:57<23:45,  1.87s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5240/6000 [2:47:59<23:35,  1.86s/it]                                                     {'loss': 0.0737, 'grad_norm': 2.3404905796051025, 'learning_rate': 1.288135593220339e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5240/6000 [2:47:59<23:35,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5241/6000 [2:48:01<23:27,  1.85s/it]                                                     {'loss': 0.0707, 'grad_norm': 9.104634284973145, 'learning_rate': 1.2864406779661018e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5241/6000 [2:48:01<23:27,  1.85s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5242/6000 [2:48:03<23:30,  1.86s/it]                                                     {'loss': 0.0172, 'grad_norm': 2.6785783767700195, 'learning_rate': 1.2847457627118644e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5242/6000 [2:48:03<23:30,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5243/6000 [2:48:05<23:53,  1.89s/it]                                                     {'loss': 0.3973, 'grad_norm': 11.327617645263672, 'learning_rate': 1.2830508474576273e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5243/6000 [2:48:05<23:53,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5244/6000 [2:48:07<23:46,  1.89s/it]                                                     {'loss': 0.0063, 'grad_norm': 0.8782625794410706, 'learning_rate': 1.28135593220339e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5244/6000 [2:48:07<23:46,  1.89s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5245/6000 [2:48:08<23:39,  1.88s/it]                                                     {'loss': 0.0256, 'grad_norm': 3.3987531661987305, 'learning_rate': 1.2796610169491528e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5245/6000 [2:48:08<23:39,  1.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5246/6000 [2:48:10<23:25,  1.86s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.9023426175117493, 'learning_rate': 1.2779661016949154e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5246/6000 [2:48:10<23:25,  1.86s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5247/6000 [2:48:12<23:13,  1.85s/it]                                                     {'loss': 0.2621, 'grad_norm': 12.39683723449707, 'learning_rate': 1.2762711864406778e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5247/6000 [2:48:12<23:13,  1.85s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5248/6000 [2:48:14<23:10,  1.85s/it]                                                     {'loss': 0.0639, 'grad_norm': 7.096614360809326, 'learning_rate': 1.2745762711864407e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5248/6000 [2:48:14<23:10,  1.85s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5249/6000 [2:48:16<23:25,  1.87s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.25548842549324036, 'learning_rate': 1.2728813559322033e-06, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5249/6000 [2:48:16<23:25,  1.87s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5250/6000 [2:48:18<23:24,  1.87s/it]                                                     {'loss': 0.1017, 'grad_norm': 10.391396522521973, 'learning_rate': 1.2711864406779662e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5250/6000 [2:48:18<23:24,  1.87s/it][2025-11-12 00:41:33,655] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5250
[2025-11-12 00:41:33,663] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:41:33,944] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5250/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5251/6000 [2:48:20<26:35,  2.13s/it]                                                     {'loss': 0.01, 'grad_norm': 1.7121925354003906, 'learning_rate': 1.2694915254237288e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5251/6000 [2:48:20<26:35,  2.13s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5252/6000 [2:48:22<25:36,  2.05s/it]                                                     {'loss': 0.1096, 'grad_norm': 6.818182468414307, 'learning_rate': 1.2677966101694917e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5252/6000 [2:48:22<25:36,  2.05s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5253/6000 [2:48:24<25:19,  2.03s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.06803404539823532, 'learning_rate': 1.2661016949152543e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5253/6000 [2:48:24<25:19,  2.03s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5254/6000 [2:48:26<25:03,  2.02s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.054797057062387466, 'learning_rate': 1.2644067796610171e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5254/6000 [2:48:26<25:03,  2.02s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5255/6000 [2:48:28<24:54,  2.01s/it]                                                     {'loss': 0.038, 'grad_norm': 4.085351943969727, 'learning_rate': 1.2627118644067798e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5255/6000 [2:48:28<24:54,  2.01s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5256/6000 [2:48:30<24:35,  1.98s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.6034512519836426, 'learning_rate': 1.2610169491525426e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5256/6000 [2:48:30<24:35,  1.98s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5257/6000 [2:48:32<24:28,  1.98s/it]                                                     {'loss': 0.0474, 'grad_norm': 2.534956216812134, 'learning_rate': 1.2593220338983053e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5257/6000 [2:48:32<24:28,  1.98s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5258/6000 [2:48:34<23:59,  1.94s/it]                                                     {'loss': 0.0201, 'grad_norm': 1.3285107612609863, 'learning_rate': 1.2576271186440677e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5258/6000 [2:48:34<23:59,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5259/6000 [2:48:36<24:03,  1.95s/it]                                                     {'loss': 0.0297, 'grad_norm': 5.930513858795166, 'learning_rate': 1.2559322033898306e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5259/6000 [2:48:36<24:03,  1.95s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5260/6000 [2:48:38<23:45,  1.93s/it]                                                     {'loss': 0.184, 'grad_norm': 10.617051124572754, 'learning_rate': 1.2542372881355932e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5260/6000 [2:48:38<23:45,  1.93s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5261/6000 [2:48:40<23:45,  1.93s/it]                                                     {'loss': 0.0885, 'grad_norm': 9.355579376220703, 'learning_rate': 1.252542372881356e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5261/6000 [2:48:40<23:45,  1.93s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5262/6000 [2:48:42<23:36,  1.92s/it]                                                     {'loss': 0.0983, 'grad_norm': 7.615602016448975, 'learning_rate': 1.2508474576271187e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5262/6000 [2:48:42<23:36,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5263/6000 [2:48:44<23:21,  1.90s/it]                                                     {'loss': 0.0365, 'grad_norm': 4.081589698791504, 'learning_rate': 1.2491525423728815e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5263/6000 [2:48:44<23:21,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5264/6000 [2:48:46<23:49,  1.94s/it]                                                     {'loss': 0.0075, 'grad_norm': 0.7272462248802185, 'learning_rate': 1.2474576271186442e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5264/6000 [2:48:46<23:49,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5265/6000 [2:48:47<23:31,  1.92s/it]                                                     {'loss': 0.2673, 'grad_norm': 10.810885429382324, 'learning_rate': 1.245762711864407e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5265/6000 [2:48:47<23:31,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5266/6000 [2:48:49<23:21,  1.91s/it]                                                     {'loss': 0.0044, 'grad_norm': 0.42937546968460083, 'learning_rate': 1.2440677966101694e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5266/6000 [2:48:49<23:21,  1.91s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5267/6000 [2:48:51<23:27,  1.92s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.020428486168384552, 'learning_rate': 1.2423728813559323e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5267/6000 [2:48:51<23:27,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5268/6000 [2:48:53<23:23,  1.92s/it]                                                     {'loss': 0.001, 'grad_norm': 0.1459546536207199, 'learning_rate': 1.240677966101695e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5268/6000 [2:48:53<23:23,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5269/6000 [2:48:55<23:24,  1.92s/it]                                                     {'loss': 0.0743, 'grad_norm': 5.115631103515625, 'learning_rate': 1.2389830508474578e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5269/6000 [2:48:55<23:24,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5270/6000 [2:48:57<23:05,  1.90s/it]                                                     {'loss': 0.0698, 'grad_norm': 3.293785572052002, 'learning_rate': 1.2372881355932204e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5270/6000 [2:48:57<23:05,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5271/6000 [2:48:59<23:08,  1.91s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.012018745765089989, 'learning_rate': 1.235593220338983e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5271/6000 [2:48:59<23:08,  1.91s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5272/6000 [2:49:01<23:39,  1.95s/it]                                                     {'loss': 0.1727, 'grad_norm': 7.956164360046387, 'learning_rate': 1.233898305084746e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5272/6000 [2:49:01<23:39,  1.95s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5273/6000 [2:49:03<23:18,  1.92s/it]                                                     {'loss': 0.0565, 'grad_norm': 4.4773335456848145, 'learning_rate': 1.2322033898305085e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5273/6000 [2:49:03<23:18,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5274/6000 [2:49:05<23:07,  1.91s/it]                                                     {'loss': 0.0336, 'grad_norm': 3.628267765045166, 'learning_rate': 1.2305084745762714e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5274/6000 [2:49:05<23:07,  1.91s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5275/6000 [2:49:07<22:53,  1.89s/it]                                                     {'loss': 0.0224, 'grad_norm': 1.5943721532821655, 'learning_rate': 1.228813559322034e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5275/6000 [2:49:07<22:53,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5276/6000 [2:49:08<22:40,  1.88s/it]                                                     {'loss': 0.1864, 'grad_norm': 13.952411651611328, 'learning_rate': 1.2271186440677967e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5276/6000 [2:49:08<22:40,  1.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5277/6000 [2:49:10<22:46,  1.89s/it]                                                     {'loss': 0.0525, 'grad_norm': 8.25467586517334, 'learning_rate': 1.2254237288135593e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5277/6000 [2:49:10<22:46,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5278/6000 [2:49:12<22:42,  1.89s/it]                                                     {'loss': 0.0936, 'grad_norm': 6.985159873962402, 'learning_rate': 1.2237288135593222e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5278/6000 [2:49:12<22:42,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5279/6000 [2:49:14<22:38,  1.88s/it]                                                     {'loss': 0.0672, 'grad_norm': 3.30061936378479, 'learning_rate': 1.2220338983050848e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5279/6000 [2:49:14<22:38,  1.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5280/6000 [2:49:16<22:40,  1.89s/it]                                                     {'loss': 0.0514, 'grad_norm': 6.1742119789123535, 'learning_rate': 1.2203389830508477e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5280/6000 [2:49:16<22:40,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5281/6000 [2:49:18<23:12,  1.94s/it]                                                     {'loss': 0.0422, 'grad_norm': 2.561434030532837, 'learning_rate': 1.2186440677966103e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5281/6000 [2:49:18<23:12,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5282/6000 [2:49:20<22:50,  1.91s/it]                                                     {'loss': 0.1563, 'grad_norm': 12.912405014038086, 'learning_rate': 1.216949152542373e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5282/6000 [2:49:20<22:50,  1.91s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5283/6000 [2:49:22<22:41,  1.90s/it]                                                     {'loss': 0.0959, 'grad_norm': 9.920368194580078, 'learning_rate': 1.2152542372881358e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5283/6000 [2:49:22<22:41,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5284/6000 [2:49:24<22:25,  1.88s/it]                                                     {'loss': 0.0116, 'grad_norm': 1.3766461610794067, 'learning_rate': 1.2135593220338984e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5284/6000 [2:49:24<22:25,  1.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5285/6000 [2:49:26<22:33,  1.89s/it]                                                     {'loss': 0.0153, 'grad_norm': 3.8781087398529053, 'learning_rate': 1.2118644067796613e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5285/6000 [2:49:26<22:33,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5286/6000 [2:49:27<22:18,  1.87s/it]                                                     {'loss': 0.0528, 'grad_norm': 5.996853828430176, 'learning_rate': 1.2101694915254237e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5286/6000 [2:49:27<22:18,  1.87s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5287/6000 [2:49:29<22:05,  1.86s/it]                                                     {'loss': 0.1233, 'grad_norm': 7.353417873382568, 'learning_rate': 1.2084745762711865e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5287/6000 [2:49:29<22:05,  1.86s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5288/6000 [2:49:31<22:12,  1.87s/it]                                                     {'loss': 0.1223, 'grad_norm': 7.039903163909912, 'learning_rate': 1.2067796610169492e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5288/6000 [2:49:31<22:12,  1.87s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5289/6000 [2:49:33<22:16,  1.88s/it]                                                     {'loss': 0.0256, 'grad_norm': 2.85416579246521, 'learning_rate': 1.205084745762712e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5289/6000 [2:49:33<22:16,  1.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5290/6000 [2:49:35<22:12,  1.88s/it]                                                     {'loss': 0.0724, 'grad_norm': 5.63950777053833, 'learning_rate': 1.2033898305084747e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5290/6000 [2:49:35<22:12,  1.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5291/6000 [2:49:37<22:24,  1.90s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.09144026041030884, 'learning_rate': 1.2016949152542375e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5291/6000 [2:49:37<22:24,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5292/6000 [2:49:39<22:19,  1.89s/it]                                                     {'loss': 0.0258, 'grad_norm': 1.983093023300171, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5292/6000 [2:49:39<22:19,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5293/6000 [2:49:41<22:14,  1.89s/it]                                                     {'loss': 0.0933, 'grad_norm': 6.404346466064453, 'learning_rate': 1.1983050847457628e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5293/6000 [2:49:41<22:14,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5294/6000 [2:49:42<22:10,  1.88s/it]                                                     {'loss': 0.0402, 'grad_norm': 4.176950454711914, 'learning_rate': 1.1966101694915254e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5294/6000 [2:49:42<22:10,  1.88s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5295/6000 [2:49:44<21:59,  1.87s/it]                                                     {'loss': 0.0594, 'grad_norm': 6.708308219909668, 'learning_rate': 1.1949152542372883e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5295/6000 [2:49:44<21:59,  1.87s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5296/6000 [2:49:46<22:08,  1.89s/it]                                                     {'loss': 0.0167, 'grad_norm': 1.7631858587265015, 'learning_rate': 1.193220338983051e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5296/6000 [2:49:46<22:08,  1.89s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5297/6000 [2:49:48<22:16,  1.90s/it]                                                     {'loss': 0.0016, 'grad_norm': 0.3658906817436218, 'learning_rate': 1.1915254237288136e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5297/6000 [2:49:48<22:16,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5298/6000 [2:49:50<22:11,  1.90s/it]                                                     {'loss': 0.0112, 'grad_norm': 2.9284133911132812, 'learning_rate': 1.1898305084745764e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5298/6000 [2:49:50<22:11,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5299/6000 [2:49:52<22:38,  1.94s/it]                                                     {'loss': 0.3933, 'grad_norm': 9.543888092041016, 'learning_rate': 1.188135593220339e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5299/6000 [2:49:52<22:38,  1.94s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5300/6000 [2:49:54<22:24,  1.92s/it]                                                     {'loss': 0.0383, 'grad_norm': 5.3839311599731445, 'learning_rate': 1.186440677966102e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5300/6000 [2:49:54<22:24,  1.92s/it][2025-11-12 00:43:09,829] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5300
[2025-11-12 00:43:09,837] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:43:10,121] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5301/6000 [2:49:57<25:19,  2.17s/it]                                                     {'loss': 0.1027, 'grad_norm': 5.175300598144531, 'learning_rate': 1.1847457627118645e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5301/6000 [2:49:57<25:19,  2.17s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5302/6000 [2:49:59<24:16,  2.09s/it]                                                     {'loss': 0.1153, 'grad_norm': 9.763751029968262, 'learning_rate': 1.1830508474576272e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5302/6000 [2:49:59<24:16,  2.09s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5303/6000 [2:50:00<23:32,  2.03s/it]                                                     {'loss': 0.0213, 'grad_norm': 3.337630033493042, 'learning_rate': 1.1813559322033898e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5303/6000 [2:50:00<23:32,  2.03s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5304/6000 [2:50:02<23:18,  2.01s/it]                                                     {'loss': 0.2258, 'grad_norm': 5.747671127319336, 'learning_rate': 1.1796610169491527e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5304/6000 [2:50:02<23:18,  2.01s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5305/6000 [2:50:04<22:47,  1.97s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.04024769738316536, 'learning_rate': 1.1779661016949153e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5305/6000 [2:50:04<22:47,  1.97s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5306/6000 [2:50:06<22:30,  1.95s/it]                                                     {'loss': 0.003, 'grad_norm': 0.3227693438529968, 'learning_rate': 1.1762711864406782e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5306/6000 [2:50:06<22:30,  1.95s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5307/6000 [2:50:08<22:10,  1.92s/it]                                                     {'loss': 0.0861, 'grad_norm': 4.718648433685303, 'learning_rate': 1.1745762711864408e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5307/6000 [2:50:08<22:10,  1.92s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5308/6000 [2:50:10<21:59,  1.91s/it]                                                     {'loss': 0.192, 'grad_norm': 13.64759349822998, 'learning_rate': 1.1728813559322034e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5308/6000 [2:50:10<21:59,  1.91s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5309/6000 [2:50:12<21:53,  1.90s/it]                                                     {'loss': 0.1086, 'grad_norm': 8.30030632019043, 'learning_rate': 1.1711864406779663e-06, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5309/6000 [2:50:12<21:53,  1.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5310/6000 [2:50:14<21:46,  1.89s/it]                                                     {'loss': 0.0066, 'grad_norm': 0.8312472105026245, 'learning_rate': 1.169491525423729e-06, 'epoch': 0.89}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5310/6000 [2:50:14<21:46,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5311/6000 [2:50:16<21:39,  1.89s/it]                                                     {'loss': 0.0131, 'grad_norm': 1.5940762758255005, 'learning_rate': 1.1677966101694918e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5311/6000 [2:50:16<21:39,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5312/6000 [2:50:17<21:42,  1.89s/it]                                                     {'loss': 0.0256, 'grad_norm': 4.400941371917725, 'learning_rate': 1.1661016949152542e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5312/6000 [2:50:17<21:42,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5313/6000 [2:50:19<21:31,  1.88s/it]                                                     {'loss': 0.1316, 'grad_norm': 5.51648473739624, 'learning_rate': 1.164406779661017e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5313/6000 [2:50:19<21:31,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5314/6000 [2:50:21<21:28,  1.88s/it]                                                     {'loss': 0.0573, 'grad_norm': 4.289799213409424, 'learning_rate': 1.1627118644067797e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5314/6000 [2:50:21<21:28,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5315/6000 [2:50:23<21:28,  1.88s/it]                                                     {'loss': 0.0068, 'grad_norm': 1.1013480424880981, 'learning_rate': 1.1610169491525425e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5315/6000 [2:50:23<21:28,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5316/6000 [2:50:25<21:19,  1.87s/it]                                                     {'loss': 0.0188, 'grad_norm': 2.912325143814087, 'learning_rate': 1.1593220338983052e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5316/6000 [2:50:25<21:19,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5317/6000 [2:50:27<21:12,  1.86s/it]                                                     {'loss': 0.0092, 'grad_norm': 1.075009822845459, 'learning_rate': 1.157627118644068e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5317/6000 [2:50:27<21:12,  1.86s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5318/6000 [2:50:29<21:13,  1.87s/it]                                                     {'loss': 0.0352, 'grad_norm': 3.5337302684783936, 'learning_rate': 1.1559322033898307e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5318/6000 [2:50:29<21:13,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5319/6000 [2:50:31<21:30,  1.90s/it]                                                     {'loss': 0.0633, 'grad_norm': 5.985857009887695, 'learning_rate': 1.1542372881355933e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5319/6000 [2:50:31<21:30,  1.90s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5320/6000 [2:50:32<21:27,  1.89s/it]                                                     {'loss': 0.0331, 'grad_norm': 3.638706922531128, 'learning_rate': 1.152542372881356e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5320/6000 [2:50:32<21:27,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5321/6000 [2:50:34<21:17,  1.88s/it]                                                     {'loss': 0.0435, 'grad_norm': 1.7564961910247803, 'learning_rate': 1.1508474576271188e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5321/6000 [2:50:34<21:17,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5322/6000 [2:50:36<21:21,  1.89s/it]                                                     {'loss': 0.0125, 'grad_norm': 1.5192304849624634, 'learning_rate': 1.1491525423728814e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5322/6000 [2:50:36<21:21,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5323/6000 [2:50:38<21:18,  1.89s/it]                                                     {'loss': 0.3425, 'grad_norm': 10.562851905822754, 'learning_rate': 1.147457627118644e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5323/6000 [2:50:38<21:18,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5324/6000 [2:50:40<22:43,  2.02s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.06623708456754684, 'learning_rate': 1.145762711864407e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5324/6000 [2:50:40<22:43,  2.02s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5325/6000 [2:50:42<22:29,  2.00s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.3374372720718384, 'learning_rate': 1.1440677966101696e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5325/6000 [2:50:42<22:29,  2.00s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5326/6000 [2:50:44<22:01,  1.96s/it]                                                     {'loss': 0.0055, 'grad_norm': 1.1039361953735352, 'learning_rate': 1.1423728813559324e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5326/6000 [2:50:44<22:01,  1.96s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5327/6000 [2:50:46<21:45,  1.94s/it]                                                     {'loss': 0.0539, 'grad_norm': 5.531970500946045, 'learning_rate': 1.140677966101695e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5327/6000 [2:50:46<21:45,  1.94s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5328/6000 [2:50:48<21:37,  1.93s/it]                                                     {'loss': 0.1479, 'grad_norm': 5.974330902099609, 'learning_rate': 1.1389830508474577e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5328/6000 [2:50:48<21:37,  1.93s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5329/6000 [2:50:50<21:18,  1.91s/it]                                                     {'loss': 0.1269, 'grad_norm': 9.234514236450195, 'learning_rate': 1.1372881355932203e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5329/6000 [2:50:50<21:18,  1.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5330/6000 [2:50:52<21:17,  1.91s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.006339178886264563, 'learning_rate': 1.1355932203389832e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5330/6000 [2:50:52<21:17,  1.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5331/6000 [2:50:54<21:12,  1.90s/it]                                                     {'loss': 0.0537, 'grad_norm': 3.1295089721679688, 'learning_rate': 1.1338983050847458e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5331/6000 [2:50:54<21:12,  1.90s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5332/6000 [2:50:56<21:08,  1.90s/it]                                                     {'loss': 0.0021, 'grad_norm': 0.43562594056129456, 'learning_rate': 1.1322033898305087e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5332/6000 [2:50:56<21:08,  1.90s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5333/6000 [2:50:57<20:57,  1.88s/it]                                                     {'loss': 0.0343, 'grad_norm': 6.952347755432129, 'learning_rate': 1.1305084745762713e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5333/6000 [2:50:57<20:57,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5334/6000 [2:50:59<21:24,  1.93s/it]                                                     {'loss': 0.1069, 'grad_norm': 7.416123867034912, 'learning_rate': 1.128813559322034e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5334/6000 [2:51:00<21:24,  1.93s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5335/6000 [2:51:01<21:13,  1.92s/it]                                                     {'loss': 0.1171, 'grad_norm': 7.391138553619385, 'learning_rate': 1.1271186440677968e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5335/6000 [2:51:01<21:13,  1.92s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5336/6000 [2:51:03<21:01,  1.90s/it]                                                     {'loss': 0.2236, 'grad_norm': 11.233956336975098, 'learning_rate': 1.1254237288135594e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5336/6000 [2:51:03<21:01,  1.90s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5337/6000 [2:51:05<20:47,  1.88s/it]                                                     {'loss': 0.0183, 'grad_norm': 2.791773796081543, 'learning_rate': 1.1237288135593223e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5337/6000 [2:51:05<20:47,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5338/6000 [2:51:07<20:40,  1.87s/it]                                                     {'loss': 0.1698, 'grad_norm': 8.270277976989746, 'learning_rate': 1.1220338983050847e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5338/6000 [2:51:07<20:40,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5339/6000 [2:51:09<20:33,  1.87s/it]                                                     {'loss': 0.1015, 'grad_norm': 8.253399848937988, 'learning_rate': 1.1203389830508475e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5339/6000 [2:51:09<20:33,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5340/6000 [2:51:11<20:33,  1.87s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.0613781176507473, 'learning_rate': 1.1186440677966102e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5340/6000 [2:51:11<20:33,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5341/6000 [2:51:13<20:35,  1.87s/it]                                                     {'loss': 0.088, 'grad_norm': 3.6974565982818604, 'learning_rate': 1.116949152542373e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5341/6000 [2:51:13<20:35,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5342/6000 [2:51:14<20:30,  1.87s/it]                                                     {'loss': 0.006, 'grad_norm': 0.8567943572998047, 'learning_rate': 1.1152542372881357e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5342/6000 [2:51:14<20:30,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5343/6000 [2:51:16<20:27,  1.87s/it]                                                     {'loss': 0.0416, 'grad_norm': 1.7092058658599854, 'learning_rate': 1.1135593220338985e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5343/6000 [2:51:16<20:27,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5344/6000 [2:51:18<20:30,  1.88s/it]                                                     {'loss': 0.1496, 'grad_norm': 6.532736778259277, 'learning_rate': 1.1118644067796612e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5344/6000 [2:51:18<20:30,  1.88s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5345/6000 [2:51:20<20:21,  1.87s/it]                                                     {'loss': 0.126, 'grad_norm': 9.681573867797852, 'learning_rate': 1.1101694915254238e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5345/6000 [2:51:20<20:21,  1.87s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5346/6000 [2:51:22<21:22,  1.96s/it]                                                     {'loss': 0.0099, 'grad_norm': 1.6208604574203491, 'learning_rate': 1.1084745762711864e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5346/6000 [2:51:22<21:22,  1.96s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5347/6000 [2:51:24<21:05,  1.94s/it]                                                     {'loss': 0.0968, 'grad_norm': 4.558871746063232, 'learning_rate': 1.1067796610169493e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5347/6000 [2:51:24<21:05,  1.94s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5348/6000 [2:51:26<20:50,  1.92s/it]                                                     {'loss': 0.0493, 'grad_norm': 6.228274822235107, 'learning_rate': 1.105084745762712e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5348/6000 [2:51:26<20:50,  1.92s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5349/6000 [2:51:28<20:47,  1.92s/it]                                                     {'loss': 0.0171, 'grad_norm': 2.745774984359741, 'learning_rate': 1.1033898305084746e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5349/6000 [2:51:28<20:47,  1.92s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5350/6000 [2:51:30<20:37,  1.90s/it]                                                     {'loss': 0.0087, 'grad_norm': 1.0515937805175781, 'learning_rate': 1.1016949152542374e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5350/6000 [2:51:30<20:37,  1.90s/it][2025-11-12 00:44:45,657] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5350
[2025-11-12 00:44:45,665] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:44:45,945] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5350/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5351/6000 [2:51:32<23:13,  2.15s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.05333974212408066, 'learning_rate': 1.1e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5351/6000 [2:51:32<23:13,  2.15s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5352/6000 [2:51:34<22:26,  2.08s/it]                                                     {'loss': 0.0891, 'grad_norm': 3.711933135986328, 'learning_rate': 1.098305084745763e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5352/6000 [2:51:34<22:26,  2.08s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5353/6000 [2:51:36<21:54,  2.03s/it]                                                     {'loss': 0.0035, 'grad_norm': 0.37944164872169495, 'learning_rate': 1.0966101694915255e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5353/6000 [2:51:36<21:54,  2.03s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5354/6000 [2:51:38<21:30,  2.00s/it]                                                     {'loss': 0.046, 'grad_norm': 4.250990390777588, 'learning_rate': 1.0949152542372882e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5354/6000 [2:51:38<21:30,  2.00s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5355/6000 [2:51:40<21:01,  1.96s/it]                                                     {'loss': 0.0624, 'grad_norm': 5.697351932525635, 'learning_rate': 1.0932203389830508e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5355/6000 [2:51:40<21:01,  1.96s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5356/6000 [2:51:42<20:54,  1.95s/it]                                                     {'loss': 0.1182, 'grad_norm': 7.905886173248291, 'learning_rate': 1.0915254237288137e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5356/6000 [2:51:42<20:54,  1.95s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5357/6000 [2:51:44<20:41,  1.93s/it]                                                     {'loss': 0.1199, 'grad_norm': 7.775209903717041, 'learning_rate': 1.0898305084745763e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5357/6000 [2:51:44<20:41,  1.93s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5358/6000 [2:51:46<20:30,  1.92s/it]                                                     {'loss': 0.0402, 'grad_norm': 3.345229148864746, 'learning_rate': 1.0881355932203392e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5358/6000 [2:51:46<20:30,  1.92s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5359/6000 [2:51:48<20:19,  1.90s/it]                                                     {'loss': 0.1573, 'grad_norm': 9.773093223571777, 'learning_rate': 1.0864406779661018e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5359/6000 [2:51:48<20:19,  1.90s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5360/6000 [2:51:50<20:45,  1.95s/it]                                                     {'loss': 0.0954, 'grad_norm': 7.618077754974365, 'learning_rate': 1.0847457627118644e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5360/6000 [2:51:50<20:45,  1.95s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5361/6000 [2:51:52<20:27,  1.92s/it]                                                     {'loss': 0.0833, 'grad_norm': 7.143590927124023, 'learning_rate': 1.0830508474576273e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5361/6000 [2:51:52<20:27,  1.92s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5362/6000 [2:51:54<20:38,  1.94s/it]                                                     {'loss': 0.0135, 'grad_norm': 2.0770325660705566, 'learning_rate': 1.08135593220339e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5362/6000 [2:51:54<20:38,  1.94s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5363/6000 [2:51:55<20:16,  1.91s/it]                                                     {'loss': 0.0035, 'grad_norm': 0.4066099226474762, 'learning_rate': 1.0796610169491528e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5363/6000 [2:51:55<20:16,  1.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5364/6000 [2:51:57<20:11,  1.91s/it]                                                     {'loss': 0.0737, 'grad_norm': 5.206759929656982, 'learning_rate': 1.0779661016949152e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5364/6000 [2:51:57<20:11,  1.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5365/6000 [2:51:59<20:01,  1.89s/it]                                                     {'loss': 0.0072, 'grad_norm': 1.221623420715332, 'learning_rate': 1.076271186440678e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5365/6000 [2:51:59<20:01,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5366/6000 [2:52:01<20:06,  1.90s/it]                                                     {'loss': 0.0134, 'grad_norm': 2.248596429824829, 'learning_rate': 1.0745762711864407e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5366/6000 [2:52:01<20:06,  1.90s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5367/6000 [2:52:03<19:56,  1.89s/it]                                                     {'loss': 0.0156, 'grad_norm': 2.4169881343841553, 'learning_rate': 1.0728813559322035e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5367/6000 [2:52:03<19:56,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5368/6000 [2:52:05<19:52,  1.89s/it]                                                     {'loss': 0.0489, 'grad_norm': 5.539217472076416, 'learning_rate': 1.0711864406779662e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5368/6000 [2:52:05<19:52,  1.89s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5369/6000 [2:52:07<19:49,  1.88s/it]                                                     {'loss': 0.0067, 'grad_norm': 1.1184436082839966, 'learning_rate': 1.0694915254237288e-06, 'epoch': 0.89}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5369/6000 [2:52:07<19:49,  1.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5370/6000 [2:52:09<20:24,  1.94s/it]                                                     {'loss': 0.0246, 'grad_norm': 2.987359046936035, 'learning_rate': 1.0677966101694917e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5370/6000 [2:52:09<20:24,  1.94s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5371/6000 [2:52:11<20:12,  1.93s/it]                                                     {'loss': 0.0419, 'grad_norm': 2.5879786014556885, 'learning_rate': 1.0661016949152543e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5371/6000 [2:52:11<20:12,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5372/6000 [2:52:13<20:01,  1.91s/it]                                                     {'loss': 0.0537, 'grad_norm': 5.825570583343506, 'learning_rate': 1.064406779661017e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5372/6000 [2:52:13<20:01,  1.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5373/6000 [2:52:14<19:52,  1.90s/it]                                                     {'loss': 0.0869, 'grad_norm': 6.6603684425354, 'learning_rate': 1.0627118644067798e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5373/6000 [2:52:14<19:52,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5374/6000 [2:52:16<20:21,  1.95s/it]                                                     {'loss': 0.1102, 'grad_norm': 6.662467956542969, 'learning_rate': 1.0610169491525424e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5374/6000 [2:52:16<20:21,  1.95s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5375/6000 [2:52:18<20:09,  1.94s/it]                                                     {'loss': 0.0828, 'grad_norm': 6.923834323883057, 'learning_rate': 1.059322033898305e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5375/6000 [2:52:18<20:09,  1.94s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5376/6000 [2:52:20<19:56,  1.92s/it]                                                     {'loss': 0.1785, 'grad_norm': 9.777565002441406, 'learning_rate': 1.057627118644068e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5376/6000 [2:52:20<19:56,  1.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5377/6000 [2:52:22<20:08,  1.94s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.4340384900569916, 'learning_rate': 1.0559322033898306e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5377/6000 [2:52:22<20:08,  1.94s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5378/6000 [2:52:24<20:00,  1.93s/it]                                                     {'loss': 0.0359, 'grad_norm': 2.7727391719818115, 'learning_rate': 1.0542372881355934e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5378/6000 [2:52:24<20:00,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5379/6000 [2:52:26<19:39,  1.90s/it]                                                     {'loss': 0.1045, 'grad_norm': 4.638545036315918, 'learning_rate': 1.052542372881356e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5379/6000 [2:52:26<19:39,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5380/6000 [2:52:28<19:52,  1.92s/it]                                                     {'loss': 0.103, 'grad_norm': 8.434576034545898, 'learning_rate': 1.0508474576271187e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5380/6000 [2:52:28<19:52,  1.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5381/6000 [2:52:30<19:38,  1.90s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.008642529137432575, 'learning_rate': 1.0491525423728813e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5381/6000 [2:52:30<19:38,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5382/6000 [2:52:32<19:25,  1.89s/it]                                                     {'loss': 0.0649, 'grad_norm': 9.128707885742188, 'learning_rate': 1.0474576271186442e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5382/6000 [2:52:32<19:25,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5383/6000 [2:52:34<20:27,  1.99s/it]                                                     {'loss': 0.0681, 'grad_norm': 8.087367057800293, 'learning_rate': 1.0457627118644068e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5383/6000 [2:52:34<20:27,  1.99s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5384/6000 [2:52:36<20:10,  1.96s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.025640511885285378, 'learning_rate': 1.0440677966101697e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5384/6000 [2:52:36<20:10,  1.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5385/6000 [2:52:38<20:07,  1.96s/it]                                                     {'loss': 0.0831, 'grad_norm': 8.402913093566895, 'learning_rate': 1.0423728813559323e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5385/6000 [2:52:38<20:07,  1.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5386/6000 [2:52:40<19:54,  1.95s/it]                                                     {'loss': 0.0134, 'grad_norm': 1.6887774467468262, 'learning_rate': 1.040677966101695e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5386/6000 [2:52:40<19:54,  1.95s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5387/6000 [2:52:42<20:09,  1.97s/it]                                                     {'loss': 0.0986, 'grad_norm': 6.880606174468994, 'learning_rate': 1.0389830508474578e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5387/6000 [2:52:42<20:09,  1.97s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5388/6000 [2:52:44<19:45,  1.94s/it]                                                     {'loss': 0.0811, 'grad_norm': 5.850138187408447, 'learning_rate': 1.0372881355932204e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5388/6000 [2:52:44<19:45,  1.94s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5389/6000 [2:52:45<19:32,  1.92s/it]                                                     {'loss': 0.146, 'grad_norm': 8.045148849487305, 'learning_rate': 1.0355932203389833e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5389/6000 [2:52:45<19:32,  1.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5390/6000 [2:52:47<19:37,  1.93s/it]                                                     {'loss': 0.0154, 'grad_norm': 1.5431256294250488, 'learning_rate': 1.0338983050847457e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5390/6000 [2:52:47<19:37,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5391/6000 [2:52:49<19:23,  1.91s/it]                                                     {'loss': 0.0039, 'grad_norm': 0.7240546345710754, 'learning_rate': 1.0322033898305086e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5391/6000 [2:52:49<19:23,  1.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5392/6000 [2:52:51<19:12,  1.90s/it]                                                     {'loss': 0.0747, 'grad_norm': 4.022989273071289, 'learning_rate': 1.0305084745762712e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5392/6000 [2:52:51<19:12,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5393/6000 [2:52:53<19:04,  1.89s/it]                                                     {'loss': 0.0395, 'grad_norm': 2.5170915126800537, 'learning_rate': 1.028813559322034e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5393/6000 [2:52:53<19:04,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5394/6000 [2:52:55<19:01,  1.88s/it]                                                     {'loss': 0.1424, 'grad_norm': 8.468645095825195, 'learning_rate': 1.0271186440677967e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5394/6000 [2:52:55<19:01,  1.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5395/6000 [2:52:57<19:04,  1.89s/it]                                                     {'loss': 0.0175, 'grad_norm': 2.4059579372406006, 'learning_rate': 1.0254237288135593e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5395/6000 [2:52:57<19:04,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5396/6000 [2:52:59<19:28,  1.94s/it]                                                     {'loss': 0.0121, 'grad_norm': 1.190494179725647, 'learning_rate': 1.0237288135593222e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5396/6000 [2:52:59<19:28,  1.94s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5397/6000 [2:53:01<19:15,  1.92s/it]                                                     {'loss': 0.0607, 'grad_norm': 2.0428853034973145, 'learning_rate': 1.0220338983050848e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5397/6000 [2:53:01<19:15,  1.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5398/6000 [2:53:03<19:01,  1.90s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.18106751143932343, 'learning_rate': 1.0203389830508477e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5398/6000 [2:53:03<19:01,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5399/6000 [2:53:04<18:55,  1.89s/it]                                                     {'loss': 0.0089, 'grad_norm': 0.6242504119873047, 'learning_rate': 1.0186440677966103e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5399/6000 [2:53:04<18:55,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5400/6000 [2:53:06<18:49,  1.88s/it]                                                     {'loss': 0.0584, 'grad_norm': 8.13483715057373, 'learning_rate': 1.016949152542373e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5400/6000 [2:53:06<18:49,  1.88s/it][2025-11-12 00:46:22,181] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5400
[2025-11-12 00:46:22,188] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:46:22,469] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5401/6000 [2:53:09<21:36,  2.16s/it]                                                     {'loss': 0.0856, 'grad_norm': 4.425902843475342, 'learning_rate': 1.0152542372881356e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5401/6000 [2:53:09<21:36,  2.16s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5402/6000 [2:53:11<20:42,  2.08s/it]                                                     {'loss': 0.0167, 'grad_norm': 1.6781328916549683, 'learning_rate': 1.0135593220338984e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5402/6000 [2:53:11<20:42,  2.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5403/6000 [2:53:13<19:54,  2.00s/it]                                                     {'loss': 0.1238, 'grad_norm': 5.686655044555664, 'learning_rate': 1.011864406779661e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5403/6000 [2:53:13<19:54,  2.00s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5404/6000 [2:53:15<19:26,  1.96s/it]                                                     {'loss': 0.1773, 'grad_norm': 7.9232988357543945, 'learning_rate': 1.010169491525424e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5404/6000 [2:53:15<19:26,  1.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5405/6000 [2:53:17<19:08,  1.93s/it]                                                     {'loss': 0.0173, 'grad_norm': 2.259117603302002, 'learning_rate': 1.0084745762711866e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5405/6000 [2:53:17<19:08,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5406/6000 [2:53:18<18:48,  1.90s/it]                                                     {'loss': 0.0909, 'grad_norm': 6.552136421203613, 'learning_rate': 1.0067796610169492e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5406/6000 [2:53:18<18:48,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5407/6000 [2:53:20<19:04,  1.93s/it]                                                     {'loss': 0.0214, 'grad_norm': 2.4564313888549805, 'learning_rate': 1.0050847457627118e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5407/6000 [2:53:20<19:04,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5408/6000 [2:53:22<18:46,  1.90s/it]                                                     {'loss': 0.2279, 'grad_norm': 7.693739891052246, 'learning_rate': 1.0033898305084747e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5408/6000 [2:53:22<18:46,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5409/6000 [2:53:24<18:40,  1.90s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.45537227392196655, 'learning_rate': 1.0016949152542373e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5409/6000 [2:53:24<18:40,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5410/6000 [2:53:26<18:28,  1.88s/it]                                                     {'loss': 0.0413, 'grad_norm': 5.320433616638184, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5410/6000 [2:53:26<18:28,  1.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5411/6000 [2:53:28<18:25,  1.88s/it]                                                     {'loss': 0.002, 'grad_norm': 0.3610200583934784, 'learning_rate': 9.983050847457628e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5411/6000 [2:53:28<18:25,  1.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5412/6000 [2:53:30<18:31,  1.89s/it]                                                     {'loss': 0.0208, 'grad_norm': 2.843639612197876, 'learning_rate': 9.966101694915254e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5412/6000 [2:53:30<18:31,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5413/6000 [2:53:32<18:27,  1.89s/it]                                                     {'loss': 0.0616, 'grad_norm': 4.984749794006348, 'learning_rate': 9.949152542372883e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5413/6000 [2:53:32<18:27,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5414/6000 [2:53:33<18:22,  1.88s/it]                                                     {'loss': 0.0813, 'grad_norm': 2.8017961978912354, 'learning_rate': 9.93220338983051e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5414/6000 [2:53:33<18:22,  1.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5415/6000 [2:53:35<18:19,  1.88s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.15563827753067017, 'learning_rate': 9.915254237288138e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5415/6000 [2:53:35<18:19,  1.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5416/6000 [2:53:37<18:47,  1.93s/it]                                                     {'loss': 0.039, 'grad_norm': 4.8274970054626465, 'learning_rate': 9.898305084745762e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5416/6000 [2:53:37<18:47,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5417/6000 [2:53:39<18:41,  1.92s/it]                                                     {'loss': 0.0085, 'grad_norm': 2.3522305488586426, 'learning_rate': 9.88135593220339e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5417/6000 [2:53:39<18:41,  1.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5418/6000 [2:53:41<18:23,  1.90s/it]                                                     {'loss': 0.0597, 'grad_norm': 4.864401817321777, 'learning_rate': 9.864406779661017e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5418/6000 [2:53:41<18:23,  1.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5419/6000 [2:53:43<18:17,  1.89s/it]                                                     {'loss': 0.0277, 'grad_norm': 4.3471198081970215, 'learning_rate': 9.847457627118645e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5419/6000 [2:53:43<18:17,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5420/6000 [2:53:45<18:16,  1.89s/it]                                                     {'loss': 0.0491, 'grad_norm': 4.797214984893799, 'learning_rate': 9.830508474576272e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5420/6000 [2:53:45<18:16,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5421/6000 [2:53:47<18:14,  1.89s/it]                                                     {'loss': 0.1444, 'grad_norm': 6.640187740325928, 'learning_rate': 9.813559322033898e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5421/6000 [2:53:47<18:14,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5422/6000 [2:53:49<18:13,  1.89s/it]                                                     {'loss': 0.0494, 'grad_norm': 5.91010856628418, 'learning_rate': 9.796610169491527e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5422/6000 [2:53:49<18:13,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5423/6000 [2:53:51<18:11,  1.89s/it]                                                     {'loss': 0.191, 'grad_norm': 9.729948043823242, 'learning_rate': 9.779661016949153e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5423/6000 [2:53:51<18:11,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5424/6000 [2:53:53<18:29,  1.93s/it]                                                     {'loss': 0.037, 'grad_norm': 4.6355061531066895, 'learning_rate': 9.762711864406782e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5424/6000 [2:53:53<18:29,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5425/6000 [2:53:54<18:19,  1.91s/it]                                                     {'loss': 0.058, 'grad_norm': 5.337979793548584, 'learning_rate': 9.745762711864408e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5425/6000 [2:53:54<18:19,  1.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5426/6000 [2:53:57<18:49,  1.97s/it]                                                     {'loss': 0.1726, 'grad_norm': 9.01406478881836, 'learning_rate': 9.728813559322034e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5426/6000 [2:53:57<18:49,  1.97s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5427/6000 [2:53:58<18:24,  1.93s/it]                                                     {'loss': 0.0141, 'grad_norm': 2.3921995162963867, 'learning_rate': 9.71186440677966e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5427/6000 [2:53:58<18:24,  1.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5428/6000 [2:54:00<18:13,  1.91s/it]                                                     {'loss': 0.0185, 'grad_norm': 2.127045154571533, 'learning_rate': 9.69491525423729e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5428/6000 [2:54:00<18:13,  1.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5429/6000 [2:54:02<17:59,  1.89s/it]                                                     {'loss': 0.0326, 'grad_norm': 6.6005353927612305, 'learning_rate': 9.677966101694916e-07, 'epoch': 0.9}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5429/6000 [2:54:02<17:59,  1.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5430/6000 [2:54:04<17:53,  1.88s/it]                                                     {'loss': 0.0523, 'grad_norm': 4.215365886688232, 'learning_rate': 9.661016949152544e-07, 'epoch': 0.91}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5430/6000 [2:54:04<17:53,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5431/6000 [2:54:06<17:52,  1.89s/it]                                                     {'loss': 0.0113, 'grad_norm': 2.029580593109131, 'learning_rate': 9.64406779661017e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5431/6000 [2:54:06<17:52,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5432/6000 [2:54:08<17:51,  1.89s/it]                                                     {'loss': 0.0106, 'grad_norm': 1.207602620124817, 'learning_rate': 9.627118644067797e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5432/6000 [2:54:08<17:51,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5433/6000 [2:54:10<17:43,  1.88s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.12444419413805008, 'learning_rate': 9.610169491525423e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5433/6000 [2:54:10<17:43,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5434/6000 [2:54:12<18:17,  1.94s/it]                                                     {'loss': 0.1868, 'grad_norm': 8.500957489013672, 'learning_rate': 9.593220338983052e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5434/6000 [2:54:12<18:17,  1.94s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5435/6000 [2:54:14<18:02,  1.92s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.4452827572822571, 'learning_rate': 9.576271186440678e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5435/6000 [2:54:14<18:02,  1.92s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5436/6000 [2:54:15<17:57,  1.91s/it]                                                     {'loss': 0.01, 'grad_norm': 1.1323738098144531, 'learning_rate': 9.559322033898307e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5436/6000 [2:54:15<17:57,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5437/6000 [2:54:17<17:54,  1.91s/it]                                                     {'loss': 0.1672, 'grad_norm': 10.715380668640137, 'learning_rate': 9.542372881355933e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5437/6000 [2:54:17<17:54,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5438/6000 [2:54:19<17:55,  1.91s/it]                                                     {'loss': 0.0621, 'grad_norm': 3.99735689163208, 'learning_rate': 9.525423728813559e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5438/6000 [2:54:19<17:55,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5439/6000 [2:54:21<17:52,  1.91s/it]                                                     {'loss': 0.0399, 'grad_norm': 4.308948993682861, 'learning_rate': 9.508474576271187e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5439/6000 [2:54:21<17:52,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5440/6000 [2:54:23<18:46,  2.01s/it]                                                     {'loss': 0.0065, 'grad_norm': 0.9308530688285828, 'learning_rate': 9.491525423728814e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5440/6000 [2:54:23<18:46,  2.01s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5441/6000 [2:54:25<18:11,  1.95s/it]                                                     {'loss': 0.0199, 'grad_norm': 4.0885701179504395, 'learning_rate': 9.474576271186442e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5441/6000 [2:54:25<18:11,  1.95s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5442/6000 [2:54:27<17:53,  1.92s/it]                                                     {'loss': 0.0717, 'grad_norm': 6.900702476501465, 'learning_rate': 9.457627118644068e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5442/6000 [2:54:27<17:53,  1.92s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5443/6000 [2:54:29<17:48,  1.92s/it]                                                     {'loss': 0.0975, 'grad_norm': 6.582887649536133, 'learning_rate': 9.440677966101696e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5443/6000 [2:54:29<17:48,  1.92s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5444/6000 [2:54:31<17:44,  1.91s/it]                                                     {'loss': 0.0158, 'grad_norm': 1.9113316535949707, 'learning_rate': 9.423728813559323e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5444/6000 [2:54:31<17:44,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5445/6000 [2:54:33<17:34,  1.90s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.3273390233516693, 'learning_rate': 9.40677966101695e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5445/6000 [2:54:33<17:34,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5446/6000 [2:54:35<17:22,  1.88s/it]                                                     {'loss': 0.0043, 'grad_norm': 0.5445110201835632, 'learning_rate': 9.389830508474578e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5446/6000 [2:54:35<17:22,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5447/6000 [2:54:37<17:43,  1.92s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.1430446356534958, 'learning_rate': 9.372881355932203e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5447/6000 [2:54:37<17:43,  1.92s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5448/6000 [2:54:38<17:25,  1.89s/it]                                                     {'loss': 0.075, 'grad_norm': 6.113434314727783, 'learning_rate': 9.355932203389831e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5448/6000 [2:54:38<17:25,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5449/6000 [2:54:40<17:30,  1.91s/it]                                                     {'loss': 0.0929, 'grad_norm': 7.5934953689575195, 'learning_rate': 9.338983050847458e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5449/6000 [2:54:40<17:30,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5450/6000 [2:54:42<17:17,  1.89s/it]                                                     {'loss': 0.0107, 'grad_norm': 1.4085391759872437, 'learning_rate': 9.322033898305086e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5450/6000 [2:54:42<17:17,  1.89s/it][2025-11-12 00:47:58,127] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5450
[2025-11-12 00:47:58,134] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:47:58,551] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5450/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5451/6000 [2:54:45<20:01,  2.19s/it]                                                     {'loss': 0.1467, 'grad_norm': 7.634027481079102, 'learning_rate': 9.305084745762713e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5451/6000 [2:54:45<20:01,  2.19s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5452/6000 [2:54:47<19:05,  2.09s/it]                                                     {'loss': 0.0307, 'grad_norm': 4.325946807861328, 'learning_rate': 9.28813559322034e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5452/6000 [2:54:47<19:05,  2.09s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5453/6000 [2:54:49<18:55,  2.08s/it]                                                     {'loss': 0.0215, 'grad_norm': 2.779325485229492, 'learning_rate': 9.271186440677967e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5453/6000 [2:54:49<18:55,  2.08s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5454/6000 [2:54:51<18:16,  2.01s/it]                                                     {'loss': 0.011, 'grad_norm': 1.7040928602218628, 'learning_rate': 9.254237288135594e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5454/6000 [2:54:51<18:16,  2.01s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5455/6000 [2:54:53<17:53,  1.97s/it]                                                     {'loss': 0.0051, 'grad_norm': 0.6395965218544006, 'learning_rate': 9.237288135593221e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5455/6000 [2:54:53<17:53,  1.97s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5456/6000 [2:54:55<17:33,  1.94s/it]                                                     {'loss': 0.0237, 'grad_norm': 3.713285446166992, 'learning_rate': 9.220338983050848e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5456/6000 [2:54:55<17:33,  1.94s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5457/6000 [2:54:57<17:28,  1.93s/it]                                                     {'loss': 0.0567, 'grad_norm': 5.9723219871521, 'learning_rate': 9.203389830508476e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5457/6000 [2:54:57<17:28,  1.93s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5458/6000 [2:54:58<17:25,  1.93s/it]                                                     {'loss': 0.002, 'grad_norm': 0.24036061763763428, 'learning_rate': 9.186440677966102e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5458/6000 [2:54:58<17:25,  1.93s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5459/6000 [2:55:00<17:07,  1.90s/it]                                                     {'loss': 0.0335, 'grad_norm': 4.495754718780518, 'learning_rate': 9.169491525423729e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5459/6000 [2:55:00<17:07,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5460/6000 [2:55:02<16:59,  1.89s/it]                                                     {'loss': 0.1592, 'grad_norm': 9.108133316040039, 'learning_rate': 9.152542372881357e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5460/6000 [2:55:02<16:59,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5461/6000 [2:55:04<16:53,  1.88s/it]                                                     {'loss': 0.0065, 'grad_norm': 1.3540823459625244, 'learning_rate': 9.135593220338984e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5461/6000 [2:55:04<16:53,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5462/6000 [2:55:06<16:59,  1.90s/it]                                                     {'loss': 0.0148, 'grad_norm': 2.967456817626953, 'learning_rate': 9.118644067796612e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5462/6000 [2:55:06<16:59,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5463/6000 [2:55:08<17:22,  1.94s/it]                                                     {'loss': 0.0101, 'grad_norm': 1.4840967655181885, 'learning_rate': 9.101694915254237e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5463/6000 [2:55:08<17:22,  1.94s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5464/6000 [2:55:10<17:23,  1.95s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.25496217608451843, 'learning_rate': 9.084745762711864e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5464/6000 [2:55:10<17:23,  1.95s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5465/6000 [2:55:12<17:11,  1.93s/it]                                                     {'loss': 0.0074, 'grad_norm': 1.6395922899246216, 'learning_rate': 9.067796610169492e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5465/6000 [2:55:12<17:11,  1.93s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5466/6000 [2:55:14<16:59,  1.91s/it]                                                     {'loss': 0.0851, 'grad_norm': 7.227845668792725, 'learning_rate': 9.050847457627119e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5466/6000 [2:55:14<16:59,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5467/6000 [2:55:16<16:48,  1.89s/it]                                                     {'loss': 0.0102, 'grad_norm': 1.1464059352874756, 'learning_rate': 9.033898305084747e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5467/6000 [2:55:16<16:48,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5468/6000 [2:55:17<16:40,  1.88s/it]                                                     {'loss': 0.0227, 'grad_norm': 3.3974246978759766, 'learning_rate': 9.016949152542373e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5468/6000 [2:55:17<16:40,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5469/6000 [2:55:19<16:45,  1.89s/it]                                                     {'loss': 0.1575, 'grad_norm': 7.035170555114746, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5469/6000 [2:55:19<16:45,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5470/6000 [2:55:21<16:47,  1.90s/it]                                                     {'loss': 0.0285, 'grad_norm': 3.1805365085601807, 'learning_rate': 8.983050847457628e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5470/6000 [2:55:21<16:47,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5471/6000 [2:55:23<16:55,  1.92s/it]                                                     {'loss': 0.0083, 'grad_norm': 0.8056415915489197, 'learning_rate': 8.966101694915256e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5471/6000 [2:55:23<16:55,  1.92s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5472/6000 [2:55:25<16:44,  1.90s/it]                                                     {'loss': 0.1389, 'grad_norm': 8.096963882446289, 'learning_rate': 8.949152542372883e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5472/6000 [2:55:25<16:44,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5473/6000 [2:55:27<16:33,  1.89s/it]                                                     {'loss': 0.0051, 'grad_norm': 0.7558016777038574, 'learning_rate': 8.932203389830508e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5473/6000 [2:55:27<16:33,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5474/6000 [2:55:29<16:29,  1.88s/it]                                                     {'loss': 0.1595, 'grad_norm': 7.572452068328857, 'learning_rate': 8.915254237288136e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5474/6000 [2:55:29<16:29,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5475/6000 [2:55:31<16:19,  1.87s/it]                                                     {'loss': 0.0577, 'grad_norm': 8.687216758728027, 'learning_rate': 8.898305084745763e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5475/6000 [2:55:31<16:19,  1.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5476/6000 [2:55:33<16:28,  1.89s/it]                                                     {'loss': 0.0274, 'grad_norm': 2.6210851669311523, 'learning_rate': 8.881355932203391e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5476/6000 [2:55:33<16:28,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5477/6000 [2:55:34<16:21,  1.88s/it]                                                     {'loss': 0.0462, 'grad_norm': 3.939818859100342, 'learning_rate': 8.864406779661018e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5477/6000 [2:55:34<16:21,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5478/6000 [2:55:36<16:13,  1.87s/it]                                                     {'loss': 0.0344, 'grad_norm': 3.713010311126709, 'learning_rate': 8.847457627118646e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5478/6000 [2:55:36<16:13,  1.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5479/6000 [2:55:38<16:15,  1.87s/it]                                                     {'loss': 0.004, 'grad_norm': 0.43612590432167053, 'learning_rate': 8.830508474576272e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5479/6000 [2:55:38<16:15,  1.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5480/6000 [2:55:40<16:11,  1.87s/it]                                                     {'loss': 0.2075, 'grad_norm': 9.323995590209961, 'learning_rate': 8.813559322033899e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5480/6000 [2:55:40<16:11,  1.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5481/6000 [2:55:42<16:30,  1.91s/it]                                                     {'loss': 0.0836, 'grad_norm': 6.8302106857299805, 'learning_rate': 8.796610169491526e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5481/6000 [2:55:42<16:30,  1.91s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5482/6000 [2:55:44<16:20,  1.89s/it]                                                     {'loss': 0.0421, 'grad_norm': 2.2796616554260254, 'learning_rate': 8.779661016949153e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5482/6000 [2:55:44<16:20,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5483/6000 [2:55:46<16:19,  1.90s/it]                                                     {'loss': 0.0213, 'grad_norm': 2.706446647644043, 'learning_rate': 8.762711864406781e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5483/6000 [2:55:46<16:19,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5484/6000 [2:55:48<16:06,  1.87s/it]                                                     {'loss': 0.0321, 'grad_norm': 4.565920352935791, 'learning_rate': 8.745762711864407e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5484/6000 [2:55:48<16:06,  1.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5485/6000 [2:55:50<16:34,  1.93s/it]                                                     {'loss': 0.0621, 'grad_norm': 3.9921555519104004, 'learning_rate': 8.728813559322034e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5485/6000 [2:55:50<16:34,  1.93s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5486/6000 [2:55:52<16:26,  1.92s/it]                                                     {'loss': 0.0474, 'grad_norm': 2.6511030197143555, 'learning_rate': 8.711864406779662e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5486/6000 [2:55:52<16:26,  1.92s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5487/6000 [2:55:53<16:14,  1.90s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.09609796851873398, 'learning_rate': 8.694915254237289e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5487/6000 [2:55:53<16:14,  1.90s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5488/6000 [2:55:55<16:08,  1.89s/it]                                                     {'loss': 0.0643, 'grad_norm': 4.590506076812744, 'learning_rate': 8.677966101694917e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5488/6000 [2:55:55<16:08,  1.89s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5489/6000 [2:55:57<16:08,  1.90s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.3165493607521057, 'learning_rate': 8.661016949152542e-07, 'epoch': 0.91}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5489/6000 [2:55:57<16:08,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5490/6000 [2:55:59<16:08,  1.90s/it]                                                     {'loss': 0.1832, 'grad_norm': 10.562480926513672, 'learning_rate': 8.64406779661017e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5490/6000 [2:55:59<16:08,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5491/6000 [2:56:01<16:05,  1.90s/it]                                                     {'loss': 0.002, 'grad_norm': 0.2756591737270355, 'learning_rate': 8.627118644067797e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5491/6000 [2:56:01<16:05,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5492/6000 [2:56:03<16:07,  1.90s/it]                                                     {'loss': 0.1072, 'grad_norm': 9.440899848937988, 'learning_rate': 8.610169491525424e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5492/6000 [2:56:03<16:07,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5493/6000 [2:56:05<16:09,  1.91s/it]                                                     {'loss': 0.1318, 'grad_norm': 6.799149513244629, 'learning_rate': 8.593220338983052e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5493/6000 [2:56:05<16:09,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5494/6000 [2:56:07<16:09,  1.92s/it]                                                     {'loss': 0.076, 'grad_norm': 4.419463157653809, 'learning_rate': 8.576271186440678e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5494/6000 [2:56:07<16:09,  1.92s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5495/6000 [2:56:09<16:14,  1.93s/it]                                                     {'loss': 0.0736, 'grad_norm': 3.1139721870422363, 'learning_rate': 8.559322033898306e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5495/6000 [2:56:09<16:14,  1.93s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5496/6000 [2:56:11<16:14,  1.93s/it]                                                     {'loss': 0.026, 'grad_norm': 3.0795559883117676, 'learning_rate': 8.542372881355933e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5496/6000 [2:56:11<16:14,  1.93s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5497/6000 [2:56:13<16:06,  1.92s/it]                                                     {'loss': 0.1146, 'grad_norm': 8.662443161010742, 'learning_rate': 8.525423728813561e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5497/6000 [2:56:13<16:06,  1.92s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5498/6000 [2:56:14<15:57,  1.91s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.09024151414632797, 'learning_rate': 8.508474576271188e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5498/6000 [2:56:14<15:57,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5499/6000 [2:56:16<15:47,  1.89s/it]                                                     {'loss': 0.006, 'grad_norm': 1.2857651710510254, 'learning_rate': 8.491525423728813e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5499/6000 [2:56:16<15:47,  1.89s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5500/6000 [2:56:18<15:45,  1.89s/it]                                                     {'loss': 0.0839, 'grad_norm': 8.117544174194336, 'learning_rate': 8.474576271186441e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5500/6000 [2:56:18<15:45,  1.89s/it][2025-11-12 00:49:34,057] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5500
[2025-11-12 00:49:34,064] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:49:34,356] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5501/6000 [2:56:21<17:45,  2.13s/it]                                                     {'loss': 0.1599, 'grad_norm': 7.231296062469482, 'learning_rate': 8.457627118644068e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5501/6000 [2:56:21<17:45,  2.13s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5502/6000 [2:56:23<17:16,  2.08s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.8400307893753052, 'learning_rate': 8.440677966101696e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5502/6000 [2:56:23<17:16,  2.08s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5503/6000 [2:56:25<16:38,  2.01s/it]                                                     {'loss': 0.0148, 'grad_norm': 1.7950456142425537, 'learning_rate': 8.423728813559323e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5503/6000 [2:56:25<16:38,  2.01s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5504/6000 [2:56:27<16:20,  1.98s/it]                                                     {'loss': 0.0542, 'grad_norm': 3.5460970401763916, 'learning_rate': 8.406779661016951e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5504/6000 [2:56:27<16:20,  1.98s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5505/6000 [2:56:28<16:01,  1.94s/it]                                                     {'loss': 0.0104, 'grad_norm': 1.8648816347122192, 'learning_rate': 8.389830508474577e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5505/6000 [2:56:28<16:01,  1.94s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5506/6000 [2:56:30<15:50,  1.92s/it]                                                     {'loss': 0.0156, 'grad_norm': 2.0522983074188232, 'learning_rate': 8.372881355932204e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5506/6000 [2:56:30<15:50,  1.92s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5507/6000 [2:56:32<15:39,  1.91s/it]                                                     {'loss': 0.0172, 'grad_norm': 2.5816948413848877, 'learning_rate': 8.355932203389832e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5507/6000 [2:56:32<15:39,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5508/6000 [2:56:34<16:03,  1.96s/it]                                                     {'loss': 0.0364, 'grad_norm': 6.105769157409668, 'learning_rate': 8.338983050847458e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5508/6000 [2:56:34<16:03,  1.96s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5509/6000 [2:56:36<15:43,  1.92s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.34480753540992737, 'learning_rate': 8.322033898305086e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5509/6000 [2:56:36<15:43,  1.92s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5510/6000 [2:56:38<15:36,  1.91s/it]                                                     {'loss': 0.0661, 'grad_norm': 3.1061577796936035, 'learning_rate': 8.305084745762712e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5510/6000 [2:56:38<15:36,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5511/6000 [2:56:40<15:26,  1.90s/it]                                                     {'loss': 0.0108, 'grad_norm': 1.6047719717025757, 'learning_rate': 8.288135593220339e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5511/6000 [2:56:40<15:26,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5512/6000 [2:56:42<15:21,  1.89s/it]                                                     {'loss': 0.0166, 'grad_norm': 2.412672996520996, 'learning_rate': 8.271186440677967e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5512/6000 [2:56:42<15:21,  1.89s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5513/6000 [2:56:44<15:23,  1.90s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.43396317958831787, 'learning_rate': 8.254237288135594e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5513/6000 [2:56:44<15:23,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5514/6000 [2:56:45<15:15,  1.88s/it]                                                     {'loss': 0.0892, 'grad_norm': 3.3535499572753906, 'learning_rate': 8.237288135593222e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5514/6000 [2:56:45<15:15,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5515/6000 [2:56:47<15:14,  1.89s/it]                                                     {'loss': 0.0375, 'grad_norm': 4.031388759613037, 'learning_rate': 8.220338983050847e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5515/6000 [2:56:47<15:14,  1.89s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5516/6000 [2:56:49<15:11,  1.88s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.6722275614738464, 'learning_rate': 8.203389830508475e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5516/6000 [2:56:49<15:11,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5517/6000 [2:56:51<15:24,  1.91s/it]                                                     {'loss': 0.0073, 'grad_norm': 0.6912730932235718, 'learning_rate': 8.186440677966102e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5517/6000 [2:56:51<15:24,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5518/6000 [2:56:53<15:14,  1.90s/it]                                                     {'loss': 0.026, 'grad_norm': 4.948452949523926, 'learning_rate': 8.169491525423729e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5518/6000 [2:56:53<15:14,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5519/6000 [2:56:55<15:14,  1.90s/it]                                                     {'loss': 0.1446, 'grad_norm': 6.506682872772217, 'learning_rate': 8.152542372881357e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5519/6000 [2:56:55<15:14,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5520/6000 [2:56:57<15:13,  1.90s/it]                                                     {'loss': 0.0236, 'grad_norm': 2.737027168273926, 'learning_rate': 8.135593220338983e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5520/6000 [2:56:57<15:13,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5521/6000 [2:56:59<15:12,  1.90s/it]                                                     {'loss': 0.1417, 'grad_norm': 6.244659423828125, 'learning_rate': 8.118644067796611e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5521/6000 [2:56:59<15:12,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5522/6000 [2:57:01<15:01,  1.89s/it]                                                     {'loss': 0.0086, 'grad_norm': 2.1087732315063477, 'learning_rate': 8.101694915254238e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5522/6000 [2:57:01<15:01,  1.89s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5523/6000 [2:57:03<14:58,  1.88s/it]                                                     {'loss': 0.2586, 'grad_norm': 11.82435131072998, 'learning_rate': 8.084745762711866e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5523/6000 [2:57:03<14:58,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5524/6000 [2:57:04<14:48,  1.87s/it]                                                     {'loss': 0.0161, 'grad_norm': 2.4649817943573, 'learning_rate': 8.067796610169493e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5524/6000 [2:57:04<14:48,  1.87s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5525/6000 [2:57:06<14:59,  1.89s/it]                                                     {'loss': 0.1935, 'grad_norm': 9.48395824432373, 'learning_rate': 8.050847457627118e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5525/6000 [2:57:06<14:59,  1.89s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5526/6000 [2:57:08<14:55,  1.89s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.2189747840166092, 'learning_rate': 8.033898305084746e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5526/6000 [2:57:08<14:55,  1.89s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5527/6000 [2:57:10<14:50,  1.88s/it]                                                     {'loss': 0.0639, 'grad_norm': 3.050295829772949, 'learning_rate': 8.016949152542373e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5527/6000 [2:57:10<14:50,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5528/6000 [2:57:12<14:45,  1.88s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.016611957922577858, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5528/6000 [2:57:12<14:45,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5529/6000 [2:57:14<14:41,  1.87s/it]                                                     {'loss': 0.0599, 'grad_norm': 5.347076416015625, 'learning_rate': 7.983050847457628e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5529/6000 [2:57:14<14:41,  1.87s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5530/6000 [2:57:16<14:33,  1.86s/it]                                                     {'loss': 0.0072, 'grad_norm': 1.2501251697540283, 'learning_rate': 7.966101694915255e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5530/6000 [2:57:16<14:33,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5531/6000 [2:57:17<14:34,  1.86s/it]                                                     {'loss': 0.0552, 'grad_norm': 6.711851596832275, 'learning_rate': 7.949152542372882e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5531/6000 [2:57:17<14:34,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5532/6000 [2:57:19<14:31,  1.86s/it]                                                     {'loss': 0.036, 'grad_norm': 2.0786304473876953, 'learning_rate': 7.932203389830509e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5532/6000 [2:57:19<14:31,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5533/6000 [2:57:21<14:31,  1.87s/it]                                                     {'loss': 0.0149, 'grad_norm': 1.543773889541626, 'learning_rate': 7.915254237288137e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5533/6000 [2:57:21<14:31,  1.87s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5534/6000 [2:57:23<14:23,  1.85s/it]                                                     {'loss': 0.1365, 'grad_norm': 7.517646312713623, 'learning_rate': 7.898305084745763e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5534/6000 [2:57:23<14:23,  1.85s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5535/6000 [2:57:25<14:30,  1.87s/it]                                                     {'loss': 0.0648, 'grad_norm': 6.943721294403076, 'learning_rate': 7.881355932203391e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5535/6000 [2:57:25<14:30,  1.87s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5536/6000 [2:57:27<14:24,  1.86s/it]                                                     {'loss': 0.1205, 'grad_norm': 7.0089311599731445, 'learning_rate': 7.864406779661017e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5536/6000 [2:57:27<14:24,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5537/6000 [2:57:29<15:24,  2.00s/it]                                                     {'loss': 0.0275, 'grad_norm': 3.438591957092285, 'learning_rate': 7.847457627118645e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5537/6000 [2:57:29<15:24,  2.00s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5538/6000 [2:57:31<15:01,  1.95s/it]                                                     {'loss': 0.0405, 'grad_norm': 5.6669087409973145, 'learning_rate': 7.830508474576272e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5538/6000 [2:57:31<15:01,  1.95s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5539/6000 [2:57:33<14:50,  1.93s/it]                                                     {'loss': 0.0107, 'grad_norm': 1.3552820682525635, 'learning_rate': 7.813559322033899e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5539/6000 [2:57:33<14:50,  1.93s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5540/6000 [2:57:35<14:43,  1.92s/it]                                                     {'loss': 0.0067, 'grad_norm': 1.4672324657440186, 'learning_rate': 7.796610169491527e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5540/6000 [2:57:35<14:43,  1.92s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5541/6000 [2:57:37<14:36,  1.91s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.11557640880346298, 'learning_rate': 7.779661016949152e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5541/6000 [2:57:37<14:36,  1.91s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5542/6000 [2:57:38<14:29,  1.90s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.5928024649620056, 'learning_rate': 7.76271186440678e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5542/6000 [2:57:38<14:29,  1.90s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5543/6000 [2:57:40<14:19,  1.88s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.10255404561758041, 'learning_rate': 7.745762711864407e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5543/6000 [2:57:40<14:19,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5544/6000 [2:57:42<14:15,  1.88s/it]                                                     {'loss': 0.1672, 'grad_norm': 13.708537101745605, 'learning_rate': 7.728813559322034e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5544/6000 [2:57:42<14:15,  1.88s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5545/6000 [2:57:44<14:12,  1.87s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.14354392886161804, 'learning_rate': 7.711864406779662e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5545/6000 [2:57:44<14:12,  1.87s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5546/6000 [2:57:46<14:07,  1.87s/it]                                                     {'loss': 0.019, 'grad_norm': 2.402099132537842, 'learning_rate': 7.694915254237288e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5546/6000 [2:57:46<14:07,  1.87s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5547/6000 [2:57:48<14:02,  1.86s/it]                                                     {'loss': 0.1139, 'grad_norm': 7.511983871459961, 'learning_rate': 7.677966101694916e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5547/6000 [2:57:48<14:02,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5548/6000 [2:57:50<14:00,  1.86s/it]                                                     {'loss': 0.1024, 'grad_norm': 3.04412841796875, 'learning_rate': 7.661016949152543e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5548/6000 [2:57:50<14:00,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5549/6000 [2:57:51<14:00,  1.86s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.4381941258907318, 'learning_rate': 7.644067796610171e-07, 'epoch': 0.92}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5549/6000 [2:57:51<14:00,  1.86s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5550/6000 [2:57:53<13:57,  1.86s/it]                                                     {'loss': 0.069, 'grad_norm': 6.2180376052856445, 'learning_rate': 7.627118644067798e-07, 'epoch': 0.93}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5550/6000 [2:57:53<13:57,  1.86s/it][2025-11-12 00:51:09,244] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5550
[2025-11-12 00:51:09,251] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:51:09,533] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5550/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5551/6000 [2:57:56<15:47,  2.11s/it]                                                     {'loss': 0.0924, 'grad_norm': 7.724793434143066, 'learning_rate': 7.610169491525423e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5551/6000 [2:57:56<15:47,  2.11s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5552/6000 [2:57:58<15:18,  2.05s/it]                                                     {'loss': 0.0729, 'grad_norm': 6.833174705505371, 'learning_rate': 7.593220338983051e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5552/6000 [2:57:58<15:18,  2.05s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5553/6000 [2:58:00<14:59,  2.01s/it]                                                     {'loss': 0.0988, 'grad_norm': 6.340693950653076, 'learning_rate': 7.576271186440678e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5553/6000 [2:58:00<14:59,  2.01s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5554/6000 [2:58:02<14:43,  1.98s/it]                                                     {'loss': 0.0146, 'grad_norm': 2.330462694168091, 'learning_rate': 7.559322033898306e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5554/6000 [2:58:02<14:43,  1.98s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5555/6000 [2:58:04<14:27,  1.95s/it]                                                     {'loss': 0.0233, 'grad_norm': 2.5544910430908203, 'learning_rate': 7.542372881355933e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5555/6000 [2:58:04<14:27,  1.95s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5556/6000 [2:58:06<14:18,  1.93s/it]                                                     {'loss': 0.0115, 'grad_norm': 2.153165102005005, 'learning_rate': 7.52542372881356e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5556/6000 [2:58:06<14:18,  1.93s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5557/6000 [2:58:07<14:09,  1.92s/it]                                                     {'loss': 0.0411, 'grad_norm': 2.725277900695801, 'learning_rate': 7.508474576271187e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5557/6000 [2:58:07<14:09,  1.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5558/6000 [2:58:09<13:58,  1.90s/it]                                                     {'loss': 0.0091, 'grad_norm': 1.540530800819397, 'learning_rate': 7.491525423728814e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5558/6000 [2:58:09<13:58,  1.90s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5559/6000 [2:58:11<13:51,  1.89s/it]                                                     {'loss': 0.0173, 'grad_norm': 2.888505220413208, 'learning_rate': 7.474576271186442e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5559/6000 [2:58:11<13:51,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5560/6000 [2:58:13<13:52,  1.89s/it]                                                     {'loss': 0.1184, 'grad_norm': 6.749037265777588, 'learning_rate': 7.457627118644069e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5560/6000 [2:58:13<13:52,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5561/6000 [2:58:15<13:41,  1.87s/it]                                                     {'loss': 0.0161, 'grad_norm': 1.8143494129180908, 'learning_rate': 7.440677966101696e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5561/6000 [2:58:15<13:41,  1.87s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5562/6000 [2:58:17<14:15,  1.95s/it]                                                     {'loss': 0.0383, 'grad_norm': 2.9175283908843994, 'learning_rate': 7.423728813559322e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5562/6000 [2:58:17<14:15,  1.95s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5563/6000 [2:58:19<13:58,  1.92s/it]                                                     {'loss': 0.0489, 'grad_norm': 5.219920635223389, 'learning_rate': 7.40677966101695e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5563/6000 [2:58:19<13:58,  1.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5564/6000 [2:58:21<14:18,  1.97s/it]                                                     {'loss': 0.0229, 'grad_norm': 1.976008415222168, 'learning_rate': 7.389830508474577e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5564/6000 [2:58:21<14:18,  1.97s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5565/6000 [2:58:23<14:08,  1.95s/it]                                                     {'loss': 0.0254, 'grad_norm': 2.7398550510406494, 'learning_rate': 7.372881355932204e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5565/6000 [2:58:23<14:08,  1.95s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5566/6000 [2:58:25<14:01,  1.94s/it]                                                     {'loss': 0.0174, 'grad_norm': 2.5487732887268066, 'learning_rate': 7.355932203389832e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5566/6000 [2:58:25<14:01,  1.94s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5567/6000 [2:58:27<14:04,  1.95s/it]                                                     {'loss': 0.0044, 'grad_norm': 0.584109902381897, 'learning_rate': 7.338983050847457e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5567/6000 [2:58:27<14:04,  1.95s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5568/6000 [2:58:29<13:46,  1.91s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.009186048991978168, 'learning_rate': 7.322033898305085e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5568/6000 [2:58:29<13:46,  1.91s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5569/6000 [2:58:30<13:38,  1.90s/it]                                                     {'loss': 0.0104, 'grad_norm': 1.5437294244766235, 'learning_rate': 7.305084745762712e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5569/6000 [2:58:30<13:38,  1.90s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5570/6000 [2:58:32<13:33,  1.89s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.14776670932769775, 'learning_rate': 7.28813559322034e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5570/6000 [2:58:32<13:33,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5571/6000 [2:58:34<13:28,  1.89s/it]                                                     {'loss': 0.0999, 'grad_norm': 5.341773509979248, 'learning_rate': 7.271186440677967e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5571/6000 [2:58:34<13:28,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5572/6000 [2:58:36<13:49,  1.94s/it]                                                     {'loss': 0.1689, 'grad_norm': 6.629171371459961, 'learning_rate': 7.254237288135593e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5572/6000 [2:58:36<13:49,  1.94s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5573/6000 [2:58:38<13:40,  1.92s/it]                                                     {'loss': 0.011, 'grad_norm': 1.5580570697784424, 'learning_rate': 7.237288135593221e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5573/6000 [2:58:38<13:40,  1.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5574/6000 [2:58:40<13:33,  1.91s/it]                                                     {'loss': 0.0924, 'grad_norm': 6.460954189300537, 'learning_rate': 7.220338983050848e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5574/6000 [2:58:40<13:33,  1.91s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5575/6000 [2:58:42<13:52,  1.96s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.05280041694641113, 'learning_rate': 7.203389830508476e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5575/6000 [2:58:42<13:52,  1.96s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5576/6000 [2:58:44<13:38,  1.93s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.20666345953941345, 'learning_rate': 7.186440677966103e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5576/6000 [2:58:44<13:38,  1.93s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5577/6000 [2:58:46<13:21,  1.90s/it]                                                     {'loss': 0.1185, 'grad_norm': 8.70590591430664, 'learning_rate': 7.169491525423728e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5577/6000 [2:58:46<13:21,  1.90s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5578/6000 [2:58:48<13:15,  1.89s/it]                                                     {'loss': 0.0452, 'grad_norm': 6.075298309326172, 'learning_rate': 7.152542372881356e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5578/6000 [2:58:48<13:15,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5579/6000 [2:58:49<13:10,  1.88s/it]                                                     {'loss': 0.0758, 'grad_norm': 10.359376907348633, 'learning_rate': 7.135593220338983e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5579/6000 [2:58:49<13:10,  1.88s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5580/6000 [2:58:51<13:12,  1.89s/it]                                                     {'loss': 0.0502, 'grad_norm': 2.440720319747925, 'learning_rate': 7.118644067796611e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5580/6000 [2:58:51<13:12,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5581/6000 [2:58:53<13:04,  1.87s/it]                                                     {'loss': 0.0858, 'grad_norm': 6.377758026123047, 'learning_rate': 7.101694915254238e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5581/6000 [2:58:53<13:04,  1.87s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5582/6000 [2:58:55<12:58,  1.86s/it]                                                     {'loss': 0.1024, 'grad_norm': 7.426405429840088, 'learning_rate': 7.084745762711865e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5582/6000 [2:58:55<12:58,  1.86s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5583/6000 [2:58:57<12:57,  1.86s/it]                                                     {'loss': 0.1472, 'grad_norm': 8.561083793640137, 'learning_rate': 7.067796610169492e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5583/6000 [2:58:57<12:57,  1.86s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5584/6000 [2:58:59<12:56,  1.87s/it]                                                     {'loss': 0.0195, 'grad_norm': 3.110775947570801, 'learning_rate': 7.05084745762712e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5584/6000 [2:58:59<12:56,  1.87s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5585/6000 [2:59:01<12:52,  1.86s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.12867066264152527, 'learning_rate': 7.033898305084747e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5585/6000 [2:59:01<12:52,  1.86s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5586/6000 [2:59:03<12:59,  1.88s/it]                                                     {'loss': 0.0627, 'grad_norm': 3.868217706680298, 'learning_rate': 7.016949152542374e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5586/6000 [2:59:03<12:59,  1.88s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5587/6000 [2:59:04<12:59,  1.89s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.6637898683547974, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5587/6000 [2:59:04<12:59,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5588/6000 [2:59:07<13:17,  1.94s/it]                                                     {'loss': 0.19, 'grad_norm': 9.55556583404541, 'learning_rate': 6.983050847457627e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5588/6000 [2:59:07<13:17,  1.94s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5589/6000 [2:59:08<13:07,  1.92s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.43430715799331665, 'learning_rate': 6.966101694915255e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5589/6000 [2:59:08<13:07,  1.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5590/6000 [2:59:10<13:00,  1.90s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.09199561178684235, 'learning_rate': 6.949152542372882e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5590/6000 [2:59:10<13:00,  1.90s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5591/6000 [2:59:12<12:50,  1.88s/it]                                                     {'loss': 0.0162, 'grad_norm': 1.4492621421813965, 'learning_rate': 6.932203389830509e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5591/6000 [2:59:12<12:50,  1.88s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5592/6000 [2:59:14<12:47,  1.88s/it]                                                     {'loss': 0.2121, 'grad_norm': 11.270246505737305, 'learning_rate': 6.915254237288137e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5592/6000 [2:59:14<12:47,  1.88s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5593/6000 [2:59:16<12:51,  1.89s/it]                                                     {'loss': 0.113, 'grad_norm': 10.305562019348145, 'learning_rate': 6.898305084745763e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5593/6000 [2:59:16<12:51,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5594/6000 [2:59:18<13:04,  1.93s/it]                                                     {'loss': 0.0534, 'grad_norm': 7.336292266845703, 'learning_rate': 6.88135593220339e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5594/6000 [2:59:18<13:04,  1.93s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5595/6000 [2:59:20<12:55,  1.91s/it]                                                     {'loss': 0.0479, 'grad_norm': 4.678896903991699, 'learning_rate': 6.864406779661017e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5595/6000 [2:59:20<12:55,  1.91s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5596/6000 [2:59:22<12:56,  1.92s/it]                                                     {'loss': 0.0457, 'grad_norm': 4.78832483291626, 'learning_rate': 6.847457627118645e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5596/6000 [2:59:22<12:56,  1.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5597/6000 [2:59:24<12:51,  1.91s/it]                                                     {'loss': 0.0777, 'grad_norm': 5.130262851715088, 'learning_rate': 6.830508474576272e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5597/6000 [2:59:24<12:51,  1.91s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5598/6000 [2:59:26<13:21,  1.99s/it]                                                     {'loss': 0.0624, 'grad_norm': 5.185816287994385, 'learning_rate': 6.813559322033898e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5598/6000 [2:59:26<13:21,  1.99s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5599/6000 [2:59:28<13:02,  1.95s/it]                                                     {'loss': 0.0345, 'grad_norm': 4.35693883895874, 'learning_rate': 6.796610169491526e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5599/6000 [2:59:28<13:02,  1.95s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5600/6000 [2:59:30<13:01,  1.95s/it]                                                     {'loss': 0.0075, 'grad_norm': 1.05881667137146, 'learning_rate': 6.779661016949153e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5600/6000 [2:59:30<13:01,  1.95s/it][2025-11-12 00:52:45,530] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5600
[2025-11-12 00:52:45,537] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:52:45,818] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5601/6000 [2:59:32<14:29,  2.18s/it]                                                     {'loss': 0.0835, 'grad_norm': 7.641546726226807, 'learning_rate': 6.762711864406781e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5601/6000 [2:59:32<14:29,  2.18s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5602/6000 [2:59:34<13:47,  2.08s/it]                                                     {'loss': 0.5622, 'grad_norm': 11.330759048461914, 'learning_rate': 6.745762711864408e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5602/6000 [2:59:34<13:47,  2.08s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5603/6000 [2:59:36<13:18,  2.01s/it]                                                     {'loss': 0.0582, 'grad_norm': 4.515298843383789, 'learning_rate': 6.728813559322033e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5603/6000 [2:59:36<13:18,  2.01s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5604/6000 [2:59:38<12:54,  1.96s/it]                                                     {'loss': 0.0637, 'grad_norm': 4.382705211639404, 'learning_rate': 6.711864406779661e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5604/6000 [2:59:38<12:54,  1.96s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5605/6000 [2:59:40<12:41,  1.93s/it]                                                     {'loss': 0.022, 'grad_norm': 1.5407278537750244, 'learning_rate': 6.694915254237288e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5605/6000 [2:59:40<12:41,  1.93s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5606/6000 [2:59:42<12:35,  1.92s/it]                                                     {'loss': 0.1567, 'grad_norm': 8.707999229431152, 'learning_rate': 6.677966101694916e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5606/6000 [2:59:42<12:35,  1.92s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5607/6000 [2:59:43<12:24,  1.89s/it]                                                     {'loss': 0.1864, 'grad_norm': 5.729513645172119, 'learning_rate': 6.661016949152543e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5607/6000 [2:59:43<12:24,  1.89s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5608/6000 [2:59:45<12:25,  1.90s/it]                                                     {'loss': 0.0123, 'grad_norm': 1.5936349630355835, 'learning_rate': 6.64406779661017e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5608/6000 [2:59:45<12:25,  1.90s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5609/6000 [2:59:47<12:17,  1.89s/it]                                                     {'loss': 0.1089, 'grad_norm': 8.40259075164795, 'learning_rate': 6.627118644067797e-07, 'epoch': 0.93}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5609/6000 [2:59:47<12:17,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5610/6000 [2:59:49<12:12,  1.88s/it]                                                     {'loss': 0.0408, 'grad_norm': 3.8241477012634277, 'learning_rate': 6.610169491525425e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5610/6000 [2:59:49<12:12,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5611/6000 [2:59:51<12:03,  1.86s/it]                                                     {'loss': 0.0296, 'grad_norm': 4.594695091247559, 'learning_rate': 6.593220338983052e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5611/6000 [2:59:51<12:03,  1.86s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5612/6000 [2:59:53<12:16,  1.90s/it]                                                     {'loss': 0.0051, 'grad_norm': 1.2547787427902222, 'learning_rate': 6.576271186440679e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5612/6000 [2:59:53<12:16,  1.90s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5613/6000 [2:59:55<12:11,  1.89s/it]                                                     {'loss': 0.0547, 'grad_norm': 6.531810760498047, 'learning_rate': 6.559322033898306e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5613/6000 [2:59:55<12:11,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5614/6000 [2:59:57<12:09,  1.89s/it]                                                     {'loss': 0.0615, 'grad_norm': 2.2883994579315186, 'learning_rate': 6.542372881355932e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5614/6000 [2:59:57<12:09,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5615/6000 [2:59:59<12:07,  1.89s/it]                                                     {'loss': 0.1086, 'grad_norm': 7.657884120941162, 'learning_rate': 6.52542372881356e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5615/6000 [2:59:59<12:07,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5616/6000 [3:00:00<12:07,  1.90s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.0727241113781929, 'learning_rate': 6.508474576271187e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5616/6000 [3:00:00<12:07,  1.90s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5617/6000 [3:00:02<12:16,  1.92s/it]                                                     {'loss': 0.1346, 'grad_norm': 6.984957695007324, 'learning_rate': 6.491525423728814e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5617/6000 [3:00:02<12:16,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5618/6000 [3:00:04<12:03,  1.89s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.03497420623898506, 'learning_rate': 6.474576271186442e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5618/6000 [3:00:04<12:03,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5619/6000 [3:00:06<11:55,  1.88s/it]                                                     {'loss': 0.0133, 'grad_norm': 2.7596378326416016, 'learning_rate': 6.457627118644068e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5619/6000 [3:00:06<11:55,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5620/6000 [3:00:08<11:55,  1.88s/it]                                                     {'loss': 0.1713, 'grad_norm': 8.273621559143066, 'learning_rate': 6.440677966101695e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5620/6000 [3:00:08<11:55,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5621/6000 [3:00:10<11:54,  1.89s/it]                                                     {'loss': 0.0782, 'grad_norm': 5.315836429595947, 'learning_rate': 6.423728813559322e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5621/6000 [3:00:10<11:54,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5622/6000 [3:00:12<11:53,  1.89s/it]                                                     {'loss': 0.0402, 'grad_norm': 5.168900966644287, 'learning_rate': 6.40677966101695e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5622/6000 [3:00:12<11:53,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5623/6000 [3:00:14<11:57,  1.90s/it]                                                     {'loss': 0.004, 'grad_norm': 0.8138900399208069, 'learning_rate': 6.389830508474577e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5623/6000 [3:00:14<11:57,  1.90s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5624/6000 [3:00:16<11:58,  1.91s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.28223755955696106, 'learning_rate': 6.372881355932203e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5624/6000 [3:00:16<11:58,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5625/6000 [3:00:18<12:54,  2.06s/it]                                                     {'loss': 0.0892, 'grad_norm': 5.0833659172058105, 'learning_rate': 6.355932203389831e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5625/6000 [3:00:18<12:54,  2.06s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5626/6000 [3:00:20<12:29,  2.00s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.2826974093914032, 'learning_rate': 6.338983050847458e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5626/6000 [3:00:20<12:29,  2.00s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5627/6000 [3:00:22<12:12,  1.96s/it]                                                     {'loss': 0.0076, 'grad_norm': 1.3138188123703003, 'learning_rate': 6.322033898305086e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5627/6000 [3:00:22<12:12,  1.96s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5628/6000 [3:00:24<11:57,  1.93s/it]                                                     {'loss': 0.0207, 'grad_norm': 2.849424362182617, 'learning_rate': 6.305084745762713e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5628/6000 [3:00:24<11:57,  1.93s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5629/6000 [3:00:26<11:49,  1.91s/it]                                                     {'loss': 0.0383, 'grad_norm': 3.8991949558258057, 'learning_rate': 6.288135593220339e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5629/6000 [3:00:26<11:49,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5630/6000 [3:00:27<11:46,  1.91s/it]                                                     {'loss': 0.032, 'grad_norm': 2.887303352355957, 'learning_rate': 6.271186440677966e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5630/6000 [3:00:27<11:46,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5631/6000 [3:00:29<11:48,  1.92s/it]                                                     {'loss': 0.0242, 'grad_norm': 3.0356533527374268, 'learning_rate': 6.254237288135593e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5631/6000 [3:00:29<11:48,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5632/6000 [3:00:31<11:36,  1.89s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.08401372283697128, 'learning_rate': 6.237288135593221e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5632/6000 [3:00:31<11:36,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5633/6000 [3:00:33<11:28,  1.88s/it]                                                     {'loss': 0.0215, 'grad_norm': 2.344196081161499, 'learning_rate': 6.220338983050847e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5633/6000 [3:00:33<11:28,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5634/6000 [3:00:35<11:29,  1.88s/it]                                                     {'loss': 0.067, 'grad_norm': 4.518004894256592, 'learning_rate': 6.203389830508475e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5634/6000 [3:00:35<11:29,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5635/6000 [3:00:37<11:26,  1.88s/it]                                                     {'loss': 0.0245, 'grad_norm': 2.1691505908966064, 'learning_rate': 6.186440677966102e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5635/6000 [3:00:37<11:26,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5636/6000 [3:00:39<11:24,  1.88s/it]                                                     {'loss': 0.0046, 'grad_norm': 1.1206755638122559, 'learning_rate': 6.16949152542373e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5636/6000 [3:00:39<11:24,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5637/6000 [3:00:41<11:21,  1.88s/it]                                                     {'loss': 0.0106, 'grad_norm': 1.7102605104446411, 'learning_rate': 6.152542372881357e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5637/6000 [3:00:41<11:21,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5638/6000 [3:00:42<11:20,  1.88s/it]                                                     {'loss': 0.3319, 'grad_norm': 11.038237571716309, 'learning_rate': 6.135593220338983e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5638/6000 [3:00:42<11:20,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5639/6000 [3:00:44<11:27,  1.90s/it]                                                     {'loss': 0.1271, 'grad_norm': 6.206979274749756, 'learning_rate': 6.118644067796611e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5639/6000 [3:00:44<11:27,  1.90s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5640/6000 [3:00:46<11:22,  1.90s/it]                                                     {'loss': 0.2361, 'grad_norm': 9.646462440490723, 'learning_rate': 6.101694915254238e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5640/6000 [3:00:46<11:22,  1.90s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5641/6000 [3:00:48<11:19,  1.89s/it]                                                     {'loss': 0.0183, 'grad_norm': 2.5814623832702637, 'learning_rate': 6.084745762711865e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5641/6000 [3:00:48<11:19,  1.89s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5642/6000 [3:00:50<11:26,  1.92s/it]                                                     {'loss': 0.0899, 'grad_norm': 6.6490044593811035, 'learning_rate': 6.067796610169492e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5642/6000 [3:00:50<11:26,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5643/6000 [3:00:52<11:23,  1.91s/it]                                                     {'loss': 0.1003, 'grad_norm': 4.996133804321289, 'learning_rate': 6.050847457627118e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5643/6000 [3:00:52<11:23,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5644/6000 [3:00:54<11:29,  1.94s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.9515796303749084, 'learning_rate': 6.033898305084746e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5644/6000 [3:00:54<11:29,  1.94s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5645/6000 [3:00:56<11:22,  1.92s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.3039465546607971, 'learning_rate': 6.016949152542373e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5645/6000 [3:00:56<11:22,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5646/6000 [3:00:58<11:38,  1.97s/it]                                                     {'loss': 0.0159, 'grad_norm': 1.4797344207763672, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5646/6000 [3:00:58<11:38,  1.97s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5647/6000 [3:01:00<11:19,  1.93s/it]                                                     {'loss': 0.1292, 'grad_norm': 7.975875377655029, 'learning_rate': 5.983050847457627e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5647/6000 [3:01:00<11:19,  1.93s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5648/6000 [3:01:02<11:17,  1.93s/it]                                                     {'loss': 0.106, 'grad_norm': 7.527548313140869, 'learning_rate': 5.966101694915255e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5648/6000 [3:01:02<11:17,  1.93s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5649/6000 [3:01:04<11:14,  1.92s/it]                                                     {'loss': 0.0291, 'grad_norm': 2.5545616149902344, 'learning_rate': 5.949152542372882e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5649/6000 [3:01:04<11:14,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5650/6000 [3:01:06<11:08,  1.91s/it]                                                     {'loss': 0.1371, 'grad_norm': 8.101929664611816, 'learning_rate': 5.93220338983051e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5650/6000 [3:01:06<11:08,  1.91s/it][2025-11-12 00:54:21,463] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5650
[2025-11-12 00:54:21,470] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:54:21,773] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5650/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5651/6000 [3:01:08<12:35,  2.16s/it]                                                     {'loss': 0.1585, 'grad_norm': 6.712447166442871, 'learning_rate': 5.915254237288136e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5651/6000 [3:01:08<12:35,  2.16s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5652/6000 [3:01:10<11:59,  2.07s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.22527115046977997, 'learning_rate': 5.898305084745763e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5652/6000 [3:01:10<11:59,  2.07s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5653/6000 [3:01:12<11:38,  2.01s/it]                                                     {'loss': 0.1132, 'grad_norm': 9.363330841064453, 'learning_rate': 5.881355932203391e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5653/6000 [3:01:12<11:38,  2.01s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5654/6000 [3:01:14<11:20,  1.97s/it]                                                     {'loss': 0.2953, 'grad_norm': 10.80459213256836, 'learning_rate': 5.864406779661017e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5654/6000 [3:01:14<11:20,  1.97s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5655/6000 [3:01:16<11:10,  1.94s/it]                                                     {'loss': 0.2368, 'grad_norm': 14.65816879272461, 'learning_rate': 5.847457627118645e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5655/6000 [3:01:16<11:10,  1.94s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5656/6000 [3:01:18<11:04,  1.93s/it]                                                     {'loss': 0.1449, 'grad_norm': 5.817155361175537, 'learning_rate': 5.830508474576271e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5656/6000 [3:01:18<11:04,  1.93s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5657/6000 [3:01:20<11:03,  1.94s/it]                                                     {'loss': 0.0877, 'grad_norm': 6.690593719482422, 'learning_rate': 5.813559322033898e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5657/6000 [3:01:20<11:03,  1.94s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5658/6000 [3:01:21<10:54,  1.91s/it]                                                     {'loss': 0.0211, 'grad_norm': 3.6330504417419434, 'learning_rate': 5.796610169491526e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5658/6000 [3:01:21<10:54,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5659/6000 [3:01:23<10:50,  1.91s/it]                                                     {'loss': 0.1019, 'grad_norm': 6.122758865356445, 'learning_rate': 5.779661016949153e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5659/6000 [3:01:23<10:50,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5660/6000 [3:01:25<10:39,  1.88s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.5330425500869751, 'learning_rate': 5.76271186440678e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5660/6000 [3:01:25<10:39,  1.88s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5661/6000 [3:01:27<10:32,  1.87s/it]                                                     {'loss': 0.0127, 'grad_norm': 1.5424765348434448, 'learning_rate': 5.745762711864407e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5661/6000 [3:01:27<10:32,  1.87s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5662/6000 [3:01:29<10:48,  1.92s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.027735570445656776, 'learning_rate': 5.728813559322035e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5662/6000 [3:01:29<10:48,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5663/6000 [3:01:31<10:49,  1.93s/it]                                                     {'loss': 0.0832, 'grad_norm': 6.2206501960754395, 'learning_rate': 5.711864406779662e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5663/6000 [3:01:31<10:49,  1.93s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5664/6000 [3:01:33<10:46,  1.93s/it]                                                     {'loss': 0.1178, 'grad_norm': 12.21381664276123, 'learning_rate': 5.694915254237288e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5664/6000 [3:01:33<10:46,  1.93s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5665/6000 [3:01:35<10:40,  1.91s/it]                                                     {'loss': 0.034, 'grad_norm': 1.7764819860458374, 'learning_rate': 5.677966101694916e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5665/6000 [3:01:35<10:40,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5666/6000 [3:01:37<10:47,  1.94s/it]                                                     {'loss': 0.0076, 'grad_norm': 1.5398725271224976, 'learning_rate': 5.661016949152543e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5666/6000 [3:01:37<10:47,  1.94s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5667/6000 [3:01:39<10:39,  1.92s/it]                                                     {'loss': 0.1454, 'grad_norm': 7.4728217124938965, 'learning_rate': 5.64406779661017e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5667/6000 [3:01:39<10:39,  1.92s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5668/6000 [3:01:41<10:34,  1.91s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.42322906851768494, 'learning_rate': 5.627118644067797e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5668/6000 [3:01:41<10:34,  1.91s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5669/6000 [3:01:43<10:47,  1.96s/it]                                                     {'loss': 0.0104, 'grad_norm': 1.236039161682129, 'learning_rate': 5.610169491525423e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5669/6000 [3:01:43<10:47,  1.96s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5670/6000 [3:01:45<10:47,  1.96s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.4451778829097748, 'learning_rate': 5.593220338983051e-07, 'epoch': 0.94}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5670/6000 [3:01:45<10:47,  1.96s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5671/6000 [3:01:46<10:35,  1.93s/it]                                                     {'loss': 0.0741, 'grad_norm': 5.804915428161621, 'learning_rate': 5.576271186440678e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5671/6000 [3:01:46<10:35,  1.93s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5672/6000 [3:01:48<10:27,  1.91s/it]                                                     {'loss': 0.054, 'grad_norm': 8.018413543701172, 'learning_rate': 5.559322033898306e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5672/6000 [3:01:48<10:27,  1.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5673/6000 [3:01:50<10:18,  1.89s/it]                                                     {'loss': 0.002, 'grad_norm': 0.36708658933639526, 'learning_rate': 5.542372881355932e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5673/6000 [3:01:50<10:18,  1.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5674/6000 [3:01:52<10:13,  1.88s/it]                                                     {'loss': 0.0543, 'grad_norm': 5.371060371398926, 'learning_rate': 5.52542372881356e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5674/6000 [3:01:52<10:13,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5675/6000 [3:01:54<10:10,  1.88s/it]                                                     {'loss': 0.1208, 'grad_norm': 7.73747444152832, 'learning_rate': 5.508474576271187e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5675/6000 [3:01:54<10:10,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5676/6000 [3:01:56<10:05,  1.87s/it]                                                     {'loss': 0.0248, 'grad_norm': 5.158267974853516, 'learning_rate': 5.491525423728815e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5676/6000 [3:01:56<10:05,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5677/6000 [3:01:58<10:03,  1.87s/it]                                                     {'loss': 0.0556, 'grad_norm': 5.1394171714782715, 'learning_rate': 5.474576271186441e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5677/6000 [3:01:58<10:03,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5678/6000 [3:02:00<10:01,  1.87s/it]                                                     {'loss': 0.0119, 'grad_norm': 1.559443473815918, 'learning_rate': 5.457627118644068e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5678/6000 [3:02:00<10:01,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5679/6000 [3:02:01<09:56,  1.86s/it]                                                     {'loss': 0.0747, 'grad_norm': 5.552145957946777, 'learning_rate': 5.440677966101696e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5679/6000 [3:02:01<09:56,  1.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5680/6000 [3:02:03<09:53,  1.85s/it]                                                     {'loss': 0.1825, 'grad_norm': 6.3246026039123535, 'learning_rate': 5.423728813559322e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5680/6000 [3:02:03<09:53,  1.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5681/6000 [3:02:05<09:50,  1.85s/it]                                                     {'loss': 0.0838, 'grad_norm': 6.949216842651367, 'learning_rate': 5.40677966101695e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5681/6000 [3:02:05<09:50,  1.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5682/6000 [3:02:07<09:46,  1.84s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.7003984451293945, 'learning_rate': 5.389830508474576e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5682/6000 [3:02:07<09:46,  1.84s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5683/6000 [3:02:09<09:46,  1.85s/it]                                                     {'loss': 0.0164, 'grad_norm': 1.1111119985580444, 'learning_rate': 5.372881355932203e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5683/6000 [3:02:09<09:46,  1.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5684/6000 [3:02:11<09:44,  1.85s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.08748156577348709, 'learning_rate': 5.355932203389831e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5684/6000 [3:02:11<09:44,  1.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5685/6000 [3:02:12<09:45,  1.86s/it]                                                     {'loss': 0.338, 'grad_norm': 9.528903007507324, 'learning_rate': 5.338983050847458e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5685/6000 [3:02:12<09:45,  1.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5686/6000 [3:02:14<09:47,  1.87s/it]                                                     {'loss': 0.1619, 'grad_norm': 8.683013916015625, 'learning_rate': 5.322033898305085e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5686/6000 [3:02:14<09:47,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5687/6000 [3:02:16<09:44,  1.87s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.3601883351802826, 'learning_rate': 5.305084745762712e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5687/6000 [3:02:16<09:44,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5688/6000 [3:02:18<09:47,  1.88s/it]                                                     {'loss': 0.0242, 'grad_norm': 3.420483350753784, 'learning_rate': 5.28813559322034e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5688/6000 [3:02:18<09:47,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5689/6000 [3:02:20<09:43,  1.88s/it]                                                     {'loss': 0.0086, 'grad_norm': 0.6652683019638062, 'learning_rate': 5.271186440677967e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5689/6000 [3:02:20<09:43,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5690/6000 [3:02:22<09:42,  1.88s/it]                                                     {'loss': 0.034, 'grad_norm': 6.253744125366211, 'learning_rate': 5.254237288135593e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5690/6000 [3:02:22<09:42,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5691/6000 [3:02:24<09:36,  1.87s/it]                                                     {'loss': 0.0327, 'grad_norm': 3.1811397075653076, 'learning_rate': 5.237288135593221e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5691/6000 [3:02:24<09:36,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5692/6000 [3:02:26<09:37,  1.88s/it]                                                     {'loss': 0.0253, 'grad_norm': 4.0125956535339355, 'learning_rate': 5.220338983050848e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5692/6000 [3:02:26<09:37,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5693/6000 [3:02:27<09:33,  1.87s/it]                                                     {'loss': 0.0723, 'grad_norm': 7.786949634552002, 'learning_rate': 5.203389830508475e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5693/6000 [3:02:27<09:33,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5694/6000 [3:02:29<09:29,  1.86s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.15867182612419128, 'learning_rate': 5.186440677966102e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5694/6000 [3:02:29<09:29,  1.86s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5695/6000 [3:02:31<09:29,  1.87s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.6639659404754639, 'learning_rate': 5.169491525423729e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5695/6000 [3:02:31<09:29,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5696/6000 [3:02:33<09:30,  1.88s/it]                                                     {'loss': 0.0546, 'grad_norm': 5.234139919281006, 'learning_rate': 5.152542372881356e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5696/6000 [3:02:33<09:30,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5697/6000 [3:02:35<09:27,  1.87s/it]                                                     {'loss': 0.0774, 'grad_norm': 6.832383632659912, 'learning_rate': 5.135593220338983e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5697/6000 [3:02:35<09:27,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5698/6000 [3:02:37<09:28,  1.88s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.3267510235309601, 'learning_rate': 5.118644067796611e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5698/6000 [3:02:37<09:28,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5699/6000 [3:02:39<09:27,  1.89s/it]                                                     {'loss': 0.0877, 'grad_norm': 7.819953918457031, 'learning_rate': 5.101694915254238e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5699/6000 [3:02:39<09:27,  1.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5700/6000 [3:02:41<09:27,  1.89s/it]                                                     {'loss': 0.1258, 'grad_norm': 5.461811065673828, 'learning_rate': 5.084745762711865e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5700/6000 [3:02:41<09:27,  1.89s/it][2025-11-12 00:55:56,566] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5700
[2025-11-12 00:55:56,573] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:55:56,879] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5701/6000 [3:02:43<10:41,  2.15s/it]                                                     {'loss': 0.0272, 'grad_norm': 2.3125393390655518, 'learning_rate': 5.067796610169492e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5701/6000 [3:02:43<10:41,  2.15s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5702/6000 [3:02:45<10:21,  2.09s/it]                                                     {'loss': 0.0033, 'grad_norm': 0.3189552426338196, 'learning_rate': 5.05084745762712e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5702/6000 [3:02:45<10:21,  2.09s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5703/6000 [3:02:47<10:04,  2.04s/it]                                                     {'loss': 0.0612, 'grad_norm': 4.200811386108398, 'learning_rate': 5.033898305084746e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5703/6000 [3:02:47<10:04,  2.04s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5704/6000 [3:02:49<09:52,  2.00s/it]                                                     {'loss': 0.0217, 'grad_norm': 3.1386678218841553, 'learning_rate': 5.016949152542373e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5704/6000 [3:02:49<09:52,  2.00s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5705/6000 [3:02:51<09:42,  1.98s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.13130787014961243, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5705/6000 [3:02:51<09:42,  1.98s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5706/6000 [3:02:53<09:32,  1.95s/it]                                                     {'loss': 0.0248, 'grad_norm': 2.3116493225097656, 'learning_rate': 4.983050847457627e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5706/6000 [3:02:53<09:32,  1.95s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5707/6000 [3:02:55<09:22,  1.92s/it]                                                     {'loss': 0.1021, 'grad_norm': 9.223689079284668, 'learning_rate': 4.966101694915255e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5707/6000 [3:02:55<09:22,  1.92s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5708/6000 [3:02:57<09:15,  1.90s/it]                                                     {'loss': 0.0612, 'grad_norm': 4.680299758911133, 'learning_rate': 4.949152542372881e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5708/6000 [3:02:57<09:15,  1.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5709/6000 [3:02:59<09:13,  1.90s/it]                                                     {'loss': 0.4965, 'grad_norm': 26.13886260986328, 'learning_rate': 4.932203389830508e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5709/6000 [3:02:59<09:13,  1.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5710/6000 [3:03:00<09:07,  1.89s/it]                                                     {'loss': 0.0385, 'grad_norm': 2.970402240753174, 'learning_rate': 4.915254237288136e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5710/6000 [3:03:00<09:07,  1.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5711/6000 [3:03:02<09:08,  1.90s/it]                                                     {'loss': 0.102, 'grad_norm': 4.433420658111572, 'learning_rate': 4.898305084745763e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5711/6000 [3:03:02<09:08,  1.90s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5712/6000 [3:03:04<09:02,  1.88s/it]                                                     {'loss': 0.052, 'grad_norm': 4.172694683074951, 'learning_rate': 4.881355932203391e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5712/6000 [3:03:04<09:02,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5713/6000 [3:03:06<09:01,  1.89s/it]                                                     {'loss': 0.0558, 'grad_norm': 4.017349720001221, 'learning_rate': 4.864406779661017e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5713/6000 [3:03:06<09:01,  1.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5714/6000 [3:03:08<08:58,  1.88s/it]                                                     {'loss': 0.2056, 'grad_norm': 10.38646125793457, 'learning_rate': 4.847457627118645e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5714/6000 [3:03:08<08:58,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5715/6000 [3:03:10<08:56,  1.88s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.0554676353931427, 'learning_rate': 4.830508474576272e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5715/6000 [3:03:10<08:56,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5716/6000 [3:03:12<08:51,  1.87s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.25997766852378845, 'learning_rate': 4.813559322033898e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5716/6000 [3:03:12<08:51,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5717/6000 [3:03:14<08:51,  1.88s/it]                                                     {'loss': 0.0458, 'grad_norm': 2.8008551597595215, 'learning_rate': 4.796610169491526e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5717/6000 [3:03:14<08:51,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5718/6000 [3:03:16<09:00,  1.92s/it]                                                     {'loss': 0.0217, 'grad_norm': 2.703029155731201, 'learning_rate': 4.779661016949153e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5718/6000 [3:03:16<09:00,  1.92s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5719/6000 [3:03:17<08:51,  1.89s/it]                                                     {'loss': 0.0826, 'grad_norm': 6.116578102111816, 'learning_rate': 4.7627118644067797e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5719/6000 [3:03:17<08:51,  1.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5720/6000 [3:03:19<08:47,  1.88s/it]                                                     {'loss': 0.0256, 'grad_norm': 2.174511432647705, 'learning_rate': 4.745762711864407e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5720/6000 [3:03:19<08:47,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5721/6000 [3:03:21<08:45,  1.88s/it]                                                     {'loss': 0.0291, 'grad_norm': 3.9356937408447266, 'learning_rate': 4.728813559322034e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5721/6000 [3:03:21<08:45,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5722/6000 [3:03:23<08:44,  1.89s/it]                                                     {'loss': 0.0112, 'grad_norm': 1.232723355293274, 'learning_rate': 4.7118644067796615e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5722/6000 [3:03:23<08:44,  1.89s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5723/6000 [3:03:25<08:39,  1.87s/it]                                                     {'loss': 0.005, 'grad_norm': 0.6964666247367859, 'learning_rate': 4.694915254237289e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5723/6000 [3:03:25<08:39,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5724/6000 [3:03:27<08:38,  1.88s/it]                                                     {'loss': 0.0255, 'grad_norm': 3.518195629119873, 'learning_rate': 4.6779661016949154e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5724/6000 [3:03:27<08:38,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5725/6000 [3:03:29<08:37,  1.88s/it]                                                     {'loss': 0.1073, 'grad_norm': 5.883754730224609, 'learning_rate': 4.661016949152543e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5725/6000 [3:03:29<08:37,  1.88s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5726/6000 [3:03:31<08:32,  1.87s/it]                                                     {'loss': 0.038, 'grad_norm': 4.133596897125244, 'learning_rate': 4.64406779661017e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5726/6000 [3:03:31<08:32,  1.87s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5727/6000 [3:03:33<08:44,  1.92s/it]                                                     {'loss': 0.0195, 'grad_norm': 1.3157734870910645, 'learning_rate': 4.627118644067797e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5727/6000 [3:03:33<08:44,  1.92s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5728/6000 [3:03:34<08:39,  1.91s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.5291913747787476, 'learning_rate': 4.610169491525424e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5728/6000 [3:03:34<08:39,  1.91s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5729/6000 [3:03:36<08:38,  1.91s/it]                                                     {'loss': 0.0506, 'grad_norm': 5.329442501068115, 'learning_rate': 4.593220338983051e-07, 'epoch': 0.95}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5729/6000 [3:03:36<08:38,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5730/6000 [3:03:38<08:33,  1.90s/it]                                                     {'loss': 0.0875, 'grad_norm': 5.866375923156738, 'learning_rate': 4.5762711864406784e-07, 'epoch': 0.95}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5730/6000 [3:03:38<08:33,  1.90s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5731/6000 [3:03:40<08:25,  1.88s/it]                                                     {'loss': 0.0243, 'grad_norm': 2.8910610675811768, 'learning_rate': 4.559322033898306e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5731/6000 [3:03:40<08:25,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5732/6000 [3:03:42<08:25,  1.89s/it]                                                     {'loss': 0.0077, 'grad_norm': 0.8980287909507751, 'learning_rate': 4.542372881355932e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5732/6000 [3:03:42<08:25,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5733/6000 [3:03:44<08:35,  1.93s/it]                                                     {'loss': 0.001, 'grad_norm': 0.10146903991699219, 'learning_rate': 4.5254237288135597e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5733/6000 [3:03:44<08:35,  1.93s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5734/6000 [3:03:46<08:31,  1.92s/it]                                                     {'loss': 0.0069, 'grad_norm': 1.7018007040023804, 'learning_rate': 4.5084745762711866e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5734/6000 [3:03:46<08:31,  1.92s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5735/6000 [3:03:48<08:25,  1.91s/it]                                                     {'loss': 0.0649, 'grad_norm': 5.906350135803223, 'learning_rate': 4.491525423728814e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5735/6000 [3:03:48<08:25,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5736/6000 [3:03:50<08:19,  1.89s/it]                                                     {'loss': 0.0099, 'grad_norm': 1.1121068000793457, 'learning_rate': 4.4745762711864415e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5736/6000 [3:03:50<08:19,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5737/6000 [3:03:52<08:17,  1.89s/it]                                                     {'loss': 0.0269, 'grad_norm': 2.6559066772460938, 'learning_rate': 4.457627118644068e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5737/6000 [3:03:52<08:17,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5738/6000 [3:03:53<08:13,  1.88s/it]                                                     {'loss': 0.124, 'grad_norm': 5.515810966491699, 'learning_rate': 4.4406779661016953e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5738/6000 [3:03:53<08:13,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5739/6000 [3:03:55<08:10,  1.88s/it]                                                     {'loss': 0.0427, 'grad_norm': 3.6487534046173096, 'learning_rate': 4.423728813559323e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5739/6000 [3:03:55<08:10,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5740/6000 [3:03:57<08:11,  1.89s/it]                                                     {'loss': 0.0133, 'grad_norm': 1.9793199300765991, 'learning_rate': 4.4067796610169497e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5740/6000 [3:03:57<08:11,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5741/6000 [3:03:59<08:11,  1.90s/it]                                                     {'loss': 0.0707, 'grad_norm': 4.8583502769470215, 'learning_rate': 4.3898305084745766e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5741/6000 [3:03:59<08:11,  1.90s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5742/6000 [3:04:01<08:06,  1.89s/it]                                                     {'loss': 0.1095, 'grad_norm': 6.454416275024414, 'learning_rate': 4.3728813559322035e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5742/6000 [3:04:01<08:06,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5743/6000 [3:04:03<08:15,  1.93s/it]                                                     {'loss': 0.0319, 'grad_norm': 3.9528000354766846, 'learning_rate': 4.355932203389831e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5743/6000 [3:04:03<08:15,  1.93s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5744/6000 [3:04:05<08:10,  1.91s/it]                                                     {'loss': 0.0942, 'grad_norm': 7.996313571929932, 'learning_rate': 4.3389830508474584e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5744/6000 [3:04:05<08:10,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5745/6000 [3:04:07<08:00,  1.89s/it]                                                     {'loss': 0.0162, 'grad_norm': 2.3289096355438232, 'learning_rate': 4.322033898305085e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5745/6000 [3:04:07<08:00,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5746/6000 [3:04:09<07:57,  1.88s/it]                                                     {'loss': 0.1355, 'grad_norm': 5.878827095031738, 'learning_rate': 4.305084745762712e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5746/6000 [3:04:09<07:57,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5747/6000 [3:04:10<07:55,  1.88s/it]                                                     {'loss': 0.0905, 'grad_norm': 7.102425575256348, 'learning_rate': 4.288135593220339e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5747/6000 [3:04:10<07:55,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5748/6000 [3:04:13<08:06,  1.93s/it]                                                     {'loss': 0.1588, 'grad_norm': 8.617110252380371, 'learning_rate': 4.2711864406779666e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5748/6000 [3:04:13<08:06,  1.93s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5749/6000 [3:04:14<08:06,  1.94s/it]                                                     {'loss': 0.0479, 'grad_norm': 3.97155499458313, 'learning_rate': 4.254237288135594e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5749/6000 [3:04:14<08:06,  1.94s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5750/6000 [3:04:16<08:00,  1.92s/it]                                                     {'loss': 0.1894, 'grad_norm': 9.983752250671387, 'learning_rate': 4.2372881355932204e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5750/6000 [3:04:16<08:00,  1.92s/it][2025-11-12 00:57:32,275] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5750
[2025-11-12 00:57:32,282] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:57:32,585] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5750/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5751/6000 [3:04:19<09:16,  2.24s/it]                                                     {'loss': 0.0113, 'grad_norm': 1.010462760925293, 'learning_rate': 4.220338983050848e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5751/6000 [3:04:19<09:16,  2.24s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5752/6000 [3:04:21<08:49,  2.14s/it]                                                     {'loss': 0.031, 'grad_norm': 4.621431827545166, 'learning_rate': 4.2033898305084753e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5752/6000 [3:04:21<08:49,  2.14s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5753/6000 [3:04:23<08:30,  2.07s/it]                                                     {'loss': 0.1508, 'grad_norm': 7.222377300262451, 'learning_rate': 4.186440677966102e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5753/6000 [3:04:23<08:30,  2.07s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5754/6000 [3:04:25<08:15,  2.01s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.035005975514650345, 'learning_rate': 4.169491525423729e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5754/6000 [3:04:25<08:15,  2.01s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5755/6000 [3:04:27<08:05,  1.98s/it]                                                     {'loss': 0.1712, 'grad_norm': 10.379136085510254, 'learning_rate': 4.152542372881356e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5755/6000 [3:04:27<08:05,  1.98s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5756/6000 [3:04:29<07:57,  1.96s/it]                                                     {'loss': 0.0308, 'grad_norm': 4.4744157791137695, 'learning_rate': 4.1355932203389835e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5756/6000 [3:04:29<07:57,  1.96s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5757/6000 [3:04:31<07:48,  1.93s/it]                                                     {'loss': 0.0106, 'grad_norm': 1.3306387662887573, 'learning_rate': 4.118644067796611e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5757/6000 [3:04:31<07:48,  1.93s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5758/6000 [3:04:33<07:43,  1.91s/it]                                                     {'loss': 0.0147, 'grad_norm': 1.5308934450149536, 'learning_rate': 4.1016949152542373e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5758/6000 [3:04:33<07:43,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5759/6000 [3:04:34<07:36,  1.89s/it]                                                     {'loss': 0.0516, 'grad_norm': 6.294005393981934, 'learning_rate': 4.0847457627118647e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5759/6000 [3:04:34<07:36,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5760/6000 [3:04:36<07:33,  1.89s/it]                                                     {'loss': 0.0355, 'grad_norm': 5.042982578277588, 'learning_rate': 4.0677966101694916e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5760/6000 [3:04:36<07:33,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5761/6000 [3:04:38<07:30,  1.89s/it]                                                     {'loss': 0.0255, 'grad_norm': 3.73431658744812, 'learning_rate': 4.050847457627119e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5761/6000 [3:04:38<07:30,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5762/6000 [3:04:40<07:29,  1.89s/it]                                                     {'loss': 0.0706, 'grad_norm': 5.475852012634277, 'learning_rate': 4.0338983050847465e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5762/6000 [3:04:40<07:29,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5763/6000 [3:04:42<07:26,  1.88s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.0719711109995842, 'learning_rate': 4.016949152542373e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5763/6000 [3:04:42<07:26,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5764/6000 [3:04:44<07:32,  1.92s/it]                                                     {'loss': 0.0619, 'grad_norm': 2.0373523235321045, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5764/6000 [3:04:44<07:32,  1.92s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5765/6000 [3:04:46<07:29,  1.91s/it]                                                     {'loss': 0.037, 'grad_norm': 3.9466214179992676, 'learning_rate': 3.983050847457627e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5765/6000 [3:04:46<07:29,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5766/6000 [3:04:48<07:27,  1.91s/it]                                                     {'loss': 0.0055, 'grad_norm': 1.0239413976669312, 'learning_rate': 3.9661016949152547e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5766/6000 [3:04:48<07:27,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5767/6000 [3:04:50<07:20,  1.89s/it]                                                     {'loss': 0.0795, 'grad_norm': 3.5395681858062744, 'learning_rate': 3.9491525423728816e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5767/6000 [3:04:50<07:20,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5768/6000 [3:04:51<07:15,  1.88s/it]                                                     {'loss': 0.2449, 'grad_norm': 9.972972869873047, 'learning_rate': 3.9322033898305085e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5768/6000 [3:04:51<07:15,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5769/6000 [3:04:53<07:12,  1.87s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.28188198804855347, 'learning_rate': 3.915254237288136e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5769/6000 [3:04:53<07:12,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5770/6000 [3:04:55<07:10,  1.87s/it]                                                     {'loss': 0.006, 'grad_norm': 1.6651970148086548, 'learning_rate': 3.8983050847457634e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5770/6000 [3:04:55<07:10,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5771/6000 [3:04:57<07:09,  1.87s/it]                                                     {'loss': 0.0608, 'grad_norm': 4.501860618591309, 'learning_rate': 3.88135593220339e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5771/6000 [3:04:57<07:09,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5772/6000 [3:04:59<07:07,  1.87s/it]                                                     {'loss': 0.0167, 'grad_norm': 2.644517421722412, 'learning_rate': 3.864406779661017e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5772/6000 [3:04:59<07:07,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5773/6000 [3:05:01<07:04,  1.87s/it]                                                     {'loss': 0.0502, 'grad_norm': 6.094687461853027, 'learning_rate': 3.847457627118644e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5773/6000 [3:05:01<07:04,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5774/6000 [3:05:03<07:03,  1.87s/it]                                                     {'loss': 0.0769, 'grad_norm': 5.124560356140137, 'learning_rate': 3.8305084745762716e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5774/6000 [3:05:03<07:03,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5775/6000 [3:05:05<07:01,  1.87s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.6077187061309814, 'learning_rate': 3.813559322033899e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5775/6000 [3:05:05<07:01,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5776/6000 [3:05:06<07:03,  1.89s/it]                                                     {'loss': 0.054, 'grad_norm': 7.49849271774292, 'learning_rate': 3.7966101694915254e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5776/6000 [3:05:06<07:03,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5777/6000 [3:05:08<07:03,  1.90s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.01938508450984955, 'learning_rate': 3.779661016949153e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5777/6000 [3:05:08<07:03,  1.90s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5778/6000 [3:05:10<06:56,  1.88s/it]                                                     {'loss': 0.1105, 'grad_norm': 6.887157917022705, 'learning_rate': 3.76271186440678e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5778/6000 [3:05:10<06:56,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5779/6000 [3:05:12<06:52,  1.87s/it]                                                     {'loss': 0.2386, 'grad_norm': 8.906959533691406, 'learning_rate': 3.745762711864407e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5779/6000 [3:05:12<06:52,  1.87s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5780/6000 [3:05:14<06:54,  1.88s/it]                                                     {'loss': 0.0055, 'grad_norm': 1.09685480594635, 'learning_rate': 3.7288135593220347e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5780/6000 [3:05:14<06:54,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5781/6000 [3:05:16<06:52,  1.88s/it]                                                     {'loss': 0.0569, 'grad_norm': 6.752373218536377, 'learning_rate': 3.711864406779661e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5781/6000 [3:05:16<06:52,  1.88s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5782/6000 [3:05:18<06:55,  1.91s/it]                                                     {'loss': 0.1309, 'grad_norm': 9.070829391479492, 'learning_rate': 3.6949152542372885e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5782/6000 [3:05:18<06:55,  1.91s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5783/6000 [3:05:20<06:49,  1.89s/it]                                                     {'loss': 0.0622, 'grad_norm': 7.474610328674316, 'learning_rate': 3.677966101694916e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5783/6000 [3:05:20<06:49,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5784/6000 [3:05:22<06:47,  1.89s/it]                                                     {'loss': 0.0396, 'grad_norm': 5.586145877838135, 'learning_rate': 3.6610169491525423e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5784/6000 [3:05:22<06:47,  1.89s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5785/6000 [3:05:24<07:22,  2.06s/it]                                                     {'loss': 0.0627, 'grad_norm': 5.7625508308410645, 'learning_rate': 3.64406779661017e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5785/6000 [3:05:24<07:22,  2.06s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5786/6000 [3:05:26<07:05,  1.99s/it]                                                     {'loss': 0.1018, 'grad_norm': 6.6008148193359375, 'learning_rate': 3.6271186440677967e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5786/6000 [3:05:26<07:05,  1.99s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5787/6000 [3:05:28<06:57,  1.96s/it]                                                     {'loss': 0.1086, 'grad_norm': 8.448515892028809, 'learning_rate': 3.610169491525424e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5787/6000 [3:05:28<06:57,  1.96s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5788/6000 [3:05:30<06:47,  1.92s/it]                                                     {'loss': 0.0626, 'grad_norm': 2.843626022338867, 'learning_rate': 3.5932203389830516e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5788/6000 [3:05:30<06:47,  1.92s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5789/6000 [3:05:32<06:48,  1.93s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.6825540661811829, 'learning_rate': 3.576271186440678e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5789/6000 [3:05:32<06:48,  1.93s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5790/6000 [3:05:33<06:41,  1.91s/it]                                                     {'loss': 0.0603, 'grad_norm': 3.7261972427368164, 'learning_rate': 3.5593220338983054e-07, 'epoch': 0.96}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5790/6000 [3:05:33<06:41,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5791/6000 [3:05:35<06:35,  1.89s/it]                                                     {'loss': 0.0659, 'grad_norm': 5.252059459686279, 'learning_rate': 3.5423728813559323e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5791/6000 [3:05:35<06:35,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5792/6000 [3:05:37<06:32,  1.89s/it]                                                     {'loss': 0.0156, 'grad_norm': 2.3831567764282227, 'learning_rate': 3.52542372881356e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5792/6000 [3:05:37<06:32,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5793/6000 [3:05:39<06:28,  1.87s/it]                                                     {'loss': 0.2269, 'grad_norm': 8.705339431762695, 'learning_rate': 3.508474576271187e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5793/6000 [3:05:39<06:28,  1.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5794/6000 [3:05:41<06:26,  1.88s/it]                                                     {'loss': 0.0724, 'grad_norm': 8.16105842590332, 'learning_rate': 3.4915254237288136e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5794/6000 [3:05:41<06:26,  1.88s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5795/6000 [3:05:43<06:23,  1.87s/it]                                                     {'loss': 0.0721, 'grad_norm': 6.309068202972412, 'learning_rate': 3.474576271186441e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5795/6000 [3:05:43<06:23,  1.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5796/6000 [3:05:45<06:25,  1.89s/it]                                                     {'loss': 0.2349, 'grad_norm': 8.40437126159668, 'learning_rate': 3.4576271186440684e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5796/6000 [3:05:45<06:25,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5797/6000 [3:05:46<06:21,  1.88s/it]                                                     {'loss': 0.1205, 'grad_norm': 5.662743091583252, 'learning_rate': 3.440677966101695e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5797/6000 [3:05:46<06:21,  1.88s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5798/6000 [3:05:48<06:26,  1.91s/it]                                                     {'loss': 0.0961, 'grad_norm': 5.339690685272217, 'learning_rate': 3.4237288135593223e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5798/6000 [3:05:48<06:26,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5799/6000 [3:05:51<06:45,  2.02s/it]                                                     {'loss': 0.0238, 'grad_norm': 4.580870151519775, 'learning_rate': 3.406779661016949e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5799/6000 [3:05:51<06:45,  2.02s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5800/6000 [3:05:53<06:35,  1.98s/it]                                                     {'loss': 0.1682, 'grad_norm': 9.993389129638672, 'learning_rate': 3.3898305084745766e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5800/6000 [3:05:53<06:35,  1.98s/it][2025-11-12 00:59:08,521] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5800
[2025-11-12 00:59:08,528] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 00:59:08,808] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5801/6000 [3:05:55<07:16,  2.20s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.2044481635093689, 'learning_rate': 3.372881355932204e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5801/6000 [3:05:55<07:16,  2.20s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5802/6000 [3:05:57<06:56,  2.10s/it]                                                     {'loss': 0.075, 'grad_norm': 4.202841758728027, 'learning_rate': 3.3559322033898305e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5802/6000 [3:05:57<06:56,  2.10s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5803/6000 [3:05:59<06:40,  2.03s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.2811395227909088, 'learning_rate': 3.338983050847458e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5803/6000 [3:05:59<06:40,  2.03s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5804/6000 [3:06:01<06:31,  2.00s/it]                                                     {'loss': 0.0314, 'grad_norm': 4.860189437866211, 'learning_rate': 3.322033898305085e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5804/6000 [3:06:01<06:31,  2.00s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5805/6000 [3:06:03<06:21,  1.96s/it]                                                     {'loss': 0.0536, 'grad_norm': 6.557731628417969, 'learning_rate': 3.305084745762712e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5805/6000 [3:06:03<06:21,  1.96s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5806/6000 [3:06:05<06:15,  1.94s/it]                                                     {'loss': 0.0116, 'grad_norm': 1.79608154296875, 'learning_rate': 3.2881355932203397e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5806/6000 [3:06:05<06:15,  1.94s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5807/6000 [3:06:07<06:07,  1.90s/it]                                                     {'loss': 0.0235, 'grad_norm': 2.207402229309082, 'learning_rate': 3.271186440677966e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5807/6000 [3:06:07<06:07,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5808/6000 [3:06:08<06:01,  1.88s/it]                                                     {'loss': 0.0718, 'grad_norm': 6.4059739112854, 'learning_rate': 3.2542372881355935e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5808/6000 [3:06:08<06:01,  1.88s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5809/6000 [3:06:10<05:57,  1.87s/it]                                                     {'loss': 0.0125, 'grad_norm': 1.4354093074798584, 'learning_rate': 3.237288135593221e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5809/6000 [3:06:10<05:57,  1.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5810/6000 [3:06:12<05:55,  1.87s/it]                                                     {'loss': 0.0099, 'grad_norm': 1.1765294075012207, 'learning_rate': 3.2203389830508473e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5810/6000 [3:06:12<05:55,  1.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5811/6000 [3:06:14<05:53,  1.87s/it]                                                     {'loss': 0.0112, 'grad_norm': 2.1813290119171143, 'learning_rate': 3.203389830508475e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5811/6000 [3:06:14<05:53,  1.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5812/6000 [3:06:16<05:50,  1.87s/it]                                                     {'loss': 0.1317, 'grad_norm': 8.86147689819336, 'learning_rate': 3.1864406779661017e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5812/6000 [3:06:16<05:50,  1.87s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5813/6000 [3:06:18<06:04,  1.95s/it]                                                     {'loss': 0.0277, 'grad_norm': 3.887289047241211, 'learning_rate': 3.169491525423729e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5813/6000 [3:06:18<06:04,  1.95s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5814/6000 [3:06:20<05:57,  1.92s/it]                                                     {'loss': 0.0541, 'grad_norm': 3.6776463985443115, 'learning_rate': 3.1525423728813566e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5814/6000 [3:06:20<05:57,  1.92s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5815/6000 [3:06:22<05:59,  1.94s/it]                                                     {'loss': 0.0879, 'grad_norm': 6.4700140953063965, 'learning_rate': 3.135593220338983e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5815/6000 [3:06:22<05:59,  1.94s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5816/6000 [3:06:24<05:52,  1.92s/it]                                                     {'loss': 0.2605, 'grad_norm': 13.045249938964844, 'learning_rate': 3.1186440677966104e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5816/6000 [3:06:24<05:52,  1.92s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5817/6000 [3:06:26<06:06,  2.00s/it]                                                     {'loss': 0.0167, 'grad_norm': 2.4778339862823486, 'learning_rate': 3.1016949152542373e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5817/6000 [3:06:26<06:06,  2.00s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5818/6000 [3:06:28<05:57,  1.96s/it]                                                     {'loss': 0.0857, 'grad_norm': 4.504674434661865, 'learning_rate': 3.084745762711865e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5818/6000 [3:06:28<05:57,  1.96s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5819/6000 [3:06:30<05:49,  1.93s/it]                                                     {'loss': 0.1588, 'grad_norm': 8.954052925109863, 'learning_rate': 3.0677966101694917e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5819/6000 [3:06:30<05:49,  1.93s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5820/6000 [3:06:31<05:44,  1.91s/it]                                                     {'loss': 0.293, 'grad_norm': 13.430606842041016, 'learning_rate': 3.050847457627119e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5820/6000 [3:06:31<05:44,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5821/6000 [3:06:33<05:40,  1.90s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.6880304217338562, 'learning_rate': 3.033898305084746e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5821/6000 [3:06:33<05:40,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5822/6000 [3:06:35<05:40,  1.91s/it]                                                     {'loss': 0.0089, 'grad_norm': 1.9446371793746948, 'learning_rate': 3.016949152542373e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5822/6000 [3:06:35<05:40,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5823/6000 [3:06:37<05:35,  1.90s/it]                                                     {'loss': 0.0161, 'grad_norm': 2.106311082839966, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5823/6000 [3:06:37<05:35,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5824/6000 [3:06:39<05:34,  1.90s/it]                                                     {'loss': 0.0328, 'grad_norm': 5.417488098144531, 'learning_rate': 2.9830508474576273e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5824/6000 [3:06:39<05:34,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5825/6000 [3:06:41<05:31,  1.89s/it]                                                     {'loss': 0.1674, 'grad_norm': 6.797817707061768, 'learning_rate': 2.966101694915255e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5825/6000 [3:06:41<05:31,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5826/6000 [3:06:43<05:32,  1.91s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.4103502929210663, 'learning_rate': 2.9491525423728817e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5826/6000 [3:06:43<05:32,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5827/6000 [3:06:45<05:28,  1.90s/it]                                                     {'loss': 0.3607, 'grad_norm': 8.532975196838379, 'learning_rate': 2.9322033898305086e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5827/6000 [3:06:45<05:28,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5828/6000 [3:06:47<05:26,  1.90s/it]                                                     {'loss': 0.1825, 'grad_norm': 8.708399772644043, 'learning_rate': 2.9152542372881355e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5828/6000 [3:06:47<05:26,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5829/6000 [3:06:49<05:25,  1.90s/it]                                                     {'loss': 0.0773, 'grad_norm': 3.4539713859558105, 'learning_rate': 2.898305084745763e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5829/6000 [3:06:49<05:25,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5830/6000 [3:06:51<05:24,  1.91s/it]                                                     {'loss': 0.2232, 'grad_norm': 9.706632614135742, 'learning_rate': 2.88135593220339e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5830/6000 [3:06:51<05:24,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5831/6000 [3:06:52<05:21,  1.90s/it]                                                     {'loss': 0.0139, 'grad_norm': 2.4737322330474854, 'learning_rate': 2.8644067796610173e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5831/6000 [3:06:53<05:21,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5832/6000 [3:06:55<05:33,  1.99s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.4056672155857086, 'learning_rate': 2.847457627118644e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5832/6000 [3:06:55<05:33,  1.99s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5833/6000 [3:06:56<05:27,  1.96s/it]                                                     {'loss': 0.0615, 'grad_norm': 5.609696865081787, 'learning_rate': 2.8305084745762716e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5833/6000 [3:06:56<05:27,  1.96s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5834/6000 [3:06:58<05:25,  1.96s/it]                                                     {'loss': 0.0056, 'grad_norm': 1.1219085454940796, 'learning_rate': 2.8135593220338986e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5834/6000 [3:06:58<05:25,  1.96s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5835/6000 [3:07:00<05:20,  1.94s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.4191170334815979, 'learning_rate': 2.7966101694915255e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5835/6000 [3:07:00<05:20,  1.94s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5836/6000 [3:07:02<05:18,  1.94s/it]                                                     {'loss': 0.1077, 'grad_norm': 5.139525890350342, 'learning_rate': 2.779661016949153e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5836/6000 [3:07:02<05:18,  1.94s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5837/6000 [3:07:04<05:13,  1.92s/it]                                                     {'loss': 0.0988, 'grad_norm': 5.125927448272705, 'learning_rate': 2.76271186440678e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5837/6000 [3:07:04<05:13,  1.92s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5838/6000 [3:07:06<05:08,  1.91s/it]                                                     {'loss': 0.0106, 'grad_norm': 1.0889205932617188, 'learning_rate': 2.7457627118644073e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5838/6000 [3:07:06<05:08,  1.91s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5839/6000 [3:07:08<05:04,  1.89s/it]                                                     {'loss': 0.1454, 'grad_norm': 5.782828330993652, 'learning_rate': 2.728813559322034e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5839/6000 [3:07:08<05:04,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5840/6000 [3:07:10<05:02,  1.89s/it]                                                     {'loss': 0.2272, 'grad_norm': 12.578997611999512, 'learning_rate': 2.711864406779661e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5840/6000 [3:07:10<05:02,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5841/6000 [3:07:12<05:00,  1.89s/it]                                                     {'loss': 0.1365, 'grad_norm': 6.2315263748168945, 'learning_rate': 2.694915254237288e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5841/6000 [3:07:12<05:00,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5842/6000 [3:07:14<04:58,  1.89s/it]                                                     {'loss': 0.0123, 'grad_norm': 1.7654743194580078, 'learning_rate': 2.6779661016949154e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5842/6000 [3:07:14<04:58,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5843/6000 [3:07:15<04:55,  1.88s/it]                                                     {'loss': 0.0103, 'grad_norm': 1.6596933603286743, 'learning_rate': 2.6610169491525424e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5843/6000 [3:07:15<04:55,  1.88s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5844/6000 [3:07:17<04:56,  1.90s/it]                                                     {'loss': 0.0843, 'grad_norm': 5.801129341125488, 'learning_rate': 2.64406779661017e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5844/6000 [3:07:17<04:56,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5845/6000 [3:07:19<04:53,  1.90s/it]                                                     {'loss': 0.028, 'grad_norm': 3.814307689666748, 'learning_rate': 2.6271186440677967e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5845/6000 [3:07:19<04:53,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5846/6000 [3:07:21<04:49,  1.88s/it]                                                     {'loss': 0.0583, 'grad_norm': 5.701471328735352, 'learning_rate': 2.610169491525424e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5846/6000 [3:07:21<04:49,  1.88s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5847/6000 [3:07:23<04:48,  1.89s/it]                                                     {'loss': 0.0387, 'grad_norm': 6.329402923583984, 'learning_rate': 2.593220338983051e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5847/6000 [3:07:23<04:48,  1.89s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5848/6000 [3:07:25<04:48,  1.90s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.5815093517303467, 'learning_rate': 2.576271186440678e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5848/6000 [3:07:25<04:48,  1.90s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5849/6000 [3:07:28<05:18,  2.11s/it]                                                     {'loss': 0.089, 'grad_norm': 8.669753074645996, 'learning_rate': 2.5593220338983054e-07, 'epoch': 0.97}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5849/6000 [3:07:28<05:18,  2.11s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5850/6000 [3:07:29<05:06,  2.04s/it]                                                     {'loss': 0.0035, 'grad_norm': 0.7016814351081848, 'learning_rate': 2.5423728813559323e-07, 'epoch': 0.97}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5850/6000 [3:07:29<05:06,  2.04s/it][2025-11-12 01:00:45,307] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5850
[2025-11-12 01:00:45,314] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 01:00:45,628] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5850/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5851/6000 [3:07:32<05:38,  2.27s/it]                                                     {'loss': 0.0201, 'grad_norm': 2.012551784515381, 'learning_rate': 2.52542372881356e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5851/6000 [3:07:32<05:38,  2.27s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5852/6000 [3:07:34<05:18,  2.15s/it]                                                     {'loss': 0.0397, 'grad_norm': 3.7361042499542236, 'learning_rate': 2.5084745762711867e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5852/6000 [3:07:34<05:18,  2.15s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5853/6000 [3:07:36<05:05,  2.08s/it]                                                     {'loss': 0.0287, 'grad_norm': 4.577634811401367, 'learning_rate': 2.4915254237288136e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5853/6000 [3:07:36<05:05,  2.08s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5854/6000 [3:07:38<04:57,  2.04s/it]                                                     {'loss': 0.0695, 'grad_norm': 7.096688270568848, 'learning_rate': 2.4745762711864405e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5854/6000 [3:07:38<04:57,  2.04s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5855/6000 [3:07:40<04:47,  1.98s/it]                                                     {'loss': 0.0518, 'grad_norm': 6.1401190757751465, 'learning_rate': 2.457627118644068e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5855/6000 [3:07:40<04:47,  1.98s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5856/6000 [3:07:42<04:41,  1.96s/it]                                                     {'loss': 0.0695, 'grad_norm': 4.177698612213135, 'learning_rate': 2.4406779661016954e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5856/6000 [3:07:42<04:41,  1.96s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5857/6000 [3:07:44<04:37,  1.94s/it]                                                     {'loss': 0.1099, 'grad_norm': 6.755804061889648, 'learning_rate': 2.4237288135593223e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5857/6000 [3:07:44<04:37,  1.94s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5858/6000 [3:07:45<04:35,  1.94s/it]                                                     {'loss': 0.0689, 'grad_norm': 5.665092468261719, 'learning_rate': 2.406779661016949e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5858/6000 [3:07:45<04:35,  1.94s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5859/6000 [3:07:47<04:28,  1.91s/it]                                                     {'loss': 0.1622, 'grad_norm': 13.536127090454102, 'learning_rate': 2.3898305084745767e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5859/6000 [3:07:47<04:28,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5860/6000 [3:07:49<04:25,  1.90s/it]                                                     {'loss': 0.1993, 'grad_norm': 10.210416793823242, 'learning_rate': 2.3728813559322036e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5860/6000 [3:07:49<04:25,  1.90s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5861/6000 [3:07:51<04:21,  1.88s/it]                                                     {'loss': 0.087, 'grad_norm': 6.119284152984619, 'learning_rate': 2.3559322033898308e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5861/6000 [3:07:51<04:21,  1.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5862/6000 [3:07:53<04:19,  1.88s/it]                                                     {'loss': 0.0723, 'grad_norm': 3.9978675842285156, 'learning_rate': 2.3389830508474577e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5862/6000 [3:07:53<04:19,  1.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5863/6000 [3:07:55<04:17,  1.88s/it]                                                     {'loss': 0.0232, 'grad_norm': 2.983715057373047, 'learning_rate': 2.322033898305085e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5863/6000 [3:07:55<04:17,  1.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5864/6000 [3:07:57<04:14,  1.87s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.5943897366523743, 'learning_rate': 2.305084745762712e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5864/6000 [3:07:57<04:14,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5865/6000 [3:07:59<04:13,  1.87s/it]                                                     {'loss': 0.0305, 'grad_norm': 4.878766059875488, 'learning_rate': 2.2881355932203392e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5865/6000 [3:07:59<04:13,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5866/6000 [3:08:00<04:12,  1.89s/it]                                                     {'loss': 0.0325, 'grad_norm': 3.1958584785461426, 'learning_rate': 2.271186440677966e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5866/6000 [3:08:00<04:12,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5867/6000 [3:08:02<04:10,  1.88s/it]                                                     {'loss': 0.025, 'grad_norm': 1.487990140914917, 'learning_rate': 2.2542372881355933e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5867/6000 [3:08:02<04:10,  1.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5868/6000 [3:08:04<04:09,  1.89s/it]                                                     {'loss': 0.0401, 'grad_norm': 3.0562546253204346, 'learning_rate': 2.2372881355932207e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5868/6000 [3:08:04<04:09,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5869/6000 [3:08:06<04:07,  1.89s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.3098955452442169, 'learning_rate': 2.2203389830508477e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5869/6000 [3:08:06<04:07,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5870/6000 [3:08:08<04:09,  1.92s/it]                                                     {'loss': 0.0634, 'grad_norm': 3.9806103706359863, 'learning_rate': 2.2033898305084748e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5870/6000 [3:08:08<04:09,  1.92s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5871/6000 [3:08:10<04:04,  1.89s/it]                                                     {'loss': 0.0731, 'grad_norm': 7.411130905151367, 'learning_rate': 2.1864406779661017e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5871/6000 [3:08:10<04:04,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5872/6000 [3:08:12<04:01,  1.89s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.3778725266456604, 'learning_rate': 2.1694915254237292e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5872/6000 [3:08:12<04:01,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5873/6000 [3:08:14<03:57,  1.87s/it]                                                     {'loss': 0.0369, 'grad_norm': 3.290604829788208, 'learning_rate': 2.152542372881356e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5873/6000 [3:08:14<03:57,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5874/6000 [3:08:16<03:57,  1.89s/it]                                                     {'loss': 0.0598, 'grad_norm': 4.714705944061279, 'learning_rate': 2.1355932203389833e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5874/6000 [3:08:16<03:57,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5875/6000 [3:08:17<03:53,  1.87s/it]                                                     {'loss': 0.0125, 'grad_norm': 2.2113120555877686, 'learning_rate': 2.1186440677966102e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5875/6000 [3:08:17<03:53,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5876/6000 [3:08:19<03:51,  1.87s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.27690714597702026, 'learning_rate': 2.1016949152542376e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5876/6000 [3:08:19<03:51,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5877/6000 [3:08:21<03:50,  1.88s/it]                                                     {'loss': 0.0051, 'grad_norm': 0.6414639353752136, 'learning_rate': 2.0847457627118646e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5877/6000 [3:08:21<03:50,  1.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5878/6000 [3:08:23<03:47,  1.87s/it]                                                     {'loss': 0.1011, 'grad_norm': 9.491424560546875, 'learning_rate': 2.0677966101694917e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5878/6000 [3:08:23<03:47,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5879/6000 [3:08:25<03:45,  1.86s/it]                                                     {'loss': 0.0126, 'grad_norm': 2.598982810974121, 'learning_rate': 2.0508474576271186e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5879/6000 [3:08:25<03:45,  1.86s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5880/6000 [3:08:27<03:45,  1.88s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.40636923909187317, 'learning_rate': 2.0338983050847458e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5880/6000 [3:08:27<03:45,  1.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5881/6000 [3:08:29<03:47,  1.91s/it]                                                     {'loss': 0.0956, 'grad_norm': 5.997983932495117, 'learning_rate': 2.0169491525423733e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5881/6000 [3:08:29<03:47,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5882/6000 [3:08:31<03:44,  1.90s/it]                                                     {'loss': 0.0072, 'grad_norm': 1.1097644567489624, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5882/6000 [3:08:31<03:44,  1.90s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5883/6000 [3:08:33<03:41,  1.89s/it]                                                     {'loss': 0.0717, 'grad_norm': 7.060918807983398, 'learning_rate': 1.9830508474576274e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5883/6000 [3:08:33<03:41,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5884/6000 [3:08:34<03:39,  1.89s/it]                                                     {'loss': 0.0876, 'grad_norm': 4.587976455688477, 'learning_rate': 1.9661016949152543e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5884/6000 [3:08:34<03:39,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5885/6000 [3:08:36<03:35,  1.87s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.35054919123649597, 'learning_rate': 1.9491525423728817e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5885/6000 [3:08:36<03:35,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5886/6000 [3:08:38<03:33,  1.87s/it]                                                     {'loss': 0.0059, 'grad_norm': 1.9180892705917358, 'learning_rate': 1.9322033898305086e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5886/6000 [3:08:38<03:33,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5887/6000 [3:08:40<03:31,  1.87s/it]                                                     {'loss': 0.003, 'grad_norm': 0.5480654239654541, 'learning_rate': 1.9152542372881358e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5887/6000 [3:08:40<03:31,  1.87s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5888/6000 [3:08:42<03:35,  1.93s/it]                                                     {'loss': 0.0308, 'grad_norm': 7.347724437713623, 'learning_rate': 1.8983050847457627e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5888/6000 [3:08:42<03:35,  1.93s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5889/6000 [3:08:44<03:37,  1.96s/it]                                                     {'loss': 0.016, 'grad_norm': 1.412981629371643, 'learning_rate': 1.88135593220339e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5889/6000 [3:08:44<03:37,  1.96s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5890/6000 [3:08:46<03:31,  1.92s/it]                                                     {'loss': 0.0179, 'grad_norm': 2.3427481651306152, 'learning_rate': 1.8644067796610173e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5890/6000 [3:08:46<03:31,  1.92s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5891/6000 [3:08:48<03:30,  1.93s/it]                                                     {'loss': 0.0047, 'grad_norm': 0.7225692868232727, 'learning_rate': 1.8474576271186442e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5891/6000 [3:08:48<03:30,  1.93s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5892/6000 [3:08:50<03:26,  1.91s/it]                                                     {'loss': 0.02, 'grad_norm': 1.625311255455017, 'learning_rate': 1.8305084745762712e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5892/6000 [3:08:50<03:26,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5893/6000 [3:08:52<03:22,  1.89s/it]                                                     {'loss': 0.1529, 'grad_norm': 9.173828125, 'learning_rate': 1.8135593220338983e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5893/6000 [3:08:52<03:22,  1.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5894/6000 [3:08:54<03:22,  1.91s/it]                                                     {'loss': 0.0177, 'grad_norm': 3.785874605178833, 'learning_rate': 1.7966101694915258e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5894/6000 [3:08:54<03:22,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5895/6000 [3:08:55<03:20,  1.91s/it]                                                     {'loss': 0.1514, 'grad_norm': 8.741083145141602, 'learning_rate': 1.7796610169491527e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5895/6000 [3:08:55<03:20,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5896/6000 [3:08:57<03:18,  1.91s/it]                                                     {'loss': 0.2103, 'grad_norm': 8.90946102142334, 'learning_rate': 1.76271186440678e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5896/6000 [3:08:57<03:18,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5897/6000 [3:08:59<03:16,  1.91s/it]                                                     {'loss': 0.0601, 'grad_norm': 8.673227310180664, 'learning_rate': 1.7457627118644068e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5897/6000 [3:08:59<03:16,  1.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5898/6000 [3:09:01<03:24,  2.01s/it]                                                     {'loss': 0.0087, 'grad_norm': 1.660739779472351, 'learning_rate': 1.7288135593220342e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5898/6000 [3:09:01<03:24,  2.01s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5899/6000 [3:09:03<03:17,  1.96s/it]                                                     {'loss': 0.0458, 'grad_norm': 5.833209991455078, 'learning_rate': 1.7118644067796611e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5899/6000 [3:09:03<03:17,  1.96s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5900/6000 [3:09:05<03:12,  1.93s/it]                                                     {'loss': 0.0767, 'grad_norm': 6.252801895141602, 'learning_rate': 1.6949152542372883e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5900/6000 [3:09:05<03:12,  1.93s/it][2025-11-12 01:02:21,078] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5900
[2025-11-12 01:02:21,085] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 01:02:21,371] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5901/6000 [3:09:08<03:33,  2.16s/it]                                                     {'loss': 0.131, 'grad_norm': 7.690262794494629, 'learning_rate': 1.6779661016949152e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5901/6000 [3:09:08<03:33,  2.16s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5902/6000 [3:09:10<03:23,  2.08s/it]                                                     {'loss': 0.0084, 'grad_norm': 1.0072838068008423, 'learning_rate': 1.6610169491525424e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5902/6000 [3:09:10<03:23,  2.08s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5903/6000 [3:09:12<03:17,  2.04s/it]                                                     {'loss': 0.0076, 'grad_norm': 1.2479130029678345, 'learning_rate': 1.6440677966101698e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5903/6000 [3:09:12<03:17,  2.04s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5904/6000 [3:09:14<03:10,  1.99s/it]                                                     {'loss': 0.0813, 'grad_norm': 7.775977611541748, 'learning_rate': 1.6271186440677968e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5904/6000 [3:09:14<03:10,  1.99s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5905/6000 [3:09:16<03:09,  1.99s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.08393391966819763, 'learning_rate': 1.6101694915254237e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5905/6000 [3:09:16<03:09,  1.99s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5906/6000 [3:09:18<03:08,  2.01s/it]                                                     {'loss': 0.022, 'grad_norm': 4.09233283996582, 'learning_rate': 1.5932203389830509e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5906/6000 [3:09:18<03:08,  2.01s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5907/6000 [3:09:20<03:03,  1.97s/it]                                                     {'loss': 0.1713, 'grad_norm': 8.791831970214844, 'learning_rate': 1.5762711864406783e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5907/6000 [3:09:20<03:03,  1.97s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5908/6000 [3:09:21<02:57,  1.93s/it]                                                     {'loss': 0.0515, 'grad_norm': 7.534584999084473, 'learning_rate': 1.5593220338983052e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5908/6000 [3:09:21<02:57,  1.93s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5909/6000 [3:09:23<02:56,  1.94s/it]                                                     {'loss': 0.0435, 'grad_norm': 4.353384017944336, 'learning_rate': 1.5423728813559324e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5909/6000 [3:09:23<02:56,  1.94s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5910/6000 [3:09:25<02:52,  1.91s/it]                                                     {'loss': 0.0349, 'grad_norm': 3.9973855018615723, 'learning_rate': 1.5254237288135596e-07, 'epoch': 0.98}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5910/6000 [3:09:25<02:52,  1.91s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5911/6000 [3:09:27<02:53,  1.95s/it]                                                     {'loss': 0.3195, 'grad_norm': 10.55443000793457, 'learning_rate': 1.5084745762711865e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5911/6000 [3:09:27<02:53,  1.95s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5912/6000 [3:09:29<02:48,  1.92s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.14187972247600555, 'learning_rate': 1.4915254237288137e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5912/6000 [3:09:29<02:48,  1.92s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5913/6000 [3:09:31<02:46,  1.91s/it]                                                     {'loss': 0.0095, 'grad_norm': 1.0594308376312256, 'learning_rate': 1.4745762711864408e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5913/6000 [3:09:31<02:46,  1.91s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5914/6000 [3:09:33<02:43,  1.90s/it]                                                     {'loss': 0.0077, 'grad_norm': 1.5470901727676392, 'learning_rate': 1.4576271186440677e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5914/6000 [3:09:33<02:43,  1.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5915/6000 [3:09:35<02:41,  1.90s/it]                                                     {'loss': 0.0245, 'grad_norm': 2.5675370693206787, 'learning_rate': 1.440677966101695e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5915/6000 [3:09:35<02:41,  1.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5916/6000 [3:09:37<02:38,  1.89s/it]                                                     {'loss': 0.0185, 'grad_norm': 2.8762669563293457, 'learning_rate': 1.423728813559322e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5916/6000 [3:09:37<02:38,  1.89s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5917/6000 [3:09:38<02:37,  1.89s/it]                                                     {'loss': 0.0983, 'grad_norm': 5.873301982879639, 'learning_rate': 1.4067796610169493e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5917/6000 [3:09:38<02:37,  1.89s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5918/6000 [3:09:40<02:34,  1.88s/it]                                                     {'loss': 0.0349, 'grad_norm': 2.967836856842041, 'learning_rate': 1.3898305084745765e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5918/6000 [3:09:40<02:34,  1.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5919/6000 [3:09:42<02:32,  1.88s/it]                                                     {'loss': 0.0283, 'grad_norm': 4.594417095184326, 'learning_rate': 1.3728813559322036e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5919/6000 [3:09:42<02:32,  1.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5920/6000 [3:09:44<02:30,  1.88s/it]                                                     {'loss': 0.042, 'grad_norm': 1.9944736957550049, 'learning_rate': 1.3559322033898305e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5920/6000 [3:09:44<02:30,  1.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5921/6000 [3:09:46<02:36,  1.98s/it]                                                     {'loss': 0.0143, 'grad_norm': 1.7527470588684082, 'learning_rate': 1.3389830508474577e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5921/6000 [3:09:46<02:36,  1.98s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5922/6000 [3:09:48<02:32,  1.95s/it]                                                     {'loss': 0.2357, 'grad_norm': 8.0341796875, 'learning_rate': 1.322033898305085e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5922/6000 [3:09:48<02:32,  1.95s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5923/6000 [3:09:50<02:28,  1.93s/it]                                                     {'loss': 0.0089, 'grad_norm': 1.4843902587890625, 'learning_rate': 1.305084745762712e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5923/6000 [3:09:50<02:28,  1.93s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5924/6000 [3:09:52<02:24,  1.90s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.20065763592720032, 'learning_rate': 1.288135593220339e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5924/6000 [3:09:52<02:24,  1.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5925/6000 [3:09:54<02:21,  1.89s/it]                                                     {'loss': 0.0475, 'grad_norm': 5.617181301116943, 'learning_rate': 1.2711864406779662e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5925/6000 [3:09:54<02:21,  1.89s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5926/6000 [3:09:56<02:22,  1.92s/it]                                                     {'loss': 0.077, 'grad_norm': 6.5036821365356445, 'learning_rate': 1.2542372881355933e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5926/6000 [3:09:56<02:22,  1.92s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5927/6000 [3:09:58<02:18,  1.90s/it]                                                     {'loss': 0.0036, 'grad_norm': 0.46916458010673523, 'learning_rate': 1.2372881355932203e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5927/6000 [3:09:58<02:18,  1.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5928/6000 [3:09:59<02:16,  1.90s/it]                                                     {'loss': 0.038, 'grad_norm': 5.046529769897461, 'learning_rate': 1.2203389830508477e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5928/6000 [3:09:59<02:16,  1.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5929/6000 [3:10:01<02:14,  1.89s/it]                                                     {'loss': 0.123, 'grad_norm': 13.557126998901367, 'learning_rate': 1.2033898305084746e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5929/6000 [3:10:01<02:14,  1.89s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5930/6000 [3:10:03<02:14,  1.92s/it]                                                     {'loss': 0.0071, 'grad_norm': 1.0265358686447144, 'learning_rate': 1.1864406779661018e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5930/6000 [3:10:03<02:14,  1.92s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5931/6000 [3:10:05<02:11,  1.91s/it]                                                     {'loss': 0.0946, 'grad_norm': 8.031167030334473, 'learning_rate': 1.1694915254237288e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5931/6000 [3:10:05<02:11,  1.91s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5932/6000 [3:10:07<02:08,  1.89s/it]                                                     {'loss': 0.1327, 'grad_norm': 7.937222003936768, 'learning_rate': 1.152542372881356e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5932/6000 [3:10:07<02:08,  1.89s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5933/6000 [3:10:09<02:08,  1.91s/it]                                                     {'loss': 0.0087, 'grad_norm': 1.0700194835662842, 'learning_rate': 1.135593220338983e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5933/6000 [3:10:09<02:08,  1.91s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5934/6000 [3:10:11<02:05,  1.91s/it]                                                     {'loss': 0.0351, 'grad_norm': 3.318105697631836, 'learning_rate': 1.1186440677966104e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5934/6000 [3:10:11<02:05,  1.91s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5935/6000 [3:10:13<02:04,  1.92s/it]                                                     {'loss': 0.0123, 'grad_norm': 2.2271728515625, 'learning_rate': 1.1016949152542374e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5935/6000 [3:10:13<02:04,  1.92s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5936/6000 [3:10:15<02:02,  1.91s/it]                                                     {'loss': 0.0181, 'grad_norm': 1.9624779224395752, 'learning_rate': 1.0847457627118646e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5936/6000 [3:10:15<02:02,  1.91s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5937/6000 [3:10:17<01:58,  1.89s/it]                                                     {'loss': 0.0545, 'grad_norm': 5.449754238128662, 'learning_rate': 1.0677966101694916e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5937/6000 [3:10:17<01:58,  1.89s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5938/6000 [3:10:18<01:56,  1.88s/it]                                                     {'loss': 0.0058, 'grad_norm': 1.039380431175232, 'learning_rate': 1.0508474576271188e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5938/6000 [3:10:18<01:56,  1.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5939/6000 [3:10:20<01:54,  1.87s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.4754995107650757, 'learning_rate': 1.0338983050847459e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5939/6000 [3:10:20<01:54,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5940/6000 [3:10:22<01:52,  1.87s/it]                                                     {'loss': 0.0204, 'grad_norm': 2.771055221557617, 'learning_rate': 1.0169491525423729e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5940/6000 [3:10:22<01:52,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5941/6000 [3:10:24<01:50,  1.87s/it]                                                     {'loss': 0.0587, 'grad_norm': 3.7831344604492188, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5941/6000 [3:10:24<01:50,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5942/6000 [3:10:26<01:48,  1.87s/it]                                                     {'loss': 0.1663, 'grad_norm': 6.268971920013428, 'learning_rate': 9.830508474576271e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5942/6000 [3:10:26<01:48,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5943/6000 [3:10:28<01:46,  1.87s/it]                                                     {'loss': 0.0201, 'grad_norm': 3.2619576454162598, 'learning_rate': 9.661016949152543e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5943/6000 [3:10:28<01:46,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5944/6000 [3:10:30<01:44,  1.86s/it]                                                     {'loss': 0.1003, 'grad_norm': 6.60591983795166, 'learning_rate': 9.491525423728814e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5944/6000 [3:10:30<01:44,  1.86s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5945/6000 [3:10:31<01:42,  1.86s/it]                                                     {'loss': 0.0338, 'grad_norm': 4.2866530418396, 'learning_rate': 9.322033898305087e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5945/6000 [3:10:31<01:42,  1.86s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5946/6000 [3:10:33<01:40,  1.86s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.3202570676803589, 'learning_rate': 9.152542372881356e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5946/6000 [3:10:33<01:40,  1.86s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5947/6000 [3:10:35<01:38,  1.86s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.8725008964538574, 'learning_rate': 8.983050847457629e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5947/6000 [3:10:35<01:38,  1.86s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5948/6000 [3:10:37<01:37,  1.87s/it]                                                     {'loss': 0.0328, 'grad_norm': 4.079476833343506, 'learning_rate': 8.8135593220339e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5948/6000 [3:10:37<01:37,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5949/6000 [3:10:39<01:41,  1.99s/it]                                                     {'loss': 0.0736, 'grad_norm': 6.563019275665283, 'learning_rate': 8.644067796610171e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5949/6000 [3:10:39<01:41,  1.99s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5950/6000 [3:10:41<01:37,  1.95s/it]                                                     {'loss': 0.0315, 'grad_norm': 5.343976020812988, 'learning_rate': 8.474576271186442e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5950/6000 [3:10:41<01:37,  1.95s/it][2025-11-12 01:03:57,133] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5950
[2025-11-12 01:03:57,140] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 01:03:57,424] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-5950/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5951/6000 [3:10:44<01:47,  2.19s/it]                                                     {'loss': 0.0885, 'grad_norm': 7.283448219299316, 'learning_rate': 8.305084745762712e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5951/6000 [3:10:44<01:47,  2.19s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5952/6000 [3:10:46<01:41,  2.10s/it]                                                     {'loss': 0.1553, 'grad_norm': 8.947408676147461, 'learning_rate': 8.135593220338984e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5952/6000 [3:10:46<01:41,  2.10s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5953/6000 [3:10:48<01:35,  2.04s/it]                                                     {'loss': 0.1003, 'grad_norm': 6.60020637512207, 'learning_rate': 7.966101694915254e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5953/6000 [3:10:48<01:35,  2.04s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5954/6000 [3:10:50<01:32,  2.01s/it]                                                     {'loss': 0.0953, 'grad_norm': 5.550606727600098, 'learning_rate': 7.796610169491526e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5954/6000 [3:10:50<01:32,  2.01s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5955/6000 [3:10:52<01:28,  1.96s/it]                                                     {'loss': 0.0044, 'grad_norm': 0.7747067213058472, 'learning_rate': 7.627118644067798e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5955/6000 [3:10:52<01:28,  1.96s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5956/6000 [3:10:54<01:34,  2.15s/it]                                                     {'loss': 0.39, 'grad_norm': 10.336267471313477, 'learning_rate': 7.457627118644068e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5956/6000 [3:10:54<01:34,  2.15s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5957/6000 [3:10:56<01:29,  2.08s/it]                                                     {'loss': 0.0227, 'grad_norm': 4.340968608856201, 'learning_rate': 7.288135593220339e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5957/6000 [3:10:56<01:29,  2.08s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5958/6000 [3:10:58<01:24,  2.02s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.4041827917098999, 'learning_rate': 7.11864406779661e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5958/6000 [3:10:58<01:24,  2.02s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5959/6000 [3:11:00<01:20,  1.97s/it]                                                     {'loss': 0.0101, 'grad_norm': 0.6995366215705872, 'learning_rate': 6.949152542372882e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5959/6000 [3:11:00<01:20,  1.97s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5960/6000 [3:11:02<01:17,  1.95s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.5964917540550232, 'learning_rate': 6.779661016949153e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5960/6000 [3:11:02<01:17,  1.95s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5961/6000 [3:11:04<01:16,  1.95s/it]                                                     {'loss': 0.0355, 'grad_norm': 4.185521602630615, 'learning_rate': 6.610169491525425e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5961/6000 [3:11:04<01:16,  1.95s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5962/6000 [3:11:06<01:13,  1.94s/it]                                                     {'loss': 0.1604, 'grad_norm': 10.439375877380371, 'learning_rate': 6.440677966101695e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5962/6000 [3:11:06<01:13,  1.94s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5963/6000 [3:11:07<01:10,  1.92s/it]                                                     {'loss': 0.2284, 'grad_norm': 7.354689121246338, 'learning_rate': 6.271186440677967e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5963/6000 [3:11:07<01:10,  1.92s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5964/6000 [3:11:09<01:08,  1.90s/it]                                                     {'loss': 0.0377, 'grad_norm': 4.484203338623047, 'learning_rate': 6.101694915254239e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5964/6000 [3:11:09<01:08,  1.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5965/6000 [3:11:11<01:05,  1.87s/it]                                                     {'loss': 0.0273, 'grad_norm': 2.636878728866577, 'learning_rate': 5.932203389830509e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5965/6000 [3:11:11<01:05,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5966/6000 [3:11:13<01:04,  1.88s/it]                                                     {'loss': 0.0528, 'grad_norm': 6.300629138946533, 'learning_rate': 5.76271186440678e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5966/6000 [3:11:13<01:04,  1.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5967/6000 [3:11:15<01:01,  1.87s/it]                                                     {'loss': 0.0924, 'grad_norm': 6.376865386962891, 'learning_rate': 5.593220338983052e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5967/6000 [3:11:15<01:01,  1.87s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5968/6000 [3:11:17<01:00,  1.88s/it]                                                     {'loss': 0.0591, 'grad_norm': 4.849377632141113, 'learning_rate': 5.423728813559323e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5968/6000 [3:11:17<01:00,  1.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5969/6000 [3:11:19<00:58,  1.89s/it]                                                     {'loss': 0.0909, 'grad_norm': 8.109339714050293, 'learning_rate': 5.254237288135594e-08, 'epoch': 0.99}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5969/6000 [3:11:19<00:58,  1.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5970/6000 [3:11:21<00:56,  1.88s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.09071849286556244, 'learning_rate': 5.0847457627118645e-08, 'epoch': 0.99}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5970/6000 [3:11:21<00:56,  1.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5971/6000 [3:11:22<00:54,  1.88s/it]                                                     {'loss': 0.0272, 'grad_norm': 3.7580673694610596, 'learning_rate': 4.9152542372881357e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5971/6000 [3:11:22<00:54,  1.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5972/6000 [3:11:24<00:52,  1.86s/it]                                                     {'loss': 0.0757, 'grad_norm': 5.671963214874268, 'learning_rate': 4.745762711864407e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5972/6000 [3:11:24<00:52,  1.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5973/6000 [3:11:26<00:50,  1.87s/it]                                                     {'loss': 0.0177, 'grad_norm': 2.267897367477417, 'learning_rate': 4.576271186440678e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5973/6000 [3:11:26<00:50,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5974/6000 [3:11:28<00:48,  1.87s/it]                                                     {'loss': 0.0613, 'grad_norm': 3.5579679012298584, 'learning_rate': 4.40677966101695e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5974/6000 [3:11:28<00:48,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5975/6000 [3:11:30<00:46,  1.87s/it]                                                     {'loss': 0.1816, 'grad_norm': 5.9953083992004395, 'learning_rate': 4.237288135593221e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5975/6000 [3:11:30<00:46,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5976/6000 [3:11:32<00:44,  1.87s/it]                                                     {'loss': 0.018, 'grad_norm': 1.8868725299835205, 'learning_rate': 4.067796610169492e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5976/6000 [3:11:32<00:44,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5977/6000 [3:11:34<00:42,  1.87s/it]                                                     {'loss': 0.0329, 'grad_norm': 2.76863694190979, 'learning_rate': 3.898305084745763e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5977/6000 [3:11:34<00:42,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5978/6000 [3:11:35<00:41,  1.87s/it]                                                     {'loss': 0.0532, 'grad_norm': 4.444514274597168, 'learning_rate': 3.728813559322034e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5978/6000 [3:11:35<00:41,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5979/6000 [3:11:37<00:39,  1.87s/it]                                                     {'loss': 0.0301, 'grad_norm': 3.459817409515381, 'learning_rate': 3.559322033898305e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5979/6000 [3:11:37<00:39,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5980/6000 [3:11:39<00:37,  1.87s/it]                                                     {'loss': 0.0699, 'grad_norm': 3.484498977661133, 'learning_rate': 3.3898305084745764e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5980/6000 [3:11:39<00:37,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5981/6000 [3:11:41<00:35,  1.87s/it]                                                     {'loss': 0.0021, 'grad_norm': 0.2324395328760147, 'learning_rate': 3.2203389830508475e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5981/6000 [3:11:41<00:35,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5982/6000 [3:11:43<00:33,  1.85s/it]                                                     {'loss': 0.3191, 'grad_norm': 11.047344207763672, 'learning_rate': 3.050847457627119e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5982/6000 [3:11:43<00:33,  1.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5983/6000 [3:11:45<00:31,  1.86s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.3539547026157379, 'learning_rate': 2.88135593220339e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5983/6000 [3:11:45<00:31,  1.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5984/6000 [3:11:47<00:29,  1.85s/it]                                                     {'loss': 0.0101, 'grad_norm': 1.1472339630126953, 'learning_rate': 2.7118644067796615e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5984/6000 [3:11:47<00:29,  1.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5985/6000 [3:11:48<00:27,  1.86s/it]                                                     {'loss': 0.0031, 'grad_norm': 0.8436347246170044, 'learning_rate': 2.5423728813559323e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5985/6000 [3:11:48<00:27,  1.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5986/6000 [3:11:50<00:26,  1.88s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.08509824424982071, 'learning_rate': 2.3728813559322034e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5986/6000 [3:11:50<00:26,  1.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5987/6000 [3:11:53<00:25,  1.96s/it]                                                     {'loss': 0.0596, 'grad_norm': 6.598342418670654, 'learning_rate': 2.203389830508475e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5987/6000 [3:11:53<00:25,  1.96s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5988/6000 [3:11:54<00:23,  1.94s/it]                                                     {'loss': 0.133, 'grad_norm': 10.612164497375488, 'learning_rate': 2.033898305084746e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5988/6000 [3:11:54<00:23,  1.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5989/6000 [3:11:56<00:21,  1.92s/it]                                                     {'loss': 0.1404, 'grad_norm': 7.112832546234131, 'learning_rate': 1.864406779661017e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5989/6000 [3:11:56<00:21,  1.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5990/6000 [3:11:58<00:18,  1.89s/it]                                                     {'loss': 0.0258, 'grad_norm': 2.820401430130005, 'learning_rate': 1.6949152542372882e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5990/6000 [3:11:58<00:18,  1.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5991/6000 [3:12:00<00:17,  1.90s/it]                                                     {'loss': 0.0077, 'grad_norm': 1.2956589460372925, 'learning_rate': 1.5254237288135596e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5991/6000 [3:12:00<00:17,  1.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5992/6000 [3:12:02<00:15,  1.89s/it]                                                     {'loss': 0.1103, 'grad_norm': 7.463004112243652, 'learning_rate': 1.3559322033898307e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5992/6000 [3:12:02<00:15,  1.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5993/6000 [3:12:04<00:13,  1.94s/it]                                                     {'loss': 0.0272, 'grad_norm': 3.410569190979004, 'learning_rate': 1.1864406779661017e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5993/6000 [3:12:04<00:13,  1.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5994/6000 [3:12:06<00:11,  1.91s/it]                                                     {'loss': 0.1101, 'grad_norm': 6.837104320526123, 'learning_rate': 1.016949152542373e-08, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5994/6000 [3:12:06<00:11,  1.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5995/6000 [3:12:08<00:09,  1.90s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.6500065922737122, 'learning_rate': 8.474576271186441e-09, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5995/6000 [3:12:08<00:09,  1.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5996/6000 [3:12:10<00:07,  1.89s/it]                                                     {'loss': 0.0537, 'grad_norm': 1.8913180828094482, 'learning_rate': 6.779661016949154e-09, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5996/6000 [3:12:10<00:07,  1.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5997/6000 [3:12:11<00:05,  1.88s/it]                                                     {'loss': 0.0729, 'grad_norm': 7.040771007537842, 'learning_rate': 5.084745762711865e-09, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5997/6000 [3:12:11<00:05,  1.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5998/6000 [3:12:13<00:03,  1.87s/it]                                                     {'loss': 0.0436, 'grad_norm': 6.283822059631348, 'learning_rate': 3.389830508474577e-09, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5998/6000 [3:12:13<00:03,  1.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5999/6000 [3:12:15<00:01,  1.98s/it]                                                     {'loss': 0.0787, 'grad_norm': 8.941612243652344, 'learning_rate': 1.6949152542372884e-09, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5999/6000 [3:12:15<00:01,  1.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6000/6000 [3:12:17<00:00,  1.97s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.15535947680473328, 'learning_rate': 0.0, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6000/6000 [3:12:17<00:00,  1.97s/it][2025-11-12 01:05:33,381] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-6000
[2025-11-12 01:05:33,382] INFO [src.trainer:618] 

Training completed. Do not forget to share your model on huggingface.co/models =)


[2025-11-12 01:05:33,388] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 01:05:33,675] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/checkpoint-6000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[2025-11-12 01:05:34,241] INFO [src.trainer:618] 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 11538.8401, 'train_samples_per_second': 16.639, 'train_steps_per_second': 0.52, 'train_loss': 0.1920615262938712, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6000/6000 [3:12:18<00:00,  1.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6000/6000 [3:12:18<00:00,  1.92s/it]
[2025-11-12 01:05:34,331] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct
[2025-11-12 01:05:34,343] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-12 01:05:34,610] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33m11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/public/exps/train/11Nov_tail_grad_only-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251111_215300-tnijsxvm/logs[0m
Job finished at: Wed Nov 12 01:05:38 CET 2025
