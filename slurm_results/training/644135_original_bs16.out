==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name original-bs16-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token False --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/train.log
W1019 23:36:36.655000 125331774928704 torch/distributed/run.py:779] 
W1019 23:36:36.655000 125331774928704 torch/distributed/run.py:779] *****************************************
W1019 23:36:36.655000 125331774928704 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1019 23:36:36.655000 125331774928704 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-19 23:36:45,239] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.14it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.98it/s]
wandb: setting up run bjfxbo46
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251019_233645-bjfxbo46
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run original-bs16-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/bjfxbo46
[2025-10-19 23:36:46,742] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.20it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.05it/s]
[2025-10-19 23:36:47,381] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-10-19 23:36:56,326] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-19 23:36:57,561] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-19 23:36:57,561] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-19 23:37:01,972] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-19 23:37:01,973] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-19 23:37:02,819] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-19 23:37:02,820] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-19 23:37:02,820] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-19 23:37:02,821] INFO [src.utils:19] ==================================================
[2025-10-19 23:37:02,822] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-19 23:37:02,822] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-19 23:37:02,823] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-19 23:37:02,823] INFO [src.utils:19] ==================================================
[2025-10-19 23:37:04,632] INFO [src.trainer:342] ***** Running training *****
[2025-10-19 23:37:04,632] INFO [src.trainer:342] ***** Running training *****
[2025-10-19 23:37:04,632] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-19 23:37:04,633] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-19 23:37:04,633] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-19 23:37:04,633] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-19 23:37:04,633] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-19 23:37:04,633] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-19 23:37:04,633] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-19 23:37:04,633] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-19 23:37:04,634] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-19 23:37:04,634] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-19 23:37:04,634] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-19 23:37:04,635] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-19 23:37:04,644] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-19 23:37:04,646] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W1019 23:37:08.231421534 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1019 23:37:08.251711620 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/6000 [00:04<7:54:33,  4.75s/it]                                                  {'loss': 20.6106, 'grad_norm': 1371.3572998046875, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<7:54:33,  4.75s/it]  0%|          | 2/6000 [00:08<6:28:44,  3.89s/it]                                                  {'loss': 17.9095, 'grad_norm': 2158.434814453125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:08<6:28:44,  3.89s/it]  0%|          | 3/6000 [00:11<6:06:36,  3.67s/it]                                                  {'loss': 15.6517, 'grad_norm': 2082.146728515625, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:11<6:06:36,  3.67s/it]  0%|          | 4/6000 [00:14<5:57:48,  3.58s/it]                                                  {'loss': 16.4366, 'grad_norm': 2164.4111328125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:14<5:57:48,  3.58s/it]  0%|          | 5/6000 [00:18<5:49:12,  3.49s/it]                                                  {'loss': 16.469, 'grad_norm': 1937.446044921875, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:18<5:49:12,  3.49s/it]  0%|          | 6/6000 [00:21<5:43:17,  3.44s/it]                                                  {'loss': 17.5447, 'grad_norm': 1592.871826171875, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:21<5:43:17,  3.44s/it]  0%|          | 7/6000 [00:24<5:38:50,  3.39s/it]                                                  {'loss': 16.1889, 'grad_norm': 2279.82421875, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:24<5:38:50,  3.39s/it]  0%|          | 8/6000 [00:28<5:34:30,  3.35s/it]                                                  {'loss': 16.6118, 'grad_norm': 1886.8822021484375, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:28<5:34:30,  3.35s/it]  0%|          | 9/6000 [00:31<5:35:08,  3.36s/it]                                                  {'loss': 12.583, 'grad_norm': 1612.8262939453125, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:31<5:35:08,  3.36s/it]  0%|          | 10/6000 [00:34<5:32:41,  3.33s/it]                                                   {'loss': 14.7394, 'grad_norm': 2018.7620849609375, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:34<5:32:41,  3.33s/it]  0%|          | 11/6000 [00:38<5:43:36,  3.44s/it]                                                   {'loss': 13.5039, 'grad_norm': 2054.8115234375, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:38<5:43:36,  3.44s/it]  0%|          | 12/6000 [00:41<5:44:43,  3.45s/it]                                                   {'loss': 10.9616, 'grad_norm': 2842.904296875, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:41<5:44:43,  3.45s/it]  0%|          | 13/6000 [00:45<5:42:13,  3.43s/it]                                                   {'loss': 11.2542, 'grad_norm': 4242.974609375, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:45<5:42:13,  3.43s/it]  0%|          | 14/6000 [00:48<5:44:09,  3.45s/it]                                                   {'loss': 10.428, 'grad_norm': 2550.575439453125, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:48<5:44:09,  3.45s/it]  0%|          | 15/6000 [00:52<5:40:29,  3.41s/it]                                                   {'loss': 5.8323, 'grad_norm': 3364.783447265625, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:52<5:40:29,  3.41s/it]  0%|          | 16/6000 [00:55<5:38:34,  3.39s/it]                                                   {'loss': 5.4706, 'grad_norm': 1787.2296142578125, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:55<5:38:34,  3.39s/it]  0%|          | 17/6000 [00:58<5:37:38,  3.39s/it]                                                   {'loss': 6.0991, 'grad_norm': 1813.58447265625, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:58<5:37:38,  3.39s/it]  0%|          | 18/6000 [01:02<5:38:30,  3.40s/it]                                                   {'loss': 4.6128, 'grad_norm': 3100.43212890625, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [01:02<5:38:30,  3.40s/it]  0%|          | 19/6000 [01:05<5:34:34,  3.36s/it]                                                   {'loss': 4.4531, 'grad_norm': 909.0242919921875, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [01:05<5:34:34,  3.36s/it]  0%|          | 20/6000 [01:08<5:37:38,  3.39s/it]                                                   {'loss': 4.1086, 'grad_norm': 842.3302001953125, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [01:09<5:37:38,  3.39s/it]  0%|          | 21/6000 [01:12<5:39:54,  3.41s/it]                                                   {'loss': 3.5255, 'grad_norm': 539.159912109375, 'learning_rate': 1.05e-05, 'epoch': 0.0}
  0%|          | 21/6000 [01:12<5:39:54,  3.41s/it]  0%|          | 22/6000 [01:15<5:39:45,  3.41s/it]                                                   {'loss': 4.1894, 'grad_norm': 377.1651611328125, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}
  0%|          | 22/6000 [01:15<5:39:45,  3.41s/it]  0%|          | 23/6000 [01:19<5:37:47,  3.39s/it]                                                   {'loss': 3.5957, 'grad_norm': 474.6644592285156, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.0}
  0%|          | 23/6000 [01:19<5:37:47,  3.39s/it]  0%|          | 24/6000 [01:22<5:40:46,  3.42s/it]                                                   {'loss': 3.9945, 'grad_norm': 746.847412109375, 'learning_rate': 1.2e-05, 'epoch': 0.0}
  0%|          | 24/6000 [01:22<5:40:46,  3.42s/it]  0%|          | 25/6000 [01:26<5:39:49,  3.41s/it]                                                   {'loss': 3.8354, 'grad_norm': 461.7709045410156, 'learning_rate': 1.25e-05, 'epoch': 0.0}
  0%|          | 25/6000 [01:26<5:39:49,  3.41s/it]  0%|          | 26/6000 [01:29<5:39:40,  3.41s/it]                                                   {'loss': 3.2589, 'grad_norm': 545.37744140625, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}
  0%|          | 26/6000 [01:29<5:39:40,  3.41s/it]  0%|          | 27/6000 [01:32<5:38:21,  3.40s/it]                                                   {'loss': 3.3979, 'grad_norm': 238.96783447265625, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.0}
  0%|          | 27/6000 [01:32<5:38:21,  3.40s/it]  0%|          | 28/6000 [01:37<6:05:39,  3.67s/it]                                                   {'loss': 3.258, 'grad_norm': 315.38787841796875, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}
  0%|          | 28/6000 [01:37<6:05:39,  3.67s/it]  0%|          | 29/6000 [01:40<5:56:15,  3.58s/it]                                                   {'loss': 3.121, 'grad_norm': 131.3683319091797, 'learning_rate': 1.45e-05, 'epoch': 0.0}
  0%|          | 29/6000 [01:40<5:56:15,  3.58s/it]  0%|          | 30/6000 [01:43<5:48:32,  3.50s/it]                                                   {'loss': 3.547, 'grad_norm': 231.8608856201172, 'learning_rate': 1.5e-05, 'epoch': 0.01}
  0%|          | 30/6000 [01:43<5:48:32,  3.50s/it]  1%|          | 31/6000 [01:47<5:43:16,  3.45s/it]                                                   {'loss': 3.1289, 'grad_norm': 450.4283142089844, 'learning_rate': 1.55e-05, 'epoch': 0.01}
  1%|          | 31/6000 [01:47<5:43:16,  3.45s/it]  1%|          | 32/6000 [01:50<5:41:27,  3.43s/it]                                                   {'loss': 3.2383, 'grad_norm': 162.18934631347656, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}
  1%|          | 32/6000 [01:50<5:41:27,  3.43s/it]  1%|          | 33/6000 [01:53<5:39:54,  3.42s/it]                                                   {'loss': 3.0212, 'grad_norm': 198.9823760986328, 'learning_rate': 1.65e-05, 'epoch': 0.01}
  1%|          | 33/6000 [01:53<5:39:54,  3.42s/it]  1%|          | 34/6000 [01:57<5:38:43,  3.41s/it]                                                   {'loss': 3.104, 'grad_norm': 152.26895141601562, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}
  1%|          | 34/6000 [01:57<5:38:43,  3.41s/it]  1%|          | 35/6000 [02:00<5:37:35,  3.40s/it]                                                   {'loss': 3.2913, 'grad_norm': 216.33837890625, 'learning_rate': 1.75e-05, 'epoch': 0.01}
  1%|          | 35/6000 [02:00<5:37:35,  3.40s/it]  1%|          | 36/6000 [02:04<5:35:06,  3.37s/it]                                                   {'loss': 2.9839, 'grad_norm': 160.65333557128906, 'learning_rate': 1.8e-05, 'epoch': 0.01}
  1%|          | 36/6000 [02:04<5:35:06,  3.37s/it]  1%|          | 37/6000 [02:07<5:35:32,  3.38s/it]                                                   {'loss': 2.8903, 'grad_norm': 139.73831176757812, 'learning_rate': 1.85e-05, 'epoch': 0.01}
  1%|          | 37/6000 [02:07<5:35:32,  3.38s/it]  1%|          | 38/6000 [02:10<5:33:23,  3.36s/it]                                                   {'loss': 2.8409, 'grad_norm': 236.7003631591797, 'learning_rate': 1.9e-05, 'epoch': 0.01}
  1%|          | 38/6000 [02:10<5:33:23,  3.36s/it]  1%|          | 39/6000 [02:14<5:32:34,  3.35s/it]                                                   {'loss': 3.0353, 'grad_norm': 124.26496887207031, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}
  1%|          | 39/6000 [02:14<5:32:34,  3.35s/it]  1%|          | 40/6000 [02:17<5:35:18,  3.38s/it]                                                   {'loss': 2.9741, 'grad_norm': 130.0684814453125, 'learning_rate': 2e-05, 'epoch': 0.01}
  1%|          | 40/6000 [02:17<5:35:18,  3.38s/it]  1%|          | 41/6000 [02:20<5:36:55,  3.39s/it]                                                   {'loss': 2.8696, 'grad_norm': 187.94261169433594, 'learning_rate': 2.05e-05, 'epoch': 0.01}
  1%|          | 41/6000 [02:20<5:36:55,  3.39s/it]  1%|          | 42/6000 [02:24<5:36:02,  3.38s/it]                                                   {'loss': 2.7754, 'grad_norm': 178.14959716796875, 'learning_rate': 2.1e-05, 'epoch': 0.01}
  1%|          | 42/6000 [02:24<5:36:02,  3.38s/it]  1%|          | 43/6000 [02:28<6:06:12,  3.69s/it]                                                   {'loss': 2.578, 'grad_norm': 261.853515625, 'learning_rate': 2.15e-05, 'epoch': 0.01}
  1%|          | 43/6000 [02:28<6:06:12,  3.69s/it]  1%|          | 44/6000 [02:32<6:11:20,  3.74s/it]                                                   {'loss': 2.5816, 'grad_norm': 210.71481323242188, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.01}
  1%|          | 44/6000 [02:32<6:11:20,  3.74s/it]  1%|          | 45/6000 [02:35<6:01:09,  3.64s/it]                                                   {'loss': 2.2613, 'grad_norm': 137.31112670898438, 'learning_rate': 2.25e-05, 'epoch': 0.01}
  1%|          | 45/6000 [02:35<6:01:09,  3.64s/it]  1%|          | 46/6000 [02:39<5:55:49,  3.59s/it]                                                   {'loss': 2.108, 'grad_norm': 146.65707397460938, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01}
  1%|          | 46/6000 [02:39<5:55:49,  3.59s/it]  1%|          | 47/6000 [02:42<5:48:31,  3.51s/it]                                                   {'loss': 2.8019, 'grad_norm': 308.19293212890625, 'learning_rate': 2.35e-05, 'epoch': 0.01}
  1%|          | 47/6000 [02:42<5:48:31,  3.51s/it]  1%|          | 48/6000 [02:46<5:46:55,  3.50s/it]                                                   {'loss': 1.6624, 'grad_norm': 158.17034912109375, 'learning_rate': 2.4e-05, 'epoch': 0.01}
  1%|          | 48/6000 [02:46<5:46:55,  3.50s/it]  1%|          | 49/6000 [02:49<5:42:43,  3.46s/it]                                                   {'loss': 1.4595, 'grad_norm': 137.18084716796875, 'learning_rate': 2.45e-05, 'epoch': 0.01}
  1%|          | 49/6000 [02:49<5:42:43,  3.46s/it]  1%|          | 50/6000 [02:53<5:44:34,  3.47s/it]                                                   {'loss': 0.9998, 'grad_norm': 250.76719665527344, 'learning_rate': 2.5e-05, 'epoch': 0.01}
  1%|          | 50/6000 [02:53<5:44:34,  3.47s/it][2025-10-19 23:39:57,934] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  1%|          | 51/6000 [02:58<6:42:50,  4.06s/it]                                                   {'loss': 0.9278, 'grad_norm': 104.41764068603516, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.01}
  1%|          | 51/6000 [02:58<6:42:50,  4.06s/it]  1%|          | 52/6000 [03:01<6:20:07,  3.83s/it]                                                   {'loss': 0.7175, 'grad_norm': 68.17033386230469, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}
  1%|          | 52/6000 [03:01<6:20:07,  3.83s/it]  1%|          | 53/6000 [03:05<6:07:28,  3.71s/it]                                                   {'loss': 0.9212, 'grad_norm': 120.29705810546875, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.01}
  1%|          | 53/6000 [03:05<6:07:28,  3.71s/it]  1%|          | 54/6000 [03:08<5:56:53,  3.60s/it]                                                   {'loss': 0.5648, 'grad_norm': 101.034423828125, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}
  1%|          | 54/6000 [03:08<5:56:53,  3.60s/it]  1%|          | 55/6000 [03:11<5:50:15,  3.54s/it]                                                   {'loss': 0.7771, 'grad_norm': 341.1685485839844, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.01}
  1%|          | 55/6000 [03:12<5:50:15,  3.54s/it]  1%|          | 56/6000 [03:15<5:44:57,  3.48s/it]                                                   {'loss': 0.3825, 'grad_norm': 149.78221130371094, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}
  1%|          | 56/6000 [03:15<5:44:57,  3.48s/it]  1%|          | 57/6000 [03:18<5:42:40,  3.46s/it]                                                   {'loss': 0.4506, 'grad_norm': 78.81340026855469, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.01}
  1%|          | 57/6000 [03:18<5:42:40,  3.46s/it]  1%|          | 58/6000 [03:22<5:39:50,  3.43s/it]                                                   {'loss': 0.4778, 'grad_norm': 62.09409713745117, 'learning_rate': 2.9e-05, 'epoch': 0.01}
  1%|          | 58/6000 [03:22<5:39:50,  3.43s/it]  1%|          | 59/6000 [03:25<5:34:55,  3.38s/it]                                                   {'loss': 0.3713, 'grad_norm': 43.13459014892578, 'learning_rate': 2.95e-05, 'epoch': 0.01}
  1%|          | 59/6000 [03:25<5:34:55,  3.38s/it]  1%|          | 60/6000 [03:28<5:35:00,  3.38s/it]                                                   {'loss': 0.6787, 'grad_norm': 250.11111450195312, 'learning_rate': 3e-05, 'epoch': 0.01}
  1%|          | 60/6000 [03:28<5:35:00,  3.38s/it]  1%|          | 61/6000 [03:32<5:33:37,  3.37s/it]                                                   {'loss': 0.2679, 'grad_norm': 32.367679595947266, 'learning_rate': 3.05e-05, 'epoch': 0.01}
  1%|          | 61/6000 [03:32<5:33:37,  3.37s/it]  1%|          | 62/6000 [03:35<5:34:30,  3.38s/it]                                                   {'loss': 0.2265, 'grad_norm': 25.452659606933594, 'learning_rate': 3.1e-05, 'epoch': 0.01}
  1%|          | 62/6000 [03:35<5:34:30,  3.38s/it]  1%|          | 63/6000 [03:38<5:34:27,  3.38s/it]                                                   {'loss': 0.1816, 'grad_norm': 20.77935028076172, 'learning_rate': 3.15e-05, 'epoch': 0.01}
  1%|          | 63/6000 [03:38<5:34:27,  3.38s/it]  1%|          | 64/6000 [03:42<5:31:37,  3.35s/it]                                                   {'loss': 0.1145, 'grad_norm': 34.25930404663086, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.01}
  1%|          | 64/6000 [03:42<5:31:37,  3.35s/it]  1%|          | 65/6000 [03:45<5:29:48,  3.33s/it]                                                   {'loss': 0.211, 'grad_norm': 24.64425277709961, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.01}
  1%|          | 65/6000 [03:45<5:29:48,  3.33s/it]  1%|          | 66/6000 [03:49<5:44:18,  3.48s/it]                                                   {'loss': 0.1861, 'grad_norm': 17.894412994384766, 'learning_rate': 3.3e-05, 'epoch': 0.01}
  1%|          | 66/6000 [03:49<5:44:18,  3.48s/it]  1%|          | 67/6000 [03:52<5:42:26,  3.46s/it]                                                   {'loss': 0.2578, 'grad_norm': 31.731122970581055, 'learning_rate': 3.35e-05, 'epoch': 0.01}
  1%|          | 67/6000 [03:52<5:42:26,  3.46s/it]  1%|          | 68/6000 [03:56<5:37:13,  3.41s/it]                                                   {'loss': 0.2461, 'grad_norm': 53.42585754394531, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.01}
  1%|          | 68/6000 [03:56<5:37:13,  3.41s/it]  1%|          | 69/6000 [03:59<5:34:49,  3.39s/it]                                                   {'loss': 0.4298, 'grad_norm': 23.24993133544922, 'learning_rate': 3.45e-05, 'epoch': 0.01}
  1%|          | 69/6000 [03:59<5:34:49,  3.39s/it]  1%|          | 70/6000 [04:03<5:43:22,  3.47s/it]                                                   {'loss': 0.1035, 'grad_norm': 13.723968505859375, 'learning_rate': 3.5e-05, 'epoch': 0.01}
  1%|          | 70/6000 [04:03<5:43:22,  3.47s/it]  1%|          | 71/6000 [04:06<5:37:36,  3.42s/it]                                                   {'loss': 0.0731, 'grad_norm': 12.089698791503906, 'learning_rate': 3.55e-05, 'epoch': 0.01}
  1%|          | 71/6000 [04:06<5:37:36,  3.42s/it]  1%|          | 72/6000 [04:10<5:47:12,  3.51s/it]                                                   {'loss': 0.2485, 'grad_norm': 20.340242385864258, 'learning_rate': 3.6e-05, 'epoch': 0.01}
  1%|          | 72/6000 [04:10<5:47:12,  3.51s/it]  1%|          | 73/6000 [04:13<5:44:50,  3.49s/it]                                                   {'loss': 0.2245, 'grad_norm': 36.776939392089844, 'learning_rate': 3.65e-05, 'epoch': 0.01}
  1%|          | 73/6000 [04:13<5:44:50,  3.49s/it]  1%|          | 74/6000 [04:16<5:38:54,  3.43s/it]                                                   {'loss': 0.2472, 'grad_norm': 28.245378494262695, 'learning_rate': 3.7e-05, 'epoch': 0.01}
  1%|          | 74/6000 [04:16<5:38:54,  3.43s/it]  1%|â–         | 75/6000 [04:20<5:35:08,  3.39s/it]                                                   {'loss': 0.1491, 'grad_norm': 32.307777404785156, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.01}
  1%|â–         | 75/6000 [04:20<5:35:08,  3.39s/it]  1%|â–         | 76/6000 [04:23<5:38:15,  3.43s/it]                                                   {'loss': 0.0676, 'grad_norm': 8.864171028137207, 'learning_rate': 3.8e-05, 'epoch': 0.01}
  1%|â–         | 76/6000 [04:23<5:38:15,  3.43s/it]  1%|â–         | 77/6000 [04:26<5:37:16,  3.42s/it]                                                   {'loss': 0.2754, 'grad_norm': 36.302616119384766, 'learning_rate': 3.85e-05, 'epoch': 0.01}
  1%|â–         | 77/6000 [04:26<5:37:16,  3.42s/it]  1%|â–         | 78/6000 [04:30<5:48:03,  3.53s/it]                                                   {'loss': 0.094, 'grad_norm': 27.844547271728516, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 78/6000 [04:30<5:48:03,  3.53s/it]  1%|â–         | 79/6000 [04:34<5:43:04,  3.48s/it]                                                   {'loss': 0.2466, 'grad_norm': 40.94247055053711, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.01}
  1%|â–         | 79/6000 [04:34<5:43:04,  3.48s/it]  1%|â–         | 80/6000 [04:37<5:47:53,  3.53s/it]                                                   {'loss': 0.1314, 'grad_norm': 19.778799057006836, 'learning_rate': 4e-05, 'epoch': 0.01}
  1%|â–         | 80/6000 [04:37<5:47:53,  3.53s/it]  1%|â–         | 81/6000 [04:41<5:42:20,  3.47s/it]                                                   {'loss': 0.0175, 'grad_norm': 3.4727885723114014, 'learning_rate': 4.05e-05, 'epoch': 0.01}
  1%|â–         | 81/6000 [04:41<5:42:20,  3.47s/it]  1%|â–         | 82/6000 [04:44<5:41:32,  3.46s/it]                                                   {'loss': 0.237, 'grad_norm': 28.439300537109375, 'learning_rate': 4.1e-05, 'epoch': 0.01}
  1%|â–         | 82/6000 [04:44<5:41:32,  3.46s/it]  1%|â–         | 83/6000 [04:47<5:39:11,  3.44s/it]                                                   {'loss': 0.1843, 'grad_norm': 31.620845794677734, 'learning_rate': 4.15e-05, 'epoch': 0.01}
  1%|â–         | 83/6000 [04:47<5:39:11,  3.44s/it]  1%|â–         | 84/6000 [04:51<5:40:12,  3.45s/it]                                                   {'loss': 0.0662, 'grad_norm': 11.042365074157715, 'learning_rate': 4.2e-05, 'epoch': 0.01}
  1%|â–         | 84/6000 [04:51<5:40:12,  3.45s/it]  1%|â–         | 85/6000 [04:55<5:49:48,  3.55s/it]                                                   {'loss': 0.1011, 'grad_norm': 17.46570587158203, 'learning_rate': 4.25e-05, 'epoch': 0.01}
  1%|â–         | 85/6000 [04:55<5:49:48,  3.55s/it]  1%|â–         | 86/6000 [04:58<5:46:33,  3.52s/it]                                                   {'loss': 0.1623, 'grad_norm': 12.862536430358887, 'learning_rate': 4.3e-05, 'epoch': 0.01}
  1%|â–         | 86/6000 [04:58<5:46:33,  3.52s/it]  1%|â–         | 87/6000 [05:01<5:40:30,  3.46s/it]                                                   {'loss': 0.0038, 'grad_norm': 1.6118544340133667, 'learning_rate': 4.35e-05, 'epoch': 0.01}
  1%|â–         | 87/6000 [05:01<5:40:30,  3.46s/it]  1%|â–         | 88/6000 [05:05<5:35:30,  3.41s/it]                                                   {'loss': 0.1226, 'grad_norm': 20.71001434326172, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 88/6000 [05:05<5:35:30,  3.41s/it]  1%|â–         | 89/6000 [05:08<5:34:05,  3.39s/it]                                                   {'loss': 0.1984, 'grad_norm': 41.11998748779297, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}
  1%|â–         | 89/6000 [05:08<5:34:05,  3.39s/it]  2%|â–         | 90/6000 [05:12<5:36:47,  3.42s/it]                                                   {'loss': 0.0301, 'grad_norm': 8.690911293029785, 'learning_rate': 4.5e-05, 'epoch': 0.01}
  2%|â–         | 90/6000 [05:12<5:36:47,  3.42s/it]  2%|â–         | 91/6000 [05:15<5:34:47,  3.40s/it]                                                   {'loss': 0.2595, 'grad_norm': 32.62234878540039, 'learning_rate': 4.55e-05, 'epoch': 0.02}
  2%|â–         | 91/6000 [05:15<5:34:47,  3.40s/it]  2%|â–         | 92/6000 [05:19<5:45:27,  3.51s/it]                                                   {'loss': 0.1781, 'grad_norm': 16.849685668945312, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.02}
  2%|â–         | 92/6000 [05:19<5:45:27,  3.51s/it]  2%|â–         | 93/6000 [05:22<5:47:20,  3.53s/it]                                                   {'loss': 0.0315, 'grad_norm': 7.154857635498047, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.02}
  2%|â–         | 93/6000 [05:22<5:47:20,  3.53s/it]  2%|â–         | 94/6000 [05:26<5:40:52,  3.46s/it]                                                   {'loss': 0.119, 'grad_norm': 37.30040740966797, 'learning_rate': 4.7e-05, 'epoch': 0.02}
  2%|â–         | 94/6000 [05:26<5:40:52,  3.46s/it]  2%|â–         | 95/6000 [05:29<5:40:43,  3.46s/it]                                                   {'loss': 0.0257, 'grad_norm': 12.315898895263672, 'learning_rate': 4.75e-05, 'epoch': 0.02}
  2%|â–         | 95/6000 [05:29<5:40:43,  3.46s/it]  2%|â–         | 96/6000 [05:32<5:40:38,  3.46s/it]                                                   {'loss': 0.2873, 'grad_norm': 16.373971939086914, 'learning_rate': 4.8e-05, 'epoch': 0.02}
  2%|â–         | 96/6000 [05:33<5:40:38,  3.46s/it]  2%|â–         | 97/6000 [05:36<5:39:02,  3.45s/it]                                                   {'loss': 0.3061, 'grad_norm': 23.85489845275879, 'learning_rate': 4.85e-05, 'epoch': 0.02}
  2%|â–         | 97/6000 [05:36<5:39:02,  3.45s/it]  2%|â–         | 98/6000 [05:39<5:37:39,  3.43s/it]                                                   {'loss': 0.2688, 'grad_norm': 26.187854766845703, 'learning_rate': 4.9e-05, 'epoch': 0.02}
  2%|â–         | 98/6000 [05:39<5:37:39,  3.43s/it]  2%|â–         | 99/6000 [05:43<5:34:40,  3.40s/it]                                                   {'loss': 0.1363, 'grad_norm': 22.63691520690918, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}
  2%|â–         | 99/6000 [05:43<5:34:40,  3.40s/it]  2%|â–         | 100/6000 [05:46<5:31:19,  3.37s/it]                                                    {'loss': 0.5611, 'grad_norm': 25.11166763305664, 'learning_rate': 5e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [05:46<5:31:19,  3.37s/it][2025-10-19 23:42:51,260] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  2%|â–         | 101/6000 [05:53<7:05:45,  4.33s/it]                                                    {'loss': 0.1049, 'grad_norm': 12.299359321594238, 'learning_rate': 4.9991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 101/6000 [05:53<7:05:45,  4.33s/it]  2%|â–         | 102/6000 [05:56<6:38:19,  4.05s/it]                                                    {'loss': 0.0591, 'grad_norm': 17.038782119750977, 'learning_rate': 4.998305084745763e-05, 'epoch': 0.02}
  2%|â–         | 102/6000 [05:56<6:38:19,  4.05s/it]  2%|â–         | 103/6000 [05:59<6:22:38,  3.89s/it]                                                    {'loss': 0.0466, 'grad_norm': 4.057306289672852, 'learning_rate': 4.997457627118644e-05, 'epoch': 0.02}
  2%|â–         | 103/6000 [05:59<6:22:38,  3.89s/it]  2%|â–         | 104/6000 [06:03<6:15:31,  3.82s/it]                                                    {'loss': 0.0716, 'grad_norm': 12.625473022460938, 'learning_rate': 4.9966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 104/6000 [06:03<6:15:31,  3.82s/it]  2%|â–         | 105/6000 [06:07<6:05:31,  3.72s/it]                                                    {'loss': 0.2373, 'grad_norm': 18.842323303222656, 'learning_rate': 4.9957627118644066e-05, 'epoch': 0.02}
  2%|â–         | 105/6000 [06:07<6:05:31,  3.72s/it]  2%|â–         | 106/6000 [06:10<6:00:33,  3.67s/it]                                                    {'loss': 0.0512, 'grad_norm': 11.69289493560791, 'learning_rate': 4.9949152542372884e-05, 'epoch': 0.02}
  2%|â–         | 106/6000 [06:10<6:00:33,  3.67s/it]  2%|â–         | 107/6000 [06:14<5:52:41,  3.59s/it]                                                    {'loss': 0.096, 'grad_norm': 12.691998481750488, 'learning_rate': 4.9940677966101695e-05, 'epoch': 0.02}
  2%|â–         | 107/6000 [06:14<5:52:41,  3.59s/it]  2%|â–         | 108/6000 [06:17<5:52:34,  3.59s/it]                                                    {'loss': 0.1003, 'grad_norm': 13.822474479675293, 'learning_rate': 4.993220338983051e-05, 'epoch': 0.02}
  2%|â–         | 108/6000 [06:17<5:52:34,  3.59s/it]  2%|â–         | 109/6000 [06:21<6:00:54,  3.68s/it]                                                    {'loss': 0.2386, 'grad_norm': 19.91547393798828, 'learning_rate': 4.9923728813559324e-05, 'epoch': 0.02}
  2%|â–         | 109/6000 [06:21<6:00:54,  3.68s/it]  2%|â–         | 110/6000 [06:24<5:53:11,  3.60s/it]                                                    {'loss': 0.0652, 'grad_norm': 9.620542526245117, 'learning_rate': 4.991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 110/6000 [06:24<5:53:11,  3.60s/it]  2%|â–         | 111/6000 [06:28<5:51:34,  3.58s/it]                                                    {'loss': 0.3079, 'grad_norm': 24.8131046295166, 'learning_rate': 4.990677966101695e-05, 'epoch': 0.02}
  2%|â–         | 111/6000 [06:28<5:51:34,  3.58s/it]  2%|â–         | 112/6000 [06:32<6:03:33,  3.70s/it]                                                    {'loss': 0.1624, 'grad_norm': 12.217832565307617, 'learning_rate': 4.9898305084745765e-05, 'epoch': 0.02}
  2%|â–         | 112/6000 [06:32<6:03:33,  3.70s/it]  2%|â–         | 113/6000 [06:35<5:56:30,  3.63s/it]                                                    {'loss': 0.1003, 'grad_norm': 15.405111312866211, 'learning_rate': 4.9889830508474576e-05, 'epoch': 0.02}
  2%|â–         | 113/6000 [06:35<5:56:30,  3.63s/it]  2%|â–         | 114/6000 [06:39<5:50:53,  3.58s/it]                                                    {'loss': 0.18, 'grad_norm': 13.5314359664917, 'learning_rate': 4.9881355932203394e-05, 'epoch': 0.02}
  2%|â–         | 114/6000 [06:39<5:50:53,  3.58s/it]  2%|â–         | 115/6000 [06:42<5:47:04,  3.54s/it]                                                    {'loss': 0.1212, 'grad_norm': 14.132549285888672, 'learning_rate': 4.9872881355932206e-05, 'epoch': 0.02}
  2%|â–         | 115/6000 [06:42<5:47:04,  3.54s/it]  2%|â–         | 116/6000 [06:46<5:45:44,  3.53s/it]                                                    {'loss': 0.1851, 'grad_norm': 32.79950714111328, 'learning_rate': 4.9864406779661024e-05, 'epoch': 0.02}
  2%|â–         | 116/6000 [06:46<5:45:44,  3.53s/it]  2%|â–         | 117/6000 [06:49<5:43:29,  3.50s/it]                                                    {'loss': 0.077, 'grad_norm': 6.8332600593566895, 'learning_rate': 4.9855932203389835e-05, 'epoch': 0.02}
  2%|â–         | 117/6000 [06:49<5:43:29,  3.50s/it]  2%|â–         | 118/6000 [06:53<5:59:29,  3.67s/it]                                                    {'loss': 0.2817, 'grad_norm': 19.768266677856445, 'learning_rate': 4.9847457627118646e-05, 'epoch': 0.02}
  2%|â–         | 118/6000 [06:53<5:59:29,  3.67s/it]  2%|â–         | 119/6000 [06:57<5:49:04,  3.56s/it]                                                    {'loss': 0.062, 'grad_norm': 9.873933792114258, 'learning_rate': 4.983898305084746e-05, 'epoch': 0.02}
  2%|â–         | 119/6000 [06:57<5:49:04,  3.56s/it]  2%|â–         | 120/6000 [07:00<5:44:19,  3.51s/it]                                                    {'loss': 0.1269, 'grad_norm': 13.452988624572754, 'learning_rate': 4.9830508474576276e-05, 'epoch': 0.02}
  2%|â–         | 120/6000 [07:00<5:44:19,  3.51s/it]  2%|â–         | 121/6000 [07:03<5:41:38,  3.49s/it]                                                    {'loss': 0.0215, 'grad_norm': 5.400279521942139, 'learning_rate': 4.982203389830509e-05, 'epoch': 0.02}
  2%|â–         | 121/6000 [07:03<5:41:38,  3.49s/it]  2%|â–         | 122/6000 [07:07<5:44:36,  3.52s/it]                                                    {'loss': 0.1374, 'grad_norm': 9.867618560791016, 'learning_rate': 4.98135593220339e-05, 'epoch': 0.02}
  2%|â–         | 122/6000 [07:07<5:44:36,  3.52s/it]  2%|â–         | 123/6000 [07:10<5:39:12,  3.46s/it]                                                    {'loss': 0.0127, 'grad_norm': 1.3947056531906128, 'learning_rate': 4.9805084745762716e-05, 'epoch': 0.02}
  2%|â–         | 123/6000 [07:10<5:39:12,  3.46s/it]  2%|â–         | 124/6000 [07:14<5:37:20,  3.44s/it]                                                    {'loss': 0.1956, 'grad_norm': 9.593043327331543, 'learning_rate': 4.979661016949153e-05, 'epoch': 0.02}
  2%|â–         | 124/6000 [07:14<5:37:20,  3.44s/it]  2%|â–         | 125/6000 [07:17<5:44:33,  3.52s/it]                                                    {'loss': 0.13, 'grad_norm': 11.44662857055664, 'learning_rate': 4.978813559322034e-05, 'epoch': 0.02}
  2%|â–         | 125/6000 [07:17<5:44:33,  3.52s/it]  2%|â–         | 126/6000 [07:21<5:43:53,  3.51s/it]                                                    {'loss': 0.1164, 'grad_norm': 12.993945121765137, 'learning_rate': 4.977966101694915e-05, 'epoch': 0.02}
  2%|â–         | 126/6000 [07:21<5:43:53,  3.51s/it]  2%|â–         | 127/6000 [07:25<5:47:06,  3.55s/it]                                                    {'loss': 0.162, 'grad_norm': 8.926255226135254, 'learning_rate': 4.977118644067797e-05, 'epoch': 0.02}
  2%|â–         | 127/6000 [07:25<5:47:06,  3.55s/it]  2%|â–         | 128/6000 [07:28<5:41:49,  3.49s/it]                                                    {'loss': 0.0399, 'grad_norm': 4.272407054901123, 'learning_rate': 4.976271186440678e-05, 'epoch': 0.02}
  2%|â–         | 128/6000 [07:28<5:41:49,  3.49s/it]  2%|â–         | 129/6000 [07:31<5:39:39,  3.47s/it]                                                    {'loss': 0.0797, 'grad_norm': 6.584299087524414, 'learning_rate': 4.97542372881356e-05, 'epoch': 0.02}
  2%|â–         | 129/6000 [07:31<5:39:39,  3.47s/it]  2%|â–         | 130/6000 [07:35<5:36:21,  3.44s/it]                                                    {'loss': 0.1118, 'grad_norm': 9.529343605041504, 'learning_rate': 4.974576271186441e-05, 'epoch': 0.02}
  2%|â–         | 130/6000 [07:35<5:36:21,  3.44s/it]  2%|â–         | 131/6000 [07:38<5:36:39,  3.44s/it]                                                    {'loss': 0.1496, 'grad_norm': 54.96293640136719, 'learning_rate': 4.973728813559323e-05, 'epoch': 0.02}
  2%|â–         | 131/6000 [07:38<5:36:39,  3.44s/it]  2%|â–         | 132/6000 [07:42<5:35:06,  3.43s/it]                                                    {'loss': 0.0616, 'grad_norm': 6.080153942108154, 'learning_rate': 4.972881355932204e-05, 'epoch': 0.02}
  2%|â–         | 132/6000 [07:42<5:35:06,  3.43s/it]  2%|â–         | 133/6000 [07:45<5:36:20,  3.44s/it]                                                    {'loss': 0.2548, 'grad_norm': 19.043519973754883, 'learning_rate': 4.972033898305085e-05, 'epoch': 0.02}
  2%|â–         | 133/6000 [07:45<5:36:20,  3.44s/it]  2%|â–         | 134/6000 [07:49<5:40:58,  3.49s/it]                                                    {'loss': 0.124, 'grad_norm': 12.171493530273438, 'learning_rate': 4.971186440677966e-05, 'epoch': 0.02}
  2%|â–         | 134/6000 [07:49<5:40:58,  3.49s/it]  2%|â–         | 135/6000 [07:52<5:38:28,  3.46s/it]                                                    {'loss': 0.2057, 'grad_norm': 10.635079383850098, 'learning_rate': 4.970338983050848e-05, 'epoch': 0.02}
  2%|â–         | 135/6000 [07:52<5:38:28,  3.46s/it]  2%|â–         | 136/6000 [07:55<5:36:05,  3.44s/it]                                                    {'loss': 0.0649, 'grad_norm': 6.939716815948486, 'learning_rate': 4.969491525423729e-05, 'epoch': 0.02}
  2%|â–         | 136/6000 [07:55<5:36:05,  3.44s/it]  2%|â–         | 137/6000 [07:59<5:50:30,  3.59s/it]                                                    {'loss': 0.1008, 'grad_norm': 10.31187629699707, 'learning_rate': 4.968644067796611e-05, 'epoch': 0.02}
  2%|â–         | 137/6000 [07:59<5:50:30,  3.59s/it]  2%|â–         | 138/6000 [08:03<5:43:17,  3.51s/it]                                                    {'loss': 0.1015, 'grad_norm': 10.583990097045898, 'learning_rate': 4.967796610169492e-05, 'epoch': 0.02}
  2%|â–         | 138/6000 [08:03<5:43:17,  3.51s/it]  2%|â–         | 139/6000 [08:06<5:44:39,  3.53s/it]                                                    {'loss': 0.1444, 'grad_norm': 11.414159774780273, 'learning_rate': 4.966949152542373e-05, 'epoch': 0.02}
  2%|â–         | 139/6000 [08:06<5:44:39,  3.53s/it]  2%|â–         | 140/6000 [08:10<5:53:49,  3.62s/it]                                                    {'loss': 0.1523, 'grad_norm': 13.763202667236328, 'learning_rate': 4.966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 140/6000 [08:10<5:53:49,  3.62s/it]  2%|â–         | 141/6000 [08:14<5:47:12,  3.56s/it]                                                    {'loss': 0.3595, 'grad_norm': 17.89418601989746, 'learning_rate': 4.965254237288136e-05, 'epoch': 0.02}
  2%|â–         | 141/6000 [08:14<5:47:12,  3.56s/it]  2%|â–         | 142/6000 [08:17<5:43:08,  3.51s/it]                                                    {'loss': 0.2022, 'grad_norm': 74.20196533203125, 'learning_rate': 4.964406779661017e-05, 'epoch': 0.02}
  2%|â–         | 142/6000 [08:17<5:43:08,  3.51s/it]  2%|â–         | 143/6000 [08:20<5:38:35,  3.47s/it]                                                    {'loss': 0.0551, 'grad_norm': 7.865431308746338, 'learning_rate': 4.963559322033898e-05, 'epoch': 0.02}
  2%|â–         | 143/6000 [08:20<5:38:35,  3.47s/it]  2%|â–         | 144/6000 [08:24<5:36:57,  3.45s/it]                                                    {'loss': 0.0137, 'grad_norm': 3.0788559913635254, 'learning_rate': 4.96271186440678e-05, 'epoch': 0.02}
  2%|â–         | 144/6000 [08:24<5:36:57,  3.45s/it]  2%|â–         | 145/6000 [08:27<5:33:21,  3.42s/it]                                                    {'loss': 0.0724, 'grad_norm': 39.56816101074219, 'learning_rate': 4.961864406779661e-05, 'epoch': 0.02}
  2%|â–         | 145/6000 [08:27<5:33:21,  3.42s/it]  2%|â–         | 146/6000 [08:31<5:37:12,  3.46s/it]                                                    {'loss': 0.0972, 'grad_norm': 11.686505317687988, 'learning_rate': 4.961016949152543e-05, 'epoch': 0.02}
  2%|â–         | 146/6000 [08:31<5:37:12,  3.46s/it]  2%|â–         | 147/6000 [08:34<5:33:20,  3.42s/it]                                                    {'loss': 0.1935, 'grad_norm': 16.266395568847656, 'learning_rate': 4.9601694915254234e-05, 'epoch': 0.02}
  2%|â–         | 147/6000 [08:34<5:33:20,  3.42s/it]  2%|â–         | 148/6000 [08:37<5:37:36,  3.46s/it]                                                    {'loss': 0.047, 'grad_norm': 8.88487720489502, 'learning_rate': 4.959322033898305e-05, 'epoch': 0.02}
  2%|â–         | 148/6000 [08:37<5:37:36,  3.46s/it]  2%|â–         | 149/6000 [08:41<5:33:24,  3.42s/it]                                                    {'loss': 0.0419, 'grad_norm': 6.654734134674072, 'learning_rate': 4.9584745762711864e-05, 'epoch': 0.02}
  2%|â–         | 149/6000 [08:41<5:33:24,  3.42s/it]  2%|â–Ž         | 150/6000 [08:44<5:32:32,  3.41s/it]                                                    {'loss': 0.0058, 'grad_norm': 0.7307014465332031, 'learning_rate': 4.957627118644068e-05, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [08:44<5:32:32,  3.41s/it][2025-10-19 23:45:49,511] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 151/6000 [08:50<6:37:31,  4.08s/it]                                                    {'loss': 0.1253, 'grad_norm': 9.415862083435059, 'learning_rate': 4.956779661016949e-05, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [08:50<6:37:31,  4.08s/it]  3%|â–Ž         | 152/6000 [08:53<6:19:14,  3.89s/it]                                                    {'loss': 0.0621, 'grad_norm': 9.070850372314453, 'learning_rate': 4.955932203389831e-05, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [08:53<6:19:14,  3.89s/it]  3%|â–Ž         | 153/6000 [08:57<6:03:08,  3.73s/it]                                                    {'loss': 0.0207, 'grad_norm': 1.5800645351409912, 'learning_rate': 4.955084745762712e-05, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [08:57<6:03:08,  3.73s/it]  3%|â–Ž         | 154/6000 [09:00<5:57:43,  3.67s/it]                                                    {'loss': 0.0612, 'grad_norm': 11.605817794799805, 'learning_rate': 4.9542372881355934e-05, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [09:00<5:57:43,  3.67s/it]  3%|â–Ž         | 155/6000 [09:04<5:49:52,  3.59s/it]                                                    {'loss': 0.077, 'grad_norm': 6.152081489562988, 'learning_rate': 4.9533898305084745e-05, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [09:04<5:49:52,  3.59s/it]  3%|â–Ž         | 156/6000 [09:07<5:46:09,  3.55s/it]                                                    {'loss': 0.0148, 'grad_norm': 3.282721996307373, 'learning_rate': 4.952542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [09:07<5:46:09,  3.55s/it]  3%|â–Ž         | 157/6000 [09:11<5:56:14,  3.66s/it]                                                    {'loss': 0.0576, 'grad_norm': 5.07899284362793, 'learning_rate': 4.9516949152542374e-05, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [09:11<5:56:14,  3.66s/it]  3%|â–Ž         | 158/6000 [09:14<5:46:11,  3.56s/it]                                                    {'loss': 0.0111, 'grad_norm': 2.037109375, 'learning_rate': 4.950847457627119e-05, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [09:14<5:46:11,  3.56s/it]  3%|â–Ž         | 159/6000 [09:18<5:39:57,  3.49s/it]                                                    {'loss': 0.2028, 'grad_norm': 101.02269744873047, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [09:18<5:39:57,  3.49s/it]  3%|â–Ž         | 160/6000 [09:22<5:57:02,  3.67s/it]                                                    {'loss': 0.0783, 'grad_norm': 9.13412857055664, 'learning_rate': 4.9491525423728815e-05, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [09:22<5:57:02,  3.67s/it]  3%|â–Ž         | 161/6000 [09:25<5:53:19,  3.63s/it]                                                    {'loss': 0.1577, 'grad_norm': 11.748015403747559, 'learning_rate': 4.9483050847457626e-05, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [09:25<5:53:19,  3.63s/it]  3%|â–Ž         | 162/6000 [09:29<5:44:50,  3.54s/it]                                                    {'loss': 0.0165, 'grad_norm': 2.169106960296631, 'learning_rate': 4.9474576271186444e-05, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [09:29<5:44:50,  3.54s/it]  3%|â–Ž         | 163/6000 [09:33<5:57:06,  3.67s/it]                                                    {'loss': 0.0583, 'grad_norm': 9.294384956359863, 'learning_rate': 4.9466101694915256e-05, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [09:33<5:57:06,  3.67s/it]  3%|â–Ž         | 164/6000 [09:36<5:48:03,  3.58s/it]                                                    {'loss': 0.367, 'grad_norm': 15.501118659973145, 'learning_rate': 4.945762711864407e-05, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [09:36<5:48:03,  3.58s/it]  3%|â–Ž         | 165/6000 [09:39<5:46:23,  3.56s/it]                                                    {'loss': 0.0247, 'grad_norm': 3.8197484016418457, 'learning_rate': 4.9449152542372885e-05, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [09:39<5:46:23,  3.56s/it]  3%|â–Ž         | 166/6000 [09:43<5:41:01,  3.51s/it]                                                    {'loss': 0.1391, 'grad_norm': 12.102993965148926, 'learning_rate': 4.9440677966101696e-05, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [09:43<5:41:01,  3.51s/it]  3%|â–Ž         | 167/6000 [09:46<5:36:58,  3.47s/it]                                                    {'loss': 0.0475, 'grad_norm': 8.579977989196777, 'learning_rate': 4.9432203389830514e-05, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [09:46<5:36:58,  3.47s/it]  3%|â–Ž         | 168/6000 [09:50<5:35:06,  3.45s/it]                                                    {'loss': 0.186, 'grad_norm': 12.124425888061523, 'learning_rate': 4.9423728813559326e-05, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [09:50<5:35:06,  3.45s/it]  3%|â–Ž         | 169/6000 [09:53<5:46:55,  3.57s/it]                                                    {'loss': 0.1305, 'grad_norm': 10.156246185302734, 'learning_rate': 4.941525423728814e-05, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [09:53<5:46:55,  3.57s/it]  3%|â–Ž         | 170/6000 [09:57<5:39:56,  3.50s/it]                                                    {'loss': 0.0979, 'grad_norm': 6.022751808166504, 'learning_rate': 4.940677966101695e-05, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [09:57<5:39:56,  3.50s/it]  3%|â–Ž         | 171/6000 [10:00<5:37:15,  3.47s/it]                                                    {'loss': 0.0619, 'grad_norm': 5.7440032958984375, 'learning_rate': 4.9398305084745766e-05, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [10:00<5:37:15,  3.47s/it]  3%|â–Ž         | 172/6000 [10:04<5:38:45,  3.49s/it]                                                    {'loss': 0.2503, 'grad_norm': 16.4306697845459, 'learning_rate': 4.938983050847458e-05, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [10:04<5:38:45,  3.49s/it]  3%|â–Ž         | 173/6000 [10:07<5:38:22,  3.48s/it]                                                    {'loss': 0.1025, 'grad_norm': 13.423791885375977, 'learning_rate': 4.9381355932203396e-05, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [10:07<5:38:22,  3.48s/it]  3%|â–Ž         | 174/6000 [10:11<5:57:20,  3.68s/it]                                                    {'loss': 0.0063, 'grad_norm': 0.9153255820274353, 'learning_rate': 4.937288135593221e-05, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [10:11<5:57:20,  3.68s/it]  3%|â–Ž         | 175/6000 [10:15<5:48:24,  3.59s/it]                                                    {'loss': 0.0549, 'grad_norm': 10.919386863708496, 'learning_rate': 4.936440677966102e-05, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [10:15<5:48:24,  3.59s/it]  3%|â–Ž         | 176/6000 [10:18<5:53:03,  3.64s/it]                                                    {'loss': 0.0309, 'grad_norm': 5.279892444610596, 'learning_rate': 4.935593220338983e-05, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [10:18<5:53:03,  3.64s/it]  3%|â–Ž         | 177/6000 [10:22<5:45:07,  3.56s/it]                                                    {'loss': 0.0265, 'grad_norm': 3.816229820251465, 'learning_rate': 4.934745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [10:22<5:45:07,  3.56s/it]  3%|â–Ž         | 178/6000 [10:25<5:41:02,  3.51s/it]                                                    {'loss': 0.0437, 'grad_norm': 6.3283281326293945, 'learning_rate': 4.933898305084746e-05, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [10:25<5:41:02,  3.51s/it]  3%|â–Ž         | 179/6000 [10:29<5:38:39,  3.49s/it]                                                    {'loss': 0.0389, 'grad_norm': 3.4141781330108643, 'learning_rate': 4.933050847457628e-05, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [10:29<5:38:39,  3.49s/it]  3%|â–Ž         | 180/6000 [10:32<5:39:07,  3.50s/it]                                                    {'loss': 0.3049, 'grad_norm': 14.236479759216309, 'learning_rate': 4.932203389830509e-05, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [10:32<5:39:07,  3.50s/it]  3%|â–Ž         | 181/6000 [10:36<5:40:49,  3.51s/it]                                                    {'loss': 0.4157, 'grad_norm': 36.71089172363281, 'learning_rate': 4.9313559322033906e-05, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [10:36<5:40:49,  3.51s/it]  3%|â–Ž         | 182/6000 [10:39<5:37:17,  3.48s/it]                                                    {'loss': 0.0162, 'grad_norm': 1.8799819946289062, 'learning_rate': 4.930508474576271e-05, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [10:39<5:37:17,  3.48s/it]  3%|â–Ž         | 183/6000 [10:42<5:32:27,  3.43s/it]                                                    {'loss': 0.1143, 'grad_norm': 7.877284049987793, 'learning_rate': 4.929661016949153e-05, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [10:42<5:32:27,  3.43s/it]  3%|â–Ž         | 184/6000 [10:46<5:31:57,  3.42s/it]                                                    {'loss': 0.1921, 'grad_norm': 11.574798583984375, 'learning_rate': 4.928813559322034e-05, 'epoch': 0.03}
  3%|â–Ž         | 184/6000 [10:46<5:31:57,  3.42s/it]  3%|â–Ž         | 185/6000 [10:49<5:30:54,  3.41s/it]                                                    {'loss': 0.2367, 'grad_norm': 12.66110897064209, 'learning_rate': 4.927966101694915e-05, 'epoch': 0.03}
  3%|â–Ž         | 185/6000 [10:49<5:30:54,  3.41s/it]  3%|â–Ž         | 186/6000 [10:53<5:31:06,  3.42s/it]                                                    {'loss': 0.0505, 'grad_norm': 10.000287055969238, 'learning_rate': 4.927118644067797e-05, 'epoch': 0.03}
  3%|â–Ž         | 186/6000 [10:53<5:31:06,  3.42s/it]  3%|â–Ž         | 187/6000 [10:56<5:32:28,  3.43s/it]                                                    {'loss': 0.0467, 'grad_norm': 6.941641330718994, 'learning_rate': 4.926271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 187/6000 [10:56<5:32:28,  3.43s/it]  3%|â–Ž         | 188/6000 [11:00<5:33:43,  3.45s/it]                                                    {'loss': 0.0853, 'grad_norm': 9.81301212310791, 'learning_rate': 4.92542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 188/6000 [11:00<5:33:43,  3.45s/it]  3%|â–Ž         | 189/6000 [11:03<5:34:38,  3.46s/it]                                                    {'loss': 0.1364, 'grad_norm': 9.492709159851074, 'learning_rate': 4.924576271186441e-05, 'epoch': 0.03}
  3%|â–Ž         | 189/6000 [11:03<5:34:38,  3.46s/it]  3%|â–Ž         | 190/6000 [11:06<5:30:42,  3.42s/it]                                                    {'loss': 0.0516, 'grad_norm': 6.0499773025512695, 'learning_rate': 4.923728813559322e-05, 'epoch': 0.03}
  3%|â–Ž         | 190/6000 [11:06<5:30:42,  3.42s/it]  3%|â–Ž         | 191/6000 [11:10<5:31:26,  3.42s/it]                                                    {'loss': 0.0831, 'grad_norm': 7.579950332641602, 'learning_rate': 4.922881355932203e-05, 'epoch': 0.03}
  3%|â–Ž         | 191/6000 [11:10<5:31:26,  3.42s/it]  3%|â–Ž         | 192/6000 [11:14<5:48:47,  3.60s/it]                                                    {'loss': 0.1109, 'grad_norm': 10.862943649291992, 'learning_rate': 4.922033898305085e-05, 'epoch': 0.03}
  3%|â–Ž         | 192/6000 [11:14<5:48:47,  3.60s/it]  3%|â–Ž         | 193/6000 [11:18<5:52:04,  3.64s/it]                                                    {'loss': 0.2033, 'grad_norm': 15.833731651306152, 'learning_rate': 4.921186440677966e-05, 'epoch': 0.03}
  3%|â–Ž         | 193/6000 [11:18<5:52:04,  3.64s/it]  3%|â–Ž         | 194/6000 [11:21<5:44:19,  3.56s/it]                                                    {'loss': 0.1541, 'grad_norm': 9.677030563354492, 'learning_rate': 4.920338983050848e-05, 'epoch': 0.03}
  3%|â–Ž         | 194/6000 [11:21<5:44:19,  3.56s/it]  3%|â–Ž         | 195/6000 [11:24<5:41:33,  3.53s/it]                                                    {'loss': 0.0123, 'grad_norm': 1.7775776386260986, 'learning_rate': 4.919491525423729e-05, 'epoch': 0.03}
  3%|â–Ž         | 195/6000 [11:24<5:41:33,  3.53s/it]  3%|â–Ž         | 196/6000 [11:28<5:39:04,  3.51s/it]                                                    {'loss': 0.0346, 'grad_norm': 5.261759281158447, 'learning_rate': 4.91864406779661e-05, 'epoch': 0.03}
  3%|â–Ž         | 196/6000 [11:28<5:39:04,  3.51s/it]  3%|â–Ž         | 197/6000 [11:31<5:40:29,  3.52s/it]                                                    {'loss': 0.0227, 'grad_norm': 2.8805124759674072, 'learning_rate': 4.9177966101694914e-05, 'epoch': 0.03}
  3%|â–Ž         | 197/6000 [11:31<5:40:29,  3.52s/it]  3%|â–Ž         | 198/6000 [11:35<5:40:08,  3.52s/it]                                                    {'loss': 0.0434, 'grad_norm': 8.231870651245117, 'learning_rate': 4.916949152542373e-05, 'epoch': 0.03}
  3%|â–Ž         | 198/6000 [11:35<5:40:08,  3.52s/it]  3%|â–Ž         | 199/6000 [11:38<5:34:50,  3.46s/it]                                                    {'loss': 0.1135, 'grad_norm': 9.01872730255127, 'learning_rate': 4.916101694915254e-05, 'epoch': 0.03}
  3%|â–Ž         | 199/6000 [11:38<5:34:50,  3.46s/it]  3%|â–Ž         | 200/6000 [11:42<5:46:12,  3.58s/it]                                                    {'loss': 0.1125, 'grad_norm': 12.571148872375488, 'learning_rate': 4.915254237288136e-05, 'epoch': 0.03}
  3%|â–Ž         | 200/6000 [11:42<5:46:12,  3.58s/it][2025-10-19 23:48:47,453] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 201/6000 [11:48<6:41:58,  4.16s/it]                                                    {'loss': 0.2496, 'grad_norm': 18.20060920715332, 'learning_rate': 4.914406779661017e-05, 'epoch': 0.03}
  3%|â–Ž         | 201/6000 [11:48<6:41:58,  4.16s/it]  3%|â–Ž         | 202/6000 [11:51<6:17:55,  3.91s/it]                                                    {'loss': 0.1873, 'grad_norm': 15.636065483093262, 'learning_rate': 4.913559322033899e-05, 'epoch': 0.03}
  3%|â–Ž         | 202/6000 [11:51<6:17:55,  3.91s/it]  3%|â–Ž         | 203/6000 [11:54<6:04:32,  3.77s/it]                                                    {'loss': 0.0797, 'grad_norm': 8.929956436157227, 'learning_rate': 4.91271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 203/6000 [11:54<6:04:32,  3.77s/it]  3%|â–Ž         | 204/6000 [11:58<5:56:15,  3.69s/it]                                                    {'loss': 0.0469, 'grad_norm': 4.648304462432861, 'learning_rate': 4.9118644067796607e-05, 'epoch': 0.03}
  3%|â–Ž         | 204/6000 [11:58<5:56:15,  3.69s/it]  3%|â–Ž         | 205/6000 [12:01<5:47:09,  3.59s/it]                                                    {'loss': 0.1847, 'grad_norm': 13.756570816040039, 'learning_rate': 4.9110169491525425e-05, 'epoch': 0.03}
  3%|â–Ž         | 205/6000 [12:01<5:47:09,  3.59s/it]  3%|â–Ž         | 206/6000 [12:05<5:39:20,  3.51s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.3021048903465271, 'learning_rate': 4.9101694915254236e-05, 'epoch': 0.03}
  3%|â–Ž         | 206/6000 [12:05<5:39:20,  3.51s/it]  3%|â–Ž         | 207/6000 [12:08<5:38:48,  3.51s/it]                                                    {'loss': 0.0383, 'grad_norm': 5.8978962898254395, 'learning_rate': 4.9093220338983054e-05, 'epoch': 0.03}
  3%|â–Ž         | 207/6000 [12:08<5:38:48,  3.51s/it]  3%|â–Ž         | 208/6000 [12:12<5:36:09,  3.48s/it]                                                    {'loss': 0.0529, 'grad_norm': 4.02773904800415, 'learning_rate': 4.9084745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 208/6000 [12:12<5:36:09,  3.48s/it]  3%|â–Ž         | 209/6000 [12:15<5:32:07,  3.44s/it]                                                    {'loss': 0.106, 'grad_norm': 9.912096977233887, 'learning_rate': 4.907627118644068e-05, 'epoch': 0.03}
  3%|â–Ž         | 209/6000 [12:15<5:32:07,  3.44s/it]  4%|â–Ž         | 210/6000 [12:19<5:43:22,  3.56s/it]                                                    {'loss': 0.0679, 'grad_norm': 39.364654541015625, 'learning_rate': 4.9067796610169495e-05, 'epoch': 0.04}
  4%|â–Ž         | 210/6000 [12:19<5:43:22,  3.56s/it]  4%|â–Ž         | 211/6000 [12:22<5:44:10,  3.57s/it]                                                    {'loss': 0.0486, 'grad_norm': 5.3708953857421875, 'learning_rate': 4.9059322033898306e-05, 'epoch': 0.04}
  4%|â–Ž         | 211/6000 [12:22<5:44:10,  3.57s/it]  4%|â–Ž         | 212/6000 [12:26<5:52:00,  3.65s/it]                                                    {'loss': 0.1529, 'grad_norm': 7.2151923179626465, 'learning_rate': 4.905084745762712e-05, 'epoch': 0.04}
  4%|â–Ž         | 212/6000 [12:26<5:52:00,  3.65s/it]  4%|â–Ž         | 213/6000 [12:30<5:48:46,  3.62s/it]                                                    {'loss': 0.0264, 'grad_norm': 2.535196542739868, 'learning_rate': 4.9042372881355935e-05, 'epoch': 0.04}
  4%|â–Ž         | 213/6000 [12:30<5:48:46,  3.62s/it]  4%|â–Ž         | 214/6000 [12:33<5:41:32,  3.54s/it]                                                    {'loss': 0.0131, 'grad_norm': 1.6487799882888794, 'learning_rate': 4.9033898305084746e-05, 'epoch': 0.04}
  4%|â–Ž         | 214/6000 [12:33<5:41:32,  3.54s/it]  4%|â–Ž         | 215/6000 [12:36<5:36:49,  3.49s/it]                                                    {'loss': 0.0509, 'grad_norm': 6.716994285583496, 'learning_rate': 4.9025423728813565e-05, 'epoch': 0.04}
  4%|â–Ž         | 215/6000 [12:36<5:36:49,  3.49s/it]  4%|â–Ž         | 216/6000 [12:40<5:34:30,  3.47s/it]                                                    {'loss': 0.0038, 'grad_norm': 0.4979064166545868, 'learning_rate': 4.9016949152542376e-05, 'epoch': 0.04}
  4%|â–Ž         | 216/6000 [12:40<5:34:30,  3.47s/it]  4%|â–Ž         | 217/6000 [12:43<5:37:07,  3.50s/it]                                                    {'loss': 0.0055, 'grad_norm': 1.2094718217849731, 'learning_rate': 4.9008474576271194e-05, 'epoch': 0.04}
  4%|â–Ž         | 217/6000 [12:43<5:37:07,  3.50s/it]  4%|â–Ž         | 218/6000 [12:47<5:36:11,  3.49s/it]                                                    {'loss': 0.0667, 'grad_norm': 9.156444549560547, 'learning_rate': 4.9e-05, 'epoch': 0.04}
  4%|â–Ž         | 218/6000 [12:47<5:36:11,  3.49s/it]  4%|â–Ž         | 219/6000 [12:50<5:30:54,  3.43s/it]                                                    {'loss': 0.1557, 'grad_norm': 13.033605575561523, 'learning_rate': 4.8991525423728816e-05, 'epoch': 0.04}
  4%|â–Ž         | 219/6000 [12:50<5:30:54,  3.43s/it]  4%|â–Ž         | 220/6000 [12:54<5:33:36,  3.46s/it]                                                    {'loss': 0.5318, 'grad_norm': 17.059968948364258, 'learning_rate': 4.898305084745763e-05, 'epoch': 0.04}
  4%|â–Ž         | 220/6000 [12:54<5:33:36,  3.46s/it]  4%|â–Ž         | 221/6000 [12:57<5:31:15,  3.44s/it]                                                    {'loss': 0.0184, 'grad_norm': 2.736295700073242, 'learning_rate': 4.8974576271186446e-05, 'epoch': 0.04}
  4%|â–Ž         | 221/6000 [12:57<5:31:15,  3.44s/it]  4%|â–Ž         | 222/6000 [13:00<5:28:00,  3.41s/it]                                                    {'loss': 0.114, 'grad_norm': 9.514172554016113, 'learning_rate': 4.896610169491526e-05, 'epoch': 0.04}
  4%|â–Ž         | 222/6000 [13:00<5:28:00,  3.41s/it]  4%|â–Ž         | 223/6000 [13:04<5:28:38,  3.41s/it]                                                    {'loss': 0.0481, 'grad_norm': 6.533058166503906, 'learning_rate': 4.8957627118644075e-05, 'epoch': 0.04}
  4%|â–Ž         | 223/6000 [13:04<5:28:38,  3.41s/it]  4%|â–Ž         | 224/6000 [13:07<5:25:25,  3.38s/it]                                                    {'loss': 0.0581, 'grad_norm': 7.995606899261475, 'learning_rate': 4.8949152542372886e-05, 'epoch': 0.04}
  4%|â–Ž         | 224/6000 [13:07<5:25:25,  3.38s/it]  4%|â–         | 225/6000 [13:11<5:32:15,  3.45s/it]                                                    {'loss': 0.1422, 'grad_norm': 8.729475021362305, 'learning_rate': 4.89406779661017e-05, 'epoch': 0.04}
  4%|â–         | 225/6000 [13:11<5:32:15,  3.45s/it]  4%|â–         | 226/6000 [13:15<5:46:24,  3.60s/it]                                                    {'loss': 0.0643, 'grad_norm': 16.32257652282715, 'learning_rate': 4.893220338983051e-05, 'epoch': 0.04}
  4%|â–         | 226/6000 [13:15<5:46:24,  3.60s/it]  4%|â–         | 227/6000 [13:18<5:39:56,  3.53s/it]                                                    {'loss': 0.0269, 'grad_norm': 4.696211338043213, 'learning_rate': 4.892372881355932e-05, 'epoch': 0.04}
  4%|â–         | 227/6000 [13:18<5:39:56,  3.53s/it]  4%|â–         | 228/6000 [13:22<5:37:53,  3.51s/it]                                                    {'loss': 0.0074, 'grad_norm': 1.1739801168441772, 'learning_rate': 4.891525423728814e-05, 'epoch': 0.04}
  4%|â–         | 228/6000 [13:22<5:37:53,  3.51s/it]  4%|â–         | 229/6000 [13:25<5:32:38,  3.46s/it]                                                    {'loss': 0.0552, 'grad_norm': 5.343305587768555, 'learning_rate': 4.890677966101695e-05, 'epoch': 0.04}
  4%|â–         | 229/6000 [13:25<5:32:38,  3.46s/it]  4%|â–         | 230/6000 [13:28<5:34:20,  3.48s/it]                                                    {'loss': 0.0688, 'grad_norm': 9.545557022094727, 'learning_rate': 4.889830508474577e-05, 'epoch': 0.04}
  4%|â–         | 230/6000 [13:28<5:34:20,  3.48s/it]  4%|â–         | 231/6000 [13:32<5:31:31,  3.45s/it]                                                    {'loss': 0.0887, 'grad_norm': 11.370285987854004, 'learning_rate': 4.888983050847458e-05, 'epoch': 0.04}
  4%|â–         | 231/6000 [13:32<5:31:31,  3.45s/it]  4%|â–         | 232/6000 [13:35<5:29:20,  3.43s/it]                                                    {'loss': 0.2338, 'grad_norm': 16.267047882080078, 'learning_rate': 4.888135593220339e-05, 'epoch': 0.04}
  4%|â–         | 232/6000 [13:35<5:29:20,  3.43s/it]  4%|â–         | 233/6000 [13:39<5:41:16,  3.55s/it]                                                    {'loss': 0.0887, 'grad_norm': 9.942121505737305, 'learning_rate': 4.88728813559322e-05, 'epoch': 0.04}
  4%|â–         | 233/6000 [13:39<5:41:16,  3.55s/it]  4%|â–         | 234/6000 [13:43<5:46:30,  3.61s/it]                                                    {'loss': 0.0352, 'grad_norm': 5.3479695320129395, 'learning_rate': 4.886440677966102e-05, 'epoch': 0.04}
  4%|â–         | 234/6000 [13:43<5:46:30,  3.61s/it]  4%|â–         | 235/6000 [13:46<5:38:50,  3.53s/it]                                                    {'loss': 0.2632, 'grad_norm': 14.775995254516602, 'learning_rate': 4.885593220338983e-05, 'epoch': 0.04}
  4%|â–         | 235/6000 [13:46<5:38:50,  3.53s/it]  4%|â–         | 236/6000 [13:50<5:37:20,  3.51s/it]                                                    {'loss': 0.1745, 'grad_norm': 7.708977222442627, 'learning_rate': 4.884745762711865e-05, 'epoch': 0.04}
  4%|â–         | 236/6000 [13:50<5:37:20,  3.51s/it]  4%|â–         | 237/6000 [13:53<5:34:58,  3.49s/it]                                                    {'loss': 0.2117, 'grad_norm': 8.338970184326172, 'learning_rate': 4.883898305084746e-05, 'epoch': 0.04}
  4%|â–         | 237/6000 [13:53<5:34:58,  3.49s/it]  4%|â–         | 238/6000 [13:57<5:45:30,  3.60s/it]                                                    {'loss': 0.1999, 'grad_norm': 8.988521575927734, 'learning_rate': 4.883050847457628e-05, 'epoch': 0.04}
  4%|â–         | 238/6000 [13:57<5:45:30,  3.60s/it]  4%|â–         | 239/6000 [14:00<5:44:12,  3.58s/it]                                                    {'loss': 0.1094, 'grad_norm': 11.13538646697998, 'learning_rate': 4.882203389830508e-05, 'epoch': 0.04}
  4%|â–         | 239/6000 [14:00<5:44:12,  3.58s/it]  4%|â–         | 240/6000 [14:04<5:40:18,  3.54s/it]                                                    {'loss': 0.1447, 'grad_norm': 10.59083080291748, 'learning_rate': 4.88135593220339e-05, 'epoch': 0.04}
  4%|â–         | 240/6000 [14:04<5:40:18,  3.54s/it]  4%|â–         | 241/6000 [14:07<5:39:13,  3.53s/it]                                                    {'loss': 0.0908, 'grad_norm': 6.790722846984863, 'learning_rate': 4.880508474576271e-05, 'epoch': 0.04}
  4%|â–         | 241/6000 [14:07<5:39:13,  3.53s/it]  4%|â–         | 242/6000 [14:11<5:34:18,  3.48s/it]                                                    {'loss': 0.0526, 'grad_norm': 5.380801200866699, 'learning_rate': 4.879661016949153e-05, 'epoch': 0.04}
  4%|â–         | 242/6000 [14:11<5:34:18,  3.48s/it]  4%|â–         | 243/6000 [14:14<5:42:20,  3.57s/it]                                                    {'loss': 0.1231, 'grad_norm': 6.275303840637207, 'learning_rate': 4.878813559322034e-05, 'epoch': 0.04}
  4%|â–         | 243/6000 [14:14<5:42:20,  3.57s/it]  4%|â–         | 244/6000 [14:18<5:37:26,  3.52s/it]                                                    {'loss': 0.0271, 'grad_norm': 2.960747718811035, 'learning_rate': 4.877966101694916e-05, 'epoch': 0.04}
  4%|â–         | 244/6000 [14:18<5:37:26,  3.52s/it]  4%|â–         | 245/6000 [14:21<5:35:00,  3.49s/it]                                                    {'loss': 0.06, 'grad_norm': 5.663773536682129, 'learning_rate': 4.877118644067797e-05, 'epoch': 0.04}
  4%|â–         | 245/6000 [14:21<5:35:00,  3.49s/it]  4%|â–         | 246/6000 [14:25<5:35:57,  3.50s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.39896467328071594, 'learning_rate': 4.876271186440678e-05, 'epoch': 0.04}
  4%|â–         | 246/6000 [14:25<5:35:57,  3.50s/it]  4%|â–         | 247/6000 [14:28<5:36:35,  3.51s/it]                                                    {'loss': 0.0386, 'grad_norm': 6.251395225524902, 'learning_rate': 4.8754237288135593e-05, 'epoch': 0.04}
  4%|â–         | 247/6000 [14:28<5:36:35,  3.51s/it]  4%|â–         | 248/6000 [14:32<5:37:00,  3.52s/it]                                                    {'loss': 0.0316, 'grad_norm': 4.883652210235596, 'learning_rate': 4.8745762711864405e-05, 'epoch': 0.04}
  4%|â–         | 248/6000 [14:32<5:37:00,  3.52s/it]  4%|â–         | 249/6000 [14:35<5:30:54,  3.45s/it]                                                    {'loss': 0.0106, 'grad_norm': 2.2909157276153564, 'learning_rate': 4.873728813559322e-05, 'epoch': 0.04}
  4%|â–         | 249/6000 [14:35<5:30:54,  3.45s/it]  4%|â–         | 250/6000 [14:39<5:29:20,  3.44s/it]                                                    {'loss': 0.03, 'grad_norm': 1.772404432296753, 'learning_rate': 4.8728813559322034e-05, 'epoch': 0.04}
  4%|â–         | 250/6000 [14:39<5:29:20,  3.44s/it][2025-10-19 23:51:43,928] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  4%|â–         | 251/6000 [14:44<6:28:37,  4.06s/it]                                                    {'loss': 0.0335, 'grad_norm': 5.5303449630737305, 'learning_rate': 4.872033898305085e-05, 'epoch': 0.04}
  4%|â–         | 251/6000 [14:44<6:28:37,  4.06s/it]  4%|â–         | 252/6000 [14:48<6:16:12,  3.93s/it]                                                    {'loss': 0.0721, 'grad_norm': 9.304975509643555, 'learning_rate': 4.8711864406779663e-05, 'epoch': 0.04}
  4%|â–         | 252/6000 [14:48<6:16:12,  3.93s/it]  4%|â–         | 253/6000 [14:51<6:02:00,  3.78s/it]                                                    {'loss': 0.0415, 'grad_norm': 4.510632514953613, 'learning_rate': 4.8703389830508475e-05, 'epoch': 0.04}
  4%|â–         | 253/6000 [14:51<6:02:00,  3.78s/it]  4%|â–         | 254/6000 [14:55<5:53:21,  3.69s/it]                                                    {'loss': 0.0988, 'grad_norm': 7.74032735824585, 'learning_rate': 4.8694915254237286e-05, 'epoch': 0.04}
  4%|â–         | 254/6000 [14:55<5:53:21,  3.69s/it]  4%|â–         | 255/6000 [14:58<5:45:19,  3.61s/it]                                                    {'loss': 0.0119, 'grad_norm': 1.4592477083206177, 'learning_rate': 4.8686440677966104e-05, 'epoch': 0.04}
  4%|â–         | 255/6000 [14:58<5:45:19,  3.61s/it]  4%|â–         | 256/6000 [15:02<5:50:20,  3.66s/it]                                                    {'loss': 0.0769, 'grad_norm': 9.210902214050293, 'learning_rate': 4.8677966101694915e-05, 'epoch': 0.04}
  4%|â–         | 256/6000 [15:02<5:50:20,  3.66s/it]  4%|â–         | 257/6000 [15:05<5:43:09,  3.59s/it]                                                    {'loss': 0.0082, 'grad_norm': 1.2659142017364502, 'learning_rate': 4.8669491525423733e-05, 'epoch': 0.04}
  4%|â–         | 257/6000 [15:05<5:43:09,  3.59s/it]  4%|â–         | 258/6000 [15:09<5:37:32,  3.53s/it]                                                    {'loss': 0.0145, 'grad_norm': 1.174040675163269, 'learning_rate': 4.8661016949152545e-05, 'epoch': 0.04}
  4%|â–         | 258/6000 [15:09<5:37:32,  3.53s/it]  4%|â–         | 259/6000 [15:12<5:31:07,  3.46s/it]                                                    {'loss': 0.0066, 'grad_norm': 1.0669106245040894, 'learning_rate': 4.865254237288136e-05, 'epoch': 0.04}
  4%|â–         | 259/6000 [15:12<5:31:07,  3.46s/it]  4%|â–         | 260/6000 [15:15<5:27:57,  3.43s/it]                                                    {'loss': 0.0143, 'grad_norm': 3.1429531574249268, 'learning_rate': 4.8644067796610174e-05, 'epoch': 0.04}
  4%|â–         | 260/6000 [15:15<5:27:57,  3.43s/it]  4%|â–         | 261/6000 [15:19<5:30:06,  3.45s/it]                                                    {'loss': 0.0743, 'grad_norm': 15.36861801147461, 'learning_rate': 4.8635593220338985e-05, 'epoch': 0.04}
  4%|â–         | 261/6000 [15:19<5:30:06,  3.45s/it]  4%|â–         | 262/6000 [15:22<5:28:52,  3.44s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.10850556194782257, 'learning_rate': 4.86271186440678e-05, 'epoch': 0.04}
  4%|â–         | 262/6000 [15:22<5:28:52,  3.44s/it]  4%|â–         | 263/6000 [15:26<5:39:28,  3.55s/it]                                                    {'loss': 0.0229, 'grad_norm': 2.980546236038208, 'learning_rate': 4.8618644067796615e-05, 'epoch': 0.04}
  4%|â–         | 263/6000 [15:26<5:39:28,  3.55s/it]  4%|â–         | 264/6000 [15:29<5:33:08,  3.48s/it]                                                    {'loss': 0.0305, 'grad_norm': 3.751189947128296, 'learning_rate': 4.8610169491525426e-05, 'epoch': 0.04}
  4%|â–         | 264/6000 [15:29<5:33:08,  3.48s/it]  4%|â–         | 265/6000 [15:33<5:35:43,  3.51s/it]                                                    {'loss': 0.026, 'grad_norm': 5.602386474609375, 'learning_rate': 4.8601694915254244e-05, 'epoch': 0.04}
  4%|â–         | 265/6000 [15:33<5:35:43,  3.51s/it]  4%|â–         | 266/6000 [15:37<5:37:52,  3.54s/it]                                                    {'loss': 0.0065, 'grad_norm': 1.1912482976913452, 'learning_rate': 4.8593220338983055e-05, 'epoch': 0.04}
  4%|â–         | 266/6000 [15:37<5:37:52,  3.54s/it]  4%|â–         | 267/6000 [15:40<5:32:09,  3.48s/it]                                                    {'loss': 0.029, 'grad_norm': 2.460433006286621, 'learning_rate': 4.858474576271187e-05, 'epoch': 0.04}
  4%|â–         | 267/6000 [15:40<5:32:09,  3.48s/it]  4%|â–         | 268/6000 [15:43<5:30:51,  3.46s/it]                                                    {'loss': 0.091, 'grad_norm': 10.737092971801758, 'learning_rate': 4.857627118644068e-05, 'epoch': 0.04}
  4%|â–         | 268/6000 [15:43<5:30:51,  3.46s/it]  4%|â–         | 269/6000 [15:47<5:31:31,  3.47s/it]                                                    {'loss': 0.0103, 'grad_norm': 1.65989351272583, 'learning_rate': 4.856779661016949e-05, 'epoch': 0.04}
  4%|â–         | 269/6000 [15:47<5:31:31,  3.47s/it]  4%|â–         | 270/6000 [15:50<5:29:59,  3.46s/it]                                                    {'loss': 0.0494, 'grad_norm': 6.475165843963623, 'learning_rate': 4.855932203389831e-05, 'epoch': 0.04}
  4%|â–         | 270/6000 [15:50<5:29:59,  3.46s/it]  5%|â–         | 271/6000 [15:54<5:29:17,  3.45s/it]                                                    {'loss': 0.0039, 'grad_norm': 0.6533001065254211, 'learning_rate': 4.855084745762712e-05, 'epoch': 0.05}
  5%|â–         | 271/6000 [15:54<5:29:17,  3.45s/it]  5%|â–         | 272/6000 [15:57<5:27:01,  3.43s/it]                                                    {'loss': 0.0689, 'grad_norm': 6.854027271270752, 'learning_rate': 4.8542372881355937e-05, 'epoch': 0.05}
  5%|â–         | 272/6000 [15:57<5:27:01,  3.43s/it]  5%|â–         | 273/6000 [16:01<5:29:32,  3.45s/it]                                                    {'loss': 0.0715, 'grad_norm': 7.733933448791504, 'learning_rate': 4.853389830508475e-05, 'epoch': 0.05}
  5%|â–         | 273/6000 [16:01<5:29:32,  3.45s/it]  5%|â–         | 274/6000 [16:04<5:39:21,  3.56s/it]                                                    {'loss': 0.0284, 'grad_norm': 2.5417087078094482, 'learning_rate': 4.8525423728813566e-05, 'epoch': 0.05}
  5%|â–         | 274/6000 [16:04<5:39:21,  3.56s/it]  5%|â–         | 275/6000 [16:08<5:37:21,  3.54s/it]                                                    {'loss': 0.1871, 'grad_norm': 15.2149076461792, 'learning_rate': 4.851694915254237e-05, 'epoch': 0.05}
  5%|â–         | 275/6000 [16:08<5:37:21,  3.54s/it]  5%|â–         | 276/6000 [16:11<5:35:52,  3.52s/it]                                                    {'loss': 0.0889, 'grad_norm': 6.6293535232543945, 'learning_rate': 4.850847457627119e-05, 'epoch': 0.05}
  5%|â–         | 276/6000 [16:11<5:35:52,  3.52s/it]  5%|â–         | 277/6000 [16:15<5:30:23,  3.46s/it]                                                    {'loss': 0.1188, 'grad_norm': 7.717788219451904, 'learning_rate': 4.85e-05, 'epoch': 0.05}
  5%|â–         | 277/6000 [16:15<5:30:23,  3.46s/it]  5%|â–         | 278/6000 [16:18<5:29:18,  3.45s/it]                                                    {'loss': 0.0109, 'grad_norm': 1.4132105112075806, 'learning_rate': 4.849152542372882e-05, 'epoch': 0.05}
  5%|â–         | 278/6000 [16:18<5:29:18,  3.45s/it]  5%|â–         | 279/6000 [16:22<5:29:14,  3.45s/it]                                                    {'loss': 0.1961, 'grad_norm': 6.8189377784729, 'learning_rate': 4.848305084745763e-05, 'epoch': 0.05}
  5%|â–         | 279/6000 [16:22<5:29:14,  3.45s/it]  5%|â–         | 280/6000 [16:25<5:27:55,  3.44s/it]                                                    {'loss': 0.0474, 'grad_norm': 5.376347541809082, 'learning_rate': 4.847457627118645e-05, 'epoch': 0.05}
  5%|â–         | 280/6000 [16:25<5:27:55,  3.44s/it]  5%|â–         | 281/6000 [16:28<5:28:02,  3.44s/it]                                                    {'loss': 0.4317, 'grad_norm': 15.1904878616333, 'learning_rate': 4.846610169491526e-05, 'epoch': 0.05}
  5%|â–         | 281/6000 [16:28<5:28:02,  3.44s/it]  5%|â–         | 282/6000 [16:32<5:40:57,  3.58s/it]                                                    {'loss': 0.172, 'grad_norm': 8.779601097106934, 'learning_rate': 4.845762711864407e-05, 'epoch': 0.05}
  5%|â–         | 282/6000 [16:32<5:40:57,  3.58s/it]  5%|â–         | 283/6000 [16:36<5:46:18,  3.63s/it]                                                    {'loss': 0.0024, 'grad_norm': 0.32368233799934387, 'learning_rate': 4.844915254237288e-05, 'epoch': 0.05}
  5%|â–         | 283/6000 [16:36<5:46:18,  3.63s/it]  5%|â–         | 284/6000 [16:40<5:59:10,  3.77s/it]                                                    {'loss': 0.0707, 'grad_norm': 7.776678085327148, 'learning_rate': 4.84406779661017e-05, 'epoch': 0.05}
  5%|â–         | 284/6000 [16:40<5:59:10,  3.77s/it]  5%|â–         | 285/6000 [16:44<5:52:53,  3.70s/it]                                                    {'loss': 0.095, 'grad_norm': 6.17357873916626, 'learning_rate': 4.843220338983051e-05, 'epoch': 0.05}
  5%|â–         | 285/6000 [16:44<5:52:53,  3.70s/it]  5%|â–         | 286/6000 [16:47<5:43:29,  3.61s/it]                                                    {'loss': 0.1498, 'grad_norm': 11.316941261291504, 'learning_rate': 4.842372881355933e-05, 'epoch': 0.05}
  5%|â–         | 286/6000 [16:47<5:43:29,  3.61s/it]  5%|â–         | 287/6000 [16:50<5:37:33,  3.55s/it]                                                    {'loss': 0.0787, 'grad_norm': 7.3337860107421875, 'learning_rate': 4.841525423728814e-05, 'epoch': 0.05}
  5%|â–         | 287/6000 [16:50<5:37:33,  3.55s/it]  5%|â–         | 288/6000 [16:54<5:33:39,  3.50s/it]                                                    {'loss': 0.0105, 'grad_norm': 2.106003999710083, 'learning_rate': 4.840677966101695e-05, 'epoch': 0.05}
  5%|â–         | 288/6000 [16:54<5:33:39,  3.50s/it]  5%|â–         | 289/6000 [16:57<5:35:24,  3.52s/it]                                                    {'loss': 0.219, 'grad_norm': 15.081960678100586, 'learning_rate': 4.839830508474576e-05, 'epoch': 0.05}
  5%|â–         | 289/6000 [16:57<5:35:24,  3.52s/it]  5%|â–         | 290/6000 [17:01<5:31:08,  3.48s/it]                                                    {'loss': 0.01, 'grad_norm': 1.3189712762832642, 'learning_rate': 4.8389830508474574e-05, 'epoch': 0.05}
  5%|â–         | 290/6000 [17:01<5:31:08,  3.48s/it]  5%|â–         | 291/6000 [17:04<5:28:04,  3.45s/it]                                                    {'loss': 0.221, 'grad_norm': 12.178939819335938, 'learning_rate': 4.838135593220339e-05, 'epoch': 0.05}
  5%|â–         | 291/6000 [17:04<5:28:04,  3.45s/it]  5%|â–         | 292/6000 [17:08<5:25:08,  3.42s/it]                                                    {'loss': 0.0989, 'grad_norm': 8.777409553527832, 'learning_rate': 4.83728813559322e-05, 'epoch': 0.05}
  5%|â–         | 292/6000 [17:08<5:25:08,  3.42s/it]  5%|â–         | 293/6000 [17:11<5:23:26,  3.40s/it]                                                    {'loss': 0.0442, 'grad_norm': 4.757688045501709, 'learning_rate': 4.836440677966102e-05, 'epoch': 0.05}
  5%|â–         | 293/6000 [17:11<5:23:26,  3.40s/it]  5%|â–         | 294/6000 [17:14<5:21:54,  3.38s/it]                                                    {'loss': 0.3988, 'grad_norm': 14.897494316101074, 'learning_rate': 4.835593220338983e-05, 'epoch': 0.05}
  5%|â–         | 294/6000 [17:14<5:21:54,  3.38s/it]  5%|â–         | 295/6000 [17:18<5:20:51,  3.37s/it]                                                    {'loss': 0.0915, 'grad_norm': 5.752946853637695, 'learning_rate': 4.834745762711865e-05, 'epoch': 0.05}
  5%|â–         | 295/6000 [17:18<5:20:51,  3.37s/it]  5%|â–         | 296/6000 [17:21<5:29:14,  3.46s/it]                                                    {'loss': 0.1519, 'grad_norm': 13.770570755004883, 'learning_rate': 4.833898305084746e-05, 'epoch': 0.05}
  5%|â–         | 296/6000 [17:21<5:29:14,  3.46s/it]  5%|â–         | 297/6000 [17:25<5:26:47,  3.44s/it]                                                    {'loss': 0.03, 'grad_norm': 2.1177680492401123, 'learning_rate': 4.833050847457627e-05, 'epoch': 0.05}
  5%|â–         | 297/6000 [17:25<5:26:47,  3.44s/it]  5%|â–         | 298/6000 [17:28<5:31:25,  3.49s/it]                                                    {'loss': 0.0617, 'grad_norm': 3.425386905670166, 'learning_rate': 4.8322033898305084e-05, 'epoch': 0.05}
  5%|â–         | 298/6000 [17:28<5:31:25,  3.49s/it]  5%|â–         | 299/6000 [17:33<5:56:21,  3.75s/it]                                                    {'loss': 0.0676, 'grad_norm': 4.5738959312438965, 'learning_rate': 4.83135593220339e-05, 'epoch': 0.05}
  5%|â–         | 299/6000 [17:33<5:56:21,  3.75s/it]  5%|â–Œ         | 300/6000 [17:36<5:47:04,  3.65s/it]                                                    {'loss': 0.0247, 'grad_norm': 4.09282922744751, 'learning_rate': 4.8305084745762714e-05, 'epoch': 0.05}
  5%|â–Œ         | 300/6000 [17:36<5:47:04,  3.65s/it][2025-10-19 23:54:41,349] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  5%|â–Œ         | 301/6000 [17:42<6:48:13,  4.30s/it]                                                    {'loss': 0.0686, 'grad_norm': 7.190703392028809, 'learning_rate': 4.829661016949153e-05, 'epoch': 0.05}
  5%|â–Œ         | 301/6000 [17:42<6:48:13,  4.30s/it]  5%|â–Œ         | 302/6000 [17:45<6:24:44,  4.05s/it]                                                    {'loss': 0.0706, 'grad_norm': 10.307544708251953, 'learning_rate': 4.828813559322034e-05, 'epoch': 0.05}
  5%|â–Œ         | 302/6000 [17:45<6:24:44,  4.05s/it]  5%|â–Œ         | 303/6000 [17:49<6:05:32,  3.85s/it]                                                    {'loss': 0.0255, 'grad_norm': 3.8517982959747314, 'learning_rate': 4.8279661016949154e-05, 'epoch': 0.05}
  5%|â–Œ         | 303/6000 [17:49<6:05:32,  3.85s/it]  5%|â–Œ         | 304/6000 [17:52<5:54:18,  3.73s/it]                                                    {'loss': 0.0818, 'grad_norm': 7.766205310821533, 'learning_rate': 4.8271186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 304/6000 [17:52<5:54:18,  3.73s/it]  5%|â–Œ         | 305/6000 [17:55<5:42:23,  3.61s/it]                                                    {'loss': 0.1157, 'grad_norm': 9.997625350952148, 'learning_rate': 4.8262711864406784e-05, 'epoch': 0.05}
  5%|â–Œ         | 305/6000 [17:55<5:42:23,  3.61s/it]  5%|â–Œ         | 306/6000 [17:59<5:36:53,  3.55s/it]                                                    {'loss': 0.0128, 'grad_norm': 1.4789810180664062, 'learning_rate': 4.8254237288135595e-05, 'epoch': 0.05}
  5%|â–Œ         | 306/6000 [17:59<5:36:53,  3.55s/it]  5%|â–Œ         | 307/6000 [18:02<5:32:09,  3.50s/it]                                                    {'loss': 0.0226, 'grad_norm': 2.931642532348633, 'learning_rate': 4.824576271186441e-05, 'epoch': 0.05}
  5%|â–Œ         | 307/6000 [18:02<5:32:09,  3.50s/it]  5%|â–Œ         | 308/6000 [18:06<5:28:12,  3.46s/it]                                                    {'loss': 0.0777, 'grad_norm': 5.26341438293457, 'learning_rate': 4.8237288135593224e-05, 'epoch': 0.05}
  5%|â–Œ         | 308/6000 [18:06<5:28:12,  3.46s/it]  5%|â–Œ         | 309/6000 [18:09<5:31:21,  3.49s/it]                                                    {'loss': 0.1433, 'grad_norm': 9.237253189086914, 'learning_rate': 4.8228813559322036e-05, 'epoch': 0.05}
  5%|â–Œ         | 309/6000 [18:09<5:31:21,  3.49s/it]  5%|â–Œ         | 310/6000 [18:13<5:27:03,  3.45s/it]                                                    {'loss': 0.0099, 'grad_norm': 1.2024831771850586, 'learning_rate': 4.822033898305085e-05, 'epoch': 0.05}
  5%|â–Œ         | 310/6000 [18:13<5:27:03,  3.45s/it]  5%|â–Œ         | 311/6000 [18:16<5:24:39,  3.42s/it]                                                    {'loss': 0.1203, 'grad_norm': 6.44085693359375, 'learning_rate': 4.821186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 311/6000 [18:16<5:24:39,  3.42s/it]  5%|â–Œ         | 312/6000 [18:19<5:25:02,  3.43s/it]                                                    {'loss': 0.2256, 'grad_norm': 10.604120254516602, 'learning_rate': 4.8203389830508476e-05, 'epoch': 0.05}
  5%|â–Œ         | 312/6000 [18:19<5:25:02,  3.43s/it]  5%|â–Œ         | 313/6000 [18:23<5:25:58,  3.44s/it]                                                    {'loss': 0.1358, 'grad_norm': 7.174952983856201, 'learning_rate': 4.819491525423729e-05, 'epoch': 0.05}
  5%|â–Œ         | 313/6000 [18:23<5:25:58,  3.44s/it]  5%|â–Œ         | 314/6000 [18:26<5:24:23,  3.42s/it]                                                    {'loss': 0.0692, 'grad_norm': 4.023189544677734, 'learning_rate': 4.8186440677966105e-05, 'epoch': 0.05}
  5%|â–Œ         | 314/6000 [18:26<5:24:23,  3.42s/it]  5%|â–Œ         | 315/6000 [18:30<5:22:05,  3.40s/it]                                                    {'loss': 0.0462, 'grad_norm': 2.4105935096740723, 'learning_rate': 4.817796610169492e-05, 'epoch': 0.05}
  5%|â–Œ         | 315/6000 [18:30<5:22:05,  3.40s/it]  5%|â–Œ         | 316/6000 [18:33<5:21:24,  3.39s/it]                                                    {'loss': 0.0098, 'grad_norm': 1.084634780883789, 'learning_rate': 4.8169491525423735e-05, 'epoch': 0.05}
  5%|â–Œ         | 316/6000 [18:33<5:21:24,  3.39s/it]  5%|â–Œ         | 317/6000 [18:37<5:27:16,  3.46s/it]                                                    {'loss': 0.0325, 'grad_norm': 3.676391124725342, 'learning_rate': 4.8161016949152546e-05, 'epoch': 0.05}
  5%|â–Œ         | 317/6000 [18:37<5:27:16,  3.46s/it]  5%|â–Œ         | 318/6000 [18:40<5:35:52,  3.55s/it]                                                    {'loss': 0.0165, 'grad_norm': 2.0532219409942627, 'learning_rate': 4.815254237288136e-05, 'epoch': 0.05}
  5%|â–Œ         | 318/6000 [18:40<5:35:52,  3.55s/it]  5%|â–Œ         | 319/6000 [18:44<5:31:34,  3.50s/it]                                                    {'loss': 0.4673, 'grad_norm': 13.399561882019043, 'learning_rate': 4.814406779661017e-05, 'epoch': 0.05}
  5%|â–Œ         | 319/6000 [18:44<5:31:34,  3.50s/it]  5%|â–Œ         | 320/6000 [18:47<5:30:24,  3.49s/it]                                                    {'loss': 0.0967, 'grad_norm': 8.814743995666504, 'learning_rate': 4.813559322033899e-05, 'epoch': 0.05}
  5%|â–Œ         | 320/6000 [18:47<5:30:24,  3.49s/it]  5%|â–Œ         | 321/6000 [18:51<5:41:31,  3.61s/it]                                                    {'loss': 0.0173, 'grad_norm': 2.7258834838867188, 'learning_rate': 4.81271186440678e-05, 'epoch': 0.05}
  5%|â–Œ         | 321/6000 [18:51<5:41:31,  3.61s/it]  5%|â–Œ         | 322/6000 [18:54<5:36:18,  3.55s/it]                                                    {'loss': 0.06, 'grad_norm': 6.550939083099365, 'learning_rate': 4.8118644067796616e-05, 'epoch': 0.05}
  5%|â–Œ         | 322/6000 [18:54<5:36:18,  3.55s/it]  5%|â–Œ         | 323/6000 [18:59<5:51:04,  3.71s/it]                                                    {'loss': 0.0406, 'grad_norm': 4.8416876792907715, 'learning_rate': 4.811016949152543e-05, 'epoch': 0.05}
  5%|â–Œ         | 323/6000 [18:59<5:51:04,  3.71s/it]  5%|â–Œ         | 324/6000 [19:02<5:42:04,  3.62s/it]                                                    {'loss': 0.1369, 'grad_norm': 9.18871021270752, 'learning_rate': 4.810169491525424e-05, 'epoch': 0.05}
  5%|â–Œ         | 324/6000 [19:02<5:42:04,  3.62s/it]  5%|â–Œ         | 325/6000 [19:05<5:36:20,  3.56s/it]                                                    {'loss': 0.0834, 'grad_norm': 7.531654357910156, 'learning_rate': 4.809322033898305e-05, 'epoch': 0.05}
  5%|â–Œ         | 325/6000 [19:05<5:36:20,  3.56s/it]  5%|â–Œ         | 326/6000 [19:09<5:30:08,  3.49s/it]                                                    {'loss': 0.1957, 'grad_norm': 15.715275764465332, 'learning_rate': 4.808474576271187e-05, 'epoch': 0.05}
  5%|â–Œ         | 326/6000 [19:09<5:30:08,  3.49s/it]  5%|â–Œ         | 327/6000 [19:12<5:25:41,  3.44s/it]                                                    {'loss': 0.0566, 'grad_norm': 4.5931396484375, 'learning_rate': 4.807627118644068e-05, 'epoch': 0.05}
  5%|â–Œ         | 327/6000 [19:12<5:25:41,  3.44s/it]  5%|â–Œ         | 328/6000 [19:15<5:25:40,  3.45s/it]                                                    {'loss': 0.0036, 'grad_norm': 0.42066559195518494, 'learning_rate': 4.80677966101695e-05, 'epoch': 0.05}
  5%|â–Œ         | 328/6000 [19:15<5:25:40,  3.45s/it]  5%|â–Œ         | 329/6000 [19:19<5:23:13,  3.42s/it]                                                    {'loss': 0.0732, 'grad_norm': 7.990554332733154, 'learning_rate': 4.805932203389831e-05, 'epoch': 0.05}
  5%|â–Œ         | 329/6000 [19:19<5:23:13,  3.42s/it]  6%|â–Œ         | 330/6000 [19:22<5:22:31,  3.41s/it]                                                    {'loss': 0.0456, 'grad_norm': 5.655594825744629, 'learning_rate': 4.805084745762712e-05, 'epoch': 0.06}
  6%|â–Œ         | 330/6000 [19:22<5:22:31,  3.41s/it]  6%|â–Œ         | 331/6000 [19:26<5:21:24,  3.40s/it]                                                    {'loss': 0.1471, 'grad_norm': 19.381359100341797, 'learning_rate': 4.804237288135594e-05, 'epoch': 0.06}
  6%|â–Œ         | 331/6000 [19:26<5:21:24,  3.40s/it]  6%|â–Œ         | 332/6000 [19:29<5:23:36,  3.43s/it]                                                    {'loss': 0.0509, 'grad_norm': 2.966784715652466, 'learning_rate': 4.803389830508474e-05, 'epoch': 0.06}
  6%|â–Œ         | 332/6000 [19:29<5:23:36,  3.43s/it]  6%|â–Œ         | 333/6000 [19:32<5:22:41,  3.42s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.5240155458450317, 'learning_rate': 4.802542372881356e-05, 'epoch': 0.06}
  6%|â–Œ         | 333/6000 [19:32<5:22:41,  3.42s/it]  6%|â–Œ         | 334/6000 [19:36<5:22:18,  3.41s/it]                                                    {'loss': 0.0268, 'grad_norm': 1.4361443519592285, 'learning_rate': 4.801694915254237e-05, 'epoch': 0.06}
  6%|â–Œ         | 334/6000 [19:36<5:22:18,  3.41s/it]  6%|â–Œ         | 335/6000 [19:39<5:22:59,  3.42s/it]                                                    {'loss': 0.009, 'grad_norm': 0.7649107575416565, 'learning_rate': 4.800847457627119e-05, 'epoch': 0.06}
  6%|â–Œ         | 335/6000 [19:39<5:22:59,  3.42s/it]  6%|â–Œ         | 336/6000 [19:43<5:19:35,  3.39s/it]                                                    {'loss': 0.1231, 'grad_norm': 8.902287483215332, 'learning_rate': 4.8e-05, 'epoch': 0.06}
  6%|â–Œ         | 336/6000 [19:43<5:19:35,  3.39s/it]  6%|â–Œ         | 337/6000 [19:46<5:23:04,  3.42s/it]                                                    {'loss': 0.0153, 'grad_norm': 0.9053710699081421, 'learning_rate': 4.799152542372882e-05, 'epoch': 0.06}
  6%|â–Œ         | 337/6000 [19:46<5:23:04,  3.42s/it]  6%|â–Œ         | 338/6000 [19:49<5:21:23,  3.41s/it]                                                    {'loss': 0.0865, 'grad_norm': 5.558671951293945, 'learning_rate': 4.798305084745763e-05, 'epoch': 0.06}
  6%|â–Œ         | 338/6000 [19:49<5:21:23,  3.41s/it]  6%|â–Œ         | 339/6000 [19:53<5:21:12,  3.40s/it]                                                    {'loss': 0.0057, 'grad_norm': 0.7231600880622864, 'learning_rate': 4.797457627118644e-05, 'epoch': 0.06}
  6%|â–Œ         | 339/6000 [19:53<5:21:12,  3.40s/it]  6%|â–Œ         | 340/6000 [19:57<5:29:06,  3.49s/it]                                                    {'loss': 0.0487, 'grad_norm': 4.635789394378662, 'learning_rate': 4.796610169491525e-05, 'epoch': 0.06}
  6%|â–Œ         | 340/6000 [19:57<5:29:06,  3.49s/it]  6%|â–Œ         | 341/6000 [20:00<5:25:30,  3.45s/it]                                                    {'loss': 0.0089, 'grad_norm': 0.8863077163696289, 'learning_rate': 4.795762711864407e-05, 'epoch': 0.06}
  6%|â–Œ         | 341/6000 [20:00<5:25:30,  3.45s/it]  6%|â–Œ         | 342/6000 [20:03<5:21:25,  3.41s/it]                                                    {'loss': 0.2799, 'grad_norm': 11.117267608642578, 'learning_rate': 4.794915254237288e-05, 'epoch': 0.06}
  6%|â–Œ         | 342/6000 [20:03<5:21:25,  3.41s/it]  6%|â–Œ         | 343/6000 [20:07<5:38:59,  3.60s/it]                                                    {'loss': 0.1411, 'grad_norm': 12.330510139465332, 'learning_rate': 4.79406779661017e-05, 'epoch': 0.06}
  6%|â–Œ         | 343/6000 [20:07<5:38:59,  3.60s/it]  6%|â–Œ         | 344/6000 [20:11<5:33:12,  3.53s/it]                                                    {'loss': 0.1363, 'grad_norm': 8.972390174865723, 'learning_rate': 4.793220338983051e-05, 'epoch': 0.06}
  6%|â–Œ         | 344/6000 [20:11<5:33:12,  3.53s/it]  6%|â–Œ         | 345/6000 [20:14<5:27:05,  3.47s/it]                                                    {'loss': 0.142, 'grad_norm': 14.500619888305664, 'learning_rate': 4.792372881355933e-05, 'epoch': 0.06}
  6%|â–Œ         | 345/6000 [20:14<5:27:05,  3.47s/it]  6%|â–Œ         | 346/6000 [20:17<5:25:54,  3.46s/it]                                                    {'loss': 0.0673, 'grad_norm': 5.360658168792725, 'learning_rate': 4.7915254237288134e-05, 'epoch': 0.06}
  6%|â–Œ         | 346/6000 [20:17<5:25:54,  3.46s/it]  6%|â–Œ         | 347/6000 [20:21<5:21:49,  3.42s/it]                                                    {'loss': 0.01, 'grad_norm': 1.775093913078308, 'learning_rate': 4.790677966101695e-05, 'epoch': 0.06}
  6%|â–Œ         | 347/6000 [20:21<5:21:49,  3.42s/it]  6%|â–Œ         | 348/6000 [20:24<5:24:18,  3.44s/it]                                                    {'loss': 0.0448, 'grad_norm': 6.608954429626465, 'learning_rate': 4.7898305084745764e-05, 'epoch': 0.06}
  6%|â–Œ         | 348/6000 [20:24<5:24:18,  3.44s/it]  6%|â–Œ         | 349/6000 [20:28<5:24:23,  3.44s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.47834157943725586, 'learning_rate': 4.788983050847458e-05, 'epoch': 0.06}
  6%|â–Œ         | 349/6000 [20:28<5:24:23,  3.44s/it]  6%|â–Œ         | 350/6000 [20:31<5:22:39,  3.43s/it]                                                    {'loss': 0.1756, 'grad_norm': 9.59128189086914, 'learning_rate': 4.788135593220339e-05, 'epoch': 0.06}
  6%|â–Œ         | 350/6000 [20:31<5:22:39,  3.43s/it][2025-10-19 23:57:36,408] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  6%|â–Œ         | 351/6000 [20:37<6:29:56,  4.14s/it]                                                    {'loss': 0.1573, 'grad_norm': 12.001639366149902, 'learning_rate': 4.7872881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 351/6000 [20:37<6:29:56,  4.14s/it]  6%|â–Œ         | 352/6000 [20:40<6:06:01,  3.89s/it]                                                    {'loss': 0.0823, 'grad_norm': 8.068408966064453, 'learning_rate': 4.786440677966102e-05, 'epoch': 0.06}
  6%|â–Œ         | 352/6000 [20:40<6:06:01,  3.89s/it]  6%|â–Œ         | 353/6000 [20:43<5:48:33,  3.70s/it]                                                    {'loss': 0.0571, 'grad_norm': 3.913452625274658, 'learning_rate': 4.7855932203389834e-05, 'epoch': 0.06}
  6%|â–Œ         | 353/6000 [20:43<5:48:33,  3.70s/it]  6%|â–Œ         | 354/6000 [20:47<5:37:46,  3.59s/it]                                                    {'loss': 0.0261, 'grad_norm': 1.9175827503204346, 'learning_rate': 4.7847457627118645e-05, 'epoch': 0.06}
  6%|â–Œ         | 354/6000 [20:47<5:37:46,  3.59s/it]  6%|â–Œ         | 355/6000 [20:50<5:28:31,  3.49s/it]                                                    {'loss': 0.0149, 'grad_norm': 3.136979579925537, 'learning_rate': 4.7838983050847456e-05, 'epoch': 0.06}
  6%|â–Œ         | 355/6000 [20:50<5:28:31,  3.49s/it]  6%|â–Œ         | 356/6000 [20:54<5:31:07,  3.52s/it]                                                    {'loss': 0.0212, 'grad_norm': 3.594944477081299, 'learning_rate': 4.7830508474576274e-05, 'epoch': 0.06}
  6%|â–Œ         | 356/6000 [20:54<5:31:07,  3.52s/it]  6%|â–Œ         | 357/6000 [20:57<5:28:17,  3.49s/it]                                                    {'loss': 0.0569, 'grad_norm': 6.653343677520752, 'learning_rate': 4.7822033898305086e-05, 'epoch': 0.06}
  6%|â–Œ         | 357/6000 [20:57<5:28:17,  3.49s/it]  6%|â–Œ         | 358/6000 [21:00<5:23:40,  3.44s/it]                                                    {'loss': 0.021, 'grad_norm': 2.4520859718322754, 'learning_rate': 4.7813559322033904e-05, 'epoch': 0.06}
  6%|â–Œ         | 358/6000 [21:00<5:23:40,  3.44s/it]  6%|â–Œ         | 359/6000 [21:04<5:22:53,  3.43s/it]                                                    {'loss': 0.0523, 'grad_norm': 7.194759845733643, 'learning_rate': 4.7805084745762715e-05, 'epoch': 0.06}
  6%|â–Œ         | 359/6000 [21:04<5:22:53,  3.43s/it]  6%|â–Œ         | 360/6000 [21:07<5:19:52,  3.40s/it]                                                    {'loss': 0.1953, 'grad_norm': 9.243268013000488, 'learning_rate': 4.7796610169491526e-05, 'epoch': 0.06}
  6%|â–Œ         | 360/6000 [21:07<5:19:52,  3.40s/it]  6%|â–Œ         | 361/6000 [21:10<5:17:56,  3.38s/it]                                                    {'loss': 0.1613, 'grad_norm': 11.722933769226074, 'learning_rate': 4.778813559322034e-05, 'epoch': 0.06}
  6%|â–Œ         | 361/6000 [21:10<5:17:56,  3.38s/it]  6%|â–Œ         | 362/6000 [21:14<5:16:27,  3.37s/it]                                                    {'loss': 0.1988, 'grad_norm': 6.461869239807129, 'learning_rate': 4.7779661016949156e-05, 'epoch': 0.06}
  6%|â–Œ         | 362/6000 [21:14<5:16:27,  3.37s/it]  6%|â–Œ         | 363/6000 [21:17<5:16:30,  3.37s/it]                                                    {'loss': 0.006, 'grad_norm': 0.8487610220909119, 'learning_rate': 4.777118644067797e-05, 'epoch': 0.06}
  6%|â–Œ         | 363/6000 [21:17<5:16:30,  3.37s/it]  6%|â–Œ         | 364/6000 [21:21<5:20:50,  3.42s/it]                                                    {'loss': 0.0684, 'grad_norm': 8.638143539428711, 'learning_rate': 4.7762711864406785e-05, 'epoch': 0.06}
  6%|â–Œ         | 364/6000 [21:21<5:20:50,  3.42s/it]  6%|â–Œ         | 365/6000 [21:24<5:20:51,  3.42s/it]                                                    {'loss': 0.028, 'grad_norm': 4.353572368621826, 'learning_rate': 4.7754237288135596e-05, 'epoch': 0.06}
  6%|â–Œ         | 365/6000 [21:24<5:20:51,  3.42s/it]  6%|â–Œ         | 366/6000 [21:27<5:18:57,  3.40s/it]                                                    {'loss': 0.0209, 'grad_norm': 2.553992509841919, 'learning_rate': 4.7745762711864414e-05, 'epoch': 0.06}
  6%|â–Œ         | 366/6000 [21:27<5:18:57,  3.40s/it]  6%|â–Œ         | 367/6000 [21:31<5:19:20,  3.40s/it]                                                    {'loss': 0.0573, 'grad_norm': 6.792778968811035, 'learning_rate': 4.773728813559322e-05, 'epoch': 0.06}
  6%|â–Œ         | 367/6000 [21:31<5:19:20,  3.40s/it]  6%|â–Œ         | 368/6000 [21:35<5:31:35,  3.53s/it]                                                    {'loss': 0.1133, 'grad_norm': 9.123258590698242, 'learning_rate': 4.772881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 368/6000 [21:35<5:31:35,  3.53s/it]  6%|â–Œ         | 369/6000 [21:38<5:26:35,  3.48s/it]                                                    {'loss': 0.0734, 'grad_norm': 5.038222312927246, 'learning_rate': 4.772033898305085e-05, 'epoch': 0.06}
  6%|â–Œ         | 369/6000 [21:38<5:26:35,  3.48s/it]  6%|â–Œ         | 370/6000 [21:41<5:24:34,  3.46s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.20911534130573273, 'learning_rate': 4.7711864406779666e-05, 'epoch': 0.06}
  6%|â–Œ         | 370/6000 [21:41<5:24:34,  3.46s/it]  6%|â–Œ         | 371/6000 [21:45<5:23:24,  3.45s/it]                                                    {'loss': 0.0184, 'grad_norm': 2.1031641960144043, 'learning_rate': 4.770338983050848e-05, 'epoch': 0.06}
  6%|â–Œ         | 371/6000 [21:45<5:23:24,  3.45s/it]  6%|â–Œ         | 372/6000 [21:48<5:21:57,  3.43s/it]                                                    {'loss': 0.0044, 'grad_norm': 0.6986923217773438, 'learning_rate': 4.769491525423729e-05, 'epoch': 0.06}
  6%|â–Œ         | 372/6000 [21:48<5:21:57,  3.43s/it]  6%|â–Œ         | 373/6000 [21:52<5:19:24,  3.41s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.44152453541755676, 'learning_rate': 4.768644067796611e-05, 'epoch': 0.06}
  6%|â–Œ         | 373/6000 [21:52<5:19:24,  3.41s/it]  6%|â–Œ         | 374/6000 [21:55<5:20:13,  3.42s/it]                                                    {'loss': 0.2849, 'grad_norm': 12.746193885803223, 'learning_rate': 4.767796610169492e-05, 'epoch': 0.06}
  6%|â–Œ         | 374/6000 [21:55<5:20:13,  3.42s/it]  6%|â–‹         | 375/6000 [21:59<5:20:18,  3.42s/it]                                                    {'loss': 0.0633, 'grad_norm': 6.179182052612305, 'learning_rate': 4.766949152542373e-05, 'epoch': 0.06}
  6%|â–‹         | 375/6000 [21:59<5:20:18,  3.42s/it]  6%|â–‹         | 376/6000 [22:02<5:18:19,  3.40s/it]                                                    {'loss': 0.0186, 'grad_norm': 1.917980670928955, 'learning_rate': 4.766101694915254e-05, 'epoch': 0.06}
  6%|â–‹         | 376/6000 [22:02<5:18:19,  3.40s/it]  6%|â–‹         | 377/6000 [22:05<5:17:21,  3.39s/it]                                                    {'loss': 0.0099, 'grad_norm': 1.9390629529953003, 'learning_rate': 4.765254237288136e-05, 'epoch': 0.06}
  6%|â–‹         | 377/6000 [22:05<5:17:21,  3.39s/it]  6%|â–‹         | 378/6000 [22:09<5:25:44,  3.48s/it]                                                    {'loss': 0.0518, 'grad_norm': 4.343812465667725, 'learning_rate': 4.764406779661017e-05, 'epoch': 0.06}
  6%|â–‹         | 378/6000 [22:09<5:25:44,  3.48s/it]  6%|â–‹         | 379/6000 [22:12<5:24:22,  3.46s/it]                                                    {'loss': 0.0011, 'grad_norm': 0.140883669257164, 'learning_rate': 4.763559322033899e-05, 'epoch': 0.06}
  6%|â–‹         | 379/6000 [22:12<5:24:22,  3.46s/it]  6%|â–‹         | 380/6000 [22:16<5:33:34,  3.56s/it]                                                    {'loss': 0.0532, 'grad_norm': 4.369194507598877, 'learning_rate': 4.76271186440678e-05, 'epoch': 0.06}
  6%|â–‹         | 380/6000 [22:16<5:33:34,  3.56s/it]  6%|â–‹         | 381/6000 [22:20<5:29:27,  3.52s/it]                                                    {'loss': 0.0282, 'grad_norm': 3.883727550506592, 'learning_rate': 4.761864406779661e-05, 'epoch': 0.06}
  6%|â–‹         | 381/6000 [22:20<5:29:27,  3.52s/it]  6%|â–‹         | 382/6000 [22:23<5:26:20,  3.49s/it]                                                    {'loss': 0.038, 'grad_norm': 5.473258972167969, 'learning_rate': 4.761016949152542e-05, 'epoch': 0.06}
  6%|â–‹         | 382/6000 [22:23<5:26:20,  3.49s/it]  6%|â–‹         | 383/6000 [22:26<5:24:03,  3.46s/it]                                                    {'loss': 0.0624, 'grad_norm': 6.697542667388916, 'learning_rate': 4.760169491525424e-05, 'epoch': 0.06}
  6%|â–‹         | 383/6000 [22:26<5:24:03,  3.46s/it]  6%|â–‹         | 384/6000 [22:30<5:24:48,  3.47s/it]                                                    {'loss': 0.0407, 'grad_norm': 5.15773344039917, 'learning_rate': 4.759322033898305e-05, 'epoch': 0.06}
  6%|â–‹         | 384/6000 [22:30<5:24:48,  3.47s/it]  6%|â–‹         | 385/6000 [22:34<5:33:46,  3.57s/it]                                                    {'loss': 0.0101, 'grad_norm': 1.9038461446762085, 'learning_rate': 4.758474576271187e-05, 'epoch': 0.06}
  6%|â–‹         | 385/6000 [22:34<5:33:46,  3.57s/it]  6%|â–‹         | 386/6000 [22:37<5:30:20,  3.53s/it]                                                    {'loss': 0.006, 'grad_norm': 1.013858437538147, 'learning_rate': 4.757627118644068e-05, 'epoch': 0.06}
  6%|â–‹         | 386/6000 [22:37<5:30:20,  3.53s/it]  6%|â–‹         | 387/6000 [22:41<5:39:57,  3.63s/it]                                                    {'loss': 0.0337, 'grad_norm': 4.720540523529053, 'learning_rate': 4.75677966101695e-05, 'epoch': 0.06}
  6%|â–‹         | 387/6000 [22:41<5:39:57,  3.63s/it]  6%|â–‹         | 388/6000 [22:45<5:37:54,  3.61s/it]                                                    {'loss': 0.021, 'grad_norm': 2.9485480785369873, 'learning_rate': 4.755932203389831e-05, 'epoch': 0.06}
  6%|â–‹         | 388/6000 [22:45<5:37:54,  3.61s/it]  6%|â–‹         | 389/6000 [22:48<5:30:49,  3.54s/it]                                                    {'loss': 0.0188, 'grad_norm': 3.0737686157226562, 'learning_rate': 4.755084745762712e-05, 'epoch': 0.06}
  6%|â–‹         | 389/6000 [22:48<5:30:49,  3.54s/it]  6%|â–‹         | 390/6000 [22:51<5:29:43,  3.53s/it]                                                    {'loss': 0.0087, 'grad_norm': 1.5079020261764526, 'learning_rate': 4.754237288135593e-05, 'epoch': 0.07}
  6%|â–‹         | 390/6000 [22:51<5:29:43,  3.53s/it]  7%|â–‹         | 391/6000 [22:55<5:23:25,  3.46s/it]                                                    {'loss': 0.4473, 'grad_norm': 15.635903358459473, 'learning_rate': 4.7533898305084744e-05, 'epoch': 0.07}
  7%|â–‹         | 391/6000 [22:55<5:23:25,  3.46s/it]  7%|â–‹         | 392/6000 [22:58<5:24:44,  3.47s/it]                                                    {'loss': 0.001, 'grad_norm': 0.12112053483724594, 'learning_rate': 4.752542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 392/6000 [22:58<5:24:44,  3.47s/it]  7%|â–‹         | 393/6000 [23:02<5:24:02,  3.47s/it]                                                    {'loss': 0.022, 'grad_norm': 3.6615471839904785, 'learning_rate': 4.751694915254237e-05, 'epoch': 0.07}
  7%|â–‹         | 393/6000 [23:02<5:24:02,  3.47s/it]  7%|â–‹         | 394/6000 [23:05<5:24:41,  3.48s/it]                                                    {'loss': 0.128, 'grad_norm': 8.015274047851562, 'learning_rate': 4.750847457627119e-05, 'epoch': 0.07}
  7%|â–‹         | 394/6000 [23:05<5:24:41,  3.48s/it]  7%|â–‹         | 395/6000 [23:09<5:21:44,  3.44s/it]                                                    {'loss': 0.0794, 'grad_norm': 8.416985511779785, 'learning_rate': 4.75e-05, 'epoch': 0.07}
  7%|â–‹         | 395/6000 [23:09<5:21:44,  3.44s/it]  7%|â–‹         | 396/6000 [23:12<5:21:46,  3.45s/it]                                                    {'loss': 0.032, 'grad_norm': 2.7756187915802, 'learning_rate': 4.7491525423728814e-05, 'epoch': 0.07}
  7%|â–‹         | 396/6000 [23:12<5:21:46,  3.45s/it]  7%|â–‹         | 397/6000 [23:16<5:33:37,  3.57s/it]                                                    {'loss': 0.0788, 'grad_norm': 2.910529375076294, 'learning_rate': 4.7483050847457625e-05, 'epoch': 0.07}
  7%|â–‹         | 397/6000 [23:16<5:33:37,  3.57s/it]  7%|â–‹         | 398/6000 [23:19<5:27:07,  3.50s/it]                                                    {'loss': 0.0736, 'grad_norm': 4.439185619354248, 'learning_rate': 4.747457627118644e-05, 'epoch': 0.07}
  7%|â–‹         | 398/6000 [23:19<5:27:07,  3.50s/it]  7%|â–‹         | 399/6000 [23:23<5:24:42,  3.48s/it]                                                    {'loss': 0.1024, 'grad_norm': 8.028230667114258, 'learning_rate': 4.7466101694915255e-05, 'epoch': 0.07}
  7%|â–‹         | 399/6000 [23:23<5:24:42,  3.48s/it]  7%|â–‹         | 400/6000 [23:26<5:23:14,  3.46s/it]                                                    {'loss': 0.004, 'grad_norm': 0.6199868321418762, 'learning_rate': 4.745762711864407e-05, 'epoch': 0.07}
  7%|â–‹         | 400/6000 [23:26<5:23:14,  3.46s/it][2025-10-20 00:00:31,351] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  7%|â–‹         | 401/6000 [23:32<6:19:46,  4.07s/it]                                                    {'loss': 0.0252, 'grad_norm': 1.6827841997146606, 'learning_rate': 4.7449152542372884e-05, 'epoch': 0.07}
  7%|â–‹         | 401/6000 [23:32<6:19:46,  4.07s/it]  7%|â–‹         | 402/6000 [23:35<5:59:11,  3.85s/it]                                                    {'loss': 0.1886, 'grad_norm': 10.022958755493164, 'learning_rate': 4.74406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 402/6000 [23:35<5:59:11,  3.85s/it]  7%|â–‹         | 403/6000 [23:38<5:45:48,  3.71s/it]                                                    {'loss': 0.0897, 'grad_norm': 8.374991416931152, 'learning_rate': 4.7432203389830506e-05, 'epoch': 0.07}
  7%|â–‹         | 403/6000 [23:38<5:45:48,  3.71s/it]  7%|â–‹         | 404/6000 [23:42<5:40:24,  3.65s/it]                                                    {'loss': 0.2087, 'grad_norm': 9.758467674255371, 'learning_rate': 4.7423728813559325e-05, 'epoch': 0.07}
  7%|â–‹         | 404/6000 [23:42<5:40:24,  3.65s/it]  7%|â–‹         | 405/6000 [23:45<5:34:00,  3.58s/it]                                                    {'loss': 0.0395, 'grad_norm': 4.830276966094971, 'learning_rate': 4.7415254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 405/6000 [23:45<5:34:00,  3.58s/it]  7%|â–‹         | 406/6000 [23:49<5:29:25,  3.53s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.0578685998916626, 'learning_rate': 4.7406779661016954e-05, 'epoch': 0.07}
  7%|â–‹         | 406/6000 [23:49<5:29:25,  3.53s/it]  7%|â–‹         | 407/6000 [23:52<5:26:45,  3.51s/it]                                                    {'loss': 0.027, 'grad_norm': 4.431674003601074, 'learning_rate': 4.7398305084745765e-05, 'epoch': 0.07}
  7%|â–‹         | 407/6000 [23:52<5:26:45,  3.51s/it]  7%|â–‹         | 408/6000 [23:56<5:43:09,  3.68s/it]                                                    {'loss': 0.0718, 'grad_norm': 7.518647193908691, 'learning_rate': 4.738983050847458e-05, 'epoch': 0.07}
  7%|â–‹         | 408/6000 [23:56<5:43:09,  3.68s/it]  7%|â–‹         | 409/6000 [24:00<5:38:21,  3.63s/it]                                                    {'loss': 0.0217, 'grad_norm': 2.593024253845215, 'learning_rate': 4.7381355932203395e-05, 'epoch': 0.07}
  7%|â–‹         | 409/6000 [24:00<5:38:21,  3.63s/it]  7%|â–‹         | 410/6000 [24:03<5:30:27,  3.55s/it]                                                    {'loss': 0.0657, 'grad_norm': 4.6606974601745605, 'learning_rate': 4.7372881355932206e-05, 'epoch': 0.07}
  7%|â–‹         | 410/6000 [24:03<5:30:27,  3.55s/it]  7%|â–‹         | 411/6000 [24:07<5:48:25,  3.74s/it]                                                    {'loss': 0.0066, 'grad_norm': 0.8277680277824402, 'learning_rate': 4.736440677966102e-05, 'epoch': 0.07}
  7%|â–‹         | 411/6000 [24:07<5:48:25,  3.74s/it]  7%|â–‹         | 412/6000 [24:10<5:35:57,  3.61s/it]                                                    {'loss': 0.1018, 'grad_norm': 6.2466020584106445, 'learning_rate': 4.735593220338983e-05, 'epoch': 0.07}
  7%|â–‹         | 412/6000 [24:10<5:35:57,  3.61s/it]  7%|â–‹         | 413/6000 [24:14<5:36:52,  3.62s/it]                                                    {'loss': 0.2217, 'grad_norm': 9.932506561279297, 'learning_rate': 4.7347457627118646e-05, 'epoch': 0.07}
  7%|â–‹         | 413/6000 [24:14<5:36:52,  3.62s/it]  7%|â–‹         | 414/6000 [24:18<5:31:26,  3.56s/it]                                                    {'loss': 0.0258, 'grad_norm': 3.3058300018310547, 'learning_rate': 4.733898305084746e-05, 'epoch': 0.07}
  7%|â–‹         | 414/6000 [24:18<5:31:26,  3.56s/it]  7%|â–‹         | 415/6000 [24:21<5:34:50,  3.60s/it]                                                    {'loss': 0.0586, 'grad_norm': 5.356313705444336, 'learning_rate': 4.7330508474576276e-05, 'epoch': 0.07}
  7%|â–‹         | 415/6000 [24:21<5:34:50,  3.60s/it]  7%|â–‹         | 416/6000 [24:25<5:35:56,  3.61s/it]                                                    {'loss': 0.0081, 'grad_norm': 2.131485939025879, 'learning_rate': 4.732203389830509e-05, 'epoch': 0.07}
  7%|â–‹         | 416/6000 [24:25<5:35:56,  3.61s/it]  7%|â–‹         | 417/6000 [24:28<5:30:19,  3.55s/it]                                                    {'loss': 0.0015, 'grad_norm': 0.20296147465705872, 'learning_rate': 4.73135593220339e-05, 'epoch': 0.07}
  7%|â–‹         | 417/6000 [24:28<5:30:19,  3.55s/it]  7%|â–‹         | 418/6000 [24:32<5:26:27,  3.51s/it]                                                    {'loss': 0.0658, 'grad_norm': 5.993596076965332, 'learning_rate': 4.730508474576271e-05, 'epoch': 0.07}
  7%|â–‹         | 418/6000 [24:32<5:26:27,  3.51s/it]  7%|â–‹         | 419/6000 [24:36<5:37:44,  3.63s/it]                                                    {'loss': 0.0318, 'grad_norm': 3.438459634780884, 'learning_rate': 4.729661016949153e-05, 'epoch': 0.07}
  7%|â–‹         | 419/6000 [24:36<5:37:44,  3.63s/it]  7%|â–‹         | 420/6000 [24:39<5:35:35,  3.61s/it]                                                    {'loss': 0.0034, 'grad_norm': 0.4515637755393982, 'learning_rate': 4.728813559322034e-05, 'epoch': 0.07}
  7%|â–‹         | 420/6000 [24:39<5:35:35,  3.61s/it]  7%|â–‹         | 421/6000 [24:43<5:31:40,  3.57s/it]                                                    {'loss': 0.2066, 'grad_norm': 11.793503761291504, 'learning_rate': 4.727966101694916e-05, 'epoch': 0.07}
  7%|â–‹         | 421/6000 [24:43<5:31:40,  3.57s/it]  7%|â–‹         | 422/6000 [24:46<5:27:40,  3.52s/it]                                                    {'loss': 0.2013, 'grad_norm': 10.192066192626953, 'learning_rate': 4.727118644067797e-05, 'epoch': 0.07}
  7%|â–‹         | 422/6000 [24:46<5:27:40,  3.52s/it]  7%|â–‹         | 423/6000 [24:49<5:24:26,  3.49s/it]                                                    {'loss': 0.0758, 'grad_norm': 5.905117511749268, 'learning_rate': 4.7262711864406786e-05, 'epoch': 0.07}
  7%|â–‹         | 423/6000 [24:49<5:24:26,  3.49s/it]  7%|â–‹         | 424/6000 [24:53<5:22:05,  3.47s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.23964343965053558, 'learning_rate': 4.72542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 424/6000 [24:53<5:22:05,  3.47s/it]  7%|â–‹         | 425/6000 [24:56<5:20:37,  3.45s/it]                                                    {'loss': 0.0285, 'grad_norm': 2.0845603942871094, 'learning_rate': 4.724576271186441e-05, 'epoch': 0.07}
  7%|â–‹         | 425/6000 [24:56<5:20:37,  3.45s/it]  7%|â–‹         | 426/6000 [25:00<5:18:21,  3.43s/it]                                                    {'loss': 0.0123, 'grad_norm': 1.8830926418304443, 'learning_rate': 4.723728813559322e-05, 'epoch': 0.07}
  7%|â–‹         | 426/6000 [25:00<5:18:21,  3.43s/it]  7%|â–‹         | 427/6000 [25:03<5:19:05,  3.44s/it]                                                    {'loss': 0.1252, 'grad_norm': 6.738365650177002, 'learning_rate': 4.722881355932204e-05, 'epoch': 0.07}
  7%|â–‹         | 427/6000 [25:03<5:19:05,  3.44s/it]  7%|â–‹         | 428/6000 [25:06<5:17:40,  3.42s/it]                                                    {'loss': 0.0111, 'grad_norm': 2.0646371841430664, 'learning_rate': 4.722033898305085e-05, 'epoch': 0.07}
  7%|â–‹         | 428/6000 [25:07<5:17:40,  3.42s/it]  7%|â–‹         | 429/6000 [25:10<5:15:35,  3.40s/it]                                                    {'loss': 0.015, 'grad_norm': 1.8960005044937134, 'learning_rate': 4.721186440677967e-05, 'epoch': 0.07}
  7%|â–‹         | 429/6000 [25:10<5:15:35,  3.40s/it]  7%|â–‹         | 430/6000 [25:13<5:15:54,  3.40s/it]                                                    {'loss': 0.0855, 'grad_norm': 8.983901977539062, 'learning_rate': 4.720338983050848e-05, 'epoch': 0.07}
  7%|â–‹         | 430/6000 [25:13<5:15:54,  3.40s/it]  7%|â–‹         | 431/6000 [25:17<5:14:35,  3.39s/it]                                                    {'loss': 0.1684, 'grad_norm': 9.797422409057617, 'learning_rate': 4.719491525423729e-05, 'epoch': 0.07}
  7%|â–‹         | 431/6000 [25:17<5:14:35,  3.39s/it]  7%|â–‹         | 432/6000 [25:20<5:16:07,  3.41s/it]                                                    {'loss': 0.1205, 'grad_norm': 8.534058570861816, 'learning_rate': 4.71864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 432/6000 [25:20<5:16:07,  3.41s/it]  7%|â–‹         | 433/6000 [25:23<5:13:59,  3.38s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.19740596413612366, 'learning_rate': 4.717796610169491e-05, 'epoch': 0.07}
  7%|â–‹         | 433/6000 [25:23<5:13:59,  3.38s/it]  7%|â–‹         | 434/6000 [25:27<5:13:46,  3.38s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.3602631688117981, 'learning_rate': 4.716949152542373e-05, 'epoch': 0.07}
  7%|â–‹         | 434/6000 [25:27<5:13:46,  3.38s/it]  7%|â–‹         | 435/6000 [25:30<5:14:09,  3.39s/it]                                                    {'loss': 0.0572, 'grad_norm': 10.237272262573242, 'learning_rate': 4.716101694915254e-05, 'epoch': 0.07}
  7%|â–‹         | 435/6000 [25:30<5:14:09,  3.39s/it]  7%|â–‹         | 436/6000 [25:34<5:16:29,  3.41s/it]                                                    {'loss': 0.0104, 'grad_norm': 1.9719867706298828, 'learning_rate': 4.715254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 436/6000 [25:34<5:16:29,  3.41s/it]  7%|â–‹         | 437/6000 [25:37<5:16:12,  3.41s/it]                                                    {'loss': 0.1173, 'grad_norm': 6.719367027282715, 'learning_rate': 4.714406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 437/6000 [25:37<5:16:12,  3.41s/it]  7%|â–‹         | 438/6000 [25:41<5:19:37,  3.45s/it]                                                    {'loss': 0.022, 'grad_norm': 2.00559663772583, 'learning_rate': 4.713559322033898e-05, 'epoch': 0.07}
  7%|â–‹         | 438/6000 [25:41<5:19:37,  3.45s/it]  7%|â–‹         | 439/6000 [25:44<5:18:08,  3.43s/it]                                                    {'loss': 0.0721, 'grad_norm': 7.64889669418335, 'learning_rate': 4.7127118644067794e-05, 'epoch': 0.07}
  7%|â–‹         | 439/6000 [25:44<5:18:08,  3.43s/it]  7%|â–‹         | 440/6000 [25:47<5:19:56,  3.45s/it]                                                    {'loss': 0.0015, 'grad_norm': 0.1710572987794876, 'learning_rate': 4.711864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 440/6000 [25:47<5:19:56,  3.45s/it]  7%|â–‹         | 441/6000 [25:51<5:26:29,  3.52s/it]                                                    {'loss': 0.0054, 'grad_norm': 0.8126327991485596, 'learning_rate': 4.7110169491525423e-05, 'epoch': 0.07}
  7%|â–‹         | 441/6000 [25:51<5:26:29,  3.52s/it]  7%|â–‹         | 442/6000 [25:55<5:33:37,  3.60s/it]                                                    {'loss': 0.0168, 'grad_norm': 3.2609434127807617, 'learning_rate': 4.710169491525424e-05, 'epoch': 0.07}
  7%|â–‹         | 442/6000 [25:55<5:33:37,  3.60s/it]  7%|â–‹         | 443/6000 [25:58<5:31:04,  3.57s/it]                                                    {'loss': 0.0059, 'grad_norm': 0.8884515762329102, 'learning_rate': 4.709322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 443/6000 [25:58<5:31:04,  3.57s/it]  7%|â–‹         | 444/6000 [26:02<5:26:55,  3.53s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.3641442358493805, 'learning_rate': 4.708474576271187e-05, 'epoch': 0.07}
  7%|â–‹         | 444/6000 [26:02<5:26:55,  3.53s/it]  7%|â–‹         | 445/6000 [26:05<5:26:11,  3.52s/it]                                                    {'loss': 0.1235, 'grad_norm': 9.928277969360352, 'learning_rate': 4.707627118644068e-05, 'epoch': 0.07}
  7%|â–‹         | 445/6000 [26:05<5:26:11,  3.52s/it]  7%|â–‹         | 446/6000 [26:09<5:23:47,  3.50s/it]                                                    {'loss': 0.0232, 'grad_norm': 4.159852504730225, 'learning_rate': 4.7067796610169493e-05, 'epoch': 0.07}
  7%|â–‹         | 446/6000 [26:09<5:23:47,  3.50s/it]  7%|â–‹         | 447/6000 [26:12<5:24:28,  3.51s/it]                                                    {'loss': 0.1666, 'grad_norm': 12.269299507141113, 'learning_rate': 4.7059322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 447/6000 [26:12<5:24:28,  3.51s/it]  7%|â–‹         | 448/6000 [26:16<5:21:50,  3.48s/it]                                                    {'loss': 0.013, 'grad_norm': 2.457150459289551, 'learning_rate': 4.705084745762712e-05, 'epoch': 0.07}
  7%|â–‹         | 448/6000 [26:16<5:21:50,  3.48s/it]  7%|â–‹         | 449/6000 [26:19<5:20:10,  3.46s/it]                                                    {'loss': 0.0381, 'grad_norm': 5.660032749176025, 'learning_rate': 4.7042372881355934e-05, 'epoch': 0.07}
  7%|â–‹         | 449/6000 [26:19<5:20:10,  3.46s/it]  8%|â–Š         | 450/6000 [26:23<5:19:25,  3.45s/it]                                                    {'loss': 0.0534, 'grad_norm': 8.277922630310059, 'learning_rate': 4.703389830508475e-05, 'epoch': 0.07}
  8%|â–Š         | 450/6000 [26:23<5:19:25,  3.45s/it][2025-10-20 00:03:27,950] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 451/6000 [26:28<6:19:35,  4.10s/it]                                                    {'loss': 0.0015, 'grad_norm': 0.3201066553592682, 'learning_rate': 4.702542372881356e-05, 'epoch': 0.08}
  8%|â–Š         | 451/6000 [26:28<6:19:35,  4.10s/it]  8%|â–Š         | 452/6000 [26:32<6:09:21,  3.99s/it]                                                    {'loss': 0.1527, 'grad_norm': 5.439130783081055, 'learning_rate': 4.7016949152542375e-05, 'epoch': 0.08}
  8%|â–Š         | 452/6000 [26:32<6:09:21,  3.99s/it]  8%|â–Š         | 453/6000 [26:35<5:52:57,  3.82s/it]                                                    {'loss': 0.1284, 'grad_norm': 10.979904174804688, 'learning_rate': 4.7008474576271186e-05, 'epoch': 0.08}
  8%|â–Š         | 453/6000 [26:35<5:52:57,  3.82s/it]  8%|â–Š         | 454/6000 [26:39<5:40:08,  3.68s/it]                                                    {'loss': 0.1036, 'grad_norm': 8.772897720336914, 'learning_rate': 4.7e-05, 'epoch': 0.08}
  8%|â–Š         | 454/6000 [26:39<5:40:08,  3.68s/it]  8%|â–Š         | 455/6000 [26:42<5:30:01,  3.57s/it]                                                    {'loss': 0.0051, 'grad_norm': 0.49593865871429443, 'learning_rate': 4.6991525423728815e-05, 'epoch': 0.08}
  8%|â–Š         | 455/6000 [26:42<5:30:01,  3.57s/it]  8%|â–Š         | 456/6000 [26:46<5:29:35,  3.57s/it]                                                    {'loss': 0.299, 'grad_norm': 11.372096061706543, 'learning_rate': 4.6983050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 456/6000 [26:46<5:29:35,  3.57s/it]  8%|â–Š         | 457/6000 [26:49<5:22:07,  3.49s/it]                                                    {'loss': 0.1775, 'grad_norm': 11.010767936706543, 'learning_rate': 4.6974576271186445e-05, 'epoch': 0.08}
  8%|â–Š         | 457/6000 [26:49<5:22:07,  3.49s/it]  8%|â–Š         | 458/6000 [26:52<5:18:06,  3.44s/it]                                                    {'loss': 0.0555, 'grad_norm': 8.020956993103027, 'learning_rate': 4.6966101694915256e-05, 'epoch': 0.08}
  8%|â–Š         | 458/6000 [26:52<5:18:06,  3.44s/it]  8%|â–Š         | 459/6000 [26:56<5:18:45,  3.45s/it]                                                    {'loss': 0.1882, 'grad_norm': 7.957621097564697, 'learning_rate': 4.6957627118644074e-05, 'epoch': 0.08}
  8%|â–Š         | 459/6000 [26:56<5:18:45,  3.45s/it]  8%|â–Š         | 460/6000 [26:59<5:17:10,  3.44s/it]                                                    {'loss': 0.0152, 'grad_norm': 1.7242097854614258, 'learning_rate': 4.694915254237288e-05, 'epoch': 0.08}
  8%|â–Š         | 460/6000 [26:59<5:17:10,  3.44s/it]  8%|â–Š         | 461/6000 [27:03<5:16:03,  3.42s/it]                                                    {'loss': 0.0212, 'grad_norm': 2.1648428440093994, 'learning_rate': 4.6940677966101697e-05, 'epoch': 0.08}
  8%|â–Š         | 461/6000 [27:03<5:16:03,  3.42s/it]  8%|â–Š         | 462/6000 [27:06<5:12:35,  3.39s/it]                                                    {'loss': 0.0581, 'grad_norm': 3.742196559906006, 'learning_rate': 4.693220338983051e-05, 'epoch': 0.08}
  8%|â–Š         | 462/6000 [27:06<5:12:35,  3.39s/it]  8%|â–Š         | 463/6000 [27:09<5:12:41,  3.39s/it]                                                    {'loss': 0.0776, 'grad_norm': 7.222288131713867, 'learning_rate': 4.6923728813559326e-05, 'epoch': 0.08}
  8%|â–Š         | 463/6000 [27:09<5:12:41,  3.39s/it]  8%|â–Š         | 464/6000 [27:13<5:10:31,  3.37s/it]                                                    {'loss': 0.1316, 'grad_norm': 11.151463508605957, 'learning_rate': 4.691525423728814e-05, 'epoch': 0.08}
  8%|â–Š         | 464/6000 [27:13<5:10:31,  3.37s/it]  8%|â–Š         | 465/6000 [27:16<5:15:02,  3.42s/it]                                                    {'loss': 0.1976, 'grad_norm': 11.553593635559082, 'learning_rate': 4.6906779661016955e-05, 'epoch': 0.08}
  8%|â–Š         | 465/6000 [27:16<5:15:02,  3.42s/it]  8%|â–Š         | 466/6000 [27:19<5:15:18,  3.42s/it]                                                    {'loss': 0.0474, 'grad_norm': 4.662613868713379, 'learning_rate': 4.6898305084745767e-05, 'epoch': 0.08}
  8%|â–Š         | 466/6000 [27:19<5:15:18,  3.42s/it]  8%|â–Š         | 467/6000 [27:23<5:23:31,  3.51s/it]                                                    {'loss': 0.1155, 'grad_norm': 8.961441993713379, 'learning_rate': 4.688983050847458e-05, 'epoch': 0.08}
  8%|â–Š         | 467/6000 [27:23<5:23:31,  3.51s/it]  8%|â–Š         | 468/6000 [27:27<5:22:50,  3.50s/it]                                                    {'loss': 0.0635, 'grad_norm': 3.75858211517334, 'learning_rate': 4.688135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 468/6000 [27:27<5:22:50,  3.50s/it]  8%|â–Š         | 469/6000 [27:30<5:19:54,  3.47s/it]                                                    {'loss': 0.1996, 'grad_norm': 9.607441902160645, 'learning_rate': 4.687288135593221e-05, 'epoch': 0.08}
  8%|â–Š         | 469/6000 [27:30<5:19:54,  3.47s/it]  8%|â–Š         | 470/6000 [27:33<5:16:34,  3.43s/it]                                                    {'loss': 0.0091, 'grad_norm': 1.2164207696914673, 'learning_rate': 4.686440677966102e-05, 'epoch': 0.08}
  8%|â–Š         | 470/6000 [27:33<5:16:34,  3.43s/it]  8%|â–Š         | 471/6000 [27:37<5:13:06,  3.40s/it]                                                    {'loss': 0.3002, 'grad_norm': 15.366828918457031, 'learning_rate': 4.6855932203389837e-05, 'epoch': 0.08}
  8%|â–Š         | 471/6000 [27:37<5:13:06,  3.40s/it]  8%|â–Š         | 472/6000 [27:40<5:13:46,  3.41s/it]                                                    {'loss': 0.1949, 'grad_norm': 7.05103874206543, 'learning_rate': 4.684745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 472/6000 [27:40<5:13:46,  3.41s/it]  8%|â–Š         | 473/6000 [27:44<5:17:15,  3.44s/it]                                                    {'loss': 0.2932, 'grad_norm': 13.031399726867676, 'learning_rate': 4.6838983050847466e-05, 'epoch': 0.08}
  8%|â–Š         | 473/6000 [27:44<5:17:15,  3.44s/it]  8%|â–Š         | 474/6000 [27:47<5:14:55,  3.42s/it]                                                    {'loss': 0.0226, 'grad_norm': 2.1939687728881836, 'learning_rate': 4.683050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 474/6000 [27:47<5:14:55,  3.42s/it]  8%|â–Š         | 475/6000 [27:50<5:14:17,  3.41s/it]                                                    {'loss': 0.1275, 'grad_norm': 4.861668586730957, 'learning_rate': 4.682203389830508e-05, 'epoch': 0.08}
  8%|â–Š         | 475/6000 [27:50<5:14:17,  3.41s/it]  8%|â–Š         | 476/6000 [27:54<5:13:35,  3.41s/it]                                                    {'loss': 0.051, 'grad_norm': 6.555978298187256, 'learning_rate': 4.68135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 476/6000 [27:54<5:13:35,  3.41s/it]  8%|â–Š         | 477/6000 [27:57<5:11:27,  3.38s/it]                                                    {'loss': 0.0062, 'grad_norm': 0.9442654848098755, 'learning_rate': 4.680508474576271e-05, 'epoch': 0.08}
  8%|â–Š         | 477/6000 [27:57<5:11:27,  3.38s/it]  8%|â–Š         | 478/6000 [28:01<5:11:06,  3.38s/it]                                                    {'loss': 0.0054, 'grad_norm': 1.4742814302444458, 'learning_rate': 4.679661016949153e-05, 'epoch': 0.08}
  8%|â–Š         | 478/6000 [28:01<5:11:06,  3.38s/it]  8%|â–Š         | 479/6000 [28:04<5:12:44,  3.40s/it]                                                    {'loss': 0.0737, 'grad_norm': 8.81371784210205, 'learning_rate': 4.678813559322034e-05, 'epoch': 0.08}
  8%|â–Š         | 479/6000 [28:04<5:12:44,  3.40s/it]  8%|â–Š         | 480/6000 [28:07<5:12:01,  3.39s/it]                                                    {'loss': 0.0199, 'grad_norm': 2.5351481437683105, 'learning_rate': 4.677966101694916e-05, 'epoch': 0.08}
  8%|â–Š         | 480/6000 [28:07<5:12:01,  3.39s/it]  8%|â–Š         | 481/6000 [28:11<5:16:29,  3.44s/it]                                                    {'loss': 0.0221, 'grad_norm': 5.272186279296875, 'learning_rate': 4.677118644067797e-05, 'epoch': 0.08}
  8%|â–Š         | 481/6000 [28:11<5:16:29,  3.44s/it]  8%|â–Š         | 482/6000 [28:14<5:14:43,  3.42s/it]                                                    {'loss': 0.0248, 'grad_norm': 4.085535526275635, 'learning_rate': 4.676271186440678e-05, 'epoch': 0.08}
  8%|â–Š         | 482/6000 [28:14<5:14:43,  3.42s/it]  8%|â–Š         | 483/6000 [28:18<5:14:30,  3.42s/it]                                                    {'loss': 0.0751, 'grad_norm': 5.110039710998535, 'learning_rate': 4.675423728813559e-05, 'epoch': 0.08}
  8%|â–Š         | 483/6000 [28:18<5:14:30,  3.42s/it]  8%|â–Š         | 484/6000 [28:21<5:20:03,  3.48s/it]                                                    {'loss': 0.0024, 'grad_norm': 0.42012566328048706, 'learning_rate': 4.674576271186441e-05, 'epoch': 0.08}
  8%|â–Š         | 484/6000 [28:21<5:20:03,  3.48s/it]  8%|â–Š         | 485/6000 [28:25<5:32:33,  3.62s/it]                                                    {'loss': 0.0077, 'grad_norm': 0.864611029624939, 'learning_rate': 4.673728813559322e-05, 'epoch': 0.08}
  8%|â–Š         | 485/6000 [28:25<5:32:33,  3.62s/it]  8%|â–Š         | 486/6000 [28:29<5:24:42,  3.53s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.29525095224380493, 'learning_rate': 4.672881355932204e-05, 'epoch': 0.08}
  8%|â–Š         | 486/6000 [28:29<5:24:42,  3.53s/it]  8%|â–Š         | 487/6000 [28:32<5:24:39,  3.53s/it]                                                    {'loss': 0.3203, 'grad_norm': 8.426947593688965, 'learning_rate': 4.672033898305085e-05, 'epoch': 0.08}
  8%|â–Š         | 487/6000 [28:32<5:24:39,  3.53s/it]  8%|â–Š         | 488/6000 [28:36<5:25:31,  3.54s/it]                                                    {'loss': 0.5342, 'grad_norm': 15.707721710205078, 'learning_rate': 4.671186440677966e-05, 'epoch': 0.08}
  8%|â–Š         | 488/6000 [28:36<5:25:31,  3.54s/it]  8%|â–Š         | 489/6000 [28:39<5:23:44,  3.52s/it]                                                    {'loss': 0.0879, 'grad_norm': 6.010833263397217, 'learning_rate': 4.6703389830508474e-05, 'epoch': 0.08}
  8%|â–Š         | 489/6000 [28:39<5:23:44,  3.52s/it]  8%|â–Š         | 490/6000 [28:43<5:22:08,  3.51s/it]                                                    {'loss': 0.095, 'grad_norm': 8.596467971801758, 'learning_rate': 4.669491525423729e-05, 'epoch': 0.08}
  8%|â–Š         | 490/6000 [28:43<5:22:08,  3.51s/it]  8%|â–Š         | 491/6000 [28:46<5:22:39,  3.51s/it]                                                    {'loss': 0.1617, 'grad_norm': 9.620083808898926, 'learning_rate': 4.66864406779661e-05, 'epoch': 0.08}
  8%|â–Š         | 491/6000 [28:46<5:22:39,  3.51s/it]  8%|â–Š         | 492/6000 [28:50<5:19:53,  3.48s/it]                                                    {'loss': 0.0444, 'grad_norm': 4.800119876861572, 'learning_rate': 4.667796610169492e-05, 'epoch': 0.08}
  8%|â–Š         | 492/6000 [28:50<5:19:53,  3.48s/it]  8%|â–Š         | 493/6000 [28:53<5:21:43,  3.51s/it]                                                    {'loss': 0.0857, 'grad_norm': 5.563450813293457, 'learning_rate': 4.666949152542373e-05, 'epoch': 0.08}
  8%|â–Š         | 493/6000 [28:53<5:21:43,  3.51s/it]  8%|â–Š         | 494/6000 [28:57<5:18:42,  3.47s/it]                                                    {'loss': 0.0569, 'grad_norm': 6.321859359741211, 'learning_rate': 4.666101694915255e-05, 'epoch': 0.08}
  8%|â–Š         | 494/6000 [28:57<5:18:42,  3.47s/it]  8%|â–Š         | 495/6000 [29:00<5:21:36,  3.51s/it]                                                    {'loss': 0.0913, 'grad_norm': 11.784954071044922, 'learning_rate': 4.6652542372881355e-05, 'epoch': 0.08}
  8%|â–Š         | 495/6000 [29:00<5:21:36,  3.51s/it]  8%|â–Š         | 496/6000 [29:04<5:18:13,  3.47s/it]                                                    {'loss': 0.0427, 'grad_norm': 6.5358734130859375, 'learning_rate': 4.6644067796610166e-05, 'epoch': 0.08}
  8%|â–Š         | 496/6000 [29:04<5:18:13,  3.47s/it]  8%|â–Š         | 497/6000 [29:07<5:13:19,  3.42s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.7859487533569336, 'learning_rate': 4.6635593220338984e-05, 'epoch': 0.08}
  8%|â–Š         | 497/6000 [29:07<5:13:19,  3.42s/it]  8%|â–Š         | 498/6000 [29:10<5:13:34,  3.42s/it]                                                    {'loss': 0.103, 'grad_norm': 5.787408351898193, 'learning_rate': 4.6627118644067795e-05, 'epoch': 0.08}
  8%|â–Š         | 498/6000 [29:10<5:13:34,  3.42s/it]  8%|â–Š         | 499/6000 [29:14<5:12:20,  3.41s/it]                                                    {'loss': 0.0424, 'grad_norm': 1.8743599653244019, 'learning_rate': 4.6618644067796614e-05, 'epoch': 0.08}
  8%|â–Š         | 499/6000 [29:14<5:12:20,  3.41s/it]  8%|â–Š         | 500/6000 [29:17<5:17:32,  3.46s/it]                                                    {'loss': 0.099, 'grad_norm': 6.774326801300049, 'learning_rate': 4.6610169491525425e-05, 'epoch': 0.08}
  8%|â–Š         | 500/6000 [29:17<5:17:32,  3.46s/it][2025-10-20 00:06:22,561] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 501/6000 [29:23<6:14:12,  4.08s/it]                                                    {'loss': 0.1525, 'grad_norm': 13.119956016540527, 'learning_rate': 4.660169491525424e-05, 'epoch': 0.08}
  8%|â–Š         | 501/6000 [29:23<6:14:12,  4.08s/it]  8%|â–Š         | 502/6000 [29:26<6:01:50,  3.95s/it]                                                    {'loss': 0.0363, 'grad_norm': 4.979997158050537, 'learning_rate': 4.6593220338983054e-05, 'epoch': 0.08}
  8%|â–Š         | 502/6000 [29:26<6:01:50,  3.95s/it]  8%|â–Š         | 503/6000 [29:30<5:48:16,  3.80s/it]                                                    {'loss': 0.0341, 'grad_norm': 3.108429193496704, 'learning_rate': 4.6584745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 503/6000 [29:30<5:48:16,  3.80s/it]  8%|â–Š         | 504/6000 [29:33<5:37:25,  3.68s/it]                                                    {'loss': 0.0259, 'grad_norm': 2.3495936393737793, 'learning_rate': 4.657627118644068e-05, 'epoch': 0.08}
  8%|â–Š         | 504/6000 [29:33<5:37:25,  3.68s/it]  8%|â–Š         | 505/6000 [29:37<5:29:26,  3.60s/it]                                                    {'loss': 0.0167, 'grad_norm': 2.0828607082366943, 'learning_rate': 4.6567796610169495e-05, 'epoch': 0.08}
  8%|â–Š         | 505/6000 [29:37<5:29:26,  3.60s/it]  8%|â–Š         | 506/6000 [29:40<5:34:21,  3.65s/it]                                                    {'loss': 0.1005, 'grad_norm': 9.275025367736816, 'learning_rate': 4.6559322033898306e-05, 'epoch': 0.08}
  8%|â–Š         | 506/6000 [29:40<5:34:21,  3.65s/it]  8%|â–Š         | 507/6000 [29:44<5:28:54,  3.59s/it]                                                    {'loss': 0.048, 'grad_norm': 6.025681972503662, 'learning_rate': 4.6550847457627124e-05, 'epoch': 0.08}
  8%|â–Š         | 507/6000 [29:44<5:28:54,  3.59s/it]  8%|â–Š         | 508/6000 [29:47<5:21:43,  3.51s/it]                                                    {'loss': 0.0461, 'grad_norm': 5.505302429199219, 'learning_rate': 4.6542372881355935e-05, 'epoch': 0.08}
  8%|â–Š         | 508/6000 [29:47<5:21:43,  3.51s/it]  8%|â–Š         | 509/6000 [29:51<5:16:47,  3.46s/it]                                                    {'loss': 0.0489, 'grad_norm': 4.980853080749512, 'learning_rate': 4.653389830508475e-05, 'epoch': 0.08}
  8%|â–Š         | 509/6000 [29:51<5:16:47,  3.46s/it]  8%|â–Š         | 510/6000 [29:54<5:16:21,  3.46s/it]                                                    {'loss': 0.0307, 'grad_norm': 4.7236328125, 'learning_rate': 4.652542372881356e-05, 'epoch': 0.09}
  8%|â–Š         | 510/6000 [29:54<5:16:21,  3.46s/it]  9%|â–Š         | 511/6000 [29:57<5:16:50,  3.46s/it]                                                    {'loss': 0.0674, 'grad_norm': 2.265733480453491, 'learning_rate': 4.6516949152542376e-05, 'epoch': 0.09}
  9%|â–Š         | 511/6000 [29:58<5:16:50,  3.46s/it]  9%|â–Š         | 512/6000 [30:01<5:15:31,  3.45s/it]                                                    {'loss': 0.0604, 'grad_norm': 7.102903366088867, 'learning_rate': 4.650847457627119e-05, 'epoch': 0.09}
  9%|â–Š         | 512/6000 [30:01<5:15:31,  3.45s/it]  9%|â–Š         | 513/6000 [30:05<5:21:09,  3.51s/it]                                                    {'loss': 0.016, 'grad_norm': 2.9737093448638916, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.09}
  9%|â–Š         | 513/6000 [30:05<5:21:09,  3.51s/it]  9%|â–Š         | 514/6000 [30:08<5:20:07,  3.50s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.3186659812927246, 'learning_rate': 4.649152542372882e-05, 'epoch': 0.09}
  9%|â–Š         | 514/6000 [30:08<5:20:07,  3.50s/it]  9%|â–Š         | 515/6000 [30:11<5:16:10,  3.46s/it]                                                    {'loss': 0.1077, 'grad_norm': 6.566264629364014, 'learning_rate': 4.6483050847457635e-05, 'epoch': 0.09}
  9%|â–Š         | 515/6000 [30:11<5:16:10,  3.46s/it]  9%|â–Š         | 516/6000 [30:15<5:22:01,  3.52s/it]                                                    {'loss': 0.0965, 'grad_norm': 11.602514266967773, 'learning_rate': 4.6474576271186446e-05, 'epoch': 0.09}
  9%|â–Š         | 516/6000 [30:15<5:22:01,  3.52s/it]  9%|â–Š         | 517/6000 [30:19<5:19:54,  3.50s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.04238729551434517, 'learning_rate': 4.646610169491525e-05, 'epoch': 0.09}
  9%|â–Š         | 517/6000 [30:19<5:19:54,  3.50s/it]  9%|â–Š         | 518/6000 [30:22<5:17:42,  3.48s/it]                                                    {'loss': 0.2495, 'grad_norm': 11.377595901489258, 'learning_rate': 4.645762711864407e-05, 'epoch': 0.09}
  9%|â–Š         | 518/6000 [30:22<5:17:42,  3.48s/it]  9%|â–Š         | 519/6000 [30:25<5:15:05,  3.45s/it]                                                    {'loss': 0.008, 'grad_norm': 1.0108619928359985, 'learning_rate': 4.644915254237288e-05, 'epoch': 0.09}
  9%|â–Š         | 519/6000 [30:25<5:15:05,  3.45s/it]  9%|â–Š         | 520/6000 [30:29<5:19:11,  3.49s/it]                                                    {'loss': 0.1831, 'grad_norm': 8.17045783996582, 'learning_rate': 4.64406779661017e-05, 'epoch': 0.09}
  9%|â–Š         | 520/6000 [30:29<5:19:11,  3.49s/it]  9%|â–Š         | 521/6000 [30:32<5:13:17,  3.43s/it]                                                    {'loss': 0.0982, 'grad_norm': 9.184820175170898, 'learning_rate': 4.643220338983051e-05, 'epoch': 0.09}
  9%|â–Š         | 521/6000 [30:32<5:13:17,  3.43s/it]  9%|â–Š         | 522/6000 [30:36<5:11:02,  3.41s/it]                                                    {'loss': 0.0036, 'grad_norm': 0.48230600357055664, 'learning_rate': 4.642372881355933e-05, 'epoch': 0.09}
  9%|â–Š         | 522/6000 [30:36<5:11:02,  3.41s/it]  9%|â–Š         | 523/6000 [30:39<5:13:10,  3.43s/it]                                                    {'loss': 0.0046, 'grad_norm': 0.6345985531806946, 'learning_rate': 4.641525423728814e-05, 'epoch': 0.09}
  9%|â–Š         | 523/6000 [30:39<5:13:10,  3.43s/it]  9%|â–Š         | 524/6000 [30:42<5:12:05,  3.42s/it]                                                    {'loss': 0.1535, 'grad_norm': 12.079461097717285, 'learning_rate': 4.640677966101695e-05, 'epoch': 0.09}
  9%|â–Š         | 524/6000 [30:42<5:12:05,  3.42s/it]  9%|â–‰         | 525/6000 [30:46<5:11:05,  3.41s/it]                                                    {'loss': 0.132, 'grad_norm': 12.319442749023438, 'learning_rate': 4.639830508474576e-05, 'epoch': 0.09}
  9%|â–‰         | 525/6000 [30:46<5:11:05,  3.41s/it]  9%|â–‰         | 526/6000 [30:49<5:09:10,  3.39s/it]                                                    {'loss': 0.0411, 'grad_norm': 4.487631797790527, 'learning_rate': 4.638983050847458e-05, 'epoch': 0.09}
  9%|â–‰         | 526/6000 [30:49<5:09:10,  3.39s/it]  9%|â–‰         | 527/6000 [30:53<5:08:30,  3.38s/it]                                                    {'loss': 0.0215, 'grad_norm': 3.7382121086120605, 'learning_rate': 4.638135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 527/6000 [30:53<5:08:30,  3.38s/it]  9%|â–‰         | 528/6000 [30:56<5:12:19,  3.42s/it]                                                    {'loss': 0.1964, 'grad_norm': 9.466121673583984, 'learning_rate': 4.637288135593221e-05, 'epoch': 0.09}
  9%|â–‰         | 528/6000 [30:56<5:12:19,  3.42s/it]  9%|â–‰         | 529/6000 [31:00<5:13:17,  3.44s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.3653576970100403, 'learning_rate': 4.636440677966102e-05, 'epoch': 0.09}
  9%|â–‰         | 529/6000 [31:00<5:13:17,  3.44s/it]  9%|â–‰         | 530/6000 [31:03<5:13:46,  3.44s/it]                                                    {'loss': 0.0061, 'grad_norm': 0.47270649671554565, 'learning_rate': 4.635593220338984e-05, 'epoch': 0.09}
  9%|â–‰         | 530/6000 [31:03<5:13:46,  3.44s/it]  9%|â–‰         | 531/6000 [31:06<5:11:10,  3.41s/it]                                                    {'loss': 0.0988, 'grad_norm': 8.911919593811035, 'learning_rate': 4.634745762711864e-05, 'epoch': 0.09}
  9%|â–‰         | 531/6000 [31:06<5:11:10,  3.41s/it]  9%|â–‰         | 532/6000 [31:10<5:11:49,  3.42s/it]                                                    {'loss': 0.0338, 'grad_norm': 7.223944187164307, 'learning_rate': 4.633898305084746e-05, 'epoch': 0.09}
  9%|â–‰         | 532/6000 [31:10<5:11:49,  3.42s/it]  9%|â–‰         | 533/6000 [31:13<5:09:14,  3.39s/it]                                                    {'loss': 0.0351, 'grad_norm': 4.906927585601807, 'learning_rate': 4.633050847457627e-05, 'epoch': 0.09}
  9%|â–‰         | 533/6000 [31:13<5:09:14,  3.39s/it]  9%|â–‰         | 534/6000 [31:17<5:15:55,  3.47s/it]                                                    {'loss': 0.0241, 'grad_norm': 3.542891025543213, 'learning_rate': 4.632203389830509e-05, 'epoch': 0.09}
  9%|â–‰         | 534/6000 [31:17<5:15:55,  3.47s/it]  9%|â–‰         | 535/6000 [31:20<5:16:13,  3.47s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.11603175848722458, 'learning_rate': 4.63135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 535/6000 [31:20<5:16:13,  3.47s/it]  9%|â–‰         | 536/6000 [31:24<5:14:49,  3.46s/it]                                                    {'loss': 0.133, 'grad_norm': 8.551237106323242, 'learning_rate': 4.630508474576272e-05, 'epoch': 0.09}
  9%|â–‰         | 536/6000 [31:24<5:14:49,  3.46s/it]  9%|â–‰         | 537/6000 [31:27<5:13:01,  3.44s/it]                                                    {'loss': 0.0116, 'grad_norm': 2.3931636810302734, 'learning_rate': 4.629661016949153e-05, 'epoch': 0.09}
  9%|â–‰         | 537/6000 [31:27<5:13:01,  3.44s/it]  9%|â–‰         | 538/6000 [31:30<5:10:54,  3.42s/it]                                                    {'loss': 0.0205, 'grad_norm': 3.814624786376953, 'learning_rate': 4.628813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 538/6000 [31:30<5:10:54,  3.42s/it]  9%|â–‰         | 539/6000 [31:34<5:08:17,  3.39s/it]                                                    {'loss': 0.0003, 'grad_norm': 0.032935500144958496, 'learning_rate': 4.627966101694915e-05, 'epoch': 0.09}
  9%|â–‰         | 539/6000 [31:34<5:08:17,  3.39s/it]  9%|â–‰         | 540/6000 [31:37<5:05:20,  3.36s/it]                                                    {'loss': 0.0801, 'grad_norm': 9.556488037109375, 'learning_rate': 4.6271186440677964e-05, 'epoch': 0.09}
  9%|â–‰         | 540/6000 [31:37<5:05:20,  3.36s/it]  9%|â–‰         | 541/6000 [31:40<5:08:30,  3.39s/it]                                                    {'loss': 0.0363, 'grad_norm': 6.613070011138916, 'learning_rate': 4.626271186440678e-05, 'epoch': 0.09}
  9%|â–‰         | 541/6000 [31:40<5:08:30,  3.39s/it]  9%|â–‰         | 542/6000 [31:44<5:08:34,  3.39s/it]                                                    {'loss': 0.035, 'grad_norm': 4.797524452209473, 'learning_rate': 4.6254237288135594e-05, 'epoch': 0.09}
  9%|â–‰         | 542/6000 [31:44<5:08:34,  3.39s/it]  9%|â–‰         | 543/6000 [31:47<5:08:53,  3.40s/it]                                                    {'loss': 0.2065, 'grad_norm': 14.239436149597168, 'learning_rate': 4.624576271186441e-05, 'epoch': 0.09}
  9%|â–‰         | 543/6000 [31:47<5:08:53,  3.40s/it]  9%|â–‰         | 544/6000 [31:51<5:09:09,  3.40s/it]                                                    {'loss': 0.1597, 'grad_norm': 11.644063949584961, 'learning_rate': 4.623728813559322e-05, 'epoch': 0.09}
  9%|â–‰         | 544/6000 [31:51<5:09:09,  3.40s/it]  9%|â–‰         | 545/6000 [31:54<5:10:48,  3.42s/it]                                                    {'loss': 0.0808, 'grad_norm': 9.668245315551758, 'learning_rate': 4.6228813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 545/6000 [31:54<5:10:48,  3.42s/it]  9%|â–‰         | 546/6000 [31:58<5:12:43,  3.44s/it]                                                    {'loss': 0.01, 'grad_norm': 1.6556552648544312, 'learning_rate': 4.6220338983050846e-05, 'epoch': 0.09}
  9%|â–‰         | 546/6000 [31:58<5:12:43,  3.44s/it]  9%|â–‰         | 547/6000 [32:01<5:15:14,  3.47s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.5498940348625183, 'learning_rate': 4.6211864406779664e-05, 'epoch': 0.09}
  9%|â–‰         | 547/6000 [32:01<5:15:14,  3.47s/it]  9%|â–‰         | 548/6000 [32:05<5:14:54,  3.47s/it]                                                    {'loss': 0.0113, 'grad_norm': 2.245011806488037, 'learning_rate': 4.6203389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 548/6000 [32:05<5:14:54,  3.47s/it]  9%|â–‰         | 549/6000 [32:08<5:11:48,  3.43s/it]                                                    {'loss': 0.0435, 'grad_norm': 5.404256343841553, 'learning_rate': 4.619491525423729e-05, 'epoch': 0.09}
  9%|â–‰         | 549/6000 [32:08<5:11:48,  3.43s/it]  9%|â–‰         | 550/6000 [32:11<5:10:15,  3.42s/it]                                                    {'loss': 0.2765, 'grad_norm': 10.492198944091797, 'learning_rate': 4.6186440677966104e-05, 'epoch': 0.09}
  9%|â–‰         | 550/6000 [32:11<5:10:15,  3.42s/it][2025-10-20 00:09:16,683] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  9%|â–‰         | 551/6000 [32:18<6:33:15,  4.33s/it]                                                    {'loss': 0.0143, 'grad_norm': 2.2198023796081543, 'learning_rate': 4.617796610169492e-05, 'epoch': 0.09}
  9%|â–‰         | 551/6000 [32:18<6:33:15,  4.33s/it]  9%|â–‰         | 552/6000 [32:21<6:09:26,  4.07s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.10115335881710052, 'learning_rate': 4.6169491525423734e-05, 'epoch': 0.09}
  9%|â–‰         | 552/6000 [32:21<6:09:26,  4.07s/it]  9%|â–‰         | 553/6000 [32:25<5:56:18,  3.92s/it]                                                    {'loss': 0.0989, 'grad_norm': 8.304349899291992, 'learning_rate': 4.6161016949152545e-05, 'epoch': 0.09}
  9%|â–‰         | 553/6000 [32:25<5:56:18,  3.92s/it]  9%|â–‰         | 554/6000 [32:28<5:41:52,  3.77s/it]                                                    {'loss': 0.2969, 'grad_norm': 11.178936958312988, 'learning_rate': 4.6152542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 554/6000 [32:28<5:41:52,  3.77s/it]  9%|â–‰         | 555/6000 [32:32<5:31:01,  3.65s/it]                                                    {'loss': 0.0998, 'grad_norm': 6.345197677612305, 'learning_rate': 4.6144067796610174e-05, 'epoch': 0.09}
  9%|â–‰         | 555/6000 [32:32<5:31:01,  3.65s/it]  9%|â–‰         | 556/6000 [32:35<5:24:25,  3.58s/it]                                                    {'loss': 0.0324, 'grad_norm': 3.484299421310425, 'learning_rate': 4.6135593220338986e-05, 'epoch': 0.09}
  9%|â–‰         | 556/6000 [32:35<5:24:25,  3.58s/it]  9%|â–‰         | 557/6000 [32:38<5:19:06,  3.52s/it]                                                    {'loss': 0.0439, 'grad_norm': 1.8918378353118896, 'learning_rate': 4.6127118644067804e-05, 'epoch': 0.09}
  9%|â–‰         | 557/6000 [32:38<5:19:06,  3.52s/it]  9%|â–‰         | 558/6000 [32:42<5:19:09,  3.52s/it]                                                    {'loss': 0.0873, 'grad_norm': 9.631097793579102, 'learning_rate': 4.6118644067796615e-05, 'epoch': 0.09}
  9%|â–‰         | 558/6000 [32:42<5:19:09,  3.52s/it]  9%|â–‰         | 559/6000 [32:46<5:22:32,  3.56s/it]                                                    {'loss': 0.042, 'grad_norm': 4.55864143371582, 'learning_rate': 4.6110169491525426e-05, 'epoch': 0.09}
  9%|â–‰         | 559/6000 [32:46<5:22:32,  3.56s/it]  9%|â–‰         | 560/6000 [32:49<5:19:02,  3.52s/it]                                                    {'loss': 0.1129, 'grad_norm': 6.775144100189209, 'learning_rate': 4.610169491525424e-05, 'epoch': 0.09}
  9%|â–‰         | 560/6000 [32:49<5:19:02,  3.52s/it]  9%|â–‰         | 561/6000 [32:53<5:33:01,  3.67s/it]                                                    {'loss': 0.0629, 'grad_norm': 6.352611541748047, 'learning_rate': 4.609322033898305e-05, 'epoch': 0.09}
  9%|â–‰         | 561/6000 [32:53<5:33:01,  3.67s/it]  9%|â–‰         | 562/6000 [32:56<5:23:14,  3.57s/it]                                                    {'loss': 0.2677, 'grad_norm': 9.727507591247559, 'learning_rate': 4.608474576271187e-05, 'epoch': 0.09}
  9%|â–‰         | 562/6000 [32:56<5:23:14,  3.57s/it]  9%|â–‰         | 563/6000 [33:00<5:19:23,  3.52s/it]                                                    {'loss': 0.0183, 'grad_norm': 3.54807710647583, 'learning_rate': 4.607627118644068e-05, 'epoch': 0.09}
  9%|â–‰         | 563/6000 [33:00<5:19:23,  3.52s/it]  9%|â–‰         | 564/6000 [33:03<5:15:57,  3.49s/it]                                                    {'loss': 0.005, 'grad_norm': 0.7703034281730652, 'learning_rate': 4.6067796610169496e-05, 'epoch': 0.09}
  9%|â–‰         | 564/6000 [33:03<5:15:57,  3.49s/it]  9%|â–‰         | 565/6000 [33:07<5:20:32,  3.54s/it]                                                    {'loss': 0.0208, 'grad_norm': 2.639873504638672, 'learning_rate': 4.605932203389831e-05, 'epoch': 0.09}
  9%|â–‰         | 565/6000 [33:07<5:20:32,  3.54s/it]  9%|â–‰         | 566/6000 [33:10<5:14:30,  3.47s/it]                                                    {'loss': 0.0316, 'grad_norm': 3.7068777084350586, 'learning_rate': 4.605084745762712e-05, 'epoch': 0.09}
  9%|â–‰         | 566/6000 [33:10<5:14:30,  3.47s/it]  9%|â–‰         | 567/6000 [33:14<5:25:21,  3.59s/it]                                                    {'loss': 0.105, 'grad_norm': 6.518970012664795, 'learning_rate': 4.604237288135593e-05, 'epoch': 0.09}
  9%|â–‰         | 567/6000 [33:14<5:25:21,  3.59s/it]  9%|â–‰         | 568/6000 [33:18<5:21:59,  3.56s/it]                                                    {'loss': 0.0428, 'grad_norm': 3.127898693084717, 'learning_rate': 4.603389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 568/6000 [33:18<5:21:59,  3.56s/it]  9%|â–‰         | 569/6000 [33:21<5:19:20,  3.53s/it]                                                    {'loss': 0.0008, 'grad_norm': 0.14001508057117462, 'learning_rate': 4.602542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 569/6000 [33:21<5:19:20,  3.53s/it] 10%|â–‰         | 570/6000 [33:24<5:15:40,  3.49s/it]                                                    {'loss': 0.1194, 'grad_norm': 9.01088809967041, 'learning_rate': 4.601694915254238e-05, 'epoch': 0.1}
 10%|â–‰         | 570/6000 [33:24<5:15:40,  3.49s/it] 10%|â–‰         | 571/6000 [33:29<5:50:50,  3.88s/it]                                                    {'loss': 0.0249, 'grad_norm': 12.73680305480957, 'learning_rate': 4.600847457627119e-05, 'epoch': 0.1}
 10%|â–‰         | 571/6000 [33:29<5:50:50,  3.88s/it] 10%|â–‰         | 572/6000 [33:33<5:38:49,  3.75s/it]                                                    {'loss': 0.5147, 'grad_norm': 82.1309814453125, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.1}
 10%|â–‰         | 572/6000 [33:33<5:38:49,  3.75s/it] 10%|â–‰         | 573/6000 [33:36<5:28:33,  3.63s/it]                                                    {'loss': 0.4578, 'grad_norm': 133.72166442871094, 'learning_rate': 4.599152542372882e-05, 'epoch': 0.1}
 10%|â–‰         | 573/6000 [33:36<5:28:33,  3.63s/it] 10%|â–‰         | 574/6000 [33:39<5:23:35,  3.58s/it]                                                    {'loss': 0.5519, 'grad_norm': 146.55442810058594, 'learning_rate': 4.598305084745763e-05, 'epoch': 0.1}
 10%|â–‰         | 574/6000 [33:39<5:23:35,  3.58s/it] 10%|â–‰         | 575/6000 [33:43<5:20:31,  3.54s/it]                                                    {'loss': 0.0184, 'grad_norm': 2.824481248855591, 'learning_rate': 4.597457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 575/6000 [33:43<5:20:31,  3.54s/it] 10%|â–‰         | 576/6000 [33:46<5:21:21,  3.55s/it]                                                    {'loss': 0.0409, 'grad_norm': 5.913000583648682, 'learning_rate': 4.596610169491526e-05, 'epoch': 0.1}
 10%|â–‰         | 576/6000 [33:46<5:21:21,  3.55s/it] 10%|â–‰         | 577/6000 [33:50<5:22:58,  3.57s/it]                                                    {'loss': 0.0928, 'grad_norm': 5.89682149887085, 'learning_rate': 4.595762711864407e-05, 'epoch': 0.1}
 10%|â–‰         | 577/6000 [33:50<5:22:58,  3.57s/it] 10%|â–‰         | 578/6000 [33:54<5:37:02,  3.73s/it]                                                    {'loss': 0.2259, 'grad_norm': 9.541855812072754, 'learning_rate': 4.594915254237288e-05, 'epoch': 0.1}
 10%|â–‰         | 578/6000 [33:54<5:37:02,  3.73s/it] 10%|â–‰         | 579/6000 [33:58<5:41:59,  3.79s/it]                                                    {'loss': 0.0295, 'grad_norm': 3.312023401260376, 'learning_rate': 4.59406779661017e-05, 'epoch': 0.1}
 10%|â–‰         | 579/6000 [33:58<5:41:59,  3.79s/it] 10%|â–‰         | 580/6000 [34:02<5:32:58,  3.69s/it]                                                    {'loss': 0.1431, 'grad_norm': 6.256964206695557, 'learning_rate': 4.593220338983051e-05, 'epoch': 0.1}
 10%|â–‰         | 580/6000 [34:02<5:32:58,  3.69s/it] 10%|â–‰         | 581/6000 [34:06<5:50:53,  3.89s/it]                                                    {'loss': 0.3832, 'grad_norm': 10.689749717712402, 'learning_rate': 4.592372881355932e-05, 'epoch': 0.1}
 10%|â–‰         | 581/6000 [34:06<5:50:53,  3.89s/it] 10%|â–‰         | 582/6000 [34:10<6:06:37,  4.06s/it]                                                    {'loss': 0.1305, 'grad_norm': 7.384018421173096, 'learning_rate': 4.591525423728813e-05, 'epoch': 0.1}
 10%|â–‰         | 582/6000 [34:10<6:06:37,  4.06s/it] 10%|â–‰         | 583/6000 [34:14<5:52:52,  3.91s/it]                                                    {'loss': 0.0038, 'grad_norm': 0.47648459672927856, 'learning_rate': 4.590677966101695e-05, 'epoch': 0.1}
 10%|â–‰         | 583/6000 [34:14<5:52:52,  3.91s/it] 10%|â–‰         | 584/6000 [34:18<5:44:03,  3.81s/it]                                                    {'loss': 0.3915, 'grad_norm': 11.809258460998535, 'learning_rate': 4.589830508474576e-05, 'epoch': 0.1}
 10%|â–‰         | 584/6000 [34:18<5:44:03,  3.81s/it] 10%|â–‰         | 585/6000 [34:22<5:49:00,  3.87s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.30881834030151367, 'learning_rate': 4.588983050847458e-05, 'epoch': 0.1}
 10%|â–‰         | 585/6000 [34:22<5:49:00,  3.87s/it] 10%|â–‰         | 586/6000 [34:25<5:36:59,  3.73s/it]                                                    {'loss': 0.0303, 'grad_norm': 3.302457571029663, 'learning_rate': 4.588135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 586/6000 [34:25<5:36:59,  3.73s/it] 10%|â–‰         | 587/6000 [34:28<5:24:49,  3.60s/it]                                                    {'loss': 0.0354, 'grad_norm': 1.4366135597229004, 'learning_rate': 4.587288135593221e-05, 'epoch': 0.1}
 10%|â–‰         | 587/6000 [34:28<5:24:49,  3.60s/it] 10%|â–‰         | 588/6000 [34:32<5:19:04,  3.54s/it]                                                    {'loss': 0.0046, 'grad_norm': 1.0775314569473267, 'learning_rate': 4.5864406779661014e-05, 'epoch': 0.1}
 10%|â–‰         | 588/6000 [34:32<5:19:04,  3.54s/it] 10%|â–‰         | 589/6000 [34:35<5:17:06,  3.52s/it]                                                    {'loss': 0.004, 'grad_norm': 0.9470477104187012, 'learning_rate': 4.585593220338983e-05, 'epoch': 0.1}
 10%|â–‰         | 589/6000 [34:35<5:17:06,  3.52s/it] 10%|â–‰         | 590/6000 [34:39<5:17:40,  3.52s/it]                                                    {'loss': 0.0428, 'grad_norm': 3.2115283012390137, 'learning_rate': 4.5847457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 590/6000 [34:39<5:17:40,  3.52s/it] 10%|â–‰         | 591/6000 [34:42<5:13:53,  3.48s/it]                                                    {'loss': 0.0677, 'grad_norm': 6.57957649230957, 'learning_rate': 4.583898305084746e-05, 'epoch': 0.1}
 10%|â–‰         | 591/6000 [34:42<5:13:53,  3.48s/it] 10%|â–‰         | 592/6000 [34:45<5:11:41,  3.46s/it]                                                    {'loss': 0.0951, 'grad_norm': 6.780308246612549, 'learning_rate': 4.583050847457627e-05, 'epoch': 0.1}
 10%|â–‰         | 592/6000 [34:45<5:11:41,  3.46s/it] 10%|â–‰         | 593/6000 [34:49<5:11:15,  3.45s/it]                                                    {'loss': 0.0318, 'grad_norm': 3.1829285621643066, 'learning_rate': 4.582203389830509e-05, 'epoch': 0.1}
 10%|â–‰         | 593/6000 [34:49<5:11:15,  3.45s/it] 10%|â–‰         | 594/6000 [34:52<5:13:30,  3.48s/it]                                                    {'loss': 0.0747, 'grad_norm': 9.564518928527832, 'learning_rate': 4.58135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 594/6000 [34:52<5:13:30,  3.48s/it] 10%|â–‰         | 595/6000 [34:56<5:20:31,  3.56s/it]                                                    {'loss': 0.0642, 'grad_norm': 11.918498039245605, 'learning_rate': 4.5805084745762714e-05, 'epoch': 0.1}
 10%|â–‰         | 595/6000 [34:56<5:20:31,  3.56s/it] 10%|â–‰         | 596/6000 [35:00<5:42:05,  3.80s/it]                                                    {'loss': 0.0588, 'grad_norm': 2.0590806007385254, 'learning_rate': 4.5796610169491525e-05, 'epoch': 0.1}
 10%|â–‰         | 596/6000 [35:00<5:42:05,  3.80s/it] 10%|â–‰         | 597/6000 [35:04<5:29:54,  3.66s/it]                                                    {'loss': 0.0548, 'grad_norm': 4.894609451293945, 'learning_rate': 4.578813559322034e-05, 'epoch': 0.1}
 10%|â–‰         | 597/6000 [35:04<5:29:54,  3.66s/it] 10%|â–‰         | 598/6000 [35:07<5:22:42,  3.58s/it]                                                    {'loss': 0.045, 'grad_norm': 7.197199821472168, 'learning_rate': 4.5779661016949154e-05, 'epoch': 0.1}
 10%|â–‰         | 598/6000 [35:07<5:22:42,  3.58s/it] 10%|â–‰         | 599/6000 [35:11<5:16:25,  3.52s/it]                                                    {'loss': 0.1355, 'grad_norm': 185.90707397460938, 'learning_rate': 4.5771186440677966e-05, 'epoch': 0.1}
 10%|â–‰         | 599/6000 [35:11<5:16:25,  3.52s/it] 10%|â–ˆ         | 600/6000 [35:14<5:13:12,  3.48s/it]                                                    {'loss': 0.022, 'grad_norm': 3.692337989807129, 'learning_rate': 4.5762711864406784e-05, 'epoch': 0.1}
 10%|â–ˆ         | 600/6000 [35:14<5:13:12,  3.48s/it][2025-10-20 00:12:19,320] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 10%|â–ˆ         | 601/6000 [35:20<6:08:38,  4.10s/it]                                                    {'loss': 0.0953, 'grad_norm': 7.745523929595947, 'learning_rate': 4.5754237288135595e-05, 'epoch': 0.1}
 10%|â–ˆ         | 601/6000 [35:20<6:08:38,  4.10s/it] 10%|â–ˆ         | 602/6000 [35:23<5:52:01,  3.91s/it]                                                    {'loss': 0.005, 'grad_norm': 1.0031018257141113, 'learning_rate': 4.5745762711864406e-05, 'epoch': 0.1}
 10%|â–ˆ         | 602/6000 [35:23<5:52:01,  3.91s/it] 10%|â–ˆ         | 603/6000 [35:26<5:38:37,  3.76s/it]                                                    {'loss': 0.1113, 'grad_norm': 8.176799774169922, 'learning_rate': 4.573728813559322e-05, 'epoch': 0.1}
 10%|â–ˆ         | 603/6000 [35:26<5:38:37,  3.76s/it] 10%|â–ˆ         | 604/6000 [35:30<5:46:40,  3.85s/it]                                                    {'loss': 0.0924, 'grad_norm': 7.262808799743652, 'learning_rate': 4.5728813559322036e-05, 'epoch': 0.1}
 10%|â–ˆ         | 604/6000 [35:30<5:46:40,  3.85s/it] 10%|â–ˆ         | 605/6000 [35:34<5:34:58,  3.73s/it]                                                    {'loss': 0.0301, 'grad_norm': 3.082906484603882, 'learning_rate': 4.572033898305085e-05, 'epoch': 0.1}
 10%|â–ˆ         | 605/6000 [35:34<5:34:58,  3.73s/it] 10%|â–ˆ         | 606/6000 [35:38<5:32:57,  3.70s/it]                                                    {'loss': 0.0053, 'grad_norm': 0.629840075969696, 'learning_rate': 4.5711864406779665e-05, 'epoch': 0.1}
 10%|â–ˆ         | 606/6000 [35:38<5:32:57,  3.70s/it] 10%|â–ˆ         | 607/6000 [35:41<5:24:17,  3.61s/it]                                                    {'loss': 0.0541, 'grad_norm': 6.3380279541015625, 'learning_rate': 4.5703389830508476e-05, 'epoch': 0.1}
 10%|â–ˆ         | 607/6000 [35:41<5:24:17,  3.61s/it] 10%|â–ˆ         | 608/6000 [35:45<5:22:35,  3.59s/it]                                                    {'loss': 0.0661, 'grad_norm': 8.099990844726562, 'learning_rate': 4.5694915254237294e-05, 'epoch': 0.1}
 10%|â–ˆ         | 608/6000 [35:45<5:22:35,  3.59s/it] 10%|â–ˆ         | 609/6000 [35:48<5:17:20,  3.53s/it]                                                    {'loss': 0.075, 'grad_norm': 5.3597893714904785, 'learning_rate': 4.5686440677966106e-05, 'epoch': 0.1}
 10%|â–ˆ         | 609/6000 [35:48<5:17:20,  3.53s/it] 10%|â–ˆ         | 610/6000 [35:51<5:13:47,  3.49s/it]                                                    {'loss': 0.0512, 'grad_norm': 6.749060153961182, 'learning_rate': 4.567796610169492e-05, 'epoch': 0.1}
 10%|â–ˆ         | 610/6000 [35:51<5:13:47,  3.49s/it] 10%|â–ˆ         | 611/6000 [35:55<5:09:36,  3.45s/it]                                                    {'loss': 0.1255, 'grad_norm': 10.632272720336914, 'learning_rate': 4.566949152542373e-05, 'epoch': 0.1}
 10%|â–ˆ         | 611/6000 [35:55<5:09:36,  3.45s/it] 10%|â–ˆ         | 612/6000 [35:58<5:13:46,  3.49s/it]                                                    {'loss': 0.0364, 'grad_norm': 2.903048276901245, 'learning_rate': 4.5661016949152546e-05, 'epoch': 0.1}
 10%|â–ˆ         | 612/6000 [35:58<5:13:46,  3.49s/it] 10%|â–ˆ         | 613/6000 [36:02<5:14:03,  3.50s/it]                                                    {'loss': 0.1757, 'grad_norm': 7.2445454597473145, 'learning_rate': 4.565254237288136e-05, 'epoch': 0.1}
 10%|â–ˆ         | 613/6000 [36:02<5:14:03,  3.50s/it] 10%|â–ˆ         | 614/6000 [36:05<5:10:19,  3.46s/it]                                                    {'loss': 0.0035, 'grad_norm': 0.5431005954742432, 'learning_rate': 4.5644067796610176e-05, 'epoch': 0.1}
 10%|â–ˆ         | 614/6000 [36:05<5:10:19,  3.46s/it] 10%|â–ˆ         | 615/6000 [36:09<5:08:57,  3.44s/it]                                                    {'loss': 0.1562, 'grad_norm': 9.602986335754395, 'learning_rate': 4.563559322033899e-05, 'epoch': 0.1}
 10%|â–ˆ         | 615/6000 [36:09<5:08:57,  3.44s/it] 10%|â–ˆ         | 616/6000 [36:12<5:07:52,  3.43s/it]                                                    {'loss': 0.0705, 'grad_norm': 3.482682943344116, 'learning_rate': 4.56271186440678e-05, 'epoch': 0.1}
 10%|â–ˆ         | 616/6000 [36:12<5:07:52,  3.43s/it] 10%|â–ˆ         | 617/6000 [36:15<5:08:05,  3.43s/it]                                                    {'loss': 0.0046, 'grad_norm': 0.713786780834198, 'learning_rate': 4.561864406779661e-05, 'epoch': 0.1}
 10%|â–ˆ         | 617/6000 [36:15<5:08:05,  3.43s/it] 10%|â–ˆ         | 618/6000 [36:19<5:06:36,  3.42s/it]                                                    {'loss': 0.0274, 'grad_norm': 2.972306251525879, 'learning_rate': 4.561016949152543e-05, 'epoch': 0.1}
 10%|â–ˆ         | 618/6000 [36:19<5:06:36,  3.42s/it] 10%|â–ˆ         | 619/6000 [36:22<5:06:05,  3.41s/it]                                                    {'loss': 0.1579, 'grad_norm': 8.706930160522461, 'learning_rate': 4.560169491525424e-05, 'epoch': 0.1}
 10%|â–ˆ         | 619/6000 [36:22<5:06:05,  3.41s/it] 10%|â–ˆ         | 620/6000 [36:25<5:04:18,  3.39s/it]                                                    {'loss': 0.0605, 'grad_norm': 5.093709945678711, 'learning_rate': 4.559322033898305e-05, 'epoch': 0.1}
 10%|â–ˆ         | 620/6000 [36:26<5:04:18,  3.39s/it] 10%|â–ˆ         | 621/6000 [36:29<5:02:26,  3.37s/it]                                                    {'loss': 0.034, 'grad_norm': 4.728597640991211, 'learning_rate': 4.558474576271187e-05, 'epoch': 0.1}
 10%|â–ˆ         | 621/6000 [36:29<5:02:26,  3.37s/it] 10%|â–ˆ         | 622/6000 [36:32<5:01:19,  3.36s/it]                                                    {'loss': 0.2086, 'grad_norm': 9.94749927520752, 'learning_rate': 4.557627118644068e-05, 'epoch': 0.1}
 10%|â–ˆ         | 622/6000 [36:32<5:01:19,  3.36s/it] 10%|â–ˆ         | 623/6000 [36:36<5:02:22,  3.37s/it]                                                    {'loss': 0.1798, 'grad_norm': 7.156209945678711, 'learning_rate': 4.556779661016949e-05, 'epoch': 0.1}
 10%|â–ˆ         | 623/6000 [36:36<5:02:22,  3.37s/it] 10%|â–ˆ         | 624/6000 [36:39<5:00:19,  3.35s/it]                                                    {'loss': 0.1227, 'grad_norm': 8.803030967712402, 'learning_rate': 4.55593220338983e-05, 'epoch': 0.1}
 10%|â–ˆ         | 624/6000 [36:39<5:00:19,  3.35s/it] 10%|â–ˆ         | 625/6000 [36:43<5:08:43,  3.45s/it]                                                    {'loss': 0.004, 'grad_norm': 0.5440457463264465, 'learning_rate': 4.555084745762712e-05, 'epoch': 0.1}
 10%|â–ˆ         | 625/6000 [36:43<5:08:43,  3.45s/it] 10%|â–ˆ         | 626/6000 [36:46<5:06:36,  3.42s/it]                                                    {'loss': 0.0627, 'grad_norm': 4.507326602935791, 'learning_rate': 4.554237288135593e-05, 'epoch': 0.1}
 10%|â–ˆ         | 626/6000 [36:46<5:06:36,  3.42s/it] 10%|â–ˆ         | 627/6000 [36:50<5:27:31,  3.66s/it]                                                    {'loss': 0.0222, 'grad_norm': 2.7226967811584473, 'learning_rate': 4.553389830508475e-05, 'epoch': 0.1}
 10%|â–ˆ         | 627/6000 [36:50<5:27:31,  3.66s/it] 10%|â–ˆ         | 628/6000 [36:54<5:21:34,  3.59s/it]                                                    {'loss': 0.1423, 'grad_norm': 7.852845668792725, 'learning_rate': 4.552542372881356e-05, 'epoch': 0.1}
 10%|â–ˆ         | 628/6000 [36:54<5:21:34,  3.59s/it] 10%|â–ˆ         | 629/6000 [36:57<5:14:29,  3.51s/it]                                                    {'loss': 0.0097, 'grad_norm': 0.8535628914833069, 'learning_rate': 4.551694915254238e-05, 'epoch': 0.1}
 10%|â–ˆ         | 629/6000 [36:57<5:14:29,  3.51s/it] 10%|â–ˆ         | 630/6000 [37:00<5:10:34,  3.47s/it]                                                    {'loss': 0.3619, 'grad_norm': 12.528667449951172, 'learning_rate': 4.550847457627119e-05, 'epoch': 0.1}
 10%|â–ˆ         | 630/6000 [37:00<5:10:34,  3.47s/it] 11%|â–ˆ         | 631/6000 [37:04<5:08:18,  3.45s/it]                                                    {'loss': 0.0872, 'grad_norm': 6.688705921173096, 'learning_rate': 4.55e-05, 'epoch': 0.11}
 11%|â–ˆ         | 631/6000 [37:04<5:08:18,  3.45s/it] 11%|â–ˆ         | 632/6000 [37:07<5:10:10,  3.47s/it]                                                    {'loss': 0.1394, 'grad_norm': 6.3921637535095215, 'learning_rate': 4.549152542372881e-05, 'epoch': 0.11}
 11%|â–ˆ         | 632/6000 [37:07<5:10:10,  3.47s/it] 11%|â–ˆ         | 633/6000 [37:11<5:10:39,  3.47s/it]                                                    {'loss': 0.0614, 'grad_norm': 2.151289463043213, 'learning_rate': 4.548305084745763e-05, 'epoch': 0.11}
 11%|â–ˆ         | 633/6000 [37:11<5:10:39,  3.47s/it] 11%|â–ˆ         | 634/6000 [37:14<5:18:36,  3.56s/it]                                                    {'loss': 0.0182, 'grad_norm': 1.9433369636535645, 'learning_rate': 4.547457627118644e-05, 'epoch': 0.11}
 11%|â–ˆ         | 634/6000 [37:14<5:18:36,  3.56s/it] 11%|â–ˆ         | 635/6000 [37:18<5:18:58,  3.57s/it]                                                    {'loss': 0.0106, 'grad_norm': 1.0677859783172607, 'learning_rate': 4.546610169491526e-05, 'epoch': 0.11}
 11%|â–ˆ         | 635/6000 [37:18<5:18:58,  3.57s/it] 11%|â–ˆ         | 636/6000 [37:21<5:14:14,  3.52s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.8697575926780701, 'learning_rate': 4.545762711864407e-05, 'epoch': 0.11}
 11%|â–ˆ         | 636/6000 [37:21<5:14:14,  3.52s/it] 11%|â–ˆ         | 637/6000 [37:25<5:12:58,  3.50s/it]                                                    {'loss': 0.0168, 'grad_norm': 2.0494749546051025, 'learning_rate': 4.544915254237288e-05, 'epoch': 0.11}
 11%|â–ˆ         | 637/6000 [37:25<5:12:58,  3.50s/it] 11%|â–ˆ         | 638/6000 [37:29<5:25:13,  3.64s/it]                                                    {'loss': 0.0631, 'grad_norm': 6.247382164001465, 'learning_rate': 4.5440677966101694e-05, 'epoch': 0.11}
 11%|â–ˆ         | 638/6000 [37:29<5:25:13,  3.64s/it] 11%|â–ˆ         | 639/6000 [37:32<5:20:50,  3.59s/it]                                                    {'loss': 0.0196, 'grad_norm': 2.0608913898468018, 'learning_rate': 4.543220338983051e-05, 'epoch': 0.11}
 11%|â–ˆ         | 639/6000 [37:32<5:20:50,  3.59s/it] 11%|â–ˆ         | 640/6000 [37:36<5:28:10,  3.67s/it]                                                    {'loss': 0.0227, 'grad_norm': 2.1062726974487305, 'learning_rate': 4.542372881355932e-05, 'epoch': 0.11}
 11%|â–ˆ         | 640/6000 [37:36<5:28:10,  3.67s/it] 11%|â–ˆ         | 641/6000 [37:40<5:33:52,  3.74s/it]                                                    {'loss': 0.0053, 'grad_norm': 0.5994457602500916, 'learning_rate': 4.5415254237288135e-05, 'epoch': 0.11}
 11%|â–ˆ         | 641/6000 [37:40<5:33:52,  3.74s/it] 11%|â–ˆ         | 642/6000 [37:43<5:23:16,  3.62s/it]                                                    {'loss': 0.0093, 'grad_norm': 1.2593594789505005, 'learning_rate': 4.540677966101695e-05, 'epoch': 0.11}
 11%|â–ˆ         | 642/6000 [37:43<5:23:16,  3.62s/it] 11%|â–ˆ         | 643/6000 [37:47<5:17:36,  3.56s/it]                                                    {'loss': 0.0522, 'grad_norm': 4.723994255065918, 'learning_rate': 4.5398305084745764e-05, 'epoch': 0.11}
 11%|â–ˆ         | 643/6000 [37:47<5:17:36,  3.56s/it] 11%|â–ˆ         | 644/6000 [37:50<5:14:47,  3.53s/it]                                                    {'loss': 0.0076, 'grad_norm': 1.2720361948013306, 'learning_rate': 4.538983050847458e-05, 'epoch': 0.11}
 11%|â–ˆ         | 644/6000 [37:50<5:14:47,  3.53s/it] 11%|â–ˆ         | 645/6000 [37:54<5:11:31,  3.49s/it]                                                    {'loss': 0.1324, 'grad_norm': 6.52439022064209, 'learning_rate': 4.5381355932203387e-05, 'epoch': 0.11}
 11%|â–ˆ         | 645/6000 [37:54<5:11:31,  3.49s/it] 11%|â–ˆ         | 646/6000 [37:57<5:18:10,  3.57s/it]                                                    {'loss': 0.0425, 'grad_norm': 4.869932651519775, 'learning_rate': 4.5372881355932205e-05, 'epoch': 0.11}
 11%|â–ˆ         | 646/6000 [37:57<5:18:10,  3.57s/it] 11%|â–ˆ         | 647/6000 [38:01<5:12:52,  3.51s/it]                                                    {'loss': 0.0999, 'grad_norm': 6.729183197021484, 'learning_rate': 4.5364406779661016e-05, 'epoch': 0.11}
 11%|â–ˆ         | 647/6000 [38:01<5:12:52,  3.51s/it] 11%|â–ˆ         | 648/6000 [38:05<5:19:05,  3.58s/it]                                                    {'loss': 0.0551, 'grad_norm': 4.197848320007324, 'learning_rate': 4.5355932203389834e-05, 'epoch': 0.11}
 11%|â–ˆ         | 648/6000 [38:05<5:19:05,  3.58s/it] 11%|â–ˆ         | 649/6000 [38:08<5:12:22,  3.50s/it]                                                    {'loss': 0.0235, 'grad_norm': 4.060806751251221, 'learning_rate': 4.5347457627118645e-05, 'epoch': 0.11}
 11%|â–ˆ         | 649/6000 [38:08<5:12:22,  3.50s/it] 11%|â–ˆ         | 650/6000 [38:11<5:07:26,  3.45s/it]                                                    {'loss': 0.1175, 'grad_norm': 6.934512615203857, 'learning_rate': 4.533898305084746e-05, 'epoch': 0.11}
 11%|â–ˆ         | 650/6000 [38:11<5:07:26,  3.45s/it][2025-10-20 00:15:16,487] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 11%|â–ˆ         | 651/6000 [38:17<6:00:24,  4.04s/it]                                                    {'loss': 0.1154, 'grad_norm': 6.521448612213135, 'learning_rate': 4.5330508474576275e-05, 'epoch': 0.11}
 11%|â–ˆ         | 651/6000 [38:17<6:00:24,  4.04s/it] 11%|â–ˆ         | 652/6000 [38:20<5:53:14,  3.96s/it]                                                    {'loss': 0.0074, 'grad_norm': 1.1318227052688599, 'learning_rate': 4.5322033898305086e-05, 'epoch': 0.11}
 11%|â–ˆ         | 652/6000 [38:20<5:53:14,  3.96s/it] 11%|â–ˆ         | 653/6000 [38:24<5:41:05,  3.83s/it]                                                    {'loss': 0.2136, 'grad_norm': 6.494247913360596, 'learning_rate': 4.53135593220339e-05, 'epoch': 0.11}
 11%|â–ˆ         | 653/6000 [38:24<5:41:05,  3.83s/it] 11%|â–ˆ         | 654/6000 [38:27<5:27:00,  3.67s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.35851243138313293, 'learning_rate': 4.5305084745762715e-05, 'epoch': 0.11}
 11%|â–ˆ         | 654/6000 [38:27<5:27:00,  3.67s/it] 11%|â–ˆ         | 655/6000 [38:31<5:19:27,  3.59s/it]                                                    {'loss': 0.0467, 'grad_norm': 2.1398138999938965, 'learning_rate': 4.5296610169491527e-05, 'epoch': 0.11}
 11%|â–ˆ         | 655/6000 [38:31<5:19:27,  3.59s/it] 11%|â–ˆ         | 656/6000 [38:34<5:13:44,  3.52s/it]                                                    {'loss': 0.1443, 'grad_norm': 7.610028266906738, 'learning_rate': 4.5288135593220345e-05, 'epoch': 0.11}
 11%|â–ˆ         | 656/6000 [38:34<5:13:44,  3.52s/it] 11%|â–ˆ         | 657/6000 [38:38<5:16:02,  3.55s/it]                                                    {'loss': 0.0653, 'grad_norm': 3.1109533309936523, 'learning_rate': 4.5279661016949156e-05, 'epoch': 0.11}
 11%|â–ˆ         | 657/6000 [38:38<5:16:02,  3.55s/it] 11%|â–ˆ         | 658/6000 [38:41<5:22:48,  3.63s/it]                                                    {'loss': 0.0049, 'grad_norm': 0.6492549777030945, 'learning_rate': 4.5271186440677974e-05, 'epoch': 0.11}
 11%|â–ˆ         | 658/6000 [38:41<5:22:48,  3.63s/it] 11%|â–ˆ         | 659/6000 [38:45<5:15:18,  3.54s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.05769798904657364, 'learning_rate': 4.526271186440678e-05, 'epoch': 0.11}
 11%|â–ˆ         | 659/6000 [38:45<5:15:18,  3.54s/it] 11%|â–ˆ         | 660/6000 [38:48<5:12:15,  3.51s/it]                                                    {'loss': 0.0143, 'grad_norm': 1.946791410446167, 'learning_rate': 4.5254237288135596e-05, 'epoch': 0.11}
 11%|â–ˆ         | 660/6000 [38:48<5:12:15,  3.51s/it] 11%|â–ˆ         | 661/6000 [38:51<5:06:11,  3.44s/it]                                                    {'loss': 0.007, 'grad_norm': 1.2549329996109009, 'learning_rate': 4.524576271186441e-05, 'epoch': 0.11}
 11%|â–ˆ         | 661/6000 [38:51<5:06:11,  3.44s/it] 11%|â–ˆ         | 662/6000 [38:55<5:04:07,  3.42s/it]                                                    {'loss': 0.035, 'grad_norm': 2.3247225284576416, 'learning_rate': 4.523728813559322e-05, 'epoch': 0.11}
 11%|â–ˆ         | 662/6000 [38:55<5:04:07,  3.42s/it] 11%|â–ˆ         | 663/6000 [38:58<5:01:52,  3.39s/it]                                                    {'loss': 0.1112, 'grad_norm': 8.263420104980469, 'learning_rate': 4.522881355932204e-05, 'epoch': 0.11}
 11%|â–ˆ         | 663/6000 [38:58<5:01:52,  3.39s/it] 11%|â–ˆ         | 664/6000 [39:02<5:05:42,  3.44s/it]                                                    {'loss': 0.0453, 'grad_norm': 5.579916954040527, 'learning_rate': 4.522033898305085e-05, 'epoch': 0.11}
 11%|â–ˆ         | 664/6000 [39:02<5:05:42,  3.44s/it] 11%|â–ˆ         | 665/6000 [39:05<5:03:54,  3.42s/it]                                                    {'loss': 0.0673, 'grad_norm': 5.085176944732666, 'learning_rate': 4.5211864406779666e-05, 'epoch': 0.11}
 11%|â–ˆ         | 665/6000 [39:05<5:03:54,  3.42s/it] 11%|â–ˆ         | 666/6000 [39:09<5:05:26,  3.44s/it]                                                    {'loss': 0.1427, 'grad_norm': 10.133636474609375, 'learning_rate': 4.520338983050848e-05, 'epoch': 0.11}
 11%|â–ˆ         | 666/6000 [39:09<5:05:26,  3.44s/it] 11%|â–ˆ         | 667/6000 [39:12<5:06:57,  3.45s/it]                                                    {'loss': 0.1287, 'grad_norm': 5.376126289367676, 'learning_rate': 4.519491525423729e-05, 'epoch': 0.11}
 11%|â–ˆ         | 667/6000 [39:12<5:06:57,  3.45s/it] 11%|â–ˆ         | 668/6000 [39:16<5:10:03,  3.49s/it]                                                    {'loss': 0.0119, 'grad_norm': 1.7666947841644287, 'learning_rate': 4.51864406779661e-05, 'epoch': 0.11}
 11%|â–ˆ         | 668/6000 [39:16<5:10:03,  3.49s/it] 11%|â–ˆ         | 669/6000 [39:19<5:06:16,  3.45s/it]                                                    {'loss': 0.0221, 'grad_norm': 2.6571767330169678, 'learning_rate': 4.517796610169492e-05, 'epoch': 0.11}
 11%|â–ˆ         | 669/6000 [39:19<5:06:16,  3.45s/it] 11%|â–ˆ         | 670/6000 [39:22<5:08:00,  3.47s/it]                                                    {'loss': 0.0141, 'grad_norm': 1.9145991802215576, 'learning_rate': 4.516949152542373e-05, 'epoch': 0.11}
 11%|â–ˆ         | 670/6000 [39:22<5:08:00,  3.47s/it] 11%|â–ˆ         | 671/6000 [39:26<5:05:28,  3.44s/it]                                                    {'loss': 0.0069, 'grad_norm': 0.9174666404724121, 'learning_rate': 4.516101694915255e-05, 'epoch': 0.11}
 11%|â–ˆ         | 671/6000 [39:26<5:05:28,  3.44s/it] 11%|â–ˆ         | 672/6000 [39:29<5:01:46,  3.40s/it]                                                    {'loss': 0.0914, 'grad_norm': 9.07601261138916, 'learning_rate': 4.515254237288136e-05, 'epoch': 0.11}
 11%|â–ˆ         | 672/6000 [39:29<5:01:46,  3.40s/it] 11%|â–ˆ         | 673/6000 [39:33<5:02:04,  3.40s/it]                                                    {'loss': 0.0435, 'grad_norm': 2.8725502490997314, 'learning_rate': 4.514406779661017e-05, 'epoch': 0.11}
 11%|â–ˆ         | 673/6000 [39:33<5:02:04,  3.40s/it] 11%|â–ˆ         | 674/6000 [39:36<5:00:00,  3.38s/it]                                                    {'loss': 0.0185, 'grad_norm': 1.030129313468933, 'learning_rate': 4.513559322033898e-05, 'epoch': 0.11}
 11%|â–ˆ         | 674/6000 [39:36<5:00:00,  3.38s/it] 11%|â–ˆâ–        | 675/6000 [39:39<4:59:48,  3.38s/it]                                                    {'loss': 0.0767, 'grad_norm': 5.367981910705566, 'learning_rate': 4.51271186440678e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 675/6000 [39:39<4:59:48,  3.38s/it] 11%|â–ˆâ–        | 676/6000 [39:43<5:00:38,  3.39s/it]                                                    {'loss': 0.043, 'grad_norm': 2.8600196838378906, 'learning_rate': 4.511864406779661e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 676/6000 [39:43<5:00:38,  3.39s/it] 11%|â–ˆâ–        | 677/6000 [39:46<5:00:14,  3.38s/it]                                                    {'loss': 0.0571, 'grad_norm': 6.660916805267334, 'learning_rate': 4.511016949152543e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 677/6000 [39:46<5:00:14,  3.38s/it] 11%|â–ˆâ–        | 678/6000 [39:49<5:00:51,  3.39s/it]                                                    {'loss': 0.0293, 'grad_norm': 3.281226634979248, 'learning_rate': 4.510169491525424e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 678/6000 [39:49<5:00:51,  3.39s/it] 11%|â–ˆâ–        | 679/6000 [39:53<4:57:29,  3.35s/it]                                                    {'loss': 0.0352, 'grad_norm': 3.587418556213379, 'learning_rate': 4.509322033898306e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 679/6000 [39:53<4:57:29,  3.35s/it] 11%|â–ˆâ–        | 680/6000 [39:56<4:59:13,  3.37s/it]                                                    {'loss': 0.0503, 'grad_norm': 6.042613506317139, 'learning_rate': 4.508474576271187e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 680/6000 [39:56<4:59:13,  3.37s/it] 11%|â–ˆâ–        | 681/6000 [40:00<5:11:24,  3.51s/it]                                                    {'loss': 0.011, 'grad_norm': 1.6459592580795288, 'learning_rate': 4.507627118644068e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 681/6000 [40:00<5:11:24,  3.51s/it] 11%|â–ˆâ–        | 682/6000 [40:03<5:10:53,  3.51s/it]                                                    {'loss': 0.0403, 'grad_norm': 6.94093656539917, 'learning_rate': 4.506779661016949e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 682/6000 [40:03<5:10:53,  3.51s/it] 11%|â–ˆâ–        | 683/6000 [40:07<5:08:57,  3.49s/it]                                                    {'loss': 0.0502, 'grad_norm': 4.615190029144287, 'learning_rate': 4.5059322033898304e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 683/6000 [40:07<5:08:57,  3.49s/it] 11%|â–ˆâ–        | 684/6000 [40:10<5:05:23,  3.45s/it]                                                    {'loss': 0.2261, 'grad_norm': 11.05600643157959, 'learning_rate': 4.505084745762712e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 684/6000 [40:10<5:05:23,  3.45s/it] 11%|â–ˆâ–        | 685/6000 [40:14<5:04:54,  3.44s/it]                                                    {'loss': 0.0405, 'grad_norm': 5.884819984436035, 'learning_rate': 4.504237288135593e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 685/6000 [40:14<5:04:54,  3.44s/it] 11%|â–ˆâ–        | 686/6000 [40:18<5:18:36,  3.60s/it]                                                    {'loss': 0.2073, 'grad_norm': 9.185528755187988, 'learning_rate': 4.503389830508475e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 686/6000 [40:18<5:18:36,  3.60s/it] 11%|â–ˆâ–        | 687/6000 [40:21<5:11:18,  3.52s/it]                                                    {'loss': 0.0105, 'grad_norm': 2.5478031635284424, 'learning_rate': 4.502542372881356e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 687/6000 [40:21<5:11:18,  3.52s/it] 11%|â–ˆâ–        | 688/6000 [40:24<5:08:52,  3.49s/it]                                                    {'loss': 0.0457, 'grad_norm': 5.225879192352295, 'learning_rate': 4.5016949152542373e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 688/6000 [40:24<5:08:52,  3.49s/it] 11%|â–ˆâ–        | 689/6000 [40:28<5:07:36,  3.48s/it]                                                    {'loss': 0.2227, 'grad_norm': 10.018317222595215, 'learning_rate': 4.5008474576271185e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 689/6000 [40:28<5:07:36,  3.48s/it] 12%|â–ˆâ–        | 690/6000 [40:31<5:06:01,  3.46s/it]                                                    {'loss': 0.0337, 'grad_norm': 1.8590174913406372, 'learning_rate': 4.5e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 690/6000 [40:31<5:06:01,  3.46s/it] 12%|â–ˆâ–        | 691/6000 [40:35<5:06:59,  3.47s/it]                                                    {'loss': 0.0263, 'grad_norm': 4.249077796936035, 'learning_rate': 4.4991525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 691/6000 [40:35<5:06:59,  3.47s/it] 12%|â–ˆâ–        | 692/6000 [40:38<5:11:24,  3.52s/it]                                                    {'loss': 0.4308, 'grad_norm': 12.779840469360352, 'learning_rate': 4.498305084745763e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 692/6000 [40:38<5:11:24,  3.52s/it] 12%|â–ˆâ–        | 693/6000 [40:42<5:05:32,  3.45s/it]                                                    {'loss': 0.0805, 'grad_norm': 6.322092056274414, 'learning_rate': 4.4974576271186443e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 693/6000 [40:42<5:05:32,  3.45s/it] 12%|â–ˆâ–        | 694/6000 [40:45<5:05:13,  3.45s/it]                                                    {'loss': 0.0025, 'grad_norm': 0.5591962337493896, 'learning_rate': 4.4966101694915255e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 694/6000 [40:45<5:05:13,  3.45s/it] 12%|â–ˆâ–        | 695/6000 [40:49<5:04:22,  3.44s/it]                                                    {'loss': 0.0125, 'grad_norm': 2.5414364337921143, 'learning_rate': 4.4957627118644066e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 695/6000 [40:49<5:04:22,  3.44s/it] 12%|â–ˆâ–        | 696/6000 [40:52<5:13:53,  3.55s/it]                                                    {'loss': 0.1364, 'grad_norm': 10.210809707641602, 'learning_rate': 4.4949152542372884e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 696/6000 [40:52<5:13:53,  3.55s/it] 12%|â–ˆâ–        | 697/6000 [40:56<5:09:51,  3.51s/it]                                                    {'loss': 0.0153, 'grad_norm': 1.6622464656829834, 'learning_rate': 4.4940677966101695e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 697/6000 [40:56<5:09:51,  3.51s/it] 12%|â–ˆâ–        | 698/6000 [40:59<5:08:52,  3.50s/it]                                                    {'loss': 0.0683, 'grad_norm': 7.90604829788208, 'learning_rate': 4.4932203389830513e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 698/6000 [40:59<5:08:52,  3.50s/it] 12%|â–ˆâ–        | 699/6000 [41:03<5:09:05,  3.50s/it]                                                    {'loss': 0.0847, 'grad_norm': 7.007997989654541, 'learning_rate': 4.4923728813559325e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 699/6000 [41:03<5:09:05,  3.50s/it] 12%|â–ˆâ–        | 700/6000 [41:06<5:09:37,  3.51s/it]                                                    {'loss': 0.0059, 'grad_norm': 0.7389703392982483, 'learning_rate': 4.491525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 700/6000 [41:06<5:09:37,  3.51s/it][2025-10-20 00:18:11,567] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|â–ˆâ–        | 701/6000 [41:12<6:08:03,  4.17s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.13675427436828613, 'learning_rate': 4.4906779661016954e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 701/6000 [41:12<6:08:03,  4.17s/it] 12%|â–ˆâ–        | 702/6000 [41:16<5:59:58,  4.08s/it]                                                    {'loss': 0.1092, 'grad_norm': 8.38579273223877, 'learning_rate': 4.4898305084745765e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 702/6000 [41:16<5:59:58,  4.08s/it] 12%|â–ˆâ–        | 703/6000 [41:19<5:43:15,  3.89s/it]                                                    {'loss': 0.0156, 'grad_norm': 2.2608754634857178, 'learning_rate': 4.488983050847458e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 703/6000 [41:19<5:43:15,  3.89s/it] 12%|â–ˆâ–        | 704/6000 [41:23<5:42:16,  3.88s/it]                                                    {'loss': 0.0022, 'grad_norm': 0.3040052652359009, 'learning_rate': 4.488135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 704/6000 [41:23<5:42:16,  3.88s/it] 12%|â–ˆâ–        | 705/6000 [41:27<5:32:31,  3.77s/it]                                                    {'loss': 0.1563, 'grad_norm': 8.541620254516602, 'learning_rate': 4.4872881355932206e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 705/6000 [41:27<5:32:31,  3.77s/it] 12%|â–ˆâ–        | 706/6000 [41:30<5:22:36,  3.66s/it]                                                    {'loss': 0.0916, 'grad_norm': 5.85390043258667, 'learning_rate': 4.486440677966102e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 706/6000 [41:30<5:22:36,  3.66s/it] 12%|â–ˆâ–        | 707/6000 [41:34<5:17:57,  3.60s/it]                                                    {'loss': 0.0411, 'grad_norm': 5.384321212768555, 'learning_rate': 4.4855932203389835e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 707/6000 [41:34<5:17:57,  3.60s/it] 12%|â–ˆâ–        | 708/6000 [41:37<5:14:18,  3.56s/it]                                                    {'loss': 0.0202, 'grad_norm': 2.5591115951538086, 'learning_rate': 4.484745762711865e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 708/6000 [41:37<5:14:18,  3.56s/it] 12%|â–ˆâ–        | 709/6000 [41:40<5:09:07,  3.51s/it]                                                    {'loss': 0.1057, 'grad_norm': 8.992353439331055, 'learning_rate': 4.483898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 709/6000 [41:40<5:09:07,  3.51s/it] 12%|â–ˆâ–        | 710/6000 [41:44<5:16:14,  3.59s/it]                                                    {'loss': 0.0346, 'grad_norm': 3.701620101928711, 'learning_rate': 4.483050847457627e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 710/6000 [41:44<5:16:14,  3.59s/it] 12%|â–ˆâ–        | 711/6000 [41:48<5:12:49,  3.55s/it]                                                    {'loss': 0.0084, 'grad_norm': 1.9354063272476196, 'learning_rate': 4.482203389830509e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 711/6000 [41:48<5:12:49,  3.55s/it] 12%|â–ˆâ–        | 712/6000 [41:51<5:10:12,  3.52s/it]                                                    {'loss': 0.0351, 'grad_norm': 4.645496845245361, 'learning_rate': 4.48135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 712/6000 [41:51<5:10:12,  3.52s/it] 12%|â–ˆâ–        | 713/6000 [41:54<5:07:03,  3.48s/it]                                                    {'loss': 0.0559, 'grad_norm': 3.440256357192993, 'learning_rate': 4.480508474576272e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 713/6000 [41:54<5:07:03,  3.48s/it] 12%|â–ˆâ–        | 714/6000 [41:58<5:05:30,  3.47s/it]                                                    {'loss': 0.0354, 'grad_norm': 4.608598232269287, 'learning_rate': 4.479661016949153e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 714/6000 [41:58<5:05:30,  3.47s/it] 12%|â–ˆâ–        | 715/6000 [42:01<5:04:32,  3.46s/it]                                                    {'loss': 0.0206, 'grad_norm': 4.484261512756348, 'learning_rate': 4.4788135593220346e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 715/6000 [42:01<5:04:32,  3.46s/it] 12%|â–ˆâ–        | 716/6000 [42:05<5:03:52,  3.45s/it]                                                    {'loss': 0.0505, 'grad_norm': 5.62428617477417, 'learning_rate': 4.477966101694915e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 716/6000 [42:05<5:03:52,  3.45s/it] 12%|â–ˆâ–        | 717/6000 [42:09<5:14:07,  3.57s/it]                                                    {'loss': 0.0776, 'grad_norm': 6.037535190582275, 'learning_rate': 4.477118644067797e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 717/6000 [42:09<5:14:07,  3.57s/it] 12%|â–ˆâ–        | 718/6000 [42:12<5:09:51,  3.52s/it]                                                    {'loss': 0.0082, 'grad_norm': 1.2449191808700562, 'learning_rate': 4.476271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 718/6000 [42:12<5:09:51,  3.52s/it] 12%|â–ˆâ–        | 719/6000 [42:15<5:08:42,  3.51s/it]                                                    {'loss': 0.0962, 'grad_norm': 9.372794151306152, 'learning_rate': 4.47542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 719/6000 [42:15<5:08:42,  3.51s/it] 12%|â–ˆâ–        | 720/6000 [42:19<5:04:37,  3.46s/it]                                                    {'loss': 0.002, 'grad_norm': 0.27381762862205505, 'learning_rate': 4.474576271186441e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 720/6000 [42:19<5:04:37,  3.46s/it] 12%|â–ˆâ–        | 721/6000 [42:22<5:06:31,  3.48s/it]                                                    {'loss': 0.0691, 'grad_norm': 6.049503326416016, 'learning_rate': 4.473728813559323e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 721/6000 [42:22<5:06:31,  3.48s/it] 12%|â–ˆâ–        | 722/6000 [42:26<5:06:02,  3.48s/it]                                                    {'loss': 0.073, 'grad_norm': 4.471012115478516, 'learning_rate': 4.472881355932204e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 722/6000 [42:26<5:06:02,  3.48s/it] 12%|â–ˆâ–        | 723/6000 [42:30<5:17:55,  3.61s/it]                                                    {'loss': 0.0069, 'grad_norm': 0.8461284041404724, 'learning_rate': 4.472033898305085e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 723/6000 [42:30<5:17:55,  3.61s/it] 12%|â–ˆâ–        | 724/6000 [42:33<5:10:39,  3.53s/it]                                                    {'loss': 0.0588, 'grad_norm': 6.407440662384033, 'learning_rate': 4.471186440677966e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 724/6000 [42:33<5:10:39,  3.53s/it] 12%|â–ˆâ–        | 725/6000 [42:36<5:05:48,  3.48s/it]                                                    {'loss': 0.0501, 'grad_norm': 5.931118488311768, 'learning_rate': 4.470338983050847e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 725/6000 [42:36<5:05:48,  3.48s/it] 12%|â–ˆâ–        | 726/6000 [42:40<5:02:51,  3.45s/it]                                                    {'loss': 0.0089, 'grad_norm': 0.9428370594978333, 'learning_rate': 4.469491525423729e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 726/6000 [42:40<5:02:51,  3.45s/it] 12%|â–ˆâ–        | 727/6000 [42:43<5:00:21,  3.42s/it]                                                    {'loss': 0.1704, 'grad_norm': 7.31556510925293, 'learning_rate': 4.46864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 727/6000 [42:43<5:00:21,  3.42s/it] 12%|â–ˆâ–        | 728/6000 [42:47<5:00:21,  3.42s/it]                                                    {'loss': 0.0313, 'grad_norm': 6.439426898956299, 'learning_rate': 4.467796610169492e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 728/6000 [42:47<5:00:21,  3.42s/it] 12%|â–ˆâ–        | 729/6000 [42:50<5:00:50,  3.42s/it]                                                    {'loss': 0.0072, 'grad_norm': 0.8321484923362732, 'learning_rate': 4.466949152542373e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 729/6000 [42:50<5:00:50,  3.42s/it] 12%|â–ˆâ–        | 730/6000 [42:53<4:58:01,  3.39s/it]                                                    {'loss': 0.1198, 'grad_norm': 7.171483039855957, 'learning_rate': 4.466101694915254e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 730/6000 [42:53<4:58:01,  3.39s/it] 12%|â–ˆâ–        | 731/6000 [42:57<4:56:53,  3.38s/it]                                                    {'loss': 0.0061, 'grad_norm': 0.7564908266067505, 'learning_rate': 4.4652542372881354e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 731/6000 [42:57<4:56:53,  3.38s/it] 12%|â–ˆâ–        | 732/6000 [43:00<5:02:18,  3.44s/it]                                                    {'loss': 0.0521, 'grad_norm': 4.964773654937744, 'learning_rate': 4.464406779661017e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 732/6000 [43:00<5:02:18,  3.44s/it] 12%|â–ˆâ–        | 733/6000 [43:04<5:05:53,  3.48s/it]                                                    {'loss': 0.029, 'grad_norm': 4.8470025062561035, 'learning_rate': 4.463559322033898e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 733/6000 [43:04<5:05:53,  3.48s/it] 12%|â–ˆâ–        | 734/6000 [43:08<5:19:11,  3.64s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.7627860307693481, 'learning_rate': 4.46271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 734/6000 [43:08<5:19:11,  3.64s/it] 12%|â–ˆâ–        | 735/6000 [43:11<5:12:23,  3.56s/it]                                                    {'loss': 0.0046, 'grad_norm': 0.6891548037528992, 'learning_rate': 4.461864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 735/6000 [43:11<5:12:23,  3.56s/it] 12%|â–ˆâ–        | 736/6000 [43:15<5:05:24,  3.48s/it]                                                    {'loss': 0.0446, 'grad_norm': 2.9858665466308594, 'learning_rate': 4.461016949152543e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 736/6000 [43:15<5:05:24,  3.48s/it] 12%|â–ˆâ–        | 737/6000 [43:18<5:03:12,  3.46s/it]                                                    {'loss': 0.0648, 'grad_norm': 5.426126480102539, 'learning_rate': 4.460169491525424e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 737/6000 [43:18<5:03:12,  3.46s/it] 12%|â–ˆâ–        | 738/6000 [43:21<4:59:54,  3.42s/it]                                                    {'loss': 0.2106, 'grad_norm': 12.507049560546875, 'learning_rate': 4.459322033898305e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 738/6000 [43:21<4:59:54,  3.42s/it] 12%|â–ˆâ–        | 739/6000 [43:25<4:59:37,  3.42s/it]                                                    {'loss': 0.042, 'grad_norm': 3.2471158504486084, 'learning_rate': 4.4584745762711864e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 739/6000 [43:25<4:59:37,  3.42s/it] 12%|â–ˆâ–        | 740/6000 [43:28<5:02:44,  3.45s/it]                                                    {'loss': 0.2001, 'grad_norm': 7.738649845123291, 'learning_rate': 4.457627118644068e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 740/6000 [43:28<5:02:44,  3.45s/it] 12%|â–ˆâ–        | 741/6000 [43:32<5:05:05,  3.48s/it]                                                    {'loss': 0.0372, 'grad_norm': 3.0005123615264893, 'learning_rate': 4.4567796610169494e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 741/6000 [43:32<5:05:05,  3.48s/it] 12%|â–ˆâ–        | 742/6000 [43:35<5:04:37,  3.48s/it]                                                    {'loss': 0.002, 'grad_norm': 0.3153722584247589, 'learning_rate': 4.455932203389831e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 742/6000 [43:35<5:04:37,  3.48s/it] 12%|â–ˆâ–        | 743/6000 [43:39<5:02:11,  3.45s/it]                                                    {'loss': 0.1548, 'grad_norm': 11.251775741577148, 'learning_rate': 4.455084745762712e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 743/6000 [43:39<5:02:11,  3.45s/it] 12%|â–ˆâ–        | 744/6000 [43:42<4:58:59,  3.41s/it]                                                    {'loss': 0.0213, 'grad_norm': 1.3205513954162598, 'learning_rate': 4.4542372881355934e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 744/6000 [43:42<4:58:59,  3.41s/it] 12%|â–ˆâ–        | 745/6000 [43:45<4:58:37,  3.41s/it]                                                    {'loss': 0.1583, 'grad_norm': 6.239482879638672, 'learning_rate': 4.4533898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 745/6000 [43:45<4:58:37,  3.41s/it] 12%|â–ˆâ–        | 746/6000 [43:49<4:59:33,  3.42s/it]                                                    {'loss': 0.3474, 'grad_norm': 9.891661643981934, 'learning_rate': 4.452542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 746/6000 [43:49<4:59:33,  3.42s/it] 12%|â–ˆâ–        | 747/6000 [43:52<5:00:06,  3.43s/it]                                                    {'loss': 0.1433, 'grad_norm': 9.994091987609863, 'learning_rate': 4.4516949152542375e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 747/6000 [43:52<5:00:06,  3.43s/it] 12%|â–ˆâ–        | 748/6000 [43:56<5:02:08,  3.45s/it]                                                    {'loss': 0.0804, 'grad_norm': 8.786584854125977, 'learning_rate': 4.4508474576271186e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 748/6000 [43:56<5:02:08,  3.45s/it] 12%|â–ˆâ–        | 749/6000 [44:00<5:21:58,  3.68s/it]                                                    {'loss': 0.1006, 'grad_norm': 9.000566482543945, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 749/6000 [44:00<5:21:58,  3.68s/it] 12%|â–ˆâ–Ž        | 750/6000 [44:04<5:23:46,  3.70s/it]                                                    {'loss': 0.2349, 'grad_norm': 9.58348274230957, 'learning_rate': 4.4491525423728816e-05, 'epoch': 0.12}
 12%|â–ˆâ–Ž        | 750/6000 [44:04<5:23:46,  3.70s/it][2025-10-20 00:21:09,041] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 751/6000 [44:09<6:14:24,  4.28s/it]                                                    {'loss': 0.0159, 'grad_norm': 1.6087746620178223, 'learning_rate': 4.448305084745763e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 751/6000 [44:09<6:14:24,  4.28s/it] 13%|â–ˆâ–Ž        | 752/6000 [44:13<6:04:46,  4.17s/it]                                                    {'loss': 0.0109, 'grad_norm': 1.765172004699707, 'learning_rate': 4.447457627118644e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 752/6000 [44:13<6:04:46,  4.17s/it] 13%|â–ˆâ–Ž        | 753/6000 [44:17<5:51:14,  4.02s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.07197190821170807, 'learning_rate': 4.4466101694915256e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 753/6000 [44:17<5:51:14,  4.02s/it] 13%|â–ˆâ–Ž        | 754/6000 [44:20<5:35:16,  3.83s/it]                                                    {'loss': 0.0507, 'grad_norm': 3.3145501613616943, 'learning_rate': 4.445762711864407e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 754/6000 [44:20<5:35:16,  3.83s/it] 13%|â–ˆâ–Ž        | 755/6000 [44:24<5:21:03,  3.67s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.15825234353542328, 'learning_rate': 4.4449152542372886e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 755/6000 [44:24<5:21:03,  3.67s/it] 13%|â–ˆâ–Ž        | 756/6000 [44:27<5:10:53,  3.56s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.12898626923561096, 'learning_rate': 4.44406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 756/6000 [44:27<5:10:53,  3.56s/it] 13%|â–ˆâ–Ž        | 757/6000 [44:31<5:12:32,  3.58s/it]                                                    {'loss': 0.0156, 'grad_norm': 2.6359710693359375, 'learning_rate': 4.4432203389830515e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 757/6000 [44:31<5:12:32,  3.58s/it] 13%|â–ˆâ–Ž        | 758/6000 [44:34<5:09:41,  3.54s/it]                                                    {'loss': 0.0111, 'grad_norm': 2.870353937149048, 'learning_rate': 4.4423728813559326e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 758/6000 [44:34<5:09:41,  3.54s/it] 13%|â–ˆâ–Ž        | 759/6000 [44:37<5:05:27,  3.50s/it]                                                    {'loss': 0.2169, 'grad_norm': 9.133469581604004, 'learning_rate': 4.441525423728814e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 759/6000 [44:37<5:05:27,  3.50s/it] 13%|â–ˆâ–Ž        | 760/6000 [44:41<5:03:17,  3.47s/it]                                                    {'loss': 0.0111, 'grad_norm': 2.024479389190674, 'learning_rate': 4.440677966101695e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 760/6000 [44:41<5:03:17,  3.47s/it] 13%|â–ˆâ–Ž        | 761/6000 [44:44<5:02:32,  3.46s/it]                                                    {'loss': 0.0512, 'grad_norm': 4.063677787780762, 'learning_rate': 4.439830508474577e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 761/6000 [44:44<5:02:32,  3.46s/it] 13%|â–ˆâ–Ž        | 762/6000 [44:48<5:05:09,  3.50s/it]                                                    {'loss': 0.0947, 'grad_norm': 8.306117057800293, 'learning_rate': 4.438983050847458e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 762/6000 [44:48<5:05:09,  3.50s/it] 13%|â–ˆâ–Ž        | 763/6000 [44:51<5:00:41,  3.45s/it]                                                    {'loss': 0.0992, 'grad_norm': 4.672121047973633, 'learning_rate': 4.4381355932203396e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 763/6000 [44:51<5:00:41,  3.45s/it] 13%|â–ˆâ–Ž        | 764/6000 [44:55<4:59:38,  3.43s/it]                                                    {'loss': 0.076, 'grad_norm': 7.568717956542969, 'learning_rate': 4.437288135593221e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 764/6000 [44:55<4:59:38,  3.43s/it] 13%|â–ˆâ–Ž        | 765/6000 [44:58<4:57:37,  3.41s/it]                                                    {'loss': 0.0353, 'grad_norm': 4.679016590118408, 'learning_rate': 4.436440677966102e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 765/6000 [44:58<4:57:37,  3.41s/it] 13%|â–ˆâ–Ž        | 766/6000 [45:01<4:59:38,  3.43s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.0962112545967102, 'learning_rate': 4.435593220338983e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 766/6000 [45:01<4:59:38,  3.43s/it] 13%|â–ˆâ–Ž        | 767/6000 [45:05<5:08:43,  3.54s/it]                                                    {'loss': 0.0034, 'grad_norm': 0.6176832318305969, 'learning_rate': 4.434745762711864e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 767/6000 [45:05<5:08:43,  3.54s/it] 13%|â–ˆâ–Ž        | 768/6000 [45:09<5:04:41,  3.49s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.2057533264160156, 'learning_rate': 4.433898305084746e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 768/6000 [45:09<5:04:41,  3.49s/it] 13%|â–ˆâ–Ž        | 769/6000 [45:12<5:08:59,  3.54s/it]                                                    {'loss': 0.0296, 'grad_norm': 1.4946097135543823, 'learning_rate': 4.433050847457627e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 769/6000 [45:12<5:08:59,  3.54s/it] 13%|â–ˆâ–Ž        | 770/6000 [45:16<5:04:17,  3.49s/it]                                                    {'loss': 0.1171, 'grad_norm': 6.440884113311768, 'learning_rate': 4.432203389830509e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 770/6000 [45:16<5:04:17,  3.49s/it] 13%|â–ˆâ–Ž        | 771/6000 [45:19<4:59:46,  3.44s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.16570007801055908, 'learning_rate': 4.43135593220339e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 771/6000 [45:19<4:59:46,  3.44s/it] 13%|â–ˆâ–Ž        | 772/6000 [45:22<4:57:10,  3.41s/it]                                                    {'loss': 0.0264, 'grad_norm': 3.815366268157959, 'learning_rate': 4.430508474576272e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 772/6000 [45:22<4:57:10,  3.41s/it] 13%|â–ˆâ–Ž        | 773/6000 [45:26<4:55:10,  3.39s/it]                                                    {'loss': 0.166, 'grad_norm': 8.822845458984375, 'learning_rate': 4.429661016949152e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 773/6000 [45:26<4:55:10,  3.39s/it] 13%|â–ˆâ–Ž        | 774/6000 [45:29<4:54:37,  3.38s/it]                                                    {'loss': 0.0035, 'grad_norm': 0.3624189794063568, 'learning_rate': 4.428813559322034e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 774/6000 [45:29<4:54:37,  3.38s/it] 13%|â–ˆâ–Ž        | 775/6000 [45:33<4:59:10,  3.44s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.2265215665102005, 'learning_rate': 4.427966101694915e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 775/6000 [45:33<4:59:10,  3.44s/it] 13%|â–ˆâ–Ž        | 776/6000 [45:36<5:00:09,  3.45s/it]                                                    {'loss': 0.0175, 'grad_norm': 2.5592119693756104, 'learning_rate': 4.427118644067797e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 776/6000 [45:36<5:00:09,  3.45s/it] 13%|â–ˆâ–Ž        | 777/6000 [45:40<5:04:29,  3.50s/it]                                                    {'loss': 0.0238, 'grad_norm': 3.522394895553589, 'learning_rate': 4.426271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 777/6000 [45:40<5:04:29,  3.50s/it] 13%|â–ˆâ–Ž        | 778/6000 [45:43<5:11:14,  3.58s/it]                                                    {'loss': 0.0915, 'grad_norm': 3.58042311668396, 'learning_rate': 4.42542372881356e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 778/6000 [45:43<5:11:14,  3.58s/it] 13%|â–ˆâ–Ž        | 779/6000 [45:47<5:06:53,  3.53s/it]                                                    {'loss': 0.1361, 'grad_norm': 8.410462379455566, 'learning_rate': 4.424576271186441e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 779/6000 [45:47<5:06:53,  3.53s/it] 13%|â–ˆâ–Ž        | 780/6000 [45:50<5:03:45,  3.49s/it]                                                    {'loss': 0.0139, 'grad_norm': 2.132455825805664, 'learning_rate': 4.423728813559322e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 780/6000 [45:50<5:03:45,  3.49s/it] 13%|â–ˆâ–Ž        | 781/6000 [45:54<5:01:06,  3.46s/it]                                                    {'loss': 0.0458, 'grad_norm': 7.414147853851318, 'learning_rate': 4.422881355932203e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 781/6000 [45:54<5:01:06,  3.46s/it] 13%|â–ˆâ–Ž        | 782/6000 [45:57<4:57:52,  3.43s/it]                                                    {'loss': 0.1555, 'grad_norm': 10.928972244262695, 'learning_rate': 4.422033898305085e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 782/6000 [45:57<4:57:52,  3.43s/it] 13%|â–ˆâ–Ž        | 783/6000 [46:00<4:54:45,  3.39s/it]                                                    {'loss': 0.0518, 'grad_norm': 5.303550720214844, 'learning_rate': 4.421186440677966e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 783/6000 [46:00<4:54:45,  3.39s/it] 13%|â–ˆâ–Ž        | 784/6000 [46:04<4:54:48,  3.39s/it]                                                    {'loss': 0.0842, 'grad_norm': 6.66156530380249, 'learning_rate': 4.420338983050848e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 784/6000 [46:04<4:54:48,  3.39s/it] 13%|â–ˆâ–Ž        | 785/6000 [46:07<4:52:21,  3.36s/it]                                                    {'loss': 0.3867, 'grad_norm': 12.865195274353027, 'learning_rate': 4.419491525423729e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 785/6000 [46:07<4:52:21,  3.36s/it] 13%|â–ˆâ–Ž        | 786/6000 [46:10<4:50:14,  3.34s/it]                                                    {'loss': 0.0934, 'grad_norm': 9.35097599029541, 'learning_rate': 4.41864406779661e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 786/6000 [46:10<4:50:14,  3.34s/it] 13%|â–ˆâ–Ž        | 787/6000 [46:14<4:53:05,  3.37s/it]                                                    {'loss': 0.0855, 'grad_norm': 8.432511329650879, 'learning_rate': 4.4177966101694914e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 787/6000 [46:14<4:53:05,  3.37s/it] 13%|â–ˆâ–Ž        | 788/6000 [46:17<4:54:28,  3.39s/it]                                                    {'loss': 0.02, 'grad_norm': 2.656026840209961, 'learning_rate': 4.4169491525423726e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 788/6000 [46:17<4:54:28,  3.39s/it] 13%|â–ˆâ–Ž        | 789/6000 [46:21<4:57:33,  3.43s/it]                                                    {'loss': 0.0795, 'grad_norm': 8.119989395141602, 'learning_rate': 4.4161016949152544e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 789/6000 [46:21<4:57:33,  3.43s/it] 13%|â–ˆâ–Ž        | 790/6000 [46:24<4:54:33,  3.39s/it]                                                    {'loss': 0.1328, 'grad_norm': 7.146642684936523, 'learning_rate': 4.4152542372881355e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 790/6000 [46:24<4:54:33,  3.39s/it] 13%|â–ˆâ–Ž        | 791/6000 [46:27<4:54:46,  3.40s/it]                                                    {'loss': 0.0372, 'grad_norm': 3.192793369293213, 'learning_rate': 4.414406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 791/6000 [46:27<4:54:46,  3.40s/it] 13%|â–ˆâ–Ž        | 792/6000 [46:31<4:56:07,  3.41s/it]                                                    {'loss': 0.0819, 'grad_norm': 8.384567260742188, 'learning_rate': 4.4135593220338984e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 792/6000 [46:31<4:56:07,  3.41s/it] 13%|â–ˆâ–Ž        | 793/6000 [46:34<4:54:38,  3.40s/it]                                                    {'loss': 0.0072, 'grad_norm': 1.4212747812271118, 'learning_rate': 4.41271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 793/6000 [46:34<4:54:38,  3.40s/it] 13%|â–ˆâ–Ž        | 794/6000 [46:38<4:57:10,  3.42s/it]                                                    {'loss': 0.0297, 'grad_norm': 3.7117345333099365, 'learning_rate': 4.4118644067796614e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 794/6000 [46:38<4:57:10,  3.42s/it] 13%|â–ˆâ–Ž        | 795/6000 [46:41<5:05:12,  3.52s/it]                                                    {'loss': 0.0435, 'grad_norm': 7.04285192489624, 'learning_rate': 4.4110169491525425e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 795/6000 [46:41<5:05:12,  3.52s/it] 13%|â–ˆâ–Ž        | 796/6000 [46:45<5:00:41,  3.47s/it]                                                    {'loss': 0.1783, 'grad_norm': 8.065217018127441, 'learning_rate': 4.4101694915254236e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 796/6000 [46:45<5:00:41,  3.47s/it] 13%|â–ˆâ–Ž        | 797/6000 [46:48<4:59:08,  3.45s/it]                                                    {'loss': 0.0385, 'grad_norm': 4.730283737182617, 'learning_rate': 4.4093220338983054e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 797/6000 [46:48<4:59:08,  3.45s/it] 13%|â–ˆâ–Ž        | 798/6000 [46:51<4:57:10,  3.43s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.14894945919513702, 'learning_rate': 4.4084745762711866e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 798/6000 [46:51<4:57:10,  3.43s/it] 13%|â–ˆâ–Ž        | 799/6000 [46:55<4:57:58,  3.44s/it]                                                    {'loss': 0.1624, 'grad_norm': 7.745637893676758, 'learning_rate': 4.4076271186440684e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 799/6000 [46:55<4:57:58,  3.44s/it] 13%|â–ˆâ–Ž        | 800/6000 [46:58<4:58:38,  3.45s/it]                                                    {'loss': 0.0703, 'grad_norm': 9.642127990722656, 'learning_rate': 4.4067796610169495e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 800/6000 [46:58<4:58:38,  3.45s/it][2025-10-20 00:24:03,748] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 801/6000 [47:04<6:01:18,  4.17s/it]                                                    {'loss': 0.0027, 'grad_norm': 0.5047283172607422, 'learning_rate': 4.4059322033898306e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 801/6000 [47:04<6:01:18,  4.17s/it] 13%|â–ˆâ–Ž        | 802/6000 [47:08<5:42:50,  3.96s/it]                                                    {'loss': 0.0307, 'grad_norm': 5.296844482421875, 'learning_rate': 4.405084745762712e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 802/6000 [47:08<5:42:50,  3.96s/it] 13%|â–ˆâ–Ž        | 803/6000 [47:11<5:27:16,  3.78s/it]                                                    {'loss': 0.1463, 'grad_norm': 4.6358323097229, 'learning_rate': 4.4042372881355936e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 803/6000 [47:11<5:27:16,  3.78s/it] 13%|â–ˆâ–Ž        | 804/6000 [47:14<5:16:59,  3.66s/it]                                                    {'loss': 0.1115, 'grad_norm': 7.9368815422058105, 'learning_rate': 4.403389830508475e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 804/6000 [47:14<5:16:59,  3.66s/it] 13%|â–ˆâ–Ž        | 805/6000 [47:18<5:10:22,  3.58s/it]                                                    {'loss': 0.0262, 'grad_norm': 3.729325771331787, 'learning_rate': 4.4025423728813565e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 805/6000 [47:18<5:10:22,  3.58s/it] 13%|â–ˆâ–Ž        | 806/6000 [47:21<5:09:25,  3.57s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.07620567083358765, 'learning_rate': 4.4016949152542376e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 806/6000 [47:21<5:09:25,  3.57s/it] 13%|â–ˆâ–Ž        | 807/6000 [47:25<5:02:41,  3.50s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.31281813979148865, 'learning_rate': 4.400847457627119e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 807/6000 [47:25<5:02:41,  3.50s/it] 13%|â–ˆâ–Ž        | 808/6000 [47:28<4:58:25,  3.45s/it]                                                    {'loss': 0.0082, 'grad_norm': 1.5654196739196777, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 808/6000 [47:28<4:58:25,  3.45s/it] 13%|â–ˆâ–Ž        | 809/6000 [47:31<4:55:03,  3.41s/it]                                                    {'loss': 0.0015, 'grad_norm': 0.15397490561008453, 'learning_rate': 4.399152542372881e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 809/6000 [47:31<4:55:03,  3.41s/it] 14%|â–ˆâ–Ž        | 810/6000 [47:35<4:56:56,  3.43s/it]                                                    {'loss': 0.2688, 'grad_norm': 11.276192665100098, 'learning_rate': 4.398305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 810/6000 [47:35<4:56:56,  3.43s/it] 14%|â–ˆâ–Ž        | 811/6000 [47:38<4:54:26,  3.40s/it]                                                    {'loss': 0.0148, 'grad_norm': 1.5812766551971436, 'learning_rate': 4.397457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 811/6000 [47:38<4:54:26,  3.40s/it] 14%|â–ˆâ–Ž        | 812/6000 [47:42<4:51:23,  3.37s/it]                                                    {'loss': 0.0139, 'grad_norm': 2.040379524230957, 'learning_rate': 4.396610169491526e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 812/6000 [47:42<4:51:23,  3.37s/it] 14%|â–ˆâ–Ž        | 813/6000 [47:46<5:10:09,  3.59s/it]                                                    {'loss': 0.1862, 'grad_norm': 9.75643539428711, 'learning_rate': 4.395762711864407e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 813/6000 [47:46<5:10:09,  3.59s/it] 14%|â–ˆâ–Ž        | 814/6000 [47:49<5:04:41,  3.53s/it]                                                    {'loss': 0.06, 'grad_norm': 5.331162452697754, 'learning_rate': 4.394915254237289e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 814/6000 [47:49<5:04:41,  3.53s/it] 14%|â–ˆâ–Ž        | 815/6000 [47:52<5:00:04,  3.47s/it]                                                    {'loss': 0.0093, 'grad_norm': 1.8466850519180298, 'learning_rate': 4.39406779661017e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 815/6000 [47:52<5:00:04,  3.47s/it] 14%|â–ˆâ–Ž        | 816/6000 [47:56<4:55:53,  3.42s/it]                                                    {'loss': 0.0975, 'grad_norm': 8.40169906616211, 'learning_rate': 4.393220338983051e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 816/6000 [47:56<4:55:53,  3.42s/it] 14%|â–ˆâ–Ž        | 817/6000 [48:00<5:16:01,  3.66s/it]                                                    {'loss': 0.156, 'grad_norm': 8.37076473236084, 'learning_rate': 4.392372881355932e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 817/6000 [48:00<5:16:01,  3.66s/it] 14%|â–ˆâ–Ž        | 818/6000 [48:03<5:07:16,  3.56s/it]                                                    {'loss': 0.0216, 'grad_norm': 3.5827295780181885, 'learning_rate': 4.391525423728814e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 818/6000 [48:03<5:07:16,  3.56s/it] 14%|â–ˆâ–Ž        | 819/6000 [48:07<5:03:56,  3.52s/it]                                                    {'loss': 0.0441, 'grad_norm': 3.131828546524048, 'learning_rate': 4.390677966101695e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 819/6000 [48:07<5:03:56,  3.52s/it] 14%|â–ˆâ–Ž        | 820/6000 [48:10<5:00:00,  3.48s/it]                                                    {'loss': 0.0172, 'grad_norm': 1.8264634609222412, 'learning_rate': 4.389830508474577e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 820/6000 [48:10<5:00:00,  3.48s/it] 14%|â–ˆâ–Ž        | 821/6000 [48:13<4:59:30,  3.47s/it]                                                    {'loss': 0.005, 'grad_norm': 0.7739611864089966, 'learning_rate': 4.388983050847458e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 821/6000 [48:13<4:59:30,  3.47s/it] 14%|â–ˆâ–Ž        | 822/6000 [48:17<4:56:07,  3.43s/it]                                                    {'loss': 0.0009, 'grad_norm': 0.11805280297994614, 'learning_rate': 4.388135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 822/6000 [48:17<4:56:07,  3.43s/it] 14%|â–ˆâ–Ž        | 823/6000 [48:20<4:54:35,  3.41s/it]                                                    {'loss': 0.0435, 'grad_norm': 4.230075836181641, 'learning_rate': 4.38728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 823/6000 [48:20<4:54:35,  3.41s/it] 14%|â–ˆâ–Ž        | 824/6000 [48:24<4:52:39,  3.39s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.07421263307332993, 'learning_rate': 4.386440677966102e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 824/6000 [48:24<4:52:39,  3.39s/it] 14%|â–ˆâ–        | 825/6000 [48:27<4:59:04,  3.47s/it]                                                    {'loss': 0.0869, 'grad_norm': 6.294147491455078, 'learning_rate': 4.385593220338983e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 825/6000 [48:27<4:59:04,  3.47s/it] 14%|â–ˆâ–        | 826/6000 [48:31<4:56:17,  3.44s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.5205812454223633, 'learning_rate': 4.384745762711865e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 826/6000 [48:31<4:56:17,  3.44s/it] 14%|â–ˆâ–        | 827/6000 [48:34<4:55:41,  3.43s/it]                                                    {'loss': 0.0222, 'grad_norm': 3.5868849754333496, 'learning_rate': 4.383898305084746e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 827/6000 [48:34<4:55:41,  3.43s/it] 14%|â–ˆâ–        | 828/6000 [48:37<4:54:44,  3.42s/it]                                                    {'loss': 0.3765, 'grad_norm': 10.198968887329102, 'learning_rate': 4.383050847457627e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 828/6000 [48:37<4:54:44,  3.42s/it] 14%|â–ˆâ–        | 829/6000 [48:41<4:56:37,  3.44s/it]                                                    {'loss': 0.1132, 'grad_norm': 4.522244453430176, 'learning_rate': 4.382203389830509e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 829/6000 [48:41<4:56:37,  3.44s/it] 14%|â–ˆâ–        | 830/6000 [48:45<5:18:26,  3.70s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.33884021639823914, 'learning_rate': 4.38135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 830/6000 [48:45<5:18:26,  3.70s/it] 14%|â–ˆâ–        | 831/6000 [48:49<5:13:01,  3.63s/it]                                                    {'loss': 0.0622, 'grad_norm': 6.199486255645752, 'learning_rate': 4.380508474576271e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 831/6000 [48:49<5:13:01,  3.63s/it] 14%|â–ˆâ–        | 832/6000 [48:52<5:06:59,  3.56s/it]                                                    {'loss': 0.1045, 'grad_norm': 7.575747489929199, 'learning_rate': 4.3796610169491524e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 832/6000 [48:52<5:06:59,  3.56s/it] 14%|â–ˆâ–        | 833/6000 [48:55<5:03:01,  3.52s/it]                                                    {'loss': 0.0036, 'grad_norm': 0.5877730250358582, 'learning_rate': 4.378813559322034e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 833/6000 [48:55<5:03:01,  3.52s/it] 14%|â–ˆâ–        | 834/6000 [48:59<4:59:19,  3.48s/it]                                                    {'loss': 0.0679, 'grad_norm': 6.618907928466797, 'learning_rate': 4.377966101694915e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 834/6000 [48:59<4:59:19,  3.48s/it] 14%|â–ˆâ–        | 835/6000 [49:03<5:12:47,  3.63s/it]                                                    {'loss': 0.0131, 'grad_norm': 1.3888100385665894, 'learning_rate': 4.377118644067797e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 835/6000 [49:03<5:12:47,  3.63s/it] 14%|â–ˆâ–        | 836/6000 [49:06<5:03:04,  3.52s/it]                                                    {'loss': 0.0914, 'grad_norm': 8.250635147094727, 'learning_rate': 4.376271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 836/6000 [49:06<5:03:04,  3.52s/it] 14%|â–ˆâ–        | 837/6000 [49:10<5:23:54,  3.76s/it]                                                    {'loss': 0.0645, 'grad_norm': 6.759537696838379, 'learning_rate': 4.3754237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 837/6000 [49:10<5:23:54,  3.76s/it] 14%|â–ˆâ–        | 838/6000 [49:14<5:25:27,  3.78s/it]                                                    {'loss': 0.0841, 'grad_norm': 9.540082931518555, 'learning_rate': 4.3745762711864405e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 838/6000 [49:14<5:25:27,  3.78s/it] 14%|â–ˆâ–        | 839/6000 [49:18<5:15:45,  3.67s/it]                                                    {'loss': 0.0067, 'grad_norm': 1.0559035539627075, 'learning_rate': 4.373728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 839/6000 [49:18<5:15:45,  3.67s/it] 14%|â–ˆâ–        | 840/6000 [49:21<5:10:32,  3.61s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.11562829464673996, 'learning_rate': 4.3728813559322035e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 840/6000 [49:21<5:10:32,  3.61s/it] 14%|â–ˆâ–        | 841/6000 [49:25<5:15:16,  3.67s/it]                                                    {'loss': 0.0999, 'grad_norm': 7.250383377075195, 'learning_rate': 4.372033898305085e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 841/6000 [49:25<5:15:16,  3.67s/it] 14%|â–ˆâ–        | 842/6000 [49:28<5:06:16,  3.56s/it]                                                    {'loss': 0.1278, 'grad_norm': 8.109253883361816, 'learning_rate': 4.3711864406779664e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 842/6000 [49:28<5:06:16,  3.56s/it] 14%|â–ˆâ–        | 843/6000 [49:31<4:58:42,  3.48s/it]                                                    {'loss': 0.0644, 'grad_norm': 7.629698276519775, 'learning_rate': 4.370338983050848e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 843/6000 [49:31<4:58:42,  3.48s/it] 14%|â–ˆâ–        | 844/6000 [49:35<4:59:13,  3.48s/it]                                                    {'loss': 0.0469, 'grad_norm': 5.812397003173828, 'learning_rate': 4.3694915254237286e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 844/6000 [49:35<4:59:13,  3.48s/it] 14%|â–ˆâ–        | 845/6000 [49:38<4:55:07,  3.43s/it]                                                    {'loss': 0.0115, 'grad_norm': 2.050307035446167, 'learning_rate': 4.3686440677966105e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 845/6000 [49:38<4:55:07,  3.43s/it] 14%|â–ˆâ–        | 846/6000 [49:42<4:56:39,  3.45s/it]                                                    {'loss': 0.0163, 'grad_norm': 2.822455644607544, 'learning_rate': 4.3677966101694916e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 846/6000 [49:42<4:56:39,  3.45s/it] 14%|â–ˆâ–        | 847/6000 [49:45<5:00:42,  3.50s/it]                                                    {'loss': 0.0454, 'grad_norm': 2.5661449432373047, 'learning_rate': 4.3669491525423734e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 847/6000 [49:45<5:00:42,  3.50s/it] 14%|â–ˆâ–        | 848/6000 [49:49<5:09:15,  3.60s/it]                                                    {'loss': 0.0999, 'grad_norm': 4.219094276428223, 'learning_rate': 4.3661016949152545e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 848/6000 [49:49<5:09:15,  3.60s/it] 14%|â–ˆâ–        | 849/6000 [49:53<5:06:17,  3.57s/it]                                                    {'loss': 0.0166, 'grad_norm': 2.197442054748535, 'learning_rate': 4.3652542372881356e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 849/6000 [49:53<5:06:17,  3.57s/it] 14%|â–ˆâ–        | 850/6000 [49:56<5:01:24,  3.51s/it]                                                    {'loss': 0.0292, 'grad_norm': 3.5719845294952393, 'learning_rate': 4.3644067796610175e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 850/6000 [49:56<5:01:24,  3.51s/it][2025-10-20 00:27:01,441] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 14%|â–ˆâ–        | 851/6000 [50:02<5:54:01,  4.13s/it]                                                    {'loss': 0.0886, 'grad_norm': 6.498027324676514, 'learning_rate': 4.3635593220338986e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 851/6000 [50:02<5:54:01,  4.13s/it] 14%|â–ˆâ–        | 852/6000 [50:05<5:36:35,  3.92s/it]                                                    {'loss': 0.1139, 'grad_norm': 5.9175944328308105, 'learning_rate': 4.36271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 852/6000 [50:05<5:36:35,  3.92s/it] 14%|â–ˆâ–        | 853/6000 [50:08<5:20:53,  3.74s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.5486823320388794, 'learning_rate': 4.361864406779661e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 853/6000 [50:08<5:20:53,  3.74s/it] 14%|â–ˆâ–        | 854/6000 [50:12<5:16:29,  3.69s/it]                                                    {'loss': 0.0312, 'grad_norm': 4.21783971786499, 'learning_rate': 4.3610169491525426e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 854/6000 [50:12<5:16:29,  3.69s/it] 14%|â–ˆâ–        | 855/6000 [50:15<5:10:31,  3.62s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.16848896443843842, 'learning_rate': 4.360169491525424e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 855/6000 [50:15<5:10:31,  3.62s/it] 14%|â–ˆâ–        | 856/6000 [50:19<5:07:55,  3.59s/it]                                                    {'loss': 0.1618, 'grad_norm': 8.325222969055176, 'learning_rate': 4.3593220338983056e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 856/6000 [50:19<5:07:55,  3.59s/it] 14%|â–ˆâ–        | 857/6000 [50:22<5:02:45,  3.53s/it]                                                    {'loss': 0.0022, 'grad_norm': 0.4241466820240021, 'learning_rate': 4.358474576271187e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 857/6000 [50:22<5:02:45,  3.53s/it] 14%|â–ˆâ–        | 858/6000 [50:26<5:00:29,  3.51s/it]                                                    {'loss': 0.0144, 'grad_norm': 1.383100152015686, 'learning_rate': 4.357627118644068e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 858/6000 [50:26<5:00:29,  3.51s/it] 14%|â–ˆâ–        | 859/6000 [50:29<4:57:06,  3.47s/it]                                                    {'loss': 0.0083, 'grad_norm': 0.9408062696456909, 'learning_rate': 4.356779661016949e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 859/6000 [50:29<4:57:06,  3.47s/it] 14%|â–ˆâ–        | 860/6000 [50:33<5:06:24,  3.58s/it]                                                    {'loss': 0.0977, 'grad_norm': 6.372868537902832, 'learning_rate': 4.355932203389831e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 860/6000 [50:33<5:06:24,  3.58s/it] 14%|â–ˆâ–        | 861/6000 [50:36<4:59:36,  3.50s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.38020458817481995, 'learning_rate': 4.355084745762712e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 861/6000 [50:36<4:59:36,  3.50s/it] 14%|â–ˆâ–        | 862/6000 [50:40<4:55:35,  3.45s/it]                                                    {'loss': 0.1932, 'grad_norm': 11.149364471435547, 'learning_rate': 4.354237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 862/6000 [50:40<4:55:35,  3.45s/it] 14%|â–ˆâ–        | 863/6000 [50:43<4:55:05,  3.45s/it]                                                    {'loss': 0.0519, 'grad_norm': 7.288707256317139, 'learning_rate': 4.353389830508475e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 863/6000 [50:43<4:55:05,  3.45s/it] 14%|â–ˆâ–        | 864/6000 [50:46<4:53:01,  3.42s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.09544134140014648, 'learning_rate': 4.3525423728813566e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 864/6000 [50:47<4:53:01,  3.42s/it] 14%|â–ˆâ–        | 865/6000 [50:50<5:01:54,  3.53s/it]                                                    {'loss': 0.1876, 'grad_norm': 11.458773612976074, 'learning_rate': 4.351694915254238e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 865/6000 [50:50<5:01:54,  3.53s/it] 14%|â–ˆâ–        | 866/6000 [50:54<4:58:09,  3.48s/it]                                                    {'loss': 0.0965, 'grad_norm': 8.138599395751953, 'learning_rate': 4.350847457627119e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 866/6000 [50:54<4:58:09,  3.48s/it] 14%|â–ˆâ–        | 867/6000 [50:57<4:56:19,  3.46s/it]                                                    {'loss': 0.3011, 'grad_norm': 10.9650297164917, 'learning_rate': 4.35e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 867/6000 [50:57<4:56:19,  3.46s/it] 14%|â–ˆâ–        | 868/6000 [51:00<4:51:29,  3.41s/it]                                                    {'loss': 0.1237, 'grad_norm': 8.251051902770996, 'learning_rate': 4.349152542372882e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 868/6000 [51:00<4:51:29,  3.41s/it] 14%|â–ˆâ–        | 869/6000 [51:04<4:50:25,  3.40s/it]                                                    {'loss': 0.0025, 'grad_norm': 0.36655932664871216, 'learning_rate': 4.348305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 869/6000 [51:04<4:50:25,  3.40s/it] 14%|â–ˆâ–        | 870/6000 [51:07<4:49:55,  3.39s/it]                                                    {'loss': 0.0686, 'grad_norm': 6.41490364074707, 'learning_rate': 4.347457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 870/6000 [51:07<4:49:55,  3.39s/it] 15%|â–ˆâ–        | 871/6000 [51:11<4:51:00,  3.40s/it]                                                    {'loss': 0.0295, 'grad_norm': 4.004617214202881, 'learning_rate': 4.346610169491526e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 871/6000 [51:11<4:51:00,  3.40s/it] 15%|â–ˆâ–        | 872/6000 [51:14<4:51:56,  3.42s/it]                                                    {'loss': 0.1374, 'grad_norm': 7.293117046356201, 'learning_rate': 4.345762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 872/6000 [51:14<4:51:56,  3.42s/it] 15%|â–ˆâ–        | 873/6000 [51:17<4:52:22,  3.42s/it]                                                    {'loss': 0.0617, 'grad_norm': 4.927126884460449, 'learning_rate': 4.344915254237288e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 873/6000 [51:17<4:52:22,  3.42s/it] 15%|â–ˆâ–        | 874/6000 [51:21<4:52:12,  3.42s/it]                                                    {'loss': 0.1331, 'grad_norm': 10.917007446289062, 'learning_rate': 4.344067796610169e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 874/6000 [51:21<4:52:12,  3.42s/it] 15%|â–ˆâ–        | 875/6000 [51:25<4:58:42,  3.50s/it]                                                    {'loss': 0.1059, 'grad_norm': 7.522167205810547, 'learning_rate': 4.343220338983051e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 875/6000 [51:25<4:58:42,  3.50s/it] 15%|â–ˆâ–        | 876/6000 [51:28<4:55:24,  3.46s/it]                                                    {'loss': 0.0157, 'grad_norm': 1.6789029836654663, 'learning_rate': 4.342372881355932e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 876/6000 [51:28<4:55:24,  3.46s/it] 15%|â–ˆâ–        | 877/6000 [51:31<4:54:03,  3.44s/it]                                                    {'loss': 0.1438, 'grad_norm': 8.760610580444336, 'learning_rate': 4.341525423728814e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 877/6000 [51:31<4:54:03,  3.44s/it] 15%|â–ˆâ–        | 878/6000 [51:35<4:54:16,  3.45s/it]                                                    {'loss': 0.0416, 'grad_norm': 4.48381233215332, 'learning_rate': 4.340677966101695e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 878/6000 [51:35<4:54:16,  3.45s/it] 15%|â–ˆâ–        | 879/6000 [51:39<5:08:54,  3.62s/it]                                                    {'loss': 0.0885, 'grad_norm': 4.688411712646484, 'learning_rate': 4.339830508474576e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 879/6000 [51:39<5:08:54,  3.62s/it] 15%|â–ˆâ–        | 880/6000 [51:42<5:04:19,  3.57s/it]                                                    {'loss': 0.377, 'grad_norm': 14.541470527648926, 'learning_rate': 4.3389830508474574e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 880/6000 [51:42<5:04:19,  3.57s/it] 15%|â–ˆâ–        | 881/6000 [51:46<5:00:22,  3.52s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.19827449321746826, 'learning_rate': 4.338135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 881/6000 [51:46<5:00:22,  3.52s/it] 15%|â–ˆâ–        | 882/6000 [51:49<4:59:54,  3.52s/it]                                                    {'loss': 0.0462, 'grad_norm': 4.426296234130859, 'learning_rate': 4.3372881355932203e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 882/6000 [51:49<4:59:54,  3.52s/it] 15%|â–ˆâ–        | 883/6000 [51:53<4:56:26,  3.48s/it]                                                    {'loss': 0.0202, 'grad_norm': 1.4859884977340698, 'learning_rate': 4.336440677966102e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 883/6000 [51:53<4:56:26,  3.48s/it] 15%|â–ˆâ–        | 884/6000 [51:56<5:01:13,  3.53s/it]                                                    {'loss': 0.1077, 'grad_norm': 6.7631378173828125, 'learning_rate': 4.335593220338983e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 884/6000 [51:56<5:01:13,  3.53s/it] 15%|â–ˆâ–        | 885/6000 [52:00<5:00:21,  3.52s/it]                                                    {'loss': 0.0132, 'grad_norm': 2.001941204071045, 'learning_rate': 4.334745762711865e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 885/6000 [52:00<5:00:21,  3.52s/it] 15%|â–ˆâ–        | 886/6000 [52:03<4:59:40,  3.52s/it]                                                    {'loss': 0.0351, 'grad_norm': 4.701663970947266, 'learning_rate': 4.333898305084746e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 886/6000 [52:03<4:59:40,  3.52s/it] 15%|â–ˆâ–        | 887/6000 [52:07<4:58:26,  3.50s/it]                                                    {'loss': 0.0042, 'grad_norm': 0.6921678781509399, 'learning_rate': 4.3330508474576273e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 887/6000 [52:07<4:58:26,  3.50s/it] 15%|â–ˆâ–        | 888/6000 [52:10<4:58:08,  3.50s/it]                                                    {'loss': 0.0129, 'grad_norm': 1.9986510276794434, 'learning_rate': 4.3322033898305085e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 888/6000 [52:10<4:58:08,  3.50s/it] 15%|â–ˆâ–        | 889/6000 [52:14<4:56:09,  3.48s/it]                                                    {'loss': 0.1263, 'grad_norm': 9.481947898864746, 'learning_rate': 4.33135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 889/6000 [52:14<4:56:09,  3.48s/it] 15%|â–ˆâ–        | 890/6000 [52:17<4:53:43,  3.45s/it]                                                    {'loss': 0.0119, 'grad_norm': 2.1335668563842773, 'learning_rate': 4.3305084745762714e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 890/6000 [52:17<4:53:43,  3.45s/it] 15%|â–ˆâ–        | 891/6000 [52:20<4:49:56,  3.41s/it]                                                    {'loss': 0.0346, 'grad_norm': 2.693626642227173, 'learning_rate': 4.3296610169491525e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 891/6000 [52:20<4:49:56,  3.41s/it] 15%|â–ˆâ–        | 892/6000 [52:24<4:48:51,  3.39s/it]                                                    {'loss': 0.0301, 'grad_norm': 2.6994681358337402, 'learning_rate': 4.3288135593220343e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 892/6000 [52:24<4:48:51,  3.39s/it] 15%|â–ˆâ–        | 893/6000 [52:27<4:46:39,  3.37s/it]                                                    {'loss': 0.1651, 'grad_norm': 8.515148162841797, 'learning_rate': 4.3279661016949155e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 893/6000 [52:27<4:46:39,  3.37s/it] 15%|â–ˆâ–        | 894/6000 [52:30<4:49:05,  3.40s/it]                                                    {'loss': 0.0294, 'grad_norm': 3.3776485919952393, 'learning_rate': 4.3271186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 894/6000 [52:30<4:49:05,  3.40s/it] 15%|â–ˆâ–        | 895/6000 [52:34<4:48:17,  3.39s/it]                                                    {'loss': 0.0288, 'grad_norm': 2.6081204414367676, 'learning_rate': 4.326271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 895/6000 [52:34<4:48:17,  3.39s/it] 15%|â–ˆâ–        | 896/6000 [52:37<4:47:19,  3.38s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.014223622158169746, 'learning_rate': 4.3254237288135595e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 896/6000 [52:37<4:47:19,  3.38s/it] 15%|â–ˆâ–        | 897/6000 [52:41<4:49:03,  3.40s/it]                                                    {'loss': 0.0214, 'grad_norm': 2.930271625518799, 'learning_rate': 4.3245762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 897/6000 [52:41<4:49:03,  3.40s/it] 15%|â–ˆâ–        | 898/6000 [52:44<4:48:48,  3.40s/it]                                                    {'loss': 0.0754, 'grad_norm': 4.808314800262451, 'learning_rate': 4.3237288135593225e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 898/6000 [52:44<4:48:48,  3.40s/it] 15%|â–ˆâ–        | 899/6000 [52:48<5:11:49,  3.67s/it]                                                    {'loss': 0.0049, 'grad_norm': 0.7640443444252014, 'learning_rate': 4.3228813559322036e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 899/6000 [52:48<5:11:49,  3.67s/it] 15%|â–ˆâ–Œ        | 900/6000 [52:52<5:06:24,  3.60s/it]                                                    {'loss': 0.0789, 'grad_norm': 5.666414260864258, 'learning_rate': 4.3220338983050854e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 900/6000 [52:52<5:06:24,  3.60s/it][2025-10-20 00:29:57,020] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|â–ˆâ–Œ        | 901/6000 [52:58<6:03:01,  4.27s/it]                                                    {'loss': 0.063, 'grad_norm': 7.695035457611084, 'learning_rate': 4.321186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 901/6000 [52:58<6:03:01,  4.27s/it] 15%|â–ˆâ–Œ        | 902/6000 [53:01<5:39:01,  3.99s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.3968796730041504, 'learning_rate': 4.3203389830508477e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 902/6000 [53:01<5:39:01,  3.99s/it] 15%|â–ˆâ–Œ        | 903/6000 [53:04<5:23:14,  3.81s/it]                                                    {'loss': 0.1126, 'grad_norm': 8.019902229309082, 'learning_rate': 4.319491525423729e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 903/6000 [53:04<5:23:14,  3.81s/it] 15%|â–ˆâ–Œ        | 904/6000 [53:08<5:13:09,  3.69s/it]                                                    {'loss': 0.2715, 'grad_norm': 6.819952487945557, 'learning_rate': 4.3186440677966106e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 904/6000 [53:08<5:13:09,  3.69s/it] 15%|â–ˆâ–Œ        | 905/6000 [53:12<5:21:05,  3.78s/it]                                                    {'loss': 0.0628, 'grad_norm': 6.794085502624512, 'learning_rate': 4.317796610169492e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 905/6000 [53:12<5:21:05,  3.78s/it] 15%|â–ˆâ–Œ        | 906/6000 [53:15<5:16:15,  3.73s/it]                                                    {'loss': 0.0257, 'grad_norm': 4.388708591461182, 'learning_rate': 4.3169491525423735e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 906/6000 [53:15<5:16:15,  3.73s/it] 15%|â–ˆâ–Œ        | 907/6000 [53:19<5:17:20,  3.74s/it]                                                    {'loss': 0.1503, 'grad_norm': 4.989123821258545, 'learning_rate': 4.3161016949152547e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 907/6000 [53:19<5:17:20,  3.74s/it] 15%|â–ˆâ–Œ        | 908/6000 [53:23<5:18:11,  3.75s/it]                                                    {'loss': 0.2141, 'grad_norm': 8.088080406188965, 'learning_rate': 4.315254237288136e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 908/6000 [53:23<5:18:11,  3.75s/it] 15%|â–ˆâ–Œ        | 909/6000 [53:26<5:07:51,  3.63s/it]                                                    {'loss': 0.0132, 'grad_norm': 1.2407596111297607, 'learning_rate': 4.314406779661017e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 909/6000 [53:26<5:07:51,  3.63s/it] 15%|â–ˆâ–Œ        | 910/6000 [53:30<5:02:04,  3.56s/it]                                                    {'loss': 0.0128, 'grad_norm': 2.078125, 'learning_rate': 4.313559322033899e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 910/6000 [53:30<5:02:04,  3.56s/it] 15%|â–ˆâ–Œ        | 911/6000 [53:33<4:59:08,  3.53s/it]                                                    {'loss': 0.0465, 'grad_norm': 4.845146656036377, 'learning_rate': 4.31271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 911/6000 [53:33<4:59:08,  3.53s/it] 15%|â–ˆâ–Œ        | 912/6000 [53:36<4:55:10,  3.48s/it]                                                    {'loss': 0.0387, 'grad_norm': 4.721320629119873, 'learning_rate': 4.311864406779661e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 912/6000 [53:36<4:55:10,  3.48s/it] 15%|â–ˆâ–Œ        | 913/6000 [53:40<4:50:27,  3.43s/it]                                                    {'loss': 0.0213, 'grad_norm': 1.0744189023971558, 'learning_rate': 4.311016949152543e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 913/6000 [53:40<4:50:27,  3.43s/it] 15%|â–ˆâ–Œ        | 914/6000 [53:43<4:59:50,  3.54s/it]                                                    {'loss': 0.0027, 'grad_norm': 0.4458022117614746, 'learning_rate': 4.310169491525424e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 914/6000 [53:43<4:59:50,  3.54s/it] 15%|â–ˆâ–Œ        | 915/6000 [53:48<5:20:24,  3.78s/it]                                                    {'loss': 0.0646, 'grad_norm': 2.587892770767212, 'learning_rate': 4.309322033898305e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 915/6000 [53:48<5:20:24,  3.78s/it] 15%|â–ˆâ–Œ        | 916/6000 [53:51<5:10:25,  3.66s/it]                                                    {'loss': 0.0219, 'grad_norm': 2.241394519805908, 'learning_rate': 4.308474576271186e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 916/6000 [53:51<5:10:25,  3.66s/it] 15%|â–ˆâ–Œ        | 917/6000 [53:54<5:00:59,  3.55s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.10058708488941193, 'learning_rate': 4.307627118644068e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 917/6000 [53:54<5:00:59,  3.55s/it] 15%|â–ˆâ–Œ        | 918/6000 [53:58<4:56:24,  3.50s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.37581557035446167, 'learning_rate': 4.306779661016949e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 918/6000 [53:58<4:56:24,  3.50s/it] 15%|â–ˆâ–Œ        | 919/6000 [54:01<4:54:37,  3.48s/it]                                                    {'loss': 0.0841, 'grad_norm': 3.603398084640503, 'learning_rate': 4.305932203389831e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 919/6000 [54:01<4:54:37,  3.48s/it] 15%|â–ˆâ–Œ        | 920/6000 [54:05<4:52:33,  3.46s/it]                                                    {'loss': 0.0293, 'grad_norm': 2.314936399459839, 'learning_rate': 4.305084745762712e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 920/6000 [54:05<4:52:33,  3.46s/it] 15%|â–ˆâ–Œ        | 921/6000 [54:08<4:56:13,  3.50s/it]                                                    {'loss': 0.1417, 'grad_norm': 7.3091278076171875, 'learning_rate': 4.304237288135594e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 921/6000 [54:08<4:56:13,  3.50s/it] 15%|â–ˆâ–Œ        | 922/6000 [54:12<4:53:23,  3.47s/it]                                                    {'loss': 0.0088, 'grad_norm': 1.2118240594863892, 'learning_rate': 4.303389830508475e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 922/6000 [54:12<4:53:23,  3.47s/it] 15%|â–ˆâ–Œ        | 923/6000 [54:15<4:52:31,  3.46s/it]                                                    {'loss': 0.1262, 'grad_norm': 6.844415664672852, 'learning_rate': 4.302542372881356e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 923/6000 [54:15<4:52:31,  3.46s/it] 15%|â–ˆâ–Œ        | 924/6000 [54:18<4:47:48,  3.40s/it]                                                    {'loss': 0.0011, 'grad_norm': 0.26981765031814575, 'learning_rate': 4.301694915254237e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 924/6000 [54:18<4:47:48,  3.40s/it] 15%|â–ˆâ–Œ        | 925/6000 [54:22<4:46:02,  3.38s/it]                                                    {'loss': 0.0285, 'grad_norm': 2.5992016792297363, 'learning_rate': 4.300847457627119e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 925/6000 [54:22<4:46:02,  3.38s/it] 15%|â–ˆâ–Œ        | 926/6000 [54:25<4:53:57,  3.48s/it]                                                    {'loss': 0.1272, 'grad_norm': 8.597545623779297, 'learning_rate': 4.3e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 926/6000 [54:25<4:53:57,  3.48s/it] 15%|â–ˆâ–Œ        | 927/6000 [54:29<4:50:52,  3.44s/it]                                                    {'loss': 0.2666, 'grad_norm': 8.556107521057129, 'learning_rate': 4.299152542372882e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 927/6000 [54:29<4:50:52,  3.44s/it] 15%|â–ˆâ–Œ        | 928/6000 [54:32<4:49:54,  3.43s/it]                                                    {'loss': 0.0415, 'grad_norm': 3.3209216594696045, 'learning_rate': 4.298305084745763e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 928/6000 [54:32<4:49:54,  3.43s/it] 15%|â–ˆâ–Œ        | 929/6000 [54:36<4:50:29,  3.44s/it]                                                    {'loss': 0.0537, 'grad_norm': 4.530092716217041, 'learning_rate': 4.297457627118644e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 929/6000 [54:36<4:50:29,  3.44s/it] 16%|â–ˆâ–Œ        | 930/6000 [54:39<4:48:51,  3.42s/it]                                                    {'loss': 0.2688, 'grad_norm': 9.63746166229248, 'learning_rate': 4.2966101694915254e-05, 'epoch': 0.15}
 16%|â–ˆâ–Œ        | 930/6000 [54:39<4:48:51,  3.42s/it] 16%|â–ˆâ–Œ        | 931/6000 [54:42<4:48:26,  3.41s/it]                                                    {'loss': 0.0134, 'grad_norm': 1.7503265142440796, 'learning_rate': 4.2957627118644065e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 931/6000 [54:42<4:48:26,  3.41s/it] 16%|â–ˆâ–Œ        | 932/6000 [54:46<4:48:44,  3.42s/it]                                                    {'loss': 0.0076, 'grad_norm': 1.3935319185256958, 'learning_rate': 4.294915254237288e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 932/6000 [54:46<4:48:44,  3.42s/it] 16%|â–ˆâ–Œ        | 933/6000 [54:49<4:47:42,  3.41s/it]                                                    {'loss': 0.0116, 'grad_norm': 2.643883466720581, 'learning_rate': 4.2940677966101694e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 933/6000 [54:49<4:47:42,  3.41s/it] 16%|â–ˆâ–Œ        | 934/6000 [54:53<4:59:57,  3.55s/it]                                                    {'loss': 0.0261, 'grad_norm': 2.9122653007507324, 'learning_rate': 4.293220338983051e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 934/6000 [54:53<4:59:57,  3.55s/it] 16%|â–ˆâ–Œ        | 935/6000 [54:56<4:54:52,  3.49s/it]                                                    {'loss': 0.0101, 'grad_norm': 0.7631649971008301, 'learning_rate': 4.2923728813559324e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 935/6000 [54:56<4:54:52,  3.49s/it] 16%|â–ˆâ–Œ        | 936/6000 [55:00<4:51:01,  3.45s/it]                                                    {'loss': 0.1128, 'grad_norm': 7.235294342041016, 'learning_rate': 4.291525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 936/6000 [55:00<4:51:01,  3.45s/it] 16%|â–ˆâ–Œ        | 937/6000 [55:03<4:51:53,  3.46s/it]                                                    {'loss': 0.0606, 'grad_norm': 5.876924991607666, 'learning_rate': 4.2906779661016946e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 937/6000 [55:03<4:51:53,  3.46s/it] 16%|â–ˆâ–Œ        | 938/6000 [55:07<4:50:50,  3.45s/it]                                                    {'loss': 0.0054, 'grad_norm': 0.7620693445205688, 'learning_rate': 4.2898305084745764e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 938/6000 [55:07<4:50:50,  3.45s/it] 16%|â–ˆâ–Œ        | 939/6000 [55:10<4:52:31,  3.47s/it]                                                    {'loss': 0.008, 'grad_norm': 0.9089761972427368, 'learning_rate': 4.2889830508474575e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 939/6000 [55:10<4:52:31,  3.47s/it] 16%|â–ˆâ–Œ        | 940/6000 [55:14<4:51:57,  3.46s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.4058670997619629, 'learning_rate': 4.2881355932203394e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 940/6000 [55:14<4:51:57,  3.46s/it] 16%|â–ˆâ–Œ        | 941/6000 [55:18<5:08:14,  3.66s/it]                                                    {'loss': 0.0143, 'grad_norm': 2.6558139324188232, 'learning_rate': 4.2872881355932205e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 941/6000 [55:18<5:08:14,  3.66s/it] 16%|â–ˆâ–Œ        | 942/6000 [55:21<5:01:26,  3.58s/it]                                                    {'loss': 0.1052, 'grad_norm': 12.493673324584961, 'learning_rate': 4.286440677966102e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 942/6000 [55:21<5:01:26,  3.58s/it] 16%|â–ˆâ–Œ        | 943/6000 [55:25<4:58:21,  3.54s/it]                                                    {'loss': 0.016, 'grad_norm': 2.2669997215270996, 'learning_rate': 4.2855932203389834e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 943/6000 [55:25<4:58:21,  3.54s/it] 16%|â–ˆâ–Œ        | 944/6000 [55:28<4:54:34,  3.50s/it]                                                    {'loss': 0.0526, 'grad_norm': 4.2334885597229, 'learning_rate': 4.2847457627118645e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 944/6000 [55:28<4:54:34,  3.50s/it] 16%|â–ˆâ–Œ        | 945/6000 [55:32<5:01:33,  3.58s/it]                                                    {'loss': 0.1554, 'grad_norm': 8.914467811584473, 'learning_rate': 4.283898305084746e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 945/6000 [55:32<5:01:33,  3.58s/it] 16%|â–ˆâ–Œ        | 946/6000 [55:35<4:58:13,  3.54s/it]                                                    {'loss': 0.0151, 'grad_norm': 2.695544481277466, 'learning_rate': 4.2830508474576275e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 946/6000 [55:35<4:58:13,  3.54s/it] 16%|â–ˆâ–Œ        | 947/6000 [55:39<4:55:27,  3.51s/it]                                                    {'loss': 0.1223, 'grad_norm': 5.779117107391357, 'learning_rate': 4.2822033898305086e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 947/6000 [55:39<4:55:27,  3.51s/it] 16%|â–ˆâ–Œ        | 948/6000 [55:42<4:59:38,  3.56s/it]                                                    {'loss': 0.1947, 'grad_norm': 10.278543472290039, 'learning_rate': 4.2813559322033904e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 948/6000 [55:42<4:59:38,  3.56s/it] 16%|â–ˆâ–Œ        | 949/6000 [55:46<5:05:21,  3.63s/it]                                                    {'loss': 0.0779, 'grad_norm': 9.656109809875488, 'learning_rate': 4.2805084745762715e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 949/6000 [55:46<5:05:21,  3.63s/it] 16%|â–ˆâ–Œ        | 950/6000 [55:50<5:01:33,  3.58s/it]                                                    {'loss': 0.0033, 'grad_norm': 2.3228628635406494, 'learning_rate': 4.279661016949153e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 950/6000 [55:50<5:01:33,  3.58s/it][2025-10-20 00:32:54,951] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 16%|â–ˆâ–Œ        | 951/6000 [55:55<5:50:13,  4.16s/it]                                                    {'loss': 0.0376, 'grad_norm': 3.2052066326141357, 'learning_rate': 4.278813559322034e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 951/6000 [55:55<5:50:13,  4.16s/it] 16%|â–ˆâ–Œ        | 952/6000 [55:59<5:30:22,  3.93s/it]                                                    {'loss': 0.2095, 'grad_norm': 19.596004486083984, 'learning_rate': 4.277966101694915e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 952/6000 [55:59<5:30:22,  3.93s/it] 16%|â–ˆâ–Œ        | 953/6000 [56:02<5:22:15,  3.83s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.7255487442016602, 'learning_rate': 4.277118644067797e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 953/6000 [56:02<5:22:15,  3.83s/it] 16%|â–ˆâ–Œ        | 954/6000 [56:05<5:10:12,  3.69s/it]                                                    {'loss': 0.1956, 'grad_norm': 24.835269927978516, 'learning_rate': 4.276271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 954/6000 [56:05<5:10:12,  3.69s/it] 16%|â–ˆâ–Œ        | 955/6000 [56:09<5:02:49,  3.60s/it]                                                    {'loss': 0.1207, 'grad_norm': 12.265593528747559, 'learning_rate': 4.27542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 955/6000 [56:09<5:02:49,  3.60s/it] 16%|â–ˆâ–Œ        | 956/6000 [56:12<5:02:43,  3.60s/it]                                                    {'loss': 0.1178, 'grad_norm': 15.798506736755371, 'learning_rate': 4.274576271186441e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 956/6000 [56:12<5:02:43,  3.60s/it] 16%|â–ˆâ–Œ        | 957/6000 [56:16<4:56:14,  3.52s/it]                                                    {'loss': 0.0203, 'grad_norm': 1.5584415197372437, 'learning_rate': 4.2737288135593226e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 957/6000 [56:16<4:56:14,  3.52s/it] 16%|â–ˆâ–Œ        | 958/6000 [56:19<4:56:16,  3.53s/it]                                                    {'loss': 0.1724, 'grad_norm': 14.622109413146973, 'learning_rate': 4.272881355932204e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 958/6000 [56:19<4:56:16,  3.53s/it] 16%|â–ˆâ–Œ        | 959/6000 [56:23<4:50:10,  3.45s/it]                                                    {'loss': 0.0535, 'grad_norm': 10.1166410446167, 'learning_rate': 4.272033898305085e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 959/6000 [56:23<4:50:10,  3.45s/it] 16%|â–ˆâ–Œ        | 960/6000 [56:26<4:50:22,  3.46s/it]                                                    {'loss': 0.2196, 'grad_norm': 14.901923179626465, 'learning_rate': 4.271186440677966e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 960/6000 [56:26<4:50:22,  3.46s/it] 16%|â–ˆâ–Œ        | 961/6000 [56:30<4:52:34,  3.48s/it]                                                    {'loss': 0.0785, 'grad_norm': 10.151115417480469, 'learning_rate': 4.270338983050848e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 961/6000 [56:30<4:52:34,  3.48s/it] 16%|â–ˆâ–Œ        | 962/6000 [56:34<5:01:45,  3.59s/it]                                                    {'loss': 0.1369, 'grad_norm': 9.566910743713379, 'learning_rate': 4.269491525423729e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 962/6000 [56:34<5:01:45,  3.59s/it] 16%|â–ˆâ–Œ        | 963/6000 [56:37<4:56:21,  3.53s/it]                                                    {'loss': 0.2392, 'grad_norm': 25.505897521972656, 'learning_rate': 4.268644067796611e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 963/6000 [56:37<4:56:21,  3.53s/it] 16%|â–ˆâ–Œ        | 964/6000 [56:40<4:53:43,  3.50s/it]                                                    {'loss': 0.1678, 'grad_norm': 16.933229446411133, 'learning_rate': 4.267796610169492e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 964/6000 [56:40<4:53:43,  3.50s/it] 16%|â–ˆâ–Œ        | 965/6000 [56:44<4:54:58,  3.52s/it]                                                    {'loss': 0.1385, 'grad_norm': 35.457984924316406, 'learning_rate': 4.266949152542373e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 965/6000 [56:44<4:54:58,  3.52s/it] 16%|â–ˆâ–Œ        | 966/6000 [56:47<4:55:19,  3.52s/it]                                                    {'loss': 0.001, 'grad_norm': 0.447738915681839, 'learning_rate': 4.266101694915254e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 966/6000 [56:47<4:55:19,  3.52s/it] 16%|â–ˆâ–Œ        | 967/6000 [56:51<4:55:01,  3.52s/it]                                                    {'loss': 0.3866, 'grad_norm': 189.03616333007812, 'learning_rate': 4.265254237288136e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 967/6000 [56:51<4:55:01,  3.52s/it] 16%|â–ˆâ–Œ        | 968/6000 [56:55<5:00:14,  3.58s/it]                                                    {'loss': 0.0564, 'grad_norm': 19.599225997924805, 'learning_rate': 4.264406779661017e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 968/6000 [56:55<5:00:14,  3.58s/it] 16%|â–ˆâ–Œ        | 969/6000 [56:58<4:55:13,  3.52s/it]                                                    {'loss': 0.0503, 'grad_norm': 14.018471717834473, 'learning_rate': 4.263559322033899e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 969/6000 [56:58<4:55:13,  3.52s/it] 16%|â–ˆâ–Œ        | 970/6000 [57:02<4:57:27,  3.55s/it]                                                    {'loss': 0.0334, 'grad_norm': 6.107539176940918, 'learning_rate': 4.26271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 970/6000 [57:02<4:57:27,  3.55s/it] 16%|â–ˆâ–Œ        | 971/6000 [57:05<4:51:57,  3.48s/it]                                                    {'loss': 0.277, 'grad_norm': 15.961150169372559, 'learning_rate': 4.261864406779662e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 971/6000 [57:05<4:51:57,  3.48s/it] 16%|â–ˆâ–Œ        | 972/6000 [57:08<4:50:20,  3.46s/it]                                                    {'loss': 0.0901, 'grad_norm': 10.850003242492676, 'learning_rate': 4.261016949152542e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 972/6000 [57:08<4:50:20,  3.46s/it] 16%|â–ˆâ–Œ        | 973/6000 [57:12<4:48:41,  3.45s/it]                                                    {'loss': 0.1081, 'grad_norm': 5.573399066925049, 'learning_rate': 4.2601694915254234e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 973/6000 [57:12<4:48:41,  3.45s/it] 16%|â–ˆâ–Œ        | 974/6000 [57:15<4:49:35,  3.46s/it]                                                    {'loss': 0.0679, 'grad_norm': 7.8766326904296875, 'learning_rate': 4.259322033898305e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 974/6000 [57:15<4:49:35,  3.46s/it] 16%|â–ˆâ–‹        | 975/6000 [57:19<4:46:38,  3.42s/it]                                                    {'loss': 0.0817, 'grad_norm': 13.721595764160156, 'learning_rate': 4.258474576271186e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 975/6000 [57:19<4:46:38,  3.42s/it] 16%|â–ˆâ–‹        | 976/6000 [57:22<4:48:43,  3.45s/it]                                                    {'loss': 0.0098, 'grad_norm': 10.810995101928711, 'learning_rate': 4.257627118644068e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 976/6000 [57:22<4:48:43,  3.45s/it] 16%|â–ˆâ–‹        | 977/6000 [57:25<4:45:31,  3.41s/it]                                                    {'loss': 0.0601, 'grad_norm': 10.581095695495605, 'learning_rate': 4.256779661016949e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 977/6000 [57:25<4:45:31,  3.41s/it] 16%|â–ˆâ–‹        | 978/6000 [57:29<4:42:07,  3.37s/it]                                                    {'loss': 0.144, 'grad_norm': 17.83025550842285, 'learning_rate': 4.255932203389831e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 978/6000 [57:29<4:42:07,  3.37s/it] 16%|â–ˆâ–‹        | 979/6000 [57:32<4:41:04,  3.36s/it]                                                    {'loss': 0.0579, 'grad_norm': 7.1100616455078125, 'learning_rate': 4.255084745762712e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 979/6000 [57:32<4:41:04,  3.36s/it] 16%|â–ˆâ–‹        | 980/6000 [57:36<4:43:35,  3.39s/it]                                                    {'loss': 0.1261, 'grad_norm': 14.526886940002441, 'learning_rate': 4.254237288135593e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 980/6000 [57:36<4:43:35,  3.39s/it] 16%|â–ˆâ–‹        | 981/6000 [57:39<4:44:07,  3.40s/it]                                                    {'loss': 0.061, 'grad_norm': 7.565169811248779, 'learning_rate': 4.2533898305084744e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 981/6000 [57:39<4:44:07,  3.40s/it] 16%|â–ˆâ–‹        | 982/6000 [57:42<4:47:45,  3.44s/it]                                                    {'loss': 0.0551, 'grad_norm': 3.7654781341552734, 'learning_rate': 4.252542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 982/6000 [57:42<4:47:45,  3.44s/it] 16%|â–ˆâ–‹        | 983/6000 [57:46<4:47:27,  3.44s/it]                                                    {'loss': 0.0238, 'grad_norm': 2.480828046798706, 'learning_rate': 4.2516949152542374e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 983/6000 [57:46<4:47:27,  3.44s/it] 16%|â–ˆâ–‹        | 984/6000 [57:49<4:45:30,  3.42s/it]                                                    {'loss': 0.1561, 'grad_norm': 14.539176940917969, 'learning_rate': 4.250847457627119e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 984/6000 [57:49<4:45:30,  3.42s/it] 16%|â–ˆâ–‹        | 985/6000 [57:53<4:48:55,  3.46s/it]                                                    {'loss': 0.093, 'grad_norm': 5.733438491821289, 'learning_rate': 4.25e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 985/6000 [57:53<4:48:55,  3.46s/it] 16%|â–ˆâ–‹        | 986/6000 [57:56<4:45:01,  3.41s/it]                                                    {'loss': 0.1164, 'grad_norm': 9.908778190612793, 'learning_rate': 4.2491525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 986/6000 [57:56<4:45:01,  3.41s/it] 16%|â–ˆâ–‹        | 987/6000 [58:00<4:47:19,  3.44s/it]                                                    {'loss': 0.0025, 'grad_norm': 0.46225398778915405, 'learning_rate': 4.2483050847457626e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 987/6000 [58:00<4:47:19,  3.44s/it] 16%|â–ˆâ–‹        | 988/6000 [58:03<4:44:51,  3.41s/it]                                                    {'loss': 0.0467, 'grad_norm': 2.7113537788391113, 'learning_rate': 4.2474576271186444e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 988/6000 [58:03<4:44:51,  3.41s/it] 16%|â–ˆâ–‹        | 989/6000 [58:06<4:45:09,  3.41s/it]                                                    {'loss': 0.0455, 'grad_norm': 4.280124187469482, 'learning_rate': 4.2466101694915255e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 989/6000 [58:06<4:45:09,  3.41s/it] 16%|â–ˆâ–‹        | 990/6000 [58:10<4:46:36,  3.43s/it]                                                    {'loss': 0.0402, 'grad_norm': 4.684081077575684, 'learning_rate': 4.245762711864407e-05, 'epoch': 0.17}
 16%|â–ˆâ–‹        | 990/6000 [58:10<4:46:36,  3.43s/it] 17%|â–ˆâ–‹        | 991/6000 [58:14<4:59:10,  3.58s/it]                                                    {'loss': 0.0168, 'grad_norm': 1.9401723146438599, 'learning_rate': 4.2449152542372884e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 991/6000 [58:14<4:59:10,  3.58s/it] 17%|â–ˆâ–‹        | 992/6000 [58:17<4:54:53,  3.53s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.22700940072536469, 'learning_rate': 4.24406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 992/6000 [58:17<4:54:53,  3.53s/it] 17%|â–ˆâ–‹        | 993/6000 [58:21<4:54:02,  3.52s/it]                                                    {'loss': 0.0057, 'grad_norm': 0.6898311376571655, 'learning_rate': 4.2432203389830514e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 993/6000 [58:21<4:54:02,  3.52s/it] 17%|â–ˆâ–‹        | 994/6000 [58:24<4:52:49,  3.51s/it]                                                    {'loss': 0.0087, 'grad_norm': 1.941455364227295, 'learning_rate': 4.242372881355932e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 994/6000 [58:24<4:52:49,  3.51s/it] 17%|â–ˆâ–‹        | 995/6000 [58:28<4:51:02,  3.49s/it]                                                    {'loss': 0.1158, 'grad_norm': 14.19626522064209, 'learning_rate': 4.2415254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 995/6000 [58:28<4:51:02,  3.49s/it] 17%|â–ˆâ–‹        | 996/6000 [58:31<4:49:10,  3.47s/it]                                                    {'loss': 0.009, 'grad_norm': 1.4153016805648804, 'learning_rate': 4.240677966101695e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 996/6000 [58:31<4:49:10,  3.47s/it] 17%|â–ˆâ–‹        | 997/6000 [58:34<4:48:41,  3.46s/it]                                                    {'loss': 0.2961, 'grad_norm': 12.949621200561523, 'learning_rate': 4.2398305084745766e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 997/6000 [58:35<4:48:41,  3.46s/it] 17%|â–ˆâ–‹        | 998/6000 [58:38<4:44:59,  3.42s/it]                                                    {'loss': 0.115, 'grad_norm': 10.822092056274414, 'learning_rate': 4.238983050847458e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 998/6000 [58:38<4:44:59,  3.42s/it] 17%|â–ˆâ–‹        | 999/6000 [58:41<4:43:59,  3.41s/it]                                                    {'loss': 0.024, 'grad_norm': 2.4153389930725098, 'learning_rate': 4.2381355932203395e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 999/6000 [58:41<4:43:59,  3.41s/it] 17%|â–ˆâ–‹        | 1000/6000 [58:45<4:44:15,  3.41s/it]                                                     {'loss': 0.0118, 'grad_norm': 2.9406418800354004, 'learning_rate': 4.2372881355932206e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1000/6000 [58:45<4:44:15,  3.41s/it][2025-10-20 00:35:49,947] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 17%|â–ˆâ–‹        | 1001/6000 [58:50<5:42:07,  4.11s/it]                                                     {'loss': 0.4106, 'grad_norm': 10.84032154083252, 'learning_rate': 4.236440677966102e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1001/6000 [58:50<5:42:07,  4.11s/it] 17%|â–ˆâ–‹        | 1002/6000 [58:54<5:23:37,  3.89s/it]                                                     {'loss': 0.007, 'grad_norm': 1.5917315483093262, 'learning_rate': 4.235593220338983e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1002/6000 [58:54<5:23:37,  3.89s/it] 17%|â–ˆâ–‹        | 1003/6000 [58:57<5:09:02,  3.71s/it]                                                     {'loss': 0.1124, 'grad_norm': 12.583834648132324, 'learning_rate': 4.234745762711865e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1003/6000 [58:57<5:09:02,  3.71s/it] 17%|â–ˆâ–‹        | 1004/6000 [59:00<5:00:09,  3.60s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.7074875235557556, 'learning_rate': 4.233898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1004/6000 [59:00<5:00:09,  3.60s/it] 17%|â–ˆâ–‹        | 1005/6000 [59:04<4:54:41,  3.54s/it]                                                     {'loss': 0.0853, 'grad_norm': 12.447755813598633, 'learning_rate': 4.2330508474576276e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1005/6000 [59:04<4:54:41,  3.54s/it] 17%|â–ˆâ–‹        | 1006/6000 [59:07<4:53:53,  3.53s/it]                                                     {'loss': 0.1854, 'grad_norm': 14.902678489685059, 'learning_rate': 4.232203389830509e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1006/6000 [59:07<4:53:53,  3.53s/it] 17%|â–ˆâ–‹        | 1007/6000 [59:11<4:50:51,  3.50s/it]                                                     {'loss': 0.0465, 'grad_norm': 4.553741931915283, 'learning_rate': 4.23135593220339e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1007/6000 [59:11<4:50:51,  3.50s/it] 17%|â–ˆâ–‹        | 1008/6000 [59:14<4:49:20,  3.48s/it]                                                     {'loss': 0.0197, 'grad_norm': 6.662134170532227, 'learning_rate': 4.230508474576271e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1008/6000 [59:14<4:49:20,  3.48s/it] 17%|â–ˆâ–‹        | 1009/6000 [59:18<4:47:38,  3.46s/it]                                                     {'loss': 0.0042, 'grad_norm': 1.2477383613586426, 'learning_rate': 4.229661016949153e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1009/6000 [59:18<4:47:38,  3.46s/it] 17%|â–ˆâ–‹        | 1010/6000 [59:21<4:44:31,  3.42s/it]                                                     {'loss': 0.061, 'grad_norm': 6.516470432281494, 'learning_rate': 4.228813559322034e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1010/6000 [59:21<4:44:31,  3.42s/it] 17%|â–ˆâ–‹        | 1011/6000 [59:24<4:44:30,  3.42s/it]                                                     {'loss': 0.0801, 'grad_norm': 4.7313151359558105, 'learning_rate': 4.227966101694916e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1011/6000 [59:24<4:44:30,  3.42s/it] 17%|â–ˆâ–‹        | 1012/6000 [59:28<4:46:59,  3.45s/it]                                                     {'loss': 0.0115, 'grad_norm': 1.5524661540985107, 'learning_rate': 4.227118644067797e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1012/6000 [59:28<4:46:59,  3.45s/it] 17%|â–ˆâ–‹        | 1013/6000 [59:31<4:44:08,  3.42s/it]                                                     {'loss': 0.0365, 'grad_norm': 4.7877516746521, 'learning_rate': 4.226271186440679e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1013/6000 [59:31<4:44:08,  3.42s/it] 17%|â–ˆâ–‹        | 1014/6000 [59:34<4:42:00,  3.39s/it]                                                     {'loss': 0.4461, 'grad_norm': 13.909783363342285, 'learning_rate': 4.22542372881356e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1014/6000 [59:34<4:42:00,  3.39s/it] 17%|â–ˆâ–‹        | 1015/6000 [59:38<4:42:29,  3.40s/it]                                                     {'loss': 0.0716, 'grad_norm': 8.548707008361816, 'learning_rate': 4.224576271186441e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1015/6000 [59:38<4:42:29,  3.40s/it] 17%|â–ˆâ–‹        | 1016/6000 [59:41<4:43:56,  3.42s/it]                                                     {'loss': 0.0592, 'grad_norm': 7.889143943786621, 'learning_rate': 4.223728813559322e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1016/6000 [59:41<4:43:56,  3.42s/it] 17%|â–ˆâ–‹        | 1017/6000 [59:45<4:44:37,  3.43s/it]                                                     {'loss': 0.1784, 'grad_norm': 10.258869171142578, 'learning_rate': 4.222881355932203e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1017/6000 [59:45<4:44:37,  3.43s/it] 17%|â–ˆâ–‹        | 1018/6000 [59:48<4:46:38,  3.45s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.20485557615756989, 'learning_rate': 4.222033898305085e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1018/6000 [59:48<4:46:38,  3.45s/it] 17%|â–ˆâ–‹        | 1019/6000 [59:52<4:45:20,  3.44s/it]                                                     {'loss': 0.1697, 'grad_norm': 11.938533782958984, 'learning_rate': 4.221186440677966e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1019/6000 [59:52<4:45:20,  3.44s/it] 17%|â–ˆâ–‹        | 1020/6000 [59:55<4:44:54,  3.43s/it]                                                     {'loss': 0.1855, 'grad_norm': 10.129475593566895, 'learning_rate': 4.220338983050848e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1020/6000 [59:55<4:44:54,  3.43s/it] 17%|â–ˆâ–‹        | 1021/6000 [59:59<4:44:40,  3.43s/it]                                                     {'loss': 0.0851, 'grad_norm': 8.173636436462402, 'learning_rate': 4.219491525423729e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1021/6000 [59:59<4:44:40,  3.43s/it] 17%|â–ˆâ–‹        | 1022/6000 [1:00:02<4:49:11,  3.49s/it]                                                       {'loss': 0.0864, 'grad_norm': 10.393996238708496, 'learning_rate': 4.21864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1022/6000 [1:00:02<4:49:11,  3.49s/it] 17%|â–ˆâ–‹        | 1023/6000 [1:00:06<4:48:24,  3.48s/it]                                                       {'loss': 0.1873, 'grad_norm': 10.707768440246582, 'learning_rate': 4.217796610169491e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1023/6000 [1:00:06<4:48:24,  3.48s/it] 17%|â–ˆâ–‹        | 1024/6000 [1:00:09<4:45:25,  3.44s/it]                                                       {'loss': 0.0503, 'grad_norm': 12.490331649780273, 'learning_rate': 4.216949152542373e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1024/6000 [1:00:09<4:45:25,  3.44s/it] 17%|â–ˆâ–‹        | 1025/6000 [1:00:12<4:43:07,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.19613511860370636, 'learning_rate': 4.216101694915254e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1025/6000 [1:00:12<4:43:07,  3.41s/it] 17%|â–ˆâ–‹        | 1026/6000 [1:00:16<4:42:14,  3.40s/it]                                                       {'loss': 0.0659, 'grad_norm': 8.649700164794922, 'learning_rate': 4.215254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1026/6000 [1:00:16<4:42:14,  3.40s/it] 17%|â–ˆâ–‹        | 1027/6000 [1:00:19<4:41:22,  3.39s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.884302139282227, 'learning_rate': 4.214406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1027/6000 [1:00:19<4:41:22,  3.39s/it] 17%|â–ˆâ–‹        | 1028/6000 [1:00:22<4:39:55,  3.38s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.4337559938430786, 'learning_rate': 4.213559322033899e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1028/6000 [1:00:22<4:39:55,  3.38s/it] 17%|â–ˆâ–‹        | 1029/6000 [1:00:26<4:39:16,  3.37s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.5672051906585693, 'learning_rate': 4.2127118644067795e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1029/6000 [1:00:26<4:39:16,  3.37s/it] 17%|â–ˆâ–‹        | 1030/6000 [1:00:29<4:38:15,  3.36s/it]                                                       {'loss': 0.094, 'grad_norm': 10.762361526489258, 'learning_rate': 4.211864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1030/6000 [1:00:29<4:38:15,  3.36s/it] 17%|â–ˆâ–‹        | 1031/6000 [1:00:33<4:38:47,  3.37s/it]                                                       {'loss': 0.0295, 'grad_norm': 4.1486430168151855, 'learning_rate': 4.2110169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1031/6000 [1:00:33<4:38:47,  3.37s/it] 17%|â–ˆâ–‹        | 1032/6000 [1:00:36<4:38:21,  3.36s/it]                                                       {'loss': 0.0182, 'grad_norm': 2.013643264770508, 'learning_rate': 4.210169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1032/6000 [1:00:36<4:38:21,  3.36s/it] 17%|â–ˆâ–‹        | 1033/6000 [1:00:39<4:38:29,  3.36s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.9501190185546875, 'learning_rate': 4.209322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1033/6000 [1:00:39<4:38:29,  3.36s/it] 17%|â–ˆâ–‹        | 1034/6000 [1:00:43<4:36:17,  3.34s/it]                                                       {'loss': 0.0886, 'grad_norm': 4.771201133728027, 'learning_rate': 4.208474576271187e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1034/6000 [1:00:43<4:36:17,  3.34s/it] 17%|â–ˆâ–‹        | 1035/6000 [1:00:46<4:38:52,  3.37s/it]                                                       {'loss': 0.0443, 'grad_norm': 4.236180305480957, 'learning_rate': 4.207627118644068e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1035/6000 [1:00:46<4:38:52,  3.37s/it] 17%|â–ˆâ–‹        | 1036/6000 [1:00:49<4:39:38,  3.38s/it]                                                       {'loss': 0.1187, 'grad_norm': 6.736222267150879, 'learning_rate': 4.2067796610169494e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1036/6000 [1:00:49<4:39:38,  3.38s/it] 17%|â–ˆâ–‹        | 1037/6000 [1:00:53<4:39:59,  3.39s/it]                                                       {'loss': 0.0795, 'grad_norm': 8.240668296813965, 'learning_rate': 4.2059322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1037/6000 [1:00:53<4:39:59,  3.39s/it] 17%|â–ˆâ–‹        | 1038/6000 [1:00:57<4:48:48,  3.49s/it]                                                       {'loss': 0.0577, 'grad_norm': 9.053875923156738, 'learning_rate': 4.2050847457627116e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1038/6000 [1:00:57<4:48:48,  3.49s/it] 17%|â–ˆâ–‹        | 1039/6000 [1:01:00<4:49:50,  3.51s/it]                                                       {'loss': 0.0564, 'grad_norm': 11.33379077911377, 'learning_rate': 4.2042372881355934e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1039/6000 [1:01:00<4:49:50,  3.51s/it] 17%|â–ˆâ–‹        | 1040/6000 [1:01:04<4:49:10,  3.50s/it]                                                       {'loss': 0.0497, 'grad_norm': 4.861746788024902, 'learning_rate': 4.2033898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1040/6000 [1:01:04<4:49:10,  3.50s/it] 17%|â–ˆâ–‹        | 1041/6000 [1:01:07<4:45:01,  3.45s/it]                                                       {'loss': 0.1624, 'grad_norm': 10.311609268188477, 'learning_rate': 4.2025423728813564e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1041/6000 [1:01:07<4:45:01,  3.45s/it] 17%|â–ˆâ–‹        | 1042/6000 [1:01:10<4:44:10,  3.44s/it]                                                       {'loss': 0.0734, 'grad_norm': 160.64706420898438, 'learning_rate': 4.2016949152542375e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1042/6000 [1:01:10<4:44:10,  3.44s/it] 17%|â–ˆâ–‹        | 1043/6000 [1:01:14<4:40:50,  3.40s/it]                                                       {'loss': 0.1917, 'grad_norm': 11.91765308380127, 'learning_rate': 4.2008474576271186e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1043/6000 [1:01:14<4:40:50,  3.40s/it] 17%|â–ˆâ–‹        | 1044/6000 [1:01:17<4:43:02,  3.43s/it]                                                       {'loss': 0.0351, 'grad_norm': 5.786638259887695, 'learning_rate': 4.2e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1044/6000 [1:01:17<4:43:02,  3.43s/it] 17%|â–ˆâ–‹        | 1045/6000 [1:01:21<4:45:42,  3.46s/it]                                                       {'loss': 0.096, 'grad_norm': 11.3002347946167, 'learning_rate': 4.1991525423728816e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1045/6000 [1:01:21<4:45:42,  3.46s/it] 17%|â–ˆâ–‹        | 1046/6000 [1:01:24<4:44:22,  3.44s/it]                                                       {'loss': 0.207, 'grad_norm': 12.761617660522461, 'learning_rate': 4.198305084745763e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1046/6000 [1:01:24<4:44:22,  3.44s/it] 17%|â–ˆâ–‹        | 1047/6000 [1:01:28<4:52:30,  3.54s/it]                                                       {'loss': 0.2402, 'grad_norm': 9.075094223022461, 'learning_rate': 4.1974576271186445e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1047/6000 [1:01:28<4:52:30,  3.54s/it] 17%|â–ˆâ–‹        | 1048/6000 [1:01:31<4:47:02,  3.48s/it]                                                       {'loss': 0.0289, 'grad_norm': 4.732681751251221, 'learning_rate': 4.1966101694915256e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1048/6000 [1:01:31<4:47:02,  3.48s/it] 17%|â–ˆâ–‹        | 1049/6000 [1:01:34<4:43:55,  3.44s/it]                                                       {'loss': 0.1535, 'grad_norm': 13.82861042022705, 'learning_rate': 4.1957627118644074e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1049/6000 [1:01:34<4:43:55,  3.44s/it] 18%|â–ˆâ–Š        | 1050/6000 [1:01:39<5:01:01,  3.65s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.5383480787277222, 'learning_rate': 4.1949152542372886e-05, 'epoch': 0.17}
 18%|â–ˆâ–Š        | 1050/6000 [1:01:39<5:01:01,  3.65s/it][2025-10-20 00:38:43,926] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1051/6000 [1:01:44<5:47:39,  4.21s/it]                                                       {'loss': 0.1389, 'grad_norm': 10.513762474060059, 'learning_rate': 4.19406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1051/6000 [1:01:44<5:47:39,  4.21s/it] 18%|â–ˆâ–Š        | 1052/6000 [1:01:48<5:27:48,  3.97s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4142096936702728, 'learning_rate': 4.193220338983051e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1052/6000 [1:01:48<5:27:48,  3.97s/it] 18%|â–ˆâ–Š        | 1053/6000 [1:01:51<5:20:33,  3.89s/it]                                                       {'loss': 0.1524, 'grad_norm': 12.198257446289062, 'learning_rate': 4.1923728813559326e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1053/6000 [1:01:51<5:20:33,  3.89s/it] 18%|â–ˆâ–Š        | 1054/6000 [1:01:55<5:11:12,  3.78s/it]                                                       {'loss': 0.0187, 'grad_norm': 3.319373607635498, 'learning_rate': 4.191525423728814e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1054/6000 [1:01:55<5:11:12,  3.78s/it] 18%|â–ˆâ–Š        | 1055/6000 [1:01:58<5:00:54,  3.65s/it]                                                       {'loss': 0.2411, 'grad_norm': 14.028650283813477, 'learning_rate': 4.1906779661016956e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1055/6000 [1:01:58<5:00:54,  3.65s/it] 18%|â–ˆâ–Š        | 1056/6000 [1:02:02<4:54:40,  3.58s/it]                                                       {'loss': 0.0341, 'grad_norm': 3.390700578689575, 'learning_rate': 4.189830508474577e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1056/6000 [1:02:02<4:54:40,  3.58s/it] 18%|â–ˆâ–Š        | 1057/6000 [1:02:05<4:50:11,  3.52s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.4909459948539734, 'learning_rate': 4.188983050847458e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1057/6000 [1:02:05<4:50:11,  3.52s/it] 18%|â–ˆâ–Š        | 1058/6000 [1:02:08<4:45:54,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14132896065711975, 'learning_rate': 4.188135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1058/6000 [1:02:08<4:45:54,  3.47s/it] 18%|â–ˆâ–Š        | 1059/6000 [1:02:12<4:46:00,  3.47s/it]                                                       {'loss': 0.082, 'grad_norm': 5.475559234619141, 'learning_rate': 4.18728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1059/6000 [1:02:12<4:46:00,  3.47s/it] 18%|â–ˆâ–Š        | 1060/6000 [1:02:15<4:42:40,  3.43s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.4849684536457062, 'learning_rate': 4.186440677966102e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1060/6000 [1:02:15<4:42:40,  3.43s/it] 18%|â–ˆâ–Š        | 1061/6000 [1:02:19<4:50:49,  3.53s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.4022067785263062, 'learning_rate': 4.185593220338983e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1061/6000 [1:02:19<4:50:49,  3.53s/it] 18%|â–ˆâ–Š        | 1062/6000 [1:02:22<4:49:31,  3.52s/it]                                                       {'loss': 0.0407, 'grad_norm': 11.297237396240234, 'learning_rate': 4.184745762711865e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1062/6000 [1:02:22<4:49:31,  3.52s/it] 18%|â–ˆâ–Š        | 1063/6000 [1:02:26<4:44:56,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025573333725333214, 'learning_rate': 4.183898305084746e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1063/6000 [1:02:26<4:44:56,  3.46s/it] 18%|â–ˆâ–Š        | 1064/6000 [1:02:29<4:45:44,  3.47s/it]                                                       {'loss': 0.013, 'grad_norm': 3.2537453174591064, 'learning_rate': 4.183050847457628e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1064/6000 [1:02:29<4:45:44,  3.47s/it] 18%|â–ˆâ–Š        | 1065/6000 [1:02:32<4:41:41,  3.42s/it]                                                       {'loss': 0.0676, 'grad_norm': 3.753129005432129, 'learning_rate': 4.182203389830508e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1065/6000 [1:02:32<4:41:41,  3.42s/it] 18%|â–ˆâ–Š        | 1066/6000 [1:02:36<4:40:47,  3.41s/it]                                                       {'loss': 0.0463, 'grad_norm': 5.334695339202881, 'learning_rate': 4.18135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1066/6000 [1:02:36<4:40:47,  3.41s/it] 18%|â–ˆâ–Š        | 1067/6000 [1:02:39<4:41:46,  3.43s/it]                                                       {'loss': 0.0814, 'grad_norm': 7.944314479827881, 'learning_rate': 4.180508474576271e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1067/6000 [1:02:39<4:41:46,  3.43s/it] 18%|â–ˆâ–Š        | 1068/6000 [1:02:43<4:38:49,  3.39s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.8292645215988159, 'learning_rate': 4.179661016949153e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1068/6000 [1:02:43<4:38:49,  3.39s/it] 18%|â–ˆâ–Š        | 1069/6000 [1:02:46<4:37:05,  3.37s/it]                                                       {'loss': 0.003, 'grad_norm': 0.25993916392326355, 'learning_rate': 4.178813559322034e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1069/6000 [1:02:46<4:37:05,  3.37s/it] 18%|â–ˆâ–Š        | 1070/6000 [1:02:49<4:38:25,  3.39s/it]                                                       {'loss': 0.2106, 'grad_norm': 9.235330581665039, 'learning_rate': 4.177966101694916e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1070/6000 [1:02:49<4:38:25,  3.39s/it] 18%|â–ˆâ–Š        | 1071/6000 [1:02:53<4:38:51,  3.39s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07790341228246689, 'learning_rate': 4.177118644067797e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1071/6000 [1:02:53<4:38:51,  3.39s/it] 18%|â–ˆâ–Š        | 1072/6000 [1:02:56<4:37:27,  3.38s/it]                                                       {'loss': 0.0444, 'grad_norm': 3.4637670516967773, 'learning_rate': 4.176271186440678e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1072/6000 [1:02:56<4:37:27,  3.38s/it] 18%|â–ˆâ–Š        | 1073/6000 [1:03:00<4:38:34,  3.39s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.2714802026748657, 'learning_rate': 4.175423728813559e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1073/6000 [1:03:00<4:38:34,  3.39s/it] 18%|â–ˆâ–Š        | 1074/6000 [1:03:03<4:39:37,  3.41s/it]                                                       {'loss': 0.0314, 'grad_norm': 6.666203498840332, 'learning_rate': 4.174576271186441e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1074/6000 [1:03:03<4:39:37,  3.41s/it] 18%|â–ˆâ–Š        | 1075/6000 [1:03:06<4:38:48,  3.40s/it]                                                       {'loss': 0.0398, 'grad_norm': 3.595635414123535, 'learning_rate': 4.173728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1075/6000 [1:03:06<4:38:48,  3.40s/it] 18%|â–ˆâ–Š        | 1076/6000 [1:03:10<4:38:16,  3.39s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.145849347114563, 'learning_rate': 4.172881355932204e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1076/6000 [1:03:10<4:38:16,  3.39s/it] 18%|â–ˆâ–Š        | 1077/6000 [1:03:13<4:37:42,  3.38s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.232700228691101, 'learning_rate': 4.172033898305085e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1077/6000 [1:03:13<4:37:42,  3.38s/it] 18%|â–ˆâ–Š        | 1078/6000 [1:03:16<4:37:14,  3.38s/it]                                                       {'loss': 0.144, 'grad_norm': 13.723087310791016, 'learning_rate': 4.171186440677966e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1078/6000 [1:03:16<4:37:14,  3.38s/it] 18%|â–ˆâ–Š        | 1079/6000 [1:03:20<4:47:08,  3.50s/it]                                                       {'loss': 0.2519, 'grad_norm': 7.848891735076904, 'learning_rate': 4.1703389830508474e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1079/6000 [1:03:20<4:47:08,  3.50s/it] 18%|â–ˆâ–Š        | 1080/6000 [1:03:24<4:48:20,  3.52s/it]                                                       {'loss': 0.0332, 'grad_norm': 5.440097332000732, 'learning_rate': 4.1694915254237285e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1080/6000 [1:03:24<4:48:20,  3.52s/it] 18%|â–ˆâ–Š        | 1081/6000 [1:03:27<4:42:27,  3.45s/it]                                                       {'loss': 0.0439, 'grad_norm': 4.944519996643066, 'learning_rate': 4.16864406779661e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1081/6000 [1:03:27<4:42:27,  3.45s/it] 18%|â–ˆâ–Š        | 1082/6000 [1:03:31<4:41:28,  3.43s/it]                                                       {'loss': 0.2057, 'grad_norm': 9.906279563903809, 'learning_rate': 4.1677966101694915e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1082/6000 [1:03:31<4:41:28,  3.43s/it] 18%|â–ˆâ–Š        | 1083/6000 [1:03:34<4:38:08,  3.39s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.5386310815811157, 'learning_rate': 4.166949152542373e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1083/6000 [1:03:34<4:38:08,  3.39s/it] 18%|â–ˆâ–Š        | 1084/6000 [1:03:37<4:40:08,  3.42s/it]                                                       {'loss': 0.0519, 'grad_norm': 4.708542346954346, 'learning_rate': 4.1661016949152544e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1084/6000 [1:03:37<4:40:08,  3.42s/it] 18%|â–ˆâ–Š        | 1085/6000 [1:03:41<4:38:15,  3.40s/it]                                                       {'loss': 0.0275, 'grad_norm': 1.6099241971969604, 'learning_rate': 4.165254237288136e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1085/6000 [1:03:41<4:38:15,  3.40s/it] 18%|â–ˆâ–Š        | 1086/6000 [1:03:44<4:45:37,  3.49s/it]                                                       {'loss': 0.0802, 'grad_norm': 8.945211410522461, 'learning_rate': 4.164406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1086/6000 [1:03:44<4:45:37,  3.49s/it] 18%|â–ˆâ–Š        | 1087/6000 [1:03:48<4:44:43,  3.48s/it]                                                       {'loss': 0.1136, 'grad_norm': 10.879376411437988, 'learning_rate': 4.1635593220338985e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1087/6000 [1:03:48<4:44:43,  3.48s/it] 18%|â–ˆâ–Š        | 1088/6000 [1:03:51<4:43:13,  3.46s/it]                                                       {'loss': 0.1197, 'grad_norm': 7.9896626472473145, 'learning_rate': 4.1627118644067796e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1088/6000 [1:03:51<4:43:13,  3.46s/it] 18%|â–ˆâ–Š        | 1089/6000 [1:03:56<5:04:57,  3.73s/it]                                                       {'loss': 0.1929, 'grad_norm': 10.05241584777832, 'learning_rate': 4.1618644067796614e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1089/6000 [1:03:56<5:04:57,  3.73s/it] 18%|â–ˆâ–Š        | 1090/6000 [1:03:59<5:00:28,  3.67s/it]                                                       {'loss': 0.0236, 'grad_norm': 3.6865620613098145, 'learning_rate': 4.1610169491525425e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1090/6000 [1:03:59<5:00:28,  3.67s/it] 18%|â–ˆâ–Š        | 1091/6000 [1:04:03<4:54:07,  3.59s/it]                                                       {'loss': 0.0313, 'grad_norm': 11.033523559570312, 'learning_rate': 4.160169491525424e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1091/6000 [1:04:03<4:54:07,  3.59s/it] 18%|â–ˆâ–Š        | 1092/6000 [1:04:06<4:48:49,  3.53s/it]                                                       {'loss': 0.0766, 'grad_norm': 9.10554313659668, 'learning_rate': 4.1593220338983055e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1092/6000 [1:04:06<4:48:49,  3.53s/it] 18%|â–ˆâ–Š        | 1093/6000 [1:04:09<4:46:05,  3.50s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.018368685618042946, 'learning_rate': 4.1584745762711866e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1093/6000 [1:04:09<4:46:05,  3.50s/it] 18%|â–ˆâ–Š        | 1094/6000 [1:04:13<4:42:47,  3.46s/it]                                                       {'loss': 0.1793, 'grad_norm': 8.369004249572754, 'learning_rate': 4.157627118644068e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1094/6000 [1:04:13<4:42:47,  3.46s/it] 18%|â–ˆâ–Š        | 1095/6000 [1:04:16<4:40:38,  3.43s/it]                                                       {'loss': 0.0248, 'grad_norm': 3.1179308891296387, 'learning_rate': 4.1567796610169495e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1095/6000 [1:04:16<4:40:38,  3.43s/it] 18%|â–ˆâ–Š        | 1096/6000 [1:04:20<4:43:36,  3.47s/it]                                                       {'loss': 0.0326, 'grad_norm': 2.999621629714966, 'learning_rate': 4.1559322033898307e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1096/6000 [1:04:20<4:43:36,  3.47s/it] 18%|â–ˆâ–Š        | 1097/6000 [1:04:23<4:41:46,  3.45s/it]                                                       {'loss': 0.0399, 'grad_norm': 5.696252822875977, 'learning_rate': 4.1550847457627125e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1097/6000 [1:04:23<4:41:46,  3.45s/it] 18%|â–ˆâ–Š        | 1098/6000 [1:04:27<4:55:26,  3.62s/it]                                                       {'loss': 0.1671, 'grad_norm': 9.38194465637207, 'learning_rate': 4.1542372881355936e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1098/6000 [1:04:27<4:55:26,  3.62s/it] 18%|â–ˆâ–Š        | 1099/6000 [1:04:31<5:05:51,  3.74s/it]                                                       {'loss': 0.0442, 'grad_norm': 6.8877458572387695, 'learning_rate': 4.153389830508475e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1099/6000 [1:04:31<5:05:51,  3.74s/it] 18%|â–ˆâ–Š        | 1100/6000 [1:04:34<4:56:42,  3.63s/it]                                                       {'loss': 0.155, 'grad_norm': 11.252397537231445, 'learning_rate': 4.152542372881356e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1100/6000 [1:04:34<4:56:42,  3.63s/it][2025-10-20 00:41:39,754] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1101/6000 [1:04:40<5:47:33,  4.26s/it]                                                       {'loss': 0.024, 'grad_norm': 2.8490376472473145, 'learning_rate': 4.151694915254237e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1101/6000 [1:04:40<5:47:33,  4.26s/it] 18%|â–ˆâ–Š        | 1102/6000 [1:04:44<5:25:39,  3.99s/it]                                                       {'loss': 0.0484, 'grad_norm': 5.680026054382324, 'learning_rate': 4.150847457627119e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1102/6000 [1:04:44<5:25:39,  3.99s/it] 18%|â–ˆâ–Š        | 1103/6000 [1:04:47<5:12:27,  3.83s/it]                                                       {'loss': 0.0634, 'grad_norm': 4.628791809082031, 'learning_rate': 4.15e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1103/6000 [1:04:47<5:12:27,  3.83s/it] 18%|â–ˆâ–Š        | 1104/6000 [1:04:50<5:02:09,  3.70s/it]                                                       {'loss': 0.0388, 'grad_norm': 5.946677207946777, 'learning_rate': 4.149152542372882e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1104/6000 [1:04:50<5:02:09,  3.70s/it] 18%|â–ˆâ–Š        | 1105/6000 [1:04:54<4:53:49,  3.60s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.7670416831970215, 'learning_rate': 4.148305084745763e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1105/6000 [1:04:54<4:53:49,  3.60s/it] 18%|â–ˆâ–Š        | 1106/6000 [1:04:57<4:47:24,  3.52s/it]                                                       {'loss': 0.0493, 'grad_norm': 4.560750961303711, 'learning_rate': 4.1474576271186446e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1106/6000 [1:04:57<4:47:24,  3.52s/it] 18%|â–ˆâ–Š        | 1107/6000 [1:05:00<4:44:08,  3.48s/it]                                                       {'loss': 0.006, 'grad_norm': 0.7777004241943359, 'learning_rate': 4.146610169491526e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1107/6000 [1:05:00<4:44:08,  3.48s/it] 18%|â–ˆâ–Š        | 1108/6000 [1:05:04<4:45:13,  3.50s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.118408441543579, 'learning_rate': 4.145762711864407e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1108/6000 [1:05:04<4:45:13,  3.50s/it] 18%|â–ˆâ–Š        | 1109/6000 [1:05:07<4:43:14,  3.47s/it]                                                       {'loss': 0.0302, 'grad_norm': 2.2398862838745117, 'learning_rate': 4.144915254237288e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1109/6000 [1:05:07<4:43:14,  3.47s/it] 18%|â–ˆâ–Š        | 1110/6000 [1:05:11<4:42:30,  3.47s/it]                                                       {'loss': 0.1421, 'grad_norm': 11.09482479095459, 'learning_rate': 4.14406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1110/6000 [1:05:11<4:42:30,  3.47s/it] 19%|â–ˆâ–Š        | 1111/6000 [1:05:14<4:41:56,  3.46s/it]                                                       {'loss': 0.1254, 'grad_norm': 8.141239166259766, 'learning_rate': 4.143220338983051e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1111/6000 [1:05:14<4:41:56,  3.46s/it] 19%|â–ˆâ–Š        | 1112/6000 [1:05:18<4:38:29,  3.42s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6227802038192749, 'learning_rate': 4.142372881355933e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1112/6000 [1:05:18<4:38:29,  3.42s/it] 19%|â–ˆâ–Š        | 1113/6000 [1:05:21<4:36:59,  3.40s/it]                                                       {'loss': 0.0295, 'grad_norm': 3.5214571952819824, 'learning_rate': 4.141525423728814e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1113/6000 [1:05:21<4:36:59,  3.40s/it] 19%|â–ˆâ–Š        | 1114/6000 [1:05:24<4:35:46,  3.39s/it]                                                       {'loss': 0.0655, 'grad_norm': 6.590247631072998, 'learning_rate': 4.140677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1114/6000 [1:05:24<4:35:46,  3.39s/it] 19%|â–ˆâ–Š        | 1115/6000 [1:05:28<4:36:31,  3.40s/it]                                                       {'loss': 0.4063, 'grad_norm': 17.425926208496094, 'learning_rate': 4.139830508474576e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1115/6000 [1:05:28<4:36:31,  3.40s/it] 19%|â–ˆâ–Š        | 1116/6000 [1:05:31<4:36:30,  3.40s/it]                                                       {'loss': 0.2486, 'grad_norm': 15.74149227142334, 'learning_rate': 4.138983050847458e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1116/6000 [1:05:31<4:36:30,  3.40s/it] 19%|â–ˆâ–Š        | 1117/6000 [1:05:35<4:38:38,  3.42s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5479937791824341, 'learning_rate': 4.138135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1117/6000 [1:05:35<4:38:38,  3.42s/it] 19%|â–ˆâ–Š        | 1118/6000 [1:05:38<4:38:18,  3.42s/it]                                                       {'loss': 0.3873, 'grad_norm': 14.456564903259277, 'learning_rate': 4.13728813559322e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1118/6000 [1:05:38<4:38:18,  3.42s/it] 19%|â–ˆâ–Š        | 1119/6000 [1:05:42<4:39:12,  3.43s/it]                                                       {'loss': 0.0396, 'grad_norm': 8.473291397094727, 'learning_rate': 4.136440677966102e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1119/6000 [1:05:42<4:39:12,  3.43s/it] 19%|â–ˆâ–Š        | 1120/6000 [1:05:45<4:39:06,  3.43s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.41772231459617615, 'learning_rate': 4.135593220338983e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1120/6000 [1:05:45<4:39:06,  3.43s/it] 19%|â–ˆâ–Š        | 1121/6000 [1:05:48<4:37:12,  3.41s/it]                                                       {'loss': 0.0187, 'grad_norm': 2.9115171432495117, 'learning_rate': 4.134745762711865e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1121/6000 [1:05:48<4:37:12,  3.41s/it] 19%|â–ˆâ–Š        | 1122/6000 [1:05:52<4:37:28,  3.41s/it]                                                       {'loss': 0.0232, 'grad_norm': 5.539410591125488, 'learning_rate': 4.1338983050847454e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1122/6000 [1:05:52<4:37:28,  3.41s/it] 19%|â–ˆâ–Š        | 1123/6000 [1:05:55<4:36:49,  3.41s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.8635267019271851, 'learning_rate': 4.133050847457627e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1123/6000 [1:05:55<4:36:49,  3.41s/it] 19%|â–ˆâ–Š        | 1124/6000 [1:05:59<4:46:05,  3.52s/it]                                                       {'loss': 0.0579, 'grad_norm': 8.532584190368652, 'learning_rate': 4.1322033898305084e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1124/6000 [1:05:59<4:46:05,  3.52s/it] 19%|â–ˆâ–‰        | 1125/6000 [1:06:02<4:44:56,  3.51s/it]                                                       {'loss': 0.1164, 'grad_norm': 7.156078815460205, 'learning_rate': 4.13135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1125/6000 [1:06:02<4:44:56,  3.51s/it] 19%|â–ˆâ–‰        | 1126/6000 [1:06:06<4:42:39,  3.48s/it]                                                       {'loss': 0.3504, 'grad_norm': 9.07312297821045, 'learning_rate': 4.130508474576271e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1126/6000 [1:06:06<4:42:39,  3.48s/it] 19%|â–ˆâ–‰        | 1127/6000 [1:06:09<4:42:17,  3.48s/it]                                                       {'loss': 0.1245, 'grad_norm': 9.746991157531738, 'learning_rate': 4.129661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1127/6000 [1:06:09<4:42:17,  3.48s/it] 19%|â–ˆâ–‰        | 1128/6000 [1:06:13<4:39:45,  3.45s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.8644318580627441, 'learning_rate': 4.128813559322034e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1128/6000 [1:06:13<4:39:45,  3.45s/it] 19%|â–ˆâ–‰        | 1129/6000 [1:06:16<4:38:29,  3.43s/it]                                                       {'loss': 0.025, 'grad_norm': 3.0437660217285156, 'learning_rate': 4.1279661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1129/6000 [1:06:16<4:38:29,  3.43s/it] 19%|â–ˆâ–‰        | 1130/6000 [1:06:19<4:38:18,  3.43s/it]                                                       {'loss': 0.0496, 'grad_norm': 2.6817567348480225, 'learning_rate': 4.1271186440677965e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1130/6000 [1:06:19<4:38:18,  3.43s/it] 19%|â–ˆâ–‰        | 1131/6000 [1:06:23<4:43:56,  3.50s/it]                                                       {'loss': 0.1212, 'grad_norm': 7.665328502655029, 'learning_rate': 4.126271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1131/6000 [1:06:23<4:43:56,  3.50s/it] 19%|â–ˆâ–‰        | 1132/6000 [1:06:27<4:40:55,  3.46s/it]                                                       {'loss': 0.0237, 'grad_norm': 2.7112042903900146, 'learning_rate': 4.1254237288135594e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1132/6000 [1:06:27<4:40:55,  3.46s/it] 19%|â–ˆâ–‰        | 1133/6000 [1:06:30<4:51:30,  3.59s/it]                                                       {'loss': 0.018, 'grad_norm': 3.5796878337860107, 'learning_rate': 4.124576271186441e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1133/6000 [1:06:30<4:51:30,  3.59s/it] 19%|â–ˆâ–‰        | 1134/6000 [1:06:34<4:59:38,  3.69s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3418698012828827, 'learning_rate': 4.1237288135593223e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1134/6000 [1:06:34<4:59:38,  3.69s/it] 19%|â–ˆâ–‰        | 1135/6000 [1:06:38<4:53:26,  3.62s/it]                                                       {'loss': 0.0583, 'grad_norm': 7.579681873321533, 'learning_rate': 4.1228813559322035e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1135/6000 [1:06:38<4:53:26,  3.62s/it] 19%|â–ˆâ–‰        | 1136/6000 [1:06:41<4:48:05,  3.55s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2730771601200104, 'learning_rate': 4.1220338983050846e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1136/6000 [1:06:41<4:48:05,  3.55s/it] 19%|â–ˆâ–‰        | 1137/6000 [1:06:45<4:42:36,  3.49s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5463333129882812, 'learning_rate': 4.1211864406779664e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1137/6000 [1:06:45<4:42:36,  3.49s/it] 19%|â–ˆâ–‰        | 1138/6000 [1:06:48<4:38:09,  3.43s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.210890293121338, 'learning_rate': 4.1203389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1138/6000 [1:06:48<4:38:09,  3.43s/it] 19%|â–ˆâ–‰        | 1139/6000 [1:06:51<4:39:27,  3.45s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.71249920129776, 'learning_rate': 4.119491525423729e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1139/6000 [1:06:51<4:39:27,  3.45s/it] 19%|â–ˆâ–‰        | 1140/6000 [1:06:55<4:42:30,  3.49s/it]                                                       {'loss': 0.0981, 'grad_norm': 7.847416877746582, 'learning_rate': 4.1186440677966105e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1140/6000 [1:06:55<4:42:30,  3.49s/it] 19%|â–ˆâ–‰        | 1141/6000 [1:06:58<4:41:40,  3.48s/it]                                                       {'loss': 0.1484, 'grad_norm': 10.86170768737793, 'learning_rate': 4.1177966101694916e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1141/6000 [1:06:58<4:41:40,  3.48s/it] 19%|â–ˆâ–‰        | 1142/6000 [1:07:02<4:41:39,  3.48s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.3749719560146332, 'learning_rate': 4.1169491525423734e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1142/6000 [1:07:02<4:41:39,  3.48s/it] 19%|â–ˆâ–‰        | 1143/6000 [1:07:05<4:36:42,  3.42s/it]                                                       {'loss': 0.4243, 'grad_norm': 10.906079292297363, 'learning_rate': 4.1161016949152545e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1143/6000 [1:07:05<4:36:42,  3.42s/it] 19%|â–ˆâ–‰        | 1144/6000 [1:07:08<4:35:57,  3.41s/it]                                                       {'loss': 0.0228, 'grad_norm': 2.607290744781494, 'learning_rate': 4.115254237288136e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1144/6000 [1:07:08<4:35:57,  3.41s/it] 19%|â–ˆâ–‰        | 1145/6000 [1:07:12<4:35:00,  3.40s/it]                                                       {'loss': 0.1593, 'grad_norm': 13.91658878326416, 'learning_rate': 4.114406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1145/6000 [1:07:12<4:35:00,  3.40s/it] 19%|â–ˆâ–‰        | 1146/6000 [1:07:15<4:36:51,  3.42s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.627333402633667, 'learning_rate': 4.1135593220338986e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1146/6000 [1:07:15<4:36:51,  3.42s/it] 19%|â–ˆâ–‰        | 1147/6000 [1:07:19<4:35:28,  3.41s/it]                                                       {'loss': 0.0789, 'grad_norm': 7.4858245849609375, 'learning_rate': 4.11271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1147/6000 [1:07:19<4:35:28,  3.41s/it] 19%|â–ˆâ–‰        | 1148/6000 [1:07:22<4:34:11,  3.39s/it]                                                       {'loss': 0.1078, 'grad_norm': 10.4893217086792, 'learning_rate': 4.1118644067796615e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1148/6000 [1:07:22<4:34:11,  3.39s/it] 19%|â–ˆâ–‰        | 1149/6000 [1:07:26<4:44:02,  3.51s/it]                                                       {'loss': 0.0929, 'grad_norm': 6.763121604919434, 'learning_rate': 4.111016949152543e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1149/6000 [1:07:26<4:44:02,  3.51s/it] 19%|â–ˆâ–‰        | 1150/6000 [1:07:29<4:43:14,  3.50s/it]                                                       {'loss': 0.0239, 'grad_norm': 2.526974678039551, 'learning_rate': 4.110169491525424e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1150/6000 [1:07:29<4:43:14,  3.50s/it][2025-10-20 00:44:34,660] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 19%|â–ˆâ–‰        | 1151/6000 [1:07:35<5:33:57,  4.13s/it]                                                       {'loss': 0.0842, 'grad_norm': 5.178463459014893, 'learning_rate': 4.109322033898305e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1151/6000 [1:07:35<5:33:57,  4.13s/it] 19%|â–ˆâ–‰        | 1152/6000 [1:07:38<5:14:31,  3.89s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03688839077949524, 'learning_rate': 4.108474576271187e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1152/6000 [1:07:38<5:14:31,  3.89s/it] 19%|â–ˆâ–‰        | 1153/6000 [1:07:42<5:04:53,  3.77s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.018065256997942924, 'learning_rate': 4.107627118644068e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1153/6000 [1:07:42<5:04:53,  3.77s/it] 19%|â–ˆâ–‰        | 1154/6000 [1:07:45<4:56:06,  3.67s/it]                                                       {'loss': 0.016, 'grad_norm': 3.138237714767456, 'learning_rate': 4.10677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1154/6000 [1:07:45<4:56:06,  3.67s/it] 19%|â–ˆâ–‰        | 1155/6000 [1:07:49<4:57:54,  3.69s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.1437015533447266, 'learning_rate': 4.105932203389831e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1155/6000 [1:07:49<4:57:54,  3.69s/it] 19%|â–ˆâ–‰        | 1156/6000 [1:07:52<4:53:03,  3.63s/it]                                                       {'loss': 0.338, 'grad_norm': 16.172822952270508, 'learning_rate': 4.1050847457627126e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1156/6000 [1:07:52<4:53:03,  3.63s/it] 19%|â–ˆâ–‰        | 1157/6000 [1:07:56<4:48:10,  3.57s/it]                                                       {'loss': 0.1214, 'grad_norm': 5.269500255584717, 'learning_rate': 4.104237288135593e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1157/6000 [1:07:56<4:48:10,  3.57s/it] 19%|â–ˆâ–‰        | 1158/6000 [1:07:59<4:44:30,  3.53s/it]                                                       {'loss': 0.0171, 'grad_norm': 3.1583971977233887, 'learning_rate': 4.103389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1158/6000 [1:07:59<4:44:30,  3.53s/it] 19%|â–ˆâ–‰        | 1159/6000 [1:08:03<4:45:46,  3.54s/it]                                                       {'loss': 0.0416, 'grad_norm': 5.539007663726807, 'learning_rate': 4.102542372881356e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1159/6000 [1:08:03<4:45:46,  3.54s/it] 19%|â–ˆâ–‰        | 1160/6000 [1:08:06<4:41:53,  3.49s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.034422751516103745, 'learning_rate': 4.101694915254237e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1160/6000 [1:08:06<4:41:53,  3.49s/it] 19%|â–ˆâ–‰        | 1161/6000 [1:08:10<4:37:24,  3.44s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.4858794212341309, 'learning_rate': 4.100847457627119e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1161/6000 [1:08:10<4:37:24,  3.44s/it] 19%|â–ˆâ–‰        | 1162/6000 [1:08:13<4:34:43,  3.41s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.7264915108680725, 'learning_rate': 4.1e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1162/6000 [1:08:13<4:34:43,  3.41s/it] 19%|â–ˆâ–‰        | 1163/6000 [1:08:16<4:32:58,  3.39s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.8776484727859497, 'learning_rate': 4.099152542372882e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1163/6000 [1:08:16<4:32:58,  3.39s/it] 19%|â–ˆâ–‰        | 1164/6000 [1:08:20<4:32:18,  3.38s/it]                                                       {'loss': 0.0541, 'grad_norm': 4.79539680480957, 'learning_rate': 4.098305084745763e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1164/6000 [1:08:20<4:32:18,  3.38s/it] 19%|â–ˆâ–‰        | 1165/6000 [1:08:23<4:34:52,  3.41s/it]                                                       {'loss': 0.034, 'grad_norm': 3.8210248947143555, 'learning_rate': 4.097457627118644e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1165/6000 [1:08:23<4:34:52,  3.41s/it] 19%|â–ˆâ–‰        | 1166/6000 [1:08:26<4:33:06,  3.39s/it]                                                       {'loss': 0.069, 'grad_norm': 4.067104816436768, 'learning_rate': 4.096610169491525e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1166/6000 [1:08:26<4:33:06,  3.39s/it] 19%|â–ˆâ–‰        | 1167/6000 [1:08:30<4:45:58,  3.55s/it]                                                       {'loss': 0.0888, 'grad_norm': 8.194183349609375, 'learning_rate': 4.095762711864407e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1167/6000 [1:08:30<4:45:58,  3.55s/it] 19%|â–ˆâ–‰        | 1168/6000 [1:08:34<4:41:19,  3.49s/it]                                                       {'loss': 0.0565, 'grad_norm': 5.566993713378906, 'learning_rate': 4.094915254237288e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1168/6000 [1:08:34<4:41:19,  3.49s/it] 19%|â–ˆâ–‰        | 1169/6000 [1:08:37<4:37:01,  3.44s/it]                                                       {'loss': 0.1387, 'grad_norm': 8.402027130126953, 'learning_rate': 4.09406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1169/6000 [1:08:37<4:37:01,  3.44s/it] 20%|â–ˆâ–‰        | 1170/6000 [1:08:40<4:34:46,  3.41s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.3706282377243042, 'learning_rate': 4.093220338983051e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1170/6000 [1:08:40<4:34:46,  3.41s/it] 20%|â–ˆâ–‰        | 1171/6000 [1:08:44<4:38:07,  3.46s/it]                                                       {'loss': 0.0267, 'grad_norm': 3.018726348876953, 'learning_rate': 4.092372881355932e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1171/6000 [1:08:44<4:38:07,  3.46s/it] 20%|â–ˆâ–‰        | 1172/6000 [1:08:47<4:38:34,  3.46s/it]                                                       {'loss': 0.0485, 'grad_norm': 6.404774188995361, 'learning_rate': 4.0915254237288134e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1172/6000 [1:08:47<4:38:34,  3.46s/it] 20%|â–ˆâ–‰        | 1173/6000 [1:08:51<4:35:54,  3.43s/it]                                                       {'loss': 0.0213, 'grad_norm': 2.649182081222534, 'learning_rate': 4.090677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1173/6000 [1:08:51<4:35:54,  3.43s/it] 20%|â–ˆâ–‰        | 1174/6000 [1:08:54<4:40:41,  3.49s/it]                                                       {'loss': 0.1251, 'grad_norm': 7.787050247192383, 'learning_rate': 4.089830508474576e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1174/6000 [1:08:54<4:40:41,  3.49s/it] 20%|â–ˆâ–‰        | 1175/6000 [1:08:58<4:40:29,  3.49s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.17477759718894958, 'learning_rate': 4.088983050847458e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1175/6000 [1:08:58<4:40:29,  3.49s/it] 20%|â–ˆâ–‰        | 1176/6000 [1:09:01<4:36:48,  3.44s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1628715544939041, 'learning_rate': 4.088135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1176/6000 [1:09:01<4:36:48,  3.44s/it] 20%|â–ˆâ–‰        | 1177/6000 [1:09:05<4:35:38,  3.43s/it]                                                       {'loss': 0.097, 'grad_norm': 6.564929962158203, 'learning_rate': 4.087288135593221e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1177/6000 [1:09:05<4:35:38,  3.43s/it] 20%|â–ˆâ–‰        | 1178/6000 [1:09:08<4:47:14,  3.57s/it]                                                       {'loss': 0.0473, 'grad_norm': 2.5233452320098877, 'learning_rate': 4.086440677966102e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1178/6000 [1:09:09<4:47:14,  3.57s/it] 20%|â–ˆâ–‰        | 1179/6000 [1:09:12<4:52:38,  3.64s/it]                                                       {'loss': 0.059, 'grad_norm': 6.781009197235107, 'learning_rate': 4.085593220338983e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1179/6000 [1:09:12<4:52:38,  3.64s/it] 20%|â–ˆâ–‰        | 1180/6000 [1:09:16<4:56:30,  3.69s/it]                                                       {'loss': 0.0487, 'grad_norm': 1.8687098026275635, 'learning_rate': 4.0847457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1180/6000 [1:09:16<4:56:30,  3.69s/it] 20%|â–ˆâ–‰        | 1181/6000 [1:09:20<4:50:20,  3.61s/it]                                                       {'loss': 0.0197, 'grad_norm': 3.106750726699829, 'learning_rate': 4.0838983050847456e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1181/6000 [1:09:20<4:50:20,  3.61s/it] 20%|â–ˆâ–‰        | 1182/6000 [1:09:24<5:07:30,  3.83s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.18077175319194794, 'learning_rate': 4.0830508474576274e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1182/6000 [1:09:24<5:07:30,  3.83s/it] 20%|â–ˆâ–‰        | 1183/6000 [1:09:27<4:56:21,  3.69s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.2823671102523804, 'learning_rate': 4.0822033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1183/6000 [1:09:27<4:56:21,  3.69s/it] 20%|â–ˆâ–‰        | 1184/6000 [1:09:31<4:50:18,  3.62s/it]                                                       {'loss': 0.1895, 'grad_norm': 8.127995491027832, 'learning_rate': 4.08135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1184/6000 [1:09:31<4:50:18,  3.62s/it] 20%|â–ˆâ–‰        | 1185/6000 [1:09:34<4:44:07,  3.54s/it]                                                       {'loss': 0.022, 'grad_norm': 2.7222533226013184, 'learning_rate': 4.0805084745762714e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1185/6000 [1:09:34<4:44:07,  3.54s/it] 20%|â–ˆâ–‰        | 1186/6000 [1:09:37<4:40:42,  3.50s/it]                                                       {'loss': 0.1805, 'grad_norm': 6.223629474639893, 'learning_rate': 4.0796610169491526e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1186/6000 [1:09:37<4:40:42,  3.50s/it] 20%|â–ˆâ–‰        | 1187/6000 [1:09:41<4:38:49,  3.48s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.45707544684410095, 'learning_rate': 4.078813559322034e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1187/6000 [1:09:41<4:38:49,  3.48s/it] 20%|â–ˆâ–‰        | 1188/6000 [1:09:44<4:34:55,  3.43s/it]                                                       {'loss': 0.0537, 'grad_norm': 6.53301477432251, 'learning_rate': 4.0779661016949155e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1188/6000 [1:09:44<4:34:55,  3.43s/it] 20%|â–ˆâ–‰        | 1189/6000 [1:09:48<4:32:56,  3.40s/it]                                                       {'loss': 0.1089, 'grad_norm': 10.140748023986816, 'learning_rate': 4.0771186440677966e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1189/6000 [1:09:48<4:32:56,  3.40s/it] 20%|â–ˆâ–‰        | 1190/6000 [1:09:51<4:37:38,  3.46s/it]                                                       {'loss': 0.0719, 'grad_norm': 7.9826273918151855, 'learning_rate': 4.0762711864406784e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1190/6000 [1:09:51<4:37:38,  3.46s/it] 20%|â–ˆâ–‰        | 1191/6000 [1:09:55<4:37:00,  3.46s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.7764891982078552, 'learning_rate': 4.0754237288135596e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1191/6000 [1:09:55<4:37:00,  3.46s/it] 20%|â–ˆâ–‰        | 1192/6000 [1:09:58<4:37:51,  3.47s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.9764786958694458, 'learning_rate': 4.0745762711864414e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1192/6000 [1:09:58<4:37:51,  3.47s/it] 20%|â–ˆâ–‰        | 1193/6000 [1:10:01<4:36:06,  3.45s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.9133090376853943, 'learning_rate': 4.073728813559322e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1193/6000 [1:10:01<4:36:06,  3.45s/it] 20%|â–ˆâ–‰        | 1194/6000 [1:10:05<4:37:26,  3.46s/it]                                                       {'loss': 0.0877, 'grad_norm': 6.054812908172607, 'learning_rate': 4.0728813559322036e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1194/6000 [1:10:05<4:37:26,  3.46s/it] 20%|â–ˆâ–‰        | 1195/6000 [1:10:08<4:36:57,  3.46s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2580019235610962, 'learning_rate': 4.072033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1195/6000 [1:10:08<4:36:57,  3.46s/it] 20%|â–ˆâ–‰        | 1196/6000 [1:10:12<4:36:40,  3.46s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03580406680703163, 'learning_rate': 4.0711864406779666e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1196/6000 [1:10:12<4:36:40,  3.46s/it] 20%|â–ˆâ–‰        | 1197/6000 [1:10:15<4:38:08,  3.47s/it]                                                       {'loss': 0.0824, 'grad_norm': 8.77699089050293, 'learning_rate': 4.070338983050848e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1197/6000 [1:10:15<4:38:08,  3.47s/it] 20%|â–ˆâ–‰        | 1198/6000 [1:10:19<4:37:06,  3.46s/it]                                                       {'loss': 0.1314, 'grad_norm': 7.835247993469238, 'learning_rate': 4.0694915254237295e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1198/6000 [1:10:19<4:37:06,  3.46s/it] 20%|â–ˆâ–‰        | 1199/6000 [1:10:22<4:35:10,  3.44s/it]                                                       {'loss': 0.1209, 'grad_norm': 6.549797058105469, 'learning_rate': 4.0686440677966106e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1199/6000 [1:10:22<4:35:10,  3.44s/it] 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:26<4:32:36,  3.41s/it]                                                       {'loss': 0.1803, 'grad_norm': 11.478557586669922, 'learning_rate': 4.067796610169492e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:26<4:32:36,  3.41s/it][2025-10-20 00:47:30,866] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:31<5:25:40,  4.07s/it]                                                       {'loss': 0.2789, 'grad_norm': 10.75948429107666, 'learning_rate': 4.066949152542373e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:31<5:25:40,  4.07s/it] 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:35<5:08:52,  3.86s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.5867570042610168, 'learning_rate': 4.066101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:35<5:08:52,  3.86s/it] 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:38<4:57:37,  3.72s/it]                                                       {'loss': 0.1632, 'grad_norm': 6.542698860168457, 'learning_rate': 4.065254237288136e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:38<4:57:37,  3.72s/it] 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:42<4:58:47,  3.74s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5123704671859741, 'learning_rate': 4.064406779661017e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:42<4:58:47,  3.74s/it] 20%|â–ˆâ–ˆ        | 1205/6000 [1:10:45<4:51:48,  3.65s/it]                                                       {'loss': 0.1456, 'grad_norm': 7.759120464324951, 'learning_rate': 4.063559322033899e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1205/6000 [1:10:45<4:51:48,  3.65s/it] 20%|â–ˆâ–ˆ        | 1206/6000 [1:10:49<4:47:18,  3.60s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.5106256008148193, 'learning_rate': 4.06271186440678e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1206/6000 [1:10:49<4:47:18,  3.60s/it] 20%|â–ˆâ–ˆ        | 1207/6000 [1:10:52<4:43:20,  3.55s/it]                                                       {'loss': 0.0881, 'grad_norm': 6.137843608856201, 'learning_rate': 4.061864406779661e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1207/6000 [1:10:52<4:43:20,  3.55s/it] 20%|â–ˆâ–ˆ        | 1208/6000 [1:10:55<4:40:27,  3.51s/it]                                                       {'loss': 0.0624, 'grad_norm': 3.5481417179107666, 'learning_rate': 4.061016949152542e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1208/6000 [1:10:55<4:40:27,  3.51s/it] 20%|â–ˆâ–ˆ        | 1209/6000 [1:10:59<4:35:23,  3.45s/it]                                                       {'loss': 0.0703, 'grad_norm': 8.628543853759766, 'learning_rate': 4.060169491525424e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1209/6000 [1:10:59<4:35:23,  3.45s/it] 20%|â–ˆâ–ˆ        | 1210/6000 [1:11:02<4:36:14,  3.46s/it]                                                       {'loss': 0.0738, 'grad_norm': 8.851181983947754, 'learning_rate': 4.059322033898305e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1210/6000 [1:11:02<4:36:14,  3.46s/it] 20%|â–ˆâ–ˆ        | 1211/6000 [1:11:06<4:34:30,  3.44s/it]                                                       {'loss': 0.0238, 'grad_norm': 2.816145420074463, 'learning_rate': 4.058474576271187e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1211/6000 [1:11:06<4:34:30,  3.44s/it] 20%|â–ˆâ–ˆ        | 1212/6000 [1:11:09<4:32:03,  3.41s/it]                                                       {'loss': 0.0595, 'grad_norm': 5.866446018218994, 'learning_rate': 4.057627118644068e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1212/6000 [1:11:09<4:32:03,  3.41s/it] 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:12<4:30:31,  3.39s/it]                                                       {'loss': 0.0581, 'grad_norm': 7.164683818817139, 'learning_rate': 4.05677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:12<4:30:31,  3.39s/it] 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:16<4:32:19,  3.41s/it]                                                       {'loss': 0.0298, 'grad_norm': 3.7046234607696533, 'learning_rate': 4.055932203389831e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:16<4:32:19,  3.41s/it] 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:19<4:31:40,  3.41s/it]                                                       {'loss': 0.0469, 'grad_norm': 7.1575727462768555, 'learning_rate': 4.055084745762712e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:19<4:31:40,  3.41s/it] 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:23<4:29:43,  3.38s/it]                                                       {'loss': 0.0481, 'grad_norm': 10.177037239074707, 'learning_rate': 4.054237288135593e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:23<4:29:43,  3.38s/it] 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:26<4:39:48,  3.51s/it]                                                       {'loss': 0.0994, 'grad_norm': 35.5139274597168, 'learning_rate': 4.053389830508475e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:26<4:39:48,  3.51s/it] 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:30<4:39:02,  3.50s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.6616928577423096, 'learning_rate': 4.052542372881356e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:30<4:39:02,  3.50s/it] 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:33<4:42:34,  3.55s/it]                                                       {'loss': 0.0292, 'grad_norm': 2.3903703689575195, 'learning_rate': 4.051694915254238e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:33<4:42:34,  3.55s/it] 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:37<4:38:19,  3.49s/it]                                                       {'loss': 0.0207, 'grad_norm': 1.3924793004989624, 'learning_rate': 4.050847457627119e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:37<4:38:19,  3.49s/it] 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:40<4:37:41,  3.49s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1937941610813141, 'learning_rate': 4.05e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:40<4:37:41,  3.49s/it] 20%|â–ˆâ–ˆ        | 1222/6000 [1:11:44<4:36:45,  3.48s/it]                                                       {'loss': 0.0565, 'grad_norm': 3.6896045207977295, 'learning_rate': 4.049152542372881e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1222/6000 [1:11:44<4:36:45,  3.48s/it] 20%|â–ˆâ–ˆ        | 1223/6000 [1:11:47<4:33:34,  3.44s/it]                                                       {'loss': 0.0215, 'grad_norm': 3.230759620666504, 'learning_rate': 4.0483050847457624e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1223/6000 [1:11:47<4:33:34,  3.44s/it] 20%|â–ˆâ–ˆ        | 1224/6000 [1:11:51<4:32:44,  3.43s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.789306640625, 'learning_rate': 4.047457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1224/6000 [1:11:51<4:32:44,  3.43s/it] 20%|â–ˆâ–ˆ        | 1225/6000 [1:11:54<4:37:22,  3.49s/it]                                                       {'loss': 0.006, 'grad_norm': 3.832759380340576, 'learning_rate': 4.0466101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1225/6000 [1:11:54<4:37:22,  3.49s/it] 20%|â–ˆâ–ˆ        | 1226/6000 [1:11:58<4:43:08,  3.56s/it]                                                       {'loss': 0.143, 'grad_norm': 6.156277179718018, 'learning_rate': 4.045762711864407e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1226/6000 [1:11:58<4:43:08,  3.56s/it] 20%|â–ˆâ–ˆ        | 1227/6000 [1:12:02<4:49:16,  3.64s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.6132996082305908, 'learning_rate': 4.044915254237288e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1227/6000 [1:12:02<4:49:16,  3.64s/it] 20%|â–ˆâ–ˆ        | 1228/6000 [1:12:05<4:42:50,  3.56s/it]                                                       {'loss': 0.0452, 'grad_norm': 1.6263315677642822, 'learning_rate': 4.0440677966101694e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1228/6000 [1:12:05<4:42:50,  3.56s/it] 20%|â–ˆâ–ˆ        | 1229/6000 [1:12:08<4:37:59,  3.50s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.20859044790267944, 'learning_rate': 4.0432203389830506e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1229/6000 [1:12:08<4:37:59,  3.50s/it] 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:12<4:34:52,  3.46s/it]                                                       {'loss': 0.0321, 'grad_norm': 3.119957685470581, 'learning_rate': 4.0423728813559324e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:12<4:34:52,  3.46s/it] 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:15<4:33:58,  3.45s/it]                                                       {'loss': 0.2958, 'grad_norm': 11.014167785644531, 'learning_rate': 4.0415254237288135e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:15<4:33:58,  3.45s/it] 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:19<4:31:55,  3.42s/it]                                                       {'loss': 0.002, 'grad_norm': 0.27946123480796814, 'learning_rate': 4.040677966101695e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:19<4:31:55,  3.42s/it] 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:22<4:38:04,  3.50s/it]                                                       {'loss': 0.0448, 'grad_norm': 5.266238212585449, 'learning_rate': 4.0398305084745764e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:22<4:38:04,  3.50s/it] 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:26<4:46:37,  3.61s/it]                                                       {'loss': 0.1197, 'grad_norm': 7.432389736175537, 'learning_rate': 4.038983050847458e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:26<4:46:37,  3.61s/it] 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:30<4:42:10,  3.55s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.457152009010315, 'learning_rate': 4.0381355932203394e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:30<4:42:10,  3.55s/it] 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:33<4:38:12,  3.50s/it]                                                       {'loss': 0.1694, 'grad_norm': 8.206377983093262, 'learning_rate': 4.0372881355932205e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:33<4:38:12,  3.50s/it] 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:36<4:35:54,  3.48s/it]                                                       {'loss': 0.0828, 'grad_norm': 6.594639778137207, 'learning_rate': 4.0364406779661016e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:36<4:35:54,  3.48s/it] 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:40<4:33:53,  3.45s/it]                                                       {'loss': 0.0514, 'grad_norm': 5.298111915588379, 'learning_rate': 4.0355932203389834e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:40<4:33:53,  3.45s/it] 21%|â–ˆâ–ˆ        | 1239/6000 [1:12:43<4:31:42,  3.42s/it]                                                       {'loss': 0.0414, 'grad_norm': 3.806859016418457, 'learning_rate': 4.0347457627118646e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1239/6000 [1:12:43<4:31:42,  3.42s/it] 21%|â–ˆâ–ˆ        | 1240/6000 [1:12:47<4:37:58,  3.50s/it]                                                       {'loss': 0.0363, 'grad_norm': 2.2334280014038086, 'learning_rate': 4.0338983050847464e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1240/6000 [1:12:47<4:37:58,  3.50s/it] 21%|â–ˆâ–ˆ        | 1241/6000 [1:12:50<4:34:43,  3.46s/it]                                                       {'loss': 0.0338, 'grad_norm': 4.164499759674072, 'learning_rate': 4.0330508474576275e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1241/6000 [1:12:50<4:34:43,  3.46s/it] 21%|â–ˆâ–ˆ        | 1242/6000 [1:12:54<4:36:21,  3.48s/it]                                                       {'loss': 0.2895, 'grad_norm': 13.375853538513184, 'learning_rate': 4.0322033898305086e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1242/6000 [1:12:54<4:36:21,  3.48s/it] 21%|â–ˆâ–ˆ        | 1243/6000 [1:12:57<4:34:12,  3.46s/it]                                                       {'loss': 0.0265, 'grad_norm': 3.294201135635376, 'learning_rate': 4.03135593220339e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1243/6000 [1:12:57<4:34:12,  3.46s/it] 21%|â–ˆâ–ˆ        | 1244/6000 [1:13:00<4:30:51,  3.42s/it]                                                       {'loss': 0.1173, 'grad_norm': 5.847660064697266, 'learning_rate': 4.030508474576271e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1244/6000 [1:13:00<4:30:51,  3.42s/it] 21%|â–ˆâ–ˆ        | 1245/6000 [1:13:04<4:28:46,  3.39s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.11230745911598206, 'learning_rate': 4.029661016949153e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1245/6000 [1:13:04<4:28:46,  3.39s/it] 21%|â–ˆâ–ˆ        | 1246/6000 [1:13:07<4:27:24,  3.37s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.4900621175765991, 'learning_rate': 4.028813559322034e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1246/6000 [1:13:07<4:27:24,  3.37s/it] 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:10<4:28:54,  3.39s/it]                                                       {'loss': 0.0557, 'grad_norm': 3.690035581588745, 'learning_rate': 4.0279661016949156e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:11<4:28:54,  3.39s/it] 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:14<4:30:06,  3.41s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05842553451657295, 'learning_rate': 4.027118644067797e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:14<4:30:06,  3.41s/it] 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:17<4:29:15,  3.40s/it]                                                       {'loss': 0.0304, 'grad_norm': 3.0744338035583496, 'learning_rate': 4.0262711864406786e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:17<4:29:15,  3.40s/it] 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:21<4:27:42,  3.38s/it]                                                       {'loss': 0.0886, 'grad_norm': 7.563131809234619, 'learning_rate': 4.025423728813559e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:21<4:27:42,  3.38s/it][2025-10-20 00:50:25,983] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:26<5:17:59,  4.02s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.05234817415475845, 'learning_rate': 4.024576271186441e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:26<5:17:59,  4.02s/it] 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:30<5:02:03,  3.82s/it]                                                       {'loss': 0.1923, 'grad_norm': 7.238652229309082, 'learning_rate': 4.023728813559322e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:30<5:02:03,  3.82s/it] 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:34<5:06:32,  3.87s/it]                                                       {'loss': 0.0367, 'grad_norm': 2.6136953830718994, 'learning_rate': 4.022881355932204e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:34<5:06:32,  3.87s/it] 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:37<4:52:50,  3.70s/it]                                                       {'loss': 0.0096, 'grad_norm': 0.9663344025611877, 'learning_rate': 4.022033898305085e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:37<4:52:50,  3.70s/it] 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:40<4:45:06,  3.61s/it]                                                       {'loss': 0.0152, 'grad_norm': 3.1831560134887695, 'learning_rate': 4.021186440677967e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:40<4:45:06,  3.61s/it] 21%|â–ˆâ–ˆ        | 1256/6000 [1:13:44<4:40:52,  3.55s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.776735305786133, 'learning_rate': 4.020338983050848e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1256/6000 [1:13:44<4:40:52,  3.55s/it] 21%|â–ˆâ–ˆ        | 1257/6000 [1:13:47<4:36:18,  3.50s/it]                                                       {'loss': 0.013, 'grad_norm': 2.1028051376342773, 'learning_rate': 4.019491525423729e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1257/6000 [1:13:47<4:36:18,  3.50s/it] 21%|â–ˆâ–ˆ        | 1258/6000 [1:13:51<4:40:30,  3.55s/it]                                                       {'loss': 0.0077, 'grad_norm': 0.6142553091049194, 'learning_rate': 4.01864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1258/6000 [1:13:51<4:40:30,  3.55s/it] 21%|â–ˆâ–ˆ        | 1259/6000 [1:13:54<4:37:29,  3.51s/it]                                                       {'loss': 0.527, 'grad_norm': 10.83984661102295, 'learning_rate': 4.017796610169492e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1259/6000 [1:13:54<4:37:29,  3.51s/it] 21%|â–ˆâ–ˆ        | 1260/6000 [1:13:57<4:33:33,  3.46s/it]                                                       {'loss': 0.0542, 'grad_norm': 3.3701095581054688, 'learning_rate': 4.016949152542373e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1260/6000 [1:13:57<4:33:33,  3.46s/it] 21%|â–ˆâ–ˆ        | 1261/6000 [1:14:01<4:32:14,  3.45s/it]                                                       {'loss': 0.1034, 'grad_norm': 8.364564895629883, 'learning_rate': 4.016101694915255e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1261/6000 [1:14:01<4:32:14,  3.45s/it] 21%|â–ˆâ–ˆ        | 1262/6000 [1:14:05<4:40:03,  3.55s/it]                                                       {'loss': 0.133, 'grad_norm': 4.492339611053467, 'learning_rate': 4.015254237288136e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1262/6000 [1:14:05<4:40:03,  3.55s/it] 21%|â–ˆâ–ˆ        | 1263/6000 [1:14:08<4:38:14,  3.52s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.047261856496334076, 'learning_rate': 4.014406779661017e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1263/6000 [1:14:08<4:38:14,  3.52s/it] 21%|â–ˆâ–ˆ        | 1264/6000 [1:14:12<4:35:59,  3.50s/it]                                                       {'loss': 0.001, 'grad_norm': 0.21492886543273926, 'learning_rate': 4.013559322033898e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1264/6000 [1:14:12<4:35:59,  3.50s/it] 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:15<4:35:35,  3.49s/it]                                                       {'loss': 0.1353, 'grad_norm': 6.076481819152832, 'learning_rate': 4.012711864406779e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:15<4:35:35,  3.49s/it] 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:18<4:34:38,  3.48s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.7702479958534241, 'learning_rate': 4.011864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:18<4:34:38,  3.48s/it] 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:22<4:42:54,  3.59s/it]                                                       {'loss': 0.049, 'grad_norm': 5.0304341316223145, 'learning_rate': 4.011016949152542e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:22<4:42:54,  3.59s/it] 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:26<4:40:15,  3.55s/it]                                                       {'loss': 0.1488, 'grad_norm': 12.227624893188477, 'learning_rate': 4.010169491525424e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:26<4:40:15,  3.55s/it] 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:29<4:37:54,  3.52s/it]                                                       {'loss': 0.1453, 'grad_norm': 10.023185729980469, 'learning_rate': 4.009322033898305e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:29<4:37:54,  3.52s/it] 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:33<4:36:47,  3.51s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.503893256187439, 'learning_rate': 4.008474576271187e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:33<4:36:47,  3.51s/it] 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:36<4:38:00,  3.53s/it]                                                       {'loss': 0.0746, 'grad_norm': 5.809530258178711, 'learning_rate': 4.007627118644068e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:36<4:38:00,  3.53s/it] 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:40<4:44:45,  3.61s/it]                                                       {'loss': 0.0571, 'grad_norm': 5.332921028137207, 'learning_rate': 4.006779661016949e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:40<4:44:45,  3.61s/it] 21%|â–ˆâ–ˆ        | 1273/6000 [1:14:43<4:38:50,  3.54s/it]                                                       {'loss': 0.0384, 'grad_norm': 2.438969850540161, 'learning_rate': 4.0059322033898304e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1273/6000 [1:14:43<4:38:50,  3.54s/it] 21%|â–ˆâ–ˆ        | 1274/6000 [1:14:47<4:33:15,  3.47s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.38663461804389954, 'learning_rate': 4.005084745762712e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1274/6000 [1:14:47<4:33:15,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:14:50<4:32:28,  3.46s/it]                                                       {'loss': 0.17, 'grad_norm': 14.699346542358398, 'learning_rate': 4.004237288135593e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:14:50<4:32:28,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:14:54<4:32:55,  3.47s/it]                                                       {'loss': 0.1653, 'grad_norm': 8.69478702545166, 'learning_rate': 4.003389830508475e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:14:54<4:32:55,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:14:57<4:32:22,  3.46s/it]                                                       {'loss': 0.3584, 'grad_norm': 16.19845962524414, 'learning_rate': 4.002542372881356e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:14:57<4:32:22,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:15:01<4:31:57,  3.46s/it]                                                       {'loss': 0.1277, 'grad_norm': 6.808588981628418, 'learning_rate': 4.0016949152542374e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:15:01<4:31:57,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:15:04<4:29:26,  3.42s/it]                                                       {'loss': 0.1621, 'grad_norm': 6.563180446624756, 'learning_rate': 4.0008474576271185e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:15:04<4:29:26,  3.42s/it] 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:15:07<4:31:13,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3453933596611023, 'learning_rate': 4e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:15:07<4:31:13,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:15:11<4:32:26,  3.46s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.27321195602417, 'learning_rate': 3.9991525423728815e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:15:11<4:32:26,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:14<4:29:38,  3.43s/it]                                                       {'loss': 0.0411, 'grad_norm': 3.9734530448913574, 'learning_rate': 3.998305084745763e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:14<4:29:38,  3.43s/it] 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:18<4:25:49,  3.38s/it]                                                       {'loss': 0.0152, 'grad_norm': 1.4718272686004639, 'learning_rate': 3.9974576271186444e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:18<4:25:49,  3.38s/it] 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:21<4:25:32,  3.38s/it]                                                       {'loss': 0.052, 'grad_norm': 3.9668984413146973, 'learning_rate': 3.996610169491526e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:21<4:25:32,  3.38s/it] 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:24<4:24:46,  3.37s/it]                                                       {'loss': 0.0445, 'grad_norm': 3.9133968353271484, 'learning_rate': 3.9957627118644066e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:24<4:24:46,  3.37s/it] 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:28<4:26:48,  3.40s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.4126927852630615, 'learning_rate': 3.994915254237288e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:28<4:26:48,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:31<4:29:47,  3.43s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2074744552373886, 'learning_rate': 3.9940677966101696e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:31<4:29:47,  3.43s/it] 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:35<4:29:39,  3.43s/it]                                                       {'loss': 0.0826, 'grad_norm': 5.491420745849609, 'learning_rate': 3.993220338983051e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:35<4:29:39,  3.43s/it] 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:38<4:26:15,  3.39s/it]                                                       {'loss': 0.0637, 'grad_norm': 5.8431525230407715, 'learning_rate': 3.9923728813559325e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:38<4:26:15,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:41<4:25:47,  3.39s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.036486756056547165, 'learning_rate': 3.9915254237288136e-05, 'epoch': 0.21}
 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:41<4:25:47,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:15:45<4:25:52,  3.39s/it]                                                       {'loss': 0.0216, 'grad_norm': 1.6820698976516724, 'learning_rate': 3.9906779661016955e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:15:45<4:25:52,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:15:48<4:25:46,  3.39s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3288828432559967, 'learning_rate': 3.9898305084745766e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:15:48<4:25:46,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:15:52<4:28:27,  3.42s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.13736459612846375, 'learning_rate': 3.988983050847458e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:15:52<4:28:27,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:15:55<4:29:59,  3.44s/it]                                                       {'loss': 0.0223, 'grad_norm': 1.4530808925628662, 'learning_rate': 3.988135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:15:55<4:29:59,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:15:58<4:27:47,  3.41s/it]                                                       {'loss': 0.0284, 'grad_norm': 4.86104679107666, 'learning_rate': 3.9872881355932206e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:15:58<4:27:47,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:16:02<4:28:28,  3.42s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.184719979763031, 'learning_rate': 3.986440677966102e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:16:02<4:28:28,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:16:06<4:35:41,  3.52s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.5801233649253845, 'learning_rate': 3.9855932203389836e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:16:06<4:35:41,  3.52s/it] 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:16:09<4:33:31,  3.49s/it]                                                       {'loss': 0.0977, 'grad_norm': 5.184957027435303, 'learning_rate': 3.984745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:16:09<4:33:31,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:13<4:33:28,  3.49s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5447497367858887, 'learning_rate': 3.983898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:13<4:33:28,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:16<4:32:16,  3.48s/it]                                                       {'loss': 0.1273, 'grad_norm': 7.159765720367432, 'learning_rate': 3.983050847457627e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:16<4:32:16,  3.48s/it][2025-10-20 00:53:21,343] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:22<5:22:50,  4.12s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.2224591970443726, 'learning_rate': 3.982203389830509e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:22<5:22:50,  4.12s/it] 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:25<5:05:04,  3.90s/it]                                                       {'loss': 0.0377, 'grad_norm': 2.836338758468628, 'learning_rate': 3.98135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:25<5:05:04,  3.90s/it] 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:28<4:52:28,  3.74s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.1701664924621582, 'learning_rate': 3.980508474576272e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:28<4:52:28,  3.74s/it] 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:16:32<4:45:04,  3.64s/it]                                                       {'loss': 0.0239, 'grad_norm': 3.516080379486084, 'learning_rate': 3.979661016949153e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:16:32<4:45:04,  3.64s/it] 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:16:35<4:38:04,  3.55s/it]                                                       {'loss': 0.0425, 'grad_norm': 4.798940658569336, 'learning_rate': 3.978813559322034e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:16:35<4:38:04,  3.55s/it] 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:16:39<4:37:17,  3.54s/it]                                                       {'loss': 0.0431, 'grad_norm': 3.8915023803710938, 'learning_rate': 3.977966101694916e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:16:39<4:37:17,  3.54s/it] 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:16:42<4:33:08,  3.49s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05904288589954376, 'learning_rate': 3.977118644067796e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:16:42<4:33:08,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:16:45<4:31:50,  3.48s/it]                                                       {'loss': 0.1575, 'grad_norm': 8.905574798583984, 'learning_rate': 3.976271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:16:45<4:31:50,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:16:49<4:30:42,  3.46s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.5770748853683472, 'learning_rate': 3.975423728813559e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:16:49<4:30:42,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:16:52<4:29:22,  3.45s/it]                                                       {'loss': 0.0204, 'grad_norm': 3.021643877029419, 'learning_rate': 3.974576271186441e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:16:52<4:29:22,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:16:56<4:25:45,  3.40s/it]                                                       {'loss': 0.0278, 'grad_norm': 4.1189045906066895, 'learning_rate': 3.973728813559322e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:16:56<4:25:45,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:16:59<4:24:48,  3.39s/it]                                                       {'loss': 0.3895, 'grad_norm': 12.80284309387207, 'learning_rate': 3.972881355932204e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:16:59<4:24:48,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:17:02<4:25:07,  3.39s/it]                                                       {'loss': 0.0933, 'grad_norm': 6.136901378631592, 'learning_rate': 3.972033898305085e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:17:02<4:25:07,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:17:06<4:23:17,  3.37s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.5522252321243286, 'learning_rate': 3.971186440677966e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:17:06<4:23:17,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:17:09<4:21:44,  3.35s/it]                                                       {'loss': 0.2441, 'grad_norm': 5.792153358459473, 'learning_rate': 3.970338983050847e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:17:09<4:21:44,  3.35s/it] 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:12<4:23:06,  3.37s/it]                                                       {'loss': 0.2901, 'grad_norm': 8.047921180725098, 'learning_rate': 3.969491525423729e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:12<4:23:06,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:16<4:23:17,  3.37s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.12289131432771683, 'learning_rate': 3.96864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:16<4:23:17,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:19<4:28:36,  3.44s/it]                                                       {'loss': 0.0353, 'grad_norm': 3.190420389175415, 'learning_rate': 3.967796610169492e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:19<4:28:36,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:23<4:26:15,  3.41s/it]                                                       {'loss': 0.2304, 'grad_norm': 7.288556098937988, 'learning_rate': 3.966949152542373e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:23<4:26:15,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:26<4:25:38,  3.41s/it]                                                       {'loss': 0.0753, 'grad_norm': 7.845386981964111, 'learning_rate': 3.966101694915255e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:26<4:25:38,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:30<4:25:39,  3.41s/it]                                                       {'loss': 0.1164, 'grad_norm': 10.75246810913086, 'learning_rate': 3.9652542372881354e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:30<4:25:39,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:17:33<4:37:28,  3.56s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.2419153451919556, 'learning_rate': 3.964406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:17:33<4:37:28,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:17:37<4:35:31,  3.53s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3026171028614044, 'learning_rate': 3.9635593220338983e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:17:37<4:35:31,  3.53s/it] 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:17:40<4:31:28,  3.48s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.4643409252166748, 'learning_rate': 3.96271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:17:40<4:31:28,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:17:44<4:28:17,  3.44s/it]                                                       {'loss': 0.0364, 'grad_norm': 2.744004249572754, 'learning_rate': 3.961864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:17:44<4:28:17,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:17:47<4:27:04,  3.43s/it]                                                       {'loss': 0.0282, 'grad_norm': 4.779033660888672, 'learning_rate': 3.9610169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:17:47<4:27:04,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:17:50<4:27:43,  3.44s/it]                                                       {'loss': 0.0086, 'grad_norm': 0.9988293647766113, 'learning_rate': 3.960169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:17:51<4:27:43,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:17:54<4:26:43,  3.43s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.9757454991340637, 'learning_rate': 3.9593220338983053e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:17:54<4:26:43,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:17:58<4:35:27,  3.54s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.447893738746643, 'learning_rate': 3.9584745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:17:58<4:35:27,  3.54s/it] 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:18:01<4:31:25,  3.49s/it]                                                       {'loss': 0.081, 'grad_norm': 4.765497207641602, 'learning_rate': 3.9576271186440676e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:18:01<4:31:25,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:18:04<4:30:04,  3.47s/it]                                                       {'loss': 0.0753, 'grad_norm': 7.59332799911499, 'learning_rate': 3.9567796610169494e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:18:05<4:30:04,  3.47s/it] 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:18:08<4:27:35,  3.44s/it]                                                       {'loss': 0.0661, 'grad_norm': 5.266357421875, 'learning_rate': 3.9559322033898305e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:18:08<4:27:35,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:11<4:27:59,  3.45s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.231614351272583, 'learning_rate': 3.9550847457627123e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:11<4:27:59,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:15<4:27:50,  3.44s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3255181610584259, 'learning_rate': 3.9542372881355935e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:15<4:27:50,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:18<4:24:31,  3.40s/it]                                                       {'loss': 0.0984, 'grad_norm': 5.526802062988281, 'learning_rate': 3.9533898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:18<4:24:31,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:21<4:24:36,  3.40s/it]                                                       {'loss': 0.0208, 'grad_norm': 3.0431089401245117, 'learning_rate': 3.952542372881356e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:21<4:24:36,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:25<4:21:54,  3.37s/it]                                                       {'loss': 0.0674, 'grad_norm': 4.262511730194092, 'learning_rate': 3.9516949152542375e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:25<4:21:54,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:28<4:22:20,  3.38s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.3921672105789185, 'learning_rate': 3.9508474576271187e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:28<4:22:20,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:18:32<4:22:00,  3.37s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.8420168161392212, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:18:32<4:22:00,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:18:35<4:21:08,  3.36s/it]                                                       {'loss': 0.0828, 'grad_norm': 7.681513786315918, 'learning_rate': 3.9491525423728816e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:18:35<4:21:08,  3.36s/it] 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:18:38<4:24:16,  3.40s/it]                                                       {'loss': 0.1406, 'grad_norm': 7.160618305206299, 'learning_rate': 3.9483050847457634e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:18:39<4:24:16,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:18:42<4:35:56,  3.55s/it]                                                       {'loss': 0.1295, 'grad_norm': 7.999895095825195, 'learning_rate': 3.9474576271186445e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:18:42<4:35:56,  3.55s/it] 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:18:46<4:40:24,  3.61s/it]                                                       {'loss': 0.0798, 'grad_norm': 4.725452899932861, 'learning_rate': 3.9466101694915257e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:18:46<4:40:24,  3.61s/it] 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:18:49<4:36:22,  3.56s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5485965013504028, 'learning_rate': 3.945762711864407e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:18:49<4:36:22,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:18:53<4:40:13,  3.61s/it]                                                       {'loss': 0.0645, 'grad_norm': 4.469666957855225, 'learning_rate': 3.9449152542372886e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:18:53<4:40:13,  3.61s/it] 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:18:57<4:35:02,  3.55s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06786332279443741, 'learning_rate': 3.94406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:18:57<4:35:02,  3.55s/it] 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:19:00<4:32:41,  3.52s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.20275229215621948, 'learning_rate': 3.943220338983051e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:19:00<4:32:41,  3.52s/it] 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:19:03<4:29:19,  3.47s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.129578709602356, 'learning_rate': 3.9423728813559327e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:19:03<4:29:19,  3.47s/it] 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:19:07<4:36:46,  3.57s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07080404460430145, 'learning_rate': 3.941525423728814e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:19:07<4:36:46,  3.57s/it] 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:11<4:37:50,  3.58s/it]                                                       {'loss': 0.0404, 'grad_norm': 4.399753570556641, 'learning_rate': 3.940677966101695e-05, 'epoch': 0.23}
 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:11<4:37:50,  3.58s/it][2025-10-20 00:56:16,139] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:16<5:23:30,  4.18s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0013545919209718704, 'learning_rate': 3.939830508474576e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:16<5:23:30,  4.18s/it] 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:20<5:05:52,  3.95s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.2553379535675049, 'learning_rate': 3.938983050847458e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:20<5:05:52,  3.95s/it] 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:23<4:56:07,  3.82s/it]                                                       {'loss': 0.0577, 'grad_norm': 6.807537078857422, 'learning_rate': 3.938135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:23<4:56:07,  3.82s/it] 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:27<4:46:54,  3.71s/it]                                                       {'loss': 0.0102, 'grad_norm': 0.8898323178291321, 'learning_rate': 3.937288135593221e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:27<4:46:54,  3.71s/it] 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:30<4:42:05,  3.64s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.6113632917404175, 'learning_rate': 3.936440677966102e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:30<4:42:05,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:19:34<4:50:40,  3.76s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.743192195892334, 'learning_rate': 3.935593220338983e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:19:34<4:50:40,  3.76s/it] 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:19:38<4:44:51,  3.68s/it]                                                       {'loss': 0.001, 'grad_norm': 0.15847469866275787, 'learning_rate': 3.934745762711864e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:19:38<4:44:51,  3.68s/it] 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:19:41<4:39:50,  3.62s/it]                                                       {'loss': 0.0707, 'grad_norm': 5.567417621612549, 'learning_rate': 3.933898305084746e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:19:41<4:39:50,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:19:45<4:41:39,  3.64s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.3833314180374146, 'learning_rate': 3.933050847457627e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:19:45<4:41:39,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:19:48<4:34:02,  3.54s/it]                                                       {'loss': 0.1199, 'grad_norm': 4.750231742858887, 'learning_rate': 3.932203389830509e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:19:48<4:34:02,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:19:52<4:29:33,  3.49s/it]                                                       {'loss': 0.2376, 'grad_norm': 14.047224044799805, 'learning_rate': 3.93135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:19:52<4:29:33,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:19:55<4:30:45,  3.50s/it]                                                       {'loss': 0.0213, 'grad_norm': 4.187534332275391, 'learning_rate': 3.930508474576272e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:19:55<4:30:45,  3.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:19:59<4:29:04,  3.48s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.2524096667766571, 'learning_rate': 3.929661016949153e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:19:59<4:29:04,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:20:02<4:25:22,  3.43s/it]                                                       {'loss': 0.0637, 'grad_norm': 5.116831302642822, 'learning_rate': 3.928813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:20:02<4:25:22,  3.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:20:06<4:33:47,  3.54s/it]                                                       {'loss': 0.0432, 'grad_norm': 7.603682041168213, 'learning_rate': 3.927966101694915e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:20:06<4:33:47,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:20:10<4:43:46,  3.67s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7458816170692444, 'learning_rate': 3.927118644067797e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:20:10<4:43:46,  3.67s/it] 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:14<4:48:42,  3.74s/it]                                                       {'loss': 0.1813, 'grad_norm': 6.63548469543457, 'learning_rate': 3.926271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:14<4:48:42,  3.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:17<4:40:24,  3.63s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1861284077167511, 'learning_rate': 3.925423728813559e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:17<4:40:24,  3.63s/it] 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:20<4:33:29,  3.54s/it]                                                       {'loss': 0.0372, 'grad_norm': 3.871029853820801, 'learning_rate': 3.924576271186441e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:20<4:33:29,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:25<4:52:25,  3.79s/it]                                                       {'loss': 0.1836, 'grad_norm': 5.3940887451171875, 'learning_rate': 3.923728813559322e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:25<4:52:25,  3.79s/it] 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:28<4:46:26,  3.71s/it]                                                       {'loss': 0.1015, 'grad_norm': 5.862688064575195, 'learning_rate': 3.9228813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:28<4:46:26,  3.71s/it] 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:20:32<4:39:15,  3.62s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.5191895365715027, 'learning_rate': 3.9220338983050845e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:20:32<4:39:15,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:20:35<4:37:07,  3.59s/it]                                                       {'loss': 0.0854, 'grad_norm': 7.19506311416626, 'learning_rate': 3.921186440677966e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:20:35<4:37:07,  3.59s/it] 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:20:39<4:36:52,  3.59s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.045780736953020096, 'learning_rate': 3.9203389830508474e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:20:39<4:36:52,  3.59s/it] 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:20:42<4:32:01,  3.53s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5157645344734192, 'learning_rate': 3.919491525423729e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:20:42<4:32:01,  3.53s/it] 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:20:46<4:33:06,  3.54s/it]                                                       {'loss': 0.3145, 'grad_norm': 15.22048568725586, 'learning_rate': 3.9186440677966104e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:20:46<4:33:06,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:20:49<4:29:09,  3.49s/it]                                                       {'loss': 0.1561, 'grad_norm': 4.965000629425049, 'learning_rate': 3.917796610169492e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:20:49<4:29:09,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:20:52<4:26:17,  3.46s/it]                                                       {'loss': 0.0138, 'grad_norm': 2.3066065311431885, 'learning_rate': 3.9169491525423726e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:20:52<4:26:17,  3.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:20:56<4:25:28,  3.45s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.8259212970733643, 'learning_rate': 3.9161016949152544e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:20:56<4:25:28,  3.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:20:59<4:23:58,  3.43s/it]                                                       {'loss': 0.0677, 'grad_norm': 4.214543342590332, 'learning_rate': 3.9152542372881355e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:20:59<4:23:58,  3.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:21:03<4:30:43,  3.52s/it]                                                       {'loss': 0.3739, 'grad_norm': 12.703177452087402, 'learning_rate': 3.9144067796610174e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:21:03<4:30:43,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:21:06<4:30:06,  3.51s/it]                                                       {'loss': 0.2167, 'grad_norm': 7.43069314956665, 'learning_rate': 3.9135593220338985e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:21:06<4:30:06,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:21:10<4:30:13,  3.51s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.7039693593978882, 'learning_rate': 3.91271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:21:10<4:30:13,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:14<4:34:54,  3.57s/it]                                                       {'loss': 0.1782, 'grad_norm': 4.399773120880127, 'learning_rate': 3.9118644067796614e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:14<4:34:54,  3.57s/it] 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:17<4:32:06,  3.54s/it]                                                       {'loss': 0.0279, 'grad_norm': 2.6009552478790283, 'learning_rate': 3.9110169491525425e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:17<4:32:06,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:21<4:29:55,  3.51s/it]                                                       {'loss': 0.1135, 'grad_norm': 9.37956714630127, 'learning_rate': 3.910169491525424e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:21<4:29:55,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:24<4:28:37,  3.49s/it]                                                       {'loss': 0.0152, 'grad_norm': 1.8126755952835083, 'learning_rate': 3.9093220338983055e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:24<4:28:37,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:28<4:28:38,  3.49s/it]                                                       {'loss': 0.0984, 'grad_norm': 5.391473770141602, 'learning_rate': 3.9084745762711866e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:28<4:28:38,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:21:32<4:44:28,  3.70s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.15826132893562317, 'learning_rate': 3.907627118644068e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:21:32<4:44:28,  3.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:21:35<4:36:35,  3.60s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.16221265494823456, 'learning_rate': 3.9067796610169495e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:21:35<4:36:35,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:21:38<4:30:00,  3.52s/it]                                                       {'loss': 0.023, 'grad_norm': 2.4244930744171143, 'learning_rate': 3.905932203389831e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:21:38<4:30:00,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:21:42<4:28:12,  3.49s/it]                                                       {'loss': 0.0647, 'grad_norm': 6.770753383636475, 'learning_rate': 3.905084745762712e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:21:42<4:28:12,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:21:45<4:26:36,  3.47s/it]                                                       {'loss': 0.0161, 'grad_norm': 1.4236946105957031, 'learning_rate': 3.904237288135593e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:21:45<4:26:36,  3.47s/it] 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:21:49<4:23:13,  3.43s/it]                                                       {'loss': 0.054, 'grad_norm': 3.1361501216888428, 'learning_rate': 3.903389830508475e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:21:49<4:23:13,  3.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:21:52<4:27:02,  3.48s/it]                                                       {'loss': 0.2673, 'grad_norm': 6.475107669830322, 'learning_rate': 3.902542372881356e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:21:52<4:27:02,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:21:56<4:26:52,  3.48s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14487780630588531, 'learning_rate': 3.901694915254238e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:21:56<4:26:52,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:21:59<4:25:04,  3.46s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.28828293085098267, 'learning_rate': 3.900847457627119e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:21:59<4:25:04,  3.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:22:02<4:23:22,  3.43s/it]                                                       {'loss': 0.0217, 'grad_norm': 3.0074024200439453, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:22:02<4:23:22,  3.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:22:06<4:21:17,  3.41s/it]                                                       {'loss': 0.2936, 'grad_norm': 6.831121444702148, 'learning_rate': 3.899152542372882e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:22:06<4:21:17,  3.41s/it] 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:22:09<4:20:31,  3.40s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4331039488315582, 'learning_rate': 3.898305084745763e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:22:09<4:20:31,  3.40s/it][2025-10-20 00:59:14,492] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:15<5:09:23,  4.04s/it]                                                       {'loss': 0.0145, 'grad_norm': 1.6360690593719482, 'learning_rate': 3.897457627118644e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:15<5:09:23,  4.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:18<4:56:03,  3.86s/it]                                                       {'loss': 0.2185, 'grad_norm': 9.391914367675781, 'learning_rate': 3.896610169491526e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:18<4:56:03,  3.86s/it] 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:21<4:43:55,  3.71s/it]                                                       {'loss': 0.0118, 'grad_norm': 2.0627756118774414, 'learning_rate': 3.895762711864407e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:22<4:43:55,  3.71s/it] 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:25<4:35:55,  3.60s/it]                                                       {'loss': 0.0522, 'grad_norm': 2.5666186809539795, 'learning_rate': 3.894915254237289e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:25<4:35:55,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:28<4:31:35,  3.55s/it]                                                       {'loss': 0.1351, 'grad_norm': 6.5637431144714355, 'learning_rate': 3.89406779661017e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:28<4:31:35,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:22:32<4:29:52,  3.52s/it]                                                       {'loss': 0.0739, 'grad_norm': 4.378693580627441, 'learning_rate': 3.893220338983051e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:22:32<4:29:52,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:22:36<4:36:45,  3.62s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0819089487195015, 'learning_rate': 3.892372881355932e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:22:36<4:36:45,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:22:39<4:32:20,  3.56s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.014425784349441528, 'learning_rate': 3.891525423728814e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:22:39<4:32:20,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:22:42<4:29:47,  3.53s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.11759680509567261, 'learning_rate': 3.890677966101695e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:22:42<4:29:47,  3.53s/it] 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:22:46<4:35:47,  3.61s/it]                                                       {'loss': 0.0446, 'grad_norm': 2.4617857933044434, 'learning_rate': 3.889830508474576e-05, 'epoch': 0.23}
 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:22:46<4:35:47,  3.61s/it] 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:22:50<4:32:39,  3.56s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.831404209136963, 'learning_rate': 3.888983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:22:50<4:32:39,  3.56s/it] 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:22:54<4:41:59,  3.69s/it]                                                       {'loss': 0.0571, 'grad_norm': 4.42396879196167, 'learning_rate': 3.888135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:22:54<4:41:59,  3.69s/it] 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:22:57<4:34:39,  3.59s/it]                                                       {'loss': 0.003, 'grad_norm': 0.35641300678253174, 'learning_rate': 3.88728813559322e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:22:57<4:34:39,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:23:00<4:31:14,  3.55s/it]                                                       {'loss': 0.2623, 'grad_norm': 7.923652172088623, 'learning_rate': 3.8864406779661014e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:23:01<4:31:14,  3.55s/it] 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:23:04<4:37:31,  3.63s/it]                                                       {'loss': 0.0333, 'grad_norm': 5.009002685546875, 'learning_rate': 3.885593220338983e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:23:04<4:37:31,  3.63s/it] 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:23:08<4:32:02,  3.56s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.6319044828414917, 'learning_rate': 3.884745762711864e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:23:08<4:32:02,  3.56s/it] 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:23:11<4:31:59,  3.56s/it]                                                       {'loss': 0.07, 'grad_norm': 4.856895446777344, 'learning_rate': 3.883898305084746e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:23:11<4:31:59,  3.56s/it] 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:15<4:29:21,  3.53s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.9955220222473145, 'learning_rate': 3.883050847457627e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:15<4:29:21,  3.53s/it] 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:18<4:29:45,  3.53s/it]                                                       {'loss': 0.0713, 'grad_norm': 4.869931697845459, 'learning_rate': 3.882203389830509e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:18<4:29:45,  3.53s/it] 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:22<4:26:31,  3.49s/it]                                                       {'loss': 0.0462, 'grad_norm': 1.8134160041809082, 'learning_rate': 3.88135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:22<4:26:31,  3.49s/it] 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:25<4:24:58,  3.47s/it]                                                       {'loss': 0.0592, 'grad_norm': 15.408137321472168, 'learning_rate': 3.880508474576271e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:25<4:24:58,  3.47s/it] 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:29<4:23:46,  3.46s/it]                                                       {'loss': 0.1927, 'grad_norm': 17.65839958190918, 'learning_rate': 3.8796610169491524e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:29<4:23:46,  3.46s/it] 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:23:32<4:21:08,  3.42s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.2052290439605713, 'learning_rate': 3.878813559322034e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:23:32<4:21:08,  3.42s/it] 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:23:35<4:21:23,  3.43s/it]                                                       {'loss': 0.3158, 'grad_norm': 10.919512748718262, 'learning_rate': 3.8779661016949154e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:23:35<4:21:23,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:23:39<4:22:17,  3.44s/it]                                                       {'loss': 0.1391, 'grad_norm': 7.720663070678711, 'learning_rate': 3.877118644067797e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:23:39<4:22:17,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:23:42<4:28:43,  3.53s/it]                                                       {'loss': 0.1039, 'grad_norm': 6.739679336547852, 'learning_rate': 3.876271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:23:43<4:28:43,  3.53s/it] 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:23:46<4:24:49,  3.47s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5794144868850708, 'learning_rate': 3.8754237288135594e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:23:46<4:24:49,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:23:49<4:23:29,  3.46s/it]                                                       {'loss': 0.1152, 'grad_norm': 7.843449592590332, 'learning_rate': 3.8745762711864406e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:23:49<4:23:29,  3.46s/it] 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:23:53<4:22:12,  3.44s/it]                                                       {'loss': 0.0276, 'grad_norm': 2.8119919300079346, 'learning_rate': 3.8737288135593224e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:23:53<4:22:12,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:23:56<4:22:23,  3.44s/it]                                                       {'loss': 0.0288, 'grad_norm': 2.767061710357666, 'learning_rate': 3.8728813559322035e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:23:56<4:22:23,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:24:00<4:28:54,  3.53s/it]                                                       {'loss': 0.0176, 'grad_norm': 1.883934736251831, 'learning_rate': 3.8720338983050846e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:24:00<4:28:54,  3.53s/it] 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:24:03<4:26:57,  3.51s/it]                                                       {'loss': 0.005, 'grad_norm': 0.49039140343666077, 'learning_rate': 3.8711864406779664e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:24:03<4:26:57,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:24:07<4:36:47,  3.64s/it]                                                       {'loss': 0.0352, 'grad_norm': 4.396533012390137, 'learning_rate': 3.8703389830508476e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:24:07<4:36:47,  3.64s/it] 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:24:11<4:35:30,  3.62s/it]                                                       {'loss': 0.0346, 'grad_norm': 3.893786907196045, 'learning_rate': 3.8694915254237294e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:24:11<4:35:30,  3.62s/it] 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:14<4:30:28,  3.55s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.4176084101200104, 'learning_rate': 3.86864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:14<4:30:28,  3.55s/it] 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:18<4:33:13,  3.59s/it]                                                       {'loss': 0.0399, 'grad_norm': 2.521074056625366, 'learning_rate': 3.8677966101694916e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:18<4:33:13,  3.59s/it] 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:21<4:30:23,  3.56s/it]                                                       {'loss': 0.1186, 'grad_norm': 5.148307800292969, 'learning_rate': 3.866949152542373e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:21<4:30:23,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:25<4:25:40,  3.49s/it]                                                       {'loss': 0.0132, 'grad_norm': 0.7979247570037842, 'learning_rate': 3.8661016949152546e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:25<4:25:40,  3.49s/it] 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:28<4:21:21,  3.44s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4135206639766693, 'learning_rate': 3.865254237288136e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:28<4:21:21,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:24:31<4:20:20,  3.43s/it]                                                       {'loss': 0.0699, 'grad_norm': 5.725816249847412, 'learning_rate': 3.8644067796610175e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:24:31<4:20:20,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:24:35<4:17:06,  3.38s/it]                                                       {'loss': 0.0415, 'grad_norm': 2.9762237071990967, 'learning_rate': 3.8635593220338986e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:24:35<4:17:06,  3.38s/it] 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:24:38<4:18:51,  3.41s/it]                                                       {'loss': 0.211, 'grad_norm': 9.987255096435547, 'learning_rate': 3.86271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:24:38<4:18:51,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:24:42<4:16:50,  3.38s/it]                                                       {'loss': 0.0356, 'grad_norm': 4.676211833953857, 'learning_rate': 3.861864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:24:42<4:16:50,  3.38s/it] 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:24:45<4:15:49,  3.37s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.3167779445648193, 'learning_rate': 3.861016949152543e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:24:45<4:15:49,  3.37s/it] 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:24:48<4:14:52,  3.36s/it]                                                       {'loss': 0.0267, 'grad_norm': 3.3548903465270996, 'learning_rate': 3.860169491525424e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:24:48<4:14:52,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:24:52<4:15:41,  3.37s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.0963282585144043, 'learning_rate': 3.8593220338983056e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:24:52<4:15:41,  3.37s/it] 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:24:55<4:14:15,  3.35s/it]                                                       {'loss': 0.0282, 'grad_norm': 2.424830675125122, 'learning_rate': 3.858474576271187e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:24:55<4:14:15,  3.35s/it] 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:24:58<4:13:35,  3.34s/it]                                                       {'loss': 0.5506, 'grad_norm': 12.237130165100098, 'learning_rate': 3.8576271186440686e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:24:58<4:13:35,  3.34s/it] 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:25:02<4:14:00,  3.35s/it]                                                       {'loss': 0.0215, 'grad_norm': 2.3463542461395264, 'learning_rate': 3.856779661016949e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:25:02<4:14:00,  3.35s/it] 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:25:05<4:14:34,  3.36s/it]                                                       {'loss': 0.034, 'grad_norm': 2.3312435150146484, 'learning_rate': 3.855932203389831e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:25:05<4:14:34,  3.36s/it][2025-10-20 01:02:10,266] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:25:11<5:04:59,  4.02s/it]                                                       {'loss': 0.0846, 'grad_norm': 7.764233589172363, 'learning_rate': 3.855084745762712e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:25:11<5:04:59,  4.02s/it] 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:25:14<4:50:20,  3.83s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6491910815238953, 'learning_rate': 3.854237288135593e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:25:14<4:50:20,  3.83s/it] 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:17<4:40:33,  3.70s/it]                                                       {'loss': 0.1768, 'grad_norm': 8.346720695495605, 'learning_rate': 3.853389830508475e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:17<4:40:33,  3.70s/it] 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:21<4:32:25,  3.60s/it]                                                       {'loss': 0.051, 'grad_norm': 2.080810546875, 'learning_rate': 3.852542372881356e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:21<4:32:25,  3.60s/it] 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:24<4:26:20,  3.52s/it]                                                       {'loss': 0.042, 'grad_norm': 1.8198504447937012, 'learning_rate': 3.851694915254238e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:24<4:26:20,  3.52s/it] 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:27<4:24:43,  3.50s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3548929989337921, 'learning_rate': 3.850847457627119e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:27<4:24:43,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:25:31<4:22:29,  3.47s/it]                                                       {'loss': 0.0672, 'grad_norm': 4.148041725158691, 'learning_rate': 3.85e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:25:31<4:22:29,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:25:34<4:21:02,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08365010470151901, 'learning_rate': 3.849152542372881e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:25:34<4:21:02,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:25:38<4:20:01,  3.44s/it]                                                       {'loss': 0.0614, 'grad_norm': 6.344557762145996, 'learning_rate': 3.848305084745763e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:25:38<4:20:01,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:25:41<4:17:39,  3.41s/it]                                                       {'loss': 0.1246, 'grad_norm': 16.942766189575195, 'learning_rate': 3.847457627118644e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:25:41<4:17:39,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:25:45<4:26:07,  3.52s/it]                                                       {'loss': 0.0667, 'grad_norm': 3.1103625297546387, 'learning_rate': 3.846610169491526e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:25:45<4:26:07,  3.52s/it] 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:25:48<4:23:10,  3.48s/it]                                                       {'loss': 0.0576, 'grad_norm': 5.668857097625732, 'learning_rate': 3.845762711864407e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:25:48<4:23:10,  3.48s/it] 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:25:52<4:22:09,  3.47s/it]                                                       {'loss': 0.105, 'grad_norm': 6.627357006072998, 'learning_rate': 3.844915254237288e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:25:52<4:22:09,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:25:55<4:18:34,  3.42s/it]                                                       {'loss': 0.1115, 'grad_norm': 9.061910629272461, 'learning_rate': 3.844067796610169e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:25:55<4:18:34,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:25:58<4:20:17,  3.44s/it]                                                       {'loss': 0.0307, 'grad_norm': 4.212320804595947, 'learning_rate': 3.843220338983051e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:25:58<4:20:17,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:26:02<4:18:16,  3.42s/it]                                                       {'loss': 0.0429, 'grad_norm': 3.906299114227295, 'learning_rate': 3.842372881355932e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:26:02<4:18:16,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:26:05<4:18:37,  3.42s/it]                                                       {'loss': 0.0427, 'grad_norm': 2.840435266494751, 'learning_rate': 3.841525423728814e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:26:05<4:18:37,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:26:09<4:17:05,  3.40s/it]                                                       {'loss': 0.1327, 'grad_norm': 9.334254264831543, 'learning_rate': 3.840677966101695e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:26:09<4:17:05,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:26:12<4:25:30,  3.52s/it]                                                       {'loss': 0.0148, 'grad_norm': 1.2530542612075806, 'learning_rate': 3.839830508474577e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:26:12<4:25:30,  3.52s/it] 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:16<4:24:36,  3.50s/it]                                                       {'loss': 0.1805, 'grad_norm': 8.76061725616455, 'learning_rate': 3.838983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:16<4:24:36,  3.50s/it] 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:19<4:23:23,  3.49s/it]                                                       {'loss': 0.1341, 'grad_norm': 9.011991500854492, 'learning_rate': 3.838135593220339e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:19<4:23:23,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:23<4:19:55,  3.44s/it]                                                       {'loss': 0.0655, 'grad_norm': 6.565017223358154, 'learning_rate': 3.8372881355932204e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:23<4:19:55,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:26<4:18:21,  3.42s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.8596692085266113, 'learning_rate': 3.8364406779661015e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:26<4:18:21,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:26:30<4:20:47,  3.46s/it]                                                       {'loss': 0.0484, 'grad_norm': 6.805460453033447, 'learning_rate': 3.835593220338983e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:26:30<4:20:47,  3.46s/it] 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:26:34<4:35:11,  3.65s/it]                                                       {'loss': 0.1784, 'grad_norm': 7.607438564300537, 'learning_rate': 3.8347457627118644e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:26:34<4:35:11,  3.65s/it] 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:26:37<4:27:04,  3.54s/it]                                                       {'loss': 0.0476, 'grad_norm': 2.9821536540985107, 'learning_rate': 3.833898305084746e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:26:37<4:27:04,  3.54s/it] 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:26:40<4:21:40,  3.47s/it]                                                       {'loss': 0.152, 'grad_norm': 8.015380859375, 'learning_rate': 3.8330508474576274e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:26:40<4:21:40,  3.47s/it] 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:26:44<4:19:19,  3.44s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1265278458595276, 'learning_rate': 3.8322033898305085e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:26:44<4:19:19,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:26:47<4:18:03,  3.42s/it]                                                       {'loss': 0.1201, 'grad_norm': 7.411555767059326, 'learning_rate': 3.8313559322033896e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:26:47<4:18:03,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:26:50<4:15:12,  3.39s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2820345163345337, 'learning_rate': 3.8305084745762714e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:26:50<4:15:12,  3.39s/it] 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:26:54<4:12:18,  3.35s/it]                                                       {'loss': 0.088, 'grad_norm': 6.830117225646973, 'learning_rate': 3.8296610169491526e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:26:54<4:12:18,  3.35s/it] 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:26:57<4:11:46,  3.34s/it]                                                       {'loss': 0.1433, 'grad_norm': 6.666225433349609, 'learning_rate': 3.8288135593220344e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:26:57<4:11:46,  3.34s/it] 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:27:00<4:13:17,  3.36s/it]                                                       {'loss': 0.078, 'grad_norm': 5.947613716125488, 'learning_rate': 3.8279661016949155e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:27:00<4:13:17,  3.36s/it] 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:27:04<4:12:59,  3.36s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.5305635929107666, 'learning_rate': 3.8271186440677966e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:27:04<4:12:59,  3.36s/it] 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:27:07<4:14:17,  3.38s/it]                                                       {'loss': 0.2451, 'grad_norm': 7.1497344970703125, 'learning_rate': 3.826271186440678e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:27:07<4:14:17,  3.38s/it] 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:27:10<4:16:02,  3.40s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.8376478552818298, 'learning_rate': 3.8254237288135596e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:27:10<4:16:02,  3.40s/it] 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:14<4:26:24,  3.54s/it]                                                       {'loss': 0.0786, 'grad_norm': 5.069413661956787, 'learning_rate': 3.824576271186441e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:14<4:26:24,  3.54s/it] 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:18<4:22:15,  3.49s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.7797434329986572, 'learning_rate': 3.8237288135593225e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:18<4:22:15,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:21<4:28:21,  3.57s/it]                                                       {'loss': 0.0779, 'grad_norm': 4.913904666900635, 'learning_rate': 3.8228813559322036e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:21<4:28:21,  3.57s/it] 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:25<4:27:25,  3.56s/it]                                                       {'loss': 0.074, 'grad_norm': 4.5964179039001465, 'learning_rate': 3.8220338983050854e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:25<4:27:25,  3.56s/it] 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:27:28<4:23:06,  3.50s/it]                                                       {'loss': 0.0176, 'grad_norm': 3.238889217376709, 'learning_rate': 3.8211864406779666e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:27:28<4:23:06,  3.50s/it] 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:27:32<4:30:47,  3.60s/it]                                                       {'loss': 0.0462, 'grad_norm': 3.6980090141296387, 'learning_rate': 3.820338983050848e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:27:32<4:30:47,  3.60s/it] 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:27:36<4:24:12,  3.52s/it]                                                       {'loss': 0.011, 'grad_norm': 1.2073560953140259, 'learning_rate': 3.819491525423729e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:27:36<4:24:12,  3.52s/it] 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:27:39<4:21:16,  3.48s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.1166826486587524, 'learning_rate': 3.81864406779661e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:27:39<4:21:16,  3.48s/it] 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:27:42<4:18:26,  3.44s/it]                                                       {'loss': 0.1304, 'grad_norm': 8.305312156677246, 'learning_rate': 3.817796610169492e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:27:42<4:18:26,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:27:46<4:17:49,  3.43s/it]                                                       {'loss': 0.1414, 'grad_norm': 6.413718223571777, 'learning_rate': 3.816949152542373e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:27:46<4:17:49,  3.43s/it] 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:27:49<4:17:11,  3.43s/it]                                                       {'loss': 0.2921, 'grad_norm': 9.473005294799805, 'learning_rate': 3.816101694915255e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:27:49<4:17:11,  3.43s/it] 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:27:53<4:16:25,  3.42s/it]                                                       {'loss': 0.0398, 'grad_norm': 3.667903423309326, 'learning_rate': 3.815254237288136e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:27:53<4:16:25,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:27:56<4:15:40,  3.41s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.5363807678222656, 'learning_rate': 3.814406779661017e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:27:56<4:15:40,  3.41s/it] 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:27:59<4:15:56,  3.41s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.6469643712043762, 'learning_rate': 3.813559322033898e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:27:59<4:15:56,  3.41s/it][2025-10-20 01:05:04,646] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:28:05<5:11:39,  4.16s/it]                                                       {'loss': 0.0454, 'grad_norm': 3.095733165740967, 'learning_rate': 3.81271186440678e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:28:05<5:11:39,  4.16s/it] 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:28:09<4:54:53,  3.93s/it]                                                       {'loss': 0.1043, 'grad_norm': 15.365400314331055, 'learning_rate': 3.811864406779661e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:28:09<4:54:53,  3.93s/it] 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:28:12<4:40:41,  3.75s/it]                                                       {'loss': 0.0915, 'grad_norm': 4.22408390045166, 'learning_rate': 3.811016949152543e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:28:12<4:40:41,  3.75s/it] 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:15<4:33:25,  3.65s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3122716546058655, 'learning_rate': 3.810169491525424e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:15<4:33:25,  3.65s/it] 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:19<4:27:25,  3.57s/it]                                                       {'loss': 0.001, 'grad_norm': 0.0892440676689148, 'learning_rate': 3.809322033898306e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:19<4:27:25,  3.57s/it] 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:22<4:23:38,  3.52s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.34361815452575684, 'learning_rate': 3.808474576271186e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:22<4:23:38,  3.52s/it] 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:26<4:21:30,  3.49s/it]                                                       {'loss': 0.185, 'grad_norm': 6.642261981964111, 'learning_rate': 3.807627118644068e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:26<4:21:30,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:28:29<4:21:50,  3.50s/it]                                                       {'loss': 0.1041, 'grad_norm': 6.456979274749756, 'learning_rate': 3.806779661016949e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:28:29<4:21:50,  3.50s/it] 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:28:33<4:20:11,  3.48s/it]                                                       {'loss': 0.105, 'grad_norm': 7.523519515991211, 'learning_rate': 3.805932203389831e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:28:33<4:20:11,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:28:36<4:20:34,  3.48s/it]                                                       {'loss': 0.0778, 'grad_norm': 3.6518867015838623, 'learning_rate': 3.805084745762712e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:28:36<4:20:34,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:28:39<4:18:25,  3.45s/it]                                                       {'loss': 0.1142, 'grad_norm': 7.832979202270508, 'learning_rate': 3.804237288135594e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:28:39<4:18:25,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:28:43<4:16:45,  3.43s/it]                                                       {'loss': 0.1161, 'grad_norm': 7.291409492492676, 'learning_rate': 3.803389830508475e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:28:43<4:16:45,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:28:46<4:16:21,  3.43s/it]                                                       {'loss': 0.1396, 'grad_norm': 7.804360389709473, 'learning_rate': 3.802542372881356e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:28:46<4:16:21,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:28:50<4:14:05,  3.40s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.20869295299053192, 'learning_rate': 3.801694915254237e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:28:50<4:14:05,  3.40s/it] 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:28:53<4:14:01,  3.40s/it]                                                       {'loss': 0.0356, 'grad_norm': 3.209308385848999, 'learning_rate': 3.8008474576271184e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:28:53<4:14:01,  3.40s/it] 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:28:56<4:16:50,  3.44s/it]                                                       {'loss': 0.1302, 'grad_norm': 6.897062301635742, 'learning_rate': 3.8e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:28:56<4:16:50,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:29:00<4:22:36,  3.51s/it]                                                       {'loss': 0.0972, 'grad_norm': 4.80639123916626, 'learning_rate': 3.799152542372881e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:29:00<4:22:36,  3.51s/it] 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:29:04<4:19:48,  3.48s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.6125284433364868, 'learning_rate': 3.798305084745763e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:29:04<4:19:48,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:29:07<4:16:51,  3.44s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.405503511428833, 'learning_rate': 3.797457627118644e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:29:07<4:16:51,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:29:10<4:20:41,  3.49s/it]                                                       {'loss': 0.0927, 'grad_norm': 5.940300941467285, 'learning_rate': 3.7966101694915254e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:29:11<4:20:41,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:14<4:17:47,  3.45s/it]                                                       {'loss': 0.0095, 'grad_norm': 0.8555951714515686, 'learning_rate': 3.7957627118644065e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:14<4:17:47,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:17<4:18:29,  3.46s/it]                                                       {'loss': 0.1612, 'grad_norm': 5.063139915466309, 'learning_rate': 3.794915254237288e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:17<4:18:29,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:21<4:17:15,  3.45s/it]                                                       {'loss': 0.0162, 'grad_norm': 2.1809868812561035, 'learning_rate': 3.7940677966101695e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:21<4:17:15,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:24<4:18:42,  3.47s/it]                                                       {'loss': 0.1003, 'grad_norm': 5.709187984466553, 'learning_rate': 3.793220338983051e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:24<4:18:42,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:28<4:20:15,  3.49s/it]                                                       {'loss': 0.0358, 'grad_norm': 3.0248374938964844, 'learning_rate': 3.7923728813559324e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:28<4:20:15,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:29:31<4:19:59,  3.49s/it]                                                       {'loss': 0.01, 'grad_norm': 1.2819592952728271, 'learning_rate': 3.791525423728814e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:29:31<4:19:59,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:29:35<4:26:55,  3.58s/it]                                                       {'loss': 0.0457, 'grad_norm': 4.622106552124023, 'learning_rate': 3.790677966101695e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:29:35<4:26:55,  3.58s/it] 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:29:39<4:35:50,  3.70s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.6597790122032166, 'learning_rate': 3.7898305084745765e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:29:39<4:35:50,  3.70s/it] 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:29:42<4:27:49,  3.59s/it]                                                       {'loss': 0.0182, 'grad_norm': 3.2639501094818115, 'learning_rate': 3.7889830508474576e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:29:42<4:27:49,  3.59s/it] 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:29:46<4:33:07,  3.67s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07562770694494247, 'learning_rate': 3.7881355932203394e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:29:46<4:33:07,  3.67s/it] 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:29:50<4:26:00,  3.57s/it]                                                       {'loss': 0.0277, 'grad_norm': 2.5257492065429688, 'learning_rate': 3.7872881355932205e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:29:50<4:26:00,  3.57s/it] 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:29:53<4:20:21,  3.50s/it]                                                       {'loss': 0.142, 'grad_norm': 5.90361213684082, 'learning_rate': 3.786440677966102e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:29:53<4:20:21,  3.50s/it] 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:29:56<4:16:56,  3.45s/it]                                                       {'loss': 0.0918, 'grad_norm': 6.28554105758667, 'learning_rate': 3.7855932203389835e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:29:56<4:16:56,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:30:00<4:13:38,  3.41s/it]                                                       {'loss': 0.0643, 'grad_norm': 5.1312079429626465, 'learning_rate': 3.7847457627118646e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:30:00<4:13:38,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:30:03<4:10:57,  3.37s/it]                                                       {'loss': 0.0988, 'grad_norm': 6.8448991775512695, 'learning_rate': 3.783898305084746e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:30:03<4:10:57,  3.37s/it] 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:30:06<4:09:46,  3.36s/it]                                                       {'loss': 0.1013, 'grad_norm': 7.531931400299072, 'learning_rate': 3.783050847457627e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:30:06<4:09:46,  3.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:30:10<4:10:37,  3.37s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.0275846719741821, 'learning_rate': 3.7822033898305087e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:30:10<4:10:37,  3.37s/it] 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:13<4:13:36,  3.41s/it]                                                       {'loss': 0.0449, 'grad_norm': 1.3003545999526978, 'learning_rate': 3.78135593220339e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:13<4:13:36,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:16<4:12:43,  3.40s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.642812192440033, 'learning_rate': 3.7805084745762716e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:16<4:12:43,  3.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:20<4:13:43,  3.41s/it]                                                       {'loss': 0.1382, 'grad_norm': 7.052773952484131, 'learning_rate': 3.779661016949153e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:20<4:13:43,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:24<4:19:16,  3.49s/it]                                                       {'loss': 0.1733, 'grad_norm': 8.539527893066406, 'learning_rate': 3.778813559322034e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:24<4:19:16,  3.49s/it] 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:27<4:17:33,  3.47s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5640334486961365, 'learning_rate': 3.777966101694915e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:27<4:17:33,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:30:30<4:18:16,  3.48s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011841803789138794, 'learning_rate': 3.777118644067797e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:30:31<4:18:16,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:30:34<4:17:00,  3.46s/it]                                                       {'loss': 0.1192, 'grad_norm': 9.130149841308594, 'learning_rate': 3.776271186440678e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:30:34<4:17:00,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:30:37<4:16:44,  3.46s/it]                                                       {'loss': 0.103, 'grad_norm': 3.705106258392334, 'learning_rate': 3.77542372881356e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:30:37<4:16:44,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:30:41<4:17:46,  3.47s/it]                                                       {'loss': 0.0369, 'grad_norm': 4.13495397567749, 'learning_rate': 3.774576271186441e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:30:41<4:17:46,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:30:44<4:14:30,  3.43s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.0001261234283447, 'learning_rate': 3.7737288135593226e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:30:44<4:14:30,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:30:48<4:13:00,  3.41s/it]                                                       {'loss': 0.0259, 'grad_norm': 2.338693141937256, 'learning_rate': 3.772881355932204e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:30:48<4:13:00,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:30:51<4:13:46,  3.42s/it]                                                       {'loss': 0.0296, 'grad_norm': 2.9166455268859863, 'learning_rate': 3.772033898305085e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:30:51<4:13:46,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:30:54<4:13:51,  3.42s/it]                                                       {'loss': 0.0225, 'grad_norm': 2.373706102371216, 'learning_rate': 3.771186440677966e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:30:54<4:13:51,  3.42s/it][2025-10-20 01:07:59,761] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:31:00<5:04:25,  4.11s/it]                                                       {'loss': 0.0306, 'grad_norm': 1.0234134197235107, 'learning_rate': 3.770338983050848e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:31:00<5:04:25,  4.11s/it] 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:31:04<4:48:20,  3.89s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.42908504605293274, 'learning_rate': 3.769491525423729e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:31:04<4:48:20,  3.89s/it] 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:31:07<4:34:41,  3.71s/it]                                                       {'loss': 0.073, 'grad_norm': 4.606621265411377, 'learning_rate': 3.768644067796611e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:31:07<4:34:41,  3.71s/it] 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:31:10<4:27:13,  3.61s/it]                                                       {'loss': 0.035, 'grad_norm': 3.153641700744629, 'learning_rate': 3.767796610169492e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:31:10<4:27:13,  3.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:31:13<4:20:30,  3.52s/it]                                                       {'loss': 0.0162, 'grad_norm': 1.273669719696045, 'learning_rate': 3.766949152542373e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:31:13<4:20:30,  3.52s/it] 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:17<4:16:24,  3.46s/it]                                                       {'loss': 0.012, 'grad_norm': 1.7871294021606445, 'learning_rate': 3.766101694915254e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:17<4:16:24,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:20<4:14:08,  3.43s/it]                                                       {'loss': 0.1063, 'grad_norm': 5.343366622924805, 'learning_rate': 3.765254237288135e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:20<4:14:08,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:24<4:13:20,  3.42s/it]                                                       {'loss': 0.03, 'grad_norm': 1.7397984266281128, 'learning_rate': 3.764406779661017e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:24<4:13:20,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:27<4:23:33,  3.56s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.12541672587394714, 'learning_rate': 3.763559322033898e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:27<4:23:33,  3.56s/it] 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:31:31<4:19:01,  3.50s/it]                                                       {'loss': 0.0522, 'grad_norm': 2.555039167404175, 'learning_rate': 3.76271186440678e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:31:31<4:19:01,  3.50s/it] 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:31:34<4:18:11,  3.49s/it]                                                       {'loss': 0.0861, 'grad_norm': 3.255598306655884, 'learning_rate': 3.761864406779661e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:31:34<4:18:11,  3.49s/it] 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:31:38<4:16:50,  3.47s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.45125114917755127, 'learning_rate': 3.761016949152543e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:31:38<4:16:50,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:31:41<4:14:08,  3.44s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.2175612449645996, 'learning_rate': 3.7601694915254234e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:31:41<4:14:08,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:31:45<4:14:58,  3.45s/it]                                                       {'loss': 0.0353, 'grad_norm': 2.6978683471679688, 'learning_rate': 3.759322033898305e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:31:45<4:14:58,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:31:48<4:12:12,  3.41s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03754432871937752, 'learning_rate': 3.7584745762711864e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:31:48<4:12:12,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:31:51<4:14:42,  3.45s/it]                                                       {'loss': 0.0509, 'grad_norm': 5.3206281661987305, 'learning_rate': 3.757627118644068e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:31:51<4:14:42,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:31:55<4:12:19,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04973912984132767, 'learning_rate': 3.756779661016949e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:31:55<4:12:19,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:31:58<4:10:45,  3.39s/it]                                                       {'loss': 0.083, 'grad_norm': 5.7160258293151855, 'learning_rate': 3.755932203389831e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:31:58<4:10:45,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:32:01<4:09:56,  3.38s/it]                                                       {'loss': 0.065, 'grad_norm': 6.378525733947754, 'learning_rate': 3.755084745762712e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:32:01<4:09:56,  3.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:32:05<4:12:50,  3.42s/it]                                                       {'loss': 0.0952, 'grad_norm': 4.707174301147461, 'learning_rate': 3.7542372881355934e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:32:05<4:12:50,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:32:08<4:13:32,  3.43s/it]                                                       {'loss': 0.0359, 'grad_norm': 1.4934406280517578, 'learning_rate': 3.7533898305084745e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:32:08<4:13:32,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:32:12<4:13:01,  3.43s/it]                                                       {'loss': 0.0573, 'grad_norm': 5.347127914428711, 'learning_rate': 3.752542372881356e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:32:12<4:13:01,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:15<4:13:27,  3.44s/it]                                                       {'loss': 0.0567, 'grad_norm': 3.3858821392059326, 'learning_rate': 3.7516949152542374e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:15<4:13:27,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:19<4:16:15,  3.47s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.3305823802948, 'learning_rate': 3.750847457627119e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:19<4:16:15,  3.47s/it] 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:22<4:14:13,  3.45s/it]                                                       {'loss': 0.0272, 'grad_norm': 2.899123430252075, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:22<4:14:13,  3.45s/it] 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:26<4:13:48,  3.44s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.6687314510345459, 'learning_rate': 3.7491525423728815e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:26<4:13:48,  3.44s/it] 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:32:29<4:12:53,  3.43s/it]                                                       {'loss': 0.1916, 'grad_norm': 7.4154438972473145, 'learning_rate': 3.7483050847457626e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:32:29<4:12:53,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:32:32<4:12:00,  3.42s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.2517290711402893, 'learning_rate': 3.747457627118644e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:32:32<4:12:00,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:32:36<4:11:22,  3.41s/it]                                                       {'loss': 0.0936, 'grad_norm': 6.393883228302002, 'learning_rate': 3.7466101694915255e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:32:36<4:11:22,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:32:39<4:09:31,  3.39s/it]                                                       {'loss': 0.2066, 'grad_norm': 7.713411331176758, 'learning_rate': 3.745762711864407e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:32:39<4:09:31,  3.39s/it] 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:32:43<4:19:38,  3.53s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.43690064549446106, 'learning_rate': 3.7449152542372885e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:32:43<4:19:38,  3.53s/it] 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:32:46<4:17:24,  3.50s/it]                                                       {'loss': 0.0737, 'grad_norm': 5.699146270751953, 'learning_rate': 3.7440677966101696e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:32:46<4:17:24,  3.50s/it] 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:32:50<4:13:40,  3.45s/it]                                                       {'loss': 0.0309, 'grad_norm': 4.272571086883545, 'learning_rate': 3.7432203389830514e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:32:50<4:13:40,  3.45s/it] 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:32:53<4:11:37,  3.42s/it]                                                       {'loss': 0.0249, 'grad_norm': 4.989236354827881, 'learning_rate': 3.7423728813559325e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:32:53<4:11:37,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:32:57<4:11:16,  3.41s/it]                                                       {'loss': 0.0866, 'grad_norm': 8.192523956298828, 'learning_rate': 3.741525423728814e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:32:57<4:11:16,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:33:00<4:11:05,  3.41s/it]                                                       {'loss': 0.0288, 'grad_norm': 2.5739200115203857, 'learning_rate': 3.740677966101695e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:33:00<4:11:05,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:33:03<4:12:16,  3.43s/it]                                                       {'loss': 0.0152, 'grad_norm': 1.9268910884857178, 'learning_rate': 3.7398305084745766e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:33:03<4:12:16,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:33:07<4:10:32,  3.41s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.44987693428993225, 'learning_rate': 3.738983050847458e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:33:07<4:10:32,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:33:11<4:19:03,  3.52s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016244884580373764, 'learning_rate': 3.7381355932203395e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:33:11<4:19:03,  3.52s/it] 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:33:14<4:14:02,  3.46s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7706429362297058, 'learning_rate': 3.737288135593221e-05, 'epoch': 0.27}
 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:33:14<4:14:02,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:17<4:11:30,  3.42s/it]                                                       {'loss': 0.0633, 'grad_norm': 5.9272003173828125, 'learning_rate': 3.736440677966102e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:17<4:11:30,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:21<4:11:19,  3.42s/it]                                                       {'loss': 0.0496, 'grad_norm': 3.4015541076660156, 'learning_rate': 3.735593220338983e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:21<4:11:19,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:24<4:09:36,  3.40s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06570431590080261, 'learning_rate': 3.734745762711865e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:24<4:09:36,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:33:28<4:12:20,  3.44s/it]                                                       {'loss': 0.0852, 'grad_norm': 6.556152820587158, 'learning_rate': 3.733898305084746e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:33:28<4:12:20,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:33:31<4:11:36,  3.43s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.3237151801586151, 'learning_rate': 3.733050847457628e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:33:31<4:11:36,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:33:34<4:10:58,  3.42s/it]                                                       {'loss': 0.1196, 'grad_norm': 4.624250411987305, 'learning_rate': 3.732203389830509e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:33:34<4:10:58,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:33:38<4:10:54,  3.42s/it]                                                       {'loss': 0.0414, 'grad_norm': 3.3672025203704834, 'learning_rate': 3.73135593220339e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:33:38<4:10:54,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:33:41<4:09:51,  3.41s/it]                                                       {'loss': 0.2761, 'grad_norm': 10.944643020629883, 'learning_rate': 3.730508474576272e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:33:41<4:09:51,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:33:45<4:10:26,  3.41s/it]                                                       {'loss': 0.1092, 'grad_norm': 6.3833208084106445, 'learning_rate': 3.729661016949152e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:33:45<4:10:26,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:33:48<4:14:36,  3.47s/it]                                                       {'loss': 0.0495, 'grad_norm': 4.007023811340332, 'learning_rate': 3.728813559322034e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:33:48<4:14:36,  3.47s/it][2025-10-20 01:10:53,479] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:33:54<5:00:08,  4.09s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6666585206985474, 'learning_rate': 3.727966101694915e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:33:54<5:00:08,  4.09s/it] 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:33:58<4:55:38,  4.03s/it]                                                       {'loss': 0.0546, 'grad_norm': 4.027791500091553, 'learning_rate': 3.727118644067797e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:33:58<4:55:38,  4.03s/it] 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:34:01<4:48:28,  3.94s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.6608960628509521, 'learning_rate': 3.726271186440678e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:34:01<4:48:28,  3.94s/it] 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:34:06<4:54:30,  4.02s/it]                                                       {'loss': 0.0151, 'grad_norm': 2.299785852432251, 'learning_rate': 3.72542372881356e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:34:06<4:54:30,  4.02s/it] 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:34:09<4:51:23,  3.98s/it]                                                       {'loss': 0.0222, 'grad_norm': 1.84917151927948, 'learning_rate': 3.724576271186441e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:34:09<4:51:23,  3.98s/it] 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:34:13<4:35:57,  3.77s/it]                                                       {'loss': 0.0314, 'grad_norm': 3.4175221920013428, 'learning_rate': 3.723728813559322e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:34:13<4:35:57,  3.77s/it] 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:16<4:27:20,  3.65s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.6805236339569092, 'learning_rate': 3.722881355932203e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:16<4:27:20,  3.65s/it] 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:20<4:30:19,  3.69s/it]                                                       {'loss': 0.0381, 'grad_norm': 4.418259143829346, 'learning_rate': 3.722033898305085e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:20<4:30:19,  3.69s/it] 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:23<4:22:40,  3.59s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.8951506614685059, 'learning_rate': 3.721186440677966e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:23<4:22:40,  3.59s/it] 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:27<4:18:13,  3.53s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.6955652236938477, 'learning_rate': 3.720338983050848e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:27<4:18:13,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:34:30<4:15:27,  3.49s/it]                                                       {'loss': 0.0561, 'grad_norm': 3.782102584838867, 'learning_rate': 3.719491525423729e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:34:30<4:15:27,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:34:33<4:11:01,  3.43s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03568302094936371, 'learning_rate': 3.71864406779661e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:34:33<4:11:01,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:34:37<4:08:11,  3.39s/it]                                                       {'loss': 0.0786, 'grad_norm': 7.853299140930176, 'learning_rate': 3.7177966101694914e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:34:37<4:08:11,  3.39s/it] 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:34:40<4:09:04,  3.41s/it]                                                       {'loss': 0.094, 'grad_norm': 4.780033588409424, 'learning_rate': 3.716949152542373e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:34:40<4:09:04,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:34:43<4:08:07,  3.40s/it]                                                       {'loss': 0.0582, 'grad_norm': 5.661144733428955, 'learning_rate': 3.716101694915254e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:34:43<4:08:07,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:34:47<4:10:27,  3.43s/it]                                                       {'loss': 0.0171, 'grad_norm': 1.2119832038879395, 'learning_rate': 3.715254237288136e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:34:47<4:10:27,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:34:50<4:08:15,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12378938496112823, 'learning_rate': 3.714406779661017e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:34:50<4:08:15,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:34:54<4:17:20,  3.52s/it]                                                       {'loss': 0.0591, 'grad_norm': 5.4007344245910645, 'learning_rate': 3.7135593220338984e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:34:54<4:17:20,  3.52s/it] 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:34:58<4:16:22,  3.51s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.6884905099868774, 'learning_rate': 3.71271186440678e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:34:58<4:16:22,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:35:01<4:16:37,  3.52s/it]                                                       {'loss': 0.0191, 'grad_norm': 1.8024276494979858, 'learning_rate': 3.711864406779661e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:35:01<4:16:37,  3.52s/it] 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:35:05<4:24:19,  3.62s/it]                                                       {'loss': 0.013, 'grad_norm': 1.3913506269454956, 'learning_rate': 3.7110169491525424e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:35:05<4:24:19,  3.62s/it] 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:35:08<4:18:37,  3.54s/it]                                                       {'loss': 0.0553, 'grad_norm': 5.009605407714844, 'learning_rate': 3.7101694915254236e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:35:08<4:18:37,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:35:12<4:16:07,  3.51s/it]                                                       {'loss': 0.0682, 'grad_norm': 7.037055015563965, 'learning_rate': 3.7093220338983054e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:35:12<4:16:07,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:15<4:14:52,  3.49s/it]                                                       {'loss': 0.1576, 'grad_norm': 7.129681587219238, 'learning_rate': 3.7084745762711865e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:15<4:14:52,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:19<4:14:39,  3.49s/it]                                                       {'loss': 0.089, 'grad_norm': 6.466314792633057, 'learning_rate': 3.707627118644068e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:19<4:14:39,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:22<4:12:30,  3.46s/it]                                                       {'loss': 0.017, 'grad_norm': 1.2334847450256348, 'learning_rate': 3.7067796610169494e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:22<4:12:30,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:25<4:10:34,  3.44s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.8700876235961914, 'learning_rate': 3.7059322033898306e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:25<4:10:34,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:35:29<4:12:23,  3.46s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.3702342510223389, 'learning_rate': 3.705084745762712e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:35:29<4:12:23,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:35:33<4:15:55,  3.51s/it]                                                       {'loss': 0.0747, 'grad_norm': 6.750594139099121, 'learning_rate': 3.7042372881355935e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:35:33<4:15:55,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:35:36<4:15:17,  3.51s/it]                                                       {'loss': 0.197, 'grad_norm': 7.443692684173584, 'learning_rate': 3.7033898305084746e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:35:36<4:15:17,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:35:40<4:16:43,  3.53s/it]                                                       {'loss': 0.1631, 'grad_norm': 8.109042167663574, 'learning_rate': 3.7025423728813564e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:35:40<4:16:43,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:35:43<4:12:26,  3.47s/it]                                                       {'loss': 0.0735, 'grad_norm': 4.427633762359619, 'learning_rate': 3.7016949152542376e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:35:43<4:12:26,  3.47s/it] 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:35:46<4:10:15,  3.44s/it]                                                       {'loss': 0.1206, 'grad_norm': 4.088632106781006, 'learning_rate': 3.7008474576271194e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:35:46<4:10:15,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:35:50<4:08:57,  3.42s/it]                                                       {'loss': 0.1519, 'grad_norm': 7.525280952453613, 'learning_rate': 3.7e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:35:50<4:08:57,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:35:54<4:18:30,  3.55s/it]                                                       {'loss': 0.0276, 'grad_norm': 3.3979740142822266, 'learning_rate': 3.6991525423728816e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:35:54<4:18:30,  3.55s/it] 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:35:57<4:21:28,  3.59s/it]                                                       {'loss': 0.0844, 'grad_norm': 8.959120750427246, 'learning_rate': 3.698305084745763e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:35:57<4:21:28,  3.59s/it] 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:36:01<4:16:44,  3.53s/it]                                                       {'loss': 0.0414, 'grad_norm': 4.56566047668457, 'learning_rate': 3.6974576271186446e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:36:01<4:16:44,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:36:04<4:13:45,  3.49s/it]                                                       {'loss': 0.043, 'grad_norm': 5.701330184936523, 'learning_rate': 3.696610169491526e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:36:04<4:13:45,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:36:08<4:12:51,  3.48s/it]                                                       {'loss': 0.005, 'grad_norm': 0.7072540521621704, 'learning_rate': 3.695762711864407e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:36:08<4:12:51,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:36:11<4:12:07,  3.47s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.9796690940856934, 'learning_rate': 3.6949152542372886e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:36:11<4:12:07,  3.47s/it] 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:15<4:15:45,  3.52s/it]                                                       {'loss': 0.1556, 'grad_norm': 5.930549621582031, 'learning_rate': 3.69406779661017e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:15<4:15:45,  3.52s/it] 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:18<4:13:06,  3.48s/it]                                                       {'loss': 0.1105, 'grad_norm': 8.453145980834961, 'learning_rate': 3.693220338983051e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:18<4:13:06,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:21<4:10:29,  3.45s/it]                                                       {'loss': 0.2824, 'grad_norm': 10.602166175842285, 'learning_rate': 3.692372881355932e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:21<4:10:29,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:25<4:07:41,  3.41s/it]                                                       {'loss': 0.0423, 'grad_norm': 3.8342502117156982, 'learning_rate': 3.691525423728814e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:25<4:07:41,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:36:28<4:07:27,  3.41s/it]                                                       {'loss': 0.0266, 'grad_norm': 3.8939054012298584, 'learning_rate': 3.690677966101695e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:36:28<4:07:27,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:36:31<4:04:48,  3.37s/it]                                                       {'loss': 0.3012, 'grad_norm': 9.882940292358398, 'learning_rate': 3.689830508474577e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:36:31<4:04:48,  3.37s/it] 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:36:35<4:04:58,  3.38s/it]                                                       {'loss': 0.0166, 'grad_norm': 2.5318210124969482, 'learning_rate': 3.688983050847458e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:36:35<4:04:58,  3.38s/it] 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:36:38<4:03:37,  3.36s/it]                                                       {'loss': 0.4388, 'grad_norm': 9.785906791687012, 'learning_rate': 3.688135593220339e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:36:38<4:03:37,  3.36s/it] 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:36:41<4:04:06,  3.37s/it]                                                       {'loss': 0.1551, 'grad_norm': 4.192760467529297, 'learning_rate': 3.68728813559322e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:36:41<4:04:06,  3.37s/it] 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:36:45<4:03:50,  3.36s/it]                                                       {'loss': 0.1751, 'grad_norm': 9.331454277038574, 'learning_rate': 3.686440677966102e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:36:45<4:03:50,  3.36s/it][2025-10-20 01:13:50,150] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:36:50<4:49:08,  3.99s/it]                                                       {'loss': 0.018, 'grad_norm': 3.5510528087615967, 'learning_rate': 3.685593220338983e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:36:50<4:49:08,  3.99s/it] 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:36:54<4:51:03,  4.02s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06800858676433563, 'learning_rate': 3.684745762711865e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:36:54<4:51:03,  4.02s/it] 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:36:58<4:39:47,  3.86s/it]                                                       {'loss': 0.169, 'grad_norm': 7.276820182800293, 'learning_rate': 3.683898305084746e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:36:58<4:39:47,  3.86s/it] 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:37:01<4:31:03,  3.74s/it]                                                       {'loss': 0.0383, 'grad_norm': 4.827688217163086, 'learning_rate': 3.683050847457628e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:37:01<4:31:03,  3.74s/it] 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:37:05<4:31:02,  3.74s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.1241703033447266, 'learning_rate': 3.682203389830509e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:37:05<4:31:02,  3.74s/it] 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:37:09<4:26:58,  3.69s/it]                                                       {'loss': 0.081, 'grad_norm': 5.774267673492432, 'learning_rate': 3.68135593220339e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:37:09<4:26:58,  3.69s/it] 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:37:12<4:24:25,  3.65s/it]                                                       {'loss': 0.021, 'grad_norm': 3.2560129165649414, 'learning_rate': 3.680508474576271e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:37:12<4:24:25,  3.65s/it] 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:16<4:17:46,  3.56s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.086552619934082, 'learning_rate': 3.679661016949153e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:16<4:17:46,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:20<4:41:04,  3.88s/it]                                                       {'loss': 0.1448, 'grad_norm': 9.12624740600586, 'learning_rate': 3.678813559322034e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:20<4:41:04,  3.88s/it] 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:24<4:38:19,  3.85s/it]                                                       {'loss': 0.0537, 'grad_norm': 5.743475914001465, 'learning_rate': 3.677966101694915e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:24<4:38:19,  3.85s/it] 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:37:27<4:31:22,  3.75s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6328093409538269, 'learning_rate': 3.677118644067797e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:37:27<4:31:22,  3.75s/it] 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:37:31<4:25:31,  3.67s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.519683837890625, 'learning_rate': 3.676271186440678e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:37:31<4:25:31,  3.67s/it] 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:37:34<4:17:57,  3.57s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4496379494667053, 'learning_rate': 3.675423728813559e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:37:34<4:17:57,  3.57s/it] 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:37:38<4:15:24,  3.53s/it]                                                       {'loss': 0.0748, 'grad_norm': 5.8826165199279785, 'learning_rate': 3.6745762711864404e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:37:38<4:15:24,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:37:41<4:13:01,  3.50s/it]                                                       {'loss': 0.0433, 'grad_norm': 3.6524765491485596, 'learning_rate': 3.673728813559322e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:37:41<4:13:01,  3.50s/it] 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:37:45<4:16:43,  3.55s/it]                                                       {'loss': 0.0532, 'grad_norm': 4.809689521789551, 'learning_rate': 3.6728813559322034e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:37:45<4:16:43,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:37:49<4:21:16,  3.62s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5073879361152649, 'learning_rate': 3.672033898305085e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:37:49<4:21:16,  3.62s/it] 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:37:52<4:14:57,  3.53s/it]                                                       {'loss': 0.0245, 'grad_norm': 4.313027381896973, 'learning_rate': 3.671186440677966e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:37:52<4:14:57,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:37:55<4:11:05,  3.48s/it]                                                       {'loss': 0.0115, 'grad_norm': 2.097123146057129, 'learning_rate': 3.6703389830508474e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:37:55<4:11:05,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:37:59<4:07:57,  3.44s/it]                                                       {'loss': 0.1555, 'grad_norm': 8.52988338470459, 'learning_rate': 3.6694915254237286e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:37:59<4:07:57,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:38:02<4:06:39,  3.42s/it]                                                       {'loss': 0.0794, 'grad_norm': 4.247147083282471, 'learning_rate': 3.6686440677966104e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:38:02<4:06:39,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:38:06<4:09:18,  3.46s/it]                                                       {'loss': 0.0413, 'grad_norm': 4.412864685058594, 'learning_rate': 3.6677966101694915e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:38:06<4:09:18,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:38:09<4:07:18,  3.43s/it]                                                       {'loss': 0.012, 'grad_norm': 1.6465586423873901, 'learning_rate': 3.666949152542373e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:38:09<4:07:18,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:38:12<4:06:13,  3.42s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.15731878578662872, 'learning_rate': 3.6661016949152544e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:38:12<4:06:13,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:16<4:05:55,  3.41s/it]                                                       {'loss': 0.0938, 'grad_norm': 5.79915714263916, 'learning_rate': 3.665254237288136e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:16<4:05:55,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:19<4:04:13,  3.39s/it]                                                       {'loss': 0.0139, 'grad_norm': 2.4627904891967773, 'learning_rate': 3.6644067796610174e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:19<4:04:13,  3.39s/it] 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:23<4:06:15,  3.42s/it]                                                       {'loss': 0.0262, 'grad_norm': 4.055212497711182, 'learning_rate': 3.6635593220338985e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:23<4:06:15,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:26<4:04:42,  3.40s/it]                                                       {'loss': 0.0605, 'grad_norm': 7.264796257019043, 'learning_rate': 3.6627118644067796e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:26<4:04:42,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:38:30<4:23:10,  3.65s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.33109763264656067, 'learning_rate': 3.661864406779661e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:38:30<4:23:10,  3.65s/it] 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:38:34<4:18:47,  3.59s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.3560233116149902, 'learning_rate': 3.6610169491525426e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:38:34<4:18:47,  3.59s/it] 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:38:37<4:13:53,  3.53s/it]                                                       {'loss': 0.0932, 'grad_norm': 7.001187801361084, 'learning_rate': 3.660169491525424e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:38:37<4:13:53,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:38:40<4:13:03,  3.52s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6012508869171143, 'learning_rate': 3.6593220338983055e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:38:40<4:13:03,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:38:44<4:10:38,  3.48s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.43344759941101074, 'learning_rate': 3.6584745762711866e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:38:44<4:10:38,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:38:47<4:11:37,  3.50s/it]                                                       {'loss': 0.0193, 'grad_norm': 2.593717098236084, 'learning_rate': 3.657627118644068e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:38:47<4:11:37,  3.50s/it] 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:38:51<4:09:42,  3.47s/it]                                                       {'loss': 0.0904, 'grad_norm': 7.286374568939209, 'learning_rate': 3.656779661016949e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:38:51<4:09:42,  3.47s/it] 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:38:54<4:08:29,  3.46s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.23373764753341675, 'learning_rate': 3.655932203389831e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:38:54<4:08:29,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:38:58<4:25:18,  3.69s/it]                                                       {'loss': 0.0311, 'grad_norm': 3.8080248832702637, 'learning_rate': 3.655084745762712e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:38:58<4:25:18,  3.69s/it] 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:39:02<4:19:51,  3.62s/it]                                                       {'loss': 0.2251, 'grad_norm': 8.966708183288574, 'learning_rate': 3.6542372881355936e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:39:02<4:19:51,  3.62s/it] 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:39:05<4:14:50,  3.55s/it]                                                       {'loss': 0.1513, 'grad_norm': 7.3829851150512695, 'learning_rate': 3.653389830508475e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:39:05<4:14:50,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:39:09<4:13:33,  3.53s/it]                                                       {'loss': 0.1877, 'grad_norm': 9.727567672729492, 'learning_rate': 3.6525423728813566e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:39:09<4:13:33,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:39:12<4:12:58,  3.52s/it]                                                       {'loss': 0.0244, 'grad_norm': 2.922886848449707, 'learning_rate': 3.651694915254237e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:39:12<4:12:58,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:16<4:13:30,  3.53s/it]                                                       {'loss': 0.0249, 'grad_norm': 2.4498302936553955, 'learning_rate': 3.650847457627119e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:16<4:13:30,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:20<4:17:48,  3.59s/it]                                                       {'loss': 0.1418, 'grad_norm': 7.488929748535156, 'learning_rate': 3.65e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:20<4:17:48,  3.59s/it] 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:23<4:13:07,  3.53s/it]                                                       {'loss': 0.0553, 'grad_norm': 4.234893321990967, 'learning_rate': 3.649152542372882e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:23<4:13:07,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:26<4:13:42,  3.54s/it]                                                       {'loss': 0.005, 'grad_norm': 0.7497206926345825, 'learning_rate': 3.648305084745763e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:26<4:13:42,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:39:30<4:08:17,  3.46s/it]                                                       {'loss': 0.1613, 'grad_norm': 5.45150899887085, 'learning_rate': 3.647457627118645e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:39:30<4:08:17,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:39:33<4:07:23,  3.45s/it]                                                       {'loss': 0.0642, 'grad_norm': 4.792564392089844, 'learning_rate': 3.646610169491526e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:39:33<4:07:23,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:39:37<4:07:55,  3.46s/it]                                                       {'loss': 0.1028, 'grad_norm': 5.841614246368408, 'learning_rate': 3.645762711864407e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:39:37<4:07:55,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:39:40<4:05:37,  3.43s/it]                                                       {'loss': 0.068, 'grad_norm': 5.571153163909912, 'learning_rate': 3.644915254237288e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:39:40<4:05:37,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:39:43<4:04:10,  3.41s/it]                                                       {'loss': 0.0841, 'grad_norm': 6.600000858306885, 'learning_rate': 3.644067796610169e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:39:43<4:04:10,  3.41s/it][2025-10-20 01:16:48,718] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:39:49<4:51:14,  4.06s/it]                                                       {'loss': 0.2322, 'grad_norm': 7.946399211883545, 'learning_rate': 3.643220338983051e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:39:49<4:51:14,  4.06s/it] 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:39:52<4:37:01,  3.87s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.6820966601371765, 'learning_rate': 3.642372881355932e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:39:52<4:37:01,  3.87s/it] 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:39:56<4:25:57,  3.71s/it]                                                       {'loss': 0.218, 'grad_norm': 7.310740947723389, 'learning_rate': 3.641525423728814e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:39:56<4:25:57,  3.71s/it] 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:39:59<4:19:45,  3.63s/it]                                                       {'loss': 0.4531, 'grad_norm': 8.557157516479492, 'learning_rate': 3.640677966101695e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:39:59<4:19:45,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:40:03<4:18:26,  3.61s/it]                                                       {'loss': 0.0399, 'grad_norm': 4.050815582275391, 'learning_rate': 3.639830508474576e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:40:03<4:18:26,  3.61s/it] 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:40:06<4:17:37,  3.60s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.2760010957717896, 'learning_rate': 3.638983050847457e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:40:06<4:17:37,  3.60s/it] 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:40:10<4:12:41,  3.53s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.006746530532837, 'learning_rate': 3.638135593220339e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:40:10<4:12:41,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:40:13<4:11:17,  3.51s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1593204289674759, 'learning_rate': 3.63728813559322e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:40:13<4:11:17,  3.51s/it] 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:17<4:08:33,  3.48s/it]                                                       {'loss': 0.0287, 'grad_norm': 2.9534912109375, 'learning_rate': 3.636440677966102e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:17<4:08:33,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:20<4:07:16,  3.46s/it]                                                       {'loss': 0.0269, 'grad_norm': 4.7532525062561035, 'learning_rate': 3.635593220338983e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:20<4:07:16,  3.46s/it] 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:23<4:08:26,  3.48s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.1131207942962646, 'learning_rate': 3.634745762711865e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:24<4:08:26,  3.48s/it] 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:27<4:06:11,  3.44s/it]                                                       {'loss': 0.0262, 'grad_norm': 2.5257914066314697, 'learning_rate': 3.633898305084746e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:27<4:06:11,  3.44s/it] 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:40:30<4:03:13,  3.40s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.16926263272762299, 'learning_rate': 3.633050847457627e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:40:30<4:03:13,  3.40s/it] 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:40:34<4:11:25,  3.52s/it]                                                       {'loss': 0.07, 'grad_norm': 5.736086845397949, 'learning_rate': 3.6322033898305084e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:40:34<4:11:25,  3.52s/it] 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:40:37<4:09:17,  3.49s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.133129596710205, 'learning_rate': 3.63135593220339e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:40:37<4:09:17,  3.49s/it] 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:40:41<4:08:04,  3.47s/it]                                                       {'loss': 0.1438, 'grad_norm': 6.340651035308838, 'learning_rate': 3.630508474576271e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:40:41<4:08:04,  3.47s/it] 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:40:44<4:04:52,  3.43s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.6602882146835327, 'learning_rate': 3.629661016949153e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:40:44<4:04:52,  3.43s/it] 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:40:47<4:02:15,  3.39s/it]                                                       {'loss': 0.0687, 'grad_norm': 5.120626449584961, 'learning_rate': 3.628813559322034e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:40:47<4:02:15,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:40:51<4:01:13,  3.38s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.246652603149414, 'learning_rate': 3.6279661016949154e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:40:51<4:01:13,  3.38s/it] 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:40:54<3:59:15,  3.35s/it]                                                       {'loss': 0.0595, 'grad_norm': 5.061239719390869, 'learning_rate': 3.6271186440677965e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:40:54<3:59:15,  3.35s/it] 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:40:58<4:01:06,  3.38s/it]                                                       {'loss': 0.0173, 'grad_norm': 2.2331154346466064, 'learning_rate': 3.6262711864406777e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:40:58<4:01:06,  3.38s/it] 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:41:01<4:02:25,  3.40s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2713819146156311, 'learning_rate': 3.6254237288135595e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:41:01<4:02:25,  3.40s/it] 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:41:04<4:02:40,  3.40s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.599419593811035, 'learning_rate': 3.6245762711864406e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:41:04<4:02:40,  3.40s/it] 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:41:08<4:05:13,  3.44s/it]                                                       {'loss': 0.0686, 'grad_norm': 3.60750675201416, 'learning_rate': 3.6237288135593224e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:41:08<4:05:13,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:41:11<4:03:42,  3.42s/it]                                                       {'loss': 0.1159, 'grad_norm': 5.2660136222839355, 'learning_rate': 3.6228813559322035e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:41:11<4:03:42,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:15<4:03:01,  3.41s/it]                                                       {'loss': 0.0385, 'grad_norm': 5.795278549194336, 'learning_rate': 3.622033898305085e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:15<4:03:01,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:18<4:02:15,  3.40s/it]                                                       {'loss': 0.0325, 'grad_norm': 3.7486610412597656, 'learning_rate': 3.621186440677966e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:18<4:02:15,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:21<4:01:29,  3.39s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.38596993684768677, 'learning_rate': 3.6203389830508476e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:21<4:01:29,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:25<4:03:11,  3.42s/it]                                                       {'loss': 0.0633, 'grad_norm': 4.45054817199707, 'learning_rate': 3.619491525423729e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:25<4:03:11,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:41:28<4:03:39,  3.42s/it]                                                       {'loss': 0.0224, 'grad_norm': 3.3178741931915283, 'learning_rate': 3.6186440677966105e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:41:28<4:03:39,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:41:32<4:01:45,  3.40s/it]                                                       {'loss': 0.0096, 'grad_norm': 0.9660753607749939, 'learning_rate': 3.6177966101694916e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:41:32<4:01:45,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:41:35<4:02:20,  3.41s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.053912535309791565, 'learning_rate': 3.6169491525423735e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:41:35<4:02:20,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:41:39<4:09:42,  3.51s/it]                                                       {'loss': 0.006, 'grad_norm': 0.7434685230255127, 'learning_rate': 3.6161016949152546e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:41:39<4:09:42,  3.51s/it] 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:41:42<4:07:36,  3.48s/it]                                                       {'loss': 0.1274, 'grad_norm': 8.889142990112305, 'learning_rate': 3.615254237288136e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:41:42<4:07:36,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:41:46<4:07:05,  3.48s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.28079214692115784, 'learning_rate': 3.614406779661017e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:41:46<4:07:05,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:41:49<4:06:30,  3.47s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.7432042360305786, 'learning_rate': 3.6135593220338986e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:41:49<4:06:30,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:41:53<4:07:03,  3.48s/it]                                                       {'loss': 0.0208, 'grad_norm': 3.0164260864257812, 'learning_rate': 3.61271186440678e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:41:53<4:07:03,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:41:56<4:06:59,  3.48s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2521386444568634, 'learning_rate': 3.6118644067796616e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:41:56<4:06:59,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:42:00<4:14:10,  3.58s/it]                                                       {'loss': 0.1417, 'grad_norm': 10.521263122558594, 'learning_rate': 3.611016949152543e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:42:00<4:14:10,  3.58s/it] 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:42:04<4:19:34,  3.66s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.479169487953186, 'learning_rate': 3.610169491525424e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:42:04<4:19:34,  3.66s/it] 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:42:07<4:13:41,  3.57s/it]                                                       {'loss': 0.0281, 'grad_norm': 4.091089248657227, 'learning_rate': 3.609322033898305e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:42:07<4:13:41,  3.57s/it] 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:42:11<4:09:14,  3.51s/it]                                                       {'loss': 0.1316, 'grad_norm': 5.84935998916626, 'learning_rate': 3.608474576271186e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:42:11<4:09:14,  3.51s/it] 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:14<4:07:32,  3.49s/it]                                                       {'loss': 0.2408, 'grad_norm': 10.221094131469727, 'learning_rate': 3.607627118644068e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:14<4:07:32,  3.49s/it] 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:17<4:06:04,  3.47s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1503416746854782, 'learning_rate': 3.606779661016949e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:17<4:06:04,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:21<4:03:59,  3.44s/it]                                                       {'loss': 0.0339, 'grad_norm': 2.535691499710083, 'learning_rate': 3.605932203389831e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:21<4:03:59,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:24<4:01:04,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.017093831673264503, 'learning_rate': 3.605084745762712e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:24<4:01:04,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:42:27<4:00:07,  3.39s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5846436023712158, 'learning_rate': 3.604237288135594e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:42:27<4:00:07,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:42:31<4:00:02,  3.39s/it]                                                       {'loss': 0.0873, 'grad_norm': 7.271985054016113, 'learning_rate': 3.603389830508475e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:42:31<4:00:02,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:42:34<4:01:41,  3.41s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3002195954322815, 'learning_rate': 3.602542372881356e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:42:34<4:01:41,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:42:38<4:11:18,  3.55s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.1943211555480957, 'learning_rate': 3.601694915254237e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:42:38<4:11:18,  3.55s/it][2025-10-20 01:19:43,528] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:42:44<4:59:39,  4.23s/it]                                                       {'loss': 0.0231, 'grad_norm': 3.222264528274536, 'learning_rate': 3.600847457627119e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:42:44<4:59:39,  4.23s/it] 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:42:47<4:41:48,  3.98s/it]                                                       {'loss': 0.147, 'grad_norm': 9.508651733398438, 'learning_rate': 3.6e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:42:47<4:41:48,  3.98s/it] 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:42:51<4:29:10,  3.80s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05845298245549202, 'learning_rate': 3.599152542372882e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:42:51<4:29:10,  3.80s/it] 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:42:54<4:20:24,  3.68s/it]                                                       {'loss': 0.0445, 'grad_norm': 4.891198635101318, 'learning_rate': 3.598305084745763e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:42:54<4:20:24,  3.68s/it] 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:42:58<4:21:14,  3.69s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.23935014009475708, 'learning_rate': 3.597457627118644e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:42:58<4:21:14,  3.69s/it] 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:43:01<4:16:31,  3.63s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.9583102464675903, 'learning_rate': 3.596610169491525e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:43:01<4:16:31,  3.63s/it] 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:43:05<4:10:34,  3.54s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.006431860849261284, 'learning_rate': 3.595762711864407e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:43:05<4:10:34,  3.54s/it] 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:43:08<4:07:15,  3.50s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.10289330035448074, 'learning_rate': 3.594915254237288e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:43:08<4:07:15,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:43:12<4:05:42,  3.48s/it]                                                       {'loss': 0.1611, 'grad_norm': 7.9621782302856445, 'learning_rate': 3.59406779661017e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:43:12<4:05:42,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:43:15<4:04:37,  3.46s/it]                                                       {'loss': 0.1409, 'grad_norm': 8.685917854309082, 'learning_rate': 3.593220338983051e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:43:15<4:04:37,  3.46s/it] 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:19<4:07:01,  3.50s/it]                                                       {'loss': 0.0231, 'grad_norm': 1.6052623987197876, 'learning_rate': 3.592372881355933e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:19<4:07:01,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:22<4:14:32,  3.60s/it]                                                       {'loss': 0.007, 'grad_norm': 0.958819568157196, 'learning_rate': 3.5915254237288134e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:22<4:14:32,  3.60s/it] 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:26<4:10:05,  3.54s/it]                                                       {'loss': 0.1388, 'grad_norm': 5.6067962646484375, 'learning_rate': 3.5906779661016945e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:26<4:10:05,  3.54s/it] 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:43:30<4:26:59,  3.78s/it]                                                       {'loss': 0.1061, 'grad_norm': 7.128872394561768, 'learning_rate': 3.5898305084745763e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:43:30<4:26:59,  3.78s/it] 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:43:35<4:42:07,  4.00s/it]                                                       {'loss': 0.0891, 'grad_norm': 7.499064922332764, 'learning_rate': 3.5889830508474575e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:43:35<4:42:07,  4.00s/it] 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:43:38<4:30:01,  3.83s/it]                                                       {'loss': 0.0281, 'grad_norm': 1.2163152694702148, 'learning_rate': 3.588135593220339e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:43:38<4:30:01,  3.83s/it] 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:43:42<4:24:12,  3.75s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.020891327410936356, 'learning_rate': 3.5872881355932204e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:43:42<4:24:12,  3.75s/it] 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:43:46<4:33:22,  3.88s/it]                                                       {'loss': 0.1174, 'grad_norm': 7.268235206604004, 'learning_rate': 3.586440677966102e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:43:46<4:33:22,  3.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:43:49<4:21:13,  3.70s/it]                                                       {'loss': 0.0251, 'grad_norm': 4.739553928375244, 'learning_rate': 3.5855932203389833e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:43:49<4:21:13,  3.70s/it] 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:43:53<4:17:15,  3.65s/it]                                                       {'loss': 0.0355, 'grad_norm': 2.622553825378418, 'learning_rate': 3.5847457627118645e-05, 'epoch': 0.29}
 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:43:53<4:17:15,  3.65s/it] 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:43:56<4:20:13,  3.69s/it]                                                       {'loss': 0.0394, 'grad_norm': 3.8604559898376465, 'learning_rate': 3.5838983050847456e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:43:56<4:20:13,  3.69s/it] 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:44:00<4:11:58,  3.58s/it]                                                       {'loss': 0.2091, 'grad_norm': 8.699201583862305, 'learning_rate': 3.5830508474576274e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:44:00<4:11:58,  3.58s/it] 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:44:03<4:07:09,  3.51s/it]                                                       {'loss': 0.1359, 'grad_norm': 5.59075403213501, 'learning_rate': 3.5822033898305085e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:44:03<4:07:09,  3.51s/it] 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:44:06<4:04:18,  3.47s/it]                                                       {'loss': 0.0782, 'grad_norm': 6.292370319366455, 'learning_rate': 3.5813559322033903e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:44:06<4:04:18,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:44:10<4:04:01,  3.47s/it]                                                       {'loss': 0.0241, 'grad_norm': 2.588500499725342, 'learning_rate': 3.5805084745762715e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:44:10<4:04:01,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:44:13<4:00:32,  3.42s/it]                                                       {'loss': 0.0686, 'grad_norm': 3.781553030014038, 'learning_rate': 3.5796610169491526e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:44:13<4:00:32,  3.42s/it] 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:17<3:59:51,  3.41s/it]                                                       {'loss': 0.0393, 'grad_norm': 2.848154306411743, 'learning_rate': 3.578813559322034e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:17<3:59:51,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:20<4:04:01,  3.47s/it]                                                       {'loss': 0.122, 'grad_norm': 7.765010356903076, 'learning_rate': 3.5779661016949155e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:20<4:04:01,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:24<4:01:49,  3.44s/it]                                                       {'loss': 0.025, 'grad_norm': 2.694673776626587, 'learning_rate': 3.577118644067797e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:24<4:01:49,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:44:27<4:01:58,  3.44s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.5697896480560303, 'learning_rate': 3.5762711864406785e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:44:27<4:01:58,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:44:30<4:01:52,  3.44s/it]                                                       {'loss': 0.009, 'grad_norm': 1.3681508302688599, 'learning_rate': 3.5754237288135596e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:44:30<4:01:52,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:44:34<4:02:39,  3.45s/it]                                                       {'loss': 0.069, 'grad_norm': 3.2846310138702393, 'learning_rate': 3.5745762711864414e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:44:34<4:02:39,  3.45s/it] 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:44:38<4:04:34,  3.48s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.9220116138458252, 'learning_rate': 3.5737288135593225e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:44:38<4:04:34,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:44:41<4:03:03,  3.46s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.36740121245384216, 'learning_rate': 3.572881355932203e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:44:41<4:03:03,  3.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:44:44<4:00:38,  3.43s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04256792366504669, 'learning_rate': 3.572033898305085e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:44:44<4:00:38,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:44:48<4:06:42,  3.51s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.889104962348938, 'learning_rate': 3.571186440677966e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:44:48<4:06:42,  3.51s/it] 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:44:51<4:04:13,  3.48s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.13775119185447693, 'learning_rate': 3.570338983050848e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:44:51<4:04:13,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:44:55<4:01:37,  3.44s/it]                                                       {'loss': 0.0318, 'grad_norm': 4.117879390716553, 'learning_rate': 3.569491525423729e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:44:55<4:01:37,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:44:58<4:00:03,  3.42s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5095136761665344, 'learning_rate': 3.5686440677966107e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:44:58<4:00:03,  3.42s/it] 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:45:01<3:58:56,  3.41s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.9222590327262878, 'learning_rate': 3.567796610169492e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:45:01<3:58:56,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:45:05<3:58:48,  3.40s/it]                                                       {'loss': 0.0096, 'grad_norm': 0.9401792883872986, 'learning_rate': 3.566949152542373e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:45:05<3:58:48,  3.40s/it] 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:45:08<4:00:56,  3.44s/it]                                                       {'loss': 0.1082, 'grad_norm': 6.440656661987305, 'learning_rate': 3.566101694915254e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:45:08<4:00:56,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:45:12<4:00:13,  3.43s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3258479833602905, 'learning_rate': 3.565254237288136e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:45:12<4:00:13,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:15<3:58:15,  3.40s/it]                                                       {'loss': 0.0279, 'grad_norm': 4.167832851409912, 'learning_rate': 3.564406779661017e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:15<3:58:15,  3.40s/it] 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:18<3:57:38,  3.39s/it]                                                       {'loss': 0.117, 'grad_norm': 7.909724235534668, 'learning_rate': 3.563559322033899e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:19<3:57:38,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:22<3:58:01,  3.40s/it]                                                       {'loss': 0.0303, 'grad_norm': 6.9200615882873535, 'learning_rate': 3.56271186440678e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:22<3:58:01,  3.40s/it] 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:25<3:57:16,  3.39s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.4194674491882324, 'learning_rate': 3.561864406779661e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:25<3:57:16,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:45:29<3:57:18,  3.39s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.9930744171142578, 'learning_rate': 3.561016949152542e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:45:29<3:57:18,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:45:32<3:59:53,  3.43s/it]                                                       {'loss': 0.0909, 'grad_norm': 3.844533920288086, 'learning_rate': 3.560169491525424e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:45:32<3:59:53,  3.43s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:45:36<4:12:51,  3.61s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2672663927078247, 'learning_rate': 3.559322033898305e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:45:36<4:12:51,  3.61s/it][2025-10-20 01:22:41,548] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:45:42<4:52:31,  4.18s/it]                                                       {'loss': 0.0665, 'grad_norm': 5.593567371368408, 'learning_rate': 3.558474576271187e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:45:42<4:52:31,  4.18s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:45:45<4:36:02,  3.95s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.051210999488830566, 'learning_rate': 3.557627118644068e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:45:45<4:36:02,  3.95s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:45:48<4:23:34,  3.77s/it]                                                       {'loss': 0.078, 'grad_norm': 5.78523063659668, 'learning_rate': 3.55677966101695e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:45:48<4:23:34,  3.77s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:45:52<4:15:24,  3.65s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03958538919687271, 'learning_rate': 3.555932203389831e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:45:52<4:15:24,  3.65s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:45:55<4:09:53,  3.57s/it]                                                       {'loss': 0.0949, 'grad_norm': 8.489173889160156, 'learning_rate': 3.555084745762712e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:45:55<4:09:53,  3.57s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:45:59<4:05:19,  3.51s/it]                                                       {'loss': 0.0647, 'grad_norm': 6.6154255867004395, 'learning_rate': 3.554237288135593e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:45:59<4:05:19,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:46:02<4:02:00,  3.46s/it]                                                       {'loss': 0.1398, 'grad_norm': 6.622654438018799, 'learning_rate': 3.5533898305084744e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:46:02<4:02:00,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:46:05<3:59:55,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09816979616880417, 'learning_rate': 3.552542372881356e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:46:05<3:59:55,  3.43s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:46:09<3:59:58,  3.44s/it]                                                       {'loss': 0.1755, 'grad_norm': 7.102482795715332, 'learning_rate': 3.551694915254237e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:46:09<3:59:58,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:46:13<4:06:20,  3.53s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.5996969938278198, 'learning_rate': 3.550847457627119e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:46:13<4:06:20,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:16<4:02:09,  3.47s/it]                                                       {'loss': 0.1188, 'grad_norm': 9.737963676452637, 'learning_rate': 3.55e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:16<4:02:09,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:19<4:00:25,  3.44s/it]                                                       {'loss': 0.1037, 'grad_norm': 5.071467399597168, 'learning_rate': 3.5491525423728814e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:19<4:00:25,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:23<3:58:55,  3.42s/it]                                                       {'loss': 0.1337, 'grad_norm': 5.958940029144287, 'learning_rate': 3.5483050847457625e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:23<3:58:55,  3.42s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:46:26<4:00:02,  3.44s/it]                                                       {'loss': 0.0261, 'grad_norm': 3.954697847366333, 'learning_rate': 3.547457627118644e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:46:26<4:00:02,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:46:30<3:59:28,  3.43s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.3967514038085938, 'learning_rate': 3.5466101694915254e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:46:30<3:59:28,  3.43s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:46:33<4:00:20,  3.45s/it]                                                       {'loss': 0.1036, 'grad_norm': 7.223679065704346, 'learning_rate': 3.545762711864407e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:46:33<4:00:20,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:46:36<3:59:48,  3.44s/it]                                                       {'loss': 0.01, 'grad_norm': 1.745025396347046, 'learning_rate': 3.5449152542372884e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:46:36<3:59:48,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:46:40<4:00:11,  3.45s/it]                                                       {'loss': 0.0857, 'grad_norm': 6.875076770782471, 'learning_rate': 3.54406779661017e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:46:40<4:00:11,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:46:44<4:08:08,  3.56s/it]                                                       {'loss': 0.153, 'grad_norm': 6.222415924072266, 'learning_rate': 3.5432203389830506e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:46:44<4:08:08,  3.56s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:46:47<4:06:54,  3.54s/it]                                                       {'loss': 0.101, 'grad_norm': 4.813457012176514, 'learning_rate': 3.5423728813559324e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:46:47<4:06:54,  3.54s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:46:51<4:03:40,  3.50s/it]                                                       {'loss': 0.2059, 'grad_norm': 9.018071174621582, 'learning_rate': 3.5415254237288135e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:46:51<4:03:40,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:46:54<4:03:48,  3.50s/it]                                                       {'loss': 0.0814, 'grad_norm': 7.059210300445557, 'learning_rate': 3.5406779661016954e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:46:54<4:03:48,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:46:58<4:02:59,  3.49s/it]                                                       {'loss': 0.0181, 'grad_norm': 1.6617655754089355, 'learning_rate': 3.5398305084745765e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:46:58<4:02:59,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:47:01<4:01:33,  3.47s/it]                                                       {'loss': 0.0162, 'grad_norm': 1.4378106594085693, 'learning_rate': 3.538983050847458e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:47:01<4:01:33,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:47:05<4:03:54,  3.51s/it]                                                       {'loss': 0.061, 'grad_norm': 4.22238826751709, 'learning_rate': 3.5381355932203394e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:47:05<4:03:54,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:47:08<4:03:17,  3.50s/it]                                                       {'loss': 0.0962, 'grad_norm': 5.7414093017578125, 'learning_rate': 3.5372881355932205e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:47:08<4:03:17,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:47:12<4:05:19,  3.53s/it]                                                       {'loss': 0.0183, 'grad_norm': 2.63122296333313, 'learning_rate': 3.536440677966102e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:47:12<4:05:19,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:15<4:02:19,  3.48s/it]                                                       {'loss': 0.0398, 'grad_norm': 2.9968442916870117, 'learning_rate': 3.535593220338983e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:15<4:02:19,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:18<4:00:55,  3.47s/it]                                                       {'loss': 0.0255, 'grad_norm': 2.265629768371582, 'learning_rate': 3.5347457627118646e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:18<4:00:55,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:22<4:09:25,  3.59s/it]                                                       {'loss': 0.0478, 'grad_norm': 4.524815559387207, 'learning_rate': 3.533898305084746e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:22<4:09:25,  3.59s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:26<4:05:32,  3.53s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.22499418258667, 'learning_rate': 3.5330508474576275e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:26<4:05:32,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:47:29<4:05:34,  3.54s/it]                                                       {'loss': 0.1141, 'grad_norm': 6.257026195526123, 'learning_rate': 3.532203389830509e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:47:29<4:05:34,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:47:33<4:02:15,  3.49s/it]                                                       {'loss': 0.0368, 'grad_norm': 3.363604784011841, 'learning_rate': 3.53135593220339e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:47:33<4:02:15,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:47:36<3:57:22,  3.42s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.0745638608932495, 'learning_rate': 3.530508474576271e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:47:36<3:57:22,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:47:39<3:56:10,  3.40s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.25388002395629883, 'learning_rate': 3.529661016949153e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:47:39<3:56:10,  3.40s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:47:43<3:59:25,  3.45s/it]                                                       {'loss': 0.012, 'grad_norm': 1.265941858291626, 'learning_rate': 3.528813559322034e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:47:43<3:59:25,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:47:46<4:00:40,  3.47s/it]                                                       {'loss': 0.0193, 'grad_norm': 2.0624334812164307, 'learning_rate': 3.527966101694916e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:47:46<4:00:40,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:47:50<4:00:38,  3.47s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.8284143805503845, 'learning_rate': 3.527118644067797e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:47:50<4:00:38,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:47:53<3:59:59,  3.46s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.3106019496917725, 'learning_rate': 3.5262711864406786e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:47:53<3:59:59,  3.46s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:47:57<4:07:53,  3.58s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.9399938583374023, 'learning_rate': 3.52542372881356e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:47:57<4:07:53,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:48:01<4:04:26,  3.53s/it]                                                       {'loss': 0.3135, 'grad_norm': 8.832405090332031, 'learning_rate': 3.524576271186441e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:48:01<4:04:26,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:48:04<4:01:38,  3.49s/it]                                                       {'loss': 0.0271, 'grad_norm': 2.406684398651123, 'learning_rate': 3.523728813559322e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:48:04<4:01:38,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:48:08<4:05:38,  3.55s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.5643890500068665, 'learning_rate': 3.522881355932204e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:48:08<4:05:38,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:48:11<4:01:40,  3.49s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.2331281900405884, 'learning_rate': 3.522033898305085e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:48:11<4:01:40,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:15<4:06:22,  3.56s/it]                                                       {'loss': 0.1265, 'grad_norm': 5.140448570251465, 'learning_rate': 3.521186440677967e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:15<4:06:22,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:18<4:07:32,  3.58s/it]                                                       {'loss': 0.0787, 'grad_norm': 4.540560245513916, 'learning_rate': 3.520338983050848e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:18<4:07:32,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:22<4:04:48,  3.54s/it]                                                       {'loss': 0.0364, 'grad_norm': 4.9593400955200195, 'learning_rate': 3.519491525423729e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:22<4:04:48,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:25<4:02:53,  3.51s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.395554542541504, 'learning_rate': 3.51864406779661e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:25<4:02:53,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:48:29<4:02:35,  3.51s/it]                                                       {'loss': 0.0324, 'grad_norm': 2.954481363296509, 'learning_rate': 3.517796610169491e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:48:29<4:02:35,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:48:33<4:18:21,  3.74s/it]                                                       {'loss': 0.1087, 'grad_norm': 5.946264743804932, 'learning_rate': 3.516949152542373e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:48:33<4:18:21,  3.74s/it][2025-10-20 01:25:38,275] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:48:39<4:58:19,  4.31s/it]                                                       {'loss': 0.1441, 'grad_norm': 8.97510814666748, 'learning_rate': 3.516101694915254e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:48:39<4:58:19,  4.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:48:42<4:39:17,  4.04s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.42730513215065, 'learning_rate': 3.515254237288136e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:48:42<4:39:17,  4.04s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:48:45<4:23:35,  3.81s/it]                                                       {'loss': 0.094, 'grad_norm': 3.6788899898529053, 'learning_rate': 3.514406779661017e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:48:45<4:23:35,  3.81s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:48:49<4:13:41,  3.67s/it]                                                       {'loss': 0.1395, 'grad_norm': 8.034524917602539, 'learning_rate': 3.513559322033899e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:48:49<4:13:41,  3.67s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:48:52<4:06:58,  3.58s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.12829771637916565, 'learning_rate': 3.5127118644067794e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:48:52<4:06:58,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:48:55<4:04:56,  3.55s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.7901768684387207, 'learning_rate': 3.511864406779661e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:48:55<4:04:56,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:49:00<4:24:06,  3.82s/it]                                                       {'loss': 0.111, 'grad_norm': 6.540427207946777, 'learning_rate': 3.511016949152542e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:49:00<4:24:06,  3.82s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:49:03<4:13:54,  3.68s/it]                                                       {'loss': 0.0321, 'grad_norm': 3.0260820388793945, 'learning_rate': 3.510169491525424e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:49:03<4:13:54,  3.68s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:49:07<4:16:41,  3.72s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.677951991558075, 'learning_rate': 3.509322033898305e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:49:07<4:16:41,  3.72s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:49:11<4:14:03,  3.68s/it]                                                       {'loss': 0.1092, 'grad_norm': 4.779608726501465, 'learning_rate': 3.508474576271187e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:49:11<4:14:03,  3.68s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:49:14<4:09:08,  3.61s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4750760793685913, 'learning_rate': 3.507627118644068e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:49:14<4:09:08,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:18<4:19:56,  3.77s/it]                                                       {'loss': 0.0554, 'grad_norm': 4.930330753326416, 'learning_rate': 3.506779661016949e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:18<4:19:56,  3.77s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:22<4:12:14,  3.66s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.25425735116004944, 'learning_rate': 3.5059322033898304e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:22<4:12:14,  3.66s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:25<4:07:00,  3.58s/it]                                                       {'loss': 0.0274, 'grad_norm': 4.2049713134765625, 'learning_rate': 3.505084745762712e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:25<4:07:00,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:49:28<4:02:31,  3.52s/it]                                                       {'loss': 0.253, 'grad_norm': 4.541049003601074, 'learning_rate': 3.5042372881355934e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:49:28<4:02:31,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:49:32<4:03:21,  3.53s/it]                                                       {'loss': 0.0244, 'grad_norm': 2.788397789001465, 'learning_rate': 3.5033898305084745e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:49:32<4:03:21,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:49:36<4:09:23,  3.62s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.9826020002365112, 'learning_rate': 3.502542372881356e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:49:36<4:09:23,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:49:39<4:04:06,  3.54s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.3889224529266357, 'learning_rate': 3.5016949152542374e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:49:39<4:04:06,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:49:43<4:02:33,  3.52s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.5031330585479736, 'learning_rate': 3.5008474576271186e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:49:43<4:02:33,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:49:46<4:00:05,  3.49s/it]                                                       {'loss': 0.0197, 'grad_norm': 2.4301302433013916, 'learning_rate': 3.5e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:49:46<4:00:05,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:49:50<4:00:24,  3.49s/it]                                                       {'loss': 0.2765, 'grad_norm': 9.577616691589355, 'learning_rate': 3.4991525423728815e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:49:50<4:00:24,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:49:53<4:07:28,  3.60s/it]                                                       {'loss': 0.0717, 'grad_norm': 3.9710536003112793, 'learning_rate': 3.4983050847457626e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:49:53<4:07:28,  3.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:49:57<4:07:22,  3.60s/it]                                                       {'loss': 0.0912, 'grad_norm': 8.369928359985352, 'learning_rate': 3.4974576271186444e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:49:57<4:07:22,  3.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:50:00<4:04:15,  3.55s/it]                                                       {'loss': 0.0231, 'grad_norm': 2.7731773853302, 'learning_rate': 3.4966101694915256e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:50:00<4:04:15,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:50:04<4:00:11,  3.49s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.5759152173995972, 'learning_rate': 3.4957627118644074e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:50:04<4:00:11,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:50:08<4:07:14,  3.60s/it]                                                       {'loss': 0.0673, 'grad_norm': 4.563230037689209, 'learning_rate': 3.4949152542372885e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:50:08<4:07:14,  3.60s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:50:11<4:05:37,  3.57s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.004820466041565, 'learning_rate': 3.4940677966101696e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:50:11<4:05:37,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:50:15<4:00:30,  3.50s/it]                                                       {'loss': 0.0262, 'grad_norm': 2.9733669757843018, 'learning_rate': 3.493220338983051e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:50:15<4:00:30,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:18<3:58:47,  3.48s/it]                                                       {'loss': 0.028, 'grad_norm': 1.5067188739776611, 'learning_rate': 3.4923728813559326e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:18<3:58:47,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:22<4:00:41,  3.51s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.5141742825508118, 'learning_rate': 3.491525423728814e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:22<4:00:41,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:25<3:57:14,  3.46s/it]                                                       {'loss': 0.0231, 'grad_norm': 3.3249053955078125, 'learning_rate': 3.4906779661016955e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:25<3:57:14,  3.46s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:50:28<3:54:27,  3.42s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.258878469467163, 'learning_rate': 3.4898305084745766e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:50:28<3:54:27,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:50:32<3:53:44,  3.41s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.395017385482788, 'learning_rate': 3.488983050847458e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:50:32<3:53:44,  3.41s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:50:35<3:55:05,  3.43s/it]                                                       {'loss': 0.0236, 'grad_norm': 3.494826555252075, 'learning_rate': 3.488135593220339e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:50:35<3:55:05,  3.43s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:50:39<4:02:09,  3.53s/it]                                                       {'loss': 0.0586, 'grad_norm': 4.611476898193359, 'learning_rate': 3.487288135593221e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:50:39<4:02:09,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:50:42<3:59:18,  3.49s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.2849926948547363, 'learning_rate': 3.486440677966102e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:50:42<3:59:18,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:50:46<3:57:50,  3.47s/it]                                                       {'loss': 0.0747, 'grad_norm': 4.013605117797852, 'learning_rate': 3.485593220338983e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:50:46<3:57:50,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:50:49<3:56:01,  3.44s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.62018620967865, 'learning_rate': 3.484745762711865e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:50:49<3:56:01,  3.44s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:50:53<4:03:34,  3.55s/it]                                                       {'loss': 0.0791, 'grad_norm': 3.2688817977905273, 'learning_rate': 3.483898305084746e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:50:53<4:03:34,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:50:56<4:03:06,  3.55s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.7547928690910339, 'learning_rate': 3.483050847457627e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:50:56<4:03:06,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:51:00<4:03:09,  3.55s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7941333651542664, 'learning_rate': 3.482203389830508e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:51:00<4:03:09,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:51:03<4:00:35,  3.51s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.44888943433761597, 'learning_rate': 3.48135593220339e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:51:03<4:00:35,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:51:07<3:56:42,  3.46s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.0971064567565918, 'learning_rate': 3.480508474576271e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:51:07<3:56:42,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:51:10<3:55:16,  3.44s/it]                                                       {'loss': 0.0164, 'grad_norm': 2.6484580039978027, 'learning_rate': 3.479661016949153e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:51:10<3:55:16,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:51:14<4:07:18,  3.61s/it]                                                       {'loss': 0.0192, 'grad_norm': 3.0834248065948486, 'learning_rate': 3.478813559322034e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:51:14<4:07:18,  3.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:17<4:00:35,  3.52s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.8422417640686035, 'learning_rate': 3.477966101694916e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:17<4:00:35,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:21<3:57:16,  3.47s/it]                                                       {'loss': 0.0399, 'grad_norm': 3.312711000442505, 'learning_rate': 3.477118644067797e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:21<3:57:16,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:24<3:54:41,  3.43s/it]                                                       {'loss': 0.0453, 'grad_norm': 5.8315510749816895, 'learning_rate': 3.476271186440678e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:24<3:54:41,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:51:27<3:52:45,  3.41s/it]                                                       {'loss': 0.193, 'grad_norm': 9.110697746276855, 'learning_rate': 3.475423728813559e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:51:27<3:52:45,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:51:31<3:52:25,  3.40s/it]                                                       {'loss': 0.0331, 'grad_norm': 3.7269599437713623, 'learning_rate': 3.474576271186441e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:51:31<3:52:25,  3.40s/it][2025-10-20 01:28:36,155] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:51:36<4:38:23,  4.08s/it]                                                       {'loss': 0.0453, 'grad_norm': 5.96586275100708, 'learning_rate': 3.473728813559322e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:51:36<4:38:23,  4.08s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:51:41<4:46:40,  4.20s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.9731113314628601, 'learning_rate': 3.472881355932204e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:51:41<4:46:40,  4.20s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:51:44<4:29:29,  3.95s/it]                                                       {'loss': 0.0983, 'grad_norm': 3.2164480686187744, 'learning_rate': 3.472033898305085e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:51:44<4:29:29,  3.95s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:51:48<4:27:22,  3.92s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1621883660554886, 'learning_rate': 3.471186440677966e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:51:48<4:27:22,  3.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:51:52<4:25:11,  3.89s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.20491217076778412, 'learning_rate': 3.470338983050847e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:51:52<4:25:11,  3.89s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:51:55<4:12:56,  3.71s/it]                                                       {'loss': 0.1853, 'grad_norm': 8.252519607543945, 'learning_rate': 3.469491525423729e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:51:55<4:12:56,  3.71s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:51:59<4:05:59,  3.61s/it]                                                       {'loss': 0.0639, 'grad_norm': 6.389533519744873, 'learning_rate': 3.46864406779661e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:51:59<4:05:59,  3.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:52:02<4:00:18,  3.52s/it]                                                       {'loss': 0.0398, 'grad_norm': 3.960184335708618, 'learning_rate': 3.4677966101694914e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:52:02<4:00:18,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:52:05<3:55:11,  3.45s/it]                                                       {'loss': 0.0387, 'grad_norm': 4.56796932220459, 'learning_rate': 3.466949152542373e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:52:05<3:55:11,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:52:09<3:55:26,  3.45s/it]                                                       {'loss': 0.0361, 'grad_norm': 4.573338508605957, 'learning_rate': 3.466101694915254e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:52:09<3:55:26,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:52:12<3:53:02,  3.42s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.7662203907966614, 'learning_rate': 3.465254237288136e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:52:12<3:53:02,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:52:15<3:52:04,  3.41s/it]                                                       {'loss': 0.0407, 'grad_norm': 3.5657050609588623, 'learning_rate': 3.4644067796610166e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:52:15<3:52:04,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:52:19<3:54:33,  3.44s/it]                                                       {'loss': 0.0714, 'grad_norm': 3.230572462081909, 'learning_rate': 3.4635593220338984e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:52:19<3:54:33,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:52:22<3:52:41,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05888434126973152, 'learning_rate': 3.4627118644067795e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:52:22<3:52:41,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:52:26<3:53:41,  3.43s/it]                                                       {'loss': 0.0223, 'grad_norm': 1.7779430150985718, 'learning_rate': 3.461864406779661e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:52:26<3:53:41,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:52:29<3:53:42,  3.43s/it]                                                       {'loss': 0.1227, 'grad_norm': 10.664870262145996, 'learning_rate': 3.4610169491525425e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:52:29<3:53:42,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:52:33<3:51:36,  3.40s/it]                                                       {'loss': 0.1395, 'grad_norm': 14.59208869934082, 'learning_rate': 3.460169491525424e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:52:33<3:51:36,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:52:36<3:50:07,  3.38s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.427732229232788, 'learning_rate': 3.4593220338983054e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:52:36<3:50:07,  3.38s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:52:39<3:54:56,  3.45s/it]                                                       {'loss': 0.1397, 'grad_norm': 3.9900693893432617, 'learning_rate': 3.4584745762711865e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:52:40<3:54:56,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:52:43<3:53:38,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0746188834309578, 'learning_rate': 3.4576271186440676e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:52:43<3:53:38,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:52:46<3:52:36,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04967567324638367, 'learning_rate': 3.4567796610169494e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:52:46<3:52:36,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:52:50<3:49:03,  3.37s/it]                                                       {'loss': 0.2213, 'grad_norm': 7.836148738861084, 'learning_rate': 3.4559322033898306e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:52:50<3:49:03,  3.37s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:52:53<3:47:27,  3.35s/it]                                                       {'loss': 0.1199, 'grad_norm': 2.348090887069702, 'learning_rate': 3.4550847457627124e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:52:53<3:47:27,  3.35s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:52:56<3:50:16,  3.39s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.34165751934051514, 'learning_rate': 3.4542372881355935e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:52:56<3:50:16,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:53:00<3:51:17,  3.41s/it]                                                       {'loss': 0.1127, 'grad_norm': 6.321831226348877, 'learning_rate': 3.4533898305084746e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:53:00<3:51:17,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:53:03<3:50:22,  3.39s/it]                                                       {'loss': 0.0389, 'grad_norm': 2.612104892730713, 'learning_rate': 3.452542372881356e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:53:03<3:50:22,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:53:07<3:52:35,  3.43s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.18094447255134583, 'learning_rate': 3.4516949152542376e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:53:07<3:52:35,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:53:10<3:51:58,  3.42s/it]                                                       {'loss': 0.0526, 'grad_norm': 3.4918529987335205, 'learning_rate': 3.450847457627119e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:53:10<3:51:58,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:53:13<3:51:38,  3.41s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1820058673620224, 'learning_rate': 3.45e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:53:13<3:51:38,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:53:17<3:53:21,  3.44s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.3201635777950287, 'learning_rate': 3.4491525423728816e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:53:17<3:53:21,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:53:21<3:58:45,  3.52s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03916982561349869, 'learning_rate': 3.448305084745763e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:53:21<3:58:45,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:53:24<3:55:25,  3.47s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.053354907780885696, 'learning_rate': 3.4474576271186446e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:53:24<3:55:25,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:53:27<3:55:13,  3.47s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.7875578999519348, 'learning_rate': 3.446610169491526e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:53:27<3:55:13,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:53:31<3:52:12,  3.43s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4962502419948578, 'learning_rate': 3.445762711864407e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:53:31<3:52:12,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:53:34<3:51:57,  3.42s/it]                                                       {'loss': 0.0636, 'grad_norm': 4.280566692352295, 'learning_rate': 3.444915254237288e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:53:34<3:51:57,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:53:38<3:51:38,  3.42s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.3546277284622192, 'learning_rate': 3.44406779661017e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:53:38<3:51:38,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:53:41<3:53:44,  3.45s/it]                                                       {'loss': 0.0112, 'grad_norm': 3.0045008659362793, 'learning_rate': 3.443220338983051e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:53:41<3:53:44,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:53:45<4:02:57,  3.59s/it]                                                       {'loss': 0.0409, 'grad_norm': 3.2183146476745605, 'learning_rate': 3.442372881355933e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:53:45<4:02:57,  3.59s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:53:48<3:57:41,  3.51s/it]                                                       {'loss': 0.0453, 'grad_norm': 5.238158702850342, 'learning_rate': 3.441525423728814e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:53:48<3:57:41,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:53:52<3:55:39,  3.48s/it]                                                       {'loss': 0.0756, 'grad_norm': 5.989760398864746, 'learning_rate': 3.440677966101695e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:53:52<3:55:39,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:53:55<3:53:01,  3.44s/it]                                                       {'loss': 0.1444, 'grad_norm': 7.963556289672852, 'learning_rate': 3.439830508474576e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:53:55<3:53:01,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:53:59<3:51:41,  3.43s/it]                                                       {'loss': 0.1226, 'grad_norm': 5.6983962059021, 'learning_rate': 3.438983050847458e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:53:59<3:51:41,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:54:02<3:50:21,  3.41s/it]                                                       {'loss': 0.021, 'grad_norm': 3.928236722946167, 'learning_rate': 3.438135593220339e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:54:02<3:50:21,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:54:05<3:53:09,  3.45s/it]                                                       {'loss': 0.0674, 'grad_norm': 7.262385368347168, 'learning_rate': 3.437288135593221e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:54:05<3:53:09,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:54:09<3:59:02,  3.54s/it]                                                       {'loss': 0.0617, 'grad_norm': 6.002289772033691, 'learning_rate': 3.436440677966102e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:54:09<3:59:02,  3.54s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:54:12<3:53:29,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2506360709667206, 'learning_rate': 3.435593220338984e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:54:12<3:53:29,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:54:16<3:53:33,  3.46s/it]                                                       {'loss': 0.1221, 'grad_norm': 5.520031929016113, 'learning_rate': 3.434745762711864e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:54:16<3:53:33,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:54:19<3:55:36,  3.49s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.21606124937534332, 'learning_rate': 3.433898305084746e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:54:19<3:55:36,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:54:23<4:01:36,  3.58s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.90913987159729, 'learning_rate': 3.433050847457627e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:54:23<4:01:36,  3.58s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:54:27<3:56:07,  3.50s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.6410216093063354, 'learning_rate': 3.432203389830508e-05, 'epoch': 0.33}
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:54:27<3:56:07,  3.50s/it][2025-10-20 01:31:31,903] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:54:32<4:39:00,  4.13s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4060920178890228, 'learning_rate': 3.43135593220339e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:54:32<4:39:00,  4.13s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:54:36<4:23:58,  3.91s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.521901547908783, 'learning_rate': 3.430508474576271e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:54:36<4:23:58,  3.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:54:39<4:13:38,  3.76s/it]                                                       {'loss': 0.002, 'grad_norm': 0.26722171902656555, 'learning_rate': 3.429661016949153e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:54:39<4:13:38,  3.76s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:54:42<4:07:56,  3.68s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.3378525674343109, 'learning_rate': 3.428813559322034e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:54:42<4:07:56,  3.68s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:54:46<4:07:55,  3.68s/it]                                                       {'loss': 0.0431, 'grad_norm': 3.908330202102661, 'learning_rate': 3.427966101694915e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:54:46<4:07:55,  3.68s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:54:50<4:04:22,  3.63s/it]                                                       {'loss': 0.0348, 'grad_norm': 2.1792092323303223, 'learning_rate': 3.4271186440677964e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:54:50<4:04:22,  3.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:54:53<4:00:16,  3.57s/it]                                                       {'loss': 0.0946, 'grad_norm': 5.6245012283325195, 'learning_rate': 3.426271186440678e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:54:53<4:00:16,  3.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:54:56<3:55:09,  3.49s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.439650297164917, 'learning_rate': 3.4254237288135593e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:54:56<3:55:09,  3.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:55:00<4:01:35,  3.59s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.020644009113311768, 'learning_rate': 3.424576271186441e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:55:00<4:01:35,  3.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:55:04<3:59:02,  3.55s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10929592698812485, 'learning_rate': 3.423728813559322e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:55:04<3:59:02,  3.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:55:07<3:55:09,  3.49s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.9955403804779053, 'learning_rate': 3.4228813559322034e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:55:07<3:55:09,  3.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:55:11<3:57:18,  3.53s/it]                                                       {'loss': 0.1116, 'grad_norm': 7.272952556610107, 'learning_rate': 3.4220338983050845e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:55:11<3:57:18,  3.53s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:55:14<3:54:27,  3.48s/it]                                                       {'loss': 0.0453, 'grad_norm': 3.3973045349121094, 'learning_rate': 3.421186440677966e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:55:14<3:54:27,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:55:17<3:51:51,  3.45s/it]                                                       {'loss': 0.0502, 'grad_norm': 3.309588670730591, 'learning_rate': 3.4203389830508475e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:55:17<3:51:51,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:55:21<3:51:10,  3.44s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.2742512226104736, 'learning_rate': 3.419491525423729e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:55:21<3:51:10,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:55:25<4:03:43,  3.62s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.1447516679763794, 'learning_rate': 3.4186440677966104e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:55:25<4:03:43,  3.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:55:28<3:57:49,  3.54s/it]                                                       {'loss': 0.0605, 'grad_norm': 4.958253383636475, 'learning_rate': 3.417796610169492e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:55:28<3:57:49,  3.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:55:32<3:56:19,  3.52s/it]                                                       {'loss': 0.2513, 'grad_norm': 9.704994201660156, 'learning_rate': 3.416949152542373e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:55:32<3:56:19,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:55:35<3:54:46,  3.49s/it]                                                       {'loss': 0.0828, 'grad_norm': 4.484443664550781, 'learning_rate': 3.4161016949152545e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:55:35<3:54:46,  3.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:55:39<4:00:15,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.024837302044034004, 'learning_rate': 3.4152542372881356e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:55:39<4:00:15,  3.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:55:42<3:56:11,  3.52s/it]                                                       {'loss': 0.012, 'grad_norm': 1.5481351613998413, 'learning_rate': 3.414406779661017e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:55:42<3:56:11,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:55:46<3:51:38,  3.45s/it]                                                       {'loss': 0.0111, 'grad_norm': 0.6917470097541809, 'learning_rate': 3.4135593220338985e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:55:46<3:51:38,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:55:49<3:49:10,  3.41s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.10290598124265671, 'learning_rate': 3.4127118644067797e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:55:49<3:49:10,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:55:52<3:49:04,  3.41s/it]                                                       {'loss': 0.0187, 'grad_norm': 1.6769458055496216, 'learning_rate': 3.4118644067796615e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:55:52<3:49:04,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:55:56<3:50:29,  3.44s/it]                                                       {'loss': 0.001, 'grad_norm': 0.15509015321731567, 'learning_rate': 3.4110169491525426e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:55:56<3:50:29,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:55:59<3:47:40,  3.39s/it]                                                       {'loss': 0.0457, 'grad_norm': 4.894767761230469, 'learning_rate': 3.410169491525424e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:55:59<3:47:40,  3.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:56:02<3:47:52,  3.40s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5615702867507935, 'learning_rate': 3.409322033898305e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:56:02<3:47:52,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:56:06<3:47:31,  3.39s/it]                                                       {'loss': 0.0521, 'grad_norm': 5.8418192863464355, 'learning_rate': 3.4084745762711867e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:56:06<3:47:31,  3.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:56:09<3:49:16,  3.42s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.37359702587127686, 'learning_rate': 3.407627118644068e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:56:09<3:49:16,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:56:13<3:50:13,  3.44s/it]                                                       {'loss': 0.015, 'grad_norm': 0.873632550239563, 'learning_rate': 3.4067796610169496e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:56:13<3:50:13,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:56:16<3:49:54,  3.43s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.0057218074798584, 'learning_rate': 3.405932203389831e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:56:16<3:49:54,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:56:20<3:50:26,  3.44s/it]                                                       {'loss': 0.1858, 'grad_norm': 10.784260749816895, 'learning_rate': 3.4050847457627125e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:56:20<3:50:26,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:56:23<3:50:46,  3.45s/it]                                                       {'loss': 0.0566, 'grad_norm': 6.990079879760742, 'learning_rate': 3.404237288135593e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:56:23<3:50:46,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:56:27<3:54:38,  3.51s/it]                                                       {'loss': 0.108, 'grad_norm': 6.83291482925415, 'learning_rate': 3.403389830508475e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:56:27<3:54:38,  3.51s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:56:30<3:52:20,  3.47s/it]                                                       {'loss': 0.0139, 'grad_norm': 2.2842001914978027, 'learning_rate': 3.402542372881356e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:56:30<3:52:20,  3.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:56:34<3:51:24,  3.46s/it]                                                       {'loss': 0.0948, 'grad_norm': 5.971240520477295, 'learning_rate': 3.401694915254238e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:56:34<3:51:24,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:56:37<3:49:09,  3.43s/it]                                                       {'loss': 0.0267, 'grad_norm': 3.1361584663391113, 'learning_rate': 3.400847457627119e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:56:37<3:49:09,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:56:40<3:48:50,  3.42s/it]                                                       {'loss': 0.0299, 'grad_norm': 3.754291534423828, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:56:40<3:48:50,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:56:44<3:52:20,  3.48s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3301900625228882, 'learning_rate': 3.399152542372882e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:56:44<3:52:20,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:56:47<3:50:09,  3.44s/it]                                                       {'loss': 0.0833, 'grad_norm': 6.69647741317749, 'learning_rate': 3.398305084745763e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:56:47<3:50:09,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:56:51<3:48:07,  3.41s/it]                                                       {'loss': 0.0308, 'grad_norm': 1.9665515422821045, 'learning_rate': 3.397457627118644e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:56:51<3:48:07,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:56:54<3:46:38,  3.39s/it]                                                       {'loss': 0.0378, 'grad_norm': 2.7273929119110107, 'learning_rate': 3.396610169491525e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:56:54<3:46:38,  3.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:56:57<3:46:08,  3.39s/it]                                                       {'loss': 0.0337, 'grad_norm': 5.372036457061768, 'learning_rate': 3.395762711864407e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:56:57<3:46:08,  3.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:57:01<3:45:23,  3.38s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.15568889677524567, 'learning_rate': 3.394915254237288e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:57:01<3:45:23,  3.38s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:57:04<3:48:30,  3.42s/it]                                                       {'loss': 0.1665, 'grad_norm': 7.243027210235596, 'learning_rate': 3.39406779661017e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:57:04<3:48:30,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:57:08<3:48:26,  3.42s/it]                                                       {'loss': 0.0239, 'grad_norm': 2.390820264816284, 'learning_rate': 3.393220338983051e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:57:08<3:48:26,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:57:11<3:48:48,  3.43s/it]                                                       {'loss': 0.0667, 'grad_norm': 6.730644226074219, 'learning_rate': 3.392372881355932e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:57:11<3:48:48,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:57:15<3:49:15,  3.44s/it]                                                       {'loss': 0.001, 'grad_norm': 0.16127312183380127, 'learning_rate': 3.391525423728813e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:57:15<3:49:15,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:57:18<3:57:28,  3.56s/it]                                                       {'loss': 0.0235, 'grad_norm': 2.2699923515319824, 'learning_rate': 3.390677966101695e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:57:18<3:57:28,  3.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:57:22<4:05:10,  3.68s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.7934784889221191, 'learning_rate': 3.389830508474576e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:57:22<4:05:10,  3.68s/it][2025-10-20 01:34:27,759] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:57:28<4:45:54,  4.29s/it]                                                       {'loss': 0.0453, 'grad_norm': 5.448843955993652, 'learning_rate': 3.388983050847458e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:57:28<4:45:54,  4.29s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:57:32<4:27:03,  4.01s/it]                                                       {'loss': 0.0215, 'grad_norm': 2.1417157649993896, 'learning_rate': 3.388135593220339e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:57:32<4:27:03,  4.01s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:57:35<4:14:11,  3.82s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.1243396997451782, 'learning_rate': 3.387288135593221e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:57:35<4:14:11,  3.82s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:57:38<4:06:07,  3.70s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015025286003947258, 'learning_rate': 3.386440677966102e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:57:38<4:06:07,  3.70s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:57:42<4:01:10,  3.62s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.4229754209518433, 'learning_rate': 3.385593220338983e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:57:42<4:01:10,  3.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:57:45<4:02:51,  3.65s/it]                                                       {'loss': 0.0489, 'grad_norm': 2.1360650062561035, 'learning_rate': 3.3847457627118644e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:57:45<4:02:51,  3.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:57:49<3:58:07,  3.58s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.41916623711586, 'learning_rate': 3.383898305084746e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:57:49<3:58:07,  3.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:57:52<3:53:57,  3.52s/it]                                                       {'loss': 0.1022, 'grad_norm': 5.5757927894592285, 'learning_rate': 3.383050847457627e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:57:52<3:53:57,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:57:56<3:50:49,  3.47s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6648687124252319, 'learning_rate': 3.382203389830509e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:57:56<3:50:49,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:57:59<3:59:02,  3.59s/it]                                                       {'loss': 0.1584, 'grad_norm': 8.632157325744629, 'learning_rate': 3.38135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:57:59<3:59:02,  3.59s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:58:03<3:55:16,  3.54s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.7644872665405273, 'learning_rate': 3.3805084745762714e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:58:03<3:55:16,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:58:06<3:51:01,  3.48s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.5344922542572021, 'learning_rate': 3.3796610169491525e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:58:06<3:51:01,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:58:10<3:52:57,  3.51s/it]                                                       {'loss': 0.3351, 'grad_norm': 12.853715896606445, 'learning_rate': 3.3788135593220336e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:58:10<3:52:57,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:58:13<3:49:29,  3.45s/it]                                                       {'loss': 0.0744, 'grad_norm': 6.7424116134643555, 'learning_rate': 3.3779661016949154e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:58:13<3:49:29,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:58:17<3:48:21,  3.44s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.654087483882904, 'learning_rate': 3.3771186440677965e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:58:17<3:48:21,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:58:20<3:51:57,  3.49s/it]                                                       {'loss': 0.0471, 'grad_norm': 4.4579548835754395, 'learning_rate': 3.3762711864406784e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:58:20<3:51:57,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:58:24<3:49:24,  3.46s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.4881681203842163, 'learning_rate': 3.3754237288135595e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:58:24<3:49:24,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:58:27<3:47:51,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06468778848648071, 'learning_rate': 3.3745762711864406e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:58:27<3:47:51,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:58:31<3:51:09,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10549593716859818, 'learning_rate': 3.373728813559322e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:58:31<3:51:09,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:58:34<3:56:55,  3.57s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.18677549064159393, 'learning_rate': 3.3728813559322035e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:58:34<3:56:55,  3.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:58:38<3:52:18,  3.50s/it]                                                       {'loss': 0.1477, 'grad_norm': 9.08941650390625, 'learning_rate': 3.372033898305085e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:58:38<3:52:18,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:58:41<3:50:16,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11879166960716248, 'learning_rate': 3.3711864406779665e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:58:41<3:50:16,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:58:45<3:51:15,  3.49s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.8160082101821899, 'learning_rate': 3.3703389830508476e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:58:45<3:51:15,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:58:48<3:48:51,  3.45s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.4097846746444702, 'learning_rate': 3.3694915254237294e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:58:48<3:48:51,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:58:51<3:47:02,  3.43s/it]                                                       {'loss': 0.0345, 'grad_norm': 3.9088289737701416, 'learning_rate': 3.3686440677966105e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:58:51<3:47:02,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:58:55<3:47:26,  3.43s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5654836297035217, 'learning_rate': 3.367796610169492e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:58:55<3:47:26,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:58:58<3:45:53,  3.41s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.6083016395568848, 'learning_rate': 3.366949152542373e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:58:58<3:45:53,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:59:01<3:44:56,  3.40s/it]                                                       {'loss': 0.031, 'grad_norm': 2.7971606254577637, 'learning_rate': 3.3661016949152546e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:59:01<3:44:56,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:59:05<3:46:57,  3.43s/it]                                                       {'loss': 0.0285, 'grad_norm': 4.51043701171875, 'learning_rate': 3.365254237288136e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:59:05<3:46:57,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:59:09<4:04:24,  3.69s/it]                                                       {'loss': 0.0795, 'grad_norm': 5.001155853271484, 'learning_rate': 3.3644067796610175e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:59:09<4:04:24,  3.69s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:59:13<3:57:56,  3.60s/it]                                                       {'loss': 0.1431, 'grad_norm': 8.907360076904297, 'learning_rate': 3.363559322033899e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:59:13<3:57:56,  3.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:59:16<3:54:00,  3.54s/it]                                                       {'loss': 0.01, 'grad_norm': 1.5484148263931274, 'learning_rate': 3.36271186440678e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:59:16<3:54:00,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:59:20<3:53:27,  3.53s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.0316576957702637, 'learning_rate': 3.361864406779661e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:59:20<3:53:27,  3.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:59:23<3:51:12,  3.50s/it]                                                       {'loss': 0.0219, 'grad_norm': 2.3668322563171387, 'learning_rate': 3.361016949152542e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:59:23<3:51:12,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:59:27<3:57:30,  3.59s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2196795493364334, 'learning_rate': 3.360169491525424e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:59:27<3:57:30,  3.59s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:59:30<3:52:45,  3.52s/it]                                                       {'loss': 0.1163, 'grad_norm': 6.4342522621154785, 'learning_rate': 3.359322033898305e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:59:30<3:52:45,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:59:34<3:49:29,  3.47s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.5808120965957642, 'learning_rate': 3.358474576271187e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:59:34<3:49:29,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:59:37<3:48:50,  3.47s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.25530382990837097, 'learning_rate': 3.357627118644068e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:59:37<3:48:50,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:59:40<3:45:31,  3.42s/it]                                                       {'loss': 0.0583, 'grad_norm': 6.473065376281738, 'learning_rate': 3.35677966101695e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:59:40<3:45:31,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:59:44<3:51:35,  3.51s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05976889282464981, 'learning_rate': 3.35593220338983e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:59:44<3:51:35,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:59:47<3:47:02,  3.44s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.4082717895507812, 'learning_rate': 3.355084745762712e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:59:47<3:47:02,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:59:51<3:43:58,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03434151038527489, 'learning_rate': 3.354237288135593e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:59:51<3:43:58,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [1:59:54<3:43:17,  3.39s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.285396546125412, 'learning_rate': 3.353389830508475e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [1:59:54<3:43:17,  3.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [1:59:57<3:44:21,  3.40s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.3655211925506592, 'learning_rate': 3.352542372881356e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [1:59:57<3:44:21,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [2:00:01<3:42:37,  3.38s/it]                                                       {'loss': 0.0268, 'grad_norm': 3.056905746459961, 'learning_rate': 3.351694915254238e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [2:00:01<3:42:37,  3.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [2:00:04<3:46:02,  3.43s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4618024230003357, 'learning_rate': 3.350847457627119e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [2:00:04<3:46:02,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [2:00:08<3:47:26,  3.45s/it]                                                       {'loss': 0.0611, 'grad_norm': 6.737834453582764, 'learning_rate': 3.35e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [2:00:08<3:47:26,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [2:00:11<3:50:23,  3.50s/it]                                                       {'loss': 0.0337, 'grad_norm': 4.338006496429443, 'learning_rate': 3.349152542372881e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [2:00:11<3:50:23,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:00:15<3:49:08,  3.48s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.22999095916748047, 'learning_rate': 3.348305084745763e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:00:15<3:49:08,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:00:18<3:47:23,  3.45s/it]                                                       {'loss': 0.1707, 'grad_norm': 6.659582138061523, 'learning_rate': 3.347457627118644e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:00:18<3:47:23,  3.45s/it][2025-10-20 01:37:23,509] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:00:24<4:29:13,  4.09s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.5805314183235168, 'learning_rate': 3.346610169491526e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:00:24<4:29:13,  4.09s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:00:27<4:18:04,  3.92s/it]                                                       {'loss': 0.1365, 'grad_norm': 5.689767360687256, 'learning_rate': 3.345762711864407e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:00:27<4:18:04,  3.92s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:00:31<4:06:59,  3.75s/it]                                                       {'loss': 0.0379, 'grad_norm': 7.000154972076416, 'learning_rate': 3.344915254237288e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:00:31<4:06:59,  3.75s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:00:34<3:59:45,  3.65s/it]                                                       {'loss': 0.0159, 'grad_norm': 1.781189203262329, 'learning_rate': 3.3440677966101694e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:00:34<3:59:45,  3.65s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:00:38<4:00:33,  3.66s/it]                                                       {'loss': 0.2762, 'grad_norm': 6.447586536407471, 'learning_rate': 3.3432203389830505e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:00:38<4:00:33,  3.66s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:00:41<3:54:40,  3.57s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.4952460527420044, 'learning_rate': 3.342372881355932e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:00:41<3:54:40,  3.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:00:45<4:07:52,  3.77s/it]                                                       {'loss': 0.0952, 'grad_norm': 7.561385631561279, 'learning_rate': 3.3415254237288134e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:00:45<4:07:52,  3.77s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:00:49<3:59:52,  3.65s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.4653015732765198, 'learning_rate': 3.340677966101695e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:00:49<3:59:52,  3.65s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:00:52<3:53:40,  3.56s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.5473213195800781, 'learning_rate': 3.3398305084745764e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:00:52<3:53:40,  3.56s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:00:55<3:50:56,  3.52s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.24483740329742432, 'learning_rate': 3.338983050847458e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:00:55<3:50:56,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:00:59<3:49:42,  3.50s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8681411743164062, 'learning_rate': 3.338135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:00:59<3:49:42,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:01:02<3:46:58,  3.46s/it]                                                       {'loss': 0.0737, 'grad_norm': 3.9886608123779297, 'learning_rate': 3.3372881355932204e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:01:02<3:46:58,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:01:06<3:46:04,  3.45s/it]                                                       {'loss': 0.049, 'grad_norm': 4.174988269805908, 'learning_rate': 3.3364406779661016e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:01:06<3:46:04,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:01:09<3:46:17,  3.45s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.6345763206481934, 'learning_rate': 3.3355932203389834e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:01:09<3:46:17,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:01:13<3:53:11,  3.56s/it]                                                       {'loss': 0.1357, 'grad_norm': 5.970787048339844, 'learning_rate': 3.3347457627118645e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:01:13<3:53:11,  3.56s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:01:17<4:02:09,  3.69s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04823387786746025, 'learning_rate': 3.333898305084746e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:01:17<4:02:09,  3.69s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:01:20<3:57:15,  3.62s/it]                                                       {'loss': 0.0203, 'grad_norm': 3.0158748626708984, 'learning_rate': 3.3330508474576274e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:01:20<3:57:15,  3.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:01:24<3:52:02,  3.54s/it]                                                       {'loss': 0.2418, 'grad_norm': 10.413482666015625, 'learning_rate': 3.3322033898305086e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:01:24<3:52:02,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:01:28<4:06:28,  3.76s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.468980312347412, 'learning_rate': 3.33135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:01:28<4:06:28,  3.76s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:01:31<3:59:57,  3.66s/it]                                                       {'loss': 0.2529, 'grad_norm': 8.700337409973145, 'learning_rate': 3.3305084745762715e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:01:31<3:59:57,  3.66s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:01:35<3:54:50,  3.59s/it]                                                       {'loss': 0.0906, 'grad_norm': 6.699169635772705, 'learning_rate': 3.3296610169491526e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:01:35<3:54:50,  3.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:01:38<3:52:16,  3.55s/it]                                                       {'loss': 0.0742, 'grad_norm': 4.036304950714111, 'learning_rate': 3.3288135593220344e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:01:38<3:52:16,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:01:42<3:48:32,  3.49s/it]                                                       {'loss': 0.0545, 'grad_norm': 5.744780540466309, 'learning_rate': 3.3279661016949156e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:01:42<3:48:32,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:01:45<3:52:37,  3.56s/it]                                                       {'loss': 0.0204, 'grad_norm': 2.801501989364624, 'learning_rate': 3.327118644067797e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:01:45<3:52:37,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:01:49<3:53:35,  3.57s/it]                                                       {'loss': 0.1063, 'grad_norm': 7.647755146026611, 'learning_rate': 3.326271186440678e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:01:49<3:53:35,  3.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:01:52<3:49:33,  3.51s/it]                                                       {'loss': 0.1196, 'grad_norm': 6.551612377166748, 'learning_rate': 3.325423728813559e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:01:52<3:49:33,  3.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:01:56<3:47:50,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04163270816206932, 'learning_rate': 3.324576271186441e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:01:56<3:47:50,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:01:59<3:46:14,  3.46s/it]                                                       {'loss': 0.1774, 'grad_norm': 7.333844184875488, 'learning_rate': 3.323728813559322e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:01:59<3:46:14,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:02:03<3:44:17,  3.43s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.023447806015610695, 'learning_rate': 3.322881355932204e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:02:03<3:44:17,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:02:06<3:43:27,  3.42s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.7774269580841064, 'learning_rate': 3.322033898305085e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:02:06<3:43:27,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:02:09<3:41:12,  3.39s/it]                                                       {'loss': 0.0928, 'grad_norm': 8.034878730773926, 'learning_rate': 3.3211864406779666e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:02:09<3:41:12,  3.39s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:02:13<3:42:00,  3.40s/it]                                                       {'loss': 0.012, 'grad_norm': 0.9967741370201111, 'learning_rate': 3.320338983050848e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:02:13<3:42:00,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:02:16<3:39:48,  3.37s/it]                                                       {'loss': 0.0132, 'grad_norm': 2.315582513809204, 'learning_rate': 3.319491525423729e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:02:16<3:39:48,  3.37s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:02:19<3:39:17,  3.36s/it]                                                       {'loss': 0.0528, 'grad_norm': 5.312265396118164, 'learning_rate': 3.31864406779661e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:02:19<3:39:17,  3.36s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:02:23<3:42:25,  3.41s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.0060184001922607, 'learning_rate': 3.317796610169492e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:02:23<3:42:25,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:02:26<3:43:42,  3.43s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.719929039478302, 'learning_rate': 3.316949152542373e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:02:26<3:43:42,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:02:30<3:50:45,  3.54s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3648707866668701, 'learning_rate': 3.316101694915255e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:02:30<3:50:45,  3.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:02:33<3:46:11,  3.47s/it]                                                       {'loss': 0.0519, 'grad_norm': 5.350907802581787, 'learning_rate': 3.315254237288136e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:02:33<3:46:11,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:02:37<3:43:35,  3.43s/it]                                                       {'loss': 0.0626, 'grad_norm': 5.290017127990723, 'learning_rate': 3.314406779661017e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:02:37<3:43:35,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:02:40<3:44:41,  3.45s/it]                                                       {'loss': 0.1025, 'grad_norm': 7.095948219299316, 'learning_rate': 3.313559322033898e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:02:40<3:44:41,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:02:44<3:43:17,  3.43s/it]                                                       {'loss': 0.0254, 'grad_norm': 3.3989195823669434, 'learning_rate': 3.31271186440678e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:02:44<3:43:17,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:02:47<3:43:07,  3.43s/it]                                                       {'loss': 0.0839, 'grad_norm': 6.8769426345825195, 'learning_rate': 3.311864406779661e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:02:47<3:43:07,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:02:51<3:43:47,  3.44s/it]                                                       {'loss': 0.0815, 'grad_norm': 7.230264186859131, 'learning_rate': 3.311016949152543e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:02:51<3:43:47,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:02:54<3:45:13,  3.46s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.1794216632843018, 'learning_rate': 3.310169491525424e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:02:54<3:45:13,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:02:58<3:53:25,  3.59s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.21764418482780457, 'learning_rate': 3.309322033898305e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:02:58<3:53:25,  3.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:03:01<3:50:07,  3.54s/it]                                                       {'loss': 0.0746, 'grad_norm': 4.392389297485352, 'learning_rate': 3.308474576271187e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:03:01<3:50:07,  3.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:03:05<3:56:38,  3.64s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.268093466758728, 'learning_rate': 3.3076271186440674e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:03:05<3:56:38,  3.64s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:03:09<3:53:01,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.042443711310625076, 'learning_rate': 3.306779661016949e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:03:09<3:53:01,  3.58s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:03:12<3:54:55,  3.61s/it]                                                       {'loss': 0.021, 'grad_norm': 2.770415782928467, 'learning_rate': 3.30593220338983e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:03:12<3:54:55,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:03:16<3:51:00,  3.55s/it]                                                       {'loss': 0.0887, 'grad_norm': 7.430176258087158, 'learning_rate': 3.305084745762712e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:03:16<3:51:00,  3.55s/it][2025-10-20 01:40:21,121] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:03:22<4:33:09,  4.20s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.32589462399482727, 'learning_rate': 3.304237288135593e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:03:22<4:33:09,  4.20s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:03:25<4:16:20,  3.95s/it]                                                       {'loss': 0.0628, 'grad_norm': 6.037868022918701, 'learning_rate': 3.303389830508475e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:03:25<4:16:20,  3.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:03:28<4:03:56,  3.76s/it]                                                       {'loss': 0.005, 'grad_norm': 1.1429051160812378, 'learning_rate': 3.302542372881356e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:03:28<4:03:56,  3.76s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:03:32<3:56:35,  3.64s/it]                                                       {'loss': 0.0859, 'grad_norm': 6.027826309204102, 'learning_rate': 3.301694915254237e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:03:32<3:56:35,  3.64s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:03:35<3:54:08,  3.61s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08527624607086182, 'learning_rate': 3.3008474576271184e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:03:35<3:54:08,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:03:38<3:47:33,  3.51s/it]                                                       {'loss': 0.0926, 'grad_norm': 7.338180065155029, 'learning_rate': 3.3e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:03:38<3:47:33,  3.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:03:42<3:46:21,  3.49s/it]                                                       {'loss': 0.0146, 'grad_norm': 1.6382571458816528, 'learning_rate': 3.2991525423728814e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:03:42<3:46:21,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:03:45<3:45:06,  3.47s/it]                                                       {'loss': 0.2126, 'grad_norm': 7.711775302886963, 'learning_rate': 3.298305084745763e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:03:45<3:45:06,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:03:49<3:45:49,  3.48s/it]                                                       {'loss': 0.2883, 'grad_norm': 6.788230895996094, 'learning_rate': 3.297457627118644e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:03:49<3:45:49,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:03:53<3:53:35,  3.60s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.40043941140174866, 'learning_rate': 3.296610169491526e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:03:53<3:53:35,  3.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:03:56<3:50:52,  3.56s/it]                                                       {'loss': 0.0669, 'grad_norm': 6.75032901763916, 'learning_rate': 3.2957627118644066e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:03:56<3:50:52,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:04:00<3:53:38,  3.61s/it]                                                       {'loss': 0.3323, 'grad_norm': 8.595616340637207, 'learning_rate': 3.2949152542372884e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:04:00<3:53:38,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:04:03<3:50:04,  3.55s/it]                                                       {'loss': 0.0453, 'grad_norm': 5.651552200317383, 'learning_rate': 3.2940677966101695e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:04:03<3:50:04,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:04:07<3:45:39,  3.48s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.679027795791626, 'learning_rate': 3.293220338983051e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:04:07<3:45:39,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:04:10<3:42:53,  3.44s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1780550628900528, 'learning_rate': 3.2923728813559324e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:04:10<3:42:53,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:04:13<3:43:08,  3.45s/it]                                                       {'loss': 0.0198, 'grad_norm': 3.015516757965088, 'learning_rate': 3.2915254237288136e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:04:13<3:43:08,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:04:17<3:42:27,  3.44s/it]                                                       {'loss': 0.3371, 'grad_norm': 8.856647491455078, 'learning_rate': 3.2906779661016954e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:04:17<3:42:27,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:04:20<3:44:14,  3.47s/it]                                                       {'loss': 0.0393, 'grad_norm': 4.735086917877197, 'learning_rate': 3.2898305084745765e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:04:20<3:44:14,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:04:24<3:44:43,  3.47s/it]                                                       {'loss': 0.0296, 'grad_norm': 2.295480251312256, 'learning_rate': 3.2889830508474576e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:04:24<3:44:43,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:04:27<3:43:23,  3.45s/it]                                                       {'loss': 0.0555, 'grad_norm': 5.034477233886719, 'learning_rate': 3.288135593220339e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:04:27<3:43:23,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:04:31<3:42:20,  3.44s/it]                                                       {'loss': 0.1084, 'grad_norm': 7.1125969886779785, 'learning_rate': 3.2872881355932206e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:04:31<3:42:20,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:04:35<3:53:36,  3.61s/it]                                                       {'loss': 0.0856, 'grad_norm': 6.952017307281494, 'learning_rate': 3.286440677966102e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:04:35<3:53:36,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:04:38<3:51:24,  3.58s/it]                                                       {'loss': 0.0783, 'grad_norm': 5.382993221282959, 'learning_rate': 3.2855932203389835e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:04:38<3:51:24,  3.58s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:04:41<3:46:13,  3.50s/it]                                                       {'loss': 0.2193, 'grad_norm': 8.115507125854492, 'learning_rate': 3.2847457627118646e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:04:41<3:46:13,  3.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:04:45<3:43:13,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.022857647389173508, 'learning_rate': 3.283898305084746e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:04:45<3:43:13,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:04:48<3:41:18,  3.43s/it]                                                       {'loss': 0.006, 'grad_norm': 1.0998892784118652, 'learning_rate': 3.283050847457627e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:04:48<3:41:18,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:04:52<3:41:15,  3.43s/it]                                                       {'loss': 0.0677, 'grad_norm': 5.270834922790527, 'learning_rate': 3.282203389830509e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:04:52<3:41:15,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:04:55<3:39:37,  3.40s/it]                                                       {'loss': 0.1571, 'grad_norm': 5.04660701751709, 'learning_rate': 3.28135593220339e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:04:55<3:39:37,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:04:58<3:39:05,  3.40s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.21117271482944489, 'learning_rate': 3.2805084745762716e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:04:58<3:39:05,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:05:02<3:37:16,  3.37s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.402138352394104, 'learning_rate': 3.279661016949153e-05, 'epoch': 0.35}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:05:02<3:37:16,  3.37s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:05:05<3:38:38,  3.39s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03459636867046356, 'learning_rate': 3.2788135593220346e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:05:05<3:38:38,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:05:09<3:40:50,  3.43s/it]                                                       {'loss': 0.0137, 'grad_norm': 1.4352424144744873, 'learning_rate': 3.277966101694916e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:05:09<3:40:50,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:05:12<3:50:33,  3.58s/it]                                                       {'loss': 0.0383, 'grad_norm': 4.19255256652832, 'learning_rate': 3.277118644067797e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:05:13<3:50:33,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:05:16<3:46:46,  3.52s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4580451250076294, 'learning_rate': 3.276271186440678e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:05:16<3:46:46,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:05:19<3:43:01,  3.46s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.720885992050171, 'learning_rate': 3.27542372881356e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:05:19<3:43:01,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:05:23<3:44:11,  3.48s/it]                                                       {'loss': 0.0593, 'grad_norm': 5.899909496307373, 'learning_rate': 3.274576271186441e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:05:23<3:44:11,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:05:26<3:42:47,  3.46s/it]                                                       {'loss': 0.0205, 'grad_norm': 4.293396472930908, 'learning_rate': 3.273728813559322e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:05:26<3:42:47,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:05:30<3:40:49,  3.43s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.8954833745956421, 'learning_rate': 3.272881355932204e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:05:30<3:40:49,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:05:33<3:38:39,  3.40s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.8774840831756592, 'learning_rate': 3.272033898305085e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:05:33<3:38:39,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:05:36<3:38:10,  3.39s/it]                                                       {'loss': 0.3502, 'grad_norm': 11.199098587036133, 'learning_rate': 3.271186440677966e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:05:36<3:38:10,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:05:40<3:39:00,  3.41s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12455291301012039, 'learning_rate': 3.270338983050847e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:05:40<3:39:00,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:05:43<3:40:38,  3.43s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.7626107931137085, 'learning_rate': 3.269491525423729e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:05:43<3:40:38,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:05:47<3:46:36,  3.53s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.1415579319000244, 'learning_rate': 3.26864406779661e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:05:47<3:46:36,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:05:50<3:44:06,  3.49s/it]                                                       {'loss': 0.0762, 'grad_norm': 5.960063457489014, 'learning_rate': 3.267796610169492e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:05:50<3:44:06,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:05:54<3:42:30,  3.46s/it]                                                       {'loss': 0.0731, 'grad_norm': 6.538580417633057, 'learning_rate': 3.266949152542373e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:05:54<3:42:30,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:05:57<3:40:57,  3.44s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.8552372455596924, 'learning_rate': 3.266101694915254e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:05:57<3:40:57,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:06:00<3:40:05,  3.43s/it]                                                       {'loss': 0.0426, 'grad_norm': 5.237875461578369, 'learning_rate': 3.265254237288135e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:06:00<3:40:05,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:06:04<3:41:11,  3.45s/it]                                                       {'loss': 0.3295, 'grad_norm': 7.012349605560303, 'learning_rate': 3.264406779661017e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:06:04<3:41:11,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:06:07<3:41:03,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07083982974290848, 'learning_rate': 3.263559322033898e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:06:07<3:41:03,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:06:11<3:39:04,  3.41s/it]                                                       {'loss': 0.2699, 'grad_norm': 8.048493385314941, 'learning_rate': 3.26271186440678e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:06:11<3:39:04,  3.41s/it][2025-10-20 01:43:16,069] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:06:17<4:31:09,  4.23s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13008441030979156, 'learning_rate': 3.261864406779661e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:06:17<4:31:09,  4.23s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:06:20<4:14:51,  3.97s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.24234947562217712, 'learning_rate': 3.261016949152543e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:06:20<4:14:51,  3.97s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:06:24<4:03:11,  3.79s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.5977068543434143, 'learning_rate': 3.260169491525424e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:06:24<4:03:11,  3.79s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:06:27<3:58:32,  3.72s/it]                                                       {'loss': 0.002, 'grad_norm': 0.32698529958724976, 'learning_rate': 3.259322033898305e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:06:27<3:58:32,  3.72s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:06:31<3:52:22,  3.63s/it]                                                       {'loss': 0.0194, 'grad_norm': 3.290900468826294, 'learning_rate': 3.2584745762711864e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:06:31<3:52:22,  3.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:06:34<3:46:47,  3.54s/it]                                                       {'loss': 0.0596, 'grad_norm': 5.394559383392334, 'learning_rate': 3.257627118644068e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:06:34<3:46:47,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:06:37<3:44:01,  3.50s/it]                                                       {'loss': 0.011, 'grad_norm': 1.5568702220916748, 'learning_rate': 3.256779661016949e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:06:37<3:44:01,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:06:41<3:41:39,  3.46s/it]                                                       {'loss': 0.0749, 'grad_norm': 5.888192653656006, 'learning_rate': 3.2559322033898305e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:06:41<3:41:39,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:06:44<3:41:30,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.083986297249794, 'learning_rate': 3.255084745762712e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:06:44<3:41:30,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:06:47<3:38:33,  3.41s/it]                                                       {'loss': 0.013, 'grad_norm': 2.4286465644836426, 'learning_rate': 3.2542372881355934e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:06:47<3:38:33,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:06:51<3:37:09,  3.39s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.4710936546325684, 'learning_rate': 3.2533898305084745e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:06:51<3:37:09,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:06:54<3:35:27,  3.37s/it]                                                       {'loss': 0.067, 'grad_norm': 5.950598239898682, 'learning_rate': 3.2525423728813557e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:06:54<3:35:27,  3.37s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:06:58<3:45:13,  3.52s/it]                                                       {'loss': 0.0133, 'grad_norm': 3.0158371925354004, 'learning_rate': 3.2516949152542375e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:06:58<3:45:13,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:07:01<3:40:39,  3.45s/it]                                                       {'loss': 0.0503, 'grad_norm': 2.2816414833068848, 'learning_rate': 3.2508474576271186e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:07:01<3:40:39,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:07:05<3:43:30,  3.50s/it]                                                       {'loss': 0.0267, 'grad_norm': 2.3868870735168457, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:07:05<3:43:30,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:07:08<3:41:47,  3.47s/it]                                                       {'loss': 0.0201, 'grad_norm': 3.0700526237487793, 'learning_rate': 3.2491525423728815e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:07:08<3:41:47,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:07:12<3:40:37,  3.45s/it]                                                       {'loss': 0.0488, 'grad_norm': 7.2652788162231445, 'learning_rate': 3.248305084745763e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:07:12<3:40:37,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:07:15<3:40:06,  3.45s/it]                                                       {'loss': 0.0338, 'grad_norm': 5.145215034484863, 'learning_rate': 3.247457627118644e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:07:15<3:40:06,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:07:18<3:37:56,  3.41s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.7825765013694763, 'learning_rate': 3.2466101694915256e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:07:18<3:37:56,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:07:22<3:37:16,  3.40s/it]                                                       {'loss': 0.0745, 'grad_norm': 6.134034156799316, 'learning_rate': 3.245762711864407e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:07:22<3:37:16,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:07:25<3:36:35,  3.39s/it]                                                       {'loss': 0.0555, 'grad_norm': 2.5633747577667236, 'learning_rate': 3.2449152542372885e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:07:25<3:36:35,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:07:29<3:40:48,  3.46s/it]                                                       {'loss': 0.0124, 'grad_norm': 0.7735742926597595, 'learning_rate': 3.2440677966101696e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:07:29<3:40:48,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:07:32<3:38:21,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.22082668542861938, 'learning_rate': 3.2432203389830515e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:07:32<3:38:21,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:07:36<3:41:36,  3.48s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.530048131942749, 'learning_rate': 3.2423728813559326e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:07:36<3:41:36,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:07:39<3:42:04,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1231154277920723, 'learning_rate': 3.241525423728814e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:07:39<3:42:04,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:07:43<3:40:55,  3.47s/it]                                                       {'loss': 0.1225, 'grad_norm': 8.019466400146484, 'learning_rate': 3.240677966101695e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:07:43<3:40:55,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:07:46<3:37:45,  3.42s/it]                                                       {'loss': 0.0177, 'grad_norm': 1.9770969152450562, 'learning_rate': 3.2398305084745766e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:07:46<3:37:45,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:07:50<3:40:46,  3.47s/it]                                                       {'loss': 0.0651, 'grad_norm': 5.7201313972473145, 'learning_rate': 3.238983050847458e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:07:50<3:40:46,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:07:53<3:39:14,  3.44s/it]                                                       {'loss': 0.1609, 'grad_norm': 7.12917423248291, 'learning_rate': 3.238135593220339e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:07:53<3:39:14,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:07:56<3:37:06,  3.41s/it]                                                       {'loss': 0.0579, 'grad_norm': 4.545073509216309, 'learning_rate': 3.237288135593221e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:07:56<3:37:06,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:08:00<3:37:41,  3.42s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6369453072547913, 'learning_rate': 3.236440677966102e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:08:00<3:37:41,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:08:03<3:37:46,  3.42s/it]                                                       {'loss': 0.0285, 'grad_norm': 3.518894910812378, 'learning_rate': 3.235593220338983e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:08:03<3:37:46,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:08:07<3:48:57,  3.60s/it]                                                       {'loss': 0.001, 'grad_norm': 0.07913016527891159, 'learning_rate': 3.234745762711864e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:08:07<3:48:57,  3.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:08:11<3:45:05,  3.54s/it]                                                       {'loss': 0.072, 'grad_norm': 4.571751117706299, 'learning_rate': 3.233898305084746e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:08:11<3:45:05,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:08:14<3:42:06,  3.49s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.07206558436155319, 'learning_rate': 3.233050847457627e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:08:14<3:42:06,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:08:18<3:48:45,  3.60s/it]                                                       {'loss': 0.0221, 'grad_norm': 3.369107723236084, 'learning_rate': 3.232203389830509e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:08:18<3:48:45,  3.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:08:22<3:51:29,  3.64s/it]                                                       {'loss': 0.0771, 'grad_norm': 6.841751575469971, 'learning_rate': 3.23135593220339e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:08:22<3:51:29,  3.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:08:25<3:47:16,  3.58s/it]                                                       {'loss': 0.1322, 'grad_norm': 7.70665168762207, 'learning_rate': 3.230508474576272e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:08:25<3:47:16,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:08:28<3:44:17,  3.53s/it]                                                       {'loss': 0.0754, 'grad_norm': 6.1921281814575195, 'learning_rate': 3.229661016949153e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:08:28<3:44:17,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:08:32<3:42:11,  3.50s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.6537883877754211, 'learning_rate': 3.228813559322034e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:08:32<3:42:11,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:08:35<3:40:25,  3.47s/it]                                                       {'loss': 0.2013, 'grad_norm': 8.69204044342041, 'learning_rate': 3.227966101694915e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:08:35<3:40:25,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:08:39<3:39:13,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08224914968013763, 'learning_rate': 3.227118644067797e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:08:39<3:39:13,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:08:42<3:35:43,  3.40s/it]                                                       {'loss': 0.0257, 'grad_norm': 3.7645695209503174, 'learning_rate': 3.226271186440678e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:08:42<3:35:43,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:08:45<3:38:12,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05313709005713463, 'learning_rate': 3.22542372881356e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:08:45<3:38:12,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:08:49<3:36:29,  3.41s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.107428550720215, 'learning_rate': 3.224576271186441e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:08:49<3:36:29,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:08:52<3:38:40,  3.45s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.4394955337047577, 'learning_rate': 3.223728813559322e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:08:52<3:38:40,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:08:56<3:35:53,  3.41s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3411490023136139, 'learning_rate': 3.222881355932203e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:08:56<3:35:53,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:08:59<3:35:46,  3.41s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.389669179916382, 'learning_rate': 3.222033898305085e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:08:59<3:35:46,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:09:02<3:36:02,  3.41s/it]                                                       {'loss': 0.3139, 'grad_norm': 10.691536903381348, 'learning_rate': 3.221186440677966e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:09:02<3:36:02,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:09:06<3:42:41,  3.52s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.6079853773117065, 'learning_rate': 3.2203389830508473e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:09:06<3:42:41,  3.52s/it][2025-10-20 01:46:11,566] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:09:12<4:27:57,  4.23s/it]                                                       {'loss': 0.0154, 'grad_norm': 3.225212335586548, 'learning_rate': 3.219491525423729e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:09:12<4:27:57,  4.23s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:09:16<4:12:37,  3.99s/it]                                                       {'loss': 0.1031, 'grad_norm': 4.25987434387207, 'learning_rate': 3.21864406779661e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:09:16<4:12:37,  3.99s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:09:19<4:03:28,  3.85s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.5304804444313049, 'learning_rate': 3.2177966101694914e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:09:19<4:03:28,  3.85s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:09:23<3:56:05,  3.73s/it]                                                       {'loss': 0.0677, 'grad_norm': 7.495234966278076, 'learning_rate': 3.2169491525423725e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:09:23<3:56:05,  3.73s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:09:26<3:49:54,  3.63s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0700252577662468, 'learning_rate': 3.2161016949152543e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:09:26<3:49:54,  3.63s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:09:30<4:03:31,  3.85s/it]                                                       {'loss': 0.0571, 'grad_norm': 4.866213798522949, 'learning_rate': 3.2152542372881355e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:09:30<4:03:31,  3.85s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:09:34<3:55:04,  3.72s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.0014036893844604, 'learning_rate': 3.214406779661017e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:09:34<3:55:04,  3.72s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:09:37<3:51:13,  3.66s/it]                                                       {'loss': 0.3644, 'grad_norm': 8.263716697692871, 'learning_rate': 3.2135593220338984e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:09:37<3:51:13,  3.66s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:09:41<3:46:14,  3.58s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.8190213441848755, 'learning_rate': 3.21271186440678e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:09:41<3:46:14,  3.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:09:44<3:44:37,  3.56s/it]                                                       {'loss': 0.0852, 'grad_norm': 6.120995044708252, 'learning_rate': 3.2118644067796613e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:09:44<3:44:37,  3.56s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:09:48<3:42:27,  3.52s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.2518596351146698, 'learning_rate': 3.2110169491525425e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:09:48<3:42:27,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:09:51<3:44:37,  3.56s/it]                                                       {'loss': 0.024, 'grad_norm': 3.321028709411621, 'learning_rate': 3.2101694915254236e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:09:51<3:44:37,  3.56s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:09:55<3:40:20,  3.49s/it]                                                       {'loss': 0.0769, 'grad_norm': 7.051602840423584, 'learning_rate': 3.2093220338983054e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:09:55<3:40:20,  3.49s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:09:58<3:36:58,  3.44s/it]                                                       {'loss': 0.0436, 'grad_norm': 3.6065139770507812, 'learning_rate': 3.2084745762711865e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:09:58<3:36:58,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:10:01<3:36:06,  3.43s/it]                                                       {'loss': 0.0129, 'grad_norm': 2.015751600265503, 'learning_rate': 3.2076271186440683e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:10:01<3:36:06,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:10:05<3:38:52,  3.47s/it]                                                       {'loss': 0.0371, 'grad_norm': 5.517631530761719, 'learning_rate': 3.2067796610169495e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:10:05<3:38:52,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:10:08<3:38:07,  3.46s/it]                                                       {'loss': 0.3107, 'grad_norm': 9.286564826965332, 'learning_rate': 3.2059322033898306e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:10:08<3:38:07,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:10:12<3:37:39,  3.45s/it]                                                       {'loss': 0.084, 'grad_norm': 6.084647178649902, 'learning_rate': 3.205084745762712e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:10:12<3:37:39,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:10:15<3:37:44,  3.46s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.7256120443344116, 'learning_rate': 3.2042372881355935e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:10:15<3:37:44,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:10:19<3:36:45,  3.44s/it]                                                       {'loss': 0.0165, 'grad_norm': 3.19256854057312, 'learning_rate': 3.203389830508475e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:10:19<3:36:45,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:10:22<3:37:20,  3.45s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.7648040652275085, 'learning_rate': 3.202542372881356e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:10:22<3:37:20,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:10:26<3:38:10,  3.46s/it]                                                       {'loss': 0.0252, 'grad_norm': 3.729099988937378, 'learning_rate': 3.2016949152542376e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:10:26<3:38:10,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:10:29<3:40:41,  3.51s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.16771547496318817, 'learning_rate': 3.200847457627119e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:10:29<3:40:41,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:10:32<3:36:43,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.24523726105690002, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:10:32<3:36:43,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:10:36<3:34:03,  3.40s/it]                                                       {'loss': 0.03, 'grad_norm': 4.013546943664551, 'learning_rate': 3.199152542372881e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:10:36<3:34:03,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:10:39<3:32:58,  3.39s/it]                                                       {'loss': 0.0901, 'grad_norm': 5.640030860900879, 'learning_rate': 3.198305084745763e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:10:39<3:32:58,  3.39s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:10:43<3:33:11,  3.39s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.3899791240692139, 'learning_rate': 3.197457627118644e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:10:43<3:33:11,  3.39s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:10:46<3:35:36,  3.43s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3211836814880371, 'learning_rate': 3.196610169491526e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:10:46<3:35:36,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:10:49<3:33:29,  3.40s/it]                                                       {'loss': 0.006, 'grad_norm': 1.2504645586013794, 'learning_rate': 3.195762711864407e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:10:49<3:33:29,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:10:53<3:40:05,  3.50s/it]                                                       {'loss': 0.0419, 'grad_norm': 5.175881385803223, 'learning_rate': 3.1949152542372887e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:10:53<3:40:05,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:10:57<3:40:27,  3.51s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.4527363777160645, 'learning_rate': 3.19406779661017e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:10:57<3:40:27,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:11:00<3:40:46,  3.52s/it]                                                       {'loss': 0.1175, 'grad_norm': 6.849242687225342, 'learning_rate': 3.193220338983051e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:11:00<3:40:46,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:11:04<3:37:48,  3.47s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.6289921998977661, 'learning_rate': 3.192372881355932e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:11:04<3:37:48,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:11:07<3:45:24,  3.59s/it]                                                       {'loss': 0.032, 'grad_norm': 3.153484582901001, 'learning_rate': 3.191525423728814e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:11:07<3:45:24,  3.59s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:11:11<3:40:59,  3.52s/it]                                                       {'loss': 0.2928, 'grad_norm': 9.490079879760742, 'learning_rate': 3.190677966101695e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:11:11<3:40:59,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:11:14<3:38:06,  3.48s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.020254604518413544, 'learning_rate': 3.189830508474577e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:11:14<3:38:06,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:11:18<3:37:31,  3.47s/it]                                                       {'loss': 0.1237, 'grad_norm': 8.436187744140625, 'learning_rate': 3.188983050847458e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:11:18<3:37:31,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:11:21<3:35:56,  3.44s/it]                                                       {'loss': 0.0215, 'grad_norm': 3.1987929344177246, 'learning_rate': 3.18813559322034e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:11:21<3:35:56,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:11:24<3:33:37,  3.41s/it]                                                       {'loss': 0.174, 'grad_norm': 9.1930513381958, 'learning_rate': 3.18728813559322e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:11:24<3:33:37,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:11:28<3:33:48,  3.41s/it]                                                       {'loss': 0.0684, 'grad_norm': 5.362553596496582, 'learning_rate': 3.186440677966101e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:11:28<3:33:48,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:11:31<3:32:14,  3.39s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.5823488235473633, 'learning_rate': 3.185593220338983e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:11:31<3:32:14,  3.39s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:11:35<3:39:40,  3.51s/it]                                                       {'loss': 0.0345, 'grad_norm': 5.038447856903076, 'learning_rate': 3.184745762711864e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:11:35<3:39:40,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:11:38<3:37:40,  3.48s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.1008553504943848, 'learning_rate': 3.183898305084746e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:11:38<3:37:40,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:11:42<3:39:19,  3.50s/it]                                                       {'loss': 0.1402, 'grad_norm': 7.173250675201416, 'learning_rate': 3.183050847457627e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:11:42<3:39:19,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:11:45<3:37:38,  3.48s/it]                                                       {'loss': 0.0592, 'grad_norm': 4.876887798309326, 'learning_rate': 3.182203389830509e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:11:45<3:37:38,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:11:49<3:34:56,  3.44s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.6706544160842896, 'learning_rate': 3.18135593220339e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:11:49<3:34:56,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:11:52<3:32:40,  3.40s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.034273386001587, 'learning_rate': 3.180508474576271e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:11:52<3:32:40,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:11:55<3:31:38,  3.38s/it]                                                       {'loss': 0.0415, 'grad_norm': 2.889789581298828, 'learning_rate': 3.1796610169491524e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:11:55<3:31:38,  3.38s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:11:59<3:39:44,  3.51s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.32730385661125183, 'learning_rate': 3.178813559322034e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:11:59<3:39:44,  3.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:12:02<3:38:22,  3.49s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.126056507229805, 'learning_rate': 3.177966101694915e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:12:02<3:38:22,  3.49s/it][2025-10-20 01:49:07,801] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:12:08<4:17:22,  4.12s/it]                                                       {'loss': 0.0405, 'grad_norm': 6.364994049072266, 'learning_rate': 3.177118644067797e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:12:08<4:17:22,  4.12s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:12:11<4:03:07,  3.89s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.2742173671722412, 'learning_rate': 3.176271186440678e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:12:11<4:03:07,  3.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:12:15<3:52:51,  3.73s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1305951625108719, 'learning_rate': 3.1754237288135594e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:12:15<3:52:51,  3.73s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:12:19<4:04:05,  3.91s/it]                                                       {'loss': 0.0177, 'grad_norm': 1.835269570350647, 'learning_rate': 3.1745762711864405e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:12:19<4:04:05,  3.91s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:12:22<3:54:26,  3.76s/it]                                                       {'loss': 0.1146, 'grad_norm': 5.937286376953125, 'learning_rate': 3.173728813559322e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:12:22<3:54:26,  3.76s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:12:26<3:50:48,  3.70s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.9461817741394043, 'learning_rate': 3.1728813559322034e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:12:26<3:50:48,  3.70s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:12:30<3:48:04,  3.66s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6243447065353394, 'learning_rate': 3.172033898305085e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:12:30<3:48:04,  3.66s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:12:33<3:42:59,  3.58s/it]                                                       {'loss': 0.1381, 'grad_norm': 7.525418281555176, 'learning_rate': 3.1711864406779664e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:12:33<3:42:59,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:12:36<3:39:03,  3.51s/it]                                                       {'loss': 0.0182, 'grad_norm': 2.9541842937469482, 'learning_rate': 3.170338983050848e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:12:36<3:39:03,  3.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:12:40<3:36:40,  3.48s/it]                                                       {'loss': 0.1593, 'grad_norm': 9.40812873840332, 'learning_rate': 3.169491525423729e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:12:40<3:36:40,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:12:44<3:48:30,  3.67s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.5940496921539307, 'learning_rate': 3.16864406779661e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:12:44<3:48:30,  3.67s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:12:47<3:43:54,  3.59s/it]                                                       {'loss': 0.0938, 'grad_norm': 4.219136714935303, 'learning_rate': 3.1677966101694916e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:12:47<3:43:54,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:12:51<3:43:13,  3.58s/it]                                                       {'loss': 0.2139, 'grad_norm': 8.782844543457031, 'learning_rate': 3.166949152542373e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:12:51<3:43:13,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:12:55<3:48:08,  3.66s/it]                                                       {'loss': 0.0392, 'grad_norm': 6.059482097625732, 'learning_rate': 3.1661016949152545e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:12:55<3:48:08,  3.66s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:12:58<3:45:59,  3.63s/it]                                                       {'loss': 0.042, 'grad_norm': 4.412360668182373, 'learning_rate': 3.1652542372881356e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:12:58<3:45:59,  3.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:13:02<3:41:51,  3.56s/it]                                                       {'loss': 0.0514, 'grad_norm': 5.053074836730957, 'learning_rate': 3.1644067796610174e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:13:02<3:41:51,  3.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:13:05<3:38:52,  3.52s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.026191040873527527, 'learning_rate': 3.1635593220338985e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:13:05<3:38:52,  3.52s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:13:08<3:35:30,  3.46s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.9470736980438232, 'learning_rate': 3.16271186440678e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:13:08<3:35:30,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:13:12<3:34:35,  3.45s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.008813084103167057, 'learning_rate': 3.161864406779661e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:13:12<3:34:35,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:13:16<3:43:37,  3.60s/it]                                                       {'loss': 0.0185, 'grad_norm': 2.3035616874694824, 'learning_rate': 3.1610169491525426e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:13:16<3:43:37,  3.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:13:19<3:41:39,  3.57s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.0879433155059814, 'learning_rate': 3.160169491525424e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:13:19<3:41:39,  3.57s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:13:23<3:37:27,  3.50s/it]                                                       {'loss': 0.0239, 'grad_norm': 1.9032905101776123, 'learning_rate': 3.1593220338983055e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:13:23<3:37:27,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:13:26<3:34:16,  3.45s/it]                                                       {'loss': 0.0372, 'grad_norm': 4.004210472106934, 'learning_rate': 3.158474576271187e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:13:26<3:34:16,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:13:29<3:35:55,  3.48s/it]                                                       {'loss': 0.1194, 'grad_norm': 7.970001697540283, 'learning_rate': 3.157627118644068e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:13:29<3:35:55,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:13:33<3:35:25,  3.47s/it]                                                       {'loss': 0.1004, 'grad_norm': 7.2113213539123535, 'learning_rate': 3.156779661016949e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:13:33<3:35:25,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:13:37<3:37:02,  3.50s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.018919840455055237, 'learning_rate': 3.155932203389831e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:13:37<3:37:02,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:13:40<3:34:38,  3.46s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.5659942626953125, 'learning_rate': 3.155084745762712e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:13:40<3:34:38,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:13:43<3:32:13,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2636701166629791, 'learning_rate': 3.154237288135594e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:13:43<3:32:13,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:13:47<3:30:20,  3.39s/it]                                                       {'loss': 0.0216, 'grad_norm': 3.1050000190734863, 'learning_rate': 3.153389830508475e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:13:47<3:30:20,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:13:50<3:32:02,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05290132388472557, 'learning_rate': 3.1525423728813566e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:13:50<3:32:02,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:13:53<3:30:55,  3.40s/it]                                                       {'loss': 0.0323, 'grad_norm': 4.283125400543213, 'learning_rate': 3.151694915254238e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:13:53<3:30:55,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:13:57<3:30:10,  3.39s/it]                                                       {'loss': 0.0107, 'grad_norm': 2.1534337997436523, 'learning_rate': 3.150847457627118e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:13:57<3:30:10,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:14:00<3:29:11,  3.38s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02621917612850666, 'learning_rate': 3.15e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:14:00<3:29:11,  3.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:14:03<3:29:31,  3.38s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.5282201766967773, 'learning_rate': 3.149152542372881e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:14:03<3:29:31,  3.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:14:07<3:28:49,  3.37s/it]                                                       {'loss': 0.116, 'grad_norm': 9.661396980285645, 'learning_rate': 3.148305084745763e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:14:07<3:28:49,  3.37s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:14:10<3:29:28,  3.38s/it]                                                       {'loss': 0.1313, 'grad_norm': 8.753140449523926, 'learning_rate': 3.147457627118644e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:14:10<3:29:28,  3.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:14:14<3:32:57,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.09584654122591019, 'learning_rate': 3.146610169491526e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:14:14<3:32:57,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:14:17<3:31:31,  3.42s/it]                                                       {'loss': 0.0981, 'grad_norm': 6.446646213531494, 'learning_rate': 3.145762711864407e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:14:17<3:31:31,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:14:21<3:30:46,  3.41s/it]                                                       {'loss': 0.1181, 'grad_norm': 7.493841648101807, 'learning_rate': 3.144915254237288e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:14:21<3:30:46,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:14:24<3:37:57,  3.53s/it]                                                       {'loss': 0.0431, 'grad_norm': 4.441740036010742, 'learning_rate': 3.144067796610169e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:14:24<3:37:57,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:14:28<3:34:22,  3.47s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.8911837339401245, 'learning_rate': 3.143220338983051e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:14:28<3:34:22,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:14:31<3:31:42,  3.43s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.582257091999054, 'learning_rate': 3.142372881355932e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:14:31<3:31:42,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:14:34<3:30:50,  3.41s/it]                                                       {'loss': 0.0789, 'grad_norm': 2.6160285472869873, 'learning_rate': 3.141525423728814e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:14:34<3:30:50,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:14:38<3:31:46,  3.43s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.5846785306930542, 'learning_rate': 3.140677966101695e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:14:38<3:31:46,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:14:41<3:31:53,  3.43s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.5432820320129395, 'learning_rate': 3.139830508474577e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:14:41<3:31:53,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:14:45<3:35:38,  3.49s/it]                                                       {'loss': 0.1498, 'grad_norm': 8.162221908569336, 'learning_rate': 3.1389830508474574e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:14:45<3:35:38,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:14:49<3:40:39,  3.58s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.4182326793670654, 'learning_rate': 3.138135593220339e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:14:49<3:40:39,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:14:53<3:53:59,  3.79s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.45962998270988464, 'learning_rate': 3.13728813559322e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:14:53<3:53:59,  3.79s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:14:56<3:47:22,  3.69s/it]                                                       {'loss': 0.1064, 'grad_norm': 4.607986927032471, 'learning_rate': 3.136440677966102e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:14:56<3:47:22,  3.69s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:15:00<3:40:44,  3.58s/it]                                                       {'loss': 0.038, 'grad_norm': 4.376086235046387, 'learning_rate': 3.135593220338983e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:15:00<3:40:44,  3.58s/it][2025-10-20 01:52:05,117] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:15:05<4:18:22,  4.19s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03632907196879387, 'learning_rate': 3.134745762711865e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:15:05<4:18:22,  4.19s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:15:09<4:02:10,  3.93s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2688530385494232, 'learning_rate': 3.133898305084746e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:15:09<4:02:10,  3.93s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:15:12<3:49:44,  3.73s/it]                                                       {'loss': 0.1905, 'grad_norm': 7.27604341506958, 'learning_rate': 3.133050847457627e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:15:12<3:49:44,  3.73s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:15:15<3:43:11,  3.62s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.24246002733707428, 'learning_rate': 3.1322033898305084e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:15:15<3:43:11,  3.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:15:19<3:41:32,  3.60s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.21917624771595, 'learning_rate': 3.1313559322033896e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:15:19<3:41:32,  3.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:15:22<3:38:53,  3.56s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.15097728371620178, 'learning_rate': 3.1305084745762714e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:15:22<3:38:53,  3.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:15:26<3:44:52,  3.65s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.5208717584609985, 'learning_rate': 3.1296610169491525e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:15:26<3:44:52,  3.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:15:30<3:40:11,  3.58s/it]                                                       {'loss': 0.0559, 'grad_norm': 5.558876037597656, 'learning_rate': 3.128813559322034e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:15:30<3:40:11,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:15:33<3:36:09,  3.51s/it]                                                       {'loss': 0.2675, 'grad_norm': 8.647773742675781, 'learning_rate': 3.1279661016949154e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:15:33<3:36:09,  3.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:15:36<3:33:53,  3.48s/it]                                                       {'loss': 0.1489, 'grad_norm': 6.844732284545898, 'learning_rate': 3.1271186440677966e-05, 'epoch': 0.39}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:15:36<3:33:53,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:15:40<3:31:45,  3.44s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.607764482498169, 'learning_rate': 3.126271186440678e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:15:40<3:31:45,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:15:43<3:30:21,  3.42s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.33791881799697876, 'learning_rate': 3.1254237288135595e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:15:43<3:30:21,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:15:47<3:31:22,  3.44s/it]                                                       {'loss': 0.0244, 'grad_norm': 2.419506788253784, 'learning_rate': 3.1245762711864406e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:15:47<3:31:22,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:15:50<3:30:31,  3.43s/it]                                                       {'loss': 0.0167, 'grad_norm': 1.1395045518875122, 'learning_rate': 3.1237288135593224e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:15:50<3:30:31,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:15:53<3:30:41,  3.43s/it]                                                       {'loss': 0.0159, 'grad_norm': 1.4658738374710083, 'learning_rate': 3.1228813559322036e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:15:53<3:30:41,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:15:57<3:28:54,  3.40s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.8132773637771606, 'learning_rate': 3.1220338983050854e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:15:57<3:28:54,  3.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:16:00<3:26:34,  3.37s/it]                                                       {'loss': 0.3479, 'grad_norm': 9.620475769042969, 'learning_rate': 3.1211864406779665e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:16:00<3:26:34,  3.37s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:16:03<3:25:30,  3.35s/it]                                                       {'loss': 0.0263, 'grad_norm': 4.602226734161377, 'learning_rate': 3.1203389830508476e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:16:03<3:25:30,  3.35s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:16:07<3:25:55,  3.36s/it]                                                       {'loss': 0.2195, 'grad_norm': 6.453204154968262, 'learning_rate': 3.119491525423729e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:16:07<3:25:55,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:16:10<3:30:20,  3.43s/it]                                                       {'loss': 0.0457, 'grad_norm': 6.270782470703125, 'learning_rate': 3.1186440677966106e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:16:10<3:30:20,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:16:14<3:28:55,  3.41s/it]                                                       {'loss': 0.08, 'grad_norm': 5.97509241104126, 'learning_rate': 3.117796610169492e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:16:14<3:28:55,  3.41s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:16:17<3:27:05,  3.38s/it]                                                       {'loss': 0.0287, 'grad_norm': 4.10959005355835, 'learning_rate': 3.1169491525423735e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:16:17<3:27:05,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:16:20<3:28:38,  3.40s/it]                                                       {'loss': 0.2279, 'grad_norm': 8.570829391479492, 'learning_rate': 3.1161016949152546e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:16:20<3:28:38,  3.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:16:24<3:27:29,  3.39s/it]                                                       {'loss': 0.0426, 'grad_norm': 4.927595615386963, 'learning_rate': 3.115254237288136e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:16:24<3:27:29,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:16:27<3:26:56,  3.38s/it]                                                       {'loss': 0.0572, 'grad_norm': 4.58259391784668, 'learning_rate': 3.114406779661017e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:16:27<3:26:56,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:16:31<3:26:45,  3.38s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3839819133281708, 'learning_rate': 3.113559322033898e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:16:31<3:26:45,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:16:34<3:25:44,  3.36s/it]                                                       {'loss': 0.0932, 'grad_norm': 8.2304048538208, 'learning_rate': 3.11271186440678e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:16:34<3:25:44,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:16:37<3:25:24,  3.36s/it]                                                       {'loss': 0.2177, 'grad_norm': 11.480177879333496, 'learning_rate': 3.111864406779661e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:16:37<3:25:24,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:16:42<3:56:43,  3.87s/it]                                                       {'loss': 0.0695, 'grad_norm': 6.760621547698975, 'learning_rate': 3.111016949152543e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:16:42<3:56:43,  3.87s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:16:46<3:46:15,  3.70s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.1169116497039795, 'learning_rate': 3.110169491525424e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:16:46<3:46:15,  3.70s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:16:49<3:40:38,  3.61s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.049144163727760315, 'learning_rate': 3.109322033898305e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:16:49<3:40:38,  3.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:16:52<3:35:43,  3.53s/it]                                                       {'loss': 0.0105, 'grad_norm': 0.987927258014679, 'learning_rate': 3.108474576271186e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:16:52<3:35:43,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:16:56<3:31:58,  3.47s/it]                                                       {'loss': 0.0225, 'grad_norm': 3.7379181385040283, 'learning_rate': 3.107627118644068e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:16:56<3:31:58,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:16:59<3:30:35,  3.45s/it]                                                       {'loss': 0.0947, 'grad_norm': 5.151671886444092, 'learning_rate': 3.106779661016949e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:16:59<3:30:35,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:17:02<3:29:31,  3.43s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3917890787124634, 'learning_rate': 3.105932203389831e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:17:02<3:29:31,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:17:06<3:28:40,  3.42s/it]                                                       {'loss': 0.1558, 'grad_norm': 5.493077754974365, 'learning_rate': 3.105084745762712e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:17:06<3:28:40,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:17:10<3:34:31,  3.51s/it]                                                       {'loss': 0.1321, 'grad_norm': 6.809962272644043, 'learning_rate': 3.104237288135594e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:17:10<3:34:31,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:17:13<3:40:46,  3.62s/it]                                                       {'loss': 0.199, 'grad_norm': 9.435534477233887, 'learning_rate': 3.103389830508475e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:17:13<3:40:46,  3.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:17:17<3:36:15,  3.54s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.6233456134796143, 'learning_rate': 3.102542372881356e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:17:17<3:36:15,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:17:20<3:34:15,  3.51s/it]                                                       {'loss': 0.0476, 'grad_norm': 5.662027359008789, 'learning_rate': 3.101694915254237e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:17:20<3:34:15,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:17:24<3:32:53,  3.49s/it]                                                       {'loss': 0.072, 'grad_norm': 7.619469165802002, 'learning_rate': 3.100847457627119e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:17:24<3:32:53,  3.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:17:28<3:41:29,  3.63s/it]                                                       {'loss': 0.052, 'grad_norm': 7.049005031585693, 'learning_rate': 3.1e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:17:28<3:41:29,  3.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:17:31<3:37:50,  3.57s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.06752478331327438, 'learning_rate': 3.099152542372882e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:17:31<3:37:50,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:17:35<3:36:21,  3.55s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.3091527819633484, 'learning_rate': 3.098305084745763e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:17:35<3:36:21,  3.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:17:38<3:34:12,  3.52s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.7799007892608643, 'learning_rate': 3.097457627118644e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:17:38<3:34:12,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:17:41<3:32:08,  3.48s/it]                                                       {'loss': 0.3409, 'grad_norm': 9.971174240112305, 'learning_rate': 3.096610169491525e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:17:41<3:32:08,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:17:45<3:33:28,  3.51s/it]                                                       {'loss': 0.0852, 'grad_norm': 8.28652286529541, 'learning_rate': 3.0957627118644065e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:17:45<3:33:28,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:17:48<3:30:28,  3.46s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.5151294469833374, 'learning_rate': 3.094915254237288e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:17:48<3:30:28,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:17:52<3:35:07,  3.54s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03221627697348595, 'learning_rate': 3.0940677966101694e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:17:52<3:35:07,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:17:56<3:39:59,  3.62s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.25592929124832153, 'learning_rate': 3.093220338983051e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:17:56<3:39:59,  3.62s/it][2025-10-20 01:55:01,181] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:18:02<4:18:51,  4.26s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.43251290917396545, 'learning_rate': 3.092372881355932e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:18:02<4:18:51,  4.26s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:18:05<4:04:37,  4.02s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.10983383655548096, 'learning_rate': 3.091525423728814e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:18:05<4:04:37,  4.02s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:18:09<4:00:57,  3.96s/it]                                                       {'loss': 0.1268, 'grad_norm': 7.8754143714904785, 'learning_rate': 3.0906779661016946e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:18:09<4:00:57,  3.96s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:18:12<3:53:25,  3.84s/it]                                                       {'loss': 0.1362, 'grad_norm': 6.607390880584717, 'learning_rate': 3.0898305084745764e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:18:12<3:53:25,  3.84s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:18:16<3:53:54,  3.85s/it]                                                       {'loss': 0.1048, 'grad_norm': 7.855776309967041, 'learning_rate': 3.0889830508474575e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:18:16<3:53:54,  3.85s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:18:20<3:56:16,  3.89s/it]                                                       {'loss': 0.1352, 'grad_norm': 7.984762668609619, 'learning_rate': 3.088135593220339e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:18:20<3:56:16,  3.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:18:24<3:48:06,  3.76s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011378359980881214, 'learning_rate': 3.0872881355932205e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:18:24<3:48:06,  3.76s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:18:27<3:41:02,  3.64s/it]                                                       {'loss': 0.0184, 'grad_norm': 1.4819233417510986, 'learning_rate': 3.086440677966102e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:18:27<3:41:02,  3.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:18:31<3:37:37,  3.59s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3044901490211487, 'learning_rate': 3.0855932203389834e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:18:31<3:37:37,  3.59s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:18:34<3:38:43,  3.61s/it]                                                       {'loss': 0.1276, 'grad_norm': 7.084944248199463, 'learning_rate': 3.0847457627118645e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:18:34<3:38:43,  3.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:18:38<3:41:02,  3.64s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0439140610396862, 'learning_rate': 3.0838983050847456e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:18:38<3:41:02,  3.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:18:41<3:36:21,  3.57s/it]                                                       {'loss': 0.0248, 'grad_norm': 1.7357743978500366, 'learning_rate': 3.0830508474576275e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:18:41<3:36:21,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:18:45<3:35:14,  3.55s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.2969763278961182, 'learning_rate': 3.0822033898305086e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:18:45<3:35:14,  3.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:18:48<3:32:54,  3.51s/it]                                                       {'loss': 0.087, 'grad_norm': 6.362093925476074, 'learning_rate': 3.0813559322033904e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:18:48<3:32:54,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:18:52<3:34:35,  3.54s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1446141004562378, 'learning_rate': 3.0805084745762715e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:18:52<3:34:35,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:18:55<3:32:07,  3.50s/it]                                                       {'loss': 0.0245, 'grad_norm': 2.9889988899230957, 'learning_rate': 3.0796610169491526e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:18:55<3:32:07,  3.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:18:59<3:30:01,  3.47s/it]                                                       {'loss': 0.0235, 'grad_norm': 2.0065314769744873, 'learning_rate': 3.078813559322034e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:18:59<3:30:01,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:19:02<3:29:39,  3.46s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1947719156742096, 'learning_rate': 3.077966101694915e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:19:02<3:29:39,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:19:06<3:30:55,  3.49s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.8400140404701233, 'learning_rate': 3.077118644067797e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:19:06<3:30:55,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:19:09<3:29:10,  3.46s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08955738693475723, 'learning_rate': 3.076271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:19:09<3:29:10,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:19:12<3:27:16,  3.43s/it]                                                       {'loss': 0.02, 'grad_norm': 3.385999917984009, 'learning_rate': 3.0754237288135596e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:19:12<3:27:16,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:19:16<3:25:47,  3.40s/it]                                                       {'loss': 0.177, 'grad_norm': 12.10427188873291, 'learning_rate': 3.074576271186441e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:19:16<3:25:47,  3.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:19:19<3:28:09,  3.44s/it]                                                       {'loss': 0.0458, 'grad_norm': 2.8918302059173584, 'learning_rate': 3.0737288135593226e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:19:19<3:28:09,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:19:23<3:26:44,  3.42s/it]                                                       {'loss': 0.0726, 'grad_norm': 5.832653045654297, 'learning_rate': 3.072881355932204e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:19:23<3:26:44,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:19:26<3:27:57,  3.44s/it]                                                       {'loss': 0.0648, 'grad_norm': 6.73342227935791, 'learning_rate': 3.072033898305085e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:19:26<3:27:57,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:19:30<3:27:27,  3.43s/it]                                                       {'loss': 0.0374, 'grad_norm': 3.580627202987671, 'learning_rate': 3.071186440677966e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:19:30<3:27:27,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:19:33<3:28:01,  3.45s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.4536428153514862, 'learning_rate': 3.070338983050848e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:19:33<3:28:01,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:19:37<3:27:50,  3.44s/it]                                                       {'loss': 0.0084, 'grad_norm': 2.1025145053863525, 'learning_rate': 3.069491525423729e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:19:37<3:27:50,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:19:40<3:26:36,  3.42s/it]                                                       {'loss': 0.0157, 'grad_norm': 2.5002384185791016, 'learning_rate': 3.068644067796611e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:19:40<3:26:36,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:19:43<3:25:41,  3.41s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.072352409362793, 'learning_rate': 3.067796610169492e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:19:43<3:25:41,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:19:47<3:24:41,  3.39s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.3503966331481934, 'learning_rate': 3.066949152542373e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:19:47<3:24:41,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:19:50<3:27:28,  3.44s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3422081470489502, 'learning_rate': 3.066101694915254e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:19:50<3:27:28,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:19:54<3:26:07,  3.42s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.1216751337051392, 'learning_rate': 3.065254237288136e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:19:54<3:26:07,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:19:57<3:25:31,  3.41s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2443668693304062, 'learning_rate': 3.064406779661017e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:19:57<3:25:31,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:20:00<3:24:01,  3.39s/it]                                                       {'loss': 0.0722, 'grad_norm': 5.641211986541748, 'learning_rate': 3.063559322033899e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:20:00<3:24:01,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:20:04<3:24:25,  3.39s/it]                                                       {'loss': 0.0344, 'grad_norm': 4.1269659996032715, 'learning_rate': 3.06271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:20:04<3:24:25,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:20:07<3:28:10,  3.46s/it]                                                       {'loss': 0.1599, 'grad_norm': 8.262153625488281, 'learning_rate': 3.061864406779661e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:20:07<3:28:10,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:20:11<3:28:23,  3.46s/it]                                                       {'loss': 0.1786, 'grad_norm': 7.209726810455322, 'learning_rate': 3.061016949152543e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:20:11<3:28:23,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:20:14<3:26:16,  3.43s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.1163053512573242, 'learning_rate': 3.0601694915254233e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:20:14<3:26:16,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:20:18<3:27:17,  3.45s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4311464726924896, 'learning_rate': 3.059322033898305e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:20:18<3:27:17,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:20:21<3:26:50,  3.44s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.2478899955749512, 'learning_rate': 3.058474576271186e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:20:21<3:26:50,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:20:25<3:27:35,  3.45s/it]                                                       {'loss': 0.1569, 'grad_norm': 6.567989826202393, 'learning_rate': 3.057627118644068e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:20:25<3:27:35,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:20:28<3:27:25,  3.45s/it]                                                       {'loss': 0.0736, 'grad_norm': 6.571313381195068, 'learning_rate': 3.056779661016949e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:20:28<3:27:25,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:20:31<3:28:13,  3.46s/it]                                                       {'loss': 0.0337, 'grad_norm': 2.284043788909912, 'learning_rate': 3.055932203389831e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:20:31<3:28:13,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:20:35<3:27:39,  3.46s/it]                                                       {'loss': 0.0327, 'grad_norm': 4.238645553588867, 'learning_rate': 3.055084745762712e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:20:35<3:27:39,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:20:39<3:32:09,  3.53s/it]                                                       {'loss': 0.0268, 'grad_norm': 2.3927857875823975, 'learning_rate': 3.054237288135593e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:20:39<3:32:09,  3.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:20:42<3:32:13,  3.53s/it]                                                       {'loss': 0.017, 'grad_norm': 2.329620599746704, 'learning_rate': 3.0533898305084744e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:20:42<3:32:13,  3.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:20:46<3:31:13,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.13550743460655212, 'learning_rate': 3.052542372881356e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:20:46<3:31:13,  3.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:20:49<3:29:46,  3.50s/it]                                                       {'loss': 0.0793, 'grad_norm': 4.439870357513428, 'learning_rate': 3.0516949152542373e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:20:49<3:29:46,  3.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:20:53<3:29:18,  3.49s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.651855230331421, 'learning_rate': 3.050847457627119e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:20:53<3:29:18,  3.49s/it][2025-10-20 01:57:57,861] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:20:58<4:09:23,  4.16s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.418216586112976, 'learning_rate': 3.05e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:20:58<4:09:23,  4.16s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:21:02<3:57:01,  3.95s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.005773198790848255, 'learning_rate': 3.0491525423728817e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:21:02<3:57:01,  3.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:21:05<3:46:03,  3.77s/it]                                                       {'loss': 0.1311, 'grad_norm': 9.022284507751465, 'learning_rate': 3.048305084745763e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:21:05<3:46:03,  3.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:21:08<3:39:04,  3.66s/it]                                                       {'loss': 0.019, 'grad_norm': 2.3255436420440674, 'learning_rate': 3.0474576271186443e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:21:08<3:39:04,  3.66s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:21:12<3:34:13,  3.58s/it]                                                       {'loss': 0.0572, 'grad_norm': 5.5777764320373535, 'learning_rate': 3.0466101694915255e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:21:12<3:34:13,  3.58s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:21:15<3:32:10,  3.54s/it]                                                       {'loss': 0.069, 'grad_norm': 6.07003116607666, 'learning_rate': 3.0457627118644066e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:21:15<3:32:10,  3.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:21:19<3:29:08,  3.49s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.3688001036643982, 'learning_rate': 3.0449152542372884e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:21:19<3:29:08,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:21:22<3:27:23,  3.46s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.14143340289592743, 'learning_rate': 3.0440677966101695e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:21:22<3:27:23,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:21:25<3:24:54,  3.42s/it]                                                       {'loss': 0.0266, 'grad_norm': 3.604641914367676, 'learning_rate': 3.043220338983051e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:21:25<3:24:54,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:21:29<3:27:20,  3.47s/it]                                                       {'loss': 0.081, 'grad_norm': 4.734704494476318, 'learning_rate': 3.042372881355932e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:21:29<3:27:20,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:21:32<3:25:17,  3.43s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.5575289726257324, 'learning_rate': 3.041525423728814e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:21:32<3:25:17,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:21:36<3:27:17,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012270592153072357, 'learning_rate': 3.0406779661016947e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:21:36<3:27:17,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:21:39<3:26:00,  3.45s/it]                                                       {'loss': 0.0649, 'grad_norm': 4.08491849899292, 'learning_rate': 3.0398305084745765e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:21:39<3:26:00,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:21:43<3:25:19,  3.44s/it]                                                       {'loss': 0.0882, 'grad_norm': 5.2673773765563965, 'learning_rate': 3.0389830508474577e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:21:43<3:25:19,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:21:46<3:24:35,  3.42s/it]                                                       {'loss': 0.0749, 'grad_norm': 4.266857147216797, 'learning_rate': 3.038135593220339e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:21:46<3:24:35,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:21:49<3:23:29,  3.41s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.5260907411575317, 'learning_rate': 3.0372881355932203e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:21:49<3:23:29,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:21:53<3:25:54,  3.45s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.5296138525009155, 'learning_rate': 3.036440677966102e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:21:53<3:25:54,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:21:56<3:25:17,  3.44s/it]                                                       {'loss': 0.2572, 'grad_norm': 10.76664924621582, 'learning_rate': 3.0355932203389832e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:21:56<3:25:17,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:22:00<3:26:35,  3.46s/it]                                                       {'loss': 0.0217, 'grad_norm': 3.146186351776123, 'learning_rate': 3.0347457627118647e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:22:00<3:26:35,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:22:04<3:33:03,  3.57s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.5714612007141113, 'learning_rate': 3.0338983050847458e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:22:04<3:33:03,  3.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:22:07<3:30:40,  3.53s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.6820297837257385, 'learning_rate': 3.0330508474576276e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:22:07<3:30:40,  3.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:22:11<3:27:54,  3.49s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5427345633506775, 'learning_rate': 3.0322033898305087e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:22:11<3:27:54,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:22:14<3:26:22,  3.46s/it]                                                       {'loss': 0.0823, 'grad_norm': 4.531215190887451, 'learning_rate': 3.0313559322033902e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:22:14<3:26:22,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:22:17<3:24:38,  3.43s/it]                                                       {'loss': 0.2061, 'grad_norm': 10.682967185974121, 'learning_rate': 3.0305084745762713e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:22:17<3:24:38,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:22:21<3:27:38,  3.48s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.2795946598052979, 'learning_rate': 3.0296610169491528e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:22:21<3:27:38,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:22:24<3:25:56,  3.46s/it]                                                       {'loss': 0.0682, 'grad_norm': 7.325143814086914, 'learning_rate': 3.028813559322034e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:22:24<3:25:56,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:22:28<3:25:44,  3.46s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.21700747311115265, 'learning_rate': 3.027966101694915e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:22:28<3:25:44,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:22:31<3:25:32,  3.45s/it]                                                       {'loss': 0.114, 'grad_norm': 7.245132923126221, 'learning_rate': 3.027118644067797e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:22:31<3:25:32,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:22:35<3:26:06,  3.46s/it]                                                       {'loss': 0.02, 'grad_norm': 3.546295166015625, 'learning_rate': 3.026271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:22:35<3:26:06,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:22:38<3:28:03,  3.50s/it]                                                       {'loss': 0.019, 'grad_norm': 2.6984565258026123, 'learning_rate': 3.0254237288135594e-05, 'epoch': 0.41}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:22:38<3:28:03,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:22:42<3:28:11,  3.50s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012043309397995472, 'learning_rate': 3.0245762711864406e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:22:42<3:28:11,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:22:45<3:24:37,  3.44s/it]                                                       {'loss': 0.058, 'grad_norm': 6.735560417175293, 'learning_rate': 3.0237288135593224e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:22:45<3:24:37,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:22:48<3:23:25,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.0315447635948658, 'learning_rate': 3.0228813559322035e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:22:48<3:23:25,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:22:52<3:29:00,  3.52s/it]                                                       {'loss': 0.008, 'grad_norm': 0.732622504234314, 'learning_rate': 3.022033898305085e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:22:52<3:29:00,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:22:56<3:26:47,  3.48s/it]                                                       {'loss': 0.0416, 'grad_norm': 5.0038580894470215, 'learning_rate': 3.021186440677966e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:22:56<3:26:47,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:22:59<3:24:02,  3.43s/it]                                                       {'loss': 0.0364, 'grad_norm': 2.973850965499878, 'learning_rate': 3.0203389830508476e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:22:59<3:24:02,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:23:02<3:22:34,  3.41s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.057882506400346756, 'learning_rate': 3.0194915254237287e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:23:02<3:22:34,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:23:06<3:23:56,  3.44s/it]                                                       {'loss': 0.0483, 'grad_norm': 4.895294189453125, 'learning_rate': 3.0186440677966105e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:23:06<3:23:56,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:23:10<3:29:44,  3.53s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.0610952377319336, 'learning_rate': 3.0177966101694916e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:23:10<3:29:44,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:23:13<3:26:13,  3.48s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.0969977378845215, 'learning_rate': 3.016949152542373e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:23:13<3:26:13,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:23:17<3:34:19,  3.61s/it]                                                       {'loss': 0.0133, 'grad_norm': 2.074312925338745, 'learning_rate': 3.0161016949152542e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:23:17<3:34:19,  3.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:23:20<3:29:01,  3.52s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.0847526788711548, 'learning_rate': 3.015254237288136e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:23:20<3:29:01,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:23:24<3:28:05,  3.51s/it]                                                       {'loss': 0.0301, 'grad_norm': 3.5294277667999268, 'learning_rate': 3.014406779661017e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:23:24<3:28:05,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:23:27<3:24:42,  3.45s/it]                                                       {'loss': 0.1681, 'grad_norm': 8.142698287963867, 'learning_rate': 3.0135593220338986e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:23:27<3:24:42,  3.45s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:23:31<3:26:51,  3.49s/it]                                                       {'loss': 0.1917, 'grad_norm': 7.5209245681762695, 'learning_rate': 3.0127118644067798e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:23:31<3:26:51,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:23:34<3:25:03,  3.46s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.8777720928192139, 'learning_rate': 3.0118644067796616e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:23:34<3:25:03,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:23:37<3:24:55,  3.46s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.4706614911556244, 'learning_rate': 3.0110169491525424e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:23:37<3:24:55,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:23:41<3:29:33,  3.54s/it]                                                       {'loss': 0.0041, 'grad_norm': 6.238819122314453, 'learning_rate': 3.0101694915254235e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:23:41<3:29:33,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:23:44<3:25:55,  3.48s/it]                                                       {'loss': 0.004, 'grad_norm': 0.8949101567268372, 'learning_rate': 3.0093220338983053e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:23:44<3:25:55,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:23:48<3:23:27,  3.44s/it]                                                       {'loss': 0.0179, 'grad_norm': 2.0752248764038086, 'learning_rate': 3.0084745762711864e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:23:48<3:23:27,  3.44s/it][2025-10-20 02:00:53,124] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:23:53<4:00:55,  4.07s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.8853281736373901, 'learning_rate': 3.007627118644068e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:23:53<4:00:55,  4.07s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:23:57<3:49:40,  3.88s/it]                                                       {'loss': 0.0207, 'grad_norm': 1.8583910465240479, 'learning_rate': 3.006779661016949e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:23:57<3:49:40,  3.88s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:24:00<3:42:49,  3.77s/it]                                                       {'loss': 0.1449, 'grad_norm': 7.673768997192383, 'learning_rate': 3.0059322033898308e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:24:00<3:42:49,  3.77s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:24:04<3:35:57,  3.65s/it]                                                       {'loss': 0.0438, 'grad_norm': 6.945932388305664, 'learning_rate': 3.005084745762712e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:24:04<3:35:57,  3.65s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:24:07<3:31:11,  3.57s/it]                                                       {'loss': 0.0776, 'grad_norm': 7.10181999206543, 'learning_rate': 3.0042372881355934e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:24:07<3:31:11,  3.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:24:10<3:27:24,  3.51s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06279072165489197, 'learning_rate': 3.0033898305084745e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:24:10<3:27:24,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:24:14<3:26:52,  3.50s/it]                                                       {'loss': 0.0898, 'grad_norm': 5.520842552185059, 'learning_rate': 3.0025423728813564e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:24:14<3:26:52,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:24:17<3:24:34,  3.47s/it]                                                       {'loss': 0.0, 'grad_norm': 0.003201107494533062, 'learning_rate': 3.001694915254237e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:24:17<3:24:34,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:24:21<3:30:27,  3.57s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.6730729341506958, 'learning_rate': 3.000847457627119e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:24:21<3:30:27,  3.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:24:24<3:26:23,  3.50s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.479562759399414, 'learning_rate': 3e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:24:24<3:26:23,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:24:28<3:29:18,  3.55s/it]                                                       {'loss': 0.084, 'grad_norm': 5.383601188659668, 'learning_rate': 2.9991525423728815e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:24:28<3:29:18,  3.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:24:31<3:26:15,  3.50s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.4599180221557617, 'learning_rate': 2.9983050847457627e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:24:31<3:26:15,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:24:35<3:24:11,  3.46s/it]                                                       {'loss': 0.0469, 'grad_norm': 5.858985900878906, 'learning_rate': 2.9974576271186445e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:24:35<3:24:11,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:24:38<3:23:16,  3.45s/it]                                                       {'loss': 0.2537, 'grad_norm': 9.046873092651367, 'learning_rate': 2.9966101694915256e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:24:38<3:23:16,  3.45s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:24:42<3:29:41,  3.56s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.9038270115852356, 'learning_rate': 2.995762711864407e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:24:42<3:29:41,  3.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:24:46<3:27:16,  3.52s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.29703274369239807, 'learning_rate': 2.9949152542372882e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:24:46<3:27:16,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:24:49<3:22:43,  3.44s/it]                                                       {'loss': 0.0922, 'grad_norm': 6.068549156188965, 'learning_rate': 2.99406779661017e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:24:49<3:22:43,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:24:52<3:21:06,  3.42s/it]                                                       {'loss': 0.0288, 'grad_norm': 2.093907594680786, 'learning_rate': 2.993220338983051e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:24:52<3:21:06,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:24:55<3:18:52,  3.38s/it]                                                       {'loss': 0.0221, 'grad_norm': 3.903837203979492, 'learning_rate': 2.992372881355932e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:24:55<3:18:52,  3.38s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:24:59<3:20:32,  3.41s/it]                                                       {'loss': 0.113, 'grad_norm': 7.946286201477051, 'learning_rate': 2.9915254237288137e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:24:59<3:20:32,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:25:02<3:19:29,  3.39s/it]                                                       {'loss': 0.0719, 'grad_norm': 6.199873924255371, 'learning_rate': 2.990677966101695e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:25:02<3:19:29,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:25:06<3:20:01,  3.40s/it]                                                       {'loss': 0.1376, 'grad_norm': 13.59959602355957, 'learning_rate': 2.9898305084745763e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:25:06<3:20:01,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:25:09<3:17:49,  3.37s/it]                                                       {'loss': 0.0978, 'grad_norm': 6.8310627937316895, 'learning_rate': 2.9889830508474575e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:25:09<3:17:49,  3.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:25:12<3:17:58,  3.37s/it]                                                       {'loss': 0.174, 'grad_norm': 7.312085151672363, 'learning_rate': 2.9881355932203393e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:25:12<3:17:58,  3.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:25:16<3:18:06,  3.37s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.9567935466766357, 'learning_rate': 2.9872881355932204e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:25:16<3:18:06,  3.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:25:19<3:19:50,  3.40s/it]                                                       {'loss': 0.0843, 'grad_norm': 4.864514350891113, 'learning_rate': 2.986440677966102e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:25:19<3:19:50,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:25:23<3:19:02,  3.39s/it]                                                       {'loss': 0.0928, 'grad_norm': 14.303658485412598, 'learning_rate': 2.985593220338983e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:25:23<3:19:02,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:25:26<3:19:06,  3.39s/it]                                                       {'loss': 0.0209, 'grad_norm': 2.63665509223938, 'learning_rate': 2.9847457627118648e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:25:26<3:19:06,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:25:29<3:19:22,  3.40s/it]                                                       {'loss': 0.1084, 'grad_norm': 7.375977993011475, 'learning_rate': 2.983898305084746e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:25:29<3:19:22,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:25:33<3:20:21,  3.42s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011136402375996113, 'learning_rate': 2.9830508474576274e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:25:33<3:20:21,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:25:36<3:22:55,  3.46s/it]                                                       {'loss': 0.0245, 'grad_norm': 3.7271931171417236, 'learning_rate': 2.9822033898305085e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:25:36<3:22:55,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:25:40<3:22:37,  3.46s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.3647911548614502, 'learning_rate': 2.98135593220339e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:25:40<3:22:37,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:25:44<3:29:46,  3.58s/it]                                                       {'loss': 0.0938, 'grad_norm': 5.0100507736206055, 'learning_rate': 2.980508474576271e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:25:44<3:29:46,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:25:47<3:32:53,  3.63s/it]                                                       {'loss': 0.2696, 'grad_norm': 7.255821228027344, 'learning_rate': 2.979661016949153e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:25:47<3:32:53,  3.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:25:51<3:30:35,  3.59s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.6918883919715881, 'learning_rate': 2.978813559322034e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:25:51<3:30:35,  3.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:25:54<3:27:26,  3.54s/it]                                                       {'loss': 0.0332, 'grad_norm': 3.4266607761383057, 'learning_rate': 2.9779661016949155e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:25:54<3:27:26,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:25:58<3:26:04,  3.52s/it]                                                       {'loss': 0.0433, 'grad_norm': 3.647120475769043, 'learning_rate': 2.9771186440677966e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:25:58<3:26:04,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:26:01<3:25:12,  3.51s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.009867398999631405, 'learning_rate': 2.9762711864406785e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:26:01<3:25:12,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:26:05<3:24:17,  3.49s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.9564933776855469, 'learning_rate': 2.9754237288135596e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:26:05<3:24:17,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:26:08<3:23:52,  3.48s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.0666345357894897, 'learning_rate': 2.9745762711864407e-05, 'epoch': 0.41}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:26:08<3:23:52,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:26:12<3:20:10,  3.42s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2882998585700989, 'learning_rate': 2.9737288135593222e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:26:12<3:20:10,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:26:15<3:20:19,  3.43s/it]                                                       {'loss': 0.0491, 'grad_norm': 5.702126502990723, 'learning_rate': 2.9728813559322033e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:26:15<3:20:19,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:26:18<3:18:35,  3.40s/it]                                                       {'loss': 0.2633, 'grad_norm': 9.617128372192383, 'learning_rate': 2.9720338983050848e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:26:18<3:18:35,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:26:22<3:18:17,  3.39s/it]                                                       {'loss': 0.2354, 'grad_norm': 8.528146743774414, 'learning_rate': 2.971186440677966e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:26:22<3:18:17,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:26:25<3:23:53,  3.49s/it]                                                       {'loss': 0.1347, 'grad_norm': 15.408044815063477, 'learning_rate': 2.9703389830508477e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:26:25<3:23:53,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:26:29<3:28:37,  3.57s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06838466972112656, 'learning_rate': 2.969491525423729e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:26:29<3:28:37,  3.57s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:26:33<3:26:33,  3.54s/it]                                                       {'loss': 0.008, 'grad_norm': 1.6697229146957397, 'learning_rate': 2.9686440677966103e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:26:33<3:26:33,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:26:36<3:30:12,  3.60s/it]                                                       {'loss': 0.1619, 'grad_norm': 8.24102783203125, 'learning_rate': 2.9677966101694914e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:26:36<3:30:12,  3.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:26:40<3:25:25,  3.52s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.6594849824905396, 'learning_rate': 2.9669491525423732e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:26:40<3:25:25,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:26:43<3:23:32,  3.49s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.556947946548462, 'learning_rate': 2.9661016949152544e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:26:43<3:23:32,  3.49s/it][2025-10-20 02:03:48,433] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:26:49<4:00:10,  4.12s/it]                                                       {'loss': 0.0723, 'grad_norm': 5.683078765869141, 'learning_rate': 2.965254237288136e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:26:49<4:00:10,  4.12s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:26:52<3:46:46,  3.89s/it]                                                       {'loss': 0.2507, 'grad_norm': 8.227174758911133, 'learning_rate': 2.964406779661017e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:26:52<3:46:46,  3.89s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:26:55<3:36:57,  3.72s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.20119257271289825, 'learning_rate': 2.9635593220338988e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:26:55<3:36:57,  3.72s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:26:59<3:29:41,  3.60s/it]                                                       {'loss': 0.2174, 'grad_norm': 8.656010627746582, 'learning_rate': 2.9627118644067796e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:26:59<3:29:41,  3.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:27:02<3:25:33,  3.53s/it]                                                       {'loss': 0.0162, 'grad_norm': 1.7602547407150269, 'learning_rate': 2.9618644067796614e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:27:02<3:25:33,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:27:05<3:23:09,  3.49s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.342084676027298, 'learning_rate': 2.9610169491525425e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:27:05<3:23:09,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:27:09<3:21:42,  3.46s/it]                                                       {'loss': 0.0349, 'grad_norm': 2.6707520484924316, 'learning_rate': 2.960169491525424e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:27:09<3:21:42,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:27:12<3:18:22,  3.41s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03427587449550629, 'learning_rate': 2.959322033898305e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:27:12<3:18:22,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:27:16<3:18:19,  3.41s/it]                                                       {'loss': 0.1026, 'grad_norm': 5.664012908935547, 'learning_rate': 2.958474576271187e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:27:16<3:18:19,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:27:19<3:22:19,  3.48s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6081782579421997, 'learning_rate': 2.957627118644068e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:27:19<3:22:19,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:27:23<3:28:56,  3.59s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04310120269656181, 'learning_rate': 2.956779661016949e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:27:23<3:28:56,  3.59s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:27:26<3:25:47,  3.54s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2222050428390503, 'learning_rate': 2.9559322033898306e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:27:26<3:25:47,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:27:30<3:25:10,  3.53s/it]                                                       {'loss': 0.011, 'grad_norm': 1.777847409248352, 'learning_rate': 2.9550847457627118e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:27:30<3:25:10,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:27:33<3:23:25,  3.50s/it]                                                       {'loss': 0.0481, 'grad_norm': 2.4328644275665283, 'learning_rate': 2.9542372881355936e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:27:33<3:23:25,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:27:37<3:23:07,  3.50s/it]                                                       {'loss': 0.473, 'grad_norm': 9.917047500610352, 'learning_rate': 2.9533898305084743e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:27:37<3:23:07,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:27:40<3:21:34,  3.47s/it]                                                       {'loss': 0.0724, 'grad_norm': 5.364720821380615, 'learning_rate': 2.952542372881356e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:27:40<3:21:34,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:27:44<3:25:29,  3.54s/it]                                                       {'loss': 0.0707, 'grad_norm': 8.138020515441895, 'learning_rate': 2.9516949152542373e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:27:44<3:25:29,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:27:47<3:22:33,  3.49s/it]                                                       {'loss': 0.1366, 'grad_norm': 7.1806840896606445, 'learning_rate': 2.9508474576271187e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:27:47<3:22:33,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:27:51<3:20:35,  3.46s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1767614781856537, 'learning_rate': 2.95e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:27:51<3:20:35,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:27:54<3:20:07,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03347385674715042, 'learning_rate': 2.9491525423728817e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:27:54<3:20:07,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:27:58<3:19:47,  3.45s/it]                                                       {'loss': 0.0142, 'grad_norm': 1.3827985525131226, 'learning_rate': 2.9483050847457628e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:27:58<3:19:47,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:28:01<3:26:33,  3.56s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.6555781364440918, 'learning_rate': 2.9474576271186443e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:28:01<3:26:33,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:28:05<3:24:31,  3.53s/it]                                                       {'loss': 0.1816, 'grad_norm': 5.643589019775391, 'learning_rate': 2.9466101694915254e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:28:05<3:24:31,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:28:08<3:21:24,  3.48s/it]                                                       {'loss': 0.0559, 'grad_norm': 4.928347110748291, 'learning_rate': 2.9457627118644072e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:28:08<3:21:24,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:28:12<3:20:32,  3.46s/it]                                                       {'loss': 0.072, 'grad_norm': 5.465752124786377, 'learning_rate': 2.9449152542372883e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:28:12<3:20:32,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:28:16<3:30:16,  3.63s/it]                                                       {'loss': 0.0284, 'grad_norm': 4.4156813621521, 'learning_rate': 2.9440677966101698e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:28:16<3:30:16,  3.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:28:20<3:33:13,  3.68s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.613173484802246, 'learning_rate': 2.943220338983051e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:28:20<3:33:13,  3.68s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:28:23<3:28:26,  3.60s/it]                                                       {'loss': 0.1271, 'grad_norm': 4.680142879486084, 'learning_rate': 2.9423728813559327e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:28:23<3:28:26,  3.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:28:26<3:24:18,  3.53s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.088736057281494, 'learning_rate': 2.9415254237288135e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:28:26<3:24:18,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:28:30<3:23:57,  3.53s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.7363505363464355, 'learning_rate': 2.9406779661016953e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:28:30<3:23:57,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:28:33<3:21:52,  3.49s/it]                                                       {'loss': 0.0298, 'grad_norm': 2.6751620769500732, 'learning_rate': 2.9398305084745765e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:28:33<3:21:52,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:28:37<3:20:27,  3.47s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.710253119468689, 'learning_rate': 2.9389830508474576e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:28:37<3:20:27,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:28:40<3:20:53,  3.48s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.018137484788894653, 'learning_rate': 2.938135593220339e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:28:40<3:20:53,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:28:44<3:20:42,  3.47s/it]                                                       {'loss': 0.0922, 'grad_norm': 7.317091464996338, 'learning_rate': 2.9372881355932202e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:28:44<3:20:42,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:28:47<3:20:18,  3.47s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.36704781651496887, 'learning_rate': 2.936440677966102e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:28:47<3:20:18,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:28:51<3:20:40,  3.48s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.21328505873680115, 'learning_rate': 2.935593220338983e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:28:51<3:20:40,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:28:54<3:20:50,  3.48s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.664085328578949, 'learning_rate': 2.9347457627118646e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:28:54<3:20:50,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:28:58<3:20:16,  3.47s/it]                                                       {'loss': 0.0498, 'grad_norm': 5.285558223724365, 'learning_rate': 2.9338983050847457e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:28:58<3:20:16,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:29:01<3:18:39,  3.44s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.29468774795532227, 'learning_rate': 2.9330508474576275e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:29:01<3:18:39,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:29:04<3:18:07,  3.44s/it]                                                       {'loss': 0.1423, 'grad_norm': 6.638961315155029, 'learning_rate': 2.9322033898305083e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:29:04<3:18:07,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:29:08<3:17:26,  3.42s/it]                                                       {'loss': 0.0302, 'grad_norm': 3.447003126144409, 'learning_rate': 2.93135593220339e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:29:08<3:17:26,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:29:11<3:15:27,  3.39s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.15571527183055878, 'learning_rate': 2.9305084745762713e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:29:11<3:15:27,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:29:14<3:15:42,  3.40s/it]                                                       {'loss': 0.0217, 'grad_norm': 2.6220405101776123, 'learning_rate': 2.9296610169491527e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:29:14<3:15:42,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:29:18<3:15:50,  3.40s/it]                                                       {'loss': 0.0323, 'grad_norm': 2.104780673980713, 'learning_rate': 2.928813559322034e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:29:18<3:15:50,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:29:21<3:15:28,  3.39s/it]                                                       {'loss': 0.0984, 'grad_norm': 5.866833209991455, 'learning_rate': 2.9279661016949157e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:29:21<3:15:28,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:29:25<3:16:57,  3.42s/it]                                                       {'loss': 0.0531, 'grad_norm': 3.3373899459838867, 'learning_rate': 2.9271186440677968e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:29:25<3:16:57,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:29:28<3:16:55,  3.42s/it]                                                       {'loss': 0.0245, 'grad_norm': 3.263965129852295, 'learning_rate': 2.9262711864406783e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:29:28<3:16:55,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:29:32<3:20:58,  3.49s/it]                                                       {'loss': 0.0713, 'grad_norm': 4.661796569824219, 'learning_rate': 2.9254237288135594e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:29:32<3:20:58,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:29:35<3:19:56,  3.48s/it]                                                       {'loss': 0.009, 'grad_norm': 1.5665745735168457, 'learning_rate': 2.9245762711864412e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:29:35<3:19:56,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:29:39<3:18:32,  3.45s/it]                                                       {'loss': 0.0697, 'grad_norm': 3.7216553688049316, 'learning_rate': 2.9237288135593223e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:29:39<3:18:32,  3.45s/it][2025-10-20 02:06:43,947] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:29:44<3:55:00,  4.09s/it]                                                       {'loss': 0.082, 'grad_norm': 10.195160865783691, 'learning_rate': 2.9228813559322038e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:29:44<3:55:00,  4.09s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:29:48<3:42:49,  3.88s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.16696979105472565, 'learning_rate': 2.922033898305085e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:29:48<3:42:49,  3.88s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:29:51<3:33:46,  3.72s/it]                                                       {'loss': 0.0286, 'grad_norm': 3.503600597381592, 'learning_rate': 2.921186440677966e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:29:51<3:33:46,  3.72s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:29:55<3:35:06,  3.75s/it]                                                       {'loss': 0.0653, 'grad_norm': 4.854884147644043, 'learning_rate': 2.9203389830508475e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:29:55<3:35:06,  3.75s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:29:58<3:28:31,  3.63s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.203877791762352, 'learning_rate': 2.9194915254237286e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:29:58<3:28:31,  3.63s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:30:02<3:27:14,  3.61s/it]                                                       {'loss': 0.2065, 'grad_norm': 9.755034446716309, 'learning_rate': 2.9186440677966104e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:30:02<3:27:14,  3.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:30:05<3:23:07,  3.54s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5903966426849365, 'learning_rate': 2.9177966101694916e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:30:05<3:23:07,  3.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:30:08<3:20:17,  3.49s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.22476443648338318, 'learning_rate': 2.916949152542373e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:30:08<3:20:17,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:30:12<3:18:37,  3.46s/it]                                                       {'loss': 0.0998, 'grad_norm': 6.7104058265686035, 'learning_rate': 2.916101694915254e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:30:12<3:18:37,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:30:15<3:20:40,  3.50s/it]                                                       {'loss': 0.0929, 'grad_norm': 6.589518070220947, 'learning_rate': 2.915254237288136e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:30:15<3:20:40,  3.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:30:19<3:18:43,  3.47s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.1540212631225586, 'learning_rate': 2.914406779661017e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:30:19<3:18:43,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:30:22<3:18:27,  3.46s/it]                                                       {'loss': 0.1706, 'grad_norm': 6.318627834320068, 'learning_rate': 2.9135593220338986e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:30:22<3:18:27,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:30:26<3:15:01,  3.40s/it]                                                       {'loss': 0.149, 'grad_norm': 6.944794654846191, 'learning_rate': 2.9127118644067797e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:30:26<3:15:01,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:30:29<3:18:28,  3.47s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.2442705631256104, 'learning_rate': 2.911864406779661e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:30:29<3:18:28,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:30:32<3:16:11,  3.43s/it]                                                       {'loss': 0.0118, 'grad_norm': 2.0740044116973877, 'learning_rate': 2.9110169491525423e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:30:32<3:16:11,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:30:36<3:14:33,  3.40s/it]                                                       {'loss': 0.2802, 'grad_norm': 7.4628520011901855, 'learning_rate': 2.910169491525424e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:30:36<3:14:33,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:30:39<3:15:26,  3.42s/it]                                                       {'loss': 0.0485, 'grad_norm': 6.439991474151611, 'learning_rate': 2.9093220338983052e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:30:39<3:15:26,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:30:43<3:19:25,  3.49s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.9295458197593689, 'learning_rate': 2.9084745762711867e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:30:43<3:19:25,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:30:46<3:18:29,  3.47s/it]                                                       {'loss': 0.2014, 'grad_norm': 8.566388130187988, 'learning_rate': 2.9076271186440678e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:30:46<3:18:29,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:30:50<3:17:13,  3.45s/it]                                                       {'loss': 0.0332, 'grad_norm': 2.9518392086029053, 'learning_rate': 2.9067796610169496e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:30:50<3:17:13,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:30:53<3:16:03,  3.43s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.289512872695923, 'learning_rate': 2.9059322033898308e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:30:53<3:16:03,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:30:57<3:16:22,  3.44s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.14045895636081696, 'learning_rate': 2.9050847457627122e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:30:57<3:16:22,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:31:00<3:13:36,  3.39s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3088885545730591, 'learning_rate': 2.9042372881355934e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:31:00<3:13:36,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:31:03<3:12:59,  3.38s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5896536707878113, 'learning_rate': 2.9033898305084745e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:31:03<3:12:59,  3.38s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:31:07<3:14:29,  3.41s/it]                                                       {'loss': 0.004, 'grad_norm': 0.7650009989738464, 'learning_rate': 2.902542372881356e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:31:07<3:14:29,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:31:10<3:14:04,  3.40s/it]                                                       {'loss': 0.0785, 'grad_norm': 7.141335487365723, 'learning_rate': 2.901694915254237e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:31:10<3:14:04,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:31:14<3:15:22,  3.42s/it]                                                       {'loss': 0.0999, 'grad_norm': 6.79396915435791, 'learning_rate': 2.900847457627119e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:31:14<3:15:22,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:31:17<3:15:05,  3.42s/it]                                                       {'loss': 0.0476, 'grad_norm': 6.2911176681518555, 'learning_rate': 2.9e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:31:17<3:15:05,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:31:20<3:14:59,  3.42s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.29831960797309875, 'learning_rate': 2.8991525423728815e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:31:20<3:14:59,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:31:24<3:14:52,  3.42s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.2407490015029907, 'learning_rate': 2.8983050847457626e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:31:24<3:14:52,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:31:27<3:16:10,  3.44s/it]                                                       {'loss': 0.0448, 'grad_norm': 4.928763389587402, 'learning_rate': 2.8974576271186444e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:31:27<3:16:10,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:31:31<3:20:53,  3.53s/it]                                                       {'loss': 0.2604, 'grad_norm': 10.57366943359375, 'learning_rate': 2.8966101694915255e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:31:31<3:20:53,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:31:34<3:17:51,  3.47s/it]                                                       {'loss': 0.2783, 'grad_norm': 8.084379196166992, 'learning_rate': 2.895762711864407e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:31:34<3:17:51,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:31:38<3:14:44,  3.42s/it]                                                       {'loss': 0.1435, 'grad_norm': 8.30628490447998, 'learning_rate': 2.894915254237288e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:31:38<3:14:44,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:31:41<3:14:49,  3.42s/it]                                                       {'loss': 0.1667, 'grad_norm': 4.722801208496094, 'learning_rate': 2.89406779661017e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:31:41<3:14:49,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:31:44<3:13:20,  3.40s/it]                                                       {'loss': 0.1741, 'grad_norm': 6.430602073669434, 'learning_rate': 2.8932203389830507e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:31:44<3:13:20,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:31:48<3:12:17,  3.38s/it]                                                       {'loss': 0.0193, 'grad_norm': 2.6952810287475586, 'learning_rate': 2.8923728813559325e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:31:48<3:12:17,  3.38s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:31:52<3:20:33,  3.53s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.009091723710298538, 'learning_rate': 2.8915254237288137e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:31:52<3:20:33,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:31:55<3:17:04,  3.47s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.17213082313537598, 'learning_rate': 2.890677966101695e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:31:55<3:17:04,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:31:58<3:16:06,  3.45s/it]                                                       {'loss': 0.0097, 'grad_norm': 0.8708859086036682, 'learning_rate': 2.8898305084745763e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:31:58<3:16:06,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:32:02<3:14:58,  3.43s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5748130679130554, 'learning_rate': 2.888983050847458e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:32:02<3:14:58,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:32:05<3:12:42,  3.39s/it]                                                       {'loss': 0.1218, 'grad_norm': 10.675416946411133, 'learning_rate': 2.8881355932203392e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:32:05<3:12:42,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:32:08<3:12:04,  3.38s/it]                                                       {'loss': 0.0439, 'grad_norm': 5.760597229003906, 'learning_rate': 2.8872881355932203e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:32:08<3:12:04,  3.38s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:32:12<3:11:22,  3.37s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.6243054270744324, 'learning_rate': 2.8864406779661018e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:32:12<3:11:22,  3.37s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:32:15<3:12:31,  3.39s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.8380874991416931, 'learning_rate': 2.885593220338983e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:32:15<3:12:31,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:32:19<3:14:16,  3.42s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.8138459324836731, 'learning_rate': 2.8847457627118647e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:32:19<3:14:16,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:32:22<3:13:01,  3.40s/it]                                                       {'loss': 0.0493, 'grad_norm': 4.118717670440674, 'learning_rate': 2.8838983050847455e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:32:22<3:13:01,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:32:25<3:12:19,  3.39s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05985749140381813, 'learning_rate': 2.8830508474576273e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:32:25<3:12:19,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:32:29<3:13:45,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3544333875179291, 'learning_rate': 2.8822033898305085e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:32:29<3:13:45,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:32:32<3:12:11,  3.39s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.05801611393690109, 'learning_rate': 2.88135593220339e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:32:32<3:12:11,  3.39s/it][2025-10-20 02:09:37,564] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:32:38<3:54:53,  4.15s/it]                                                       {'loss': 0.1248, 'grad_norm': 4.6519551277160645, 'learning_rate': 2.880508474576271e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:32:38<3:54:53,  4.15s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:32:41<3:40:53,  3.90s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.6644905209541321, 'learning_rate': 2.879661016949153e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:32:41<3:40:53,  3.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:32:45<3:32:06,  3.75s/it]                                                       {'loss': 0.054, 'grad_norm': 3.2705399990081787, 'learning_rate': 2.878813559322034e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:32:45<3:32:06,  3.75s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:32:48<3:26:40,  3.65s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.9897633194923401, 'learning_rate': 2.8779661016949155e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:32:48<3:26:40,  3.65s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:32:52<3:22:45,  3.58s/it]                                                       {'loss': 0.0665, 'grad_norm': 3.213352680206299, 'learning_rate': 2.8771186440677966e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:32:52<3:22:45,  3.58s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:32:55<3:18:48,  3.51s/it]                                                       {'loss': 0.0175, 'grad_norm': 1.4466619491577148, 'learning_rate': 2.8762711864406784e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:32:55<3:18:48,  3.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:32:58<3:16:05,  3.47s/it]                                                       {'loss': 0.0521, 'grad_norm': 5.368462562561035, 'learning_rate': 2.8754237288135595e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:32:58<3:16:05,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:33:02<3:14:22,  3.44s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.9316787123680115, 'learning_rate': 2.874576271186441e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:33:02<3:14:22,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:33:05<3:13:22,  3.42s/it]                                                       {'loss': 0.0321, 'grad_norm': 5.068419933319092, 'learning_rate': 2.873728813559322e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:33:05<3:13:22,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:33:09<3:11:48,  3.39s/it]                                                       {'loss': 0.0804, 'grad_norm': 5.472041130065918, 'learning_rate': 2.8728813559322036e-05, 'epoch': 0.43}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:33:09<3:11:48,  3.39s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:33:12<3:13:51,  3.43s/it]                                                       {'loss': 0.1127, 'grad_norm': 4.7913103103637695, 'learning_rate': 2.8720338983050847e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:33:12<3:13:51,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:33:15<3:12:11,  3.40s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0018065011827275157, 'learning_rate': 2.8711864406779665e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:33:15<3:12:11,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:33:19<3:17:23,  3.50s/it]                                                       {'loss': 0.0642, 'grad_norm': 4.365809917449951, 'learning_rate': 2.8703389830508476e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:33:19<3:17:23,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:33:22<3:14:38,  3.45s/it]                                                       {'loss': 0.0259, 'grad_norm': 2.959137201309204, 'learning_rate': 2.8694915254237288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:33:22<3:14:38,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:33:26<3:12:53,  3.42s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.9063217639923096, 'learning_rate': 2.8686440677966102e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:33:26<3:12:53,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:33:29<3:13:25,  3.43s/it]                                                       {'loss': 0.2284, 'grad_norm': 6.308097839355469, 'learning_rate': 2.8677966101694914e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:33:29<3:13:25,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:33:33<3:13:13,  3.43s/it]                                                       {'loss': 0.0381, 'grad_norm': 5.138872146606445, 'learning_rate': 2.8669491525423732e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:33:33<3:13:13,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:33:36<3:13:02,  3.42s/it]                                                       {'loss': 0.0827, 'grad_norm': 8.113966941833496, 'learning_rate': 2.8661016949152543e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:33:36<3:13:02,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:33:40<3:15:58,  3.48s/it]                                                       {'loss': 0.0295, 'grad_norm': 3.1092591285705566, 'learning_rate': 2.8652542372881358e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:33:40<3:15:58,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:33:43<3:18:46,  3.53s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.7342027425765991, 'learning_rate': 2.864406779661017e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:33:43<3:18:46,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:33:47<3:18:37,  3.53s/it]                                                       {'loss': 0.022, 'grad_norm': 4.342132091522217, 'learning_rate': 2.8635593220338984e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:33:47<3:18:37,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:33:50<3:17:35,  3.51s/it]                                                       {'loss': 0.104, 'grad_norm': 5.202670574188232, 'learning_rate': 2.8627118644067795e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:33:50<3:17:35,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:33:54<3:14:23,  3.45s/it]                                                       {'loss': 0.0234, 'grad_norm': 3.2755279541015625, 'learning_rate': 2.8618644067796613e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:33:54<3:14:23,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:33:57<3:14:12,  3.45s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.9097487926483154, 'learning_rate': 2.8610169491525424e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:33:57<3:14:12,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:34:01<3:16:02,  3.49s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.7712275385856628, 'learning_rate': 2.860169491525424e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:34:01<3:16:02,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:34:04<3:18:00,  3.52s/it]                                                       {'loss': 0.1313, 'grad_norm': 9.413585662841797, 'learning_rate': 2.859322033898305e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:34:04<3:18:00,  3.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:34:08<3:19:12,  3.54s/it]                                                       {'loss': 0.1173, 'grad_norm': 5.792726516723633, 'learning_rate': 2.858474576271187e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:34:08<3:19:12,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:34:11<3:16:24,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012709072791039944, 'learning_rate': 2.857627118644068e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:34:11<3:16:24,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:34:15<3:15:20,  3.48s/it]                                                       {'loss': 0.0328, 'grad_norm': 4.772731781005859, 'learning_rate': 2.8567796610169494e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:34:15<3:15:20,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:34:18<3:13:56,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.020565269514918327, 'learning_rate': 2.8559322033898306e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:34:18<3:13:56,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:34:21<3:12:04,  3.42s/it]                                                       {'loss': 0.0106, 'grad_norm': 0.9656325578689575, 'learning_rate': 2.8550847457627124e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:34:21<3:12:04,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:34:25<3:10:24,  3.39s/it]                                                       {'loss': 0.1228, 'grad_norm': 6.6213226318359375, 'learning_rate': 2.854237288135593e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:34:25<3:10:24,  3.39s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:34:28<3:08:52,  3.37s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4375034272670746, 'learning_rate': 2.853389830508475e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:34:28<3:08:52,  3.37s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:34:32<3:11:20,  3.41s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03077300824224949, 'learning_rate': 2.852542372881356e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:34:32<3:11:20,  3.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:34:35<3:12:22,  3.43s/it]                                                       {'loss': 0.0419, 'grad_norm': 4.848311901092529, 'learning_rate': 2.8516949152542372e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:34:35<3:12:22,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:34:39<3:25:41,  3.67s/it]                                                       {'loss': 0.04, 'grad_norm': 3.0810396671295166, 'learning_rate': 2.8508474576271187e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:34:39<3:25:41,  3.67s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:34:43<3:22:08,  3.61s/it]                                                       {'loss': 0.1698, 'grad_norm': 7.124449729919434, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:34:43<3:22:08,  3.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:34:46<3:20:01,  3.57s/it]                                                       {'loss': 0.0506, 'grad_norm': 2.9016940593719482, 'learning_rate': 2.8491525423728816e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:34:46<3:20:01,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:34:50<3:18:34,  3.54s/it]                                                       {'loss': 0.0566, 'grad_norm': 4.221778869628906, 'learning_rate': 2.8483050847457628e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:34:50<3:18:34,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:34:53<3:19:40,  3.57s/it]                                                       {'loss': 0.0944, 'grad_norm': 7.2891926765441895, 'learning_rate': 2.8474576271186442e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:34:53<3:19:40,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:34:57<3:25:14,  3.67s/it]                                                       {'loss': 0.1628, 'grad_norm': 7.350916385650635, 'learning_rate': 2.8466101694915253e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:34:57<3:25:14,  3.67s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:35:01<3:19:52,  3.57s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.6547248959541321, 'learning_rate': 2.845762711864407e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:35:01<3:19:52,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:35:04<3:16:10,  3.51s/it]                                                       {'loss': 0.0493, 'grad_norm': 5.786644458770752, 'learning_rate': 2.844915254237288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:35:04<3:16:10,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:35:07<3:13:13,  3.45s/it]                                                       {'loss': 0.0971, 'grad_norm': 5.5086517333984375, 'learning_rate': 2.8440677966101698e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:35:07<3:13:13,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:35:11<3:12:57,  3.45s/it]                                                       {'loss': 0.0238, 'grad_norm': 3.6292009353637695, 'learning_rate': 2.843220338983051e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:35:11<3:12:57,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:35:14<3:12:06,  3.44s/it]                                                       {'loss': 0.015, 'grad_norm': 1.722551941871643, 'learning_rate': 2.8423728813559323e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:35:14<3:12:06,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:35:18<3:13:11,  3.46s/it]                                                       {'loss': 0.0507, 'grad_norm': 3.8804123401641846, 'learning_rate': 2.8415254237288135e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:35:18<3:13:11,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:35:21<3:11:54,  3.43s/it]                                                       {'loss': 0.2256, 'grad_norm': 8.897171020507812, 'learning_rate': 2.8406779661016953e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:35:21<3:11:54,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:35:25<3:14:02,  3.47s/it]                                                       {'loss': 0.0655, 'grad_norm': 5.494260311126709, 'learning_rate': 2.8398305084745764e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:35:25<3:14:02,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:35:28<3:13:01,  3.46s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.44400590658187866, 'learning_rate': 2.838983050847458e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:35:28<3:13:01,  3.46s/it][2025-10-20 02:12:33,265] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:35:34<3:49:58,  4.12s/it]                                                       {'loss': 0.0901, 'grad_norm': 9.064422607421875, 'learning_rate': 2.838135593220339e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:35:34<3:49:58,  4.12s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:35:37<3:40:39,  3.95s/it]                                                       {'loss': 0.027, 'grad_norm': 3.4852683544158936, 'learning_rate': 2.8372881355932208e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:35:37<3:40:39,  3.95s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:35:41<3:39:29,  3.93s/it]                                                       {'loss': 0.0487, 'grad_norm': 1.8488409519195557, 'learning_rate': 2.836440677966102e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:35:41<3:39:29,  3.93s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:35:44<3:29:31,  3.76s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.6508773565292358, 'learning_rate': 2.8355932203389834e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:35:44<3:29:31,  3.76s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:35:48<3:22:48,  3.64s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.3181703090667725, 'learning_rate': 2.8347457627118645e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:35:48<3:22:48,  3.64s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:35:51<3:17:02,  3.54s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.11351820081472397, 'learning_rate': 2.8338983050847457e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:35:51<3:17:02,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:35:55<3:23:23,  3.65s/it]                                                       {'loss': 0.1262, 'grad_norm': 6.2654500007629395, 'learning_rate': 2.833050847457627e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:35:55<3:23:23,  3.65s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:35:58<3:19:16,  3.58s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.859067976474762, 'learning_rate': 2.8322033898305083e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:35:58<3:19:16,  3.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:36:02<3:23:49,  3.66s/it]                                                       {'loss': 0.035, 'grad_norm': 1.2628971338272095, 'learning_rate': 2.83135593220339e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:36:02<3:23:49,  3.66s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:36:06<3:26:28,  3.71s/it]                                                       {'loss': 0.015, 'grad_norm': 2.768673896789551, 'learning_rate': 2.8305084745762712e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:36:06<3:26:28,  3.71s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:36:09<3:21:01,  3.61s/it]                                                       {'loss': 0.0771, 'grad_norm': 7.141515731811523, 'learning_rate': 2.8296610169491527e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:36:09<3:21:01,  3.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:36:13<3:17:21,  3.55s/it]                                                       {'loss': 0.0717, 'grad_norm': 6.384199142456055, 'learning_rate': 2.8288135593220338e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:36:13<3:17:21,  3.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:36:16<3:14:36,  3.50s/it]                                                       {'loss': 0.0792, 'grad_norm': 4.12797212600708, 'learning_rate': 2.8279661016949156e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:36:16<3:14:36,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:36:20<3:12:44,  3.47s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.0878822803497314, 'learning_rate': 2.8271186440677967e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:36:20<3:12:44,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:36:23<3:15:14,  3.51s/it]                                                       {'loss': 0.0256, 'grad_norm': 1.7812962532043457, 'learning_rate': 2.8262711864406782e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:36:23<3:15:14,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:36:27<3:14:05,  3.49s/it]                                                       {'loss': 0.1204, 'grad_norm': 5.552886009216309, 'learning_rate': 2.8254237288135593e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:36:27<3:14:05,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:36:30<3:13:53,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.006605152972042561, 'learning_rate': 2.824576271186441e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:36:30<3:13:53,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:36:34<3:19:14,  3.59s/it]                                                       {'loss': 0.0547, 'grad_norm': 6.9772748947143555, 'learning_rate': 2.823728813559322e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:36:34<3:19:14,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:36:37<3:16:20,  3.54s/it]                                                       {'loss': 0.004, 'grad_norm': 0.7027350068092346, 'learning_rate': 2.8228813559322037e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:36:37<3:16:20,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:36:41<3:13:03,  3.48s/it]                                                       {'loss': 0.135, 'grad_norm': 5.424440860748291, 'learning_rate': 2.822033898305085e-05, 'epoch': 0.45}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:36:41<3:13:03,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:36:45<3:20:26,  3.61s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.7312809228897095, 'learning_rate': 2.8211864406779663e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:36:45<3:20:26,  3.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:36:48<3:18:08,  3.57s/it]                                                       {'loss': 0.0234, 'grad_norm': 2.58798885345459, 'learning_rate': 2.8203389830508475e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:36:48<3:18:08,  3.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:36:52<3:15:56,  3.53s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.02611255832016468, 'learning_rate': 2.8194915254237293e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:36:52<3:15:56,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:36:55<3:14:35,  3.51s/it]                                                       {'loss': 0.0614, 'grad_norm': 3.8721847534179688, 'learning_rate': 2.8186440677966104e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:36:55<3:14:35,  3.51s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:36:59<3:18:48,  3.59s/it]                                                       {'loss': 0.1065, 'grad_norm': 5.706039905548096, 'learning_rate': 2.817796610169492e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:36:59<3:18:48,  3.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:37:02<3:14:23,  3.51s/it]                                                       {'loss': 0.0324, 'grad_norm': 3.1933510303497314, 'learning_rate': 2.816949152542373e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:37:02<3:14:23,  3.51s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:37:06<3:13:57,  3.50s/it]                                                       {'loss': 0.0166, 'grad_norm': 2.2367727756500244, 'learning_rate': 2.816101694915254e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:37:06<3:13:57,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:37:09<3:12:48,  3.48s/it]                                                       {'loss': 0.0885, 'grad_norm': 7.18168830871582, 'learning_rate': 2.815254237288136e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:37:09<3:12:48,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:37:12<3:10:23,  3.44s/it]                                                       {'loss': 0.0381, 'grad_norm': 4.18287467956543, 'learning_rate': 2.8144067796610167e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:37:12<3:10:23,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:37:16<3:12:11,  3.47s/it]                                                       {'loss': 0.015, 'grad_norm': 1.6516075134277344, 'learning_rate': 2.8135593220338985e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:37:16<3:12:11,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:37:19<3:09:31,  3.43s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6040117144584656, 'learning_rate': 2.8127118644067796e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:37:19<3:09:31,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:37:23<3:08:51,  3.42s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.0127393007278442, 'learning_rate': 2.811864406779661e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:37:23<3:08:51,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:37:26<3:07:52,  3.40s/it]                                                       {'loss': 0.0522, 'grad_norm': 6.607132434844971, 'learning_rate': 2.8110169491525422e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:37:26<3:07:52,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:37:29<3:06:29,  3.37s/it]                                                       {'loss': 0.4682, 'grad_norm': 10.04887866973877, 'learning_rate': 2.810169491525424e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:37:29<3:06:29,  3.37s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:37:33<3:05:44,  3.36s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1835062950849533, 'learning_rate': 2.8093220338983052e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:37:33<3:05:44,  3.36s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:37:36<3:06:49,  3.38s/it]                                                       {'loss': 0.1345, 'grad_norm': 3.9917538166046143, 'learning_rate': 2.8084745762711866e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:37:36<3:06:49,  3.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:37:39<3:06:34,  3.38s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.3823727369308472, 'learning_rate': 2.8076271186440678e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:37:39<3:06:34,  3.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:37:43<3:06:13,  3.37s/it]                                                       {'loss': 0.0376, 'grad_norm': 3.106133222579956, 'learning_rate': 2.8067796610169496e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:37:43<3:06:13,  3.37s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:37:46<3:06:24,  3.38s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.7669996023178101, 'learning_rate': 2.8059322033898307e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:37:46<3:06:24,  3.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:37:50<3:06:20,  3.38s/it]                                                       {'loss': 0.108, 'grad_norm': 6.8525519371032715, 'learning_rate': 2.8050847457627122e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:37:50<3:06:20,  3.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:37:53<3:07:22,  3.40s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.14999230206012726, 'learning_rate': 2.8042372881355933e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:37:53<3:07:22,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:37:57<3:08:25,  3.42s/it]                                                       {'loss': 0.0368, 'grad_norm': 4.560539722442627, 'learning_rate': 2.8033898305084748e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:37:57<3:08:25,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:38:00<3:08:05,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08012646436691284, 'learning_rate': 2.802542372881356e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:38:00<3:08:05,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:38:04<3:13:07,  3.51s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014383611269295216, 'learning_rate': 2.8016949152542377e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:38:04<3:13:07,  3.51s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:38:07<3:14:14,  3.53s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.106013536453247, 'learning_rate': 2.8008474576271188e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:38:07<3:14:14,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:38:11<3:13:41,  3.52s/it]                                                       {'loss': 0.1546, 'grad_norm': 8.46056842803955, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:38:11<3:13:41,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:38:14<3:13:00,  3.51s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.9828610420227051, 'learning_rate': 2.7991525423728814e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:38:14<3:13:00,  3.51s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:38:18<3:10:11,  3.46s/it]                                                       {'loss': 0.0354, 'grad_norm': 2.0134928226470947, 'learning_rate': 2.7983050847457626e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:38:18<3:10:11,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:38:21<3:09:05,  3.44s/it]                                                       {'loss': 0.0194, 'grad_norm': 10.903139114379883, 'learning_rate': 2.7974576271186444e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:38:21<3:09:05,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:38:24<3:08:02,  3.42s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.49846723675727844, 'learning_rate': 2.7966101694915255e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:38:24<3:08:02,  3.42s/it][2025-10-20 02:15:29,629] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:38:30<3:48:40,  4.16s/it]                                                       {'loss': 0.0381, 'grad_norm': 3.4866435527801514, 'learning_rate': 2.795762711864407e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:38:30<3:48:40,  4.16s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:38:34<3:43:02,  4.06s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.44057971239089966, 'learning_rate': 2.794915254237288e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:38:34<3:43:02,  4.06s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:38:37<3:32:03,  3.86s/it]                                                       {'loss': 0.0334, 'grad_norm': 4.860686302185059, 'learning_rate': 2.7940677966101696e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:38:37<3:32:03,  3.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:38:41<3:25:01,  3.73s/it]                                                       {'loss': 0.1621, 'grad_norm': 6.28778600692749, 'learning_rate': 2.7932203389830507e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:38:41<3:25:01,  3.73s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:38:45<3:24:41,  3.73s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07391169667243958, 'learning_rate': 2.7923728813559325e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:38:45<3:24:41,  3.73s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:38:48<3:18:25,  3.61s/it]                                                       {'loss': 0.147, 'grad_norm': 11.744963645935059, 'learning_rate': 2.7915254237288136e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:38:48<3:18:25,  3.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:38:51<3:14:09,  3.54s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.577596127986908, 'learning_rate': 2.790677966101695e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:38:51<3:14:09,  3.54s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:38:55<3:17:23,  3.60s/it]                                                       {'loss': 0.0157, 'grad_norm': 2.261578321456909, 'learning_rate': 2.7898305084745762e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:38:55<3:17:23,  3.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:38:59<3:16:33,  3.58s/it]                                                       {'loss': 0.0428, 'grad_norm': 4.383406639099121, 'learning_rate': 2.788983050847458e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:38:59<3:16:33,  3.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:39:02<3:15:40,  3.57s/it]                                                       {'loss': 0.0991, 'grad_norm': 4.713241100311279, 'learning_rate': 2.788135593220339e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:39:02<3:15:40,  3.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:39:05<3:12:49,  3.52s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06140508875250816, 'learning_rate': 2.7872881355932206e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:39:05<3:12:49,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:39:09<3:12:01,  3.50s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.45957282185554504, 'learning_rate': 2.7864406779661017e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:39:09<3:12:01,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:39:12<3:10:16,  3.47s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.469693899154663, 'learning_rate': 2.7855932203389835e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:39:12<3:10:16,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:39:16<3:08:45,  3.45s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.16087807714939117, 'learning_rate': 2.7847457627118643e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:39:16<3:08:45,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:39:19<3:09:52,  3.47s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.674574851989746, 'learning_rate': 2.783898305084746e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:39:19<3:09:52,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:39:23<3:10:55,  3.49s/it]                                                       {'loss': 0.1243, 'grad_norm': 8.397043228149414, 'learning_rate': 2.7830508474576273e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:39:23<3:10:55,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:39:26<3:07:46,  3.43s/it]                                                       {'loss': 0.0236, 'grad_norm': 2.135003089904785, 'learning_rate': 2.7822033898305087e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:39:26<3:07:46,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:39:29<3:06:44,  3.41s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.967207670211792, 'learning_rate': 2.78135593220339e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:39:29<3:06:44,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:39:33<3:06:58,  3.42s/it]                                                       {'loss': 0.1128, 'grad_norm': 5.564600467681885, 'learning_rate': 2.780508474576271e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:39:33<3:06:58,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:39:36<3:08:31,  3.45s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.6599507331848145, 'learning_rate': 2.7796610169491528e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:39:36<3:08:31,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:39:40<3:07:39,  3.43s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.8847668170928955, 'learning_rate': 2.778813559322034e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:39:40<3:07:39,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:39:43<3:07:03,  3.42s/it]                                                       {'loss': 0.1838, 'grad_norm': 8.482593536376953, 'learning_rate': 2.7779661016949154e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:39:43<3:07:03,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:39:47<3:05:22,  3.39s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025472987443208694, 'learning_rate': 2.7771186440677965e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:39:47<3:05:22,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:39:50<3:04:11,  3.37s/it]                                                       {'loss': 0.0402, 'grad_norm': 4.27970027923584, 'learning_rate': 2.7762711864406783e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:39:50<3:04:11,  3.37s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:39:53<3:05:01,  3.39s/it]                                                       {'loss': 0.0693, 'grad_norm': 5.605043888092041, 'learning_rate': 2.775423728813559e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:39:53<3:05:01,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:39:57<3:06:13,  3.41s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3365209400653839, 'learning_rate': 2.774576271186441e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:39:57<3:06:13,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:40:00<3:06:31,  3.42s/it]                                                       {'loss': 0.0765, 'grad_norm': 12.230066299438477, 'learning_rate': 2.773728813559322e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:40:00<3:06:31,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:40:04<3:05:36,  3.40s/it]                                                       {'loss': 0.0363, 'grad_norm': 4.427382946014404, 'learning_rate': 2.7728813559322035e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:40:04<3:05:36,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:40:07<3:05:31,  3.40s/it]                                                       {'loss': 0.0303, 'grad_norm': 2.9383091926574707, 'learning_rate': 2.7720338983050847e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:40:07<3:05:31,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:40:10<3:04:38,  3.39s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.8188727498054504, 'learning_rate': 2.7711864406779665e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:40:10<3:04:38,  3.39s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:40:14<3:04:25,  3.38s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10713467746973038, 'learning_rate': 2.7703389830508476e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:40:14<3:04:25,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:40:17<3:04:54,  3.39s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.312007427215576, 'learning_rate': 2.769491525423729e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:40:17<3:04:54,  3.39s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:40:20<3:04:15,  3.38s/it]                                                       {'loss': 0.2593, 'grad_norm': 10.596410751342773, 'learning_rate': 2.7686440677966102e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:40:20<3:04:15,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:40:24<3:10:55,  3.51s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.8458073735237122, 'learning_rate': 2.767796610169492e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:40:24<3:10:55,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:40:28<3:09:27,  3.48s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.3250625133514404, 'learning_rate': 2.766949152542373e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:40:28<3:09:27,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:40:31<3:12:57,  3.55s/it]                                                       {'loss': 0.0779, 'grad_norm': 3.958545684814453, 'learning_rate': 2.7661016949152546e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:40:31<3:12:57,  3.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:40:35<3:12:05,  3.53s/it]                                                       {'loss': 0.0948, 'grad_norm': 6.546162128448486, 'learning_rate': 2.7652542372881357e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:40:35<3:12:05,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:40:38<3:09:39,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014659607782959938, 'learning_rate': 2.7644067796610172e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:40:38<3:09:39,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:40:42<3:09:59,  3.50s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2543487250804901, 'learning_rate': 2.7635593220338983e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:40:42<3:09:59,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:40:45<3:08:22,  3.47s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.384714961051941, 'learning_rate': 2.7627118644067794e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:40:45<3:08:22,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:40:49<3:08:32,  3.47s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.9325737357139587, 'learning_rate': 2.7618644067796612e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:40:49<3:08:32,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:40:52<3:05:47,  3.42s/it]                                                       {'loss': 0.081, 'grad_norm': 6.340486526489258, 'learning_rate': 2.7610169491525424e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:40:52<3:05:47,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:40:55<3:04:23,  3.40s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.322170376777649, 'learning_rate': 2.760169491525424e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:40:55<3:04:23,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:40:59<3:03:25,  3.38s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.2346622943878174, 'learning_rate': 2.759322033898305e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:40:59<3:03:25,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:41:02<3:05:39,  3.42s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.9926828145980835, 'learning_rate': 2.7584745762711868e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:41:02<3:05:39,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:41:06<3:12:51,  3.56s/it]                                                       {'loss': 0.0736, 'grad_norm': 5.872991561889648, 'learning_rate': 2.757627118644068e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:41:06<3:12:51,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:41:10<3:16:54,  3.63s/it]                                                       {'loss': 0.058, 'grad_norm': 4.282632350921631, 'learning_rate': 2.7567796610169494e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:41:10<3:16:54,  3.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:41:13<3:12:56,  3.56s/it]                                                       {'loss': 0.1082, 'grad_norm': 5.240143299102783, 'learning_rate': 2.7559322033898305e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:41:13<3:12:56,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:41:17<3:09:18,  3.49s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.6302608847618103, 'learning_rate': 2.755084745762712e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:41:17<3:09:18,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:41:20<3:06:48,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1577453762292862, 'learning_rate': 2.754237288135593e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:41:20<3:06:48,  3.45s/it][2025-10-20 02:18:25,248] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:41:26<3:42:07,  4.10s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011156480759382248, 'learning_rate': 2.753389830508475e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:41:26<3:42:07,  4.10s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:41:29<3:30:34,  3.89s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.18907612562179565, 'learning_rate': 2.752542372881356e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:41:29<3:30:34,  3.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:41:32<3:21:57,  3.73s/it]                                                       {'loss': 0.1437, 'grad_norm': 5.377883434295654, 'learning_rate': 2.7516949152542375e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:41:32<3:21:57,  3.73s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:41:36<3:24:59,  3.79s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.38320785760879517, 'learning_rate': 2.7508474576271186e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:41:36<3:24:59,  3.79s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:41:40<3:20:18,  3.70s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.19219081103801727, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:41:40<3:20:18,  3.70s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:41:43<3:19:02,  3.68s/it]                                                       {'loss': 0.0644, 'grad_norm': 5.3903350830078125, 'learning_rate': 2.7491525423728816e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:41:43<3:19:02,  3.68s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:41:47<3:15:09,  3.61s/it]                                                       {'loss': 0.0448, 'grad_norm': 4.269000053405762, 'learning_rate': 2.748305084745763e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:41:47<3:15:09,  3.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:41:50<3:10:47,  3.53s/it]                                                       {'loss': 0.0178, 'grad_norm': 2.0896923542022705, 'learning_rate': 2.747457627118644e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:41:50<3:10:47,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:41:54<3:12:22,  3.56s/it]                                                       {'loss': 0.101, 'grad_norm': 6.067020416259766, 'learning_rate': 2.746610169491526e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:41:54<3:12:22,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:41:57<3:09:36,  3.51s/it]                                                       {'loss': 0.0752, 'grad_norm': 4.093761444091797, 'learning_rate': 2.7457627118644068e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:41:57<3:09:36,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:42:01<3:08:37,  3.49s/it]                                                       {'loss': 0.1702, 'grad_norm': 6.5734076499938965, 'learning_rate': 2.744915254237288e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:42:01<3:08:37,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:42:04<3:07:40,  3.48s/it]                                                       {'loss': 0.2249, 'grad_norm': 9.274642944335938, 'learning_rate': 2.7440677966101697e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:42:04<3:07:40,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:42:07<3:05:44,  3.44s/it]                                                       {'loss': 0.1606, 'grad_norm': 7.455470561981201, 'learning_rate': 2.7432203389830508e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:42:07<3:05:44,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:42:11<3:07:30,  3.48s/it]                                                       {'loss': 0.0226, 'grad_norm': 3.2550182342529297, 'learning_rate': 2.7423728813559323e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:42:11<3:07:30,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:42:15<3:08:33,  3.50s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.283273458480835, 'learning_rate': 2.7415254237288134e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:42:15<3:08:33,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:42:18<3:06:11,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06759298592805862, 'learning_rate': 2.7406779661016952e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:42:18<3:06:11,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:42:21<3:08:20,  3.50s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02247471921145916, 'learning_rate': 2.7398305084745764e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:42:21<3:08:20,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:42:25<3:05:58,  3.45s/it]                                                       {'loss': 0.0448, 'grad_norm': 3.9765913486480713, 'learning_rate': 2.7389830508474578e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:42:25<3:05:58,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:42:28<3:06:06,  3.46s/it]                                                       {'loss': 0.1828, 'grad_norm': 6.0079345703125, 'learning_rate': 2.738135593220339e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:42:28<3:06:06,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:42:32<3:05:12,  3.44s/it]                                                       {'loss': 0.004, 'grad_norm': 0.5967643857002258, 'learning_rate': 2.7372881355932208e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:42:32<3:05:12,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:42:35<3:04:19,  3.43s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.1572338342666626, 'learning_rate': 2.7364406779661015e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:42:35<3:04:19,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:42:38<3:03:52,  3.42s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.028385858982801437, 'learning_rate': 2.7355932203389833e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:42:38<3:03:52,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:42:42<3:12:05,  3.57s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03962690755724907, 'learning_rate': 2.7347457627118645e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:42:42<3:12:05,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:42:46<3:08:07,  3.50s/it]                                                       {'loss': 0.0169, 'grad_norm': 1.5076696872711182, 'learning_rate': 2.733898305084746e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:42:46<3:08:07,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:42:49<3:05:21,  3.45s/it]                                                       {'loss': 0.262, 'grad_norm': 5.568517684936523, 'learning_rate': 2.733050847457627e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:42:49<3:05:21,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:42:53<3:07:00,  3.48s/it]                                                       {'loss': 0.0991, 'grad_norm': 5.907354831695557, 'learning_rate': 2.732203389830509e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:42:53<3:07:00,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:42:56<3:04:07,  3.43s/it]                                                       {'loss': 0.0332, 'grad_norm': 3.8510687351226807, 'learning_rate': 2.73135593220339e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:42:56<3:04:07,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:42:59<3:05:52,  3.46s/it]                                                       {'loss': 0.2038, 'grad_norm': 8.698076248168945, 'learning_rate': 2.7305084745762715e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:42:59<3:05:52,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:43:03<3:04:31,  3.44s/it]                                                       {'loss': 0.0282, 'grad_norm': 2.387982130050659, 'learning_rate': 2.7296610169491526e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:43:03<3:04:31,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:43:06<3:02:26,  3.40s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.4694597721099854, 'learning_rate': 2.7288135593220337e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:43:06<3:02:26,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:43:10<3:07:21,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.5245960354804993, 'learning_rate': 2.7279661016949155e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:43:10<3:07:21,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:43:13<3:07:50,  3.50s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.35450345277786255, 'learning_rate': 2.7271186440677963e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:43:13<3:07:50,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:43:17<3:04:29,  3.44s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6917293667793274, 'learning_rate': 2.726271186440678e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:43:17<3:04:29,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:43:20<3:05:36,  3.46s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.327479362487793, 'learning_rate': 2.7254237288135593e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:43:20<3:05:36,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:43:24<3:10:55,  3.56s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.6328889727592468, 'learning_rate': 2.7245762711864407e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:43:24<3:10:55,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:43:28<3:10:56,  3.56s/it]                                                       {'loss': 0.0389, 'grad_norm': 4.394882678985596, 'learning_rate': 2.723728813559322e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:43:28<3:10:56,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:43:31<3:09:56,  3.55s/it]                                                       {'loss': 0.1351, 'grad_norm': 6.722649097442627, 'learning_rate': 2.7228813559322037e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:43:31<3:09:56,  3.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:43:35<3:08:14,  3.52s/it]                                                       {'loss': 0.1342, 'grad_norm': 6.1461567878723145, 'learning_rate': 2.7220338983050848e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:43:35<3:08:14,  3.52s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:43:38<3:05:41,  3.47s/it]                                                       {'loss': 0.1924, 'grad_norm': 10.8582763671875, 'learning_rate': 2.7211864406779663e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:43:38<3:05:41,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:43:41<3:04:06,  3.44s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.8912927508354187, 'learning_rate': 2.7203389830508474e-05, 'epoch': 0.47}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:43:41<3:04:06,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:43:45<3:03:55,  3.44s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3698437511920929, 'learning_rate': 2.7194915254237292e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:43:45<3:03:55,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:43:48<3:03:33,  3.43s/it]                                                       {'loss': 0.0698, 'grad_norm': 5.592118263244629, 'learning_rate': 2.7186440677966103e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:43:48<3:03:33,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:43:52<3:03:19,  3.43s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.1571601778268814, 'learning_rate': 2.7177966101694918e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:43:52<3:03:19,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:43:55<3:10:11,  3.56s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.0321414470672607, 'learning_rate': 2.716949152542373e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:43:55<3:10:11,  3.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:43:59<3:07:07,  3.50s/it]                                                       {'loss': 0.1279, 'grad_norm': 8.480451583862305, 'learning_rate': 2.7161016949152547e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:43:59<3:07:07,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:44:02<3:04:24,  3.45s/it]                                                       {'loss': 0.2755, 'grad_norm': 11.240478515625, 'learning_rate': 2.7152542372881355e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:44:02<3:04:24,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:44:06<3:04:49,  3.46s/it]                                                       {'loss': 0.0545, 'grad_norm': 5.073224067687988, 'learning_rate': 2.7144067796610173e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:44:06<3:04:49,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:44:09<3:04:55,  3.47s/it]                                                       {'loss': 0.0952, 'grad_norm': 3.60811185836792, 'learning_rate': 2.7135593220338985e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:44:09<3:04:55,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:44:13<3:04:12,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08605517446994781, 'learning_rate': 2.71271186440678e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:44:13<3:04:12,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:44:16<3:01:24,  3.40s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3949901759624481, 'learning_rate': 2.711864406779661e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:44:16<3:01:24,  3.40s/it][2025-10-20 02:21:21,105] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:44:21<3:36:04,  4.05s/it]                                                       {'loss': 0.0621, 'grad_norm': 4.8916239738464355, 'learning_rate': 2.7110169491525422e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:44:21<3:36:04,  4.05s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:44:25<3:25:07,  3.85s/it]                                                       {'loss': 0.0147, 'grad_norm': 0.9776778817176819, 'learning_rate': 2.710169491525424e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:44:25<3:25:07,  3.85s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:44:28<3:17:49,  3.71s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.281738519668579, 'learning_rate': 2.709322033898305e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:44:28<3:17:49,  3.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:44:32<3:13:18,  3.63s/it]                                                       {'loss': 0.1565, 'grad_norm': 6.274387359619141, 'learning_rate': 2.7084745762711866e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:44:32<3:13:18,  3.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:44:35<3:13:53,  3.64s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.01858825609087944, 'learning_rate': 2.7076271186440677e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:44:35<3:13:53,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:44:39<3:09:17,  3.56s/it]                                                       {'loss': 0.0531, 'grad_norm': 3.7147045135498047, 'learning_rate': 2.7067796610169495e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:44:39<3:09:17,  3.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:44:42<3:07:37,  3.53s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.0407225638628006, 'learning_rate': 2.7059322033898303e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:44:42<3:07:37,  3.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:44:45<3:05:04,  3.48s/it]                                                       {'loss': 0.0418, 'grad_norm': 1.4748506546020508, 'learning_rate': 2.705084745762712e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:44:45<3:05:04,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:44:49<3:04:53,  3.48s/it]                                                       {'loss': 0.1771, 'grad_norm': 8.389007568359375, 'learning_rate': 2.7042372881355932e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:44:49<3:04:53,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:44:53<3:13:55,  3.65s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.34495943784713745, 'learning_rate': 2.7033898305084747e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:44:53<3:13:55,  3.65s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:44:57<3:12:54,  3.63s/it]                                                       {'loss': 0.0908, 'grad_norm': 7.954901695251465, 'learning_rate': 2.702542372881356e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:44:57<3:12:54,  3.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:45:00<3:08:24,  3.55s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.8503899574279785, 'learning_rate': 2.7016949152542376e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:45:00<3:08:24,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:45:03<3:06:41,  3.51s/it]                                                       {'loss': 0.03, 'grad_norm': 3.714022397994995, 'learning_rate': 2.7008474576271188e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:45:03<3:06:41,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:45:07<3:05:41,  3.50s/it]                                                       {'loss': 0.1568, 'grad_norm': 7.352535247802734, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:45:07<3:05:41,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:45:10<3:04:18,  3.47s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.264337420463562, 'learning_rate': 2.6991525423728814e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:45:10<3:04:18,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:45:14<3:03:09,  3.45s/it]                                                       {'loss': 0.1339, 'grad_norm': 6.984333515167236, 'learning_rate': 2.6983050847457632e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:45:14<3:03:09,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:45:17<3:06:22,  3.51s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.2125433683395386, 'learning_rate': 2.6974576271186443e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:45:17<3:06:22,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:45:21<3:06:35,  3.52s/it]                                                       {'loss': 0.1648, 'grad_norm': 7.923708438873291, 'learning_rate': 2.6966101694915258e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:45:21<3:06:35,  3.52s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:45:24<3:05:49,  3.51s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.5929932594299316, 'learning_rate': 2.695762711864407e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:45:24<3:05:49,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:45:28<3:17:05,  3.72s/it]                                                       {'loss': 0.0167, 'grad_norm': 1.9983278512954712, 'learning_rate': 2.6949152542372884e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:45:28<3:17:05,  3.72s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:45:32<3:12:56,  3.64s/it]                                                       {'loss': 0.0415, 'grad_norm': 5.416545391082764, 'learning_rate': 2.6940677966101695e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:45:32<3:12:56,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:45:35<3:08:11,  3.55s/it]                                                       {'loss': 0.0911, 'grad_norm': 3.9130077362060547, 'learning_rate': 2.6932203389830506e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:45:35<3:08:11,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:45:39<3:05:10,  3.50s/it]                                                       {'loss': 0.1183, 'grad_norm': 6.5027360916137695, 'learning_rate': 2.6923728813559324e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:45:39<3:05:10,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:45:42<3:03:17,  3.46s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.8485396504402161, 'learning_rate': 2.6915254237288136e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:45:42<3:03:17,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:45:46<3:03:36,  3.47s/it]                                                       {'loss': 0.0153, 'grad_norm': 1.919014573097229, 'learning_rate': 2.690677966101695e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:45:46<3:03:36,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:45:49<3:01:59,  3.44s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.1270084381103516, 'learning_rate': 2.689830508474576e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:45:49<3:01:59,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:45:52<3:02:29,  3.45s/it]                                                       {'loss': 0.007, 'grad_norm': 0.7672474980354309, 'learning_rate': 2.688983050847458e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:45:52<3:02:29,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:45:56<3:01:52,  3.44s/it]                                                       {'loss': 0.0566, 'grad_norm': 5.883295059204102, 'learning_rate': 2.688135593220339e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:45:56<3:01:52,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:45:59<3:00:21,  3.41s/it]                                                       {'loss': 0.1544, 'grad_norm': 11.828903198242188, 'learning_rate': 2.6872881355932206e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:45:59<3:00:21,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:46:03<3:00:24,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07879638671875, 'learning_rate': 2.6864406779661017e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:46:03<3:00:24,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:46:06<3:00:01,  3.41s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3415663540363312, 'learning_rate': 2.685593220338983e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:46:06<3:00:01,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:46:09<2:58:44,  3.39s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.891955852508545, 'learning_rate': 2.6847457627118643e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:46:09<2:58:44,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:46:13<2:59:43,  3.40s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.31203144788742065, 'learning_rate': 2.683898305084746e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:46:13<2:59:43,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:46:16<2:59:05,  3.39s/it]                                                       {'loss': 0.0449, 'grad_norm': 3.8508617877960205, 'learning_rate': 2.6830508474576272e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:46:16<2:59:05,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:46:19<2:59:26,  3.40s/it]                                                       {'loss': 0.0802, 'grad_norm': 8.936745643615723, 'learning_rate': 2.6822033898305087e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:46:19<2:59:26,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:46:23<2:58:48,  3.39s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.44088926911354065, 'learning_rate': 2.6813559322033898e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:46:23<2:58:48,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:46:26<2:57:45,  3.37s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05979001522064209, 'learning_rate': 2.6805084745762716e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:46:26<2:57:45,  3.37s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:46:30<2:59:05,  3.40s/it]                                                       {'loss': 0.0533, 'grad_norm': 5.630944728851318, 'learning_rate': 2.6796610169491527e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:46:30<2:59:05,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:46:33<2:58:08,  3.38s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9761490225791931, 'learning_rate': 2.6788135593220342e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:46:33<2:58:08,  3.38s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:46:36<2:58:36,  3.39s/it]                                                       {'loss': 0.0524, 'grad_norm': 4.619911193847656, 'learning_rate': 2.6779661016949153e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:46:36<2:58:36,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:46:40<2:59:45,  3.41s/it]                                                       {'loss': 0.0291, 'grad_norm': 3.481207847595215, 'learning_rate': 2.677118644067797e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:46:40<2:59:45,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:46:44<3:05:57,  3.53s/it]                                                       {'loss': 0.0112, 'grad_norm': 0.8651288747787476, 'learning_rate': 2.676271186440678e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:46:44<3:05:57,  3.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:46:47<3:10:13,  3.62s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.1864968538284302, 'learning_rate': 2.675423728813559e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:46:47<3:10:13,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:46:51<3:05:13,  3.52s/it]                                                       {'loss': 0.1328, 'grad_norm': 5.707200050354004, 'learning_rate': 2.674576271186441e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:46:51<3:05:13,  3.52s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:46:54<3:03:49,  3.50s/it]                                                       {'loss': 0.0126, 'grad_norm': 0.7551375031471252, 'learning_rate': 2.673728813559322e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:46:54<3:03:49,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:46:58<3:09:32,  3.61s/it]                                                       {'loss': 0.1157, 'grad_norm': 5.305572986602783, 'learning_rate': 2.6728813559322035e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:46:58<3:09:32,  3.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:47:02<3:11:04,  3.64s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.49929529428482056, 'learning_rate': 2.6720338983050846e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:47:02<3:11:04,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:47:06<3:13:41,  3.69s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.8605201840400696, 'learning_rate': 2.6711864406779664e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:47:06<3:13:41,  3.69s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:47:09<3:10:45,  3.63s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.48002755641937256, 'learning_rate': 2.6703389830508475e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:47:09<3:10:45,  3.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:47:12<3:05:35,  3.54s/it]                                                       {'loss': 0.0499, 'grad_norm': 5.144430637359619, 'learning_rate': 2.669491525423729e-05, 'epoch': 0.47}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:47:12<3:05:35,  3.54s/it][2025-10-20 02:24:17,746] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:47:18<3:40:16,  4.20s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3235035240650177, 'learning_rate': 2.66864406779661e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:47:18<3:40:16,  4.20s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:47:22<3:29:33,  3.99s/it]                                                       {'loss': 0.1914, 'grad_norm': 8.041196823120117, 'learning_rate': 2.667796610169492e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:47:22<3:29:33,  3.99s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:47:25<3:19:45,  3.81s/it]                                                       {'loss': 0.1665, 'grad_norm': 8.537154197692871, 'learning_rate': 2.6669491525423727e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:47:25<3:19:45,  3.81s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:47:29<3:18:27,  3.78s/it]                                                       {'loss': 0.0254, 'grad_norm': 2.698817253112793, 'learning_rate': 2.6661016949152545e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:47:29<3:18:27,  3.78s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:47:32<3:11:10,  3.65s/it]                                                       {'loss': 0.0685, 'grad_norm': 5.918381690979004, 'learning_rate': 2.6652542372881357e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:47:32<3:11:10,  3.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:47:36<3:07:29,  3.58s/it]                                                       {'loss': 0.0233, 'grad_norm': 1.9453725814819336, 'learning_rate': 2.664406779661017e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:47:36<3:07:29,  3.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:47:39<3:03:40,  3.51s/it]                                                       {'loss': 0.254, 'grad_norm': 8.38552188873291, 'learning_rate': 2.6635593220338983e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:47:39<3:03:40,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:47:42<3:04:52,  3.53s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.385369300842285, 'learning_rate': 2.66271186440678e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:47:42<3:04:52,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:47:46<3:04:35,  3.53s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.6388213634490967, 'learning_rate': 2.6618644067796612e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:47:46<3:04:35,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:47:49<3:03:37,  3.51s/it]                                                       {'loss': 0.0341, 'grad_norm': 2.628222703933716, 'learning_rate': 2.6610169491525427e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:47:49<3:03:37,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:47:53<3:02:34,  3.49s/it]                                                       {'loss': 0.0269, 'grad_norm': 4.403678894042969, 'learning_rate': 2.6601694915254238e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:47:53<3:02:34,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:47:56<3:00:55,  3.46s/it]                                                       {'loss': 0.2652, 'grad_norm': 7.3460469245910645, 'learning_rate': 2.6593220338983056e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:47:56<3:00:55,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:48:00<3:01:13,  3.47s/it]                                                       {'loss': 0.0743, 'grad_norm': 4.264872074127197, 'learning_rate': 2.6584745762711867e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:48:00<3:01:13,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:48:03<2:59:29,  3.43s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5112459063529968, 'learning_rate': 2.6576271186440675e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:48:03<2:59:29,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:48:07<3:01:31,  3.47s/it]                                                       {'loss': 0.0181, 'grad_norm': 2.7797017097473145, 'learning_rate': 2.6567796610169493e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:48:07<3:01:31,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:48:10<3:00:13,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05872037261724472, 'learning_rate': 2.6559322033898304e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:48:10<3:00:13,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:48:13<2:59:19,  3.43s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.47906485199928284, 'learning_rate': 2.655084745762712e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:48:13<2:59:19,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:48:17<3:00:55,  3.47s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.041962213814258575, 'learning_rate': 2.654237288135593e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:48:17<3:00:55,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:48:21<3:03:06,  3.51s/it]                                                       {'loss': 0.0763, 'grad_norm': 5.37451171875, 'learning_rate': 2.653389830508475e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:48:21<3:03:06,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:48:24<2:59:45,  3.45s/it]                                                       {'loss': 0.009, 'grad_norm': 1.2641677856445312, 'learning_rate': 2.652542372881356e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:48:24<2:59:45,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:48:27<2:58:22,  3.42s/it]                                                       {'loss': 0.0641, 'grad_norm': 5.533454895019531, 'learning_rate': 2.6516949152542374e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:48:27<2:58:22,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:48:31<2:58:39,  3.43s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.443621873855591, 'learning_rate': 2.6508474576271186e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:48:31<2:58:39,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:48:34<2:58:01,  3.42s/it]                                                       {'loss': 0.0965, 'grad_norm': 8.213080406188965, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:48:34<2:58:01,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:48:38<2:58:36,  3.43s/it]                                                       {'loss': 0.0048, 'grad_norm': 1.076663613319397, 'learning_rate': 2.6491525423728815e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:48:38<2:58:36,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:48:41<2:57:04,  3.40s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2476188838481903, 'learning_rate': 2.648305084745763e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:48:41<2:57:04,  3.40s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:48:44<2:58:41,  3.43s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.5048961639404297, 'learning_rate': 2.647457627118644e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:48:44<2:58:41,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:48:48<2:59:17,  3.44s/it]                                                       {'loss': 0.023, 'grad_norm': 2.719193935394287, 'learning_rate': 2.6466101694915256e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:48:48<2:59:17,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:48:51<2:58:18,  3.43s/it]                                                       {'loss': 0.0601, 'grad_norm': 4.588874816894531, 'learning_rate': 2.6457627118644067e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:48:51<2:58:18,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:48:55<2:57:24,  3.41s/it]                                                       {'loss': 0.1038, 'grad_norm': 3.2483301162719727, 'learning_rate': 2.6449152542372885e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:48:55<2:57:24,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:48:59<3:04:49,  3.55s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.14676149189472198, 'learning_rate': 2.6440677966101696e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:48:59<3:04:49,  3.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:49:02<3:01:06,  3.48s/it]                                                       {'loss': 0.006, 'grad_norm': 0.5973581671714783, 'learning_rate': 2.643220338983051e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:49:02<3:01:06,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:49:05<2:58:57,  3.44s/it]                                                       {'loss': 0.0268, 'grad_norm': 3.5571236610412598, 'learning_rate': 2.6423728813559322e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:49:05<2:58:57,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:49:09<2:57:17,  3.41s/it]                                                       {'loss': 0.0387, 'grad_norm': 4.819115161895752, 'learning_rate': 2.641525423728814e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:49:09<2:57:17,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:49:12<2:57:36,  3.42s/it]                                                       {'loss': 0.0212, 'grad_norm': 3.121439218521118, 'learning_rate': 2.640677966101695e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:49:12<2:57:36,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:49:16<3:11:23,  3.69s/it]                                                       {'loss': 0.0359, 'grad_norm': 2.940797805786133, 'learning_rate': 2.6398305084745763e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:49:16<3:11:23,  3.69s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:49:20<3:06:12,  3.59s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.45154228806495667, 'learning_rate': 2.6389830508474578e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:49:20<3:06:12,  3.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:49:23<3:03:52,  3.54s/it]                                                       {'loss': 0.0496, 'grad_norm': 2.1848700046539307, 'learning_rate': 2.638135593220339e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:49:23<3:03:52,  3.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:49:27<3:01:54,  3.51s/it]                                                       {'loss': 0.1072, 'grad_norm': 5.367653846740723, 'learning_rate': 2.6372881355932204e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:49:27<3:01:54,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:49:30<3:00:13,  3.48s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4478479027748108, 'learning_rate': 2.6364406779661015e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:49:30<3:00:13,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:49:33<2:59:16,  3.46s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.2883257865905762, 'learning_rate': 2.6355932203389833e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:49:33<2:59:16,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:49:37<2:59:54,  3.47s/it]                                                       {'loss': 0.1204, 'grad_norm': 5.8533525466918945, 'learning_rate': 2.6347457627118644e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:49:37<2:59:54,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:49:40<2:58:01,  3.44s/it]                                                       {'loss': 0.3791, 'grad_norm': 8.1436185836792, 'learning_rate': 2.633898305084746e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:49:40<2:58:01,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:49:44<2:59:17,  3.46s/it]                                                       {'loss': 0.1336, 'grad_norm': 8.277932167053223, 'learning_rate': 2.633050847457627e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:49:44<2:59:17,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:49:47<2:57:27,  3.43s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.9743308424949646, 'learning_rate': 2.6322033898305088e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:49:47<2:57:27,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:49:50<2:56:45,  3.42s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.702416181564331, 'learning_rate': 2.63135593220339e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:49:50<2:56:45,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [2:49:54<3:00:40,  3.49s/it]                                                       {'loss': 0.0429, 'grad_norm': 3.881086587905884, 'learning_rate': 2.6305084745762714e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [2:49:54<3:00:40,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [2:49:58<2:59:03,  3.46s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.3763790726661682, 'learning_rate': 2.6296610169491525e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [2:49:58<2:59:03,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [2:50:01<2:57:55,  3.44s/it]                                                       {'loss': 0.2342, 'grad_norm': 8.310023307800293, 'learning_rate': 2.6288135593220344e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [2:50:01<2:57:55,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [2:50:04<2:55:40,  3.40s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.2009168118238449, 'learning_rate': 2.627966101694915e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [2:50:04<2:55:40,  3.40s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [2:50:08<2:55:47,  3.40s/it]                                                       {'loss': 0.0522, 'grad_norm': 6.1220598220825195, 'learning_rate': 2.627118644067797e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [2:50:08<2:55:47,  3.40s/it][2025-10-20 02:27:12,931] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [2:50:14<3:37:50,  4.22s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.7181764245033264, 'learning_rate': 2.626271186440678e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [2:50:14<3:37:50,  4.22s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [2:50:17<3:27:16,  4.01s/it]                                                       {'loss': 0.2732, 'grad_norm': 7.708460330963135, 'learning_rate': 2.6254237288135595e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [2:50:17<3:27:16,  4.01s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [2:50:21<3:16:25,  3.81s/it]                                                       {'loss': 0.0183, 'grad_norm': 2.9678783416748047, 'learning_rate': 2.6245762711864407e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [2:50:21<3:16:25,  3.81s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [2:50:24<3:08:47,  3.66s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.7505518794059753, 'learning_rate': 2.6237288135593225e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [2:50:24<3:08:47,  3.66s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [2:50:27<3:03:17,  3.55s/it]                                                       {'loss': 0.0264, 'grad_norm': 3.0679943561553955, 'learning_rate': 2.6228813559322036e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [2:50:27<3:03:17,  3.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [2:50:31<3:00:35,  3.50s/it]                                                       {'loss': 0.0232, 'grad_norm': 1.8557130098342896, 'learning_rate': 2.6220338983050847e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [2:50:31<3:00:35,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [2:50:34<2:57:21,  3.44s/it]                                                       {'loss': 0.025, 'grad_norm': 2.984179973602295, 'learning_rate': 2.6211864406779662e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [2:50:34<2:57:21,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [2:50:37<2:55:48,  3.41s/it]                                                       {'loss': 0.0124, 'grad_norm': 0.927065908908844, 'learning_rate': 2.6203389830508473e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [2:50:37<2:55:48,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [2:50:41<2:55:25,  3.41s/it]                                                       {'loss': 0.2626, 'grad_norm': 8.542057991027832, 'learning_rate': 2.619491525423729e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [2:50:41<2:55:25,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [2:50:44<2:55:47,  3.41s/it]                                                       {'loss': 0.1491, 'grad_norm': 5.052485942840576, 'learning_rate': 2.61864406779661e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [2:50:44<2:55:47,  3.41s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [2:50:47<2:56:02,  3.42s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.17640112340450287, 'learning_rate': 2.6177966101694917e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [2:50:47<2:56:02,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [2:50:51<2:55:09,  3.40s/it]                                                       {'loss': 0.0608, 'grad_norm': 5.751553535461426, 'learning_rate': 2.616949152542373e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [2:50:51<2:55:09,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [2:50:54<2:55:26,  3.41s/it]                                                       {'loss': 0.0773, 'grad_norm': 2.4853196144104004, 'learning_rate': 2.6161016949152543e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [2:50:54<2:55:26,  3.41s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [2:50:58<2:55:40,  3.42s/it]                                                       {'loss': 0.0687, 'grad_norm': 3.0021519660949707, 'learning_rate': 2.6152542372881355e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [2:50:58<2:55:40,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [2:51:01<2:55:58,  3.42s/it]                                                       {'loss': 0.3955, 'grad_norm': 10.157235145568848, 'learning_rate': 2.6144067796610173e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [2:51:01<2:55:58,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [2:51:05<3:07:35,  3.65s/it]                                                       {'loss': 0.0169, 'grad_norm': 1.9541937112808228, 'learning_rate': 2.6135593220338984e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [2:51:05<3:07:35,  3.65s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [2:51:09<3:02:33,  3.55s/it]                                                       {'loss': 0.1695, 'grad_norm': 5.505436420440674, 'learning_rate': 2.61271186440678e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [2:51:09<3:02:33,  3.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [2:51:12<3:01:27,  3.53s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.1883784830570221, 'learning_rate': 2.611864406779661e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [2:51:12<3:01:27,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [2:51:16<3:00:42,  3.52s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.9084708094596863, 'learning_rate': 2.6110169491525428e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [2:51:16<3:00:42,  3.52s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [2:51:19<2:59:59,  3.51s/it]                                                       {'loss': 0.0725, 'grad_norm': 5.552107334136963, 'learning_rate': 2.610169491525424e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [2:51:19<2:59:59,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [2:51:22<2:58:04,  3.47s/it]                                                       {'loss': 0.0292, 'grad_norm': 2.667787790298462, 'learning_rate': 2.6093220338983054e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [2:51:22<2:58:04,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [2:51:26<2:56:57,  3.45s/it]                                                       {'loss': 0.0367, 'grad_norm': 4.492724895477295, 'learning_rate': 2.6084745762711865e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [2:51:26<2:56:57,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [2:51:31<3:26:29,  4.03s/it]                                                       {'loss': 0.1047, 'grad_norm': 3.68699049949646, 'learning_rate': 2.6076271186440683e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [2:51:31<3:26:29,  4.03s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [2:51:35<3:23:16,  3.97s/it]                                                       {'loss': 0.0419, 'grad_norm': 2.6251344680786133, 'learning_rate': 2.606779661016949e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [2:51:35<3:23:16,  3.97s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [2:51:38<3:14:26,  3.79s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13634324073791504, 'learning_rate': 2.605932203389831e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [2:51:38<3:14:26,  3.79s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [2:51:42<3:07:36,  3.66s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.647671103477478, 'learning_rate': 2.605084745762712e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [2:51:42<3:07:36,  3.66s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [2:51:45<3:04:44,  3.61s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.2748578190803528, 'learning_rate': 2.6042372881355932e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [2:51:45<3:04:44,  3.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [2:51:49<3:03:31,  3.58s/it]                                                       {'loss': 0.1075, 'grad_norm': 5.252266883850098, 'learning_rate': 2.6033898305084746e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [2:51:49<3:03:31,  3.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [2:51:53<3:07:34,  3.66s/it]                                                       {'loss': 0.0744, 'grad_norm': 6.865900993347168, 'learning_rate': 2.6025423728813558e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [2:51:53<3:07:34,  3.66s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [2:51:56<3:03:37,  3.59s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.6076940298080444, 'learning_rate': 2.6016949152542376e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [2:51:56<3:03:37,  3.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [2:52:00<3:01:05,  3.54s/it]                                                       {'loss': 0.0276, 'grad_norm': 3.0678257942199707, 'learning_rate': 2.6008474576271187e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [2:52:00<3:01:05,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [2:52:03<2:59:33,  3.51s/it]                                                       {'loss': 0.1067, 'grad_norm': 6.451044082641602, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [2:52:03<2:59:33,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [2:52:07<3:00:18,  3.53s/it]                                                       {'loss': 0.151, 'grad_norm': 7.852035999298096, 'learning_rate': 2.5991525423728813e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [2:52:07<3:00:18,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [2:52:10<2:57:45,  3.48s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.1553902626037598, 'learning_rate': 2.598305084745763e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [2:52:10<2:57:45,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [2:52:13<2:56:27,  3.45s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10648132115602493, 'learning_rate': 2.597457627118644e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [2:52:13<2:56:27,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [2:52:17<2:57:01,  3.47s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.230981707572937, 'learning_rate': 2.5966101694915257e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [2:52:17<2:57:01,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [2:52:21<3:03:41,  3.60s/it]                                                       {'loss': 0.0217, 'grad_norm': 2.702341079711914, 'learning_rate': 2.595762711864407e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [2:52:21<3:03:41,  3.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [2:52:24<3:00:02,  3.53s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.3183072507381439, 'learning_rate': 2.5949152542372883e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [2:52:24<3:00:02,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [2:52:28<2:58:30,  3.50s/it]                                                       {'loss': 0.0108, 'grad_norm': 0.7873972654342651, 'learning_rate': 2.5940677966101694e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [2:52:28<2:58:30,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [2:52:31<2:56:11,  3.45s/it]                                                       {'loss': 0.1907, 'grad_norm': 6.175914287567139, 'learning_rate': 2.5932203389830512e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [2:52:31<2:56:11,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [2:52:34<2:55:31,  3.44s/it]                                                       {'loss': 0.0392, 'grad_norm': 2.6862409114837646, 'learning_rate': 2.5923728813559324e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [2:52:34<2:55:31,  3.44s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [2:52:38<3:00:42,  3.55s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5317295789718628, 'learning_rate': 2.591525423728814e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [2:52:38<3:00:42,  3.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [2:52:41<2:59:00,  3.51s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3827080726623535, 'learning_rate': 2.590677966101695e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [2:52:42<2:59:00,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [2:52:45<2:58:33,  3.51s/it]                                                       {'loss': 0.0623, 'grad_norm': 6.7882981300354, 'learning_rate': 2.5898305084745768e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [2:52:45<2:58:33,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [2:52:48<2:56:24,  3.46s/it]                                                       {'loss': 0.1545, 'grad_norm': 7.966553211212158, 'learning_rate': 2.588983050847458e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [2:52:48<2:56:24,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [2:52:52<2:54:18,  3.42s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1474689096212387, 'learning_rate': 2.5881355932203394e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [2:52:52<2:54:18,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [2:52:55<2:59:23,  3.53s/it]                                                       {'loss': 0.0215, 'grad_norm': 1.6548703908920288, 'learning_rate': 2.5872881355932205e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [2:52:55<2:59:23,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [2:52:59<3:00:49,  3.55s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.4334501028060913, 'learning_rate': 2.5864406779661016e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [2:52:59<3:00:49,  3.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [2:53:02<2:57:48,  3.50s/it]                                                       {'loss': 0.0562, 'grad_norm': 5.434153079986572, 'learning_rate': 2.585593220338983e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [2:53:02<2:57:48,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [2:53:06<2:57:05,  3.48s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.023622989654541, 'learning_rate': 2.5847457627118642e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [2:53:06<2:57:05,  3.48s/it][2025-10-20 02:30:11,211] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [2:53:12<3:29:44,  4.13s/it]                                                       {'loss': 0.0161, 'grad_norm': 1.937247395515442, 'learning_rate': 2.583898305084746e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [2:53:12<3:29:44,  4.13s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [2:53:15<3:19:31,  3.93s/it]                                                       {'loss': 0.1035, 'grad_norm': 6.5713629722595215, 'learning_rate': 2.583050847457627e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [2:53:15<3:19:31,  3.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [2:53:18<3:10:19,  3.75s/it]                                                       {'loss': 0.1116, 'grad_norm': 7.544299125671387, 'learning_rate': 2.5822033898305086e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [2:53:18<3:10:19,  3.75s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [2:53:22<3:05:05,  3.65s/it]                                                       {'loss': 0.0415, 'grad_norm': 4.334876537322998, 'learning_rate': 2.5813559322033898e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [2:53:22<3:05:05,  3.65s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [2:53:25<3:00:41,  3.56s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.5199626684188843, 'learning_rate': 2.5805084745762716e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [2:53:25<3:00:41,  3.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [2:53:28<2:56:39,  3.48s/it]                                                       {'loss': 0.0904, 'grad_norm': 5.701406955718994, 'learning_rate': 2.5796610169491527e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [2:53:28<2:56:39,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [2:53:32<2:54:44,  3.45s/it]                                                       {'loss': 0.0376, 'grad_norm': 3.1309311389923096, 'learning_rate': 2.578813559322034e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [2:53:32<2:54:44,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [2:53:35<2:53:08,  3.42s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.6267942190170288, 'learning_rate': 2.5779661016949153e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [2:53:35<2:53:08,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [2:53:39<2:54:58,  3.45s/it]                                                       {'loss': 0.0192, 'grad_norm': 3.925459384918213, 'learning_rate': 2.5771186440677967e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [2:53:39<2:54:58,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [2:53:42<2:57:14,  3.50s/it]                                                       {'loss': 0.0403, 'grad_norm': 3.8068532943725586, 'learning_rate': 2.576271186440678e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [2:53:42<2:57:14,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [2:53:46<2:56:29,  3.48s/it]                                                       {'loss': 0.3532, 'grad_norm': 8.832497596740723, 'learning_rate': 2.5754237288135597e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [2:53:46<2:56:29,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [2:53:49<2:55:04,  3.46s/it]                                                       {'loss': 0.0688, 'grad_norm': 5.244063377380371, 'learning_rate': 2.5745762711864408e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [2:53:49<2:55:04,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [2:53:53<2:57:04,  3.50s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.547181248664856, 'learning_rate': 2.5737288135593223e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [2:53:53<2:57:04,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [2:53:56<2:55:26,  3.47s/it]                                                       {'loss': 0.1415, 'grad_norm': 6.232992649078369, 'learning_rate': 2.5728813559322034e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [2:53:56<2:55:26,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [2:54:00<2:55:50,  3.48s/it]                                                       {'loss': 0.0365, 'grad_norm': 3.636413335800171, 'learning_rate': 2.5720338983050852e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [2:54:00<2:55:50,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [2:54:03<2:55:09,  3.46s/it]                                                       {'loss': 0.131, 'grad_norm': 7.4978837966918945, 'learning_rate': 2.5711864406779663e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [2:54:03<2:55:09,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [2:54:06<2:53:34,  3.43s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3383263051509857, 'learning_rate': 2.5703389830508475e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [2:54:06<2:53:34,  3.43s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [2:54:10<2:51:22,  3.39s/it]                                                       {'loss': 0.0255, 'grad_norm': 2.5109190940856934, 'learning_rate': 2.569491525423729e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [2:54:10<2:51:22,  3.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [2:54:13<2:53:15,  3.43s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0469149686396122, 'learning_rate': 2.56864406779661e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [2:54:13<2:53:15,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [2:54:16<2:51:40,  3.40s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06176118180155754, 'learning_rate': 2.5677966101694915e-05, 'epoch': 0.49}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [2:54:16<2:51:40,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [2:54:20<2:51:41,  3.40s/it]                                                       {'loss': 0.1781, 'grad_norm': 9.33761978149414, 'learning_rate': 2.5669491525423727e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [2:54:20<2:51:41,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [2:54:23<2:52:02,  3.41s/it]                                                       {'loss': 0.0136, 'grad_norm': 2.327928066253662, 'learning_rate': 2.5661016949152545e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [2:54:23<2:52:02,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [2:54:27<2:53:55,  3.45s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.0558712482452393, 'learning_rate': 2.5652542372881356e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [2:54:27<2:53:55,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [2:54:30<2:52:56,  3.43s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.47476205229759216, 'learning_rate': 2.564406779661017e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [2:54:30<2:52:56,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [2:54:34<2:55:18,  3.48s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.5214171409606934, 'learning_rate': 2.5635593220338982e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [2:54:34<2:55:18,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [2:54:37<2:55:48,  3.49s/it]                                                       {'loss': 0.0365, 'grad_norm': 4.120388507843018, 'learning_rate': 2.56271186440678e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [2:54:37<2:55:48,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [2:54:41<3:00:22,  3.58s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4942886233329773, 'learning_rate': 2.561864406779661e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [2:54:41<3:00:22,  3.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [2:54:44<2:56:21,  3.50s/it]                                                       {'loss': 0.0732, 'grad_norm': 4.896265506744385, 'learning_rate': 2.5610169491525426e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [2:54:44<2:56:21,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [2:54:48<2:54:55,  3.47s/it]                                                       {'loss': 0.1645, 'grad_norm': 7.991163730621338, 'learning_rate': 2.5601694915254237e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [2:54:48<2:54:55,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [2:54:52<3:00:04,  3.58s/it]                                                       {'loss': 0.0639, 'grad_norm': 4.085067272186279, 'learning_rate': 2.5593220338983055e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [2:54:52<3:00:04,  3.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [2:54:55<2:56:53,  3.52s/it]                                                       {'loss': 0.008, 'grad_norm': 1.3724931478500366, 'learning_rate': 2.5584745762711863e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [2:54:55<2:56:53,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [2:54:59<2:57:30,  3.53s/it]                                                       {'loss': 0.0571, 'grad_norm': 3.7449569702148438, 'learning_rate': 2.557627118644068e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [2:54:59<2:57:30,  3.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [2:55:02<2:55:42,  3.49s/it]                                                       {'loss': 0.0204, 'grad_norm': 2.3430874347686768, 'learning_rate': 2.5567796610169493e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [2:55:02<2:55:42,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [2:55:05<2:52:59,  3.44s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.13665679097175598, 'learning_rate': 2.5559322033898307e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [2:55:05<2:52:59,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [2:55:09<2:51:48,  3.42s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12100636214017868, 'learning_rate': 2.555084745762712e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [2:55:09<2:51:48,  3.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [2:55:12<2:56:31,  3.51s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.3380489349365234, 'learning_rate': 2.5542372881355937e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [2:55:12<2:56:31,  3.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [2:55:16<2:54:38,  3.48s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.3848802447319031, 'learning_rate': 2.5533898305084748e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [2:55:16<2:54:38,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [2:55:20<2:58:56,  3.56s/it]                                                       {'loss': 0.0559, 'grad_norm': 4.309224605560303, 'learning_rate': 2.552542372881356e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [2:55:20<2:58:56,  3.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [2:55:23<2:55:29,  3.50s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10847186297178268, 'learning_rate': 2.5516949152542374e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [2:55:23<2:55:29,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [2:55:27<3:05:06,  3.69s/it]                                                       {'loss': 0.0555, 'grad_norm': 4.770597457885742, 'learning_rate': 2.5508474576271185e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [2:55:27<3:05:06,  3.69s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [2:55:30<2:59:29,  3.58s/it]                                                       {'loss': 0.0763, 'grad_norm': 3.8448710441589355, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [2:55:30<2:59:29,  3.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [2:55:34<2:56:56,  3.53s/it]                                                       {'loss': 0.0774, 'grad_norm': 7.864707946777344, 'learning_rate': 2.549152542372881e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [2:55:34<2:56:56,  3.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [2:55:37<2:54:02,  3.47s/it]                                                       {'loss': 0.1265, 'grad_norm': 8.748292922973633, 'learning_rate': 2.548305084745763e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [2:55:37<2:54:02,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [2:55:40<2:51:37,  3.43s/it]                                                       {'loss': 0.5775, 'grad_norm': 21.61049461364746, 'learning_rate': 2.547457627118644e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [2:55:40<2:51:37,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [2:55:44<2:51:04,  3.42s/it]                                                       {'loss': 0.3705, 'grad_norm': 9.799640655517578, 'learning_rate': 2.5466101694915255e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [2:55:44<2:51:04,  3.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [2:55:48<2:54:29,  3.49s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.43936243653297424, 'learning_rate': 2.5457627118644066e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [2:55:48<2:54:29,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [2:55:51<2:53:47,  3.47s/it]                                                       {'loss': 0.002, 'grad_norm': 0.26293280720710754, 'learning_rate': 2.5449152542372884e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [2:55:51<2:53:47,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [2:55:54<2:54:05,  3.48s/it]                                                       {'loss': 0.2478, 'grad_norm': 10.50844669342041, 'learning_rate': 2.5440677966101696e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [2:55:54<2:54:05,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [2:55:58<2:59:56,  3.60s/it]                                                       {'loss': 0.0672, 'grad_norm': 5.54754638671875, 'learning_rate': 2.543220338983051e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [2:55:58<2:59:56,  3.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [2:56:02<2:57:10,  3.54s/it]                                                       {'loss': 0.0491, 'grad_norm': 5.058810710906982, 'learning_rate': 2.5423728813559322e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [2:56:02<2:57:10,  3.54s/it][2025-10-20 02:33:07,078] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [2:56:08<3:33:26,  4.27s/it]                                                       {'loss': 0.0692, 'grad_norm': 5.476180553436279, 'learning_rate': 2.541525423728814e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [2:56:08<3:33:26,  4.27s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [2:56:11<3:19:44,  4.00s/it]                                                       {'loss': 0.0872, 'grad_norm': 4.597071170806885, 'learning_rate': 2.540677966101695e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [2:56:11<3:19:44,  4.00s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [2:56:15<3:19:35,  4.00s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.5527682304382324, 'learning_rate': 2.5398305084745766e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [2:56:15<3:19:35,  4.00s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [2:56:18<3:10:01,  3.81s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3364478349685669, 'learning_rate': 2.5389830508474577e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [2:56:18<3:10:01,  3.81s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [2:56:22<3:06:22,  3.73s/it]                                                       {'loss': 0.0632, 'grad_norm': 7.006865501403809, 'learning_rate': 2.538135593220339e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [2:56:22<3:06:22,  3.73s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [2:56:26<3:03:45,  3.68s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.05539870262146, 'learning_rate': 2.5372881355932203e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [2:56:26<3:03:45,  3.68s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [2:56:29<3:04:28,  3.70s/it]                                                       {'loss': 0.0095, 'grad_norm': 0.8964045643806458, 'learning_rate': 2.536440677966102e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [2:56:29<3:04:28,  3.70s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [2:56:33<2:59:45,  3.60s/it]                                                       {'loss': 0.1837, 'grad_norm': 9.480380058288574, 'learning_rate': 2.5355932203389832e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [2:56:33<2:59:45,  3.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [2:56:36<2:57:29,  3.56s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.9252406358718872, 'learning_rate': 2.5347457627118644e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [2:56:36<2:57:29,  3.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [2:56:39<2:54:19,  3.50s/it]                                                       {'loss': 0.1713, 'grad_norm': 7.852441310882568, 'learning_rate': 2.5338983050847458e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [2:56:40<2:54:19,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [2:56:43<2:51:25,  3.44s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.49552062153816223, 'learning_rate': 2.533050847457627e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [2:56:43<2:51:25,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [2:56:46<2:49:55,  3.41s/it]                                                       {'loss': 0.2959, 'grad_norm': 6.427151679992676, 'learning_rate': 2.5322033898305088e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [2:56:46<2:49:55,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [2:56:50<2:50:24,  3.42s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.37181493639945984, 'learning_rate': 2.53135593220339e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [2:56:50<2:50:24,  3.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [2:56:53<2:49:52,  3.41s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5864036083221436, 'learning_rate': 2.5305084745762714e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [2:56:53<2:49:52,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [2:56:56<2:48:52,  3.39s/it]                                                       {'loss': 0.1777, 'grad_norm': 7.446283340454102, 'learning_rate': 2.5296610169491525e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [2:56:56<2:48:52,  3.39s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [2:57:00<2:49:51,  3.42s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.094987154006958, 'learning_rate': 2.528813559322034e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [2:57:00<2:49:51,  3.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [2:57:03<2:52:57,  3.48s/it]                                                       {'loss': 0.0307, 'grad_norm': 4.877371788024902, 'learning_rate': 2.527966101694915e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [2:57:03<2:52:57,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [2:57:07<2:52:02,  3.46s/it]                                                       {'loss': 0.0317, 'grad_norm': 4.335729122161865, 'learning_rate': 2.527118644067797e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [2:57:07<2:52:02,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [2:57:10<2:51:55,  3.46s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.04288811609148979, 'learning_rate': 2.526271186440678e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [2:57:10<2:51:55,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [2:57:14<2:49:25,  3.41s/it]                                                       {'loss': 0.1559, 'grad_norm': 6.49465799331665, 'learning_rate': 2.5254237288135595e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [2:57:14<2:49:25,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [2:57:17<2:48:18,  3.39s/it]                                                       {'loss': 0.0493, 'grad_norm': 3.6260018348693848, 'learning_rate': 2.5245762711864406e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [2:57:17<2:48:18,  3.39s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [2:57:20<2:48:23,  3.39s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.020278235897421837, 'learning_rate': 2.5237288135593224e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [2:57:20<2:48:23,  3.39s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [2:57:24<2:54:22,  3.51s/it]                                                       {'loss': 0.05, 'grad_norm': 5.201631546020508, 'learning_rate': 2.5228813559322035e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [2:57:24<2:54:22,  3.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [2:57:28<2:53:29,  3.50s/it]                                                       {'loss': 0.2941, 'grad_norm': 7.335589408874512, 'learning_rate': 2.522033898305085e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [2:57:28<2:53:29,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [2:57:31<2:50:52,  3.45s/it]                                                       {'loss': 0.2035, 'grad_norm': 7.67504358291626, 'learning_rate': 2.521186440677966e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [2:57:31<2:50:52,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [2:57:35<2:53:03,  3.49s/it]                                                       {'loss': 0.0284, 'grad_norm': 1.9429864883422852, 'learning_rate': 2.520338983050848e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [2:57:35<2:53:03,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [2:57:38<2:50:29,  3.44s/it]                                                       {'loss': 0.1021, 'grad_norm': 4.342234134674072, 'learning_rate': 2.5194915254237287e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [2:57:38<2:50:29,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [2:57:41<2:52:16,  3.48s/it]                                                       {'loss': 0.0316, 'grad_norm': 2.719238758087158, 'learning_rate': 2.5186440677966105e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [2:57:41<2:52:16,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [2:57:45<2:50:27,  3.44s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.3270520567893982, 'learning_rate': 2.5177966101694917e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [2:57:45<2:50:27,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [2:57:48<2:49:11,  3.42s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.0973745584487915, 'learning_rate': 2.5169491525423728e-05, 'epoch': 0.51}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [2:57:48<2:49:11,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [2:57:52<2:50:08,  3.44s/it]                                                       {'loss': 0.048, 'grad_norm': 2.491894245147705, 'learning_rate': 2.5161016949152543e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [2:57:52<2:50:08,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [2:57:55<2:53:49,  3.51s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.9085063934326172, 'learning_rate': 2.5152542372881354e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [2:57:55<2:53:49,  3.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [2:57:59<2:52:44,  3.49s/it]                                                       {'loss': 0.3748, 'grad_norm': 9.951435089111328, 'learning_rate': 2.5144067796610172e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [2:57:59<2:52:44,  3.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [2:58:02<2:53:02,  3.50s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3859553933143616, 'learning_rate': 2.5135593220338983e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [2:58:02<2:53:02,  3.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [2:58:06<2:54:53,  3.54s/it]                                                       {'loss': 0.0768, 'grad_norm': 4.798724174499512, 'learning_rate': 2.5127118644067798e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [2:58:06<2:54:53,  3.54s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [2:58:09<2:53:44,  3.52s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04868094250559807, 'learning_rate': 2.511864406779661e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [2:58:09<2:53:44,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [2:58:13<2:51:31,  3.47s/it]                                                       {'loss': 0.0, 'grad_norm': 0.003359472379088402, 'learning_rate': 2.5110169491525427e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [2:58:13<2:51:31,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [2:58:16<2:51:16,  3.47s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.13946600258350372, 'learning_rate': 2.5101694915254235e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [2:58:16<2:51:16,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [2:58:20<2:50:09,  3.45s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.20128697156906128, 'learning_rate': 2.5093220338983053e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [2:58:20<2:50:09,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [2:58:23<2:50:14,  3.45s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.9747120141983032, 'learning_rate': 2.5084745762711865e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [2:58:23<2:50:14,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [2:58:26<2:49:06,  3.43s/it]                                                       {'loss': 0.0242, 'grad_norm': 1.5517598390579224, 'learning_rate': 2.507627118644068e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [2:58:26<2:49:06,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [2:58:30<2:47:10,  3.39s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.22521290183067322, 'learning_rate': 2.506779661016949e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [2:58:30<2:47:10,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [2:58:33<2:47:55,  3.41s/it]                                                       {'loss': 0.0913, 'grad_norm': 7.259303569793701, 'learning_rate': 2.505932203389831e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [2:58:33<2:47:55,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [2:58:37<2:48:10,  3.41s/it]                                                       {'loss': 0.0258, 'grad_norm': 2.8434245586395264, 'learning_rate': 2.505084745762712e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [2:58:37<2:48:10,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [2:58:40<2:47:40,  3.40s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.033359844237565994, 'learning_rate': 2.5042372881355935e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [2:58:40<2:47:40,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [2:58:44<2:49:23,  3.44s/it]                                                       {'loss': 0.1942, 'grad_norm': 8.61805534362793, 'learning_rate': 2.5033898305084746e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [2:58:44<2:49:23,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [2:58:47<2:48:39,  3.43s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.1648791879415512, 'learning_rate': 2.5025423728813564e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [2:58:47<2:48:39,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [2:58:51<2:51:23,  3.48s/it]                                                       {'loss': 0.1079, 'grad_norm': 4.885339260101318, 'learning_rate': 2.5016949152542375e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [2:58:51<2:51:23,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [2:58:54<2:55:47,  3.57s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.2416183203458786, 'learning_rate': 2.500847457627119e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [2:58:54<2:55:47,  3.57s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [2:58:58<2:54:24,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.02961050346493721, 'learning_rate': 2.5e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [2:58:58<2:54:24,  3.55s/it][2025-10-20 02:36:03,124] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [2:59:04<3:32:44,  4.33s/it]                                                       {'loss': 0.2385, 'grad_norm': 9.241708755493164, 'learning_rate': 2.4991525423728816e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [2:59:04<3:32:44,  4.33s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [2:59:08<3:24:41,  4.17s/it]                                                       {'loss': 0.0969, 'grad_norm': 5.292929172515869, 'learning_rate': 2.4983050847457627e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [2:59:08<3:24:41,  4.17s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [2:59:11<3:11:55,  3.91s/it]                                                       {'loss': 0.0261, 'grad_norm': 3.47463321685791, 'learning_rate': 2.4974576271186442e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [2:59:11<3:11:55,  3.91s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [2:59:14<3:03:12,  3.73s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.503675103187561, 'learning_rate': 2.4966101694915257e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [2:59:14<3:03:12,  3.73s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [2:59:18<2:58:07,  3.63s/it]                                                       {'loss': 0.0818, 'grad_norm': 5.291109561920166, 'learning_rate': 2.495762711864407e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [2:59:18<2:58:07,  3.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [2:59:21<2:55:50,  3.58s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6971778869628906, 'learning_rate': 2.4949152542372882e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [2:59:21<2:55:50,  3.58s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [2:59:25<2:52:46,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14074744284152985, 'learning_rate': 2.4940677966101697e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [2:59:25<2:52:46,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [2:59:28<2:50:38,  3.48s/it]                                                       {'loss': 0.0277, 'grad_norm': 3.0504813194274902, 'learning_rate': 2.4932203389830512e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [2:59:28<2:50:38,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [2:59:32<2:58:39,  3.64s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.31782153248786926, 'learning_rate': 2.4923728813559323e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [2:59:32<2:58:39,  3.64s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [2:59:36<2:58:55,  3.65s/it]                                                       {'loss': 0.0227, 'grad_norm': 2.7285122871398926, 'learning_rate': 2.4915254237288138e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [2:59:36<2:58:55,  3.65s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [2:59:39<2:55:50,  3.59s/it]                                                       {'loss': 0.0385, 'grad_norm': 4.0982794761657715, 'learning_rate': 2.490677966101695e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [2:59:39<2:55:50,  3.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [2:59:43<2:52:56,  3.53s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.2270440310239792, 'learning_rate': 2.4898305084745764e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [2:59:43<2:52:56,  3.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [2:59:46<2:50:30,  3.48s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.9198801517486572, 'learning_rate': 2.4889830508474575e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [2:59:46<2:50:30,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [2:59:50<2:55:46,  3.59s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.7385272979736328, 'learning_rate': 2.488135593220339e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [2:59:50<2:55:46,  3.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [2:59:53<2:53:37,  3.55s/it]                                                       {'loss': 0.171, 'grad_norm': 6.810558795928955, 'learning_rate': 2.4872881355932204e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [2:59:53<2:53:37,  3.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [2:59:57<2:50:34,  3.49s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.9551149606704712, 'learning_rate': 2.486440677966102e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [2:59:57<2:50:34,  3.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [3:00:00<2:47:59,  3.44s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.7077363729476929, 'learning_rate': 2.485593220338983e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [3:00:00<2:47:59,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [3:00:03<2:47:38,  3.43s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.8272067904472351, 'learning_rate': 2.4847457627118645e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [3:00:03<2:47:38,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [3:00:07<2:46:53,  3.42s/it]                                                       {'loss': 0.1748, 'grad_norm': 7.1678080558776855, 'learning_rate': 2.483898305084746e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [3:00:07<2:46:53,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [3:00:10<2:45:58,  3.40s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.3205305337905884, 'learning_rate': 2.483050847457627e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [3:00:10<2:45:58,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [3:00:13<2:45:25,  3.39s/it]                                                       {'loss': 0.0202, 'grad_norm': 3.274400472640991, 'learning_rate': 2.4822033898305086e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [3:00:13<2:45:25,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [3:00:17<2:45:08,  3.38s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.5606019496917725, 'learning_rate': 2.48135593220339e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [3:00:17<2:45:08,  3.38s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [3:00:21<2:51:05,  3.51s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0987054631114006, 'learning_rate': 2.4805084745762715e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [3:00:21<2:51:05,  3.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [3:00:24<2:51:27,  3.52s/it]                                                       {'loss': 0.309, 'grad_norm': 9.562695503234863, 'learning_rate': 2.4796610169491526e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [3:00:24<2:51:27,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [3:00:27<2:49:16,  3.47s/it]                                                       {'loss': 0.1684, 'grad_norm': 5.496121406555176, 'learning_rate': 2.478813559322034e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [3:00:27<2:49:16,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [3:00:31<2:52:54,  3.55s/it]                                                       {'loss': 0.1483, 'grad_norm': 4.996230602264404, 'learning_rate': 2.4779661016949156e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [3:00:31<2:52:54,  3.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [3:00:34<2:49:32,  3.48s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.8859844207763672, 'learning_rate': 2.4771186440677967e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [3:00:35<2:49:32,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [3:00:38<2:47:04,  3.43s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2641657888889313, 'learning_rate': 2.476271186440678e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [3:00:38<2:47:04,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [3:00:41<2:45:15,  3.39s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.6007513999938965, 'learning_rate': 2.4754237288135596e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [3:00:41<2:45:15,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [3:00:45<2:45:10,  3.39s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.8386056423187256, 'learning_rate': 2.4745762711864408e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [3:00:45<2:45:10,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [3:00:48<2:45:15,  3.40s/it]                                                       {'loss': 0.0156, 'grad_norm': 2.542623996734619, 'learning_rate': 2.4737288135593222e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [3:00:48<2:45:15,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [3:00:51<2:45:33,  3.40s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.36580923199653625, 'learning_rate': 2.4728813559322034e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [3:00:51<2:45:33,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [3:00:55<2:46:28,  3.42s/it]                                                       {'loss': 0.0131, 'grad_norm': 0.645121693611145, 'learning_rate': 2.4720338983050848e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [3:00:55<2:46:28,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [3:00:58<2:46:15,  3.42s/it]                                                       {'loss': 0.1143, 'grad_norm': 9.042016983032227, 'learning_rate': 2.4711864406779663e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [3:00:58<2:46:15,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [3:01:02<2:47:52,  3.46s/it]                                                       {'loss': 0.0985, 'grad_norm': 5.416324615478516, 'learning_rate': 2.4703389830508474e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [3:01:02<2:47:52,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [3:01:05<2:48:08,  3.46s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.6594042778015137, 'learning_rate': 2.469491525423729e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [3:01:05<2:48:08,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [3:01:09<2:47:33,  3.45s/it]                                                       {'loss': 0.014, 'grad_norm': 1.3776856660842896, 'learning_rate': 2.4686440677966103e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [3:01:09<2:47:33,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [3:01:12<2:47:27,  3.45s/it]                                                       {'loss': 0.2069, 'grad_norm': 10.974448204040527, 'learning_rate': 2.4677966101694915e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [3:01:12<2:47:27,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [3:01:16<2:46:28,  3.43s/it]                                                       {'loss': 0.0324, 'grad_norm': 4.17748498916626, 'learning_rate': 2.466949152542373e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [3:01:16<2:46:28,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [3:01:19<2:49:08,  3.49s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.0437545776367188, 'learning_rate': 2.4661016949152544e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [3:01:19<2:49:08,  3.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [3:01:22<2:46:27,  3.43s/it]                                                       {'loss': 0.2316, 'grad_norm': 9.265092849731445, 'learning_rate': 2.4652542372881355e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [3:01:22<2:46:27,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [3:01:26<2:46:56,  3.44s/it]                                                       {'loss': 0.1573, 'grad_norm': 8.049683570861816, 'learning_rate': 2.464406779661017e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [3:01:26<2:46:56,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [3:01:29<2:45:54,  3.42s/it]                                                       {'loss': 0.0472, 'grad_norm': 5.368041515350342, 'learning_rate': 2.4635593220338985e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [3:01:29<2:45:54,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [3:01:33<2:55:21,  3.62s/it]                                                       {'loss': 0.0202, 'grad_norm': 4.451233863830566, 'learning_rate': 2.46271186440678e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [3:01:33<2:55:21,  3.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [3:01:37<2:51:55,  3.55s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.1871864795684814, 'learning_rate': 2.461864406779661e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [3:01:37<2:51:55,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [3:01:40<2:48:35,  3.48s/it]                                                       {'loss': 0.0832, 'grad_norm': 5.840604782104492, 'learning_rate': 2.4610169491525425e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [3:01:40<2:48:35,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [3:01:43<2:47:44,  3.47s/it]                                                       {'loss': 0.127, 'grad_norm': 9.027678489685059, 'learning_rate': 2.460169491525424e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [3:01:44<2:47:44,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [3:01:47<2:47:33,  3.46s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.7111547589302063, 'learning_rate': 2.459322033898305e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [3:01:47<2:47:33,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [3:01:50<2:45:50,  3.43s/it]                                                       {'loss': 0.0305, 'grad_norm': 1.8073551654815674, 'learning_rate': 2.4584745762711866e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [3:01:50<2:45:50,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [3:01:54<2:45:12,  3.42s/it]                                                       {'loss': 0.0278, 'grad_norm': 4.313396453857422, 'learning_rate': 2.457627118644068e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [3:01:54<2:45:12,  3.42s/it][2025-10-20 02:38:59,017] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [3:01:59<3:17:29,  4.09s/it]                                                       {'loss': 0.0367, 'grad_norm': 2.0410656929016113, 'learning_rate': 2.4567796610169495e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [3:01:59<3:17:29,  4.09s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [3:02:03<3:06:43,  3.87s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011603235267102718, 'learning_rate': 2.4559322033898303e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [3:02:03<3:06:43,  3.87s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [3:02:06<3:00:01,  3.73s/it]                                                       {'loss': 0.1776, 'grad_norm': 8.44677448272705, 'learning_rate': 2.4550847457627118e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [3:02:06<3:00:01,  3.73s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [3:02:09<2:55:07,  3.63s/it]                                                       {'loss': 0.134, 'grad_norm': 4.61554479598999, 'learning_rate': 2.4542372881355933e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [3:02:09<2:55:07,  3.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [3:02:13<2:52:50,  3.58s/it]                                                       {'loss': 0.0341, 'grad_norm': 2.6231577396392822, 'learning_rate': 2.4533898305084747e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [3:02:13<2:52:50,  3.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [3:02:17<2:57:00,  3.67s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.549497127532959, 'learning_rate': 2.452542372881356e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [3:02:17<2:57:00,  3.67s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [3:02:20<2:52:47,  3.58s/it]                                                       {'loss': 0.0187, 'grad_norm': 3.095792055130005, 'learning_rate': 2.4516949152542373e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [3:02:20<2:52:47,  3.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [3:02:24<2:49:28,  3.52s/it]                                                       {'loss': 0.0312, 'grad_norm': 4.414961338043213, 'learning_rate': 2.4508474576271188e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [3:02:24<2:49:28,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [3:02:27<2:46:36,  3.46s/it]                                                       {'loss': 0.0369, 'grad_norm': 5.5731964111328125, 'learning_rate': 2.45e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [3:02:27<2:46:36,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [3:02:30<2:46:00,  3.45s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.1830172538757324, 'learning_rate': 2.4491525423728814e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [3:02:30<2:46:00,  3.45s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [3:02:34<2:45:02,  3.43s/it]                                                       {'loss': 0.0171, 'grad_norm': 3.4126176834106445, 'learning_rate': 2.448305084745763e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [3:02:34<2:45:02,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [3:02:37<2:46:56,  3.47s/it]                                                       {'loss': 0.1125, 'grad_norm': 11.89027214050293, 'learning_rate': 2.4474576271186443e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [3:02:37<2:46:56,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [3:02:41<2:44:44,  3.42s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.1101346015930176, 'learning_rate': 2.4466101694915255e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [3:02:41<2:44:44,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [3:02:44<2:44:41,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2871217131614685, 'learning_rate': 2.445762711864407e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [3:02:44<2:44:41,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [3:02:48<2:46:11,  3.46s/it]                                                       {'loss': 0.1204, 'grad_norm': 7.272620677947998, 'learning_rate': 2.4449152542372884e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [3:02:48<2:46:11,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [3:02:52<2:53:47,  3.62s/it]                                                       {'loss': 0.0685, 'grad_norm': 4.905493259429932, 'learning_rate': 2.4440677966101695e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [3:02:52<2:53:47,  3.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [3:02:55<2:49:40,  3.53s/it]                                                       {'loss': 0.0655, 'grad_norm': 6.5669355392456055, 'learning_rate': 2.443220338983051e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [3:02:55<2:49:40,  3.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [3:02:59<2:53:11,  3.61s/it]                                                       {'loss': 0.0227, 'grad_norm': 3.4857373237609863, 'learning_rate': 2.4423728813559324e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [3:02:59<2:53:11,  3.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [3:03:02<2:55:13,  3.65s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2527191638946533, 'learning_rate': 2.441525423728814e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [3:03:02<2:55:13,  3.65s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [3:03:06<2:50:50,  3.56s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.7544333934783936, 'learning_rate': 2.440677966101695e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [3:03:06<2:50:50,  3.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [3:03:09<2:48:44,  3.52s/it]                                                       {'loss': 0.013, 'grad_norm': 2.1206257343292236, 'learning_rate': 2.4398305084745765e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [3:03:09<2:48:44,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [3:03:13<2:47:50,  3.50s/it]                                                       {'loss': 0.0238, 'grad_norm': 3.306391477584839, 'learning_rate': 2.438983050847458e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [3:03:13<2:47:50,  3.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [3:03:16<2:48:43,  3.52s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.5836887955665588, 'learning_rate': 2.438135593220339e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [3:03:16<2:48:43,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [3:03:20<2:48:44,  3.52s/it]                                                       {'loss': 0.0395, 'grad_norm': 5.999814510345459, 'learning_rate': 2.4372881355932202e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [3:03:20<2:48:44,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [3:03:23<2:46:29,  3.47s/it]                                                       {'loss': 0.0251, 'grad_norm': 5.400340557098389, 'learning_rate': 2.4364406779661017e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [3:03:23<2:46:29,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [3:03:26<2:43:57,  3.42s/it]                                                       {'loss': 0.1589, 'grad_norm': 5.150424003601074, 'learning_rate': 2.4355932203389832e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [3:03:26<2:43:57,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [3:03:30<2:43:07,  3.41s/it]                                                       {'loss': 0.062, 'grad_norm': 9.384510040283203, 'learning_rate': 2.4347457627118643e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [3:03:30<2:43:07,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [3:03:33<2:43:21,  3.41s/it]                                                       {'loss': 0.0507, 'grad_norm': 3.6634418964385986, 'learning_rate': 2.4338983050847458e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [3:03:33<2:43:21,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [3:03:37<2:48:36,  3.52s/it]                                                       {'loss': 0.0422, 'grad_norm': 6.24153470993042, 'learning_rate': 2.4330508474576272e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [3:03:37<2:48:36,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [3:03:40<2:47:28,  3.50s/it]                                                       {'loss': 0.0522, 'grad_norm': 4.988957405090332, 'learning_rate': 2.4322033898305087e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [3:03:40<2:47:28,  3.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [3:03:44<2:45:27,  3.46s/it]                                                       {'loss': 0.023, 'grad_norm': 3.969296932220459, 'learning_rate': 2.43135593220339e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [3:03:44<2:45:27,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [3:03:47<2:43:39,  3.42s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.2095659077167511, 'learning_rate': 2.4305084745762713e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [3:03:47<2:43:39,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [3:03:50<2:42:50,  3.41s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.07035074383020401, 'learning_rate': 2.4296610169491528e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [3:03:50<2:42:50,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [3:03:54<2:48:08,  3.52s/it]                                                       {'loss': 0.1508, 'grad_norm': 9.031686782836914, 'learning_rate': 2.428813559322034e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [3:03:54<2:48:08,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [3:03:58<2:48:35,  3.53s/it]                                                       {'loss': 0.0789, 'grad_norm': 5.147765636444092, 'learning_rate': 2.4279661016949154e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [3:03:58<2:48:35,  3.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [3:04:01<2:48:05,  3.52s/it]                                                       {'loss': 0.2293, 'grad_norm': 5.696145057678223, 'learning_rate': 2.4271186440677968e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [3:04:01<2:48:05,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [3:04:05<2:45:35,  3.47s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10963273048400879, 'learning_rate': 2.4262711864406783e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [3:04:05<2:45:35,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [3:04:08<2:47:17,  3.51s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6572574377059937, 'learning_rate': 2.4254237288135594e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [3:04:08<2:47:17,  3.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [3:04:12<2:45:50,  3.48s/it]                                                       {'loss': 0.0771, 'grad_norm': 5.801792621612549, 'learning_rate': 2.424576271186441e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [3:04:12<2:45:50,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [3:04:15<2:43:44,  3.44s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.117689609527588, 'learning_rate': 2.4237288135593224e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [3:04:15<2:43:44,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [3:04:18<2:42:39,  3.41s/it]                                                       {'loss': 0.0209, 'grad_norm': 2.6575729846954346, 'learning_rate': 2.4228813559322035e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [3:04:18<2:42:39,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [3:04:22<2:42:02,  3.40s/it]                                                       {'loss': 0.0131, 'grad_norm': 1.494920253753662, 'learning_rate': 2.422033898305085e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [3:04:22<2:42:02,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [3:04:25<2:41:15,  3.39s/it]                                                       {'loss': 0.0761, 'grad_norm': 9.852985382080078, 'learning_rate': 2.4211864406779664e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [3:04:25<2:41:15,  3.39s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [3:04:29<2:41:59,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014175965450704098, 'learning_rate': 2.4203389830508476e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [3:04:29<2:41:59,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [3:04:32<2:42:10,  3.41s/it]                                                       {'loss': 0.0309, 'grad_norm': 3.768707513809204, 'learning_rate': 2.4194915254237287e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [3:04:32<2:42:10,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [3:04:35<2:40:45,  3.38s/it]                                                       {'loss': 0.0235, 'grad_norm': 3.0906879901885986, 'learning_rate': 2.41864406779661e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [3:04:35<2:40:45,  3.38s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [3:04:39<2:39:59,  3.36s/it]                                                       {'loss': 0.1311, 'grad_norm': 5.811765670776367, 'learning_rate': 2.4177966101694916e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [3:04:39<2:39:59,  3.36s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [3:04:42<2:40:08,  3.37s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3268914818763733, 'learning_rate': 2.416949152542373e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [3:04:42<2:40:08,  3.37s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [3:04:45<2:41:32,  3.40s/it]                                                       {'loss': 0.0468, 'grad_norm': 4.130618572235107, 'learning_rate': 2.4161016949152542e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [3:04:45<2:41:32,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [3:04:49<2:40:17,  3.37s/it]                                                       {'loss': 0.1308, 'grad_norm': 6.269256114959717, 'learning_rate': 2.4152542372881357e-05, 'epoch': 0.53}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [3:04:49<2:40:17,  3.37s/it][2025-10-20 02:41:54,103] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [3:04:54<3:12:43,  4.06s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.24185346066951752, 'learning_rate': 2.414406779661017e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [3:04:54<3:12:43,  4.06s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [3:04:58<3:02:21,  3.84s/it]                                                       {'loss': 0.0447, 'grad_norm': 4.906948566436768, 'learning_rate': 2.4135593220338983e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [3:04:58<3:02:21,  3.84s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [3:05:01<2:54:52,  3.69s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.215075969696045, 'learning_rate': 2.4127118644067797e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [3:05:01<2:54:52,  3.69s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [3:05:04<2:50:53,  3.60s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.18762452900409698, 'learning_rate': 2.4118644067796612e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [3:05:05<2:50:53,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [3:05:08<2:47:22,  3.53s/it]                                                       {'loss': 0.1475, 'grad_norm': 5.359857559204102, 'learning_rate': 2.4110169491525423e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [3:05:08<2:47:22,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [3:05:11<2:45:41,  3.50s/it]                                                       {'loss': 0.0882, 'grad_norm': 6.96506404876709, 'learning_rate': 2.4101694915254238e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [3:05:11<2:45:41,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [3:05:15<2:45:23,  3.49s/it]                                                       {'loss': 0.0535, 'grad_norm': 2.3034260272979736, 'learning_rate': 2.4093220338983053e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [3:05:15<2:45:23,  3.49s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [3:05:18<2:44:37,  3.48s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.3760236501693726, 'learning_rate': 2.4084745762711867e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [3:05:18<2:44:37,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [3:05:22<2:43:37,  3.46s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.35637471079826355, 'learning_rate': 2.407627118644068e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [3:05:22<2:43:37,  3.46s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [3:05:25<2:46:48,  3.52s/it]                                                       {'loss': 0.0236, 'grad_norm': 3.5795552730560303, 'learning_rate': 2.4067796610169493e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [3:05:25<2:46:48,  3.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [3:05:29<2:46:49,  3.53s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.14777161180973053, 'learning_rate': 2.4059322033898308e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [3:05:29<2:46:49,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [3:05:32<2:44:35,  3.48s/it]                                                       {'loss': 0.0849, 'grad_norm': 7.89017391204834, 'learning_rate': 2.405084745762712e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [3:05:32<2:44:35,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [3:05:36<2:43:10,  3.45s/it]                                                       {'loss': 0.1189, 'grad_norm': 7.862585067749023, 'learning_rate': 2.4042372881355934e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [3:05:36<2:43:10,  3.45s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [3:05:39<2:47:51,  3.55s/it]                                                       {'loss': 0.001, 'grad_norm': 0.20867909491062164, 'learning_rate': 2.403389830508475e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [3:05:39<2:47:51,  3.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [3:05:43<2:45:10,  3.50s/it]                                                       {'loss': 0.1125, 'grad_norm': 5.47947359085083, 'learning_rate': 2.402542372881356e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [3:05:43<2:45:10,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [3:05:46<2:46:36,  3.53s/it]                                                       {'loss': 0.0385, 'grad_norm': 4.9952921867370605, 'learning_rate': 2.401694915254237e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [3:05:46<2:46:36,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [3:05:50<2:43:28,  3.46s/it]                                                       {'loss': 0.2241, 'grad_norm': 6.66341495513916, 'learning_rate': 2.4008474576271186e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [3:05:50<2:43:28,  3.46s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [3:05:53<2:46:25,  3.53s/it]                                                       {'loss': 0.0596, 'grad_norm': 5.981139183044434, 'learning_rate': 2.4e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [3:05:53<2:46:25,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [3:05:57<2:44:31,  3.49s/it]                                                       {'loss': 0.0689, 'grad_norm': 4.270610809326172, 'learning_rate': 2.3991525423728815e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [3:05:57<2:44:31,  3.49s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [3:06:00<2:44:55,  3.50s/it]                                                       {'loss': 0.0406, 'grad_norm': 4.97443962097168, 'learning_rate': 2.3983050847457627e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [3:06:00<2:44:55,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [3:06:04<2:49:13,  3.59s/it]                                                       {'loss': 0.1561, 'grad_norm': 10.113198280334473, 'learning_rate': 2.397457627118644e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [3:06:04<2:49:13,  3.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [3:06:08<2:55:21,  3.72s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.3298228681087494, 'learning_rate': 2.3966101694915256e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [3:06:08<2:55:21,  3.72s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [3:06:12<2:55:30,  3.73s/it]                                                       {'loss': 0.0619, 'grad_norm': 6.122227668762207, 'learning_rate': 2.3957627118644067e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [3:06:12<2:55:30,  3.73s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [3:06:15<2:51:57,  3.65s/it]                                                       {'loss': 0.2488, 'grad_norm': 6.855921268463135, 'learning_rate': 2.3949152542372882e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [3:06:15<2:51:57,  3.65s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [3:06:19<2:50:39,  3.62s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.9304624795913696, 'learning_rate': 2.3940677966101697e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [3:06:19<2:50:39,  3.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [3:06:22<2:47:41,  3.56s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.5381695032119751, 'learning_rate': 2.393220338983051e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [3:06:22<2:47:41,  3.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [3:06:26<2:46:32,  3.54s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08372634649276733, 'learning_rate': 2.3923728813559323e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [3:06:26<2:46:32,  3.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [3:06:29<2:48:41,  3.59s/it]                                                       {'loss': 0.0348, 'grad_norm': 3.277181386947632, 'learning_rate': 2.3915254237288137e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [3:06:29<2:48:41,  3.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [3:06:33<2:45:13,  3.51s/it]                                                       {'loss': 0.0416, 'grad_norm': 4.067013263702393, 'learning_rate': 2.3906779661016952e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [3:06:33<2:45:13,  3.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [3:06:36<2:43:59,  3.49s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.6232194900512695, 'learning_rate': 2.3898305084745763e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [3:06:36<2:43:59,  3.49s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [3:06:40<2:42:48,  3.47s/it]                                                       {'loss': 0.0934, 'grad_norm': 6.910632133483887, 'learning_rate': 2.3889830508474578e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [3:06:40<2:42:48,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [3:06:43<2:41:34,  3.44s/it]                                                       {'loss': 0.1322, 'grad_norm': 9.233129501342773, 'learning_rate': 2.3881355932203392e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [3:06:43<2:41:34,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [3:06:46<2:40:47,  3.42s/it]                                                       {'loss': 0.0956, 'grad_norm': 6.8068366050720215, 'learning_rate': 2.3872881355932207e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [3:06:46<2:40:47,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [3:06:50<2:44:04,  3.50s/it]                                                       {'loss': 0.0161, 'grad_norm': 0.8614735007286072, 'learning_rate': 2.386440677966102e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [3:06:50<2:44:04,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [3:06:53<2:41:50,  3.45s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.297412246465683, 'learning_rate': 2.3855932203389833e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [3:06:53<2:41:50,  3.45s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [3:06:57<2:40:40,  3.43s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.8068230152130127, 'learning_rate': 2.3847457627118644e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [3:06:57<2:40:40,  3.43s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [3:07:00<2:39:45,  3.41s/it]                                                       {'loss': 0.0267, 'grad_norm': 3.4026341438293457, 'learning_rate': 2.383898305084746e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [3:07:00<2:39:45,  3.41s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [3:07:04<2:39:36,  3.41s/it]                                                       {'loss': 0.1351, 'grad_norm': 7.371487617492676, 'learning_rate': 2.383050847457627e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [3:07:04<2:39:36,  3.41s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [3:07:07<2:39:19,  3.40s/it]                                                       {'loss': 0.0178, 'grad_norm': 3.4382357597351074, 'learning_rate': 2.3822033898305085e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [3:07:07<2:39:19,  3.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [3:07:11<2:47:55,  3.59s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.9807884693145752, 'learning_rate': 2.38135593220339e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [3:07:11<2:47:55,  3.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [3:07:14<2:45:29,  3.53s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.977325201034546, 'learning_rate': 2.380508474576271e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [3:07:14<2:45:29,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [3:07:18<2:42:53,  3.48s/it]                                                       {'loss': 0.1323, 'grad_norm': 7.262048244476318, 'learning_rate': 2.3796610169491526e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [3:07:18<2:42:53,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [3:07:21<2:41:02,  3.44s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.12077028304338455, 'learning_rate': 2.378813559322034e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [3:07:21<2:41:02,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [3:07:24<2:39:49,  3.42s/it]                                                       {'loss': 0.1158, 'grad_norm': 7.173490047454834, 'learning_rate': 2.3779661016949155e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [3:07:24<2:39:49,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [3:07:28<2:38:47,  3.40s/it]                                                       {'loss': 0.0337, 'grad_norm': 4.125422477722168, 'learning_rate': 2.3771186440677966e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [3:07:28<2:38:47,  3.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [3:07:31<2:37:47,  3.38s/it]                                                       {'loss': 0.176, 'grad_norm': 6.937026500701904, 'learning_rate': 2.376271186440678e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [3:07:31<2:37:47,  3.38s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [3:07:34<2:38:03,  3.38s/it]                                                       {'loss': 0.0567, 'grad_norm': 6.185713291168213, 'learning_rate': 2.3754237288135596e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [3:07:35<2:38:03,  3.38s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [3:07:38<2:38:08,  3.39s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.8503085970878601, 'learning_rate': 2.3745762711864407e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [3:07:38<2:38:08,  3.39s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [3:07:41<2:40:21,  3.44s/it]                                                       {'loss': 0.0117, 'grad_norm': 0.8073421716690063, 'learning_rate': 2.373728813559322e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [3:07:41<2:40:21,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [3:07:45<2:41:21,  3.46s/it]                                                       {'loss': 0.005, 'grad_norm': 0.7533918023109436, 'learning_rate': 2.3728813559322036e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [3:07:45<2:41:21,  3.46s/it][2025-10-20 02:44:50,275] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [3:07:51<3:12:59,  4.14s/it]                                                       {'loss': 0.007, 'grad_norm': 0.6284124255180359, 'learning_rate': 2.372033898305085e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [3:07:51<3:12:59,  4.14s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [3:07:54<3:02:02,  3.90s/it]                                                       {'loss': 0.0461, 'grad_norm': 4.655863285064697, 'learning_rate': 2.3711864406779662e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [3:07:54<3:02:02,  3.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [3:07:57<2:54:31,  3.74s/it]                                                       {'loss': 0.0499, 'grad_norm': 5.579944610595703, 'learning_rate': 2.3703389830508477e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [3:07:57<2:54:31,  3.74s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [3:08:01<2:48:10,  3.61s/it]                                                       {'loss': 0.0482, 'grad_norm': 4.274076461791992, 'learning_rate': 2.369491525423729e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [3:08:01<2:48:10,  3.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [3:08:04<2:45:04,  3.54s/it]                                                       {'loss': 0.0217, 'grad_norm': 1.6203346252441406, 'learning_rate': 2.3686440677966103e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [3:08:04<2:45:04,  3.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [3:08:08<2:52:29,  3.70s/it]                                                       {'loss': 0.0337, 'grad_norm': 2.8951127529144287, 'learning_rate': 2.3677966101694914e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [3:08:08<2:52:29,  3.70s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [3:08:12<2:48:06,  3.61s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.2248502969741821, 'learning_rate': 2.366949152542373e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [3:08:12<2:48:06,  3.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [3:08:15<2:47:49,  3.61s/it]                                                       {'loss': 0.0084, 'grad_norm': 0.9537900686264038, 'learning_rate': 2.3661016949152544e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [3:08:15<2:47:49,  3.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [3:08:19<2:46:30,  3.58s/it]                                                       {'loss': 0.1175, 'grad_norm': 8.682989120483398, 'learning_rate': 2.3652542372881355e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [3:08:19<2:46:30,  3.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [3:08:22<2:44:03,  3.53s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09167981147766113, 'learning_rate': 2.364406779661017e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [3:08:22<2:44:03,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [3:08:25<2:42:27,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.7960573434829712, 'learning_rate': 2.3635593220338984e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [3:08:26<2:42:27,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [3:08:29<2:40:51,  3.46s/it]                                                       {'loss': 0.0119, 'grad_norm': 2.439885377883911, 'learning_rate': 2.36271186440678e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [3:08:29<2:40:51,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [3:08:33<2:43:38,  3.52s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.44022268056869507, 'learning_rate': 2.361864406779661e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [3:08:33<2:43:38,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [3:08:36<2:43:13,  3.52s/it]                                                       {'loss': 0.0463, 'grad_norm': 1.0258251428604126, 'learning_rate': 2.3610169491525425e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [3:08:36<2:43:13,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [3:08:40<2:47:02,  3.60s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.5220202207565308, 'learning_rate': 2.360169491525424e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [3:08:40<2:47:02,  3.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [3:08:43<2:43:14,  3.52s/it]                                                       {'loss': 0.1081, 'grad_norm': 8.58156967163086, 'learning_rate': 2.359322033898305e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [3:08:43<2:43:14,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [3:08:47<2:43:04,  3.52s/it]                                                       {'loss': 0.0142, 'grad_norm': 3.69313907623291, 'learning_rate': 2.3584745762711865e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [3:08:47<2:43:04,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [3:08:50<2:41:42,  3.49s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06994284689426422, 'learning_rate': 2.357627118644068e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [3:08:50<2:41:42,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [3:08:53<2:40:12,  3.46s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.9446370601654053, 'learning_rate': 2.356779661016949e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [3:08:53<2:40:12,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [3:08:57<2:38:35,  3.42s/it]                                                       {'loss': 0.0533, 'grad_norm': 4.617331504821777, 'learning_rate': 2.3559322033898306e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [3:08:57<2:38:35,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [3:09:00<2:37:32,  3.40s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.42906028032302856, 'learning_rate': 2.355084745762712e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [3:09:00<2:37:32,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [3:09:04<2:40:54,  3.48s/it]                                                       {'loss': 0.0105, 'grad_norm': 0.9791685938835144, 'learning_rate': 2.3542372881355935e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [3:09:04<2:40:54,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [3:09:07<2:40:56,  3.48s/it]                                                       {'loss': 0.0751, 'grad_norm': 6.15744686126709, 'learning_rate': 2.3533898305084747e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [3:09:07<2:40:56,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [3:09:11<2:42:30,  3.51s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016817672178149223, 'learning_rate': 2.352542372881356e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [3:09:11<2:42:30,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [3:09:14<2:41:15,  3.49s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.18240325152873993, 'learning_rate': 2.3516949152542376e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [3:09:14<2:41:15,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [3:09:18<2:40:35,  3.47s/it]                                                       {'loss': 0.1213, 'grad_norm': 12.248113632202148, 'learning_rate': 2.3508474576271187e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [3:09:18<2:40:35,  3.47s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [3:09:21<2:39:40,  3.46s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2396061271429062, 'learning_rate': 2.35e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [3:09:21<2:39:40,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [3:09:25<2:40:09,  3.47s/it]                                                       {'loss': 0.1812, 'grad_norm': 8.024507522583008, 'learning_rate': 2.3491525423728813e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [3:09:25<2:40:09,  3.47s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [3:09:28<2:38:51,  3.44s/it]                                                       {'loss': 0.0141, 'grad_norm': 2.2898807525634766, 'learning_rate': 2.3483050847457628e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [3:09:28<2:38:51,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [3:09:31<2:38:52,  3.44s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.3918325901031494, 'learning_rate': 2.347457627118644e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [3:09:32<2:38:52,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [3:09:35<2:38:08,  3.43s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03506637364625931, 'learning_rate': 2.3466101694915254e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [3:09:35<2:38:08,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [3:09:38<2:39:27,  3.46s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.1045360565185547, 'learning_rate': 2.345762711864407e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [3:09:38<2:39:27,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [3:09:42<2:37:06,  3.41s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6022379398345947, 'learning_rate': 2.3449152542372883e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [3:09:42<2:37:06,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [3:09:45<2:36:24,  3.39s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.6485021114349365, 'learning_rate': 2.3440677966101695e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [3:09:45<2:36:24,  3.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [3:09:48<2:35:42,  3.38s/it]                                                       {'loss': 0.433, 'grad_norm': 10.28257942199707, 'learning_rate': 2.343220338983051e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [3:09:48<2:35:42,  3.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [3:09:52<2:37:41,  3.42s/it]                                                       {'loss': 0.1146, 'grad_norm': 4.971947193145752, 'learning_rate': 2.3423728813559324e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [3:09:52<2:37:41,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [3:09:55<2:36:27,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.10272107273340225, 'learning_rate': 2.3415254237288135e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [3:09:55<2:36:27,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [3:09:59<2:41:09,  3.50s/it]                                                       {'loss': 0.0215, 'grad_norm': 1.569071650505066, 'learning_rate': 2.340677966101695e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [3:09:59<2:41:09,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [3:10:03<2:41:44,  3.51s/it]                                                       {'loss': 0.0481, 'grad_norm': 6.62254524230957, 'learning_rate': 2.3398305084745765e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [3:10:03<2:41:44,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [3:10:06<2:41:05,  3.50s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.6582973003387451, 'learning_rate': 2.338983050847458e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [3:10:06<2:41:05,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [3:10:09<2:40:21,  3.49s/it]                                                       {'loss': 0.0987, 'grad_norm': 7.645607948303223, 'learning_rate': 2.338135593220339e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [3:10:09<2:40:21,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [3:10:13<2:40:56,  3.50s/it]                                                       {'loss': 0.0289, 'grad_norm': 4.841674327850342, 'learning_rate': 2.3372881355932205e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [3:10:13<2:40:56,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [3:10:16<2:39:54,  3.48s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.834331750869751, 'learning_rate': 2.336440677966102e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [3:10:16<2:39:54,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [3:10:21<2:52:22,  3.75s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1658894419670105, 'learning_rate': 2.335593220338983e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [3:10:21<2:52:22,  3.75s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [3:10:24<2:50:17,  3.71s/it]                                                       {'loss': 0.0231, 'grad_norm': 1.3288604021072388, 'learning_rate': 2.3347457627118646e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [3:10:24<2:50:17,  3.71s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [3:10:28<2:46:23,  3.63s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3549841642379761, 'learning_rate': 2.333898305084746e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [3:10:28<2:46:23,  3.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [3:10:31<2:42:49,  3.55s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.044480800628662, 'learning_rate': 2.3330508474576275e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [3:10:31<2:42:49,  3.55s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [3:10:35<2:41:03,  3.51s/it]                                                       {'loss': 0.1111, 'grad_norm': 7.0549139976501465, 'learning_rate': 2.3322033898305083e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [3:10:35<2:41:03,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [3:10:38<2:39:28,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03149428591132164, 'learning_rate': 2.3313559322033898e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [3:10:38<2:39:28,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [3:10:42<2:39:55,  3.49s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.4518676996231079, 'learning_rate': 2.3305084745762712e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [3:10:42<2:39:55,  3.49s/it][2025-10-20 02:47:46,915] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [3:10:47<3:10:17,  4.15s/it]                                                       {'loss': 0.0185, 'grad_norm': 1.3073385953903198, 'learning_rate': 2.3296610169491527e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [3:10:47<3:10:17,  4.15s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [3:10:51<2:59:12,  3.91s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.5800580978393555, 'learning_rate': 2.328813559322034e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [3:10:51<2:59:12,  3.91s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [3:10:54<2:52:51,  3.78s/it]                                                       {'loss': 0.013, 'grad_norm': 2.333225965499878, 'learning_rate': 2.3279661016949153e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [3:10:54<2:52:51,  3.78s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [3:10:57<2:46:12,  3.63s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.2552821636199951, 'learning_rate': 2.3271186440677968e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [3:10:57<2:46:12,  3.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [3:11:01<2:42:54,  3.56s/it]                                                       {'loss': 0.0164, 'grad_norm': 1.5720628499984741, 'learning_rate': 2.326271186440678e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [3:11:01<2:42:54,  3.56s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [3:11:04<2:40:49,  3.52s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011519106104969978, 'learning_rate': 2.3254237288135594e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [3:11:04<2:40:49,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [3:11:08<2:46:08,  3.63s/it]                                                       {'loss': 0.0579, 'grad_norm': 3.7063801288604736, 'learning_rate': 2.324576271186441e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [3:11:08<2:46:08,  3.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [3:11:12<2:43:48,  3.58s/it]                                                       {'loss': 0.1078, 'grad_norm': 7.911413669586182, 'learning_rate': 2.3237288135593223e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [3:11:12<2:43:48,  3.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [3:11:15<2:42:32,  3.56s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.534425675868988, 'learning_rate': 2.3228813559322034e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [3:11:15<2:42:32,  3.56s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [3:11:19<2:44:48,  3.61s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.44239187240600586, 'learning_rate': 2.322033898305085e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [3:11:19<2:44:48,  3.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [3:11:22<2:42:01,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03616448864340782, 'learning_rate': 2.3211864406779664e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [3:11:22<2:42:01,  3.55s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [3:11:26<2:39:45,  3.50s/it]                                                       {'loss': 0.0592, 'grad_norm': 2.382293462753296, 'learning_rate': 2.3203389830508475e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [3:11:26<2:39:45,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [3:11:29<2:37:44,  3.46s/it]                                                       {'loss': 0.0128, 'grad_norm': 2.3104422092437744, 'learning_rate': 2.319491525423729e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [3:11:29<2:37:44,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [3:11:32<2:36:21,  3.43s/it]                                                       {'loss': 0.0248, 'grad_norm': 3.5364251136779785, 'learning_rate': 2.3186440677966104e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [3:11:32<2:36:21,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [3:11:36<2:35:31,  3.41s/it]                                                       {'loss': 0.1784, 'grad_norm': 8.789347648620605, 'learning_rate': 2.317796610169492e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [3:11:36<2:35:31,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [3:11:39<2:34:30,  3.39s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.6499341130256653, 'learning_rate': 2.316949152542373e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [3:11:39<2:34:30,  3.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [3:11:42<2:33:09,  3.36s/it]                                                       {'loss': 0.0206, 'grad_norm': 1.9128077030181885, 'learning_rate': 2.3161016949152545e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [3:11:42<2:33:09,  3.36s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [3:11:46<2:33:10,  3.36s/it]                                                       {'loss': 0.3382, 'grad_norm': 10.149731636047363, 'learning_rate': 2.315254237288136e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [3:11:46<2:33:10,  3.36s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [3:11:49<2:33:03,  3.36s/it]                                                       {'loss': 0.0891, 'grad_norm': 6.234212398529053, 'learning_rate': 2.314406779661017e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [3:11:49<2:33:03,  3.36s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [3:11:52<2:32:47,  3.36s/it]                                                       {'loss': 0.0793, 'grad_norm': 6.179402828216553, 'learning_rate': 2.3135593220338982e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [3:11:52<2:32:47,  3.36s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [3:11:56<2:32:52,  3.36s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.7385988831520081, 'learning_rate': 2.3127118644067797e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [3:11:56<2:32:52,  3.36s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [3:11:59<2:33:06,  3.37s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3025611937046051, 'learning_rate': 2.311864406779661e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [3:11:59<2:33:06,  3.37s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [3:12:03<2:39:29,  3.51s/it]                                                       {'loss': 0.0518, 'grad_norm': 3.3279898166656494, 'learning_rate': 2.3110169491525423e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [3:12:03<2:39:29,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [3:12:06<2:37:57,  3.48s/it]                                                       {'loss': 0.0193, 'grad_norm': 2.0644586086273193, 'learning_rate': 2.3101694915254237e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [3:12:06<2:37:57,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [3:12:10<2:42:11,  3.57s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.16732953488826752, 'learning_rate': 2.3093220338983052e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [3:12:10<2:42:11,  3.57s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [3:12:14<2:39:03,  3.50s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.33818021416664124, 'learning_rate': 2.3084745762711867e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [3:12:14<2:39:03,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [3:12:17<2:36:47,  3.45s/it]                                                       {'loss': 0.1089, 'grad_norm': 5.712974548339844, 'learning_rate': 2.3076271186440678e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [3:12:17<2:36:47,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [3:12:20<2:35:42,  3.43s/it]                                                       {'loss': 0.1126, 'grad_norm': 3.4197440147399902, 'learning_rate': 2.3067796610169493e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [3:12:20<2:35:42,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [3:12:24<2:43:00,  3.59s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.40982484817504883, 'learning_rate': 2.3059322033898307e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [3:12:24<2:43:00,  3.59s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [3:12:28<2:39:49,  3.53s/it]                                                       {'loss': 0.0475, 'grad_norm': 4.65780782699585, 'learning_rate': 2.305084745762712e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [3:12:28<2:39:49,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [3:12:31<2:38:31,  3.50s/it]                                                       {'loss': 0.0853, 'grad_norm': 6.540591239929199, 'learning_rate': 2.3042372881355933e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [3:12:31<2:38:31,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [3:12:35<2:38:57,  3.51s/it]                                                       {'loss': 0.046, 'grad_norm': 5.806128978729248, 'learning_rate': 2.3033898305084748e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [3:12:35<2:38:57,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [3:12:38<2:40:36,  3.55s/it]                                                       {'loss': 0.1116, 'grad_norm': 5.972699165344238, 'learning_rate': 2.302542372881356e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [3:12:38<2:40:36,  3.55s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [3:12:42<2:38:18,  3.50s/it]                                                       {'loss': 0.0377, 'grad_norm': 4.4554314613342285, 'learning_rate': 2.3016949152542374e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [3:12:42<2:38:18,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [3:12:45<2:36:00,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3035922348499298, 'learning_rate': 2.300847457627119e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [3:12:45<2:36:00,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [3:12:49<2:39:26,  3.52s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.1946921348571777, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [3:12:49<2:39:26,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [3:12:52<2:38:05,  3.50s/it]                                                       {'loss': 0.0784, 'grad_norm': 6.122519493103027, 'learning_rate': 2.2991525423728815e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [3:12:52<2:38:05,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [3:12:55<2:36:31,  3.46s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.3140498399734497, 'learning_rate': 2.298305084745763e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [3:12:55<2:36:31,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [3:12:59<2:34:47,  3.43s/it]                                                       {'loss': 0.0895, 'grad_norm': 6.15716552734375, 'learning_rate': 2.297457627118644e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [3:12:59<2:34:47,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [3:13:02<2:34:32,  3.42s/it]                                                       {'loss': 0.2564, 'grad_norm': 6.627216339111328, 'learning_rate': 2.2966101694915255e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [3:13:02<2:34:32,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [3:13:06<2:36:24,  3.46s/it]                                                       {'loss': 0.016, 'grad_norm': 2.04331374168396, 'learning_rate': 2.2957627118644067e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [3:13:06<2:36:24,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [3:13:09<2:36:07,  3.46s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.7452152371406555, 'learning_rate': 2.294915254237288e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [3:13:09<2:36:07,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [3:13:13<2:35:20,  3.44s/it]                                                       {'loss': 0.002, 'grad_norm': 0.34867390990257263, 'learning_rate': 2.2940677966101696e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [3:13:13<2:35:20,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [3:13:16<2:35:34,  3.45s/it]                                                       {'loss': 0.0226, 'grad_norm': 1.8092046976089478, 'learning_rate': 2.2932203389830507e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [3:13:16<2:35:34,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [3:13:20<2:36:08,  3.46s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.8612484931945801, 'learning_rate': 2.2923728813559322e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [3:13:20<2:36:08,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [3:13:23<2:34:16,  3.42s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.41950172185897827, 'learning_rate': 2.2915254237288137e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [3:13:23<2:34:16,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [3:13:26<2:32:52,  3.39s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08038685470819473, 'learning_rate': 2.290677966101695e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [3:13:26<2:32:52,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [3:13:30<2:34:16,  3.43s/it]                                                       {'loss': 0.0179, 'grad_norm': 2.020697832107544, 'learning_rate': 2.2898305084745763e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [3:13:30<2:34:16,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [3:13:33<2:33:18,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13386784493923187, 'learning_rate': 2.2889830508474577e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [3:13:33<2:33:18,  3.41s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [3:13:36<2:32:47,  3.40s/it]                                                       {'loss': 0.0517, 'grad_norm': 4.371133327484131, 'learning_rate': 2.2881355932203392e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [3:13:36<2:32:47,  3.40s/it][2025-10-20 02:50:41,769] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [3:13:42<3:03:06,  4.07s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.30861249566078186, 'learning_rate': 2.2872881355932203e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [3:13:42<3:03:06,  4.07s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [3:13:45<2:53:13,  3.85s/it]                                                       {'loss': 0.0787, 'grad_norm': 3.980100393295288, 'learning_rate': 2.2864406779661018e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [3:13:45<2:53:13,  3.85s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [3:13:49<2:46:40,  3.71s/it]                                                       {'loss': 0.0332, 'grad_norm': 3.8388044834136963, 'learning_rate': 2.2855932203389833e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [3:13:49<2:46:40,  3.71s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [3:13:52<2:40:50,  3.58s/it]                                                       {'loss': 0.0414, 'grad_norm': 5.353688716888428, 'learning_rate': 2.2847457627118647e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [3:13:52<2:40:50,  3.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [3:13:55<2:37:49,  3.51s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11091430485248566, 'learning_rate': 2.283898305084746e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [3:13:55<2:37:49,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [3:13:59<2:38:04,  3.52s/it]                                                       {'loss': 0.2446, 'grad_norm': 11.381564140319824, 'learning_rate': 2.2830508474576273e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [3:13:59<2:38:04,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [3:14:02<2:35:39,  3.47s/it]                                                       {'loss': 0.289, 'grad_norm': 7.694684982299805, 'learning_rate': 2.2822033898305088e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [3:14:02<2:35:39,  3.47s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [3:14:06<2:35:04,  3.46s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.8788809776306152, 'learning_rate': 2.28135593220339e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [3:14:06<2:35:04,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [3:14:09<2:35:27,  3.47s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.4480018615722656, 'learning_rate': 2.2805084745762714e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [3:14:09<2:35:27,  3.47s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [3:14:13<2:34:46,  3.45s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.7794273495674133, 'learning_rate': 2.2796610169491525e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [3:14:13<2:34:46,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [3:14:16<2:35:08,  3.46s/it]                                                       {'loss': 0.1244, 'grad_norm': 5.109651565551758, 'learning_rate': 2.278813559322034e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [3:14:16<2:35:08,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [3:14:20<2:34:59,  3.46s/it]                                                       {'loss': 0.0879, 'grad_norm': 4.581972599029541, 'learning_rate': 2.277966101694915e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [3:14:20<2:34:59,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [3:14:23<2:32:46,  3.41s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.839888572692871, 'learning_rate': 2.2771186440677966e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [3:14:23<2:32:46,  3.41s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [3:14:27<2:38:42,  3.55s/it]                                                       {'loss': 0.0226, 'grad_norm': 4.1591691970825195, 'learning_rate': 2.276271186440678e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [3:14:27<2:38:42,  3.55s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [3:14:30<2:38:00,  3.53s/it]                                                       {'loss': 0.0616, 'grad_norm': 5.867262840270996, 'learning_rate': 2.2754237288135595e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [3:14:30<2:38:00,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [3:14:34<2:36:33,  3.50s/it]                                                       {'loss': 0.0331, 'grad_norm': 3.6928935050964355, 'learning_rate': 2.2745762711864406e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [3:14:34<2:36:33,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [3:14:37<2:33:51,  3.44s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.18431268632411957, 'learning_rate': 2.273728813559322e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [3:14:37<2:33:51,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [3:14:40<2:32:48,  3.42s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16769367456436157, 'learning_rate': 2.2728813559322036e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [3:14:40<2:32:48,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [3:14:44<2:33:36,  3.44s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.0980587005615234, 'learning_rate': 2.2720338983050847e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [3:14:44<2:33:36,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [3:14:47<2:33:51,  3.44s/it]                                                       {'loss': 0.2858, 'grad_norm': 11.305174827575684, 'learning_rate': 2.271186440677966e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [3:14:47<2:33:51,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [3:14:51<2:32:54,  3.42s/it]                                                       {'loss': 0.2583, 'grad_norm': 10.983768463134766, 'learning_rate': 2.2703389830508476e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [3:14:51<2:32:54,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [3:14:54<2:33:23,  3.44s/it]                                                       {'loss': 0.0119, 'grad_norm': 2.6780710220336914, 'learning_rate': 2.269491525423729e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [3:14:54<2:33:23,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [3:14:58<2:33:12,  3.43s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02822369523346424, 'learning_rate': 2.2686440677966102e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [3:14:58<2:33:12,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [3:15:01<2:32:24,  3.42s/it]                                                       {'loss': 0.0579, 'grad_norm': 7.068955898284912, 'learning_rate': 2.2677966101694917e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [3:15:01<2:32:24,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [3:15:04<2:33:34,  3.44s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.4155174493789673, 'learning_rate': 2.266949152542373e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [3:15:04<2:33:34,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [3:15:08<2:37:12,  3.53s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11430317908525467, 'learning_rate': 2.2661016949152543e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [3:15:08<2:37:12,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [3:15:12<2:47:39,  3.76s/it]                                                       {'loss': 0.0958, 'grad_norm': 7.76561164855957, 'learning_rate': 2.2652542372881358e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [3:15:12<2:47:39,  3.76s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [3:15:16<2:41:42,  3.63s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.18818160891532898, 'learning_rate': 2.2644067796610172e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [3:15:16<2:41:42,  3.63s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [3:15:19<2:39:02,  3.57s/it]                                                       {'loss': 0.006, 'grad_norm': 0.8249958157539368, 'learning_rate': 2.2635593220338987e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [3:15:19<2:39:02,  3.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [3:15:23<2:37:32,  3.54s/it]                                                       {'loss': 0.0177, 'grad_norm': 2.3426640033721924, 'learning_rate': 2.2627118644067798e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [3:15:23<2:37:32,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [3:15:26<2:35:03,  3.49s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2705373167991638, 'learning_rate': 2.261864406779661e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [3:15:26<2:35:03,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [3:15:29<2:33:08,  3.44s/it]                                                       {'loss': 0.007, 'grad_norm': 0.6483015418052673, 'learning_rate': 2.2610169491525424e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [3:15:29<2:33:08,  3.44s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [3:15:33<2:31:49,  3.42s/it]                                                       {'loss': 0.0593, 'grad_norm': 1.7704436779022217, 'learning_rate': 2.260169491525424e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [3:15:33<2:31:49,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [3:15:36<2:31:30,  3.41s/it]                                                       {'loss': 0.0817, 'grad_norm': 3.5729405879974365, 'learning_rate': 2.259322033898305e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [3:15:36<2:31:30,  3.41s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [3:15:40<2:37:21,  3.54s/it]                                                       {'loss': 0.0871, 'grad_norm': 3.287745475769043, 'learning_rate': 2.2584745762711865e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [3:15:40<2:37:21,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [3:15:44<2:42:18,  3.66s/it]                                                       {'loss': 0.0227, 'grad_norm': 2.724506378173828, 'learning_rate': 2.257627118644068e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [3:15:44<2:42:18,  3.66s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [3:15:47<2:40:29,  3.62s/it]                                                       {'loss': 0.0212, 'grad_norm': 3.8286547660827637, 'learning_rate': 2.256779661016949e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [3:15:47<2:40:29,  3.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [3:15:51<2:37:06,  3.54s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.7093334197998047, 'learning_rate': 2.2559322033898305e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [3:15:51<2:37:06,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [3:15:54<2:35:11,  3.50s/it]                                                       {'loss': 0.0212, 'grad_norm': 3.0754010677337646, 'learning_rate': 2.255084745762712e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [3:15:54<2:35:11,  3.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [3:15:58<2:34:27,  3.48s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1874600648880005, 'learning_rate': 2.2542372881355935e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [3:15:58<2:34:27,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [3:16:01<2:32:13,  3.44s/it]                                                       {'loss': 0.0737, 'grad_norm': 6.960238933563232, 'learning_rate': 2.2533898305084746e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [3:16:01<2:32:13,  3.44s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [3:16:04<2:30:56,  3.41s/it]                                                       {'loss': 0.064, 'grad_norm': 6.776591777801514, 'learning_rate': 2.252542372881356e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [3:16:04<2:30:56,  3.41s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [3:16:08<2:30:18,  3.39s/it]                                                       {'loss': 0.0831, 'grad_norm': 4.963603973388672, 'learning_rate': 2.2516949152542375e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [3:16:08<2:30:18,  3.39s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [3:16:11<2:30:28,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08298628777265549, 'learning_rate': 2.2508474576271187e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [3:16:11<2:30:28,  3.40s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [3:16:15<2:30:19,  3.40s/it]                                                       {'loss': 0.0232, 'grad_norm': 4.121583461761475, 'learning_rate': 2.25e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [3:16:15<2:30:19,  3.40s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [3:16:18<2:35:54,  3.52s/it]                                                       {'loss': 0.0145, 'grad_norm': 2.622814655303955, 'learning_rate': 2.2491525423728816e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [3:16:18<2:35:54,  3.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [3:16:22<2:40:09,  3.62s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.9826489090919495, 'learning_rate': 2.2483050847457627e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [3:16:22<2:40:09,  3.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [3:16:25<2:35:53,  3.53s/it]                                                       {'loss': 0.0722, 'grad_norm': 4.901008129119873, 'learning_rate': 2.2474576271186442e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [3:16:25<2:35:53,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [3:16:29<2:33:35,  3.48s/it]                                                       {'loss': 0.289, 'grad_norm': 10.13315486907959, 'learning_rate': 2.2466101694915257e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [3:16:29<2:33:35,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [3:16:32<2:32:53,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.008893999271094799, 'learning_rate': 2.245762711864407e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [3:16:32<2:32:53,  3.46s/it][2025-10-20 02:53:37,599] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [3:16:38<3:03:35,  4.16s/it]                                                       {'loss': 0.0214, 'grad_norm': 2.487734079360962, 'learning_rate': 2.2449152542372883e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [3:16:38<3:03:35,  4.16s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [3:16:42<2:54:39,  3.96s/it]                                                       {'loss': 0.03, 'grad_norm': 3.335822820663452, 'learning_rate': 2.2440677966101694e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [3:16:42<2:54:39,  3.96s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [3:16:45<2:48:25,  3.82s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.13972361385822296, 'learning_rate': 2.243220338983051e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [3:16:45<2:48:25,  3.82s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [3:16:48<2:42:05,  3.68s/it]                                                       {'loss': 0.0182, 'grad_norm': 1.5382814407348633, 'learning_rate': 2.2423728813559323e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [3:16:48<2:42:05,  3.68s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [3:16:52<2:37:42,  3.58s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5033575296401978, 'learning_rate': 2.2415254237288135e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [3:16:52<2:37:42,  3.58s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [3:16:55<2:35:50,  3.54s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.61933171749115, 'learning_rate': 2.240677966101695e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [3:16:55<2:35:50,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [3:16:59<2:38:24,  3.60s/it]                                                       {'loss': 0.1416, 'grad_norm': 5.714543342590332, 'learning_rate': 2.2398305084745764e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [3:16:59<2:38:24,  3.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [3:17:02<2:36:52,  3.56s/it]                                                       {'loss': 0.055, 'grad_norm': 7.6398210525512695, 'learning_rate': 2.2389830508474575e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [3:17:02<2:36:52,  3.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [3:17:06<2:36:10,  3.55s/it]                                                       {'loss': 0.1567, 'grad_norm': 7.429864406585693, 'learning_rate': 2.238135593220339e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [3:17:06<2:36:10,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [3:17:10<2:38:16,  3.60s/it]                                                       {'loss': 0.0225, 'grad_norm': 3.2669782638549805, 'learning_rate': 2.2372881355932205e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [3:17:10<2:38:16,  3.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [3:17:13<2:35:11,  3.53s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.2048487663269043, 'learning_rate': 2.236440677966102e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [3:17:13<2:35:11,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [3:17:16<2:33:13,  3.49s/it]                                                       {'loss': 0.0631, 'grad_norm': 2.9779956340789795, 'learning_rate': 2.235593220338983e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [3:17:16<2:33:13,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [3:17:20<2:33:45,  3.50s/it]                                                       {'loss': 0.088, 'grad_norm': 5.7833991050720215, 'learning_rate': 2.2347457627118645e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [3:17:20<2:33:45,  3.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [3:17:23<2:31:43,  3.45s/it]                                                       {'loss': 0.2453, 'grad_norm': 6.854144096374512, 'learning_rate': 2.233898305084746e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [3:17:23<2:31:43,  3.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [3:17:27<2:31:26,  3.45s/it]                                                       {'loss': 0.2887, 'grad_norm': 8.235478401184082, 'learning_rate': 2.233050847457627e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [3:17:27<2:31:26,  3.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [3:17:30<2:31:55,  3.46s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.8332329988479614, 'learning_rate': 2.2322033898305086e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [3:17:30<2:31:55,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [3:17:34<2:32:09,  3.47s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.16438552737236023, 'learning_rate': 2.23135593220339e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [3:17:34<2:32:09,  3.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [3:17:37<2:31:22,  3.45s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5782002210617065, 'learning_rate': 2.2305084745762715e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [3:17:37<2:31:22,  3.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [3:17:40<2:29:50,  3.42s/it]                                                       {'loss': 0.0469, 'grad_norm': 6.101870059967041, 'learning_rate': 2.2296610169491526e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [3:17:40<2:29:50,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [3:17:44<2:31:31,  3.46s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.958146870136261, 'learning_rate': 2.228813559322034e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [3:17:44<2:31:31,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [3:17:49<2:45:52,  3.79s/it]                                                       {'loss': 0.243, 'grad_norm': 10.04068660736084, 'learning_rate': 2.2279661016949156e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [3:17:49<2:45:52,  3.79s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [3:17:52<2:41:22,  3.68s/it]                                                       {'loss': 0.1207, 'grad_norm': 4.39284610748291, 'learning_rate': 2.2271186440677967e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [3:17:52<2:41:22,  3.68s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [3:17:55<2:38:10,  3.61s/it]                                                       {'loss': 0.0349, 'grad_norm': 1.1387596130371094, 'learning_rate': 2.226271186440678e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [3:17:55<2:38:10,  3.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [3:17:59<2:35:09,  3.55s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.7898867130279541, 'learning_rate': 2.2254237288135593e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [3:17:59<2:35:09,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [3:18:02<2:34:54,  3.54s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.3857104778289795, 'learning_rate': 2.2245762711864408e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [3:18:02<2:34:54,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [3:18:06<2:32:17,  3.48s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.5963982343673706, 'learning_rate': 2.223728813559322e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [3:18:06<2:32:17,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [3:18:09<2:32:38,  3.49s/it]                                                       {'loss': 0.0876, 'grad_norm': 7.363788604736328, 'learning_rate': 2.2228813559322034e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [3:18:09<2:32:38,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [3:18:13<2:42:40,  3.72s/it]                                                       {'loss': 0.0284, 'grad_norm': 2.7038655281066895, 'learning_rate': 2.222033898305085e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [3:18:13<2:42:40,  3.72s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [3:18:17<2:37:10,  3.60s/it]                                                       {'loss': 0.1039, 'grad_norm': 6.496160507202148, 'learning_rate': 2.2211864406779663e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [3:18:17<2:37:10,  3.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [3:18:20<2:33:11,  3.51s/it]                                                       {'loss': 0.1679, 'grad_norm': 6.15646505355835, 'learning_rate': 2.2203389830508474e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [3:18:20<2:33:11,  3.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [3:18:23<2:31:56,  3.48s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.939875066280365, 'learning_rate': 2.219491525423729e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [3:18:23<2:31:56,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [3:18:28<2:39:43,  3.66s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.56169593334198, 'learning_rate': 2.2186440677966104e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [3:18:28<2:39:43,  3.66s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [3:18:31<2:36:40,  3.59s/it]                                                       {'loss': 0.1227, 'grad_norm': 8.065834045410156, 'learning_rate': 2.2177966101694915e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [3:18:31<2:36:40,  3.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [3:18:34<2:33:41,  3.53s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.49417394399642944, 'learning_rate': 2.216949152542373e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [3:18:34<2:33:41,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [3:18:38<2:34:17,  3.54s/it]                                                       {'loss': 0.0167, 'grad_norm': 2.3352441787719727, 'learning_rate': 2.2161016949152544e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [3:18:38<2:34:17,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [3:18:41<2:31:24,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09509763866662979, 'learning_rate': 2.215254237288136e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [3:18:41<2:31:24,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [3:18:45<2:31:20,  3.48s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.019891809672117233, 'learning_rate': 2.214406779661017e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [3:18:45<2:31:20,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [3:18:48<2:29:31,  3.43s/it]                                                       {'loss': 0.2841, 'grad_norm': 7.036423206329346, 'learning_rate': 2.2135593220338985e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [3:18:48<2:29:31,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [3:18:51<2:29:26,  3.43s/it]                                                       {'loss': 0.0086, 'grad_norm': 2.7249886989593506, 'learning_rate': 2.21271186440678e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [3:18:51<2:29:26,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [3:18:55<2:28:46,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03131048381328583, 'learning_rate': 2.211864406779661e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [3:18:55<2:28:46,  3.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [3:18:59<2:33:34,  3.53s/it]                                                       {'loss': 0.1236, 'grad_norm': 7.334731101989746, 'learning_rate': 2.2110169491525426e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [3:18:59<2:33:34,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [3:19:02<2:32:53,  3.52s/it]                                                       {'loss': 0.1104, 'grad_norm': 6.307775020599365, 'learning_rate': 2.210169491525424e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [3:19:02<2:32:53,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [3:19:06<2:31:23,  3.48s/it]                                                       {'loss': 0.0461, 'grad_norm': 4.548435688018799, 'learning_rate': 2.209322033898305e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [3:19:06<2:31:23,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [3:19:09<2:28:57,  3.43s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.14878930151462555, 'learning_rate': 2.2084745762711863e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [3:19:09<2:28:57,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [3:19:13<2:39:41,  3.68s/it]                                                       {'loss': 0.0434, 'grad_norm': 0.6013149619102478, 'learning_rate': 2.2076271186440678e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [3:19:13<2:39:41,  3.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [3:19:17<2:36:04,  3.60s/it]                                                       {'loss': 0.0549, 'grad_norm': 5.756167411804199, 'learning_rate': 2.2067796610169492e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [3:19:17<2:36:04,  3.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [3:19:20<2:33:24,  3.54s/it]                                                       {'loss': 0.1967, 'grad_norm': 7.713608264923096, 'learning_rate': 2.2059322033898307e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [3:19:20<2:33:24,  3.54s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [3:19:23<2:31:26,  3.49s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.7406631708145142, 'learning_rate': 2.2050847457627118e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [3:19:23<2:31:26,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [3:19:27<2:30:32,  3.47s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1004287600517273, 'learning_rate': 2.2042372881355933e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [3:19:27<2:30:32,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [3:19:31<2:36:31,  3.61s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.9646050333976746, 'learning_rate': 2.2033898305084748e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [3:19:31<2:36:31,  3.61s/it][2025-10-20 02:56:35,997] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [3:19:36<3:03:09,  4.23s/it]                                                       {'loss': 0.3, 'grad_norm': 7.6258697509765625, 'learning_rate': 2.202542372881356e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [3:19:36<3:03:09,  4.23s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [3:19:40<2:53:20,  4.00s/it]                                                       {'loss': 0.0873, 'grad_norm': 7.517884254455566, 'learning_rate': 2.2016949152542373e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [3:19:40<2:53:20,  4.00s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [3:19:43<2:44:51,  3.81s/it]                                                       {'loss': 0.1389, 'grad_norm': 7.669320583343506, 'learning_rate': 2.2008474576271188e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [3:19:43<2:44:51,  3.81s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [3:19:47<2:41:21,  3.73s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.20462413132190704, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [3:19:47<2:41:21,  3.73s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [3:19:50<2:39:04,  3.68s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.201791450381279, 'learning_rate': 2.1991525423728814e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [3:19:50<2:39:04,  3.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [3:19:54<2:34:20,  3.57s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.5946463346481323, 'learning_rate': 2.198305084745763e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [3:19:54<2:34:20,  3.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [3:19:57<2:32:33,  3.53s/it]                                                       {'loss': 0.1577, 'grad_norm': 6.088714122772217, 'learning_rate': 2.1974576271186443e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [3:19:57<2:32:33,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [3:20:01<2:43:01,  3.77s/it]                                                       {'loss': 0.004, 'grad_norm': 0.44753673672676086, 'learning_rate': 2.1966101694915255e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [3:20:01<2:43:01,  3.77s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [3:20:05<2:39:24,  3.69s/it]                                                       {'loss': 0.2126, 'grad_norm': 8.696420669555664, 'learning_rate': 2.195762711864407e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [3:20:05<2:39:24,  3.69s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [3:20:08<2:35:43,  3.61s/it]                                                       {'loss': 0.0428, 'grad_norm': 6.189406394958496, 'learning_rate': 2.1949152542372884e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [3:20:08<2:35:43,  3.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [3:20:12<2:33:28,  3.56s/it]                                                       {'loss': 0.1207, 'grad_norm': 5.125295639038086, 'learning_rate': 2.1940677966101695e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [3:20:12<2:33:28,  3.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [3:20:15<2:32:11,  3.53s/it]                                                       {'loss': 0.0703, 'grad_norm': 3.258666753768921, 'learning_rate': 2.193220338983051e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [3:20:15<2:32:11,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [3:20:19<2:29:24,  3.47s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.1612744331359863, 'learning_rate': 2.1923728813559325e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [3:20:19<2:29:24,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [3:20:22<2:27:14,  3.42s/it]                                                       {'loss': 0.1311, 'grad_norm': 9.831581115722656, 'learning_rate': 2.1915254237288136e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [3:20:22<2:27:14,  3.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [3:20:25<2:28:46,  3.45s/it]                                                       {'loss': 0.0519, 'grad_norm': 4.760809898376465, 'learning_rate': 2.190677966101695e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [3:20:25<2:28:46,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [3:20:29<2:28:58,  3.46s/it]                                                       {'loss': 0.0672, 'grad_norm': 6.663999080657959, 'learning_rate': 2.1898305084745762e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [3:20:29<2:28:58,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [3:20:32<2:30:40,  3.50s/it]                                                       {'loss': 0.013, 'grad_norm': 1.5076990127563477, 'learning_rate': 2.1889830508474577e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [3:20:32<2:30:40,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [3:20:36<2:29:08,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.16399747133255005, 'learning_rate': 2.188135593220339e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [3:20:36<2:29:08,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [3:20:39<2:28:16,  3.45s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.7126234173774719, 'learning_rate': 2.1872881355932203e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [3:20:39<2:28:16,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [3:20:43<2:27:07,  3.42s/it]                                                       {'loss': 0.0563, 'grad_norm': 5.956464767456055, 'learning_rate': 2.1864406779661017e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [3:20:43<2:27:07,  3.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [3:20:46<2:28:35,  3.46s/it]                                                       {'loss': 0.1057, 'grad_norm': 7.50178337097168, 'learning_rate': 2.1855932203389832e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [3:20:46<2:28:35,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [3:20:50<2:28:02,  3.45s/it]                                                       {'loss': 0.091, 'grad_norm': 6.932943344116211, 'learning_rate': 2.1847457627118643e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [3:20:50<2:28:02,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [3:20:53<2:34:36,  3.60s/it]                                                       {'loss': 0.129, 'grad_norm': 7.251992225646973, 'learning_rate': 2.1838983050847458e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [3:20:53<2:34:36,  3.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [3:20:57<2:33:19,  3.57s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.3472300171852112, 'learning_rate': 2.1830508474576273e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [3:20:57<2:33:19,  3.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [3:21:00<2:31:17,  3.53s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.14613239467144012, 'learning_rate': 2.1822033898305087e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [3:21:00<2:31:17,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [3:21:04<2:30:11,  3.50s/it]                                                       {'loss': 0.027, 'grad_norm': 2.0751774311065674, 'learning_rate': 2.18135593220339e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [3:21:04<2:30:11,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [3:21:07<2:29:51,  3.49s/it]                                                       {'loss': 0.0156, 'grad_norm': 1.6291917562484741, 'learning_rate': 2.1805084745762713e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [3:21:07<2:29:51,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [3:21:11<2:28:26,  3.46s/it]                                                       {'loss': 0.1052, 'grad_norm': 7.4855828285217285, 'learning_rate': 2.1796610169491528e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [3:21:11<2:28:26,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [3:21:14<2:27:51,  3.45s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4560246467590332, 'learning_rate': 2.178813559322034e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [3:21:14<2:27:51,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [3:21:17<2:26:30,  3.42s/it]                                                       {'loss': 0.2935, 'grad_norm': 8.630481719970703, 'learning_rate': 2.1779661016949154e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [3:21:17<2:26:30,  3.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [3:21:21<2:31:13,  3.53s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.46535006165504456, 'learning_rate': 2.177118644067797e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [3:21:21<2:31:13,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [3:21:25<2:30:27,  3.52s/it]                                                       {'loss': 0.074, 'grad_norm': 3.433749198913574, 'learning_rate': 2.1762711864406783e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [3:21:25<2:30:27,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [3:21:28<2:29:49,  3.50s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.2076939046382904, 'learning_rate': 2.1754237288135594e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [3:21:28<2:29:49,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [3:21:32<2:28:23,  3.47s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.6034692525863647, 'learning_rate': 2.174576271186441e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [3:21:32<2:28:23,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [3:21:35<2:27:40,  3.45s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.7990401983261108, 'learning_rate': 2.173728813559322e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [3:21:35<2:27:40,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [3:21:38<2:27:32,  3.45s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.4358574450016022, 'learning_rate': 2.1728813559322035e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [3:21:38<2:27:32,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [3:21:42<2:33:11,  3.59s/it]                                                       {'loss': 0.0647, 'grad_norm': 5.028743267059326, 'learning_rate': 2.1720338983050846e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [3:21:42<2:33:11,  3.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [3:21:46<2:30:24,  3.52s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.4116274118423462, 'learning_rate': 2.171186440677966e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [3:21:46<2:30:24,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [3:21:50<2:36:00,  3.66s/it]                                                       {'loss': 0.0353, 'grad_norm': 3.4002156257629395, 'learning_rate': 2.1703389830508476e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [3:21:50<2:36:00,  3.66s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [3:21:53<2:32:44,  3.58s/it]                                                       {'loss': 0.0829, 'grad_norm': 6.434131622314453, 'learning_rate': 2.1694915254237287e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [3:21:53<2:32:44,  3.58s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [3:21:57<2:31:42,  3.56s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.6758878231048584, 'learning_rate': 2.1686440677966102e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [3:21:57<2:31:42,  3.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [3:22:00<2:30:31,  3.53s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4702635705471039, 'learning_rate': 2.1677966101694916e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [3:22:00<2:30:31,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [3:22:04<2:29:42,  3.51s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.9199652671813965, 'learning_rate': 2.166949152542373e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [3:22:04<2:29:42,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [3:22:07<2:29:09,  3.50s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.227260947227478, 'learning_rate': 2.1661016949152542e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [3:22:07<2:29:09,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [3:22:10<2:27:57,  3.47s/it]                                                       {'loss': 0.0148, 'grad_norm': 1.8890749216079712, 'learning_rate': 2.1652542372881357e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [3:22:10<2:27:57,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [3:22:14<2:31:30,  3.56s/it]                                                       {'loss': 0.0744, 'grad_norm': 4.740810871124268, 'learning_rate': 2.1644067796610172e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [3:22:14<2:31:30,  3.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [3:22:18<2:29:33,  3.52s/it]                                                       {'loss': 0.037, 'grad_norm': 2.600672960281372, 'learning_rate': 2.1635593220338983e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [3:22:18<2:29:33,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [3:22:21<2:27:41,  3.47s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5920783877372742, 'learning_rate': 2.1627118644067798e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [3:22:21<2:27:41,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [3:22:24<2:27:03,  3.46s/it]                                                       {'loss': 0.0503, 'grad_norm': 4.997690677642822, 'learning_rate': 2.1618644067796612e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [3:22:24<2:27:03,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [3:22:28<2:32:25,  3.59s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.0706514120101929, 'learning_rate': 2.1610169491525427e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [3:22:28<2:32:25,  3.59s/it][2025-10-20 02:59:33,636] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [3:22:34<2:59:41,  4.23s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.07935050874948502, 'learning_rate': 2.1601694915254238e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [3:22:34<2:59:41,  4.23s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [3:22:38<2:57:34,  4.18s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.4642676115036011, 'learning_rate': 2.1593220338983053e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [3:22:38<2:57:34,  4.18s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [3:22:42<2:47:54,  3.96s/it]                                                       {'loss': 0.2029, 'grad_norm': 8.941102981567383, 'learning_rate': 2.1584745762711868e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [3:22:42<2:47:54,  3.96s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [3:22:45<2:40:30,  3.78s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.7728519439697266, 'learning_rate': 2.157627118644068e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [3:22:45<2:40:30,  3.78s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [3:22:49<2:41:31,  3.81s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3758430480957031, 'learning_rate': 2.1567796610169494e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [3:22:49<2:41:31,  3.81s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [3:22:52<2:36:55,  3.70s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03795354813337326, 'learning_rate': 2.1559322033898305e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [3:22:52<2:36:55,  3.70s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [3:22:56<2:32:05,  3.59s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.61536705493927, 'learning_rate': 2.155084745762712e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [3:22:56<2:32:05,  3.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [3:22:59<2:28:49,  3.51s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06967656314373016, 'learning_rate': 2.154237288135593e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [3:22:59<2:28:49,  3.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [3:23:02<2:27:30,  3.48s/it]                                                       {'loss': 0.036, 'grad_norm': 3.934352397918701, 'learning_rate': 2.1533898305084746e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [3:23:02<2:27:30,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [3:23:06<2:25:40,  3.44s/it]                                                       {'loss': 0.0697, 'grad_norm': 6.72812032699585, 'learning_rate': 2.152542372881356e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [3:23:06<2:25:40,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [3:23:09<2:25:05,  3.43s/it]                                                       {'loss': 0.2396, 'grad_norm': 8.59090518951416, 'learning_rate': 2.1516949152542375e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [3:23:09<2:25:05,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [3:23:12<2:24:26,  3.41s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.3995034396648407, 'learning_rate': 2.1508474576271186e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [3:23:12<2:24:26,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [3:23:16<2:25:40,  3.45s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.17000392079353333, 'learning_rate': 2.15e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [3:23:16<2:25:40,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [3:23:19<2:25:10,  3.43s/it]                                                       {'loss': 0.019, 'grad_norm': 1.961272954940796, 'learning_rate': 2.1491525423728816e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [3:23:19<2:25:10,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [3:23:23<2:24:08,  3.41s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.084484338760376, 'learning_rate': 2.1483050847457627e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [3:23:23<2:24:08,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [3:23:26<2:22:59,  3.39s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1823737472295761, 'learning_rate': 2.147457627118644e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [3:23:26<2:22:59,  3.39s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [3:23:29<2:22:34,  3.38s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.8196403980255127, 'learning_rate': 2.1466101694915256e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [3:23:29<2:22:34,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [3:23:33<2:23:32,  3.40s/it]                                                       {'loss': 0.0231, 'grad_norm': 3.911623239517212, 'learning_rate': 2.145762711864407e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [3:23:33<2:23:32,  3.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [3:23:37<2:27:49,  3.50s/it]                                                       {'loss': 0.1696, 'grad_norm': 7.454638481140137, 'learning_rate': 2.1449152542372882e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [3:23:37<2:27:49,  3.50s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [3:23:40<2:27:33,  3.50s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5231450200080872, 'learning_rate': 2.1440677966101697e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [3:23:40<2:27:33,  3.50s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [3:23:43<2:25:18,  3.45s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.10788553208112717, 'learning_rate': 2.143220338983051e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [3:23:43<2:25:18,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [3:23:47<2:24:32,  3.43s/it]                                                       {'loss': 0.048, 'grad_norm': 5.791947364807129, 'learning_rate': 2.1423728813559323e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [3:23:47<2:24:32,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [3:23:50<2:26:08,  3.47s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.2524188458919525, 'learning_rate': 2.1415254237288137e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [3:23:50<2:26:08,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [3:23:54<2:25:46,  3.46s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.415892094373703, 'learning_rate': 2.1406779661016952e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [3:23:54<2:25:46,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [3:23:57<2:24:53,  3.44s/it]                                                       {'loss': 0.0568, 'grad_norm': 5.295909881591797, 'learning_rate': 2.1398305084745763e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [3:23:57<2:24:53,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [3:24:01<2:24:40,  3.44s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.6147912740707397, 'learning_rate': 2.1389830508474575e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [3:24:01<2:24:40,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [3:24:04<2:26:24,  3.48s/it]                                                       {'loss': 0.1278, 'grad_norm': 8.621068000793457, 'learning_rate': 2.138135593220339e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [3:24:04<2:26:24,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [3:24:08<2:25:02,  3.45s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2555246949195862, 'learning_rate': 2.1372881355932204e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [3:24:08<2:25:02,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [3:24:11<2:25:41,  3.47s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.15104764699935913, 'learning_rate': 2.136440677966102e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [3:24:11<2:25:41,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [3:24:15<2:29:09,  3.55s/it]                                                       {'loss': 0.3367, 'grad_norm': 9.951030731201172, 'learning_rate': 2.135593220338983e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [3:24:15<2:29:09,  3.55s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [3:24:18<2:26:37,  3.49s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.49915143847465515, 'learning_rate': 2.1347457627118645e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [3:24:18<2:26:37,  3.49s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [3:24:22<2:24:54,  3.45s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014569580554962158, 'learning_rate': 2.133898305084746e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [3:24:22<2:24:54,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [3:24:25<2:24:26,  3.44s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.7325731515884399, 'learning_rate': 2.133050847457627e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [3:24:25<2:24:26,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [3:24:28<2:22:58,  3.41s/it]                                                       {'loss': 0.0282, 'grad_norm': 3.382093906402588, 'learning_rate': 2.1322033898305085e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [3:24:28<2:22:58,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [3:24:32<2:24:32,  3.45s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.47498801350593567, 'learning_rate': 2.13135593220339e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [3:24:32<2:24:32,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [3:24:35<2:25:37,  3.48s/it]                                                       {'loss': 0.0439, 'grad_norm': 3.4728097915649414, 'learning_rate': 2.130508474576271e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [3:24:35<2:25:37,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [3:24:39<2:25:09,  3.47s/it]                                                       {'loss': 0.1388, 'grad_norm': 9.358431816101074, 'learning_rate': 2.1296610169491526e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [3:24:39<2:25:09,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [3:24:42<2:26:14,  3.49s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.6851953268051147, 'learning_rate': 2.128813559322034e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [3:24:42<2:26:14,  3.49s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [3:24:46<2:23:57,  3.44s/it]                                                       {'loss': 0.1851, 'grad_norm': 7.706669807434082, 'learning_rate': 2.1279661016949155e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [3:24:46<2:23:57,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [3:24:49<2:21:57,  3.39s/it]                                                       {'loss': 0.1171, 'grad_norm': 4.0725932121276855, 'learning_rate': 2.1271186440677967e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [3:24:49<2:21:57,  3.39s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [3:24:52<2:21:13,  3.38s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.44759976863861084, 'learning_rate': 2.126271186440678e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [3:24:52<2:21:13,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [3:24:56<2:20:58,  3.37s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3136044442653656, 'learning_rate': 2.1254237288135596e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [3:24:56<2:20:58,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [3:24:59<2:20:05,  3.35s/it]                                                       {'loss': 0.0155, 'grad_norm': 1.7774665355682373, 'learning_rate': 2.1245762711864407e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [3:24:59<2:20:05,  3.35s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [3:25:02<2:20:39,  3.37s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.814917802810669, 'learning_rate': 2.1237288135593222e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [3:25:02<2:20:39,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [3:25:06<2:20:55,  3.38s/it]                                                       {'loss': 0.0758, 'grad_norm': 6.007325649261475, 'learning_rate': 2.1228813559322037e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [3:25:06<2:20:55,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [3:25:09<2:20:46,  3.37s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.23659788072109222, 'learning_rate': 2.122033898305085e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [3:25:09<2:20:46,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [3:25:13<2:20:15,  3.36s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.6219358444213867, 'learning_rate': 2.121186440677966e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [3:25:13<2:20:15,  3.36s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [3:25:16<2:26:18,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.021884024143218994, 'learning_rate': 2.1203389830508474e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [3:25:16<2:26:18,  3.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [3:25:20<2:26:15,  3.51s/it]                                                       {'loss': 0.0594, 'grad_norm': 4.528343677520752, 'learning_rate': 2.119491525423729e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [3:25:20<2:26:15,  3.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [3:25:23<2:25:53,  3.50s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.11135149002075195, 'learning_rate': 2.1186440677966103e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [3:25:23<2:25:53,  3.50s/it][2025-10-20 03:02:28,691] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [3:25:29<2:54:28,  4.19s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.322304606437683, 'learning_rate': 2.1177966101694914e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [3:25:29<2:54:28,  4.19s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [3:25:33<2:44:21,  3.95s/it]                                                       {'loss': 0.0219, 'grad_norm': 3.696108818054199, 'learning_rate': 2.116949152542373e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [3:25:33<2:44:21,  3.95s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [3:25:36<2:38:23,  3.81s/it]                                                       {'loss': 0.0212, 'grad_norm': 2.482515335083008, 'learning_rate': 2.1161016949152544e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [3:25:36<2:38:23,  3.81s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [3:25:39<2:32:53,  3.68s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.500836730003357, 'learning_rate': 2.1152542372881355e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [3:25:39<2:32:53,  3.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [3:25:43<2:30:08,  3.61s/it]                                                       {'loss': 0.0292, 'grad_norm': 3.2514121532440186, 'learning_rate': 2.114406779661017e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [3:25:43<2:30:08,  3.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [3:25:46<2:28:58,  3.58s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.14941181242465973, 'learning_rate': 2.1135593220338984e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [3:25:46<2:28:58,  3.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [3:25:50<2:27:46,  3.56s/it]                                                       {'loss': 0.1151, 'grad_norm': 6.65935754776001, 'learning_rate': 2.11271186440678e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [3:25:50<2:27:46,  3.56s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [3:25:53<2:24:39,  3.48s/it]                                                       {'loss': 0.0482, 'grad_norm': 2.9154410362243652, 'learning_rate': 2.111864406779661e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [3:25:53<2:24:39,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [3:25:57<2:23:38,  3.46s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.24920916557312012, 'learning_rate': 2.1110169491525425e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [3:25:57<2:23:38,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [3:26:00<2:24:05,  3.47s/it]                                                       {'loss': 0.0257, 'grad_norm': 3.913865566253662, 'learning_rate': 2.110169491525424e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [3:26:00<2:24:05,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [3:26:04<2:25:32,  3.51s/it]                                                       {'loss': 0.0177, 'grad_norm': 2.3840675354003906, 'learning_rate': 2.109322033898305e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [3:26:04<2:25:32,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [3:26:07<2:24:59,  3.50s/it]                                                       {'loss': 0.0988, 'grad_norm': 7.2947564125061035, 'learning_rate': 2.1084745762711866e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [3:26:07<2:24:59,  3.50s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [3:26:11<2:25:28,  3.51s/it]                                                       {'loss': 0.1066, 'grad_norm': 5.759300231933594, 'learning_rate': 2.107627118644068e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [3:26:11<2:25:28,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [3:26:14<2:25:05,  3.50s/it]                                                       {'loss': 0.019, 'grad_norm': 3.606847047805786, 'learning_rate': 2.1067796610169495e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [3:26:14<2:25:05,  3.50s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [3:26:18<2:23:00,  3.45s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.1652886867523193, 'learning_rate': 2.1059322033898306e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [3:26:18<2:23:00,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [3:26:21<2:22:13,  3.44s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.0373029708862305, 'learning_rate': 2.105084745762712e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [3:26:21<2:22:13,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [3:26:24<2:22:38,  3.45s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.43101629614830017, 'learning_rate': 2.1042372881355936e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [3:26:24<2:22:38,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [3:26:28<2:21:14,  3.41s/it]                                                       {'loss': 0.5191, 'grad_norm': 11.086629867553711, 'learning_rate': 2.1033898305084747e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [3:26:28<2:21:14,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [3:26:31<2:23:28,  3.47s/it]                                                       {'loss': 0.1931, 'grad_norm': 6.076813220977783, 'learning_rate': 2.1025423728813558e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [3:26:31<2:23:28,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [3:26:35<2:24:19,  3.49s/it]                                                       {'loss': 0.1219, 'grad_norm': 6.835512161254883, 'learning_rate': 2.1016949152542373e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [3:26:35<2:24:19,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [3:26:38<2:23:29,  3.47s/it]                                                       {'loss': 0.165, 'grad_norm': 8.273799896240234, 'learning_rate': 2.1008474576271188e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [3:26:38<2:23:29,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [3:26:42<2:31:41,  3.67s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.713238537311554, 'learning_rate': 2.1e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [3:26:42<2:31:41,  3.67s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [3:26:46<2:27:54,  3.58s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.6939213871955872, 'learning_rate': 2.0991525423728814e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [3:26:46<2:27:54,  3.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [3:26:49<2:25:06,  3.52s/it]                                                       {'loss': 0.0211, 'grad_norm': 1.100938320159912, 'learning_rate': 2.0983050847457628e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [3:26:49<2:25:06,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [3:26:53<2:23:46,  3.49s/it]                                                       {'loss': 0.2152, 'grad_norm': 10.406018257141113, 'learning_rate': 2.0974576271186443e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [3:26:53<2:23:46,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [3:26:56<2:22:52,  3.46s/it]                                                       {'loss': 0.061, 'grad_norm': 5.88194465637207, 'learning_rate': 2.0966101694915254e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [3:26:56<2:22:52,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [3:26:59<2:21:10,  3.43s/it]                                                       {'loss': 0.0146, 'grad_norm': 1.2386972904205322, 'learning_rate': 2.095762711864407e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [3:26:59<2:21:10,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [3:27:03<2:19:53,  3.40s/it]                                                       {'loss': 0.0657, 'grad_norm': 3.967155933380127, 'learning_rate': 2.0949152542372883e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [3:27:03<2:19:53,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [3:27:06<2:21:14,  3.43s/it]                                                       {'loss': 0.0388, 'grad_norm': 2.8848445415496826, 'learning_rate': 2.0940677966101695e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [3:27:06<2:21:14,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [3:27:10<2:20:17,  3.41s/it]                                                       {'loss': 0.1357, 'grad_norm': 9.293242454528809, 'learning_rate': 2.093220338983051e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [3:27:10<2:20:17,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [3:27:13<2:19:30,  3.39s/it]                                                       {'loss': 0.0276, 'grad_norm': 3.4803409576416016, 'learning_rate': 2.0923728813559324e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [3:27:13<2:19:30,  3.39s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [3:27:16<2:18:34,  3.37s/it]                                                       {'loss': 0.0227, 'grad_norm': 1.5807225704193115, 'learning_rate': 2.091525423728814e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [3:27:16<2:18:34,  3.37s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [3:27:20<2:18:35,  3.37s/it]                                                       {'loss': 0.0173, 'grad_norm': 2.9654252529144287, 'learning_rate': 2.090677966101695e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [3:27:20<2:18:35,  3.37s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [3:27:23<2:19:24,  3.39s/it]                                                       {'loss': 0.008, 'grad_norm': 0.5612787008285522, 'learning_rate': 2.0898305084745765e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [3:27:23<2:19:24,  3.39s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [3:27:26<2:20:13,  3.41s/it]                                                       {'loss': 0.0154, 'grad_norm': 1.2257676124572754, 'learning_rate': 2.088983050847458e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [3:27:26<2:20:13,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [3:27:30<2:22:41,  3.47s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4395207464694977, 'learning_rate': 2.088135593220339e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [3:27:30<2:22:41,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [3:27:33<2:21:06,  3.44s/it]                                                       {'loss': 0.1193, 'grad_norm': 5.942832946777344, 'learning_rate': 2.0872881355932205e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [3:27:33<2:21:06,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [3:27:37<2:20:15,  3.42s/it]                                                       {'loss': 0.4603, 'grad_norm': 9.468541145324707, 'learning_rate': 2.086440677966102e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [3:27:37<2:20:15,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [3:27:40<2:19:27,  3.40s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.23952561616897583, 'learning_rate': 2.085593220338983e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [3:27:40<2:19:27,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [3:27:44<2:19:10,  3.39s/it]                                                       {'loss': 0.001, 'grad_norm': 0.17402631044387817, 'learning_rate': 2.0847457627118643e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [3:27:44<2:19:10,  3.39s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [3:27:47<2:18:14,  3.37s/it]                                                       {'loss': 0.1864, 'grad_norm': 5.841026782989502, 'learning_rate': 2.0838983050847457e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [3:27:47<2:18:14,  3.37s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [3:27:50<2:18:29,  3.38s/it]                                                       {'loss': 0.1152, 'grad_norm': 6.837563514709473, 'learning_rate': 2.0830508474576272e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [3:27:50<2:18:29,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [3:27:54<2:19:20,  3.40s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.76728355884552, 'learning_rate': 2.0822033898305087e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [3:27:54<2:19:20,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [3:27:57<2:19:20,  3.40s/it]                                                       {'loss': 0.1605, 'grad_norm': 6.6035051345825195, 'learning_rate': 2.0813559322033898e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [3:27:57<2:19:20,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [3:28:00<2:18:14,  3.38s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.4693045914173126, 'learning_rate': 2.0805084745762713e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [3:28:00<2:18:14,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [3:28:04<2:23:46,  3.52s/it]                                                       {'loss': 0.0878, 'grad_norm': 5.902619361877441, 'learning_rate': 2.0796610169491527e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [3:28:04<2:23:46,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [3:28:08<2:22:52,  3.49s/it]                                                       {'loss': 0.086, 'grad_norm': 6.593813419342041, 'learning_rate': 2.078813559322034e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [3:28:08<2:22:52,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [3:28:11<2:21:01,  3.45s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.23111774027347565, 'learning_rate': 2.0779661016949153e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [3:28:11<2:21:01,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [3:28:14<2:19:15,  3.41s/it]                                                       {'loss': 0.0274, 'grad_norm': 3.640813112258911, 'learning_rate': 2.0771186440677968e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [3:28:14<2:19:15,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [3:28:18<2:18:26,  3.39s/it]                                                       {'loss': 0.1214, 'grad_norm': 4.709726333618164, 'learning_rate': 2.076271186440678e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [3:28:18<2:18:26,  3.39s/it][2025-10-20 03:05:23,050] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [3:28:24<2:57:36,  4.35s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.0746099948883057, 'learning_rate': 2.0754237288135594e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [3:28:24<2:57:36,  4.35s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [3:28:28<2:50:12,  4.17s/it]                                                       {'loss': 0.0429, 'grad_norm': 2.3920705318450928, 'learning_rate': 2.074576271186441e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [3:28:28<2:50:12,  4.17s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [3:28:32<2:42:09,  3.98s/it]                                                       {'loss': 0.007, 'grad_norm': 0.899309515953064, 'learning_rate': 2.0737288135593223e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [3:28:32<2:42:09,  3.98s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [3:28:35<2:35:02,  3.80s/it]                                                       {'loss': 0.0297, 'grad_norm': 2.1594598293304443, 'learning_rate': 2.0728813559322035e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [3:28:35<2:35:02,  3.80s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [3:28:38<2:29:49,  3.68s/it]                                                       {'loss': 0.0832, 'grad_norm': 5.986965179443359, 'learning_rate': 2.072033898305085e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [3:28:38<2:29:49,  3.68s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [3:28:42<2:26:41,  3.60s/it]                                                       {'loss': 0.1302, 'grad_norm': 5.647182941436768, 'learning_rate': 2.0711864406779664e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [3:28:42<2:26:41,  3.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [3:28:45<2:25:22,  3.57s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.20497868955135345, 'learning_rate': 2.0703389830508475e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [3:28:45<2:25:22,  3.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [3:28:49<2:25:56,  3.59s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0009772718185558915, 'learning_rate': 2.069491525423729e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [3:28:49<2:25:56,  3.59s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [3:28:52<2:23:30,  3.53s/it]                                                       {'loss': 0.1411, 'grad_norm': 6.043728828430176, 'learning_rate': 2.06864406779661e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [3:28:52<2:23:30,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [3:28:56<2:20:50,  3.46s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.0872151181101799, 'learning_rate': 2.0677966101694916e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [3:28:56<2:20:50,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [3:28:59<2:19:15,  3.43s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.273952007293701, 'learning_rate': 2.0669491525423727e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [3:28:59<2:19:15,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [3:29:02<2:18:12,  3.40s/it]                                                       {'loss': 0.0194, 'grad_norm': 1.055810570716858, 'learning_rate': 2.0661016949152542e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [3:29:02<2:18:12,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [3:29:06<2:19:34,  3.44s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.1717008799314499, 'learning_rate': 2.0652542372881356e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [3:29:06<2:19:34,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [3:29:10<2:23:34,  3.54s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.1472456157207489, 'learning_rate': 2.064406779661017e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [3:29:10<2:23:34,  3.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [3:29:13<2:21:34,  3.49s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.7639634609222412, 'learning_rate': 2.0635593220338982e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [3:29:13<2:21:34,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [3:29:17<2:22:57,  3.52s/it]                                                       {'loss': 0.0298, 'grad_norm': 4.220564842224121, 'learning_rate': 2.0627118644067797e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [3:29:17<2:22:57,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [3:29:20<2:20:46,  3.47s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2256268560886383, 'learning_rate': 2.0618644067796612e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [3:29:20<2:20:46,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [3:29:23<2:20:28,  3.47s/it]                                                       {'loss': 0.1873, 'grad_norm': 5.094748020172119, 'learning_rate': 2.0610169491525423e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [3:29:23<2:20:28,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [3:29:27<2:19:19,  3.44s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.6649457812309265, 'learning_rate': 2.0601694915254238e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [3:29:27<2:19:19,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [3:29:30<2:18:31,  3.42s/it]                                                       {'loss': 0.0151, 'grad_norm': 1.5347216129302979, 'learning_rate': 2.0593220338983052e-05, 'epoch': 0.59}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [3:29:30<2:18:31,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [3:29:33<2:16:45,  3.38s/it]                                                       {'loss': 0.0488, 'grad_norm': 2.1923601627349854, 'learning_rate': 2.0584745762711867e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [3:29:33<2:16:45,  3.38s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [3:29:37<2:18:34,  3.42s/it]                                                       {'loss': 0.0572, 'grad_norm': 5.004220962524414, 'learning_rate': 2.057627118644068e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [3:29:37<2:18:34,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [3:29:40<2:17:22,  3.40s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.7591986656188965, 'learning_rate': 2.0567796610169493e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [3:29:40<2:17:22,  3.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [3:29:44<2:22:51,  3.53s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07660619914531708, 'learning_rate': 2.0559322033898308e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [3:29:44<2:22:51,  3.53s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [3:29:48<2:30:00,  3.71s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.11993858218193054, 'learning_rate': 2.055084745762712e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [3:29:48<2:30:00,  3.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [3:29:52<2:26:37,  3.63s/it]                                                       {'loss': 0.0203, 'grad_norm': 1.7749446630477905, 'learning_rate': 2.0542372881355934e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [3:29:52<2:26:37,  3.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [3:29:55<2:26:35,  3.63s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.559551239013672, 'learning_rate': 2.053389830508475e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [3:29:55<2:26:35,  3.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [3:29:59<2:22:52,  3.54s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.13942426443099976, 'learning_rate': 2.0525423728813563e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [3:29:59<2:22:52,  3.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [3:30:02<2:20:05,  3.47s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.13946455717086792, 'learning_rate': 2.0516949152542374e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [3:30:02<2:20:05,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [3:30:05<2:19:36,  3.46s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.4293367862701416, 'learning_rate': 2.0508474576271186e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [3:30:05<2:19:36,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [3:30:09<2:24:26,  3.58s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.036589231342077255, 'learning_rate': 2.05e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [3:30:09<2:24:26,  3.58s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [3:30:13<2:23:32,  3.56s/it]                                                       {'loss': 0.2183, 'grad_norm': 6.41470193862915, 'learning_rate': 2.0491525423728815e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [3:30:13<2:23:32,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [3:30:16<2:25:21,  3.61s/it]                                                       {'loss': 0.1045, 'grad_norm': 7.218542098999023, 'learning_rate': 2.0483050847457626e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [3:30:17<2:25:21,  3.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [3:30:20<2:23:17,  3.56s/it]                                                       {'loss': 0.0413, 'grad_norm': 3.6584537029266357, 'learning_rate': 2.047457627118644e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [3:30:20<2:23:17,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [3:30:23<2:20:21,  3.49s/it]                                                       {'loss': 0.0486, 'grad_norm': 4.424038410186768, 'learning_rate': 2.0466101694915256e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [3:30:23<2:20:21,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [3:30:27<2:18:38,  3.45s/it]                                                       {'loss': 0.0499, 'grad_norm': 5.442716121673584, 'learning_rate': 2.0457627118644067e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [3:30:27<2:18:38,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [3:30:30<2:17:31,  3.42s/it]                                                       {'loss': 0.0531, 'grad_norm': 5.323546886444092, 'learning_rate': 2.044915254237288e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [3:30:30<2:17:31,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [3:30:33<2:17:24,  3.42s/it]                                                       {'loss': 0.1641, 'grad_norm': 7.100481033325195, 'learning_rate': 2.0440677966101696e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [3:30:33<2:17:24,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [3:30:37<2:18:44,  3.45s/it]                                                       {'loss': 0.1761, 'grad_norm': 4.959792613983154, 'learning_rate': 2.043220338983051e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [3:30:37<2:18:44,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [3:30:40<2:18:26,  3.45s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.5961087942123413, 'learning_rate': 2.0423728813559322e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [3:30:40<2:18:26,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [3:30:44<2:17:35,  3.43s/it]                                                       {'loss': 0.1159, 'grad_norm': 5.806439399719238, 'learning_rate': 2.0415254237288137e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [3:30:44<2:17:35,  3.43s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [3:30:47<2:16:40,  3.41s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.9615635871887207, 'learning_rate': 2.040677966101695e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [3:30:47<2:16:40,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [3:30:50<2:15:59,  3.39s/it]                                                       {'loss': 0.2524, 'grad_norm': 6.932527542114258, 'learning_rate': 2.0398305084745763e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [3:30:50<2:15:59,  3.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [3:30:54<2:22:22,  3.55s/it]                                                       {'loss': 0.1126, 'grad_norm': 6.004842758178711, 'learning_rate': 2.0389830508474577e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [3:30:54<2:22:22,  3.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [3:30:58<2:21:03,  3.52s/it]                                                       {'loss': 0.1417, 'grad_norm': 4.889350891113281, 'learning_rate': 2.0381355932203392e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [3:30:58<2:21:03,  3.52s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [3:31:01<2:19:25,  3.48s/it]                                                       {'loss': 0.009, 'grad_norm': 1.0922199487686157, 'learning_rate': 2.0372881355932207e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [3:31:01<2:19:25,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [3:31:05<2:18:53,  3.47s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.769886314868927, 'learning_rate': 2.0364406779661018e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [3:31:05<2:18:53,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [3:31:08<2:18:23,  3.46s/it]                                                       {'loss': 0.1553, 'grad_norm': 9.1613187789917, 'learning_rate': 2.0355932203389833e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [3:31:08<2:18:23,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [3:31:11<2:16:48,  3.42s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.47544065117836, 'learning_rate': 2.0347457627118647e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [3:31:11<2:16:48,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [3:31:15<2:15:55,  3.40s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.8540587425231934, 'learning_rate': 2.033898305084746e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [3:31:15<2:15:55,  3.40s/it][2025-10-20 03:08:20,080] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [3:31:21<2:47:25,  4.19s/it]                                                       {'loss': 0.0306, 'grad_norm': 2.270779848098755, 'learning_rate': 2.033050847457627e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [3:31:21<2:47:25,  4.19s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [3:31:24<2:38:22,  3.96s/it]                                                       {'loss': 0.1381, 'grad_norm': 8.404117584228516, 'learning_rate': 2.0322033898305085e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [3:31:24<2:38:22,  3.96s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [3:31:28<2:32:42,  3.82s/it]                                                       {'loss': 0.0549, 'grad_norm': 6.593600749969482, 'learning_rate': 2.03135593220339e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [3:31:28<2:32:42,  3.82s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [3:31:31<2:27:14,  3.69s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6066754460334778, 'learning_rate': 2.030508474576271e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [3:31:31<2:27:14,  3.69s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [3:31:34<2:23:16,  3.59s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016661223024129868, 'learning_rate': 2.0296610169491525e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [3:31:34<2:23:16,  3.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [3:31:38<2:21:26,  3.54s/it]                                                       {'loss': 0.1015, 'grad_norm': 2.6734604835510254, 'learning_rate': 2.028813559322034e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [3:31:38<2:21:26,  3.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [3:31:41<2:19:54,  3.51s/it]                                                       {'loss': 0.071, 'grad_norm': 6.619655132293701, 'learning_rate': 2.0279661016949155e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [3:31:41<2:19:54,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [3:31:45<2:20:06,  3.51s/it]                                                       {'loss': 0.1865, 'grad_norm': 9.775068283081055, 'learning_rate': 2.0271186440677966e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [3:31:45<2:20:06,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [3:31:49<2:29:29,  3.75s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.09344111382961273, 'learning_rate': 2.026271186440678e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [3:31:49<2:29:29,  3.75s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [3:31:53<2:36:30,  3.93s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4132019281387329, 'learning_rate': 2.0254237288135595e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [3:31:53<2:36:30,  3.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [3:31:57<2:30:31,  3.78s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0838383287191391, 'learning_rate': 2.0245762711864407e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [3:31:57<2:30:31,  3.78s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [3:32:01<2:28:05,  3.72s/it]                                                       {'loss': 0.0797, 'grad_norm': 7.280719757080078, 'learning_rate': 2.023728813559322e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [3:32:01<2:28:05,  3.72s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [3:32:04<2:23:35,  3.61s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07703913003206253, 'learning_rate': 2.0228813559322036e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [3:32:04<2:23:35,  3.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [3:32:08<2:25:30,  3.66s/it]                                                       {'loss': 0.0488, 'grad_norm': 3.3173375129699707, 'learning_rate': 2.0220338983050847e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [3:32:08<2:25:30,  3.66s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [3:32:11<2:22:17,  3.58s/it]                                                       {'loss': 0.319, 'grad_norm': 9.963958740234375, 'learning_rate': 2.0211864406779662e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [3:32:11<2:22:17,  3.58s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [3:32:14<2:20:32,  3.54s/it]                                                       {'loss': 0.2452, 'grad_norm': 9.423245429992676, 'learning_rate': 2.0203389830508477e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [3:32:14<2:20:32,  3.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [3:32:18<2:18:44,  3.49s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5607734322547913, 'learning_rate': 2.019491525423729e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [3:32:18<2:18:44,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [3:32:21<2:17:32,  3.46s/it]                                                       {'loss': 0.0292, 'grad_norm': 3.4476778507232666, 'learning_rate': 2.0186440677966103e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [3:32:21<2:17:32,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [3:32:25<2:18:10,  3.48s/it]                                                       {'loss': 0.0729, 'grad_norm': 4.710452556610107, 'learning_rate': 2.0177966101694917e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [3:32:25<2:18:10,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [3:32:28<2:19:02,  3.51s/it]                                                       {'loss': 0.024, 'grad_norm': 2.831387758255005, 'learning_rate': 2.0169491525423732e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [3:32:28<2:19:02,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [3:32:32<2:20:24,  3.54s/it]                                                       {'loss': 0.2571, 'grad_norm': 9.701862335205078, 'learning_rate': 2.0161016949152543e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [3:32:32<2:20:24,  3.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [3:32:35<2:17:47,  3.48s/it]                                                       {'loss': 0.1851, 'grad_norm': 6.733112335205078, 'learning_rate': 2.0152542372881354e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [3:32:35<2:17:47,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [3:32:39<2:16:26,  3.44s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.4528256952762604, 'learning_rate': 2.014406779661017e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [3:32:39<2:16:26,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [3:32:42<2:15:08,  3.41s/it]                                                       {'loss': 0.0922, 'grad_norm': 5.621376037597656, 'learning_rate': 2.0135593220338984e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [3:32:42<2:15:08,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [3:32:45<2:15:02,  3.41s/it]                                                       {'loss': 0.2148, 'grad_norm': 7.444774150848389, 'learning_rate': 2.0127118644067795e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [3:32:45<2:15:02,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [3:32:49<2:14:57,  3.41s/it]                                                       {'loss': 0.0885, 'grad_norm': 8.297233581542969, 'learning_rate': 2.011864406779661e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [3:32:49<2:14:57,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [3:32:52<2:14:47,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02112157642841339, 'learning_rate': 2.0110169491525424e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [3:32:52<2:14:47,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [3:32:55<2:13:01,  3.37s/it]                                                       {'loss': 0.0106, 'grad_norm': 2.1614043712615967, 'learning_rate': 2.010169491525424e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [3:32:55<2:13:01,  3.37s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [3:32:59<2:17:27,  3.48s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.6011984944343567, 'learning_rate': 2.009322033898305e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [3:32:59<2:17:27,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [3:33:03<2:15:39,  3.43s/it]                                                       {'loss': 0.2425, 'grad_norm': 8.898824691772461, 'learning_rate': 2.0084745762711865e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [3:33:03<2:15:39,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [3:33:06<2:16:08,  3.45s/it]                                                       {'loss': 0.018, 'grad_norm': 1.9519540071487427, 'learning_rate': 2.007627118644068e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [3:33:06<2:16:08,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [3:33:09<2:15:58,  3.45s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.757607638835907, 'learning_rate': 2.006779661016949e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [3:33:09<2:15:58,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [3:33:14<2:25:51,  3.70s/it]                                                       {'loss': 0.2773, 'grad_norm': 8.034285545349121, 'learning_rate': 2.0059322033898306e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [3:33:14<2:25:51,  3.70s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [3:33:17<2:22:22,  3.61s/it]                                                       {'loss': 0.083, 'grad_norm': 6.304504871368408, 'learning_rate': 2.005084745762712e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [3:33:17<2:22:22,  3.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [3:33:21<2:20:42,  3.57s/it]                                                       {'loss': 0.001, 'grad_norm': 0.15732255578041077, 'learning_rate': 2.0042372881355935e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [3:33:21<2:20:42,  3.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [3:33:24<2:19:22,  3.54s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.202297329902649, 'learning_rate': 2.0033898305084746e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [3:33:24<2:19:22,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [3:33:28<2:19:55,  3.55s/it]                                                       {'loss': 0.0714, 'grad_norm': 4.825423240661621, 'learning_rate': 2.002542372881356e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [3:33:28<2:19:55,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [3:33:31<2:18:59,  3.53s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13315467536449432, 'learning_rate': 2.0016949152542376e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [3:33:31<2:18:59,  3.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [3:33:35<2:19:26,  3.54s/it]                                                       {'loss': 0.0817, 'grad_norm': 8.318580627441406, 'learning_rate': 2.0008474576271187e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [3:33:35<2:19:26,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [3:33:38<2:19:29,  3.55s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.15151925384998322, 'learning_rate': 2e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [3:33:38<2:19:29,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [3:33:42<2:17:59,  3.51s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.756673574447632, 'learning_rate': 1.9991525423728816e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [3:33:42<2:17:59,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [3:33:45<2:16:39,  3.48s/it]                                                       {'loss': 0.0725, 'grad_norm': 2.954425573348999, 'learning_rate': 1.998305084745763e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [3:33:45<2:16:39,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [3:33:49<2:21:01,  3.59s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.12241648882627487, 'learning_rate': 1.997457627118644e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [3:33:49<2:21:01,  3.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [3:33:52<2:18:05,  3.52s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6958213448524475, 'learning_rate': 1.9966101694915254e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [3:33:52<2:18:05,  3.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [3:33:56<2:17:22,  3.50s/it]                                                       {'loss': 0.151, 'grad_norm': 11.900142669677734, 'learning_rate': 1.9957627118644068e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [3:33:56<2:17:22,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [3:33:59<2:16:55,  3.49s/it]                                                       {'loss': 0.1908, 'grad_norm': 7.659387111663818, 'learning_rate': 1.9949152542372883e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [3:33:59<2:16:55,  3.49s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [3:34:03<2:15:31,  3.46s/it]                                                       {'loss': 0.0644, 'grad_norm': 4.704768180847168, 'learning_rate': 1.9940677966101694e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [3:34:03<2:15:31,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [3:34:06<2:14:32,  3.43s/it]                                                       {'loss': 0.0127, 'grad_norm': 2.7818078994750977, 'learning_rate': 1.993220338983051e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [3:34:06<2:14:32,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [3:34:09<2:14:45,  3.44s/it]                                                       {'loss': 0.021, 'grad_norm': 1.773364543914795, 'learning_rate': 1.9923728813559324e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [3:34:09<2:14:45,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [3:34:13<2:13:23,  3.41s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.23740674555301666, 'learning_rate': 1.9915254237288135e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [3:34:13<2:13:23,  3.41s/it][2025-10-20 03:11:18,100] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [3:34:18<2:39:51,  4.08s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3053598701953888, 'learning_rate': 1.990677966101695e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [3:34:18<2:39:51,  4.08s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [3:34:22<2:32:04,  3.89s/it]                                                       {'loss': 0.012, 'grad_norm': 1.7184590101242065, 'learning_rate': 1.9898305084745764e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [3:34:22<2:32:04,  3.89s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [3:34:25<2:25:51,  3.73s/it]                                                       {'loss': 0.1013, 'grad_norm': 7.062990188598633, 'learning_rate': 1.988983050847458e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [3:34:25<2:25:51,  3.73s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [3:34:29<2:20:53,  3.60s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05221583694219589, 'learning_rate': 1.988135593220339e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [3:34:29<2:20:53,  3.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [3:34:32<2:18:45,  3.55s/it]                                                       {'loss': 0.2494, 'grad_norm': 9.235363006591797, 'learning_rate': 1.9872881355932205e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [3:34:32<2:18:45,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [3:34:35<2:16:03,  3.48s/it]                                                       {'loss': 0.2448, 'grad_norm': 8.186088562011719, 'learning_rate': 1.986440677966102e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [3:34:35<2:16:03,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [3:34:39<2:14:37,  3.45s/it]                                                       {'loss': 0.0341, 'grad_norm': 3.6702535152435303, 'learning_rate': 1.985593220338983e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [3:34:39<2:14:37,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [3:34:42<2:14:57,  3.46s/it]                                                       {'loss': 0.0301, 'grad_norm': 4.163206100463867, 'learning_rate': 1.9847457627118645e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [3:34:42<2:14:57,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [3:34:46<2:18:00,  3.54s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.25411736965179443, 'learning_rate': 1.983898305084746e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [3:34:46<2:18:00,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [3:34:49<2:16:44,  3.51s/it]                                                       {'loss': 0.0354, 'grad_norm': 4.633613586425781, 'learning_rate': 1.9830508474576275e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [3:34:49<2:16:44,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [3:34:53<2:15:21,  3.47s/it]                                                       {'loss': 0.0137, 'grad_norm': 2.0507166385650635, 'learning_rate': 1.9822033898305086e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [3:34:53<2:15:21,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [3:34:56<2:13:51,  3.44s/it]                                                       {'loss': 0.0391, 'grad_norm': 4.592114448547363, 'learning_rate': 1.98135593220339e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [3:34:56<2:13:51,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [3:34:59<2:13:48,  3.44s/it]                                                       {'loss': 0.1099, 'grad_norm': 5.204304218292236, 'learning_rate': 1.9805084745762712e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [3:34:59<2:13:48,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [3:35:03<2:12:54,  3.41s/it]                                                       {'loss': 0.0398, 'grad_norm': 4.010562419891357, 'learning_rate': 1.9796610169491527e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [3:35:03<2:12:54,  3.41s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [3:35:07<2:19:38,  3.59s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.842585802078247, 'learning_rate': 1.9788135593220338e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [3:35:07<2:19:38,  3.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [3:35:11<2:23:53,  3.70s/it]                                                       {'loss': 0.1272, 'grad_norm': 4.946565628051758, 'learning_rate': 1.9779661016949153e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [3:35:11<2:23:53,  3.70s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [3:35:14<2:20:33,  3.61s/it]                                                       {'loss': 0.0354, 'grad_norm': 3.8754076957702637, 'learning_rate': 1.9771186440677967e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [3:35:14<2:20:33,  3.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [3:35:18<2:17:28,  3.54s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1127537414431572, 'learning_rate': 1.976271186440678e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [3:35:18<2:17:28,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [3:35:21<2:15:59,  3.50s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.5100076794624329, 'learning_rate': 1.9754237288135593e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [3:35:21<2:15:59,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [3:35:25<2:19:34,  3.59s/it]                                                       {'loss': 0.0754, 'grad_norm': 6.366754531860352, 'learning_rate': 1.9745762711864408e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [3:35:25<2:19:34,  3.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [3:35:28<2:15:48,  3.50s/it]                                                       {'loss': 0.033, 'grad_norm': 4.438666820526123, 'learning_rate': 1.9737288135593223e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [3:35:28<2:15:48,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [3:35:31<2:14:27,  3.47s/it]                                                       {'loss': 0.0365, 'grad_norm': 3.086230516433716, 'learning_rate': 1.9728813559322034e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [3:35:31<2:14:27,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [3:35:35<2:12:42,  3.42s/it]                                                       {'loss': 0.2266, 'grad_norm': 9.613110542297363, 'learning_rate': 1.972033898305085e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [3:35:35<2:12:42,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [3:35:39<2:16:43,  3.53s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2221696674823761, 'learning_rate': 1.9711864406779663e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [3:35:39<2:16:43,  3.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [3:35:42<2:16:49,  3.53s/it]                                                       {'loss': 0.0403, 'grad_norm': 4.041731357574463, 'learning_rate': 1.9703389830508475e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [3:35:42<2:16:49,  3.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [3:35:46<2:16:10,  3.52s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.1201493740081787, 'learning_rate': 1.969491525423729e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [3:35:46<2:16:10,  3.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [3:35:49<2:14:45,  3.48s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04765214025974274, 'learning_rate': 1.9686440677966104e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [3:35:49<2:14:45,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [3:35:52<2:12:31,  3.42s/it]                                                       {'loss': 0.0531, 'grad_norm': 3.2938387393951416, 'learning_rate': 1.9677966101694915e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [3:35:52<2:12:31,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [3:35:56<2:11:18,  3.39s/it]                                                       {'loss': 0.001, 'grad_norm': 0.09711495041847229, 'learning_rate': 1.966949152542373e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [3:35:56<2:11:18,  3.39s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [3:35:59<2:12:39,  3.43s/it]                                                       {'loss': 0.0336, 'grad_norm': 4.855432033538818, 'learning_rate': 1.9661016949152545e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [3:35:59<2:12:39,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [3:36:03<2:13:35,  3.46s/it]                                                       {'loss': 0.0253, 'grad_norm': 1.533520221710205, 'learning_rate': 1.965254237288136e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [3:36:03<2:13:35,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [3:36:06<2:12:35,  3.43s/it]                                                       {'loss': 0.0634, 'grad_norm': 4.563529968261719, 'learning_rate': 1.964406779661017e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [3:36:06<2:12:35,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [3:36:10<2:17:32,  3.56s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.16132216155529022, 'learning_rate': 1.9635593220338985e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [3:36:10<2:17:32,  3.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [3:36:13<2:14:54,  3.50s/it]                                                       {'loss': 0.1627, 'grad_norm': 8.453390121459961, 'learning_rate': 1.9627118644067796e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [3:36:13<2:14:54,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [3:36:17<2:17:19,  3.56s/it]                                                       {'loss': 0.0169, 'grad_norm': 1.627546787261963, 'learning_rate': 1.961864406779661e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [3:36:17<2:17:19,  3.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [3:36:20<2:16:34,  3.54s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.007715219631791115, 'learning_rate': 1.9610169491525422e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [3:36:20<2:16:34,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [3:36:24<2:19:17,  3.61s/it]                                                       {'loss': 0.1365, 'grad_norm': 8.495059967041016, 'learning_rate': 1.9601694915254237e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [3:36:24<2:19:17,  3.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [3:36:28<2:16:06,  3.53s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7573038935661316, 'learning_rate': 1.9593220338983052e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [3:36:28<2:16:06,  3.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [3:36:31<2:14:38,  3.50s/it]                                                       {'loss': 0.0623, 'grad_norm': 6.14235782623291, 'learning_rate': 1.9584745762711863e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [3:36:31<2:14:38,  3.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [3:36:34<2:14:42,  3.50s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.2642781734466553, 'learning_rate': 1.9576271186440678e-05, 'epoch': 0.61}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [3:36:34<2:14:42,  3.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [3:36:38<2:13:10,  3.46s/it]                                                       {'loss': 0.0667, 'grad_norm': 2.8025925159454346, 'learning_rate': 1.9567796610169492e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [3:36:38<2:13:10,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [3:36:41<2:13:30,  3.47s/it]                                                       {'loss': 0.0123, 'grad_norm': 3.229844093322754, 'learning_rate': 1.9559322033898307e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [3:36:41<2:13:30,  3.47s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [3:36:45<2:12:56,  3.46s/it]                                                       {'loss': 0.042, 'grad_norm': 4.265204906463623, 'learning_rate': 1.955084745762712e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [3:36:45<2:12:56,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [3:36:48<2:15:13,  3.52s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.1700674295425415, 'learning_rate': 1.9542372881355933e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [3:36:48<2:15:13,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [3:36:52<2:14:46,  3.51s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08561547100543976, 'learning_rate': 1.9533898305084748e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [3:36:52<2:14:46,  3.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [3:36:55<2:14:08,  3.49s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.32005342841148376, 'learning_rate': 1.952542372881356e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [3:36:55<2:14:08,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [3:36:59<2:13:47,  3.49s/it]                                                       {'loss': 0.0502, 'grad_norm': 4.681102275848389, 'learning_rate': 1.9516949152542374e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [3:36:59<2:13:47,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [3:37:03<2:22:19,  3.71s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.8780980706214905, 'learning_rate': 1.950847457627119e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [3:37:03<2:22:19,  3.71s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [3:37:07<2:21:56,  3.70s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.36427924036979675, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [3:37:07<2:21:56,  3.70s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [3:37:10<2:21:54,  3.70s/it]                                                       {'loss': 0.0782, 'grad_norm': 7.314472198486328, 'learning_rate': 1.9491525423728814e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [3:37:10<2:21:54,  3.70s/it][2025-10-20 03:14:15,781] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [3:37:16<2:45:16,  4.31s/it]                                                       {'loss': 0.0921, 'grad_norm': 4.787247657775879, 'learning_rate': 1.948305084745763e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [3:37:16<2:45:16,  4.31s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [3:37:20<2:34:34,  4.04s/it]                                                       {'loss': 0.0238, 'grad_norm': 2.9034667015075684, 'learning_rate': 1.9474576271186444e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [3:37:20<2:34:34,  4.04s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [3:37:23<2:26:50,  3.84s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3920226991176605, 'learning_rate': 1.9466101694915255e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [3:37:23<2:26:50,  3.84s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [3:37:26<2:21:48,  3.71s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.8242967128753662, 'learning_rate': 1.945762711864407e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [3:37:26<2:21:48,  3.71s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [3:37:30<2:21:22,  3.70s/it]                                                       {'loss': 0.0177, 'grad_norm': 3.1113409996032715, 'learning_rate': 1.944915254237288e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [3:37:30<2:21:22,  3.70s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [3:37:34<2:22:07,  3.72s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.3417046070098877, 'learning_rate': 1.9440677966101696e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [3:37:34<2:22:07,  3.72s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [3:37:37<2:17:11,  3.59s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.025713736191391945, 'learning_rate': 1.9432203389830507e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [3:37:37<2:17:11,  3.59s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [3:37:40<2:14:03,  3.51s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.4173949062824249, 'learning_rate': 1.942372881355932e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [3:37:40<2:14:03,  3.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [3:37:44<2:11:33,  3.45s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.6838597059249878, 'learning_rate': 1.9415254237288136e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [3:37:44<2:11:33,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [3:37:47<2:10:41,  3.42s/it]                                                       {'loss': 0.1029, 'grad_norm': 4.605458736419678, 'learning_rate': 1.940677966101695e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [3:37:47<2:10:41,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [3:37:50<2:10:00,  3.41s/it]                                                       {'loss': 0.1853, 'grad_norm': 6.9517645835876465, 'learning_rate': 1.9398305084745762e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [3:37:50<2:10:00,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [3:37:54<2:09:53,  3.41s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.7779886722564697, 'learning_rate': 1.9389830508474577e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [3:37:54<2:09:53,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [3:37:57<2:10:01,  3.41s/it]                                                       {'loss': 0.0867, 'grad_norm': 8.12137508392334, 'learning_rate': 1.938135593220339e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [3:37:57<2:10:01,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [3:38:01<2:11:16,  3.45s/it]                                                       {'loss': 0.1104, 'grad_norm': 3.060985803604126, 'learning_rate': 1.9372881355932203e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [3:38:01<2:11:16,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [3:38:04<2:11:28,  3.45s/it]                                                       {'loss': 0.0375, 'grad_norm': 5.3262152671813965, 'learning_rate': 1.9364406779661017e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [3:38:04<2:11:28,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [3:38:08<2:10:13,  3.42s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.2084085941314697, 'learning_rate': 1.9355932203389832e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [3:38:08<2:10:13,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [3:38:11<2:12:48,  3.49s/it]                                                       {'loss': 0.085, 'grad_norm': 5.504044055938721, 'learning_rate': 1.9347457627118647e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [3:38:11<2:12:48,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [3:38:15<2:11:51,  3.47s/it]                                                       {'loss': 0.0252, 'grad_norm': 1.5241689682006836, 'learning_rate': 1.9338983050847458e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [3:38:15<2:11:51,  3.47s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [3:38:18<2:13:37,  3.51s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2485603392124176, 'learning_rate': 1.9330508474576273e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [3:38:18<2:13:37,  3.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [3:38:22<2:12:55,  3.50s/it]                                                       {'loss': 0.1549, 'grad_norm': 6.035689830780029, 'learning_rate': 1.9322033898305087e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [3:38:22<2:12:55,  3.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [3:38:25<2:11:53,  3.47s/it]                                                       {'loss': 0.0746, 'grad_norm': 7.757422924041748, 'learning_rate': 1.93135593220339e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [3:38:25<2:11:53,  3.47s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [3:38:29<2:15:10,  3.56s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.9049928188323975, 'learning_rate': 1.9305084745762713e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [3:38:29<2:15:10,  3.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [3:38:32<2:12:33,  3.49s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2860792577266693, 'learning_rate': 1.9296610169491528e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [3:38:32<2:12:33,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [3:38:36<2:17:05,  3.61s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.480294942855835, 'learning_rate': 1.9288135593220343e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [3:38:36<2:17:05,  3.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [3:38:40<2:15:06,  3.56s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.040070269256830215, 'learning_rate': 1.9279661016949154e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [3:38:40<2:15:06,  3.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [3:38:43<2:17:47,  3.64s/it]                                                       {'loss': 0.2163, 'grad_norm': 7.238338470458984, 'learning_rate': 1.9271186440677965e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [3:38:43<2:17:47,  3.64s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [3:38:47<2:15:20,  3.57s/it]                                                       {'loss': 0.0, 'grad_norm': 0.004480578470975161, 'learning_rate': 1.926271186440678e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [3:38:47<2:15:20,  3.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [3:38:50<2:13:43,  3.53s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.5824152231216431, 'learning_rate': 1.9254237288135595e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [3:38:50<2:13:43,  3.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [3:38:54<2:11:35,  3.48s/it]                                                       {'loss': 0.1729, 'grad_norm': 8.882645606994629, 'learning_rate': 1.9245762711864406e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [3:38:54<2:11:35,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [3:38:58<2:16:15,  3.60s/it]                                                       {'loss': 0.0389, 'grad_norm': 2.8998870849609375, 'learning_rate': 1.923728813559322e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [3:38:58<2:16:15,  3.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [3:39:01<2:13:55,  3.54s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.13206683099269867, 'learning_rate': 1.9228813559322035e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [3:39:01<2:13:55,  3.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [3:39:04<2:13:10,  3.52s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.918323040008545, 'learning_rate': 1.9220338983050847e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [3:39:04<2:13:10,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [3:39:08<2:16:53,  3.62s/it]                                                       {'loss': 0.0, 'grad_norm': 0.005583913531154394, 'learning_rate': 1.921186440677966e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [3:39:08<2:16:53,  3.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [3:39:12<2:15:16,  3.58s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.7144575119018555, 'learning_rate': 1.9203389830508476e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [3:39:12<2:15:16,  3.58s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [3:39:15<2:14:10,  3.55s/it]                                                       {'loss': 0.1614, 'grad_norm': 5.568973064422607, 'learning_rate': 1.919491525423729e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [3:39:15<2:14:10,  3.55s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [3:39:19<2:12:50,  3.52s/it]                                                       {'loss': 0.0447, 'grad_norm': 1.2644611597061157, 'learning_rate': 1.9186440677966102e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [3:39:19<2:12:50,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [3:39:22<2:11:42,  3.49s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.869197130203247, 'learning_rate': 1.9177966101694917e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [3:39:22<2:11:42,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [3:39:26<2:11:23,  3.49s/it]                                                       {'loss': 0.0547, 'grad_norm': 3.5030272006988525, 'learning_rate': 1.916949152542373e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [3:39:26<2:11:23,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [3:39:29<2:10:09,  3.45s/it]                                                       {'loss': 0.0913, 'grad_norm': 6.700500011444092, 'learning_rate': 1.9161016949152543e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [3:39:29<2:10:09,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [3:39:32<2:08:17,  3.41s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.020701318979263306, 'learning_rate': 1.9152542372881357e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [3:39:32<2:08:17,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [3:39:36<2:08:48,  3.42s/it]                                                       {'loss': 0.1477, 'grad_norm': 6.0846710205078125, 'learning_rate': 1.9144067796610172e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [3:39:36<2:08:48,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [3:39:39<2:08:08,  3.41s/it]                                                       {'loss': 0.164, 'grad_norm': 8.063311576843262, 'learning_rate': 1.9135593220338983e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [3:39:39<2:08:08,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [3:39:42<2:07:24,  3.39s/it]                                                       {'loss': 0.0498, 'grad_norm': 4.653221607208252, 'learning_rate': 1.9127118644067798e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [3:39:42<2:07:24,  3.39s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [3:39:46<2:06:58,  3.38s/it]                                                       {'loss': 0.0168, 'grad_norm': 3.2936065196990967, 'learning_rate': 1.9118644067796613e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [3:39:46<2:06:58,  3.38s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [3:39:49<2:07:20,  3.39s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.0641854852437973, 'learning_rate': 1.9110169491525427e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [3:39:49<2:07:20,  3.39s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [3:39:53<2:12:58,  3.54s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.2488867044448853, 'learning_rate': 1.910169491525424e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [3:39:53<2:12:58,  3.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [3:39:56<2:11:08,  3.49s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4164430499076843, 'learning_rate': 1.909322033898305e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [3:39:56<2:11:08,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [3:40:00<2:10:34,  3.48s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.2225788831710815, 'learning_rate': 1.9084745762711864e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [3:40:00<2:10:34,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [3:40:03<2:08:36,  3.43s/it]                                                       {'loss': 0.0305, 'grad_norm': 3.7884719371795654, 'learning_rate': 1.907627118644068e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [3:40:03<2:08:36,  3.43s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [3:40:07<2:08:54,  3.44s/it]                                                       {'loss': 0.0372, 'grad_norm': 6.032003879547119, 'learning_rate': 1.906779661016949e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [3:40:07<2:08:54,  3.44s/it][2025-10-20 03:17:11,988] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [3:40:12<2:32:56,  4.08s/it]                                                       {'loss': 0.0157, 'grad_norm': 2.1913323402404785, 'learning_rate': 1.9059322033898305e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [3:40:12<2:32:56,  4.08s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [3:40:16<2:25:25,  3.88s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.411112308502197, 'learning_rate': 1.905084745762712e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [3:40:16<2:25:25,  3.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [3:40:19<2:19:00,  3.71s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.20756970345973969, 'learning_rate': 1.904237288135593e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [3:40:19<2:19:00,  3.71s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [3:40:22<2:15:06,  3.61s/it]                                                       {'loss': 0.0291, 'grad_norm': 3.7108817100524902, 'learning_rate': 1.9033898305084746e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [3:40:22<2:15:06,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [3:40:26<2:13:38,  3.57s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.140501618385315, 'learning_rate': 1.902542372881356e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [3:40:26<2:13:38,  3.57s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [3:40:29<2:10:58,  3.50s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.260546922683716, 'learning_rate': 1.9016949152542375e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [3:40:29<2:10:58,  3.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [3:40:33<2:12:25,  3.54s/it]                                                       {'loss': 0.0666, 'grad_norm': 5.07521915435791, 'learning_rate': 1.9008474576271186e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [3:40:33<2:12:25,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [3:40:36<2:11:04,  3.51s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.4306104183197021, 'learning_rate': 1.9e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [3:40:36<2:11:04,  3.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [3:40:40<2:11:24,  3.52s/it]                                                       {'loss': 0.0147, 'grad_norm': 0.9660908579826355, 'learning_rate': 1.8991525423728816e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [3:40:40<2:11:24,  3.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [3:40:43<2:09:31,  3.47s/it]                                                       {'loss': 0.2663, 'grad_norm': 8.991307258605957, 'learning_rate': 1.8983050847457627e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [3:40:43<2:09:31,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [3:40:47<2:09:02,  3.46s/it]                                                       {'loss': 0.0707, 'grad_norm': 4.538769721984863, 'learning_rate': 1.897457627118644e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [3:40:47<2:09:02,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [3:40:50<2:10:21,  3.49s/it]                                                       {'loss': 0.0688, 'grad_norm': 4.09677791595459, 'learning_rate': 1.8966101694915256e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [3:40:50<2:10:21,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [3:40:54<2:08:58,  3.46s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.591292142868042, 'learning_rate': 1.895762711864407e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [3:40:54<2:08:58,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [3:40:57<2:08:00,  3.44s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.6028062105178833, 'learning_rate': 1.8949152542372882e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [3:40:57<2:08:00,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [3:41:00<2:07:41,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.050538692623376846, 'learning_rate': 1.8940677966101697e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [3:41:00<2:07:41,  3.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [3:41:04<2:09:27,  3.48s/it]                                                       {'loss': 0.0595, 'grad_norm': 5.543929576873779, 'learning_rate': 1.893220338983051e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [3:41:04<2:09:27,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [3:41:07<2:08:22,  3.45s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.7951880693435669, 'learning_rate': 1.8923728813559323e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [3:41:07<2:08:22,  3.45s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [3:41:11<2:07:53,  3.44s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.9881710410118103, 'learning_rate': 1.8915254237288134e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [3:41:11<2:07:53,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [3:41:14<2:07:06,  3.42s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.22154080867767334, 'learning_rate': 1.890677966101695e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [3:41:14<2:07:06,  3.42s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [3:41:18<2:07:17,  3.42s/it]                                                       {'loss': 0.0864, 'grad_norm': 6.254462242126465, 'learning_rate': 1.8898305084745764e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [3:41:18<2:07:17,  3.42s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [3:41:21<2:09:11,  3.48s/it]                                                       {'loss': 0.0558, 'grad_norm': 6.6187920570373535, 'learning_rate': 1.8889830508474575e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [3:41:21<2:09:11,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [3:41:25<2:15:55,  3.66s/it]                                                       {'loss': 0.0449, 'grad_norm': 3.380100727081299, 'learning_rate': 1.888135593220339e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [3:41:25<2:15:55,  3.66s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [3:41:29<2:14:15,  3.62s/it]                                                       {'loss': 0.0358, 'grad_norm': 1.4496946334838867, 'learning_rate': 1.8872881355932204e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [3:41:29<2:14:15,  3.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [3:41:33<2:22:10,  3.83s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.8585902452468872, 'learning_rate': 1.886440677966102e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [3:41:33<2:22:10,  3.83s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [3:41:37<2:18:18,  3.73s/it]                                                       {'loss': 0.0463, 'grad_norm': 5.9433698654174805, 'learning_rate': 1.885593220338983e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [3:41:37<2:18:18,  3.73s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [3:41:40<2:15:29,  3.66s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.115428924560547, 'learning_rate': 1.8847457627118645e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [3:41:40<2:15:29,  3.66s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [3:41:43<2:11:53,  3.56s/it]                                                       {'loss': 0.0152, 'grad_norm': 1.8005664348602295, 'learning_rate': 1.883898305084746e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [3:41:43<2:11:53,  3.56s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [3:41:47<2:09:12,  3.49s/it]                                                       {'loss': 0.0779, 'grad_norm': 4.8938469886779785, 'learning_rate': 1.883050847457627e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [3:41:47<2:09:12,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [3:41:50<2:07:57,  3.46s/it]                                                       {'loss': 0.0625, 'grad_norm': 4.532576084136963, 'learning_rate': 1.8822033898305085e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [3:41:50<2:07:57,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [3:41:53<2:06:49,  3.43s/it]                                                       {'loss': 0.0496, 'grad_norm': 4.855991363525391, 'learning_rate': 1.88135593220339e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [3:41:53<2:06:49,  3.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [3:41:57<2:08:20,  3.47s/it]                                                       {'loss': 0.0505, 'grad_norm': 3.422427177429199, 'learning_rate': 1.8805084745762715e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [3:41:57<2:08:20,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [3:42:00<2:07:04,  3.44s/it]                                                       {'loss': 0.0497, 'grad_norm': 5.84404993057251, 'learning_rate': 1.8796610169491526e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [3:42:00<2:07:04,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [3:42:04<2:06:56,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16545993089675903, 'learning_rate': 1.878813559322034e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [3:42:04<2:06:56,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [3:42:07<2:05:32,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015735428780317307, 'learning_rate': 1.8779661016949155e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [3:42:07<2:05:32,  3.40s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [3:42:11<2:10:17,  3.53s/it]                                                       {'loss': 0.0568, 'grad_norm': 6.019310474395752, 'learning_rate': 1.8771186440677967e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [3:42:11<2:10:17,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [3:42:14<2:10:30,  3.54s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.21181292831897736, 'learning_rate': 1.876271186440678e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [3:42:14<2:10:30,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [3:42:18<2:14:06,  3.64s/it]                                                       {'loss': 0.1038, 'grad_norm': 8.126327514648438, 'learning_rate': 1.8754237288135596e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [3:42:18<2:14:06,  3.64s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [3:42:22<2:13:45,  3.63s/it]                                                       {'loss': 0.1655, 'grad_norm': 6.746260643005371, 'learning_rate': 1.8745762711864407e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [3:42:22<2:13:45,  3.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [3:42:26<2:13:14,  3.62s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.6358784437179565, 'learning_rate': 1.873728813559322e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [3:42:26<2:13:14,  3.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [3:42:29<2:13:28,  3.62s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011538046412169933, 'learning_rate': 1.8728813559322033e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [3:42:29<2:13:28,  3.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [3:42:33<2:19:09,  3.78s/it]                                                       {'loss': 0.1513, 'grad_norm': 8.415022850036621, 'learning_rate': 1.8720338983050848e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [3:42:33<2:19:09,  3.78s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [3:42:37<2:19:45,  3.80s/it]                                                       {'loss': 0.0912, 'grad_norm': 4.1584320068359375, 'learning_rate': 1.8711864406779663e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [3:42:37<2:19:45,  3.80s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [3:42:41<2:15:12,  3.68s/it]                                                       {'loss': 0.1983, 'grad_norm': 9.197196960449219, 'learning_rate': 1.8703389830508474e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [3:42:41<2:15:12,  3.68s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [3:42:44<2:11:54,  3.59s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.299547553062439, 'learning_rate': 1.869491525423729e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [3:42:44<2:11:54,  3.59s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [3:42:47<2:08:53,  3.51s/it]                                                       {'loss': 0.0625, 'grad_norm': 4.514853477478027, 'learning_rate': 1.8686440677966103e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [3:42:47<2:08:53,  3.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [3:42:51<2:12:19,  3.60s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.2404398918151855, 'learning_rate': 1.8677966101694915e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [3:42:51<2:12:19,  3.60s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [3:42:54<2:09:50,  3.54s/it]                                                       {'loss': 0.003, 'grad_norm': 0.461772084236145, 'learning_rate': 1.866949152542373e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [3:42:54<2:09:50,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [3:42:58<2:08:25,  3.50s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.9699481129646301, 'learning_rate': 1.8661016949152544e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [3:42:58<2:08:25,  3.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [3:43:01<2:06:56,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.016957048326730728, 'learning_rate': 1.865254237288136e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [3:43:01<2:06:56,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [3:43:05<2:05:42,  3.43s/it]                                                       {'loss': 0.1748, 'grad_norm': 7.76522970199585, 'learning_rate': 1.864406779661017e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [3:43:05<2:05:42,  3.43s/it][2025-10-20 03:20:09,927] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [3:43:10<2:29:36,  4.08s/it]                                                       {'loss': 0.0232, 'grad_norm': 2.174527645111084, 'learning_rate': 1.8635593220338985e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [3:43:10<2:29:36,  4.08s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [3:43:14<2:22:04,  3.88s/it]                                                       {'loss': 0.1242, 'grad_norm': 7.815098762512207, 'learning_rate': 1.86271186440678e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [3:43:14<2:22:04,  3.88s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [3:43:17<2:17:22,  3.75s/it]                                                       {'loss': 0.006, 'grad_norm': 1.0051281452178955, 'learning_rate': 1.861864406779661e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [3:43:17<2:17:22,  3.75s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [3:43:20<2:12:58,  3.63s/it]                                                       {'loss': 0.0417, 'grad_norm': 2.935460090637207, 'learning_rate': 1.8610169491525425e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [3:43:20<2:12:58,  3.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [3:43:24<2:09:51,  3.55s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.8572899103164673, 'learning_rate': 1.860169491525424e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [3:43:24<2:09:51,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [3:43:27<2:09:03,  3.53s/it]                                                       {'loss': 0.0907, 'grad_norm': 5.644728660583496, 'learning_rate': 1.859322033898305e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [3:43:27<2:09:03,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [3:43:31<2:06:22,  3.46s/it]                                                       {'loss': 0.2086, 'grad_norm': 6.90966272354126, 'learning_rate': 1.8584745762711866e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [3:43:31<2:06:22,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [3:43:34<2:05:39,  3.44s/it]                                                       {'loss': 0.0, 'grad_norm': 0.002824106253683567, 'learning_rate': 1.857627118644068e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [3:43:34<2:05:39,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [3:43:38<2:12:16,  3.62s/it]                                                       {'loss': 0.0336, 'grad_norm': 6.99648904800415, 'learning_rate': 1.8567796610169492e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [3:43:38<2:12:16,  3.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [3:43:41<2:09:38,  3.55s/it]                                                       {'loss': 0.0647, 'grad_norm': 6.111966133117676, 'learning_rate': 1.8559322033898307e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [3:43:41<2:09:38,  3.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [3:43:45<2:08:10,  3.51s/it]                                                       {'loss': 0.0673, 'grad_norm': 6.2836503982543945, 'learning_rate': 1.8550847457627118e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [3:43:45<2:08:10,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [3:43:48<2:08:30,  3.52s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08502930402755737, 'learning_rate': 1.8542372881355932e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [3:43:48<2:08:30,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [3:43:52<2:10:28,  3.58s/it]                                                       {'loss': 0.0576, 'grad_norm': 5.27419900894165, 'learning_rate': 1.8533898305084747e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [3:43:52<2:10:28,  3.58s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [3:43:56<2:09:04,  3.54s/it]                                                       {'loss': 0.0229, 'grad_norm': 2.867021083831787, 'learning_rate': 1.852542372881356e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [3:43:56<2:09:04,  3.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [3:43:59<2:07:39,  3.51s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.9361331462860107, 'learning_rate': 1.8516949152542373e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [3:43:59<2:07:39,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [3:44:02<2:06:26,  3.47s/it]                                                       {'loss': 0.0604, 'grad_norm': 5.148462295532227, 'learning_rate': 1.8508474576271188e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [3:44:02<2:06:26,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [3:44:06<2:06:56,  3.49s/it]                                                       {'loss': 0.134, 'grad_norm': 7.583280086517334, 'learning_rate': 1.85e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [3:44:06<2:06:56,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [3:44:09<2:05:39,  3.46s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.228991985321045, 'learning_rate': 1.8491525423728814e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [3:44:09<2:05:39,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [3:44:13<2:05:46,  3.46s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.5747677087783813, 'learning_rate': 1.848305084745763e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [3:44:13<2:05:46,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [3:44:16<2:04:20,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2649288773536682, 'learning_rate': 1.8474576271186443e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [3:44:16<2:04:20,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [3:44:19<2:03:54,  3.41s/it]                                                       {'loss': 0.0496, 'grad_norm': 1.4966769218444824, 'learning_rate': 1.8466101694915254e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [3:44:19<2:03:54,  3.41s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [3:44:23<2:04:31,  3.43s/it]                                                       {'loss': 0.1435, 'grad_norm': 4.5313720703125, 'learning_rate': 1.845762711864407e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [3:44:23<2:04:31,  3.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [3:44:27<2:07:36,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.15848128497600555, 'learning_rate': 1.8449152542372884e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [3:44:27<2:07:36,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [3:44:30<2:06:39,  3.49s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.04666145518422127, 'learning_rate': 1.8440677966101695e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [3:44:30<2:06:39,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [3:44:33<2:04:49,  3.44s/it]                                                       {'loss': 0.0923, 'grad_norm': 4.425552845001221, 'learning_rate': 1.843220338983051e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [3:44:33<2:04:49,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [3:44:37<2:03:45,  3.42s/it]                                                       {'loss': 0.0962, 'grad_norm': 5.57220983505249, 'learning_rate': 1.8423728813559324e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [3:44:37<2:03:45,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [3:44:40<2:03:32,  3.41s/it]                                                       {'loss': 0.1204, 'grad_norm': 7.460832595825195, 'learning_rate': 1.841525423728814e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [3:44:40<2:03:32,  3.41s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [3:44:44<2:03:12,  3.40s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.7350456118583679, 'learning_rate': 1.840677966101695e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [3:44:44<2:03:12,  3.40s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [3:44:47<2:02:58,  3.40s/it]                                                       {'loss': 0.0646, 'grad_norm': 4.125298500061035, 'learning_rate': 1.8398305084745765e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [3:44:47<2:02:58,  3.40s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [3:44:50<2:03:23,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.17941774427890778, 'learning_rate': 1.8389830508474576e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [3:44:50<2:03:23,  3.41s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [3:44:54<2:04:08,  3.43s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5953121185302734, 'learning_rate': 1.838135593220339e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [3:44:54<2:04:08,  3.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [3:44:57<2:04:53,  3.46s/it]                                                       {'loss': 0.0852, 'grad_norm': 11.55320930480957, 'learning_rate': 1.8372881355932202e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [3:44:57<2:04:53,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [3:45:01<2:08:13,  3.55s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.45949608087539673, 'learning_rate': 1.8364406779661017e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [3:45:01<2:08:13,  3.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [3:45:04<2:05:47,  3.48s/it]                                                       {'loss': 0.1027, 'grad_norm': 8.462997436523438, 'learning_rate': 1.835593220338983e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [3:45:04<2:05:47,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [3:45:08<2:09:39,  3.59s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2926832437515259, 'learning_rate': 1.8347457627118643e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [3:45:08<2:09:39,  3.59s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [3:45:12<2:06:55,  3.52s/it]                                                       {'loss': 0.021, 'grad_norm': 3.2431232929229736, 'learning_rate': 1.8338983050847458e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [3:45:12<2:06:55,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [3:45:15<2:04:46,  3.46s/it]                                                       {'loss': 0.0248, 'grad_norm': 2.634409189224243, 'learning_rate': 1.8330508474576272e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [3:45:15<2:04:46,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [3:45:18<2:03:50,  3.44s/it]                                                       {'loss': 0.0347, 'grad_norm': 3.506808042526245, 'learning_rate': 1.8322033898305087e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [3:45:18<2:03:50,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [3:45:22<2:06:57,  3.52s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.13502848148345947, 'learning_rate': 1.8313559322033898e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [3:45:22<2:06:57,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [3:45:25<2:04:50,  3.47s/it]                                                       {'loss': 0.0578, 'grad_norm': 3.9727230072021484, 'learning_rate': 1.8305084745762713e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [3:45:25<2:04:50,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [3:45:29<2:10:09,  3.62s/it]                                                       {'loss': 0.0448, 'grad_norm': 3.9921743869781494, 'learning_rate': 1.8296610169491528e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [3:45:29<2:10:09,  3.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [3:45:33<2:09:23,  3.60s/it]                                                       {'loss': 0.2308, 'grad_norm': 10.845123291015625, 'learning_rate': 1.828813559322034e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [3:45:33<2:09:23,  3.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [3:45:36<2:06:40,  3.52s/it]                                                       {'loss': 0.0203, 'grad_norm': 3.217200517654419, 'learning_rate': 1.8279661016949153e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [3:45:36<2:06:40,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [3:45:40<2:06:55,  3.53s/it]                                                       {'loss': 0.2413, 'grad_norm': 8.914782524108887, 'learning_rate': 1.8271186440677968e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [3:45:40<2:06:55,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [3:45:43<2:07:47,  3.56s/it]                                                       {'loss': 0.0156, 'grad_norm': 1.5768845081329346, 'learning_rate': 1.8262711864406783e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [3:45:43<2:07:47,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [3:45:47<2:10:52,  3.65s/it]                                                       {'loss': 0.2511, 'grad_norm': 10.359492301940918, 'learning_rate': 1.8254237288135594e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [3:45:47<2:10:52,  3.65s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [3:45:51<2:07:50,  3.56s/it]                                                       {'loss': 0.1519, 'grad_norm': 7.468224048614502, 'learning_rate': 1.824576271186441e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [3:45:51<2:07:50,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [3:45:54<2:05:04,  3.49s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.783843994140625, 'learning_rate': 1.8237288135593223e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [3:45:54<2:05:04,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [3:45:57<2:03:15,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06886833906173706, 'learning_rate': 1.8228813559322035e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [3:45:57<2:03:15,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [3:46:01<2:04:03,  3.46s/it]                                                       {'loss': 0.1689, 'grad_norm': 4.701437473297119, 'learning_rate': 1.8220338983050846e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [3:46:01<2:04:03,  3.46s/it][2025-10-20 03:23:06,157] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [3:46:07<2:28:11,  4.14s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.7066996097564697, 'learning_rate': 1.821186440677966e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [3:46:07<2:28:11,  4.14s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [3:46:10<2:19:56,  3.91s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.8011040091514587, 'learning_rate': 1.8203389830508475e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [3:46:10<2:19:56,  3.91s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [3:46:13<2:14:40,  3.76s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.62276291847229, 'learning_rate': 1.8194915254237287e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [3:46:13<2:14:40,  3.76s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [3:46:17<2:11:03,  3.66s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.4256924092769623, 'learning_rate': 1.81864406779661e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [3:46:17<2:11:03,  3.66s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [3:46:20<2:10:17,  3.64s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.12454181909561157, 'learning_rate': 1.8177966101694916e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [3:46:20<2:10:17,  3.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [3:46:24<2:08:21,  3.59s/it]                                                       {'loss': 0.2515, 'grad_norm': 6.903720855712891, 'learning_rate': 1.816949152542373e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [3:46:24<2:08:21,  3.59s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [3:46:27<2:06:03,  3.53s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.14520792663097382, 'learning_rate': 1.8161016949152542e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [3:46:27<2:06:03,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [3:46:31<2:04:25,  3.49s/it]                                                       {'loss': 0.0761, 'grad_norm': 4.7533159255981445, 'learning_rate': 1.8152542372881357e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [3:46:31<2:04:25,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [3:46:34<2:04:01,  3.48s/it]                                                       {'loss': 0.0744, 'grad_norm': 3.5298869609832764, 'learning_rate': 1.814406779661017e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [3:46:34<2:04:01,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [3:46:37<2:02:36,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05322062596678734, 'learning_rate': 1.8135593220338983e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [3:46:37<2:02:36,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [3:46:41<2:02:51,  3.45s/it]                                                       {'loss': 0.1768, 'grad_norm': 8.50028133392334, 'learning_rate': 1.8127118644067797e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [3:46:41<2:02:51,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [3:46:44<2:02:32,  3.44s/it]                                                       {'loss': 0.239, 'grad_norm': 7.402455806732178, 'learning_rate': 1.8118644067796612e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [3:46:44<2:02:32,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [3:46:48<2:03:59,  3.48s/it]                                                       {'loss': 0.105, 'grad_norm': 6.402743339538574, 'learning_rate': 1.8110169491525427e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [3:46:48<2:03:59,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [3:46:51<2:04:30,  3.50s/it]                                                       {'loss': 0.1372, 'grad_norm': 8.552544593811035, 'learning_rate': 1.8101694915254238e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [3:46:51<2:04:30,  3.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [3:46:55<2:03:12,  3.46s/it]                                                       {'loss': 0.1305, 'grad_norm': 7.635507106781006, 'learning_rate': 1.8093220338983053e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [3:46:55<2:03:12,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [3:46:58<2:03:32,  3.47s/it]                                                       {'loss': 0.0928, 'grad_norm': 5.039848804473877, 'learning_rate': 1.8084745762711867e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [3:46:58<2:03:32,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [3:47:03<2:20:32,  3.95s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.17033930122852325, 'learning_rate': 1.807627118644068e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [3:47:03<2:20:32,  3.95s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [3:47:07<2:14:53,  3.80s/it]                                                       {'loss': 0.002, 'grad_norm': 0.43530988693237305, 'learning_rate': 1.8067796610169493e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [3:47:07<2:14:53,  3.80s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [3:47:10<2:12:04,  3.72s/it]                                                       {'loss': 0.0486, 'grad_norm': 4.619927883148193, 'learning_rate': 1.8059322033898308e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [3:47:10<2:12:04,  3.72s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [3:47:14<2:08:44,  3.63s/it]                                                       {'loss': 0.0334, 'grad_norm': 3.7561161518096924, 'learning_rate': 1.805084745762712e-05, 'epoch': 0.65}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [3:47:14<2:08:44,  3.63s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [3:47:17<2:06:15,  3.56s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.6192423105239868, 'learning_rate': 1.804237288135593e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [3:47:17<2:06:15,  3.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [3:47:21<2:06:21,  3.56s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.493922621011734, 'learning_rate': 1.8033898305084745e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [3:47:21<2:06:21,  3.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [3:47:24<2:04:35,  3.51s/it]                                                       {'loss': 0.0381, 'grad_norm': 3.053534746170044, 'learning_rate': 1.802542372881356e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [3:47:24<2:04:35,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [3:47:27<2:02:06,  3.45s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6128378510475159, 'learning_rate': 1.8016949152542374e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [3:47:27<2:02:06,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [3:47:31<2:01:07,  3.42s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.38567453622817993, 'learning_rate': 1.8008474576271186e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [3:47:31<2:01:07,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [3:47:34<2:00:58,  3.42s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.9098241925239563, 'learning_rate': 1.8e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [3:47:34<2:00:58,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [3:47:38<2:00:44,  3.41s/it]                                                       {'loss': 0.0984, 'grad_norm': 6.441413402557373, 'learning_rate': 1.7991525423728815e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [3:47:38<2:00:44,  3.41s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [3:47:41<2:06:00,  3.56s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.6580278873443604, 'learning_rate': 1.7983050847457626e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [3:47:42<2:06:00,  3.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [3:47:45<2:04:04,  3.51s/it]                                                       {'loss': 0.0286, 'grad_norm': 2.708588123321533, 'learning_rate': 1.797457627118644e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [3:47:45<2:04:04,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [3:47:48<2:02:34,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.18155762553215027, 'learning_rate': 1.7966101694915256e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [3:47:48<2:02:34,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [3:47:52<2:03:06,  3.49s/it]                                                       {'loss': 0.26, 'grad_norm': 6.6814775466918945, 'learning_rate': 1.7957627118644067e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [3:47:52<2:03:06,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [3:47:55<2:01:20,  3.44s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.2927977740764618, 'learning_rate': 1.7949152542372882e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [3:47:55<2:01:20,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [3:47:59<2:03:08,  3.49s/it]                                                       {'loss': 0.0368, 'grad_norm': 3.168564796447754, 'learning_rate': 1.7940677966101696e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [3:47:59<2:03:08,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [3:48:02<2:02:02,  3.46s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.310805082321167, 'learning_rate': 1.793220338983051e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [3:48:02<2:02:02,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [3:48:06<2:03:16,  3.50s/it]                                                       {'loss': 0.0432, 'grad_norm': 2.2479939460754395, 'learning_rate': 1.7923728813559322e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [3:48:06<2:03:16,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [3:48:09<2:01:28,  3.45s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14729858934879303, 'learning_rate': 1.7915254237288137e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [3:48:09<2:01:28,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [3:48:13<2:03:06,  3.50s/it]                                                       {'loss': 0.2852, 'grad_norm': 14.001665115356445, 'learning_rate': 1.7906779661016952e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [3:48:13<2:03:06,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [3:48:17<2:07:28,  3.62s/it]                                                       {'loss': 0.1753, 'grad_norm': 9.793720245361328, 'learning_rate': 1.7898305084745763e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [3:48:17<2:07:28,  3.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [3:48:20<2:04:56,  3.55s/it]                                                       {'loss': 0.0486, 'grad_norm': 5.396374225616455, 'learning_rate': 1.7889830508474578e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [3:48:20<2:04:56,  3.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [3:48:23<2:03:16,  3.51s/it]                                                       {'loss': 0.004, 'grad_norm': 0.9487504363059998, 'learning_rate': 1.7881355932203392e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [3:48:23<2:03:16,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [3:48:27<2:02:17,  3.48s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.5100129246711731, 'learning_rate': 1.7872881355932207e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [3:48:27<2:02:17,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [3:48:30<2:01:15,  3.45s/it]                                                       {'loss': 0.1016, 'grad_norm': 6.382513999938965, 'learning_rate': 1.7864406779661015e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [3:48:30<2:01:15,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [3:48:34<2:04:48,  3.55s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.664823055267334, 'learning_rate': 1.785593220338983e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [3:48:34<2:04:48,  3.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [3:48:37<2:03:19,  3.51s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10009749978780746, 'learning_rate': 1.7847457627118644e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [3:48:37<2:03:19,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [3:48:41<2:01:38,  3.47s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.192075490951538, 'learning_rate': 1.783898305084746e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [3:48:41<2:01:38,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [3:48:44<2:01:23,  3.46s/it]                                                       {'loss': 0.0154, 'grad_norm': 3.6770005226135254, 'learning_rate': 1.783050847457627e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [3:48:44<2:01:23,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [3:48:47<1:59:45,  3.42s/it]                                                       {'loss': 0.0103, 'grad_norm': 2.227372884750366, 'learning_rate': 1.7822033898305085e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [3:48:47<1:59:45,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [3:48:51<1:59:32,  3.41s/it]                                                       {'loss': 0.015, 'grad_norm': 2.0103039741516113, 'learning_rate': 1.78135593220339e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [3:48:51<1:59:32,  3.41s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [3:48:54<1:58:50,  3.39s/it]                                                       {'loss': 0.2425, 'grad_norm': 8.438222885131836, 'learning_rate': 1.780508474576271e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [3:48:54<1:58:50,  3.39s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [3:48:58<2:00:45,  3.45s/it]                                                       {'loss': 0.0407, 'grad_norm': 3.733863592147827, 'learning_rate': 1.7796610169491526e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [3:48:58<2:00:45,  3.45s/it][2025-10-20 03:26:03,130] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [3:49:04<2:25:59,  4.17s/it]                                                       {'loss': 0.4237, 'grad_norm': 10.721176147460938, 'learning_rate': 1.778813559322034e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [3:49:04<2:25:59,  4.17s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [3:49:07<2:17:32,  3.93s/it]                                                       {'loss': 0.0177, 'grad_norm': 4.084013938903809, 'learning_rate': 1.7779661016949155e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [3:49:07<2:17:32,  3.93s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [3:49:10<2:11:59,  3.78s/it]                                                       {'loss': 0.1634, 'grad_norm': 6.676524639129639, 'learning_rate': 1.7771186440677966e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [3:49:10<2:11:59,  3.78s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [3:49:14<2:08:10,  3.67s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09301017224788666, 'learning_rate': 1.776271186440678e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [3:49:14<2:08:10,  3.67s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [3:49:17<2:04:22,  3.56s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.739371120929718, 'learning_rate': 1.7754237288135596e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [3:49:17<2:04:22,  3.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [3:49:21<2:03:15,  3.53s/it]                                                       {'loss': 0.0335, 'grad_norm': 2.300978660583496, 'learning_rate': 1.7745762711864407e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [3:49:21<2:03:15,  3.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [3:49:24<2:02:12,  3.50s/it]                                                       {'loss': 0.1626, 'grad_norm': 7.216850757598877, 'learning_rate': 1.773728813559322e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [3:49:24<2:02:12,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [3:49:27<2:00:58,  3.47s/it]                                                       {'loss': 0.0958, 'grad_norm': 5.882802963256836, 'learning_rate': 1.7728813559322036e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [3:49:27<2:00:58,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [3:49:31<2:02:39,  3.52s/it]                                                       {'loss': 0.0411, 'grad_norm': 4.135713577270508, 'learning_rate': 1.772033898305085e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [3:49:31<2:02:39,  3.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [3:49:34<2:00:58,  3.47s/it]                                                       {'loss': 0.0187, 'grad_norm': 2.3881587982177734, 'learning_rate': 1.7711864406779662e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [3:49:34<2:00:58,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [3:49:38<2:00:11,  3.45s/it]                                                       {'loss': 0.0654, 'grad_norm': 3.908695936203003, 'learning_rate': 1.7703389830508477e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [3:49:38<2:00:11,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [3:49:41<2:00:47,  3.47s/it]                                                       {'loss': 0.0815, 'grad_norm': 7.0235395431518555, 'learning_rate': 1.769491525423729e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [3:49:41<2:00:47,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [3:49:45<1:59:48,  3.44s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.1855530738830566, 'learning_rate': 1.7686440677966103e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [3:49:45<1:59:48,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [3:49:48<1:58:21,  3.40s/it]                                                       {'loss': 0.0226, 'grad_norm': 1.8192049264907837, 'learning_rate': 1.7677966101694914e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [3:49:48<1:58:21,  3.40s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [3:49:52<2:02:30,  3.53s/it]                                                       {'loss': 0.081, 'grad_norm': 6.4162983894348145, 'learning_rate': 1.766949152542373e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [3:49:52<2:02:30,  3.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [3:49:55<2:01:31,  3.50s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.23202429711818695, 'learning_rate': 1.7661016949152543e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [3:49:55<2:01:31,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [3:49:59<2:00:39,  3.48s/it]                                                       {'loss': 0.001, 'grad_norm': 0.15184259414672852, 'learning_rate': 1.7652542372881355e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [3:49:59<2:00:39,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [3:50:02<1:59:50,  3.45s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.9087421894073486, 'learning_rate': 1.764406779661017e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [3:50:02<1:59:50,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [3:50:06<1:59:20,  3.44s/it]                                                       {'loss': 0.1649, 'grad_norm': 5.144345760345459, 'learning_rate': 1.7635593220338984e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [3:50:06<1:59:20,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [3:50:09<1:58:51,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011658765375614166, 'learning_rate': 1.76271186440678e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [3:50:09<1:58:51,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [3:50:12<1:58:50,  3.43s/it]                                                       {'loss': 0.0484, 'grad_norm': 1.746476411819458, 'learning_rate': 1.761864406779661e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [3:50:12<1:58:50,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [3:50:16<1:59:15,  3.44s/it]                                                       {'loss': 0.0503, 'grad_norm': 2.348363161087036, 'learning_rate': 1.7610169491525425e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [3:50:16<1:59:15,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [3:50:19<2:00:00,  3.47s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.4102761149406433, 'learning_rate': 1.760169491525424e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [3:50:19<2:00:00,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [3:50:23<1:58:28,  3.42s/it]                                                       {'loss': 0.0455, 'grad_norm': 3.293497323989868, 'learning_rate': 1.759322033898305e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [3:50:23<1:58:28,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [3:50:26<2:01:50,  3.52s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.12354882061481476, 'learning_rate': 1.7584745762711865e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [3:50:26<2:01:50,  3.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [3:50:30<2:03:54,  3.58s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011805713176727295, 'learning_rate': 1.757627118644068e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [3:50:30<2:03:54,  3.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [3:50:34<2:01:47,  3.53s/it]                                                       {'loss': 0.0623, 'grad_norm': 6.56973934173584, 'learning_rate': 1.7567796610169495e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [3:50:34<2:01:47,  3.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [3:50:37<2:00:29,  3.49s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2456352561712265, 'learning_rate': 1.7559322033898306e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [3:50:37<2:00:29,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [3:50:41<2:02:14,  3.54s/it]                                                       {'loss': 0.1227, 'grad_norm': 5.187266826629639, 'learning_rate': 1.755084745762712e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [3:50:41<2:02:14,  3.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [3:50:44<1:59:56,  3.48s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.43953755497932434, 'learning_rate': 1.7542372881355935e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [3:50:44<1:59:56,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [3:50:47<1:59:10,  3.46s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.056509584188461304, 'learning_rate': 1.7533898305084747e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [3:50:47<1:59:10,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [3:50:51<2:02:54,  3.57s/it]                                                       {'loss': 0.0621, 'grad_norm': 5.089077949523926, 'learning_rate': 1.752542372881356e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [3:50:51<2:02:54,  3.57s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [3:50:55<2:01:09,  3.52s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.28691574931144714, 'learning_rate': 1.7516949152542373e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [3:50:55<2:01:09,  3.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [3:50:58<1:59:48,  3.48s/it]                                                       {'loss': 0.2429, 'grad_norm': 10.52043628692627, 'learning_rate': 1.7508474576271187e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [3:50:58<1:59:48,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [3:51:01<1:58:52,  3.45s/it]                                                       {'loss': 0.0471, 'grad_norm': 4.958565711975098, 'learning_rate': 1.75e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [3:51:01<1:58:52,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [3:51:05<1:58:17,  3.44s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.379711389541626, 'learning_rate': 1.7491525423728813e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [3:51:05<1:58:17,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [3:51:08<1:58:09,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.052120644599199295, 'learning_rate': 1.7483050847457628e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [3:51:08<1:58:09,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [3:51:12<1:57:07,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.008499308489263058, 'learning_rate': 1.7474576271186442e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [3:51:12<1:57:07,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [3:51:15<1:57:13,  3.41s/it]                                                       {'loss': 0.0724, 'grad_norm': 5.678421974182129, 'learning_rate': 1.7466101694915254e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [3:51:15<1:57:13,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [3:51:18<1:56:39,  3.40s/it]                                                       {'loss': 0.1188, 'grad_norm': 6.161764144897461, 'learning_rate': 1.745762711864407e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [3:51:18<1:56:39,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [3:51:22<1:56:42,  3.40s/it]                                                       {'loss': 0.001, 'grad_norm': 0.13040821254253387, 'learning_rate': 1.7449152542372883e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [3:51:22<1:56:42,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [3:51:25<1:56:00,  3.38s/it]                                                       {'loss': 0.2173, 'grad_norm': 6.827595233917236, 'learning_rate': 1.7440677966101694e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [3:51:25<1:56:00,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [3:51:29<1:56:34,  3.40s/it]                                                       {'loss': 0.0, 'grad_norm': 0.005642136093229055, 'learning_rate': 1.743220338983051e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [3:51:29<1:56:34,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [3:51:32<1:55:43,  3.38s/it]                                                       {'loss': 0.003, 'grad_norm': 0.4080426096916199, 'learning_rate': 1.7423728813559324e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [3:51:32<1:55:43,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [3:51:35<1:57:10,  3.42s/it]                                                       {'loss': 0.1561, 'grad_norm': 8.992345809936523, 'learning_rate': 1.7415254237288135e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [3:51:35<1:57:10,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [3:51:39<1:56:40,  3.41s/it]                                                       {'loss': 0.0693, 'grad_norm': 4.060514450073242, 'learning_rate': 1.740677966101695e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [3:51:39<1:56:40,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [3:51:42<1:55:20,  3.37s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.4129732847213745, 'learning_rate': 1.7398305084745764e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [3:51:42<1:55:20,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [3:51:45<1:54:36,  3.35s/it]                                                       {'loss': 0.002, 'grad_norm': 0.17440718412399292, 'learning_rate': 1.738983050847458e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [3:51:45<1:54:36,  3.35s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [3:51:49<1:56:18,  3.40s/it]                                                       {'loss': 0.0597, 'grad_norm': 3.737443208694458, 'learning_rate': 1.738135593220339e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [3:51:49<1:56:18,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [3:51:52<1:56:06,  3.40s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.41447776556015015, 'learning_rate': 1.7372881355932205e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [3:51:52<1:56:06,  3.40s/it][2025-10-20 03:28:57,598] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [3:51:58<2:19:31,  4.09s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2538466453552246, 'learning_rate': 1.736440677966102e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [3:51:58<2:19:31,  4.09s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [3:52:01<2:11:52,  3.86s/it]                                                       {'loss': 0.076, 'grad_norm': 5.3159356117248535, 'learning_rate': 1.735593220338983e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [3:52:01<2:11:52,  3.86s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [3:52:05<2:07:17,  3.73s/it]                                                       {'loss': 0.0223, 'grad_norm': 2.0598528385162354, 'learning_rate': 1.7347457627118646e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [3:52:05<2:07:17,  3.73s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [3:52:08<2:04:06,  3.64s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.35094329714775085, 'learning_rate': 1.7338983050847457e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [3:52:08<2:04:06,  3.64s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [3:52:12<2:01:24,  3.56s/it]                                                       {'loss': 0.0461, 'grad_norm': 3.826176643371582, 'learning_rate': 1.733050847457627e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [3:52:12<2:01:24,  3.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [3:52:15<2:04:04,  3.64s/it]                                                       {'loss': 0.033, 'grad_norm': 3.298318386077881, 'learning_rate': 1.7322033898305083e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [3:52:15<2:04:04,  3.64s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [3:52:19<2:03:12,  3.62s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.5884882211685181, 'learning_rate': 1.7313559322033898e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [3:52:19<2:03:12,  3.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [3:52:22<2:00:47,  3.55s/it]                                                       {'loss': 0.0496, 'grad_norm': 3.03796124458313, 'learning_rate': 1.7305084745762712e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [3:52:22<2:00:47,  3.55s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [3:52:26<1:59:21,  3.51s/it]                                                       {'loss': 0.0335, 'grad_norm': 4.789913654327393, 'learning_rate': 1.7296610169491527e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [3:52:26<1:59:21,  3.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [3:52:29<1:58:09,  3.48s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5729050636291504, 'learning_rate': 1.7288135593220338e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [3:52:29<1:58:09,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [3:52:33<1:57:17,  3.45s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7858172059059143, 'learning_rate': 1.7279661016949153e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [3:52:33<1:57:17,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [3:52:36<1:56:34,  3.43s/it]                                                       {'loss': 0.0535, 'grad_norm': 6.052205562591553, 'learning_rate': 1.7271186440677968e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [3:52:36<1:56:34,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [3:52:39<1:55:40,  3.41s/it]                                                       {'loss': 0.0835, 'grad_norm': 4.034501075744629, 'learning_rate': 1.726271186440678e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [3:52:39<1:55:40,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [3:52:43<1:55:19,  3.40s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.5029518604278564, 'learning_rate': 1.7254237288135594e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [3:52:43<1:55:19,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [3:52:46<1:55:09,  3.40s/it]                                                       {'loss': 0.0645, 'grad_norm': 6.212093353271484, 'learning_rate': 1.7245762711864408e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [3:52:46<1:55:09,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [3:52:49<1:54:27,  3.38s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3477689325809479, 'learning_rate': 1.7237288135593223e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [3:52:49<1:54:27,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [3:52:53<1:53:42,  3.36s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06546451896429062, 'learning_rate': 1.7228813559322034e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [3:52:53<1:53:42,  3.36s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [3:52:56<1:56:55,  3.45s/it]                                                       {'loss': 0.069, 'grad_norm': 4.159231185913086, 'learning_rate': 1.722033898305085e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [3:52:56<1:56:55,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [3:53:00<1:55:40,  3.42s/it]                                                       {'loss': 0.4108, 'grad_norm': 8.251230239868164, 'learning_rate': 1.7211864406779664e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [3:53:00<1:55:40,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [3:53:03<1:56:57,  3.46s/it]                                                       {'loss': 0.4729, 'grad_norm': 7.012199401855469, 'learning_rate': 1.7203389830508475e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [3:53:03<1:56:57,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [3:53:07<1:57:11,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.04728059470653534, 'learning_rate': 1.719491525423729e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [3:53:07<1:57:11,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [3:53:10<1:55:46,  3.43s/it]                                                       {'loss': 0.0596, 'grad_norm': 5.394124507904053, 'learning_rate': 1.7186440677966104e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [3:53:10<1:55:46,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [3:53:14<1:57:04,  3.47s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.23721444606781, 'learning_rate': 1.717796610169492e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [3:53:14<1:57:04,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [3:53:17<1:54:57,  3.40s/it]                                                       {'loss': 0.0351, 'grad_norm': 3.553941011428833, 'learning_rate': 1.716949152542373e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [3:53:17<1:54:57,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [3:53:20<1:55:32,  3.42s/it]                                                       {'loss': 0.047, 'grad_norm': 5.068787097930908, 'learning_rate': 1.716101694915254e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [3:53:20<1:55:32,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [3:53:24<1:54:58,  3.41s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06949350982904434, 'learning_rate': 1.7152542372881356e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [3:53:24<1:54:58,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [3:53:27<1:55:14,  3.42s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.040864065289497375, 'learning_rate': 1.714406779661017e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [3:53:27<1:55:14,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [3:53:30<1:53:52,  3.38s/it]                                                       {'loss': 0.001, 'grad_norm': 0.20342907309532166, 'learning_rate': 1.7135593220338982e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [3:53:30<1:53:52,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [3:53:34<1:53:36,  3.37s/it]                                                       {'loss': 0.0749, 'grad_norm': 5.659117698669434, 'learning_rate': 1.7127118644067797e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [3:53:34<1:53:36,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [3:53:37<1:53:18,  3.37s/it]                                                       {'loss': 0.1147, 'grad_norm': 6.477589130401611, 'learning_rate': 1.711864406779661e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [3:53:37<1:53:18,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [3:53:40<1:53:00,  3.36s/it]                                                       {'loss': 0.0266, 'grad_norm': 2.3533034324645996, 'learning_rate': 1.7110169491525423e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [3:53:40<1:53:00,  3.36s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [3:53:44<1:52:29,  3.34s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.250123530626297, 'learning_rate': 1.7101694915254237e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [3:53:44<1:52:29,  3.34s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [3:53:47<1:53:25,  3.37s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.457545757293701, 'learning_rate': 1.7093220338983052e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [3:53:47<1:53:25,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [3:53:51<1:52:55,  3.36s/it]                                                       {'loss': 0.0677, 'grad_norm': 2.9070701599121094, 'learning_rate': 1.7084745762711867e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [3:53:51<1:52:55,  3.36s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [3:53:54<1:53:29,  3.38s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.9472556114196777, 'learning_rate': 1.7076271186440678e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [3:53:54<1:53:29,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [3:53:57<1:54:14,  3.40s/it]                                                       {'loss': 0.048, 'grad_norm': 2.0750508308410645, 'learning_rate': 1.7067796610169493e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [3:53:57<1:54:14,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [3:54:01<1:55:12,  3.43s/it]                                                       {'loss': 0.0194, 'grad_norm': 1.7673113346099854, 'learning_rate': 1.7059322033898307e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [3:54:01<1:55:12,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [3:54:04<1:55:01,  3.43s/it]                                                       {'loss': 0.1692, 'grad_norm': 5.082737922668457, 'learning_rate': 1.705084745762712e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [3:54:04<1:55:01,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [3:54:08<1:55:36,  3.45s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8281198143959045, 'learning_rate': 1.7042372881355933e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [3:54:08<1:55:36,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [3:54:11<1:55:03,  3.43s/it]                                                       {'loss': 0.0516, 'grad_norm': 3.8063035011291504, 'learning_rate': 1.7033898305084748e-05, 'epoch': 0.67}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [3:54:11<1:55:03,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [3:54:15<1:54:16,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.12420430034399033, 'learning_rate': 1.7025423728813563e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [3:54:15<1:54:16,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [3:54:18<1:54:30,  3.42s/it]                                                       {'loss': 0.038, 'grad_norm': 5.24574089050293, 'learning_rate': 1.7016949152542374e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [3:54:18<1:54:30,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [3:54:22<1:54:41,  3.43s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.531524658203125, 'learning_rate': 1.700847457627119e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [3:54:22<1:54:41,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [3:54:26<2:03:26,  3.69s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.43093129992485046, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [3:54:26<2:03:26,  3.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [3:54:29<2:01:34,  3.64s/it]                                                       {'loss': 0.0423, 'grad_norm': 3.9357340335845947, 'learning_rate': 1.6991525423728815e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [3:54:29<2:01:34,  3.64s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [3:54:33<1:58:50,  3.56s/it]                                                       {'loss': 0.0545, 'grad_norm': 1.7325143814086914, 'learning_rate': 1.6983050847457626e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [3:54:33<1:58:50,  3.56s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [3:54:36<1:57:47,  3.53s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.6332964301109314, 'learning_rate': 1.697457627118644e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [3:54:36<1:57:47,  3.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [3:54:40<1:55:46,  3.47s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.6995620727539062, 'learning_rate': 1.6966101694915255e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [3:54:40<1:55:46,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [3:54:43<1:55:06,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06989631056785583, 'learning_rate': 1.6957627118644066e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [3:54:43<1:55:06,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [3:54:46<1:55:12,  3.46s/it]                                                       {'loss': 0.078, 'grad_norm': 6.029562473297119, 'learning_rate': 1.694915254237288e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [3:54:46<1:55:12,  3.46s/it][2025-10-20 03:31:51,706] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [3:54:52<2:16:12,  4.09s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1935303956270218, 'learning_rate': 1.6940677966101696e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [3:54:52<2:16:12,  4.09s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [3:54:55<2:09:45,  3.90s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.7110552191734314, 'learning_rate': 1.693220338983051e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [3:54:55<2:09:45,  3.90s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [3:54:59<2:05:19,  3.77s/it]                                                       {'loss': 0.141, 'grad_norm': 5.55281400680542, 'learning_rate': 1.6923728813559322e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [3:54:59<2:05:19,  3.77s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [3:55:02<2:02:24,  3.68s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3499506711959839, 'learning_rate': 1.6915254237288136e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [3:55:02<2:02:24,  3.68s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [3:55:06<1:58:57,  3.58s/it]                                                       {'loss': 0.062, 'grad_norm': 3.060143232345581, 'learning_rate': 1.690677966101695e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [3:55:06<1:58:57,  3.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [3:55:09<1:56:40,  3.51s/it]                                                       {'loss': 0.0239, 'grad_norm': 2.646970748901367, 'learning_rate': 1.6898305084745762e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [3:55:09<1:56:40,  3.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [3:55:12<1:55:55,  3.49s/it]                                                       {'loss': 0.0372, 'grad_norm': 3.477205514907837, 'learning_rate': 1.6889830508474577e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [3:55:12<1:55:55,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [3:55:16<1:53:40,  3.42s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.7111773490905762, 'learning_rate': 1.6881355932203392e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [3:55:16<1:53:40,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [3:55:19<1:53:05,  3.41s/it]                                                       {'loss': 0.0455, 'grad_norm': 4.0871734619140625, 'learning_rate': 1.6872881355932203e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [3:55:19<1:53:05,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [3:55:23<1:53:00,  3.41s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.5924965143203735, 'learning_rate': 1.6864406779661018e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [3:55:23<1:53:00,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [3:55:26<1:53:40,  3.43s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.21850638091564178, 'learning_rate': 1.6855932203389832e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [3:55:26<1:53:40,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [3:55:29<1:53:17,  3.42s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.08814273774623871, 'learning_rate': 1.6847457627118647e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [3:55:29<1:53:17,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [3:55:33<1:52:48,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.11222013831138611, 'learning_rate': 1.683898305084746e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [3:55:33<1:52:48,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [3:55:36<1:52:30,  3.40s/it]                                                       {'loss': 0.1587, 'grad_norm': 8.079914093017578, 'learning_rate': 1.6830508474576273e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [3:55:36<1:52:30,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [3:55:40<1:52:39,  3.41s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.049005500972270966, 'learning_rate': 1.6822033898305088e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [3:55:40<1:52:39,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [3:55:43<1:53:44,  3.44s/it]                                                       {'loss': 0.0643, 'grad_norm': 4.494237899780273, 'learning_rate': 1.68135593220339e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [3:55:43<1:53:44,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [3:55:46<1:52:40,  3.41s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.0931520462036133, 'learning_rate': 1.680508474576271e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [3:55:46<1:52:40,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [3:55:50<1:51:47,  3.38s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.15420253574848175, 'learning_rate': 1.6796610169491525e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [3:55:50<1:51:47,  3.38s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [3:55:53<1:51:43,  3.38s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.27887919545173645, 'learning_rate': 1.678813559322034e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [3:55:53<1:51:43,  3.38s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [3:55:57<1:52:03,  3.40s/it]                                                       {'loss': 0.0271, 'grad_norm': 3.8633852005004883, 'learning_rate': 1.677966101694915e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [3:55:57<1:52:03,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [3:56:00<1:51:51,  3.39s/it]                                                       {'loss': 0.007, 'grad_norm': 1.6100342273712158, 'learning_rate': 1.6771186440677966e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [3:56:00<1:51:51,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [3:56:04<2:01:04,  3.67s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.7503058314323425, 'learning_rate': 1.676271186440678e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [3:56:04<2:01:04,  3.67s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [3:56:08<1:58:39,  3.60s/it]                                                       {'loss': 0.1326, 'grad_norm': 6.409638404846191, 'learning_rate': 1.6754237288135595e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [3:56:08<1:58:39,  3.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [3:56:12<2:06:46,  3.85s/it]                                                       {'loss': 0.0399, 'grad_norm': 3.186107635498047, 'learning_rate': 1.6745762711864406e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [3:56:12<2:06:46,  3.85s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [3:56:16<2:02:37,  3.73s/it]                                                       {'loss': 0.2964, 'grad_norm': 10.101288795471191, 'learning_rate': 1.673728813559322e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [3:56:16<2:02:37,  3.73s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [3:56:19<1:59:28,  3.63s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.4709540009498596, 'learning_rate': 1.6728813559322036e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [3:56:19<1:59:28,  3.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [3:56:23<2:03:55,  3.77s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.22626405954360962, 'learning_rate': 1.6720338983050847e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [3:56:23<2:03:55,  3.77s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [3:56:27<2:01:07,  3.69s/it]                                                       {'loss': 0.051, 'grad_norm': 5.159614562988281, 'learning_rate': 1.671186440677966e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [3:56:27<2:01:07,  3.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [3:56:30<1:58:30,  3.61s/it]                                                       {'loss': 0.1801, 'grad_norm': 6.213160514831543, 'learning_rate': 1.6703389830508476e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [3:56:30<1:58:30,  3.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [3:56:33<1:56:10,  3.54s/it]                                                       {'loss': 0.1412, 'grad_norm': 7.059875011444092, 'learning_rate': 1.669491525423729e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [3:56:33<1:56:10,  3.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [3:56:37<1:54:03,  3.48s/it]                                                       {'loss': 0.057, 'grad_norm': 2.6323537826538086, 'learning_rate': 1.6686440677966102e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [3:56:37<1:54:03,  3.48s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [3:56:40<1:53:48,  3.47s/it]                                                       {'loss': 0.0378, 'grad_norm': 4.30496883392334, 'learning_rate': 1.6677966101694917e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [3:56:40<1:53:48,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [3:56:44<1:53:29,  3.46s/it]                                                       {'loss': 0.014, 'grad_norm': 1.540440320968628, 'learning_rate': 1.666949152542373e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [3:56:44<1:53:29,  3.46s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [3:56:47<1:52:00,  3.42s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.814798355102539, 'learning_rate': 1.6661016949152543e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [3:56:47<1:52:00,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [3:56:50<1:52:43,  3.44s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.1677795797586441, 'learning_rate': 1.6652542372881357e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [3:56:50<1:52:43,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [3:56:54<1:51:34,  3.41s/it]                                                       {'loss': 0.0445, 'grad_norm': 4.512093544006348, 'learning_rate': 1.6644067796610172e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [3:56:54<1:51:34,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [3:56:57<1:50:42,  3.38s/it]                                                       {'loss': 0.0589, 'grad_norm': 3.3934316635131836, 'learning_rate': 1.6635593220338983e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [3:56:57<1:50:42,  3.38s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [3:57:01<1:52:13,  3.43s/it]                                                       {'loss': 0.0885, 'grad_norm': 6.68471097946167, 'learning_rate': 1.6627118644067795e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [3:57:01<1:52:13,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [3:57:04<1:52:32,  3.44s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.344669222831726, 'learning_rate': 1.661864406779661e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [3:57:04<1:52:32,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [3:57:08<1:54:27,  3.50s/it]                                                       {'loss': 0.0107, 'grad_norm': 0.760243833065033, 'learning_rate': 1.6610169491525424e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [3:57:08<1:54:27,  3.50s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [3:57:12<1:57:45,  3.61s/it]                                                       {'loss': 0.1046, 'grad_norm': 6.692784786224365, 'learning_rate': 1.660169491525424e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [3:57:12<1:57:45,  3.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [3:57:15<1:55:42,  3.55s/it]                                                       {'loss': 0.0691, 'grad_norm': 5.339348316192627, 'learning_rate': 1.659322033898305e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [3:57:15<1:55:42,  3.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [3:57:19<1:58:27,  3.63s/it]                                                       {'loss': 0.0382, 'grad_norm': 3.8470916748046875, 'learning_rate': 1.6584745762711865e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [3:57:19<1:58:27,  3.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [3:57:22<1:55:49,  3.55s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.1237488985061646, 'learning_rate': 1.657627118644068e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [3:57:22<1:55:49,  3.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [3:57:26<1:55:06,  3.53s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.0860810279846191, 'learning_rate': 1.656779661016949e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [3:57:26<1:55:06,  3.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [3:57:29<1:53:46,  3.49s/it]                                                       {'loss': 0.005, 'grad_norm': 1.1904442310333252, 'learning_rate': 1.6559322033898305e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [3:57:29<1:53:46,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [3:57:33<1:54:49,  3.53s/it]                                                       {'loss': 0.2002, 'grad_norm': 8.041603088378906, 'learning_rate': 1.655084745762712e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [3:57:33<1:54:49,  3.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [3:57:36<1:54:31,  3.52s/it]                                                       {'loss': 0.0612, 'grad_norm': 4.789434909820557, 'learning_rate': 1.6542372881355935e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [3:57:36<1:54:31,  3.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [3:57:40<1:54:51,  3.53s/it]                                                       {'loss': 0.1484, 'grad_norm': 6.391555309295654, 'learning_rate': 1.6533898305084746e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [3:57:40<1:54:51,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [3:57:43<1:54:39,  3.53s/it]                                                       {'loss': 0.1748, 'grad_norm': 6.896557807922363, 'learning_rate': 1.652542372881356e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [3:57:43<1:54:39,  3.53s/it][2025-10-20 03:34:48,583] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [3:57:49<2:15:10,  4.16s/it]                                                       {'loss': 0.1763, 'grad_norm': 7.965489864349365, 'learning_rate': 1.6516949152542375e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [3:57:49<2:15:10,  4.16s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [3:57:52<2:07:56,  3.94s/it]                                                       {'loss': 0.0442, 'grad_norm': 3.8289287090301514, 'learning_rate': 1.6508474576271187e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [3:57:52<2:07:56,  3.94s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [3:57:56<2:06:03,  3.88s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.9856894016265869, 'learning_rate': 1.65e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [3:57:56<2:06:03,  3.88s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [3:58:00<2:01:53,  3.76s/it]                                                       {'loss': 0.1194, 'grad_norm': 6.419713020324707, 'learning_rate': 1.6491525423728816e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [3:58:00<2:01:53,  3.76s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [3:58:03<1:59:20,  3.68s/it]                                                       {'loss': 0.0444, 'grad_norm': 3.6843624114990234, 'learning_rate': 1.648305084745763e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [3:58:03<1:59:20,  3.68s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [3:58:07<1:59:32,  3.69s/it]                                                       {'loss': 0.2141, 'grad_norm': 7.728039741516113, 'learning_rate': 1.6474576271186442e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [3:58:07<1:59:32,  3.69s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [3:58:10<1:55:32,  3.57s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.8924592733383179, 'learning_rate': 1.6466101694915257e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [3:58:10<1:55:32,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [3:58:13<1:53:34,  3.51s/it]                                                       {'loss': 0.0206, 'grad_norm': 2.3640596866607666, 'learning_rate': 1.6457627118644068e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [3:58:13<1:53:34,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [3:58:17<1:51:54,  3.46s/it]                                                       {'loss': 0.0112, 'grad_norm': 2.934462308883667, 'learning_rate': 1.6449152542372883e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [3:58:17<1:51:54,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [3:58:20<1:50:50,  3.43s/it]                                                       {'loss': 0.1407, 'grad_norm': 7.224464416503906, 'learning_rate': 1.6440677966101694e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [3:58:20<1:50:50,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [3:58:24<1:50:46,  3.43s/it]                                                       {'loss': 0.2067, 'grad_norm': 10.68801212310791, 'learning_rate': 1.643220338983051e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [3:58:24<1:50:46,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [3:58:27<1:49:40,  3.40s/it]                                                       {'loss': 0.0542, 'grad_norm': 6.866054534912109, 'learning_rate': 1.6423728813559323e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [3:58:27<1:49:40,  3.40s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [3:58:31<1:55:53,  3.59s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6586020588874817, 'learning_rate': 1.6415254237288134e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [3:58:31<1:55:53,  3.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [3:58:34<1:53:23,  3.51s/it]                                                       {'loss': 0.0282, 'grad_norm': 3.342952251434326, 'learning_rate': 1.640677966101695e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [3:58:34<1:53:23,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [3:58:38<1:57:29,  3.64s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.16107384860515594, 'learning_rate': 1.6398305084745764e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [3:58:38<1:57:29,  3.64s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [3:58:42<1:55:05,  3.57s/it]                                                       {'loss': 0.0253, 'grad_norm': 2.764613151550293, 'learning_rate': 1.638983050847458e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [3:58:42<1:55:05,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [3:58:45<1:53:19,  3.52s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.1800459325313568, 'learning_rate': 1.638135593220339e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [3:58:45<1:53:19,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [3:58:48<1:52:13,  3.49s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.8675020933151245, 'learning_rate': 1.6372881355932204e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [3:58:48<1:52:13,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [3:58:52<1:50:52,  3.45s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.294630289077759, 'learning_rate': 1.636440677966102e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [3:58:52<1:50:52,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [3:58:55<1:49:49,  3.41s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3757045865058899, 'learning_rate': 1.635593220338983e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [3:58:55<1:49:49,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [3:58:59<1:50:04,  3.42s/it]                                                       {'loss': 0.1025, 'grad_norm': 7.241772651672363, 'learning_rate': 1.6347457627118645e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [3:58:59<1:50:04,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [3:59:02<1:50:41,  3.44s/it]                                                       {'loss': 0.003, 'grad_norm': 0.47248876094818115, 'learning_rate': 1.633898305084746e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [3:59:02<1:50:41,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [3:59:06<1:53:25,  3.53s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.7493048906326294, 'learning_rate': 1.633050847457627e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [3:59:06<1:53:25,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [3:59:09<1:52:01,  3.49s/it]                                                       {'loss': 0.1738, 'grad_norm': 7.000829696655273, 'learning_rate': 1.6322033898305086e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [3:59:09<1:52:01,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [3:59:12<1:50:05,  3.43s/it]                                                       {'loss': 0.0938, 'grad_norm': 5.040741443634033, 'learning_rate': 1.63135593220339e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [3:59:12<1:50:05,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [3:59:16<1:52:42,  3.51s/it]                                                       {'loss': 0.002, 'grad_norm': 0.28388291597366333, 'learning_rate': 1.6305084745762715e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [3:59:16<1:52:42,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [3:59:20<1:51:47,  3.49s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.543583333492279, 'learning_rate': 1.6296610169491526e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [3:59:20<1:51:47,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [3:59:23<1:51:45,  3.49s/it]                                                       {'loss': 0.0581, 'grad_norm': 6.466235637664795, 'learning_rate': 1.628813559322034e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [3:59:23<1:51:45,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [3:59:26<1:50:32,  3.45s/it]                                                       {'loss': 0.1118, 'grad_norm': 5.84748649597168, 'learning_rate': 1.6279661016949152e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [3:59:26<1:50:32,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [3:59:30<1:50:04,  3.44s/it]                                                       {'loss': 0.0506, 'grad_norm': 5.710246562957764, 'learning_rate': 1.6271186440677967e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [3:59:30<1:50:04,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [3:59:34<1:52:31,  3.52s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.2949546277523041, 'learning_rate': 1.6262711864406778e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [3:59:34<1:52:31,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [3:59:37<1:51:44,  3.50s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.044880494475364685, 'learning_rate': 1.6254237288135593e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [3:59:37<1:51:44,  3.50s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [3:59:40<1:50:31,  3.46s/it]                                                       {'loss': 0.0769, 'grad_norm': 4.45262336730957, 'learning_rate': 1.6245762711864408e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [3:59:40<1:50:31,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [3:59:44<1:54:11,  3.58s/it]                                                       {'loss': 0.044, 'grad_norm': 5.8735737800598145, 'learning_rate': 1.623728813559322e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [3:59:44<1:54:11,  3.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [3:59:48<1:52:27,  3.52s/it]                                                       {'loss': 0.0374, 'grad_norm': 3.206394910812378, 'learning_rate': 1.6228813559322034e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [3:59:48<1:52:27,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [3:59:51<1:50:31,  3.46s/it]                                                       {'loss': 0.0277, 'grad_norm': 4.2730278968811035, 'learning_rate': 1.6220338983050848e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [3:59:51<1:50:31,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [3:59:54<1:50:40,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015451974235475063, 'learning_rate': 1.6211864406779663e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [3:59:54<1:50:40,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [3:59:58<1:52:58,  3.55s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.401236891746521, 'learning_rate': 1.6203389830508474e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [3:59:58<1:52:58,  3.55s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [4:00:02<1:51:28,  3.50s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.9481701850891113, 'learning_rate': 1.619491525423729e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [4:00:02<1:51:28,  3.50s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [4:00:05<1:50:18,  3.47s/it]                                                       {'loss': 0.0431, 'grad_norm': 2.258159637451172, 'learning_rate': 1.6186440677966104e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [4:00:05<1:50:18,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [4:00:08<1:49:28,  3.44s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1062997579574585, 'learning_rate': 1.6177966101694915e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [4:00:08<1:49:28,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [4:00:12<1:48:41,  3.42s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.6369200944900513, 'learning_rate': 1.616949152542373e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [4:00:12<1:48:41,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [4:00:15<1:48:25,  3.41s/it]                                                       {'loss': 0.0912, 'grad_norm': 5.976011276245117, 'learning_rate': 1.6161016949152544e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [4:00:15<1:48:25,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [4:00:18<1:47:57,  3.40s/it]                                                       {'loss': 0.0945, 'grad_norm': 11.195456504821777, 'learning_rate': 1.615254237288136e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [4:00:18<1:47:57,  3.40s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [4:00:22<1:48:35,  3.42s/it]                                                       {'loss': 0.0484, 'grad_norm': 5.553781509399414, 'learning_rate': 1.614406779661017e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [4:00:22<1:48:35,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [4:00:25<1:48:58,  3.43s/it]                                                       {'loss': 0.0377, 'grad_norm': 1.91541588306427, 'learning_rate': 1.6135593220338985e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [4:00:25<1:48:58,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [4:00:29<1:48:50,  3.43s/it]                                                       {'loss': 0.128, 'grad_norm': 5.278456211090088, 'learning_rate': 1.61271186440678e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [4:00:29<1:48:50,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [4:00:32<1:49:24,  3.45s/it]                                                       {'loss': 0.0378, 'grad_norm': 5.018717288970947, 'learning_rate': 1.611864406779661e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [4:00:32<1:49:24,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [4:00:36<1:48:54,  3.44s/it]                                                       {'loss': 0.0476, 'grad_norm': 5.635587692260742, 'learning_rate': 1.6110169491525425e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [4:00:36<1:48:54,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [4:00:40<1:53:24,  3.58s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3966735899448395, 'learning_rate': 1.6101694915254237e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [4:00:40<1:53:24,  3.58s/it][2025-10-20 03:37:44,932] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [4:00:46<2:15:24,  4.28s/it]                                                       {'loss': 0.1455, 'grad_norm': 6.192822456359863, 'learning_rate': 1.609322033898305e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [4:00:46<2:15:24,  4.28s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [4:00:49<2:07:41,  4.04s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1535397619009018, 'learning_rate': 1.6084745762711863e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [4:00:49<2:07:41,  4.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [4:00:53<2:05:08,  3.96s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.0715744495391846, 'learning_rate': 1.6076271186440677e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [4:00:53<2:05:08,  3.96s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [4:00:57<2:03:16,  3.90s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.2261199951171875, 'learning_rate': 1.6067796610169492e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [4:00:57<2:03:16,  3.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [4:01:00<1:58:53,  3.76s/it]                                                       {'loss': 0.1592, 'grad_norm': 7.754444122314453, 'learning_rate': 1.6059322033898307e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [4:01:00<1:58:53,  3.76s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [4:01:04<1:59:21,  3.78s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.008278727531433, 'learning_rate': 1.6050847457627118e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [4:01:04<1:59:21,  3.78s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [4:01:07<1:55:44,  3.67s/it]                                                       {'loss': 0.0552, 'grad_norm': 4.866792678833008, 'learning_rate': 1.6042372881355933e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [4:01:07<1:55:44,  3.67s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [4:01:11<1:52:29,  3.57s/it]                                                       {'loss': 0.0381, 'grad_norm': 4.169734477996826, 'learning_rate': 1.6033898305084747e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [4:01:11<1:52:29,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [4:01:15<1:56:25,  3.69s/it]                                                       {'loss': 0.0561, 'grad_norm': 4.8267035484313965, 'learning_rate': 1.602542372881356e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [4:01:15<1:56:25,  3.69s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [4:01:18<1:53:29,  3.60s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.498672217130661, 'learning_rate': 1.6016949152542373e-05, 'epoch': 0.69}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [4:01:18<1:53:29,  3.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [4:01:21<1:52:00,  3.56s/it]                                                       {'loss': 0.1018, 'grad_norm': 9.46402359008789, 'learning_rate': 1.6008474576271188e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [4:01:21<1:52:00,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [4:01:25<1:50:09,  3.50s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.23614707589149475, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [4:01:25<1:50:09,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [4:01:29<1:54:00,  3.63s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.023424465209245682, 'learning_rate': 1.5991525423728814e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [4:01:29<1:54:00,  3.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [4:01:32<1:51:59,  3.56s/it]                                                       {'loss': 0.0787, 'grad_norm': 5.199241638183594, 'learning_rate': 1.598305084745763e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [4:01:32<1:51:59,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [4:01:35<1:49:52,  3.50s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.28887397050857544, 'learning_rate': 1.5974576271186443e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [4:01:35<1:49:52,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [4:01:39<1:48:51,  3.47s/it]                                                       {'loss': 0.1247, 'grad_norm': 7.547723770141602, 'learning_rate': 1.5966101694915255e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [4:01:39<1:48:51,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [4:01:43<1:52:22,  3.58s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.5286802053451538, 'learning_rate': 1.595762711864407e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [4:01:43<1:52:22,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [4:01:46<1:50:10,  3.51s/it]                                                       {'loss': 0.0466, 'grad_norm': 4.493710994720459, 'learning_rate': 1.5949152542372884e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [4:01:46<1:50:10,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [4:01:49<1:49:42,  3.50s/it]                                                       {'loss': 0.0246, 'grad_norm': 1.0318063497543335, 'learning_rate': 1.59406779661017e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [4:01:49<1:49:42,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [4:01:53<1:48:53,  3.48s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16117657721042633, 'learning_rate': 1.5932203389830507e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [4:01:53<1:48:53,  3.48s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [4:01:56<1:48:15,  3.46s/it]                                                       {'loss': 0.1449, 'grad_norm': 9.736360549926758, 'learning_rate': 1.592372881355932e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [4:01:56<1:48:15,  3.46s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [4:02:00<1:48:13,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025572137907147408, 'learning_rate': 1.5915254237288136e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [4:02:00<1:48:13,  3.46s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [4:02:03<1:47:51,  3.45s/it]                                                       {'loss': 0.0298, 'grad_norm': 3.0893030166625977, 'learning_rate': 1.590677966101695e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [4:02:03<1:47:51,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [4:02:07<1:47:52,  3.45s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.12304425239563, 'learning_rate': 1.5898305084745762e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [4:02:07<1:47:52,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [4:02:10<1:47:35,  3.44s/it]                                                       {'loss': 0.0272, 'grad_norm': 2.9057018756866455, 'learning_rate': 1.5889830508474576e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [4:02:10<1:47:35,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [4:02:13<1:47:10,  3.43s/it]                                                       {'loss': 0.1036, 'grad_norm': 7.111004829406738, 'learning_rate': 1.588135593220339e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [4:02:13<1:47:10,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [4:02:17<1:46:37,  3.42s/it]                                                       {'loss': 0.165, 'grad_norm': 7.247085094451904, 'learning_rate': 1.5872881355932202e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [4:02:17<1:46:37,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [4:02:20<1:48:24,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0918707475066185, 'learning_rate': 1.5864406779661017e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [4:02:20<1:48:24,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [4:02:24<1:46:34,  3.42s/it]                                                       {'loss': 0.2815, 'grad_norm': 8.364415168762207, 'learning_rate': 1.5855932203389832e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [4:02:24<1:46:34,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [4:02:27<1:46:36,  3.42s/it]                                                       {'loss': 0.1099, 'grad_norm': 6.706945419311523, 'learning_rate': 1.5847457627118646e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [4:02:27<1:46:36,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [4:02:31<1:47:16,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.11263290792703629, 'learning_rate': 1.5838983050847458e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [4:02:31<1:47:16,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [4:02:34<1:46:11,  3.41s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.389772891998291, 'learning_rate': 1.5830508474576272e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [4:02:34<1:46:11,  3.41s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [4:02:38<1:53:33,  3.65s/it]                                                       {'loss': 0.0172, 'grad_norm': 2.1609249114990234, 'learning_rate': 1.5822033898305087e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [4:02:38<1:53:33,  3.65s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [4:02:42<1:51:20,  3.58s/it]                                                       {'loss': 0.2728, 'grad_norm': 10.203317642211914, 'learning_rate': 1.58135593220339e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [4:02:42<1:51:20,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [4:02:45<1:49:16,  3.52s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.2462745904922485, 'learning_rate': 1.5805084745762713e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [4:02:45<1:49:16,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [4:02:49<1:52:16,  3.61s/it]                                                       {'loss': 0.0148, 'grad_norm': 1.8028422594070435, 'learning_rate': 1.5796610169491528e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [4:02:49<1:52:16,  3.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [4:02:53<1:55:53,  3.73s/it]                                                       {'loss': 0.049, 'grad_norm': 2.7812185287475586, 'learning_rate': 1.578813559322034e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [4:02:53<1:55:53,  3.73s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [4:02:56<1:53:41,  3.66s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.6635689735412598, 'learning_rate': 1.5779661016949154e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [4:02:56<1:53:41,  3.66s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [4:03:00<1:51:32,  3.60s/it]                                                       {'loss': 0.0411, 'grad_norm': 5.897984981536865, 'learning_rate': 1.577118644067797e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [4:03:00<1:51:32,  3.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [4:03:03<1:51:04,  3.58s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.13328562676906586, 'learning_rate': 1.5762711864406783e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [4:03:03<1:51:04,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [4:03:07<1:50:01,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.046721089631319046, 'learning_rate': 1.575423728813559e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [4:03:07<1:50:01,  3.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [4:03:10<1:48:20,  3.50s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.3987784385681152, 'learning_rate': 1.5745762711864406e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [4:03:10<1:48:20,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [4:03:14<1:48:02,  3.49s/it]                                                       {'loss': 0.2578, 'grad_norm': 11.192221641540527, 'learning_rate': 1.573728813559322e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [4:03:14<1:48:02,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [4:03:17<1:48:55,  3.52s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.16572171449661255, 'learning_rate': 1.5728813559322035e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [4:03:17<1:48:55,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [4:03:21<1:47:13,  3.47s/it]                                                       {'loss': 0.1075, 'grad_norm': 5.279555320739746, 'learning_rate': 1.5720338983050846e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [4:03:21<1:47:13,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [4:03:24<1:48:11,  3.50s/it]                                                       {'loss': 0.0193, 'grad_norm': 2.4838197231292725, 'learning_rate': 1.571186440677966e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [4:03:24<1:48:11,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [4:03:28<1:47:09,  3.47s/it]                                                       {'loss': 0.015, 'grad_norm': 2.8626859188079834, 'learning_rate': 1.5703389830508476e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [4:03:28<1:47:09,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [4:03:31<1:45:36,  3.42s/it]                                                       {'loss': 0.1576, 'grad_norm': 5.764892101287842, 'learning_rate': 1.5694915254237287e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [4:03:31<1:45:36,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [4:03:34<1:44:48,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.01310938224196434, 'learning_rate': 1.56864406779661e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [4:03:34<1:44:48,  3.40s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [4:03:38<1:44:14,  3.38s/it]                                                       {'loss': 0.1036, 'grad_norm': 5.648301601409912, 'learning_rate': 1.5677966101694916e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [4:03:38<1:44:14,  3.38s/it][2025-10-20 03:40:42,900] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [4:03:43<2:05:05,  4.06s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.6420367956161499, 'learning_rate': 1.566949152542373e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [4:03:43<2:05:05,  4.06s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [4:03:47<1:59:18,  3.87s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.25138911604881287, 'learning_rate': 1.5661016949152542e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [4:03:47<1:59:18,  3.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [4:03:50<1:54:08,  3.71s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.200808048248291, 'learning_rate': 1.5652542372881357e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [4:03:50<1:54:08,  3.71s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [4:03:54<1:56:00,  3.77s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.4017716646194458, 'learning_rate': 1.564406779661017e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [4:03:54<1:56:00,  3.77s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [4:03:57<1:52:25,  3.66s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.6961478590965271, 'learning_rate': 1.5635593220338983e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [4:03:57<1:52:25,  3.66s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [4:04:01<1:50:53,  3.61s/it]                                                       {'loss': 0.0685, 'grad_norm': 8.750787734985352, 'learning_rate': 1.5627118644067798e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [4:04:01<1:50:53,  3.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [4:04:04<1:50:09,  3.59s/it]                                                       {'loss': 0.0908, 'grad_norm': 7.650111675262451, 'learning_rate': 1.5618644067796612e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [4:04:04<1:50:09,  3.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [4:04:08<1:51:33,  3.63s/it]                                                       {'loss': 0.049, 'grad_norm': 5.7802910804748535, 'learning_rate': 1.5610169491525427e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [4:04:08<1:51:33,  3.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [4:04:12<1:50:44,  3.61s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03980445861816406, 'learning_rate': 1.5601694915254238e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [4:04:12<1:50:44,  3.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [4:04:15<1:48:48,  3.55s/it]                                                       {'loss': 0.1345, 'grad_norm': 6.981592178344727, 'learning_rate': 1.5593220338983053e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [4:04:15<1:48:48,  3.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [4:04:18<1:47:49,  3.52s/it]                                                       {'loss': 0.03, 'grad_norm': 3.413156270980835, 'learning_rate': 1.5584745762711867e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [4:04:18<1:47:49,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [4:04:22<1:47:33,  3.51s/it]                                                       {'loss': 0.0927, 'grad_norm': 5.333627700805664, 'learning_rate': 1.557627118644068e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [4:04:22<1:47:33,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [4:04:25<1:46:50,  3.49s/it]                                                       {'loss': 0.0289, 'grad_norm': 2.1356773376464844, 'learning_rate': 1.556779661016949e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [4:04:25<1:46:50,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [4:04:29<1:46:17,  3.47s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.8003588914871216, 'learning_rate': 1.5559322033898305e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [4:04:29<1:46:17,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [4:04:32<1:45:58,  3.47s/it]                                                       {'loss': 0.0461, 'grad_norm': 4.5836100578308105, 'learning_rate': 1.555084745762712e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [4:04:32<1:45:58,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [4:04:36<1:46:00,  3.47s/it]                                                       {'loss': 0.0825, 'grad_norm': 5.741554260253906, 'learning_rate': 1.554237288135593e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [4:04:36<1:46:00,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [4:04:39<1:46:02,  3.47s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.2938153743743896, 'learning_rate': 1.5533898305084745e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [4:04:39<1:46:02,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [4:04:43<1:46:07,  3.48s/it]                                                       {'loss': 0.0919, 'grad_norm': 5.243122577667236, 'learning_rate': 1.552542372881356e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [4:04:43<1:46:07,  3.48s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [4:04:47<1:51:43,  3.66s/it]                                                       {'loss': 0.004, 'grad_norm': 0.36320409178733826, 'learning_rate': 1.5516949152542375e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [4:04:47<1:51:43,  3.66s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [4:04:50<1:49:30,  3.59s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.01309618167579174, 'learning_rate': 1.5508474576271186e-05, 'epoch': 0.69}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [4:04:50<1:49:30,  3.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [4:04:54<1:52:04,  3.68s/it]                                                       {'loss': 0.3121, 'grad_norm': 8.396660804748535, 'learning_rate': 1.55e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [4:04:54<1:52:04,  3.68s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [4:04:58<1:50:14,  3.62s/it]                                                       {'loss': 0.1859, 'grad_norm': 6.683129787445068, 'learning_rate': 1.5491525423728815e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [4:04:58<1:50:14,  3.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [4:05:01<1:49:25,  3.59s/it]                                                       {'loss': 0.0465, 'grad_norm': 4.012784957885742, 'learning_rate': 1.5483050847457627e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [4:05:01<1:49:25,  3.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [4:05:05<1:47:44,  3.54s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.040956322103738785, 'learning_rate': 1.547457627118644e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [4:05:05<1:47:44,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [4:05:08<1:47:14,  3.53s/it]                                                       {'loss': 0.0235, 'grad_norm': 1.8147133588790894, 'learning_rate': 1.5466101694915256e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [4:05:08<1:47:14,  3.53s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [4:05:11<1:45:53,  3.48s/it]                                                       {'loss': 0.0798, 'grad_norm': 4.790409564971924, 'learning_rate': 1.545762711864407e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [4:05:11<1:45:53,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [4:05:15<1:45:25,  3.47s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.4977846145629883, 'learning_rate': 1.5449152542372882e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [4:05:15<1:45:25,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [4:05:18<1:44:44,  3.45s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.32735055685043335, 'learning_rate': 1.5440677966101697e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [4:05:18<1:44:44,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [4:05:22<1:44:14,  3.43s/it]                                                       {'loss': 0.1388, 'grad_norm': 7.837574481964111, 'learning_rate': 1.543220338983051e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [4:05:22<1:44:14,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [4:05:25<1:42:53,  3.39s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.2923257648944855, 'learning_rate': 1.5423728813559323e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [4:05:25<1:42:53,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [4:05:28<1:42:09,  3.37s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2639314532279968, 'learning_rate': 1.5415254237288137e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [4:05:28<1:42:09,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [4:05:32<1:43:11,  3.41s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.10359787940979004, 'learning_rate': 1.5406779661016952e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [4:05:32<1:43:11,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [4:05:35<1:43:25,  3.42s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.4847247302532196, 'learning_rate': 1.5398305084745763e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [4:05:35<1:43:25,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [4:05:39<1:43:29,  3.42s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.038583360612392426, 'learning_rate': 1.5389830508474574e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [4:05:39<1:43:29,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [4:05:42<1:43:19,  3.42s/it]                                                       {'loss': 0.3926, 'grad_norm': 6.719691753387451, 'learning_rate': 1.538135593220339e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [4:05:42<1:43:19,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [4:05:45<1:43:23,  3.42s/it]                                                       {'loss': 0.015, 'grad_norm': 1.7670003175735474, 'learning_rate': 1.5372881355932204e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [4:05:45<1:43:23,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [4:05:49<1:42:57,  3.41s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.42838287353515625, 'learning_rate': 1.536440677966102e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [4:05:49<1:42:57,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [4:05:52<1:43:14,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.31936874985694885, 'learning_rate': 1.535593220338983e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [4:05:52<1:43:14,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [4:05:56<1:44:55,  3.48s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.9949311017990112, 'learning_rate': 1.5347457627118644e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [4:05:56<1:44:55,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [4:05:59<1:44:38,  3.47s/it]                                                       {'loss': 0.1714, 'grad_norm': 8.230317115783691, 'learning_rate': 1.533898305084746e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [4:05:59<1:44:38,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [4:06:03<1:44:20,  3.46s/it]                                                       {'loss': 0.1032, 'grad_norm': 6.981738567352295, 'learning_rate': 1.533050847457627e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [4:06:03<1:44:20,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [4:06:06<1:45:01,  3.49s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3658052086830139, 'learning_rate': 1.5322033898305085e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [4:06:06<1:45:01,  3.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [4:06:10<1:45:14,  3.49s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.0975470542907715, 'learning_rate': 1.53135593220339e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [4:06:10<1:45:14,  3.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [4:06:13<1:45:08,  3.49s/it]                                                       {'loss': 0.0993, 'grad_norm': 8.094365119934082, 'learning_rate': 1.5305084745762714e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [4:06:13<1:45:08,  3.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [4:06:17<1:44:44,  3.48s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.2587176561355591, 'learning_rate': 1.5296610169491526e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [4:06:17<1:44:44,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [4:06:20<1:44:26,  3.47s/it]                                                       {'loss': 0.0562, 'grad_norm': 1.354868769645691, 'learning_rate': 1.528813559322034e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [4:06:20<1:44:26,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [4:06:24<1:43:18,  3.44s/it]                                                       {'loss': 0.1062, 'grad_norm': 5.514703750610352, 'learning_rate': 1.5279661016949155e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [4:06:24<1:43:18,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [4:06:27<1:42:43,  3.42s/it]                                                       {'loss': 0.1353, 'grad_norm': 6.84941291809082, 'learning_rate': 1.5271186440677966e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [4:06:27<1:42:43,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [4:06:30<1:42:23,  3.41s/it]                                                       {'loss': 0.0858, 'grad_norm': 7.82274055480957, 'learning_rate': 1.526271186440678e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [4:06:30<1:42:23,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [4:06:34<1:42:06,  3.40s/it]                                                       {'loss': 0.0644, 'grad_norm': 7.369753360748291, 'learning_rate': 1.5254237288135596e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [4:06:34<1:42:06,  3.40s/it][2025-10-20 03:43:39,093] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [4:06:39<2:01:42,  4.06s/it]                                                       {'loss': 0.012, 'grad_norm': 1.7941676378250122, 'learning_rate': 1.5245762711864409e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [4:06:39<2:01:42,  4.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [4:06:43<1:55:50,  3.87s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.978009581565857, 'learning_rate': 1.5237288135593222e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [4:06:43<1:55:50,  3.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [4:06:46<1:51:21,  3.72s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.457292318344116, 'learning_rate': 1.5228813559322033e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [4:06:46<1:51:21,  3.72s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [4:06:50<1:48:29,  3.62s/it]                                                       {'loss': 0.058, 'grad_norm': 2.8095052242279053, 'learning_rate': 1.5220338983050848e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [4:06:50<1:48:29,  3.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [4:06:53<1:46:43,  3.57s/it]                                                       {'loss': 0.0185, 'grad_norm': 1.8446327447891235, 'learning_rate': 1.521186440677966e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [4:06:53<1:46:43,  3.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [4:06:56<1:44:42,  3.50s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4426935911178589, 'learning_rate': 1.5203389830508474e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [4:06:56<1:44:42,  3.50s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [4:07:00<1:43:16,  3.46s/it]                                                       {'loss': 0.0427, 'grad_norm': 4.450825214385986, 'learning_rate': 1.5194915254237288e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [4:07:00<1:43:16,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [4:07:03<1:42:51,  3.44s/it]                                                       {'loss': 0.165, 'grad_norm': 6.8778815269470215, 'learning_rate': 1.5186440677966101e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [4:07:03<1:42:51,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [4:07:07<1:43:52,  3.48s/it]                                                       {'loss': 0.0264, 'grad_norm': 3.859178304672241, 'learning_rate': 1.5177966101694916e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [4:07:07<1:43:52,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [4:07:10<1:42:14,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.17636454105377197, 'learning_rate': 1.5169491525423729e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [4:07:10<1:42:14,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [4:07:13<1:42:25,  3.44s/it]                                                       {'loss': 0.0805, 'grad_norm': 6.8960065841674805, 'learning_rate': 1.5161016949152544e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [4:07:13<1:42:25,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [4:07:17<1:41:56,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1217455342411995, 'learning_rate': 1.5152542372881357e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [4:07:17<1:41:56,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [4:07:20<1:41:45,  3.42s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07519684731960297, 'learning_rate': 1.514406779661017e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [4:07:20<1:41:45,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [4:07:24<1:40:45,  3.38s/it]                                                       {'loss': 0.0495, 'grad_norm': 2.4367835521698, 'learning_rate': 1.5135593220338984e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [4:07:24<1:40:45,  3.38s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [4:07:27<1:42:24,  3.44s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.1543697118759155, 'learning_rate': 1.5127118644067797e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [4:07:27<1:42:24,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [4:07:30<1:41:25,  3.41s/it]                                                       {'loss': 0.2421, 'grad_norm': 7.0221147537231445, 'learning_rate': 1.5118644067796612e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [4:07:30<1:41:25,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [4:07:34<1:42:03,  3.43s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.350970983505249, 'learning_rate': 1.5110169491525425e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [4:07:34<1:42:03,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [4:07:37<1:41:45,  3.43s/it]                                                       {'loss': 0.0941, 'grad_norm': 6.900639533996582, 'learning_rate': 1.5101694915254238e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [4:07:37<1:41:45,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [4:07:41<1:41:23,  3.42s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3311980962753296, 'learning_rate': 1.5093220338983053e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [4:07:41<1:41:23,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [4:07:44<1:40:37,  3.39s/it]                                                       {'loss': 0.0977, 'grad_norm': 5.7247796058654785, 'learning_rate': 1.5084745762711865e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [4:07:44<1:40:37,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [4:07:48<1:40:58,  3.41s/it]                                                       {'loss': 0.1446, 'grad_norm': 7.92715311050415, 'learning_rate': 1.507627118644068e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [4:07:48<1:40:58,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [4:07:51<1:44:49,  3.54s/it]                                                       {'loss': 0.1066, 'grad_norm': 5.9233903884887695, 'learning_rate': 1.5067796610169493e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [4:07:51<1:44:49,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [4:07:55<1:44:58,  3.54s/it]                                                       {'loss': 0.0646, 'grad_norm': 5.462076187133789, 'learning_rate': 1.5059322033898308e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [4:07:55<1:44:58,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [4:07:59<1:46:16,  3.59s/it]                                                       {'loss': 0.1459, 'grad_norm': 7.356307029724121, 'learning_rate': 1.5050847457627117e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [4:07:59<1:46:16,  3.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [4:08:03<1:50:13,  3.73s/it]                                                       {'loss': 0.1331, 'grad_norm': 7.000356197357178, 'learning_rate': 1.5042372881355932e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [4:08:03<1:50:13,  3.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [4:08:07<1:57:17,  3.97s/it]                                                       {'loss': 0.019, 'grad_norm': 3.07381010055542, 'learning_rate': 1.5033898305084745e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [4:08:07<1:57:17,  3.97s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [4:08:11<1:51:46,  3.78s/it]                                                       {'loss': 0.008, 'grad_norm': 0.9640028476715088, 'learning_rate': 1.502542372881356e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [4:08:11<1:51:46,  3.78s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [4:08:14<1:49:37,  3.71s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.4601573050022125, 'learning_rate': 1.5016949152542373e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [4:08:14<1:49:37,  3.71s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [4:08:17<1:46:11,  3.60s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5637165307998657, 'learning_rate': 1.5008474576271186e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [4:08:17<1:46:11,  3.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [4:08:21<1:47:50,  3.66s/it]                                                       {'loss': 0.0244, 'grad_norm': 2.6009562015533447, 'learning_rate': 1.5e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [4:08:21<1:47:50,  3.66s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [4:08:25<1:48:13,  3.67s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6342576146125793, 'learning_rate': 1.4991525423728813e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [4:08:25<1:48:13,  3.67s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [4:08:28<1:45:27,  3.58s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.0803773403167725, 'learning_rate': 1.4983050847457628e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [4:08:28<1:45:27,  3.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [4:08:32<1:44:08,  3.54s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.48059341311454773, 'learning_rate': 1.4974576271186441e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [4:08:32<1:44:08,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [4:08:35<1:42:39,  3.49s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.3743526935577393, 'learning_rate': 1.4966101694915256e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [4:08:35<1:42:39,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [4:08:38<1:41:14,  3.44s/it]                                                       {'loss': 0.0279, 'grad_norm': 2.8729922771453857, 'learning_rate': 1.4957627118644069e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [4:08:38<1:41:14,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [4:08:42<1:40:42,  3.43s/it]                                                       {'loss': 0.0399, 'grad_norm': 4.779196739196777, 'learning_rate': 1.4949152542372882e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [4:08:42<1:40:42,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [4:08:46<1:44:47,  3.57s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.023981094360352, 'learning_rate': 1.4940677966101696e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [4:08:46<1:44:47,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [4:08:49<1:43:11,  3.51s/it]                                                       {'loss': 0.0882, 'grad_norm': 6.207080841064453, 'learning_rate': 1.493220338983051e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [4:08:49<1:43:11,  3.51s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [4:08:52<1:41:30,  3.46s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3798174262046814, 'learning_rate': 1.4923728813559324e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [4:08:52<1:41:30,  3.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [4:08:56<1:39:58,  3.41s/it]                                                       {'loss': 0.0441, 'grad_norm': 2.9340245723724365, 'learning_rate': 1.4915254237288137e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [4:08:56<1:39:58,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [4:08:59<1:40:02,  3.41s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.3333178460597992, 'learning_rate': 1.490677966101695e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [4:08:59<1:40:02,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [4:09:03<1:40:42,  3.44s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.34905821084976196, 'learning_rate': 1.4898305084745765e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [4:09:03<1:40:42,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [4:09:07<1:44:38,  3.57s/it]                                                       {'loss': 0.0922, 'grad_norm': 5.448127746582031, 'learning_rate': 1.4889830508474578e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [4:09:07<1:44:38,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [4:09:11<1:49:17,  3.73s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5097017288208008, 'learning_rate': 1.4881355932203392e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [4:09:11<1:49:17,  3.73s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [4:09:14<1:46:13,  3.63s/it]                                                       {'loss': 0.0898, 'grad_norm': 6.640996932983398, 'learning_rate': 1.4872881355932204e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [4:09:14<1:46:13,  3.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [4:09:18<1:47:56,  3.69s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.15887118875980377, 'learning_rate': 1.4864406779661017e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [4:09:18<1:47:56,  3.69s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [4:09:21<1:45:45,  3.62s/it]                                                       {'loss': 0.0695, 'grad_norm': 6.122314929962158, 'learning_rate': 1.485593220338983e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [4:09:21<1:45:45,  3.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [4:09:25<1:44:20,  3.57s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.15556851029396057, 'learning_rate': 1.4847457627118644e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [4:09:25<1:44:20,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [4:09:28<1:42:04,  3.50s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.20723138749599457, 'learning_rate': 1.4838983050847457e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [4:09:28<1:42:04,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [4:09:32<1:42:18,  3.51s/it]                                                       {'loss': 0.0354, 'grad_norm': 3.7237820625305176, 'learning_rate': 1.4830508474576272e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [4:09:32<1:42:18,  3.51s/it][2025-10-20 03:46:36,946] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [4:09:37<2:00:00,  4.12s/it]                                                       {'loss': 0.0426, 'grad_norm': 2.182821273803711, 'learning_rate': 1.4822033898305085e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [4:09:37<2:00:00,  4.12s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [4:09:41<1:54:26,  3.93s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012673137709498405, 'learning_rate': 1.4813559322033898e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [4:09:41<1:54:26,  3.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [4:09:44<1:53:40,  3.90s/it]                                                       {'loss': 0.0257, 'grad_norm': 2.479964256286621, 'learning_rate': 1.4805084745762712e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [4:09:45<1:53:40,  3.90s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [4:09:48<1:48:51,  3.74s/it]                                                       {'loss': 0.1127, 'grad_norm': 6.243407249450684, 'learning_rate': 1.4796610169491525e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [4:09:48<1:48:51,  3.74s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [4:09:51<1:44:54,  3.61s/it]                                                       {'loss': 0.0353, 'grad_norm': 2.4794228076934814, 'learning_rate': 1.478813559322034e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [4:09:51<1:44:54,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [4:09:55<1:42:41,  3.53s/it]                                                       {'loss': 0.0565, 'grad_norm': 4.8018927574157715, 'learning_rate': 1.4779661016949153e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [4:09:55<1:42:41,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [4:09:58<1:41:14,  3.49s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2518303394317627, 'learning_rate': 1.4771186440677968e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [4:09:58<1:41:14,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [4:10:01<1:41:45,  3.50s/it]                                                       {'loss': 0.0255, 'grad_norm': 1.7851653099060059, 'learning_rate': 1.476271186440678e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [4:10:01<1:41:45,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [4:10:05<1:39:39,  3.43s/it]                                                       {'loss': 0.0504, 'grad_norm': 3.762714385986328, 'learning_rate': 1.4754237288135594e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [4:10:05<1:39:39,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [4:10:08<1:38:55,  3.41s/it]                                                       {'loss': 0.041, 'grad_norm': 4.377255439758301, 'learning_rate': 1.4745762711864408e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [4:10:08<1:38:55,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [4:10:12<1:39:52,  3.45s/it]                                                       {'loss': 0.1365, 'grad_norm': 6.057042598724365, 'learning_rate': 1.4737288135593221e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [4:10:12<1:39:52,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [4:10:15<1:38:54,  3.41s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.1313610076904297, 'learning_rate': 1.4728813559322036e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [4:10:15<1:38:54,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [4:10:19<1:42:58,  3.56s/it]                                                       {'loss': 0.1206, 'grad_norm': 7.3396897315979, 'learning_rate': 1.4720338983050849e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [4:10:19<1:42:58,  3.56s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [4:10:22<1:41:47,  3.52s/it]                                                       {'loss': 0.0263, 'grad_norm': 2.95625376701355, 'learning_rate': 1.4711864406779664e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [4:10:22<1:41:47,  3.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [4:10:26<1:40:18,  3.47s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.23723213374614716, 'learning_rate': 1.4703389830508477e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [4:10:26<1:40:18,  3.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [4:10:29<1:38:36,  3.41s/it]                                                       {'loss': 0.0964, 'grad_norm': 6.844170093536377, 'learning_rate': 1.4694915254237288e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [4:10:29<1:38:36,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [4:10:32<1:38:43,  3.42s/it]                                                       {'loss': 0.045, 'grad_norm': 3.9153449535369873, 'learning_rate': 1.4686440677966101e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [4:10:32<1:38:43,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [4:10:36<1:38:21,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.023997869342565536, 'learning_rate': 1.4677966101694916e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [4:10:36<1:38:21,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [4:10:39<1:39:02,  3.43s/it]                                                       {'loss': 0.1579, 'grad_norm': 8.074957847595215, 'learning_rate': 1.4669491525423729e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [4:10:39<1:39:02,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [4:10:43<1:40:51,  3.50s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03203711658716202, 'learning_rate': 1.4661016949152542e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [4:10:43<1:40:51,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [4:10:47<1:43:56,  3.61s/it]                                                       {'loss': 0.0318, 'grad_norm': 2.7915830612182617, 'learning_rate': 1.4652542372881356e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [4:10:47<1:43:56,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [4:10:50<1:42:04,  3.54s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.8994349837303162, 'learning_rate': 1.464406779661017e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [4:10:50<1:42:04,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [4:10:54<1:41:00,  3.51s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.01795320212841034, 'learning_rate': 1.4635593220338984e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [4:10:54<1:41:00,  3.51s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [4:10:57<1:39:19,  3.45s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6940420269966125, 'learning_rate': 1.4627118644067797e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [4:10:57<1:39:19,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [4:11:00<1:40:41,  3.50s/it]                                                       {'loss': 0.1376, 'grad_norm': 5.958740711212158, 'learning_rate': 1.4618644067796612e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [4:11:00<1:40:41,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [4:11:04<1:40:14,  3.49s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.3964996337890625, 'learning_rate': 1.4610169491525425e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [4:11:04<1:40:14,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [4:11:08<1:44:38,  3.64s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.5643255710601807, 'learning_rate': 1.4601694915254238e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [4:11:08<1:44:38,  3.64s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [4:11:12<1:45:48,  3.69s/it]                                                       {'loss': 0.1364, 'grad_norm': 8.413947105407715, 'learning_rate': 1.4593220338983052e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [4:11:12<1:45:48,  3.69s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [4:11:15<1:43:08,  3.60s/it]                                                       {'loss': 0.0205, 'grad_norm': 3.0337560176849365, 'learning_rate': 1.4584745762711865e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [4:11:15<1:43:08,  3.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [4:11:19<1:41:42,  3.55s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06629639863967896, 'learning_rate': 1.457627118644068e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [4:11:19<1:41:42,  3.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [4:11:22<1:39:47,  3.48s/it]                                                       {'loss': 0.2471, 'grad_norm': 10.169198036193848, 'learning_rate': 1.4567796610169493e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [4:11:22<1:39:47,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [4:11:25<1:38:38,  3.44s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.5944653749465942, 'learning_rate': 1.4559322033898306e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [4:11:25<1:38:38,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [4:11:29<1:38:21,  3.44s/it]                                                       {'loss': 0.0148, 'grad_norm': 1.858403205871582, 'learning_rate': 1.455084745762712e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [4:11:29<1:38:21,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [4:11:33<1:42:25,  3.58s/it]                                                       {'loss': 0.0815, 'grad_norm': 6.098756790161133, 'learning_rate': 1.4542372881355933e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [4:11:33<1:42:25,  3.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [4:11:36<1:39:58,  3.50s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.558725118637085, 'learning_rate': 1.4533898305084748e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [4:11:36<1:39:58,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [4:11:39<1:40:54,  3.53s/it]                                                       {'loss': 0.0549, 'grad_norm': 6.054725170135498, 'learning_rate': 1.4525423728813561e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [4:11:39<1:40:54,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [4:11:43<1:39:25,  3.48s/it]                                                       {'loss': 0.0297, 'grad_norm': 4.253343105316162, 'learning_rate': 1.4516949152542372e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [4:11:43<1:39:25,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [4:11:46<1:38:18,  3.45s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.21492600440979004, 'learning_rate': 1.4508474576271185e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [4:11:46<1:38:18,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [4:11:50<1:37:24,  3.42s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.7961365580558777, 'learning_rate': 1.45e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [4:11:50<1:37:24,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [4:11:53<1:36:43,  3.39s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.8332080841064453, 'learning_rate': 1.4491525423728813e-05, 'epoch': 0.71}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [4:11:53<1:36:43,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [4:11:56<1:36:35,  3.39s/it]                                                       {'loss': 0.0198, 'grad_norm': 1.7078063488006592, 'learning_rate': 1.4483050847457628e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [4:11:56<1:36:35,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [4:12:00<1:35:58,  3.37s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.4418565034866333, 'learning_rate': 1.447457627118644e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [4:12:00<1:35:58,  3.37s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [4:12:03<1:37:38,  3.43s/it]                                                       {'loss': 0.0457, 'grad_norm': 5.009456157684326, 'learning_rate': 1.4466101694915254e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [4:12:03<1:37:38,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [4:12:07<1:37:00,  3.41s/it]                                                       {'loss': 0.0221, 'grad_norm': 3.7681610584259033, 'learning_rate': 1.4457627118644068e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [4:12:07<1:37:00,  3.41s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [4:12:10<1:36:32,  3.40s/it]                                                       {'loss': 0.0904, 'grad_norm': 6.073605060577393, 'learning_rate': 1.4449152542372881e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [4:12:10<1:36:32,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [4:12:14<1:39:21,  3.50s/it]                                                       {'loss': 0.3964, 'grad_norm': 9.914353370666504, 'learning_rate': 1.4440677966101696e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [4:12:14<1:39:21,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [4:12:17<1:38:46,  3.48s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.15408988296985626, 'learning_rate': 1.4432203389830509e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [4:12:17<1:38:46,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [4:12:21<1:42:17,  3.61s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.674243450164795, 'learning_rate': 1.4423728813559324e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [4:12:21<1:42:17,  3.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [4:12:24<1:40:02,  3.53s/it]                                                       {'loss': 0.005, 'grad_norm': 0.5056096911430359, 'learning_rate': 1.4415254237288137e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [4:12:24<1:40:02,  3.53s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [4:12:28<1:38:48,  3.49s/it]                                                       {'loss': 0.0481, 'grad_norm': 3.4547886848449707, 'learning_rate': 1.440677966101695e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [4:12:28<1:38:48,  3.49s/it][2025-10-20 03:49:33,036] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [4:12:33<1:57:01,  4.13s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.6262432336807251, 'learning_rate': 1.4398305084745764e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [4:12:33<1:57:01,  4.13s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [4:12:37<1:50:17,  3.90s/it]                                                       {'loss': 0.0038, 'grad_norm': 1.0452452898025513, 'learning_rate': 1.4389830508474577e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [4:12:37<1:50:17,  3.90s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [4:12:40<1:45:43,  3.74s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.9658104181289673, 'learning_rate': 1.4381355932203392e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [4:12:40<1:45:43,  3.74s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [4:12:44<1:46:07,  3.75s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3271166980266571, 'learning_rate': 1.4372881355932205e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [4:12:44<1:46:07,  3.75s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [4:12:47<1:42:52,  3.64s/it]                                                       {'loss': 0.1163, 'grad_norm': 7.365200519561768, 'learning_rate': 1.4364406779661018e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [4:12:47<1:42:52,  3.64s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [4:12:51<1:44:54,  3.72s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.23293817043304443, 'learning_rate': 1.4355932203389833e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [4:12:51<1:44:54,  3.72s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [4:12:54<1:41:27,  3.60s/it]                                                       {'loss': 0.0217, 'grad_norm': 1.888365626335144, 'learning_rate': 1.4347457627118644e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [4:12:54<1:41:27,  3.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [4:12:58<1:40:00,  3.55s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.2657705545425415, 'learning_rate': 1.4338983050847457e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [4:12:58<1:40:00,  3.55s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [4:13:01<1:38:13,  3.49s/it]                                                       {'loss': 0.0797, 'grad_norm': 3.451153039932251, 'learning_rate': 1.4330508474576272e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [4:13:01<1:38:13,  3.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [4:13:05<1:36:45,  3.43s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5945641398429871, 'learning_rate': 1.4322033898305085e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [4:13:05<1:36:45,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [4:13:08<1:37:03,  3.45s/it]                                                       {'loss': 0.4304, 'grad_norm': 10.63486385345459, 'learning_rate': 1.4313559322033898e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [4:13:08<1:37:03,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [4:13:12<1:38:45,  3.51s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.3792628347873688, 'learning_rate': 1.4305084745762712e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [4:13:12<1:38:45,  3.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [4:13:15<1:37:16,  3.46s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.65726637840271, 'learning_rate': 1.4296610169491525e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [4:13:15<1:37:16,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [4:13:18<1:36:06,  3.42s/it]                                                       {'loss': 0.0647, 'grad_norm': 6.966577529907227, 'learning_rate': 1.428813559322034e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [4:13:18<1:36:06,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [4:13:22<1:41:08,  3.60s/it]                                                       {'loss': 0.0632, 'grad_norm': 4.363656520843506, 'learning_rate': 1.4279661016949153e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [4:13:22<1:41:08,  3.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [4:13:26<1:41:24,  3.61s/it]                                                       {'loss': 0.0905, 'grad_norm': 5.796674728393555, 'learning_rate': 1.4271186440677966e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [4:13:26<1:41:24,  3.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [4:13:29<1:39:51,  3.56s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.39030545949935913, 'learning_rate': 1.426271186440678e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [4:13:29<1:39:51,  3.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [4:13:33<1:38:31,  3.51s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3019430637359619, 'learning_rate': 1.4254237288135593e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [4:13:33<1:38:31,  3.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [4:13:36<1:37:24,  3.48s/it]                                                       {'loss': 0.0915, 'grad_norm': 8.864180564880371, 'learning_rate': 1.4245762711864408e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [4:13:36<1:37:24,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [4:13:40<1:36:29,  3.45s/it]                                                       {'loss': 0.1718, 'grad_norm': 8.498090744018555, 'learning_rate': 1.4237288135593221e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [4:13:40<1:36:29,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [4:13:43<1:37:51,  3.50s/it]                                                       {'loss': 0.1327, 'grad_norm': 7.9268999099731445, 'learning_rate': 1.4228813559322036e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [4:13:43<1:37:51,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [4:13:47<1:37:27,  3.49s/it]                                                       {'loss': 0.0986, 'grad_norm': 4.638864040374756, 'learning_rate': 1.4220338983050849e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [4:13:47<1:37:27,  3.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [4:13:50<1:36:22,  3.45s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6789448261260986, 'learning_rate': 1.4211864406779662e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [4:13:50<1:36:22,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [4:13:53<1:35:39,  3.42s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.6309529542922974, 'learning_rate': 1.4203389830508476e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [4:13:53<1:35:39,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [4:13:57<1:36:36,  3.46s/it]                                                       {'loss': 0.0493, 'grad_norm': 5.335835933685303, 'learning_rate': 1.419491525423729e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [4:13:57<1:36:36,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [4:14:01<1:38:52,  3.54s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05294707417488098, 'learning_rate': 1.4186440677966104e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [4:14:01<1:38:52,  3.54s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [4:14:04<1:37:50,  3.51s/it]                                                       {'loss': 0.0585, 'grad_norm': 4.101824760437012, 'learning_rate': 1.4177966101694917e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [4:14:04<1:37:50,  3.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [4:14:08<1:36:41,  3.47s/it]                                                       {'loss': 0.0197, 'grad_norm': 3.0584053993225098, 'learning_rate': 1.4169491525423728e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [4:14:08<1:36:41,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [4:14:11<1:35:47,  3.44s/it]                                                       {'loss': 0.115, 'grad_norm': 4.522175312042236, 'learning_rate': 1.4161016949152541e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [4:14:11<1:35:47,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [4:14:14<1:35:08,  3.42s/it]                                                       {'loss': 0.0199, 'grad_norm': 2.070720911026001, 'learning_rate': 1.4152542372881356e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [4:14:14<1:35:08,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [4:14:18<1:38:14,  3.53s/it]                                                       {'loss': 0.0615, 'grad_norm': 5.036050319671631, 'learning_rate': 1.4144067796610169e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [4:14:18<1:38:14,  3.53s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [4:14:21<1:36:38,  3.48s/it]                                                       {'loss': 0.0677, 'grad_norm': 5.084066390991211, 'learning_rate': 1.4135593220338984e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [4:14:21<1:36:38,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [4:14:25<1:37:34,  3.51s/it]                                                       {'loss': 0.0209, 'grad_norm': 2.8805956840515137, 'learning_rate': 1.4127118644067797e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [4:14:25<1:37:34,  3.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [4:14:28<1:37:08,  3.50s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.5337881445884705, 'learning_rate': 1.411864406779661e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [4:14:28<1:37:08,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [4:14:32<1:36:46,  3.49s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.9323019981384277, 'learning_rate': 1.4110169491525424e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [4:14:32<1:36:46,  3.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [4:14:35<1:35:33,  3.45s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.8779733180999756, 'learning_rate': 1.4101694915254237e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [4:14:35<1:35:33,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [4:14:39<1:35:54,  3.46s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.4008053541183472, 'learning_rate': 1.4093220338983052e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [4:14:39<1:35:54,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [4:14:42<1:35:14,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02570096217095852, 'learning_rate': 1.4084745762711865e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [4:14:42<1:35:14,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [4:14:46<1:34:52,  3.43s/it]                                                       {'loss': 0.0848, 'grad_norm': 6.9312262535095215, 'learning_rate': 1.407627118644068e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [4:14:46<1:34:52,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [4:14:49<1:34:15,  3.41s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.616275429725647, 'learning_rate': 1.4067796610169493e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [4:14:49<1:34:15,  3.41s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [4:14:52<1:34:46,  3.43s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.0835720300674438, 'learning_rate': 1.4059322033898306e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [4:14:52<1:34:46,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [4:14:56<1:34:55,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04980998858809471, 'learning_rate': 1.405084745762712e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [4:14:56<1:34:55,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [4:14:59<1:35:14,  3.45s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.5866206288337708, 'learning_rate': 1.4042372881355933e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [4:14:59<1:35:14,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [4:15:03<1:34:52,  3.44s/it]                                                       {'loss': 0.0993, 'grad_norm': 5.76617956161499, 'learning_rate': 1.4033898305084748e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [4:15:03<1:34:52,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [4:15:06<1:35:11,  3.45s/it]                                                       {'loss': 0.0966, 'grad_norm': 6.102910995483398, 'learning_rate': 1.4025423728813561e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [4:15:06<1:35:11,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [4:15:10<1:35:05,  3.45s/it]                                                       {'loss': 0.0275, 'grad_norm': 5.222344875335693, 'learning_rate': 1.4016949152542374e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [4:15:10<1:35:05,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [4:15:13<1:34:32,  3.43s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.9975006580352783, 'learning_rate': 1.4008474576271189e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [4:15:13<1:34:32,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [4:15:17<1:37:22,  3.54s/it]                                                       {'loss': 0.0174, 'grad_norm': 3.2843830585479736, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [4:15:17<1:37:22,  3.54s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [4:15:20<1:35:41,  3.48s/it]                                                       {'loss': 0.0408, 'grad_norm': 5.216535568237305, 'learning_rate': 1.3991525423728813e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [4:15:20<1:35:41,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [4:15:24<1:35:28,  3.47s/it]                                                       {'loss': 0.0327, 'grad_norm': 3.4305484294891357, 'learning_rate': 1.3983050847457627e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [4:15:24<1:35:28,  3.47s/it][2025-10-20 03:52:28,941] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [4:15:29<1:53:06,  4.12s/it]                                                       {'loss': 0.1326, 'grad_norm': 9.220473289489746, 'learning_rate': 1.397457627118644e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [4:15:29<1:53:06,  4.12s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [4:15:33<1:48:05,  3.94s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.7130277156829834, 'learning_rate': 1.3966101694915253e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [4:15:33<1:48:05,  3.94s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [4:15:36<1:43:23,  3.77s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.776179313659668, 'learning_rate': 1.3957627118644068e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [4:15:36<1:43:23,  3.77s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [4:15:40<1:40:16,  3.66s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.1703091859817505, 'learning_rate': 1.3949152542372881e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [4:15:40<1:40:16,  3.66s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [4:15:43<1:37:35,  3.56s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04203088954091072, 'learning_rate': 1.3940677966101696e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [4:15:43<1:37:35,  3.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [4:15:47<1:39:53,  3.65s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05246620625257492, 'learning_rate': 1.3932203389830509e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [4:15:47<1:39:53,  3.65s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [4:15:50<1:37:53,  3.58s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08193518966436386, 'learning_rate': 1.3923728813559322e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [4:15:50<1:37:53,  3.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [4:15:53<1:36:09,  3.51s/it]                                                       {'loss': 0.4194, 'grad_norm': 7.897434234619141, 'learning_rate': 1.3915254237288136e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [4:15:53<1:36:09,  3.51s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [4:15:57<1:34:45,  3.46s/it]                                                       {'loss': 0.0726, 'grad_norm': 5.1467814445495605, 'learning_rate': 1.390677966101695e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [4:15:57<1:34:45,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [4:16:00<1:35:30,  3.49s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.4232213497161865, 'learning_rate': 1.3898305084745764e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [4:16:00<1:35:30,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [4:16:04<1:34:16,  3.45s/it]                                                       {'loss': 0.0352, 'grad_norm': 5.16579532623291, 'learning_rate': 1.3889830508474577e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [4:16:04<1:34:16,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [4:16:07<1:33:50,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.052045874297618866, 'learning_rate': 1.3881355932203392e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [4:16:07<1:33:50,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [4:16:11<1:34:40,  3.47s/it]                                                       {'loss': 0.1161, 'grad_norm': 5.88140344619751, 'learning_rate': 1.3872881355932205e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [4:16:11<1:34:40,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [4:16:14<1:34:33,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.280800461769104, 'learning_rate': 1.3864406779661018e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [4:16:14<1:34:33,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [4:16:18<1:33:45,  3.44s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.5795761942863464, 'learning_rate': 1.3855932203389832e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [4:16:18<1:33:45,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [4:16:21<1:33:09,  3.42s/it]                                                       {'loss': 0.019, 'grad_norm': 2.021514415740967, 'learning_rate': 1.3847457627118645e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [4:16:21<1:33:09,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [4:16:24<1:32:51,  3.41s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.16338202357292175, 'learning_rate': 1.383898305084746e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [4:16:24<1:32:51,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [4:16:28<1:32:30,  3.40s/it]                                                       {'loss': 0.0924, 'grad_norm': 5.423367500305176, 'learning_rate': 1.3830508474576273e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [4:16:28<1:32:30,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [4:16:31<1:32:36,  3.41s/it]                                                       {'loss': 0.1434, 'grad_norm': 5.377054214477539, 'learning_rate': 1.3822033898305086e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [4:16:31<1:32:36,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [4:16:35<1:32:48,  3.42s/it]                                                       {'loss': 0.3089, 'grad_norm': 9.496516227722168, 'learning_rate': 1.3813559322033897e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [4:16:35<1:32:48,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [4:16:38<1:32:44,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.18502993881702423, 'learning_rate': 1.3805084745762712e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [4:16:38<1:32:44,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [4:16:41<1:32:28,  3.41s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.712242066860199, 'learning_rate': 1.3796610169491525e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [4:16:41<1:32:28,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [4:16:45<1:33:52,  3.46s/it]                                                       {'loss': 0.0159, 'grad_norm': 1.583133578300476, 'learning_rate': 1.378813559322034e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [4:16:45<1:33:52,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [4:16:48<1:33:57,  3.47s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.8428611159324646, 'learning_rate': 1.3779661016949153e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [4:16:48<1:33:57,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [4:16:52<1:33:08,  3.44s/it]                                                       {'loss': 0.0563, 'grad_norm': 6.811554908752441, 'learning_rate': 1.3771186440677965e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [4:16:52<1:33:08,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [4:16:55<1:33:55,  3.47s/it]                                                       {'loss': 0.0446, 'grad_norm': 3.212252140045166, 'learning_rate': 1.376271186440678e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [4:16:55<1:33:55,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [4:16:59<1:35:00,  3.51s/it]                                                       {'loss': 0.0344, 'grad_norm': 2.738698959350586, 'learning_rate': 1.3754237288135593e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [4:16:59<1:35:00,  3.51s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [4:17:02<1:34:02,  3.48s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.5378431081771851, 'learning_rate': 1.3745762711864408e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [4:17:02<1:34:02,  3.48s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [4:17:06<1:33:43,  3.47s/it]                                                       {'loss': 0.0469, 'grad_norm': 3.89731764793396, 'learning_rate': 1.373728813559322e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [4:17:06<1:33:43,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [4:17:09<1:32:08,  3.41s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5149351954460144, 'learning_rate': 1.3728813559322034e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [4:17:09<1:32:08,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [4:17:12<1:31:44,  3.40s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.7326738834381104, 'learning_rate': 1.3720338983050848e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [4:17:12<1:31:44,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [4:17:16<1:31:25,  3.39s/it]                                                       {'loss': 0.1747, 'grad_norm': 7.65735387802124, 'learning_rate': 1.3711864406779661e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [4:17:16<1:31:25,  3.39s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [4:17:19<1:32:33,  3.43s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07480095326900482, 'learning_rate': 1.3703389830508476e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [4:17:19<1:32:33,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [4:17:23<1:32:15,  3.43s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.8488116264343262, 'learning_rate': 1.3694915254237289e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [4:17:23<1:32:15,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [4:17:26<1:31:33,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.005658826790750027, 'learning_rate': 1.3686440677966104e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [4:17:26<1:31:33,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [4:17:30<1:37:06,  3.61s/it]                                                       {'loss': 0.0785, 'grad_norm': 8.15146541595459, 'learning_rate': 1.3677966101694917e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [4:17:30<1:37:06,  3.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [4:17:34<1:35:23,  3.55s/it]                                                       {'loss': 0.0225, 'grad_norm': 2.656224250793457, 'learning_rate': 1.366949152542373e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [4:17:34<1:35:23,  3.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [4:17:37<1:34:33,  3.52s/it]                                                       {'loss': 0.0892, 'grad_norm': 9.706080436706543, 'learning_rate': 1.3661016949152544e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [4:17:37<1:34:33,  3.52s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [4:17:41<1:37:33,  3.63s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.6681511402130127, 'learning_rate': 1.3652542372881357e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [4:17:41<1:37:33,  3.63s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [4:17:44<1:36:34,  3.60s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012849144637584686, 'learning_rate': 1.3644067796610169e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [4:17:44<1:36:34,  3.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [4:17:48<1:35:47,  3.57s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02281726337969303, 'learning_rate': 1.3635593220338982e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [4:17:48<1:35:47,  3.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [4:17:51<1:35:06,  3.55s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1709292232990265, 'learning_rate': 1.3627118644067796e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [4:17:51<1:35:06,  3.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [4:17:55<1:33:22,  3.49s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.5128241777420044, 'learning_rate': 1.361864406779661e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [4:17:55<1:33:22,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [4:17:58<1:31:57,  3.44s/it]                                                       {'loss': 0.0726, 'grad_norm': 7.354517936706543, 'learning_rate': 1.3610169491525424e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [4:17:58<1:31:57,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [4:18:01<1:30:43,  3.39s/it]                                                       {'loss': 0.246, 'grad_norm': 9.508075714111328, 'learning_rate': 1.3601694915254237e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [4:18:01<1:30:43,  3.39s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [4:18:05<1:29:55,  3.36s/it]                                                       {'loss': 0.0253, 'grad_norm': 2.279675245285034, 'learning_rate': 1.3593220338983052e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [4:18:05<1:29:55,  3.36s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [4:18:09<1:33:31,  3.50s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.3219357132911682, 'learning_rate': 1.3584745762711865e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [4:18:09<1:33:31,  3.50s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [4:18:12<1:31:56,  3.44s/it]                                                       {'loss': 0.0978, 'grad_norm': 5.025259494781494, 'learning_rate': 1.3576271186440678e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [4:18:12<1:31:56,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [4:18:15<1:31:24,  3.43s/it]                                                       {'loss': 0.2116, 'grad_norm': 8.586977005004883, 'learning_rate': 1.3567796610169492e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [4:18:15<1:31:24,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [4:18:19<1:31:05,  3.42s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.0938035175204277, 'learning_rate': 1.3559322033898305e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [4:18:19<1:31:05,  3.42s/it][2025-10-20 03:55:23,950] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [4:18:24<1:48:22,  4.07s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.336679607629776, 'learning_rate': 1.355084745762712e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [4:18:24<1:48:22,  4.07s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [4:18:28<1:42:55,  3.86s/it]                                                       {'loss': 0.0545, 'grad_norm': 5.6207661628723145, 'learning_rate': 1.3542372881355933e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [4:18:28<1:42:55,  3.86s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [4:18:31<1:39:21,  3.73s/it]                                                       {'loss': 0.0385, 'grad_norm': 3.2352383136749268, 'learning_rate': 1.3533898305084748e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [4:18:31<1:39:21,  3.73s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [4:18:34<1:37:07,  3.65s/it]                                                       {'loss': 0.046, 'grad_norm': 3.173771619796753, 'learning_rate': 1.352542372881356e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [4:18:34<1:37:07,  3.65s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [4:18:38<1:35:29,  3.59s/it]                                                       {'loss': 0.0175, 'grad_norm': 1.425418496131897, 'learning_rate': 1.3516949152542374e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [4:18:38<1:35:29,  3.59s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [4:18:41<1:33:20,  3.51s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.7592296600341797, 'learning_rate': 1.3508474576271188e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [4:18:41<1:33:20,  3.51s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [4:18:45<1:32:33,  3.49s/it]                                                       {'loss': 0.0348, 'grad_norm': 4.227117538452148, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [4:18:45<1:32:33,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [4:18:48<1:31:08,  3.43s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0806037187576294, 'learning_rate': 1.3491525423728816e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [4:18:48<1:31:08,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [4:18:51<1:30:30,  3.41s/it]                                                       {'loss': 0.022, 'grad_norm': 2.9847588539123535, 'learning_rate': 1.3483050847457629e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [4:18:51<1:30:30,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [4:18:55<1:29:22,  3.37s/it]                                                       {'loss': 0.0816, 'grad_norm': 6.817488193511963, 'learning_rate': 1.3474576271186442e-05, 'epoch': 0.73}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [4:18:55<1:29:22,  3.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [4:18:58<1:29:33,  3.38s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.7995386123657227, 'learning_rate': 1.3466101694915253e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [4:18:58<1:29:33,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [4:19:01<1:28:48,  3.36s/it]                                                       {'loss': 0.0443, 'grad_norm': 1.987992763519287, 'learning_rate': 1.3457627118644068e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [4:19:01<1:28:48,  3.36s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [4:19:05<1:29:17,  3.38s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.5705702304840088, 'learning_rate': 1.344915254237288e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [4:19:05<1:29:17,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [4:19:08<1:30:57,  3.44s/it]                                                       {'loss': 0.01, 'grad_norm': 1.5957825183868408, 'learning_rate': 1.3440677966101695e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [4:19:08<1:30:57,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [4:19:12<1:30:27,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03953059762716293, 'learning_rate': 1.3432203389830508e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [4:19:12<1:30:27,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [4:19:15<1:30:09,  3.41s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.34524112939834595, 'learning_rate': 1.3423728813559321e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [4:19:15<1:30:09,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [4:19:19<1:32:51,  3.52s/it]                                                       {'loss': 0.2981, 'grad_norm': 12.114246368408203, 'learning_rate': 1.3415254237288136e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [4:19:19<1:32:51,  3.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [4:19:22<1:31:40,  3.48s/it]                                                       {'loss': 0.0515, 'grad_norm': 7.115189552307129, 'learning_rate': 1.3406779661016949e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [4:19:22<1:31:40,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [4:19:26<1:30:26,  3.43s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.32201722264289856, 'learning_rate': 1.3398305084745764e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [4:19:26<1:30:26,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [4:19:29<1:29:31,  3.40s/it]                                                       {'loss': 0.0, 'grad_norm': 0.004547862336039543, 'learning_rate': 1.3389830508474577e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [4:19:29<1:29:31,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [4:19:32<1:28:41,  3.37s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0743950828909874, 'learning_rate': 1.338135593220339e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [4:19:32<1:28:41,  3.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [4:19:36<1:29:16,  3.39s/it]                                                       {'loss': 0.002, 'grad_norm': 0.29457277059555054, 'learning_rate': 1.3372881355932204e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [4:19:36<1:29:16,  3.39s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [4:19:39<1:28:49,  3.38s/it]                                                       {'loss': 0.119, 'grad_norm': 7.259287357330322, 'learning_rate': 1.3364406779661017e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [4:19:39<1:28:49,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [4:19:43<1:33:14,  3.55s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.030220281332731247, 'learning_rate': 1.3355932203389832e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [4:19:43<1:33:14,  3.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [4:19:46<1:31:17,  3.48s/it]                                                       {'loss': 0.2711, 'grad_norm': 6.035621166229248, 'learning_rate': 1.3347457627118645e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [4:19:46<1:31:17,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [4:19:50<1:30:13,  3.44s/it]                                                       {'loss': 0.0502, 'grad_norm': 5.8329901695251465, 'learning_rate': 1.333898305084746e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [4:19:50<1:30:13,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [4:19:53<1:30:11,  3.44s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.010713722556829453, 'learning_rate': 1.3330508474576273e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [4:19:53<1:30:11,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [4:19:56<1:29:33,  3.42s/it]                                                       {'loss': 0.0157, 'grad_norm': 0.906251847743988, 'learning_rate': 1.3322033898305086e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [4:19:56<1:29:33,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [4:20:00<1:29:01,  3.40s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.6021495461463928, 'learning_rate': 1.33135593220339e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [4:20:00<1:29:01,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [4:20:03<1:28:25,  3.38s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.06494463980197906, 'learning_rate': 1.3305084745762713e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [4:20:03<1:28:25,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [4:20:07<1:29:41,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.2094719409942627, 'learning_rate': 1.3296610169491528e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [4:20:07<1:29:41,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [4:20:10<1:28:52,  3.40s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.51532244682312, 'learning_rate': 1.3288135593220338e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [4:20:10<1:28:52,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [4:20:13<1:29:00,  3.41s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.9436041712760925, 'learning_rate': 1.3279661016949152e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [4:20:13<1:29:00,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [4:20:17<1:28:52,  3.41s/it]                                                       {'loss': 0.004, 'grad_norm': 0.37856990098953247, 'learning_rate': 1.3271186440677965e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [4:20:17<1:28:52,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [4:20:20<1:28:12,  3.38s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.16867344081401825, 'learning_rate': 1.326271186440678e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [4:20:20<1:28:12,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [4:20:24<1:27:50,  3.37s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.442218154668808, 'learning_rate': 1.3254237288135593e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [4:20:24<1:27:50,  3.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [4:20:27<1:29:03,  3.42s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.6383333206176758, 'learning_rate': 1.3245762711864408e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [4:20:27<1:29:03,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [4:20:30<1:28:21,  3.39s/it]                                                       {'loss': 0.0424, 'grad_norm': 3.847628355026245, 'learning_rate': 1.323728813559322e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [4:20:30<1:28:21,  3.39s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [4:20:34<1:31:13,  3.51s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.447252869606018, 'learning_rate': 1.3228813559322033e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [4:20:34<1:31:13,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [4:20:38<1:30:04,  3.46s/it]                                                       {'loss': 0.1045, 'grad_norm': 6.215408802032471, 'learning_rate': 1.3220338983050848e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [4:20:38<1:30:04,  3.46s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [4:20:41<1:29:11,  3.43s/it]                                                       {'loss': 0.0357, 'grad_norm': 3.374826669692993, 'learning_rate': 1.3211864406779661e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [4:20:41<1:29:11,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [4:20:44<1:29:23,  3.44s/it]                                                       {'loss': 0.0599, 'grad_norm': 6.4896135330200195, 'learning_rate': 1.3203389830508476e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [4:20:44<1:29:23,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [4:20:48<1:29:51,  3.46s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2303171455860138, 'learning_rate': 1.3194915254237289e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [4:20:48<1:29:51,  3.46s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [4:20:51<1:29:08,  3.44s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.7443556785583496, 'learning_rate': 1.3186440677966102e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [4:20:51<1:29:08,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [4:20:55<1:29:01,  3.43s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.6144486665725708, 'learning_rate': 1.3177966101694916e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [4:20:55<1:29:01,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [4:20:58<1:31:20,  3.53s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.5869083404541016, 'learning_rate': 1.316949152542373e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [4:20:58<1:31:20,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [4:21:02<1:30:33,  3.50s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.7688512802124023, 'learning_rate': 1.3161016949152544e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [4:21:02<1:30:33,  3.50s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [4:21:05<1:29:38,  3.47s/it]                                                       {'loss': 0.0636, 'grad_norm': 2.2540416717529297, 'learning_rate': 1.3152542372881357e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [4:21:05<1:29:38,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [4:21:09<1:28:54,  3.44s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.0821834802627563, 'learning_rate': 1.3144067796610172e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [4:21:09<1:28:54,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [4:21:12<1:29:17,  3.46s/it]                                                       {'loss': 0.011, 'grad_norm': 1.691367745399475, 'learning_rate': 1.3135593220338985e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [4:21:12<1:29:17,  3.46s/it][2025-10-20 03:58:17,410] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [4:21:19<1:52:50,  4.37s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05234909802675247, 'learning_rate': 1.3127118644067798e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [4:21:19<1:52:50,  4.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [4:21:22<1:45:13,  4.08s/it]                                                       {'loss': 0.2994, 'grad_norm': 10.997650146484375, 'learning_rate': 1.3118644067796612e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [4:21:22<1:45:13,  4.08s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [4:21:26<1:43:31,  4.02s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.864931344985962, 'learning_rate': 1.3110169491525424e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [4:21:26<1:43:31,  4.02s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [4:21:29<1:38:39,  3.83s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.159273147583008, 'learning_rate': 1.3101694915254237e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [4:21:29<1:38:39,  3.83s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [4:21:33<1:35:05,  3.69s/it]                                                       {'loss': 0.0261, 'grad_norm': 2.117647647857666, 'learning_rate': 1.309322033898305e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [4:21:33<1:35:05,  3.69s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [4:21:36<1:32:50,  3.61s/it]                                                       {'loss': 0.005, 'grad_norm': 1.3260418176651, 'learning_rate': 1.3084745762711864e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [4:21:36<1:32:50,  3.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [4:21:39<1:31:34,  3.56s/it]                                                       {'loss': 0.0327, 'grad_norm': 2.2347123622894287, 'learning_rate': 1.3076271186440677e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [4:21:39<1:31:34,  3.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [4:21:43<1:30:06,  3.51s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.332749605178833, 'learning_rate': 1.3067796610169492e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [4:21:43<1:30:06,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [4:21:47<1:32:48,  3.61s/it]                                                       {'loss': 0.0162, 'grad_norm': 6.231738567352295, 'learning_rate': 1.3059322033898305e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [4:21:47<1:32:48,  3.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [4:21:50<1:30:30,  3.53s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.22809475660324097, 'learning_rate': 1.305084745762712e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [4:21:50<1:30:30,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [4:21:54<1:32:55,  3.62s/it]                                                       {'loss': 0.0318, 'grad_norm': 2.992384672164917, 'learning_rate': 1.3042372881355933e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [4:21:54<1:32:55,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [4:21:57<1:32:33,  3.61s/it]                                                       {'loss': 0.0656, 'grad_norm': 5.868546009063721, 'learning_rate': 1.3033898305084746e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [4:21:57<1:32:33,  3.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [4:22:01<1:33:07,  3.64s/it]                                                       {'loss': 0.1463, 'grad_norm': 7.917872905731201, 'learning_rate': 1.302542372881356e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [4:22:01<1:33:07,  3.64s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [4:22:05<1:31:29,  3.57s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.23373092710971832, 'learning_rate': 1.3016949152542373e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [4:22:05<1:31:29,  3.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [4:22:08<1:30:22,  3.53s/it]                                                       {'loss': 0.0521, 'grad_norm': 8.977113723754883, 'learning_rate': 1.3008474576271188e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [4:22:08<1:30:22,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [4:22:12<1:29:55,  3.52s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6654066443443298, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [4:22:12<1:29:55,  3.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [4:22:15<1:32:28,  3.62s/it]                                                       {'loss': 0.0626, 'grad_norm': 6.539743423461914, 'learning_rate': 1.2991525423728816e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [4:22:15<1:32:28,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [4:22:19<1:30:33,  3.55s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04925287142395973, 'learning_rate': 1.2983050847457629e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [4:22:19<1:30:33,  3.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [4:22:22<1:28:41,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.032067764550447464, 'learning_rate': 1.2974576271186442e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [4:22:22<1:28:41,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [4:22:25<1:27:15,  3.42s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.37973499298095703, 'learning_rate': 1.2966101694915256e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [4:22:25<1:27:15,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [4:22:29<1:27:16,  3.43s/it]                                                       {'loss': 0.1135, 'grad_norm': 8.374190330505371, 'learning_rate': 1.295762711864407e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [4:22:29<1:27:16,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [4:22:32<1:26:46,  3.41s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.9141894578933716, 'learning_rate': 1.2949152542372884e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [4:22:32<1:26:46,  3.41s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [4:22:36<1:26:54,  3.41s/it]                                                       {'loss': 0.062, 'grad_norm': 5.887660980224609, 'learning_rate': 1.2940677966101697e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [4:22:36<1:26:54,  3.41s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [4:22:39<1:26:42,  3.41s/it]                                                       {'loss': 0.1909, 'grad_norm': 7.841447353363037, 'learning_rate': 1.2932203389830508e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [4:22:39<1:26:42,  3.41s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [4:22:42<1:26:12,  3.39s/it]                                                       {'loss': 0.199, 'grad_norm': 6.753255367279053, 'learning_rate': 1.2923728813559321e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [4:22:42<1:26:12,  3.39s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [4:22:46<1:29:36,  3.53s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.305536150932312, 'learning_rate': 1.2915254237288136e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [4:22:46<1:29:36,  3.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [4:22:50<1:28:57,  3.50s/it]                                                       {'loss': 0.1459, 'grad_norm': 9.298937797546387, 'learning_rate': 1.2906779661016949e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [4:22:50<1:28:57,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [4:22:53<1:29:17,  3.52s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.4470857083797455, 'learning_rate': 1.2898305084745763e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [4:22:53<1:29:17,  3.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [4:22:57<1:34:51,  3.74s/it]                                                       {'loss': 0.0796, 'grad_norm': 6.416548728942871, 'learning_rate': 1.2889830508474576e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [4:22:57<1:34:51,  3.74s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [4:23:01<1:32:09,  3.64s/it]                                                       {'loss': 0.0143, 'grad_norm': 2.3585238456726074, 'learning_rate': 1.288135593220339e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [4:23:01<1:32:09,  3.64s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [4:23:04<1:29:46,  3.55s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.9702867865562439, 'learning_rate': 1.2872881355932204e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [4:23:04<1:29:46,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [4:23:08<1:29:38,  3.54s/it]                                                       {'loss': 0.0425, 'grad_norm': 5.265545845031738, 'learning_rate': 1.2864406779661017e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [4:23:08<1:29:38,  3.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [4:23:11<1:27:59,  3.48s/it]                                                       {'loss': 0.2112, 'grad_norm': 5.965429306030273, 'learning_rate': 1.2855932203389832e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [4:23:11<1:27:59,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [4:23:14<1:27:33,  3.47s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.5622549057006836, 'learning_rate': 1.2847457627118645e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [4:23:14<1:27:33,  3.47s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [4:23:18<1:29:53,  3.56s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0626617968082428, 'learning_rate': 1.2838983050847458e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [4:23:18<1:29:53,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [4:23:22<1:27:57,  3.49s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.1357967853546143, 'learning_rate': 1.2830508474576272e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [4:23:22<1:27:57,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [4:23:25<1:27:36,  3.47s/it]                                                       {'loss': 0.2181, 'grad_norm': 8.927450180053711, 'learning_rate': 1.2822033898305085e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [4:23:25<1:27:36,  3.47s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [4:23:28<1:26:55,  3.45s/it]                                                       {'loss': 0.0235, 'grad_norm': 2.4908251762390137, 'learning_rate': 1.28135593220339e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [4:23:28<1:26:55,  3.45s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [4:23:32<1:29:23,  3.55s/it]                                                       {'loss': 0.0676, 'grad_norm': 4.308617115020752, 'learning_rate': 1.2805084745762713e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [4:23:32<1:29:23,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [4:23:36<1:27:56,  3.49s/it]                                                       {'loss': 0.1504, 'grad_norm': 11.330794334411621, 'learning_rate': 1.2796610169491528e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [4:23:36<1:27:56,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [4:23:39<1:30:18,  3.59s/it]                                                       {'loss': 0.0, 'grad_norm': 0.007458216045051813, 'learning_rate': 1.278813559322034e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [4:23:39<1:30:18,  3.59s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [4:23:43<1:28:34,  3.52s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.3503692150115967, 'learning_rate': 1.2779661016949154e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [4:23:43<1:28:34,  3.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [4:23:46<1:27:36,  3.49s/it]                                                       {'loss': 0.0657, 'grad_norm': 6.698152542114258, 'learning_rate': 1.2771186440677968e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [4:23:46<1:27:36,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [4:23:50<1:27:59,  3.51s/it]                                                       {'loss': 0.0358, 'grad_norm': 4.695052623748779, 'learning_rate': 1.276271186440678e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [4:23:50<1:27:59,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [4:23:53<1:26:04,  3.43s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1365407109260559, 'learning_rate': 1.2754237288135593e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [4:23:53<1:26:04,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [4:23:56<1:25:53,  3.43s/it]                                                       {'loss': 0.0923, 'grad_norm': 5.69642448425293, 'learning_rate': 1.2745762711864406e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [4:23:56<1:25:53,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [4:24:00<1:25:07,  3.40s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.12793223559856415, 'learning_rate': 1.273728813559322e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [4:24:00<1:25:07,  3.40s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [4:24:03<1:24:29,  3.38s/it]                                                       {'loss': 0.0197, 'grad_norm': 2.4669950008392334, 'learning_rate': 1.2728813559322033e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [4:24:03<1:24:29,  3.38s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [4:24:06<1:24:29,  3.38s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.091747522354126, 'learning_rate': 1.2720338983050848e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [4:24:06<1:24:29,  3.38s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [4:24:10<1:24:14,  3.37s/it]                                                       {'loss': 0.0864, 'grad_norm': 6.345101833343506, 'learning_rate': 1.2711864406779661e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [4:24:10<1:24:14,  3.37s/it][2025-10-20 04:01:15,089] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [4:24:15<1:41:07,  4.05s/it]                                                       {'loss': 0.0325, 'grad_norm': 2.883939743041992, 'learning_rate': 1.2703389830508476e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [4:24:15<1:41:07,  4.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [4:24:19<1:38:39,  3.95s/it]                                                       {'loss': 0.3092, 'grad_norm': 12.62904167175293, 'learning_rate': 1.2694915254237289e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [4:24:19<1:38:39,  3.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [4:24:23<1:35:11,  3.82s/it]                                                       {'loss': 0.0721, 'grad_norm': 6.244080066680908, 'learning_rate': 1.2686440677966101e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [4:24:23<1:35:11,  3.82s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [4:24:26<1:31:44,  3.68s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3493722081184387, 'learning_rate': 1.2677966101694916e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [4:24:26<1:31:44,  3.68s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [4:24:29<1:29:16,  3.58s/it]                                                       {'loss': 0.0403, 'grad_norm': 5.770503997802734, 'learning_rate': 1.2669491525423729e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [4:24:29<1:29:16,  3.58s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [4:24:33<1:28:19,  3.55s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.36769920587539673, 'learning_rate': 1.2661016949152544e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [4:24:33<1:28:19,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [4:24:36<1:27:03,  3.50s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08686432242393494, 'learning_rate': 1.2652542372881357e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [4:24:36<1:27:03,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [4:24:40<1:26:59,  3.50s/it]                                                       {'loss': 0.052, 'grad_norm': 4.87555456161499, 'learning_rate': 1.264406779661017e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [4:24:40<1:26:59,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [4:24:43<1:26:42,  3.49s/it]                                                       {'loss': 0.222, 'grad_norm': 7.787018775939941, 'learning_rate': 1.2635593220338984e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [4:24:43<1:26:42,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [4:24:47<1:25:49,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14681528508663177, 'learning_rate': 1.2627118644067797e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [4:24:47<1:25:49,  3.46s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [4:24:50<1:25:25,  3.44s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.5455487966537476, 'learning_rate': 1.2618644067796612e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [4:24:50<1:25:25,  3.44s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [4:24:53<1:24:59,  3.43s/it]                                                       {'loss': 0.0209, 'grad_norm': 2.7766945362091064, 'learning_rate': 1.2610169491525425e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [4:24:53<1:24:59,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [4:24:57<1:28:14,  3.56s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.958808183670044, 'learning_rate': 1.260169491525424e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [4:24:57<1:28:14,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [4:25:01<1:26:15,  3.48s/it]                                                       {'loss': 0.057, 'grad_norm': 4.997366905212402, 'learning_rate': 1.2593220338983053e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [4:25:01<1:26:15,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [4:25:04<1:29:06,  3.60s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.467221200466156, 'learning_rate': 1.2584745762711864e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [4:25:04<1:29:06,  3.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [4:25:08<1:26:54,  3.51s/it]                                                       {'loss': 0.1277, 'grad_norm': 8.805547714233398, 'learning_rate': 1.2576271186440677e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [4:25:08<1:26:54,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [4:25:11<1:25:41,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011340727098286152, 'learning_rate': 1.2567796610169492e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [4:25:11<1:25:41,  3.47s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [4:25:15<1:26:05,  3.49s/it]                                                       {'loss': 0.011, 'grad_norm': 1.3625648021697998, 'learning_rate': 1.2559322033898305e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [4:25:15<1:26:05,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [4:25:18<1:26:22,  3.50s/it]                                                       {'loss': 0.1745, 'grad_norm': 5.954594612121582, 'learning_rate': 1.2550847457627118e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [4:25:18<1:26:22,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [4:25:22<1:29:58,  3.65s/it]                                                       {'loss': 0.0324, 'grad_norm': 4.742590427398682, 'learning_rate': 1.2542372881355932e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [4:25:22<1:29:58,  3.65s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [4:25:25<1:27:29,  3.55s/it]                                                       {'loss': 0.2422, 'grad_norm': 11.140268325805664, 'learning_rate': 1.2533898305084745e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [4:25:25<1:27:29,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [4:25:30<1:31:30,  3.71s/it]                                                       {'loss': 0.0559, 'grad_norm': 6.27256441116333, 'learning_rate': 1.252542372881356e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [4:25:30<1:31:30,  3.71s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [4:25:33<1:29:24,  3.63s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.6355844736099243, 'learning_rate': 1.2516949152542373e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [4:25:33<1:29:24,  3.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [4:25:38<1:36:15,  3.91s/it]                                                       {'loss': 0.091, 'grad_norm': 3.8933770656585693, 'learning_rate': 1.2508474576271188e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [4:25:38<1:36:15,  3.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [4:25:41<1:32:54,  3.78s/it]                                                       {'loss': 0.0749, 'grad_norm': 4.511592864990234, 'learning_rate': 1.25e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [4:25:41<1:32:54,  3.78s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [4:25:45<1:30:56,  3.70s/it]                                                       {'loss': 0.003, 'grad_norm': 0.40851330757141113, 'learning_rate': 1.2491525423728814e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [4:25:45<1:30:56,  3.70s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [4:25:49<1:38:05,  4.00s/it]                                                       {'loss': 0.1479, 'grad_norm': 8.892923355102539, 'learning_rate': 1.2483050847457628e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [4:25:49<1:38:05,  4.00s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [4:25:53<1:34:33,  3.85s/it]                                                       {'loss': 0.2727, 'grad_norm': 8.255538940429688, 'learning_rate': 1.2474576271186441e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [4:25:53<1:34:33,  3.85s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [4:25:56<1:31:13,  3.72s/it]                                                       {'loss': 0.2395, 'grad_norm': 9.44310188293457, 'learning_rate': 1.2466101694915256e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [4:25:56<1:31:13,  3.72s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [4:26:00<1:28:34,  3.62s/it]                                                       {'loss': 0.0352, 'grad_norm': 4.596212863922119, 'learning_rate': 1.2457627118644069e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [4:26:00<1:28:34,  3.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [4:26:03<1:27:19,  3.57s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.0262548923492432, 'learning_rate': 1.2449152542372882e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [4:26:03<1:27:19,  3.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [4:26:06<1:26:36,  3.54s/it]                                                       {'loss': 0.0834, 'grad_norm': 7.004795074462891, 'learning_rate': 1.2440677966101695e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [4:26:06<1:26:36,  3.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [4:26:10<1:25:01,  3.48s/it]                                                       {'loss': 0.0422, 'grad_norm': 5.534938335418701, 'learning_rate': 1.243220338983051e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [4:26:10<1:25:01,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [4:26:14<1:27:00,  3.56s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013859089463949203, 'learning_rate': 1.2423728813559323e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [4:26:14<1:27:00,  3.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [4:26:17<1:26:49,  3.56s/it]                                                       {'loss': 0.0327, 'grad_norm': 6.865238189697266, 'learning_rate': 1.2415254237288135e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [4:26:17<1:26:49,  3.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [4:26:21<1:28:41,  3.63s/it]                                                       {'loss': 0.025, 'grad_norm': 2.764110565185547, 'learning_rate': 1.240677966101695e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [4:26:21<1:28:41,  3.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [4:26:24<1:27:24,  3.59s/it]                                                       {'loss': 0.0988, 'grad_norm': 7.2823567390441895, 'learning_rate': 1.2398305084745763e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [4:26:24<1:27:24,  3.59s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [4:26:28<1:25:49,  3.52s/it]                                                       {'loss': 0.0184, 'grad_norm': 3.3818602561950684, 'learning_rate': 1.2389830508474578e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [4:26:28<1:25:49,  3.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [4:26:31<1:25:16,  3.50s/it]                                                       {'loss': 0.0627, 'grad_norm': 4.584501266479492, 'learning_rate': 1.238135593220339e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [4:26:31<1:25:16,  3.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [4:26:35<1:25:30,  3.51s/it]                                                       {'loss': 0.0382, 'grad_norm': 5.18740177154541, 'learning_rate': 1.2372881355932204e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [4:26:35<1:25:30,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [4:26:39<1:29:52,  3.70s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.4847321510314941, 'learning_rate': 1.2364406779661017e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [4:26:39<1:29:52,  3.70s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [4:26:42<1:26:59,  3.58s/it]                                                       {'loss': 0.0936, 'grad_norm': 5.770008087158203, 'learning_rate': 1.2355932203389831e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [4:26:42<1:26:59,  3.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [4:26:46<1:26:10,  3.55s/it]                                                       {'loss': 0.0893, 'grad_norm': 8.006470680236816, 'learning_rate': 1.2347457627118644e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [4:26:46<1:26:10,  3.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [4:26:49<1:25:07,  3.51s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.569228172302246, 'learning_rate': 1.2338983050847457e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [4:26:49<1:25:07,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [4:26:52<1:24:26,  3.48s/it]                                                       {'loss': 0.0387, 'grad_norm': 1.8173104524612427, 'learning_rate': 1.2330508474576272e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [4:26:52<1:24:26,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [4:26:56<1:26:59,  3.59s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03881615027785301, 'learning_rate': 1.2322033898305085e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [4:26:56<1:26:59,  3.59s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [4:27:00<1:25:54,  3.55s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.13425995409488678, 'learning_rate': 1.23135593220339e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [4:27:00<1:25:54,  3.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [4:27:03<1:24:57,  3.51s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3020133078098297, 'learning_rate': 1.2305084745762713e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [4:27:03<1:24:57,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [4:27:06<1:23:17,  3.44s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.15178194642066956, 'learning_rate': 1.2296610169491526e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [4:27:06<1:23:17,  3.44s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [4:27:10<1:24:03,  3.48s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.785500168800354, 'learning_rate': 1.228813559322034e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [4:27:10<1:24:03,  3.48s/it][2025-10-20 04:04:15,348] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [4:27:16<1:39:11,  4.11s/it]                                                       {'loss': 0.0873, 'grad_norm': 6.194225788116455, 'learning_rate': 1.2279661016949152e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [4:27:16<1:39:11,  4.11s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [4:27:19<1:33:42,  3.88s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.8664712905883789, 'learning_rate': 1.2271186440677966e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [4:27:19<1:33:42,  3.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [4:27:22<1:30:17,  3.74s/it]                                                       {'loss': 0.004, 'grad_norm': 0.9091032147407532, 'learning_rate': 1.226271186440678e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [4:27:22<1:30:17,  3.74s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [4:27:26<1:30:25,  3.75s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10137788206338882, 'learning_rate': 1.2254237288135594e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [4:27:26<1:30:25,  3.75s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [4:27:30<1:27:50,  3.65s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.4555416405200958, 'learning_rate': 1.2245762711864407e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [4:27:30<1:27:50,  3.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [4:27:33<1:26:00,  3.57s/it]                                                       {'loss': 0.1031, 'grad_norm': 6.22839879989624, 'learning_rate': 1.2237288135593222e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [4:27:33<1:26:00,  3.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [4:27:37<1:31:32,  3.81s/it]                                                       {'loss': 0.011, 'grad_norm': 1.1989619731903076, 'learning_rate': 1.2228813559322035e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [4:27:37<1:31:32,  3.81s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [4:27:41<1:29:33,  3.73s/it]                                                       {'loss': 0.2832, 'grad_norm': 6.946929931640625, 'learning_rate': 1.2220338983050848e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [4:27:41<1:29:33,  3.73s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [4:27:44<1:27:36,  3.65s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.1910255402326584, 'learning_rate': 1.2211864406779662e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [4:27:44<1:27:36,  3.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [4:27:48<1:25:31,  3.56s/it]                                                       {'loss': 0.1069, 'grad_norm': 5.632065296173096, 'learning_rate': 1.2203389830508475e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [4:27:48<1:25:31,  3.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [4:27:51<1:24:24,  3.52s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.0060662031173706, 'learning_rate': 1.219491525423729e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [4:27:51<1:24:24,  3.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [4:27:54<1:22:48,  3.46s/it]                                                       {'loss': 0.0426, 'grad_norm': 5.557948112487793, 'learning_rate': 1.2186440677966101e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [4:27:54<1:22:48,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [4:27:58<1:22:30,  3.44s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3783906102180481, 'learning_rate': 1.2177966101694916e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [4:27:58<1:22:30,  3.44s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [4:28:01<1:22:48,  3.46s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.9214807748794556, 'learning_rate': 1.2169491525423729e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [4:28:01<1:22:48,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [4:28:05<1:21:51,  3.42s/it]                                                       {'loss': 0.0574, 'grad_norm': 2.7066612243652344, 'learning_rate': 1.2161016949152544e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [4:28:05<1:21:51,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [4:28:08<1:21:16,  3.40s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.41653650999069214, 'learning_rate': 1.2152542372881356e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [4:28:08<1:21:16,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [4:28:12<1:22:30,  3.45s/it]                                                       {'loss': 0.015, 'grad_norm': 1.61737859249115, 'learning_rate': 1.214406779661017e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [4:28:12<1:22:30,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [4:28:15<1:22:02,  3.44s/it]                                                       {'loss': 0.1021, 'grad_norm': 6.2875213623046875, 'learning_rate': 1.2135593220338984e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [4:28:15<1:22:02,  3.44s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [4:28:18<1:20:49,  3.39s/it]                                                       {'loss': 0.0545, 'grad_norm': 6.4240336418151855, 'learning_rate': 1.2127118644067797e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [4:28:18<1:20:49,  3.39s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [4:28:22<1:20:19,  3.37s/it]                                                       {'loss': 0.0342, 'grad_norm': 3.841508626937866, 'learning_rate': 1.2118644067796612e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [4:28:22<1:20:19,  3.37s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [4:28:25<1:20:01,  3.36s/it]                                                       {'loss': 0.0101, 'grad_norm': 2.4413161277770996, 'learning_rate': 1.2110169491525425e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [4:28:25<1:20:01,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [4:28:28<1:19:52,  3.36s/it]                                                       {'loss': 0.1469, 'grad_norm': 5.487713813781738, 'learning_rate': 1.2101694915254238e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [4:28:28<1:19:52,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [4:28:32<1:19:20,  3.34s/it]                                                       {'loss': 0.007, 'grad_norm': 0.9349632859230042, 'learning_rate': 1.209322033898305e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [4:28:32<1:19:20,  3.34s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [4:28:35<1:20:43,  3.40s/it]                                                       {'loss': 0.2371, 'grad_norm': 6.896998405456543, 'learning_rate': 1.2084745762711865e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [4:28:35<1:20:43,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [4:28:39<1:21:05,  3.41s/it]                                                       {'loss': 0.005, 'grad_norm': 0.8357753157615662, 'learning_rate': 1.2076271186440678e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [4:28:39<1:21:05,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [4:28:42<1:20:57,  3.41s/it]                                                       {'loss': 0.1008, 'grad_norm': 5.558510780334473, 'learning_rate': 1.2067796610169491e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [4:28:42<1:20:57,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [4:28:45<1:20:57,  3.41s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.7117182612419128, 'learning_rate': 1.2059322033898306e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [4:28:45<1:20:57,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [4:28:49<1:21:04,  3.42s/it]                                                       {'loss': 0.0352, 'grad_norm': 5.031946182250977, 'learning_rate': 1.2050847457627119e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [4:28:49<1:21:04,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [4:28:52<1:20:43,  3.41s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.505885899066925, 'learning_rate': 1.2042372881355934e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [4:28:52<1:20:43,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [4:28:56<1:20:41,  3.41s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.7996431589126587, 'learning_rate': 1.2033898305084747e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [4:28:56<1:20:41,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [4:28:59<1:20:04,  3.39s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.4387347996234894, 'learning_rate': 1.202542372881356e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [4:28:59<1:20:04,  3.39s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [4:29:02<1:19:43,  3.37s/it]                                                       {'loss': 0.1164, 'grad_norm': 9.396870613098145, 'learning_rate': 1.2016949152542374e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [4:29:02<1:19:43,  3.37s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [4:29:06<1:20:13,  3.40s/it]                                                       {'loss': 0.0851, 'grad_norm': 5.318643093109131, 'learning_rate': 1.2008474576271186e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [4:29:06<1:20:13,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [4:29:10<1:24:03,  3.56s/it]                                                       {'loss': 0.0392, 'grad_norm': 2.8518941402435303, 'learning_rate': 1.2e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [4:29:10<1:24:03,  3.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [4:29:13<1:22:36,  3.50s/it]                                                       {'loss': 0.2066, 'grad_norm': 10.572550773620605, 'learning_rate': 1.1991525423728813e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [4:29:13<1:22:36,  3.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [4:29:16<1:21:12,  3.45s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.964195966720581, 'learning_rate': 1.1983050847457628e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [4:29:16<1:21:12,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [4:29:20<1:21:54,  3.48s/it]                                                       {'loss': 0.0188, 'grad_norm': 3.535827398300171, 'learning_rate': 1.1974576271186441e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [4:29:20<1:21:54,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [4:29:23<1:20:41,  3.43s/it]                                                       {'loss': 0.0664, 'grad_norm': 5.756350994110107, 'learning_rate': 1.1966101694915256e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [4:29:23<1:20:41,  3.43s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [4:29:27<1:20:10,  3.41s/it]                                                       {'loss': 0.3078, 'grad_norm': 6.69007682800293, 'learning_rate': 1.1957627118644069e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [4:29:27<1:20:10,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [4:29:30<1:19:26,  3.38s/it]                                                       {'loss': 0.0593, 'grad_norm': 5.887726783752441, 'learning_rate': 1.1949152542372882e-05, 'epoch': 0.77}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [4:29:30<1:19:26,  3.38s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [4:29:33<1:19:59,  3.41s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.1503281593322754, 'learning_rate': 1.1940677966101696e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [4:29:33<1:19:59,  3.41s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [4:29:37<1:20:43,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.30641043186187744, 'learning_rate': 1.193220338983051e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [4:29:37<1:20:43,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [4:29:41<1:22:43,  3.53s/it]                                                       {'loss': 0.0635, 'grad_norm': 6.306400299072266, 'learning_rate': 1.1923728813559322e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [4:29:41<1:22:43,  3.53s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [4:29:44<1:21:40,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.6424530744552612, 'learning_rate': 1.1915254237288135e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [4:29:44<1:21:40,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [4:29:47<1:20:56,  3.46s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.4333330988883972, 'learning_rate': 1.190677966101695e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [4:29:47<1:20:56,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [4:29:51<1:20:03,  3.42s/it]                                                       {'loss': 0.0136, 'grad_norm': 2.1734278202056885, 'learning_rate': 1.1898305084745763e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [4:29:51<1:20:03,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [4:29:55<1:24:45,  3.63s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.1418370008468628, 'learning_rate': 1.1889830508474578e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [4:29:55<1:24:45,  3.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [4:29:58<1:23:21,  3.57s/it]                                                       {'loss': 0.066, 'grad_norm': 4.284172534942627, 'learning_rate': 1.188135593220339e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [4:29:58<1:23:21,  3.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [4:30:02<1:22:22,  3.53s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.24752287566661835, 'learning_rate': 1.1872881355932203e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [4:30:02<1:22:22,  3.53s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [4:30:05<1:21:13,  3.48s/it]                                                       {'loss': 0.0537, 'grad_norm': 2.6986472606658936, 'learning_rate': 1.1864406779661018e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [4:30:05<1:21:13,  3.48s/it][2025-10-20 04:07:10,397] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [4:30:11<1:36:41,  4.15s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.7781617641448975, 'learning_rate': 1.1855932203389831e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [4:30:11<1:36:41,  4.15s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [4:30:14<1:31:41,  3.93s/it]                                                       {'loss': 0.1743, 'grad_norm': 9.063464164733887, 'learning_rate': 1.1847457627118646e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [4:30:14<1:31:41,  3.93s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [4:30:18<1:27:44,  3.77s/it]                                                       {'loss': 0.0366, 'grad_norm': 3.873640775680542, 'learning_rate': 1.1838983050847457e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [4:30:18<1:27:44,  3.77s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [4:30:21<1:25:11,  3.66s/it]                                                       {'loss': 0.008, 'grad_norm': 1.25043785572052, 'learning_rate': 1.1830508474576272e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [4:30:21<1:25:11,  3.66s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [4:30:24<1:23:14,  3.58s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.9461233019828796, 'learning_rate': 1.1822033898305085e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [4:30:24<1:23:14,  3.58s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [4:30:28<1:21:39,  3.52s/it]                                                       {'loss': 0.054, 'grad_norm': 4.443502426147461, 'learning_rate': 1.18135593220339e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [4:30:28<1:21:39,  3.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [4:30:31<1:20:15,  3.46s/it]                                                       {'loss': 0.0096, 'grad_norm': 2.2304224967956543, 'learning_rate': 1.1805084745762712e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [4:30:31<1:20:15,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [4:30:34<1:19:24,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03965746611356735, 'learning_rate': 1.1796610169491525e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [4:30:34<1:19:24,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [4:30:39<1:27:42,  3.78s/it]                                                       {'loss': 0.0566, 'grad_norm': 6.409756183624268, 'learning_rate': 1.178813559322034e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [4:30:39<1:27:42,  3.78s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [4:30:43<1:25:54,  3.71s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.776803195476532, 'learning_rate': 1.1779661016949153e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [4:30:43<1:25:54,  3.71s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [4:30:47<1:29:12,  3.85s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.6058331727981567, 'learning_rate': 1.1771186440677968e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [4:30:47<1:29:12,  3.85s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [4:30:50<1:25:53,  3.71s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4714433550834656, 'learning_rate': 1.176271186440678e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [4:30:50<1:25:53,  3.71s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [4:30:54<1:26:47,  3.75s/it]                                                       {'loss': 0.2079, 'grad_norm': 7.242431163787842, 'learning_rate': 1.1754237288135594e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [4:30:54<1:26:47,  3.75s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [4:30:57<1:23:39,  3.62s/it]                                                       {'loss': 0.0392, 'grad_norm': 3.7957186698913574, 'learning_rate': 1.1745762711864407e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [4:30:57<1:23:39,  3.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [4:31:01<1:22:13,  3.56s/it]                                                       {'loss': 0.0321, 'grad_norm': 3.121398448944092, 'learning_rate': 1.173728813559322e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [4:31:01<1:22:13,  3.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [4:31:04<1:20:50,  3.50s/it]                                                       {'loss': 0.0105, 'grad_norm': 0.8617134094238281, 'learning_rate': 1.1728813559322034e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [4:31:04<1:20:50,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [4:31:08<1:20:52,  3.51s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.0808507204055786, 'learning_rate': 1.1720338983050847e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [4:31:08<1:20:52,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [4:31:11<1:19:30,  3.45s/it]                                                       {'loss': 0.0191, 'grad_norm': 2.8943288326263428, 'learning_rate': 1.1711864406779662e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [4:31:11<1:19:30,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [4:31:15<1:20:24,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012116385623812675, 'learning_rate': 1.1703389830508475e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [4:31:15<1:20:24,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [4:31:18<1:20:02,  3.48s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.4979315996170044, 'learning_rate': 1.169491525423729e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [4:31:18<1:20:02,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [4:31:21<1:19:13,  3.45s/it]                                                       {'loss': 0.2232, 'grad_norm': 6.757628917694092, 'learning_rate': 1.1686440677966103e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [4:31:21<1:19:13,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [4:31:25<1:19:23,  3.46s/it]                                                       {'loss': 0.0597, 'grad_norm': 7.279315948486328, 'learning_rate': 1.1677966101694916e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [4:31:25<1:19:23,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [4:31:28<1:20:34,  3.51s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5320308804512024, 'learning_rate': 1.166949152542373e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [4:31:28<1:20:34,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [4:31:32<1:20:07,  3.49s/it]                                                       {'loss': 0.0525, 'grad_norm': 3.9794414043426514, 'learning_rate': 1.1661016949152542e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [4:31:32<1:20:07,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [4:31:35<1:19:12,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09173527359962463, 'learning_rate': 1.1652542372881356e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [4:31:35<1:19:12,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [4:31:39<1:18:08,  3.41s/it]                                                       {'loss': 0.0162, 'grad_norm': 2.084542751312256, 'learning_rate': 1.164406779661017e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [4:31:39<1:18:08,  3.41s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [4:31:42<1:17:34,  3.39s/it]                                                       {'loss': 0.0831, 'grad_norm': 4.6752729415893555, 'learning_rate': 1.1635593220338984e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [4:31:42<1:17:34,  3.39s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [4:31:45<1:17:54,  3.41s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.5045215487480164, 'learning_rate': 1.1627118644067797e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [4:31:45<1:17:54,  3.41s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [4:31:49<1:18:05,  3.42s/it]                                                       {'loss': 0.0186, 'grad_norm': 1.9107167720794678, 'learning_rate': 1.1618644067796612e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [4:31:49<1:18:05,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [4:31:53<1:22:24,  3.61s/it]                                                       {'loss': 0.0227, 'grad_norm': 2.5261642932891846, 'learning_rate': 1.1610169491525424e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [4:31:53<1:22:24,  3.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [4:31:56<1:21:13,  3.56s/it]                                                       {'loss': 0.1645, 'grad_norm': 5.104094982147217, 'learning_rate': 1.1601694915254237e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [4:31:56<1:21:13,  3.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [4:32:00<1:19:57,  3.51s/it]                                                       {'loss': 0.1674, 'grad_norm': 10.500117301940918, 'learning_rate': 1.1593220338983052e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [4:32:00<1:19:57,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [4:32:03<1:18:24,  3.44s/it]                                                       {'loss': 0.0922, 'grad_norm': 5.778611183166504, 'learning_rate': 1.1584745762711865e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [4:32:03<1:18:24,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [4:32:06<1:18:20,  3.44s/it]                                                       {'loss': 0.0789, 'grad_norm': 5.69359016418457, 'learning_rate': 1.157627118644068e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [4:32:06<1:18:20,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [4:32:10<1:17:47,  3.42s/it]                                                       {'loss': 0.1535, 'grad_norm': 6.3913774490356445, 'learning_rate': 1.1567796610169491e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [4:32:10<1:17:47,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [4:32:13<1:17:16,  3.40s/it]                                                       {'loss': 0.021, 'grad_norm': 1.3343838453292847, 'learning_rate': 1.1559322033898306e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [4:32:13<1:17:16,  3.40s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [4:32:17<1:17:28,  3.41s/it]                                                       {'loss': 0.0048, 'grad_norm': 1.2479488849639893, 'learning_rate': 1.1550847457627119e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [4:32:17<1:17:28,  3.41s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [4:32:21<1:21:29,  3.59s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.043535612523555756, 'learning_rate': 1.1542372881355933e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [4:32:21<1:21:29,  3.59s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [4:32:24<1:19:42,  3.51s/it]                                                       {'loss': 0.0571, 'grad_norm': 4.186086177825928, 'learning_rate': 1.1533898305084746e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [4:32:24<1:19:42,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [4:32:27<1:18:34,  3.47s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.9525009989738464, 'learning_rate': 1.152542372881356e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [4:32:27<1:18:34,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [4:32:31<1:19:20,  3.50s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03557070344686508, 'learning_rate': 1.1516949152542374e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [4:32:31<1:19:20,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [4:32:34<1:17:50,  3.44s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.302948921918869, 'learning_rate': 1.1508474576271187e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [4:32:34<1:17:50,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [4:32:38<1:20:21,  3.55s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11256170272827148, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [4:32:38<1:20:21,  3.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [4:32:41<1:19:07,  3.50s/it]                                                       {'loss': 0.0909, 'grad_norm': 4.811701774597168, 'learning_rate': 1.1491525423728815e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [4:32:41<1:19:07,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [4:32:45<1:18:14,  3.46s/it]                                                       {'loss': 0.0777, 'grad_norm': 7.173185348510742, 'learning_rate': 1.1483050847457628e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [4:32:45<1:18:14,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [4:32:48<1:17:12,  3.42s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.34313702583313, 'learning_rate': 1.147457627118644e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [4:32:48<1:17:12,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [4:32:51<1:16:41,  3.40s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.3802578449249268, 'learning_rate': 1.1466101694915254e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [4:32:51<1:16:41,  3.40s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [4:32:55<1:17:39,  3.45s/it]                                                       {'loss': 0.0315, 'grad_norm': 3.1688051223754883, 'learning_rate': 1.1457627118644068e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [4:32:55<1:17:39,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [4:32:58<1:18:05,  3.47s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.19174443185329437, 'learning_rate': 1.1449152542372881e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [4:32:59<1:18:05,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [4:33:02<1:17:48,  3.46s/it]                                                       {'loss': 0.1061, 'grad_norm': 7.600315570831299, 'learning_rate': 1.1440677966101696e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [4:33:02<1:17:48,  3.46s/it][2025-10-20 04:10:07,257] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [4:33:08<1:32:49,  4.13s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.06931789964437485, 'learning_rate': 1.1432203389830509e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [4:33:08<1:32:49,  4.13s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [4:33:11<1:29:35,  3.99s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.82362300157547, 'learning_rate': 1.1423728813559324e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [4:33:11<1:29:35,  3.99s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [4:33:15<1:26:08,  3.84s/it]                                                       {'loss': 0.0296, 'grad_norm': 5.002448081970215, 'learning_rate': 1.1415254237288137e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [4:33:15<1:26:08,  3.84s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [4:33:18<1:23:25,  3.72s/it]                                                       {'loss': 0.0227, 'grad_norm': 1.7954294681549072, 'learning_rate': 1.140677966101695e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [4:33:18<1:23:25,  3.72s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [4:33:22<1:20:29,  3.59s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.7553929090499878, 'learning_rate': 1.1398305084745763e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [4:33:22<1:20:29,  3.59s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [4:33:25<1:20:05,  3.58s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.6039131879806519, 'learning_rate': 1.1389830508474576e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [4:33:25<1:20:05,  3.58s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [4:33:28<1:18:27,  3.51s/it]                                                       {'loss': 0.0347, 'grad_norm': 4.153928279876709, 'learning_rate': 1.138135593220339e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [4:33:28<1:18:27,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [4:33:32<1:17:54,  3.48s/it]                                                       {'loss': 0.1984, 'grad_norm': 9.117657661437988, 'learning_rate': 1.1372881355932203e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [4:33:32<1:17:54,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [4:33:35<1:17:09,  3.45s/it]                                                       {'loss': 0.0248, 'grad_norm': 1.6825240850448608, 'learning_rate': 1.1364406779661018e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [4:33:35<1:17:09,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [4:33:39<1:16:43,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.34545964002609253, 'learning_rate': 1.135593220338983e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [4:33:39<1:16:43,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [4:33:42<1:16:23,  3.42s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.0485130548477173, 'learning_rate': 1.1347457627118646e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [4:33:42<1:16:23,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [4:33:45<1:16:08,  3.41s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.4856541156768799, 'learning_rate': 1.1338983050847458e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [4:33:45<1:16:08,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [4:33:49<1:15:50,  3.40s/it]                                                       {'loss': 0.0207, 'grad_norm': 1.789734959602356, 'learning_rate': 1.1330508474576271e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [4:33:49<1:15:50,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [4:33:52<1:15:45,  3.40s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.4586421251296997, 'learning_rate': 1.1322033898305086e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [4:33:52<1:15:45,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [4:33:55<1:15:09,  3.38s/it]                                                       {'loss': 0.1301, 'grad_norm': 5.317589282989502, 'learning_rate': 1.1313559322033899e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [4:33:55<1:15:09,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [4:33:59<1:15:03,  3.38s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.058616653084754944, 'learning_rate': 1.1305084745762712e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [4:33:59<1:15:03,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [4:34:02<1:15:10,  3.38s/it]                                                       {'loss': 0.0534, 'grad_norm': 5.238205432891846, 'learning_rate': 1.1296610169491525e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [4:34:02<1:15:10,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [4:34:06<1:15:19,  3.39s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.029100842773914337, 'learning_rate': 1.128813559322034e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [4:34:06<1:15:19,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [4:34:09<1:14:54,  3.38s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1479891985654831, 'learning_rate': 1.1279661016949153e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [4:34:09<1:14:54,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [4:34:12<1:14:27,  3.36s/it]                                                       {'loss': 0.0142, 'grad_norm': 1.7122375965118408, 'learning_rate': 1.1271186440677967e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [4:34:12<1:14:27,  3.36s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [4:34:16<1:14:47,  3.38s/it]                                                       {'loss': 0.029, 'grad_norm': 3.7383999824523926, 'learning_rate': 1.126271186440678e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [4:34:16<1:14:47,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [4:34:19<1:15:53,  3.43s/it]                                                       {'loss': 0.2203, 'grad_norm': 11.653538703918457, 'learning_rate': 1.1254237288135593e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [4:34:19<1:15:53,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [4:34:23<1:15:49,  3.43s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2208223044872284, 'learning_rate': 1.1245762711864408e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [4:34:23<1:15:49,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [4:34:26<1:15:04,  3.40s/it]                                                       {'loss': 0.119, 'grad_norm': 5.644077777862549, 'learning_rate': 1.1237288135593221e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [4:34:26<1:15:04,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [4:34:29<1:14:44,  3.38s/it]                                                       {'loss': 0.001, 'grad_norm': 0.17707982659339905, 'learning_rate': 1.1228813559322036e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [4:34:29<1:14:44,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [4:34:33<1:14:43,  3.39s/it]                                                       {'loss': 0.0656, 'grad_norm': 8.610573768615723, 'learning_rate': 1.1220338983050847e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [4:34:33<1:14:43,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [4:34:36<1:14:32,  3.38s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.21679219603538513, 'learning_rate': 1.1211864406779662e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [4:34:36<1:14:32,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [4:34:40<1:14:48,  3.40s/it]                                                       {'loss': 0.0462, 'grad_norm': 5.228184223175049, 'learning_rate': 1.1203389830508475e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [4:34:40<1:14:48,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [4:34:43<1:15:05,  3.41s/it]                                                       {'loss': 0.0264, 'grad_norm': 3.59767746925354, 'learning_rate': 1.1194915254237288e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [4:34:43<1:15:05,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [4:34:46<1:14:09,  3.37s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2889079451560974, 'learning_rate': 1.1186440677966102e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [4:34:46<1:14:09,  3.37s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [4:34:50<1:13:42,  3.35s/it]                                                       {'loss': 0.0609, 'grad_norm': 5.0792388916015625, 'learning_rate': 1.1177966101694915e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [4:34:50<1:13:42,  3.35s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [4:34:53<1:14:35,  3.40s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.12440690398216248, 'learning_rate': 1.116949152542373e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [4:34:53<1:14:35,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [4:34:56<1:14:23,  3.39s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5330688953399658, 'learning_rate': 1.1161016949152543e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [4:34:57<1:14:23,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [4:35:00<1:15:46,  3.46s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.0949629545211792, 'learning_rate': 1.1152542372881358e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [4:35:00<1:15:46,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [4:35:04<1:15:50,  3.46s/it]                                                       {'loss': 0.0925, 'grad_norm': 5.189168453216553, 'learning_rate': 1.114406779661017e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [4:35:04<1:15:50,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [4:35:07<1:15:38,  3.45s/it]                                                       {'loss': 0.1682, 'grad_norm': 6.762631416320801, 'learning_rate': 1.1135593220338984e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [4:35:07<1:15:38,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [4:35:10<1:14:48,  3.42s/it]                                                       {'loss': 0.0781, 'grad_norm': 3.1612322330474854, 'learning_rate': 1.1127118644067797e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [4:35:10<1:14:48,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [4:35:14<1:14:33,  3.41s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.2358229160308838, 'learning_rate': 1.111864406779661e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [4:35:14<1:14:33,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [4:35:17<1:16:42,  3.51s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5731518268585205, 'learning_rate': 1.1110169491525424e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [4:35:17<1:16:42,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [4:35:21<1:16:16,  3.49s/it]                                                       {'loss': 0.067, 'grad_norm': 7.128046989440918, 'learning_rate': 1.1101694915254237e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [4:35:21<1:16:16,  3.49s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [4:35:24<1:15:15,  3.45s/it]                                                       {'loss': 0.2115, 'grad_norm': 7.634720325469971, 'learning_rate': 1.1093220338983052e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [4:35:24<1:15:15,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [4:35:28<1:14:11,  3.40s/it]                                                       {'loss': 0.0546, 'grad_norm': 1.4435476064682007, 'learning_rate': 1.1084745762711865e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [4:35:28<1:14:11,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [4:35:31<1:14:46,  3.43s/it]                                                       {'loss': 0.0218, 'grad_norm': 3.962592363357544, 'learning_rate': 1.107627118644068e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [4:35:31<1:14:46,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [4:35:35<1:14:50,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05676942691206932, 'learning_rate': 1.1067796610169492e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [4:35:35<1:14:50,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [4:35:38<1:16:24,  3.51s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.8630039691925049, 'learning_rate': 1.1059322033898305e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [4:35:38<1:16:24,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [4:35:42<1:15:19,  3.47s/it]                                                       {'loss': 0.0162, 'grad_norm': 1.4717020988464355, 'learning_rate': 1.105084745762712e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [4:35:42<1:15:19,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [4:35:45<1:14:56,  3.45s/it]                                                       {'loss': 0.0671, 'grad_norm': 5.265902042388916, 'learning_rate': 1.1042372881355931e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [4:35:45<1:14:56,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [4:35:48<1:13:58,  3.41s/it]                                                       {'loss': 0.0173, 'grad_norm': 2.7082982063293457, 'learning_rate': 1.1033898305084746e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [4:35:48<1:13:58,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [4:35:52<1:13:55,  3.41s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4013242721557617, 'learning_rate': 1.1025423728813559e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [4:35:52<1:13:55,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [4:35:55<1:13:50,  3.41s/it]                                                       {'loss': 0.0275, 'grad_norm': 4.740272521972656, 'learning_rate': 1.1016949152542374e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [4:35:55<1:13:50,  3.41s/it][2025-10-20 04:13:00,446] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [4:36:01<1:28:26,  4.09s/it]                                                       {'loss': 0.1442, 'grad_norm': 7.595262050628662, 'learning_rate': 1.1008474576271187e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [4:36:01<1:28:26,  4.09s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [4:36:04<1:24:48,  3.92s/it]                                                       {'loss': 0.0462, 'grad_norm': 3.0423779487609863, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [4:36:04<1:24:48,  3.92s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [4:36:08<1:21:29,  3.77s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.461242198944092, 'learning_rate': 1.0991525423728814e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [4:36:08<1:21:29,  3.77s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [4:36:11<1:19:10,  3.67s/it]                                                       {'loss': 0.1297, 'grad_norm': 6.117565631866455, 'learning_rate': 1.0983050847457627e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [4:36:11<1:19:10,  3.67s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [4:36:15<1:17:37,  3.60s/it]                                                       {'loss': 0.085, 'grad_norm': 5.909968852996826, 'learning_rate': 1.0974576271186442e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [4:36:15<1:17:37,  3.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [4:36:18<1:16:23,  3.54s/it]                                                       {'loss': 0.1825, 'grad_norm': 8.06796646118164, 'learning_rate': 1.0966101694915255e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [4:36:18<1:16:23,  3.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [4:36:21<1:15:19,  3.50s/it]                                                       {'loss': 0.0319, 'grad_norm': 3.170748233795166, 'learning_rate': 1.0957627118644068e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [4:36:21<1:15:19,  3.50s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [4:36:25<1:14:11,  3.45s/it]                                                       {'loss': 0.0132, 'grad_norm': 2.312567710876465, 'learning_rate': 1.0949152542372881e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [4:36:25<1:14:11,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [4:36:28<1:13:38,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06689625233411789, 'learning_rate': 1.0940677966101696e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [4:36:28<1:13:38,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [4:36:32<1:13:38,  3.43s/it]                                                       {'loss': 0.0317, 'grad_norm': 3.0300850868225098, 'learning_rate': 1.0932203389830509e-05, 'epoch': 0.79}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [4:36:32<1:13:38,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [4:36:35<1:13:16,  3.41s/it]                                                       {'loss': 0.06, 'grad_norm': 2.9723758697509766, 'learning_rate': 1.0923728813559322e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [4:36:35<1:13:16,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [4:36:39<1:15:06,  3.50s/it]                                                       {'loss': 0.0693, 'grad_norm': 4.2365403175354, 'learning_rate': 1.0915254237288136e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [4:36:39<1:15:06,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [4:36:42<1:14:15,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.053705327212810516, 'learning_rate': 1.090677966101695e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [4:36:42<1:14:15,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [4:36:46<1:17:32,  3.62s/it]                                                       {'loss': 0.3742, 'grad_norm': 7.33284330368042, 'learning_rate': 1.0898305084745764e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [4:36:46<1:17:32,  3.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [4:36:49<1:15:52,  3.54s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013488775119185448, 'learning_rate': 1.0889830508474577e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [4:36:49<1:15:52,  3.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [4:36:53<1:14:51,  3.50s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.6742404103279114, 'learning_rate': 1.0881355932203392e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [4:36:53<1:14:51,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [4:36:56<1:14:34,  3.49s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.35025253891944885, 'learning_rate': 1.0872881355932205e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [4:36:56<1:14:34,  3.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [4:37:00<1:15:28,  3.53s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.6293227672576904, 'learning_rate': 1.0864406779661018e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [4:37:00<1:15:28,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [4:37:03<1:15:19,  3.53s/it]                                                       {'loss': 0.015, 'grad_norm': 3.6532654762268066, 'learning_rate': 1.085593220338983e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [4:37:03<1:15:19,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [4:37:07<1:14:27,  3.49s/it]                                                       {'loss': 0.0948, 'grad_norm': 7.392186641693115, 'learning_rate': 1.0847457627118644e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [4:37:07<1:14:27,  3.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [4:37:10<1:12:50,  3.42s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.5288562774658203, 'learning_rate': 1.0838983050847458e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [4:37:10<1:12:50,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [4:37:13<1:12:05,  3.38s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.046031419187784195, 'learning_rate': 1.0830508474576271e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [4:37:13<1:12:05,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [4:37:17<1:12:06,  3.39s/it]                                                       {'loss': 0.0885, 'grad_norm': 7.61411714553833, 'learning_rate': 1.0822033898305086e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [4:37:17<1:12:06,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [4:37:20<1:11:52,  3.38s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.0115795135498047, 'learning_rate': 1.0813559322033899e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [4:37:20<1:11:52,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [4:37:24<1:12:18,  3.40s/it]                                                       {'loss': 0.0391, 'grad_norm': 4.239685535430908, 'learning_rate': 1.0805084745762714e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [4:37:24<1:12:18,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [4:37:27<1:14:42,  3.52s/it]                                                       {'loss': 0.1499, 'grad_norm': 12.869819641113281, 'learning_rate': 1.0796610169491526e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [4:37:27<1:14:42,  3.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [4:37:31<1:16:33,  3.61s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.872688353061676, 'learning_rate': 1.078813559322034e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [4:37:31<1:16:33,  3.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [4:37:35<1:15:03,  3.54s/it]                                                       {'loss': 0.0442, 'grad_norm': 4.677775859832764, 'learning_rate': 1.0779661016949152e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [4:37:35<1:15:03,  3.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [4:37:38<1:14:04,  3.50s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.2133123874664307, 'learning_rate': 1.0771186440677965e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [4:37:38<1:14:04,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [4:37:41<1:13:38,  3.48s/it]                                                       {'loss': 0.0252, 'grad_norm': 1.693117380142212, 'learning_rate': 1.076271186440678e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [4:37:41<1:13:38,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [4:37:45<1:13:06,  3.46s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3003174960613251, 'learning_rate': 1.0754237288135593e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [4:37:45<1:13:06,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [4:37:48<1:12:37,  3.44s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.021519970148801804, 'learning_rate': 1.0745762711864408e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [4:37:48<1:12:37,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [4:37:52<1:15:46,  3.59s/it]                                                       {'loss': 0.1482, 'grad_norm': 6.254916191101074, 'learning_rate': 1.073728813559322e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [4:37:52<1:15:46,  3.59s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [4:37:56<1:15:14,  3.57s/it]                                                       {'loss': 0.0311, 'grad_norm': 4.852262496948242, 'learning_rate': 1.0728813559322035e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [4:37:56<1:15:14,  3.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [4:37:59<1:14:11,  3.52s/it]                                                       {'loss': 0.0266, 'grad_norm': 3.796543598175049, 'learning_rate': 1.0720338983050848e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [4:37:59<1:14:11,  3.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [4:38:02<1:13:19,  3.48s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09130599349737167, 'learning_rate': 1.0711864406779661e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [4:38:02<1:13:19,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [4:38:06<1:12:40,  3.45s/it]                                                       {'loss': 0.0249, 'grad_norm': 3.5082881450653076, 'learning_rate': 1.0703389830508476e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [4:38:06<1:12:40,  3.45s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [4:38:10<1:15:05,  3.57s/it]                                                       {'loss': 0.0596, 'grad_norm': 2.517970561981201, 'learning_rate': 1.0694915254237287e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [4:38:10<1:15:05,  3.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [4:38:13<1:14:06,  3.53s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.76368647813797, 'learning_rate': 1.0686440677966102e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [4:38:13<1:14:06,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [4:38:17<1:13:41,  3.51s/it]                                                       {'loss': 0.0787, 'grad_norm': 3.4371705055236816, 'learning_rate': 1.0677966101694915e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [4:38:17<1:13:41,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [4:38:20<1:12:55,  3.48s/it]                                                       {'loss': 0.3251, 'grad_norm': 12.837854385375977, 'learning_rate': 1.066949152542373e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [4:38:20<1:12:55,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [4:38:23<1:13:24,  3.50s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.16753298044204712, 'learning_rate': 1.0661016949152543e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [4:38:23<1:13:24,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [4:38:27<1:12:41,  3.47s/it]                                                       {'loss': 0.0564, 'grad_norm': 4.6098198890686035, 'learning_rate': 1.0652542372881356e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [4:38:27<1:12:41,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [4:38:30<1:11:50,  3.43s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.9556988477706909, 'learning_rate': 1.064406779661017e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [4:38:30<1:11:50,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [4:38:34<1:11:06,  3.40s/it]                                                       {'loss': 0.049, 'grad_norm': 3.482991933822632, 'learning_rate': 1.0635593220338983e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [4:38:34<1:11:06,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [4:38:37<1:10:54,  3.39s/it]                                                       {'loss': 0.0565, 'grad_norm': 3.4980692863464355, 'learning_rate': 1.0627118644067798e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [4:38:37<1:10:54,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [4:38:41<1:12:15,  3.46s/it]                                                       {'loss': 0.0276, 'grad_norm': 5.600910186767578, 'learning_rate': 1.0618644067796611e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [4:38:41<1:12:15,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [4:38:44<1:11:39,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05183584988117218, 'learning_rate': 1.0610169491525426e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [4:38:44<1:11:39,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [4:38:47<1:11:06,  3.41s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.788764238357544, 'learning_rate': 1.0601694915254237e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [4:38:47<1:11:06,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [4:38:51<1:10:38,  3.39s/it]                                                       {'loss': 0.0366, 'grad_norm': 4.183150291442871, 'learning_rate': 1.0593220338983052e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [4:38:51<1:10:38,  3.39s/it][2025-10-20 04:15:55,939] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [4:38:56<1:24:42,  4.07s/it]                                                       {'loss': 0.0174, 'grad_norm': 1.9968900680541992, 'learning_rate': 1.0584745762711865e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [4:38:56<1:24:42,  4.07s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [4:39:00<1:20:53,  3.89s/it]                                                       {'loss': 0.0174, 'grad_norm': 3.384323835372925, 'learning_rate': 1.0576271186440678e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [4:39:00<1:20:53,  3.89s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [4:39:03<1:17:24,  3.72s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5681639909744263, 'learning_rate': 1.0567796610169492e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [4:39:03<1:17:24,  3.72s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [4:39:06<1:14:39,  3.59s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.9853938817977905, 'learning_rate': 1.0559322033898305e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [4:39:06<1:14:39,  3.59s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [4:39:10<1:13:15,  3.53s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.9851351976394653, 'learning_rate': 1.055084745762712e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [4:39:10<1:13:15,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [4:39:13<1:12:01,  3.47s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.6870509386062622, 'learning_rate': 1.0542372881355933e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [4:39:13<1:12:01,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [4:39:16<1:10:58,  3.43s/it]                                                       {'loss': 0.0901, 'grad_norm': 8.600686073303223, 'learning_rate': 1.0533898305084747e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [4:39:16<1:10:58,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [4:39:20<1:10:46,  3.42s/it]                                                       {'loss': 0.0398, 'grad_norm': 4.932579040527344, 'learning_rate': 1.052542372881356e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [4:39:20<1:10:46,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [4:39:23<1:10:35,  3.41s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.035246361047029495, 'learning_rate': 1.0516949152542373e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [4:39:23<1:10:35,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [4:39:27<1:09:55,  3.38s/it]                                                       {'loss': 0.0732, 'grad_norm': 6.831591606140137, 'learning_rate': 1.0508474576271186e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [4:39:27<1:09:55,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [4:39:30<1:09:55,  3.39s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3719862401485443, 'learning_rate': 1.05e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [4:39:30<1:09:55,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [4:39:33<1:10:01,  3.39s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2120995670557022, 'learning_rate': 1.0491525423728814e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [4:39:33<1:10:01,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [4:39:37<1:09:39,  3.38s/it]                                                       {'loss': 0.252, 'grad_norm': 8.650364875793457, 'learning_rate': 1.0483050847457627e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [4:39:37<1:09:39,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [4:39:40<1:11:40,  3.48s/it]                                                       {'loss': 0.005, 'grad_norm': 0.8917402625083923, 'learning_rate': 1.0474576271186442e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [4:39:40<1:11:40,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [4:39:44<1:10:58,  3.45s/it]                                                       {'loss': 0.0463, 'grad_norm': 5.758429527282715, 'learning_rate': 1.0466101694915255e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [4:39:44<1:10:58,  3.45s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [4:39:47<1:10:16,  3.42s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.7279499769210815, 'learning_rate': 1.045762711864407e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [4:39:47<1:10:16,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [4:39:50<1:09:49,  3.40s/it]                                                       {'loss': 0.1241, 'grad_norm': 8.989928245544434, 'learning_rate': 1.0449152542372882e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [4:39:50<1:09:49,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [4:39:54<1:09:23,  3.38s/it]                                                       {'loss': 0.049, 'grad_norm': 5.42200231552124, 'learning_rate': 1.0440677966101695e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [4:39:54<1:09:23,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [4:39:57<1:09:28,  3.39s/it]                                                       {'loss': 0.0899, 'grad_norm': 9.982640266418457, 'learning_rate': 1.043220338983051e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [4:39:57<1:09:28,  3.39s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [4:40:01<1:09:34,  3.39s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05649816244840622, 'learning_rate': 1.0423728813559321e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [4:40:01<1:09:34,  3.39s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [4:40:04<1:10:00,  3.42s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.622138738632202, 'learning_rate': 1.0415254237288136e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [4:40:04<1:10:00,  3.42s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [4:40:07<1:09:12,  3.38s/it]                                                       {'loss': 0.0964, 'grad_norm': 7.00709342956543, 'learning_rate': 1.0406779661016949e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [4:40:07<1:09:12,  3.38s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [4:40:11<1:10:17,  3.44s/it]                                                       {'loss': 0.0327, 'grad_norm': 4.800811767578125, 'learning_rate': 1.0398305084745764e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [4:40:11<1:10:17,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [4:40:14<1:10:41,  3.46s/it]                                                       {'loss': 0.0964, 'grad_norm': 3.3184561729431152, 'learning_rate': 1.0389830508474577e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [4:40:14<1:10:41,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [4:40:18<1:10:43,  3.46s/it]                                                       {'loss': 0.2472, 'grad_norm': 8.78844928741455, 'learning_rate': 1.038135593220339e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [4:40:18<1:10:43,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [4:40:21<1:10:20,  3.45s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.12645956873893738, 'learning_rate': 1.0372881355932204e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [4:40:21<1:10:20,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [4:40:25<1:09:52,  3.43s/it]                                                       {'loss': 0.0889, 'grad_norm': 4.7839226722717285, 'learning_rate': 1.0364406779661017e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [4:40:25<1:09:52,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [4:40:28<1:09:24,  3.41s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03499196842312813, 'learning_rate': 1.0355932203389832e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [4:40:28<1:09:24,  3.41s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [4:40:32<1:13:30,  3.61s/it]                                                       {'loss': 0.2013, 'grad_norm': 9.755437850952148, 'learning_rate': 1.0347457627118645e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [4:40:32<1:13:30,  3.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [4:40:36<1:12:00,  3.54s/it]                                                       {'loss': 0.0178, 'grad_norm': 3.007366418838501, 'learning_rate': 1.0338983050847458e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [4:40:36<1:12:00,  3.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [4:40:39<1:12:15,  3.56s/it]                                                       {'loss': 0.0657, 'grad_norm': 4.6899824142456055, 'learning_rate': 1.0330508474576271e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [4:40:39<1:12:15,  3.56s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [4:40:42<1:10:44,  3.48s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.0478782653808594, 'learning_rate': 1.0322033898305086e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [4:40:42<1:10:44,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [4:40:46<1:09:58,  3.45s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05153989419341087, 'learning_rate': 1.0313559322033899e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [4:40:46<1:09:58,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [4:40:50<1:12:19,  3.57s/it]                                                       {'loss': 0.1496, 'grad_norm': 8.213984489440918, 'learning_rate': 1.0305084745762712e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [4:40:50<1:12:19,  3.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [4:40:53<1:10:40,  3.49s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04902536794543266, 'learning_rate': 1.0296610169491526e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [4:40:53<1:10:40,  3.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [4:40:56<1:09:58,  3.46s/it]                                                       {'loss': 0.0166, 'grad_norm': 2.5814008712768555, 'learning_rate': 1.028813559322034e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [4:40:56<1:09:58,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [4:41:00<1:11:56,  3.56s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14974157512187958, 'learning_rate': 1.0279661016949154e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [4:41:00<1:11:56,  3.56s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [4:41:04<1:13:06,  3.62s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.825000047683716, 'learning_rate': 1.0271186440677967e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [4:41:04<1:13:06,  3.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [4:41:07<1:11:41,  3.55s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.0078198909759521, 'learning_rate': 1.0262711864406781e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [4:41:07<1:11:41,  3.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [4:41:11<1:10:45,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.017376435920596123, 'learning_rate': 1.0254237288135593e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [4:41:11<1:10:45,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [4:41:14<1:09:33,  3.45s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5396177768707275, 'learning_rate': 1.0245762711864407e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [4:41:14<1:09:33,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [4:41:18<1:10:35,  3.51s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.15873326361179352, 'learning_rate': 1.023728813559322e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [4:41:18<1:10:35,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [4:41:21<1:09:41,  3.46s/it]                                                       {'loss': 0.0552, 'grad_norm': 5.781554222106934, 'learning_rate': 1.0228813559322033e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [4:41:21<1:09:41,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [4:41:24<1:09:10,  3.44s/it]                                                       {'loss': 0.043, 'grad_norm': 3.8813352584838867, 'learning_rate': 1.0220338983050848e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [4:41:24<1:09:10,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [4:41:28<1:08:52,  3.43s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.2613054513931274, 'learning_rate': 1.0211864406779661e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [4:41:28<1:08:52,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [4:41:31<1:08:50,  3.43s/it]                                                       {'loss': 0.069, 'grad_norm': 5.153999328613281, 'learning_rate': 1.0203389830508476e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [4:41:31<1:08:50,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [4:41:35<1:09:09,  3.45s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.7308908700942993, 'learning_rate': 1.0194915254237289e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [4:41:35<1:09:09,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [4:41:38<1:09:20,  3.46s/it]                                                       {'loss': 0.0466, 'grad_norm': 4.9439005851745605, 'learning_rate': 1.0186440677966103e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [4:41:38<1:09:20,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [4:41:42<1:10:58,  3.55s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06696423888206482, 'learning_rate': 1.0177966101694916e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [4:41:42<1:10:58,  3.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [4:41:45<1:09:27,  3.47s/it]                                                       {'loss': 0.0945, 'grad_norm': 3.1994500160217285, 'learning_rate': 1.016949152542373e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [4:41:45<1:09:27,  3.47s/it][2025-10-20 04:18:50,602] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [4:41:51<1:22:32,  4.13s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.45170900225639343, 'learning_rate': 1.0161016949152542e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [4:41:51<1:22:32,  4.13s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [4:41:55<1:21:50,  4.10s/it]                                                       {'loss': 0.0052, 'grad_norm': 1.2487162351608276, 'learning_rate': 1.0152542372881355e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [4:41:55<1:21:50,  4.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [4:41:58<1:18:16,  3.92s/it]                                                       {'loss': 0.0636, 'grad_norm': 6.087030410766602, 'learning_rate': 1.014406779661017e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [4:41:58<1:18:16,  3.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [4:42:02<1:15:13,  3.77s/it]                                                       {'loss': 0.0757, 'grad_norm': 2.802196502685547, 'learning_rate': 1.0135593220338983e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [4:42:02<1:15:13,  3.77s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [4:42:06<1:14:32,  3.74s/it]                                                       {'loss': 0.146, 'grad_norm': 5.609958171844482, 'learning_rate': 1.0127118644067798e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [4:42:06<1:14:32,  3.74s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [4:42:09<1:12:06,  3.62s/it]                                                       {'loss': 0.0114, 'grad_norm': 2.1257925033569336, 'learning_rate': 1.011864406779661e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [4:42:09<1:12:06,  3.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [4:42:12<1:10:51,  3.56s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3232259750366211, 'learning_rate': 1.0110169491525424e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [4:42:12<1:10:51,  3.56s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [4:42:16<1:10:27,  3.55s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.37997952103614807, 'learning_rate': 1.0101694915254238e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [4:42:16<1:10:27,  3.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [4:42:19<1:09:01,  3.48s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.144558310508728, 'learning_rate': 1.0093220338983051e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [4:42:19<1:09:01,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [4:42:23<1:08:16,  3.44s/it]                                                       {'loss': 0.1404, 'grad_norm': 4.6053147315979, 'learning_rate': 1.0084745762711866e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [4:42:23<1:08:16,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [4:42:26<1:07:52,  3.43s/it]                                                       {'loss': 0.0231, 'grad_norm': 2.0900509357452393, 'learning_rate': 1.0076271186440677e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [4:42:26<1:07:52,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [4:42:29<1:08:22,  3.45s/it]                                                       {'loss': 0.0199, 'grad_norm': 2.7250492572784424, 'learning_rate': 1.0067796610169492e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [4:42:29<1:08:22,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [4:42:33<1:07:49,  3.43s/it]                                                       {'loss': 0.0588, 'grad_norm': 7.724752902984619, 'learning_rate': 1.0059322033898305e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [4:42:33<1:07:49,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [4:42:37<1:11:52,  3.64s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3031773865222931, 'learning_rate': 1.005084745762712e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [4:42:37<1:11:52,  3.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [4:42:40<1:10:05,  3.55s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5933800339698792, 'learning_rate': 1.0042372881355933e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [4:42:40<1:10:05,  3.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [4:42:44<1:08:39,  3.48s/it]                                                       {'loss': 0.2541, 'grad_norm': 8.894706726074219, 'learning_rate': 1.0033898305084746e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [4:42:44<1:08:39,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [4:42:47<1:07:54,  3.44s/it]                                                       {'loss': 0.0252, 'grad_norm': 3.2393276691436768, 'learning_rate': 1.002542372881356e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [4:42:47<1:07:54,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [4:42:51<1:10:21,  3.57s/it]                                                       {'loss': 0.0769, 'grad_norm': 4.624879360198975, 'learning_rate': 1.0016949152542373e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [4:42:51<1:10:21,  3.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [4:42:54<1:09:46,  3.55s/it]                                                       {'loss': 0.0458, 'grad_norm': 3.9702558517456055, 'learning_rate': 1.0008474576271188e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [4:42:54<1:09:46,  3.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [4:42:58<1:08:44,  3.50s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.3120206594467163, 'learning_rate': 1e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [4:42:58<1:08:44,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [4:43:01<1:07:45,  3.45s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2538021206855774, 'learning_rate': 9.991525423728815e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [4:43:01<1:07:45,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [4:43:05<1:08:06,  3.47s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.7425671815872192, 'learning_rate': 9.983050847457627e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [4:43:05<1:08:06,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [4:43:08<1:07:19,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.13906942307949066, 'learning_rate': 9.974576271186441e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [4:43:08<1:07:19,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [4:43:11<1:06:50,  3.41s/it]                                                       {'loss': 0.1242, 'grad_norm': 6.913417339324951, 'learning_rate': 9.966101694915254e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [4:43:11<1:06:50,  3.41s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [4:43:15<1:09:03,  3.53s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.6720064878463745, 'learning_rate': 9.957627118644067e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [4:43:15<1:09:03,  3.53s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [4:43:18<1:07:53,  3.47s/it]                                                       {'loss': 0.2281, 'grad_norm': 8.99820327758789, 'learning_rate': 9.949152542372882e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [4:43:18<1:07:53,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [4:43:22<1:07:38,  3.46s/it]                                                       {'loss': 0.3007, 'grad_norm': 7.307105541229248, 'learning_rate': 9.940677966101695e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [4:43:22<1:07:38,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [4:43:25<1:07:10,  3.44s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.48872679471969604, 'learning_rate': 9.93220338983051e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [4:43:25<1:07:10,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [4:43:29<1:07:00,  3.43s/it]                                                       {'loss': 0.1371, 'grad_norm': 7.367702007293701, 'learning_rate': 9.923728813559323e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [4:43:29<1:07:00,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [4:43:33<1:15:01,  3.85s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.25192791223526, 'learning_rate': 9.915254237288137e-06, 'epoch': 0.81}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [4:43:33<1:15:01,  3.85s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [4:43:37<1:13:17,  3.76s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.7246711254119873, 'learning_rate': 9.90677966101695e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [4:43:37<1:13:17,  3.76s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [4:43:40<1:10:51,  3.64s/it]                                                       {'loss': 0.0299, 'grad_norm': 1.0804531574249268, 'learning_rate': 9.898305084745763e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [4:43:40<1:10:51,  3.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [4:43:44<1:12:15,  3.71s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.18533791601657867, 'learning_rate': 9.889830508474576e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [4:43:44<1:12:15,  3.71s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [4:43:48<1:10:13,  3.61s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16746202111244202, 'learning_rate': 9.88135593220339e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [4:43:48<1:10:13,  3.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [4:43:52<1:13:27,  3.78s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.52437162399292, 'learning_rate': 9.872881355932204e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [4:43:52<1:13:27,  3.78s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [4:43:55<1:11:19,  3.68s/it]                                                       {'loss': 0.0767, 'grad_norm': 4.645207405090332, 'learning_rate': 9.864406779661017e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [4:43:55<1:11:19,  3.68s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [4:43:59<1:09:41,  3.60s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.0799466222524643, 'learning_rate': 9.855932203389832e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [4:43:59<1:09:41,  3.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [4:44:02<1:11:01,  3.67s/it]                                                       {'loss': 0.109, 'grad_norm': 5.6503586769104, 'learning_rate': 9.847457627118645e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [4:44:02<1:11:01,  3.67s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [4:44:07<1:15:52,  3.92s/it]                                                       {'loss': 0.0217, 'grad_norm': 2.23323392868042, 'learning_rate': 9.838983050847458e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [4:44:07<1:15:52,  3.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [4:44:10<1:12:35,  3.75s/it]                                                       {'loss': 0.1948, 'grad_norm': 6.046518325805664, 'learning_rate': 9.830508474576272e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [4:44:10<1:12:35,  3.75s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [4:44:14<1:10:29,  3.65s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.1209276914596558, 'learning_rate': 9.822033898305085e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [4:44:14<1:10:29,  3.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [4:44:17<1:09:21,  3.59s/it]                                                       {'loss': 0.0374, 'grad_norm': 5.719027519226074, 'learning_rate': 9.813559322033898e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [4:44:17<1:09:21,  3.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [4:44:21<1:10:11,  3.64s/it]                                                       {'loss': 0.1688, 'grad_norm': 9.042478561401367, 'learning_rate': 9.805084745762711e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [4:44:21<1:10:11,  3.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [4:44:25<1:09:34,  3.61s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.2449643909931183, 'learning_rate': 9.796610169491526e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [4:44:25<1:09:34,  3.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [4:44:28<1:08:44,  3.57s/it]                                                       {'loss': 0.2349, 'grad_norm': 9.424729347229004, 'learning_rate': 9.788135593220339e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [4:44:28<1:08:44,  3.57s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [4:44:31<1:07:14,  3.50s/it]                                                       {'loss': 0.0438, 'grad_norm': 0.4127872586250305, 'learning_rate': 9.779661016949154e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [4:44:31<1:07:14,  3.50s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [4:44:35<1:06:39,  3.47s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.52411949634552, 'learning_rate': 9.771186440677967e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [4:44:35<1:06:39,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [4:44:38<1:05:52,  3.43s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6475226283073425, 'learning_rate': 9.76271186440678e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [4:44:38<1:05:52,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [4:44:42<1:06:15,  3.45s/it]                                                       {'loss': 0.0139, 'grad_norm': 2.0767264366149902, 'learning_rate': 9.754237288135594e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [4:44:42<1:06:15,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [4:44:45<1:06:11,  3.45s/it]                                                       {'loss': 0.0466, 'grad_norm': 4.378381729125977, 'learning_rate': 9.745762711864407e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [4:44:45<1:06:11,  3.45s/it][2025-10-20 04:21:50,348] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [4:44:51<1:19:02,  4.13s/it]                                                       {'loss': 0.0943, 'grad_norm': 6.904473781585693, 'learning_rate': 9.737288135593222e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [4:44:51<1:19:02,  4.13s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [4:44:54<1:14:27,  3.89s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1396704912185669, 'learning_rate': 9.728813559322035e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [4:44:54<1:14:27,  3.89s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [4:44:57<1:10:56,  3.71s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.046963054686784744, 'learning_rate': 9.720338983050848e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [4:44:57<1:10:56,  3.71s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [4:45:01<1:09:17,  3.63s/it]                                                       {'loss': 0.3324, 'grad_norm': 7.9651288986206055, 'learning_rate': 9.71186440677966e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [4:45:01<1:09:17,  3.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [4:45:04<1:09:37,  3.65s/it]                                                       {'loss': 0.038, 'grad_norm': 3.3741402626037598, 'learning_rate': 9.703389830508475e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [4:45:04<1:09:37,  3.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [4:45:08<1:07:19,  3.53s/it]                                                       {'loss': 0.0927, 'grad_norm': 5.917897701263428, 'learning_rate': 9.694915254237288e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [4:45:08<1:07:19,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [4:45:11<1:06:25,  3.49s/it]                                                       {'loss': 0.006, 'grad_norm': 1.341325044631958, 'learning_rate': 9.686440677966101e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [4:45:11<1:06:25,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [4:45:15<1:06:51,  3.51s/it]                                                       {'loss': 0.3816, 'grad_norm': 10.290961265563965, 'learning_rate': 9.677966101694916e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [4:45:15<1:06:51,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [4:45:19<1:08:30,  3.60s/it]                                                       {'loss': 0.0163, 'grad_norm': 2.219024181365967, 'learning_rate': 9.669491525423729e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [4:45:19<1:08:30,  3.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [4:45:22<1:06:45,  3.51s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.3177292346954346, 'learning_rate': 9.661016949152544e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [4:45:22<1:06:45,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [4:45:25<1:06:01,  3.48s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1710321307182312, 'learning_rate': 9.652542372881357e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [4:45:25<1:06:01,  3.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [4:45:29<1:05:27,  3.45s/it]                                                       {'loss': 0.0548, 'grad_norm': 4.561428070068359, 'learning_rate': 9.644067796610171e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [4:45:29<1:05:27,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [4:45:32<1:04:54,  3.43s/it]                                                       {'loss': 0.0558, 'grad_norm': 6.350434303283691, 'learning_rate': 9.635593220338983e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [4:45:32<1:04:54,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [4:45:36<1:07:01,  3.54s/it]                                                       {'loss': 0.1447, 'grad_norm': 6.351319313049316, 'learning_rate': 9.627118644067797e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [4:45:36<1:07:01,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [4:45:39<1:07:16,  3.56s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.789679765701294, 'learning_rate': 9.61864406779661e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [4:45:39<1:07:16,  3.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [4:45:43<1:06:29,  3.52s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.1913864612579346, 'learning_rate': 9.610169491525423e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [4:45:43<1:06:29,  3.52s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [4:45:46<1:05:27,  3.47s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.21688959002494812, 'learning_rate': 9.601694915254238e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [4:45:46<1:05:27,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [4:45:50<1:04:56,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.032087426632642746, 'learning_rate': 9.593220338983051e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [4:45:50<1:04:56,  3.44s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [4:45:53<1:04:40,  3.43s/it]                                                       {'loss': 0.0521, 'grad_norm': 5.259714603424072, 'learning_rate': 9.584745762711866e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [4:45:53<1:04:40,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [4:45:56<1:04:06,  3.40s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.26118114590644836, 'learning_rate': 9.576271186440679e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [4:45:56<1:04:06,  3.40s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [4:46:00<1:07:04,  3.56s/it]                                                       {'loss': 0.0428, 'grad_norm': 4.736275672912598, 'learning_rate': 9.567796610169492e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [4:46:00<1:07:04,  3.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [4:46:04<1:06:23,  3.53s/it]                                                       {'loss': 0.0915, 'grad_norm': 4.896330833435059, 'learning_rate': 9.559322033898306e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [4:46:04<1:06:23,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [4:46:07<1:05:41,  3.50s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.1802774667739868, 'learning_rate': 9.55084745762712e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [4:46:07<1:05:41,  3.50s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [4:46:11<1:05:54,  3.51s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.8937337398529053, 'learning_rate': 9.542372881355932e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [4:46:11<1:05:54,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [4:46:14<1:05:00,  3.47s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.8260167837142944, 'learning_rate': 9.533898305084745e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [4:46:14<1:05:00,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [4:46:18<1:06:52,  3.57s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2765684723854065, 'learning_rate': 9.52542372881356e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [4:46:18<1:06:52,  3.57s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [4:46:21<1:06:11,  3.54s/it]                                                       {'loss': 0.191, 'grad_norm': 6.392406940460205, 'learning_rate': 9.516949152542373e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [4:46:21<1:06:11,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [4:46:25<1:05:29,  3.50s/it]                                                       {'loss': 0.0797, 'grad_norm': 6.600411415100098, 'learning_rate': 9.508474576271188e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [4:46:25<1:05:29,  3.50s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [4:46:28<1:05:16,  3.49s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3153473436832428, 'learning_rate': 9.5e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [4:46:28<1:05:16,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [4:46:32<1:05:12,  3.49s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5660866498947144, 'learning_rate': 9.491525423728814e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [4:46:32<1:05:12,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [4:46:35<1:04:01,  3.43s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.25753355026245117, 'learning_rate': 9.483050847457628e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [4:46:35<1:04:01,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [4:46:38<1:04:03,  3.44s/it]                                                       {'loss': 0.0595, 'grad_norm': 3.2952821254730225, 'learning_rate': 9.474576271186441e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [4:46:38<1:04:03,  3.44s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [4:46:42<1:03:25,  3.41s/it]                                                       {'loss': 0.1418, 'grad_norm': 6.497212886810303, 'learning_rate': 9.466101694915256e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [4:46:42<1:03:25,  3.41s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [4:46:45<1:03:10,  3.40s/it]                                                       {'loss': 0.2347, 'grad_norm': 6.560770034790039, 'learning_rate': 9.457627118644067e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [4:46:45<1:03:10,  3.40s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [4:46:49<1:03:41,  3.43s/it]                                                       {'loss': 0.2285, 'grad_norm': 8.274874687194824, 'learning_rate': 9.449152542372882e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [4:46:49<1:03:41,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [4:46:52<1:04:11,  3.46s/it]                                                       {'loss': 0.0342, 'grad_norm': 4.340173721313477, 'learning_rate': 9.440677966101695e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [4:46:52<1:04:11,  3.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [4:46:56<1:04:15,  3.46s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.8265215754508972, 'learning_rate': 9.43220338983051e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [4:46:56<1:04:15,  3.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [4:46:59<1:03:36,  3.43s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.791715383529663, 'learning_rate': 9.423728813559322e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [4:46:59<1:03:36,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [4:47:02<1:03:12,  3.41s/it]                                                       {'loss': 0.0751, 'grad_norm': 4.95250129699707, 'learning_rate': 9.415254237288135e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [4:47:02<1:03:12,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [4:47:06<1:02:28,  3.38s/it]                                                       {'loss': 0.1501, 'grad_norm': 7.140450954437256, 'learning_rate': 9.40677966101695e-06, 'epoch': 0.81}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [4:47:06<1:02:28,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [4:47:09<1:02:01,  3.36s/it]                                                       {'loss': 0.1701, 'grad_norm': 6.1468915939331055, 'learning_rate': 9.398305084745763e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [4:47:09<1:02:01,  3.36s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [4:47:12<1:01:58,  3.36s/it]                                                       {'loss': 0.1351, 'grad_norm': 5.7074384689331055, 'learning_rate': 9.389830508474578e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [4:47:12<1:01:58,  3.36s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [4:47:16<1:02:17,  3.38s/it]                                                       {'loss': 0.0547, 'grad_norm': 5.082123756408691, 'learning_rate': 9.38135593220339e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [4:47:16<1:02:17,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [4:47:19<1:02:10,  3.37s/it]                                                       {'loss': 0.0331, 'grad_norm': 6.869235038757324, 'learning_rate': 9.372881355932204e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [4:47:19<1:02:10,  3.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [4:47:22<1:02:17,  3.38s/it]                                                       {'loss': 0.0169, 'grad_norm': 1.5372645854949951, 'learning_rate': 9.364406779661017e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [4:47:22<1:02:17,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [4:47:26<1:02:02,  3.37s/it]                                                       {'loss': 0.0379, 'grad_norm': 2.701460599899292, 'learning_rate': 9.355932203389831e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [4:47:26<1:02:02,  3.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [4:47:29<1:01:58,  3.37s/it]                                                       {'loss': 0.1018, 'grad_norm': 3.917733669281006, 'learning_rate': 9.347457627118644e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [4:47:29<1:01:58,  3.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [4:47:33<1:02:05,  3.38s/it]                                                       {'loss': 0.2055, 'grad_norm': 4.483410358428955, 'learning_rate': 9.338983050847457e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [4:47:33<1:02:05,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [4:47:36<1:02:40,  3.42s/it]                                                       {'loss': 0.0208, 'grad_norm': 1.962101697921753, 'learning_rate': 9.330508474576272e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [4:47:36<1:02:40,  3.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [4:47:40<1:04:46,  3.53s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.2861309051513672, 'learning_rate': 9.322033898305085e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [4:47:40<1:04:46,  3.53s/it][2025-10-20 04:24:45,223] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [4:47:46<1:16:10,  4.16s/it]                                                       {'loss': 0.0663, 'grad_norm': 3.462578058242798, 'learning_rate': 9.3135593220339e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [4:47:46<1:16:10,  4.16s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [4:47:49<1:11:46,  3.92s/it]                                                       {'loss': 0.0466, 'grad_norm': 2.49161958694458, 'learning_rate': 9.305084745762713e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [4:47:49<1:11:46,  3.92s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [4:47:52<1:09:25,  3.80s/it]                                                       {'loss': 0.005, 'grad_norm': 1.194940447807312, 'learning_rate': 9.296610169491526e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [4:47:52<1:09:25,  3.80s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [4:47:56<1:07:15,  3.68s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.0878510475158691, 'learning_rate': 9.28813559322034e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [4:47:56<1:07:15,  3.68s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [4:47:59<1:06:12,  3.63s/it]                                                       {'loss': 0.012, 'grad_norm': 0.6579506397247314, 'learning_rate': 9.279661016949153e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [4:47:59<1:06:12,  3.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [4:48:03<1:04:19,  3.53s/it]                                                       {'loss': 0.0448, 'grad_norm': 5.444867134094238, 'learning_rate': 9.271186440677966e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [4:48:03<1:04:19,  3.53s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [4:48:06<1:03:50,  3.50s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.3302663266658783, 'learning_rate': 9.26271186440678e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [4:48:06<1:03:50,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [4:48:09<1:03:17,  3.48s/it]                                                       {'loss': 0.1107, 'grad_norm': 7.652631759643555, 'learning_rate': 9.254237288135594e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [4:48:09<1:03:17,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [4:48:13<1:02:34,  3.44s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.102605938911438, 'learning_rate': 9.245762711864407e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [4:48:13<1:02:34,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [4:48:16<1:02:45,  3.45s/it]                                                       {'loss': 0.0642, 'grad_norm': 4.525345802307129, 'learning_rate': 9.237288135593222e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [4:48:16<1:02:45,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [4:48:20<1:01:49,  3.41s/it]                                                       {'loss': 0.0886, 'grad_norm': 7.564700126647949, 'learning_rate': 9.228813559322035e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [4:48:20<1:01:49,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [4:48:23<1:01:33,  3.39s/it]                                                       {'loss': 0.0876, 'grad_norm': 2.8179497718811035, 'learning_rate': 9.220338983050847e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [4:48:23<1:01:33,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [4:48:26<1:01:30,  3.40s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.7739818692207336, 'learning_rate': 9.211864406779662e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [4:48:26<1:01:30,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [4:48:30<1:01:30,  3.40s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.5108624696731567, 'learning_rate': 9.203389830508475e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [4:48:30<1:01:30,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [4:48:33<1:01:58,  3.43s/it]                                                       {'loss': 0.0346, 'grad_norm': 3.886813163757324, 'learning_rate': 9.194915254237288e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [4:48:33<1:01:58,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [4:48:37<1:01:59,  3.43s/it]                                                       {'loss': 0.0328, 'grad_norm': 3.6401970386505127, 'learning_rate': 9.186440677966101e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [4:48:37<1:01:59,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [4:48:40<1:02:01,  3.44s/it]                                                       {'loss': 0.0107, 'grad_norm': 0.8889790177345276, 'learning_rate': 9.177966101694916e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [4:48:40<1:02:01,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [4:48:44<1:02:33,  3.47s/it]                                                       {'loss': 0.0224, 'grad_norm': 0.9388999342918396, 'learning_rate': 9.169491525423729e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [4:48:44<1:02:33,  3.47s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [4:48:47<1:02:15,  3.46s/it]                                                       {'loss': 0.1544, 'grad_norm': 9.27454662322998, 'learning_rate': 9.161016949152543e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [4:48:47<1:02:15,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [4:48:51<1:02:02,  3.45s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6957288384437561, 'learning_rate': 9.152542372881356e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [4:48:51<1:02:02,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [4:48:54<1:02:02,  3.45s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.83821439743042, 'learning_rate': 9.14406779661017e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [4:48:54<1:02:02,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [4:48:58<1:04:30,  3.59s/it]                                                       {'loss': 0.0224, 'grad_norm': 2.823509693145752, 'learning_rate': 9.135593220338984e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [4:48:58<1:04:30,  3.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [4:49:01<1:03:54,  3.56s/it]                                                       {'loss': 0.0806, 'grad_norm': 3.7558176517486572, 'learning_rate': 9.127118644067797e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [4:49:01<1:03:54,  3.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [4:49:05<1:02:42,  3.50s/it]                                                       {'loss': 0.0361, 'grad_norm': 1.9391447305679321, 'learning_rate': 9.118644067796612e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [4:49:05<1:02:42,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [4:49:08<1:03:54,  3.57s/it]                                                       {'loss': 0.1575, 'grad_norm': 7.786468029022217, 'learning_rate': 9.110169491525423e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [4:49:09<1:03:54,  3.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [4:49:12<1:03:29,  3.55s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.6161620616912842, 'learning_rate': 9.101694915254238e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [4:49:12<1:03:29,  3.55s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [4:49:15<1:02:31,  3.50s/it]                                                       {'loss': 0.0236, 'grad_norm': 2.9336163997650146, 'learning_rate': 9.09322033898305e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [4:49:15<1:02:31,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [4:49:19<1:01:39,  3.45s/it]                                                       {'loss': 0.139, 'grad_norm': 8.858800888061523, 'learning_rate': 9.084745762711865e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [4:49:19<1:01:39,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [4:49:22<1:02:07,  3.48s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.8959572911262512, 'learning_rate': 9.076271186440678e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [4:49:22<1:02:07,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [4:49:26<1:01:18,  3.44s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.149248480796814, 'learning_rate': 9.067796610169491e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [4:49:26<1:01:18,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [4:49:29<1:02:16,  3.50s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.197324275970459, 'learning_rate': 9.059322033898306e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [4:49:29<1:02:16,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [4:49:33<1:01:31,  3.46s/it]                                                       {'loss': 0.1813, 'grad_norm': 7.58647346496582, 'learning_rate': 9.050847457627119e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [4:49:33<1:01:31,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [4:49:36<1:00:28,  3.40s/it]                                                       {'loss': 0.283, 'grad_norm': 7.778563499450684, 'learning_rate': 9.042372881355934e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [4:49:36<1:00:28,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [4:49:39<1:00:22,  3.40s/it]                                                       {'loss': 0.026, 'grad_norm': 2.8055543899536133, 'learning_rate': 9.033898305084747e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [4:49:39<1:00:22,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [4:49:43<1:00:25,  3.40s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.9741649627685547, 'learning_rate': 9.02542372881356e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [4:49:43<1:00:25,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [4:49:47<1:05:47,  3.71s/it]                                                       {'loss': 0.0293, 'grad_norm': 3.368940830230713, 'learning_rate': 9.016949152542373e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [4:49:47<1:05:47,  3.71s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [4:49:51<1:08:58,  3.89s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.4742858409881592, 'learning_rate': 9.008474576271187e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [4:49:51<1:08:58,  3.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [4:49:55<1:06:59,  3.78s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.650850772857666, 'learning_rate': 9e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [4:49:55<1:06:59,  3.78s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [4:49:58<1:04:46,  3.66s/it]                                                       {'loss': 0.0208, 'grad_norm': 2.467271089553833, 'learning_rate': 8.991525423728813e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [4:49:58<1:04:46,  3.66s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [4:50:02<1:03:49,  3.61s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.7234046459197998, 'learning_rate': 8.983050847457628e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [4:50:02<1:03:49,  3.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [4:50:05<1:02:36,  3.55s/it]                                                       {'loss': 0.0258, 'grad_norm': 3.7825307846069336, 'learning_rate': 8.974576271186441e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [4:50:05<1:02:36,  3.55s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [4:50:09<1:02:23,  3.54s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.2950605154037476, 'learning_rate': 8.966101694915256e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [4:50:09<1:02:23,  3.54s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [4:50:12<1:01:53,  3.51s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.6595540046691895, 'learning_rate': 8.957627118644069e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [4:50:12<1:01:53,  3.51s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [4:50:16<1:01:17,  3.48s/it]                                                       {'loss': 0.0282, 'grad_norm': 2.9516212940216064, 'learning_rate': 8.949152542372881e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [4:50:16<1:01:17,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [4:50:19<1:02:26,  3.55s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06344106793403625, 'learning_rate': 8.940677966101696e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [4:50:19<1:02:26,  3.55s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [4:50:23<1:01:35,  3.51s/it]                                                       {'loss': 0.1257, 'grad_norm': 6.352939128875732, 'learning_rate': 8.932203389830507e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [4:50:23<1:01:35,  3.51s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [4:50:26<1:01:04,  3.48s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.3638888597488403, 'learning_rate': 8.923728813559322e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [4:50:26<1:01:04,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [4:50:31<1:05:41,  3.75s/it]                                                       {'loss': 0.0984, 'grad_norm': 7.337754249572754, 'learning_rate': 8.915254237288135e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [4:50:31<1:05:41,  3.75s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [4:50:34<1:03:28,  3.62s/it]                                                       {'loss': 0.0548, 'grad_norm': 6.35614538192749, 'learning_rate': 8.90677966101695e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [4:50:34<1:03:28,  3.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [4:50:37<1:02:19,  3.56s/it]                                                       {'loss': 0.1876, 'grad_norm': 6.384278774261475, 'learning_rate': 8.898305084745763e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [4:50:37<1:02:19,  3.56s/it][2025-10-20 04:27:42,595] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [4:50:43<1:16:08,  4.35s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10684023797512054, 'learning_rate': 8.889830508474577e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [4:50:43<1:16:08,  4.35s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [4:50:47<1:13:20,  4.20s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.04666006565094, 'learning_rate': 8.88135593220339e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [4:50:47<1:13:20,  4.20s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [4:50:51<1:08:29,  3.93s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0011153705418109894, 'learning_rate': 8.872881355932203e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [4:50:51<1:08:29,  3.93s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [4:50:54<1:07:46,  3.89s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05459916964173317, 'learning_rate': 8.864406779661018e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [4:50:54<1:07:46,  3.89s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [4:50:58<1:05:28,  3.76s/it]                                                       {'loss': 0.0549, 'grad_norm': 5.639049053192139, 'learning_rate': 8.855932203389831e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [4:50:58<1:05:28,  3.76s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [4:51:01<1:03:37,  3.66s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.7807174324989319, 'learning_rate': 8.847457627118646e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [4:51:01<1:03:37,  3.66s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [4:51:05<1:03:38,  3.66s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1635817289352417, 'learning_rate': 8.838983050847457e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [4:51:05<1:03:38,  3.66s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [4:51:08<1:02:23,  3.59s/it]                                                       {'loss': 0.0042, 'grad_norm': 2.010910987854004, 'learning_rate': 8.830508474576272e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [4:51:08<1:02:23,  3.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [4:51:12<1:03:09,  3.64s/it]                                                       {'loss': 0.0151, 'grad_norm': 2.4584574699401855, 'learning_rate': 8.822033898305085e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [4:51:12<1:03:09,  3.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [4:51:16<1:02:35,  3.61s/it]                                                       {'loss': 0.0457, 'grad_norm': 5.1986212730407715, 'learning_rate': 8.8135593220339e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [4:51:16<1:02:35,  3.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [4:51:19<1:03:11,  3.65s/it]                                                       {'loss': 0.1089, 'grad_norm': 7.082550525665283, 'learning_rate': 8.805084745762712e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [4:51:19<1:03:11,  3.65s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [4:51:23<1:04:50,  3.75s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.07537872344255447, 'learning_rate': 8.796610169491525e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [4:51:23<1:04:50,  3.75s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [4:51:27<1:03:27,  3.67s/it]                                                       {'loss': 0.0779, 'grad_norm': 5.650496482849121, 'learning_rate': 8.78813559322034e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [4:51:27<1:03:27,  3.67s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [4:51:30<1:01:33,  3.57s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13632118701934814, 'learning_rate': 8.779661016949153e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [4:51:30<1:01:33,  3.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [4:51:34<1:01:00,  3.54s/it]                                                       {'loss': 0.0873, 'grad_norm': 8.939496040344238, 'learning_rate': 8.771186440677968e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [4:51:34<1:01:00,  3.54s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [4:51:37<1:01:16,  3.56s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.7293427586555481, 'learning_rate': 8.76271186440678e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [4:51:37<1:01:16,  3.56s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [4:51:41<1:01:00,  3.54s/it]                                                       {'loss': 0.003, 'grad_norm': 0.4199671745300293, 'learning_rate': 8.754237288135594e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [4:51:41<1:01:00,  3.54s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [4:51:44<1:00:04,  3.49s/it]                                                       {'loss': 0.0779, 'grad_norm': 5.486323833465576, 'learning_rate': 8.745762711864407e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [4:51:44<1:00:04,  3.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [4:51:47<59:08,  3.44s/it]                                                       {'loss': 0.086, 'grad_norm': 5.892845630645752, 'learning_rate': 8.737288135593221e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [4:51:47<59:08,  3.44s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [4:51:51<58:42,  3.42s/it]                                                     {'loss': 0.1087, 'grad_norm': 7.966152191162109, 'learning_rate': 8.728813559322034e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [4:51:51<58:42,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [4:51:54<58:24,  3.41s/it]                                                     {'loss': 0.0722, 'grad_norm': 3.934891939163208, 'learning_rate': 8.720338983050847e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [4:51:54<58:24,  3.41s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [4:51:58<57:52,  3.38s/it]                                                     {'loss': 0.0271, 'grad_norm': 3.922248601913452, 'learning_rate': 8.711864406779662e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [4:51:58<57:52,  3.38s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [4:52:01<58:09,  3.40s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.31109511852264404, 'learning_rate': 8.703389830508475e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [4:52:01<58:09,  3.40s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [4:52:05<59:44,  3.49s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.09693676978349686, 'learning_rate': 8.69491525423729e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [4:52:05<59:44,  3.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [4:52:08<59:26,  3.48s/it]                                                     {'loss': 0.1284, 'grad_norm': 6.922426223754883, 'learning_rate': 8.686440677966103e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [4:52:08<59:26,  3.48s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [4:52:12<59:01,  3.46s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.48675376176834106, 'learning_rate': 8.677966101694915e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [4:52:12<59:01,  3.46s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [4:52:15<58:23,  3.42s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.20215639472007751, 'learning_rate': 8.669491525423728e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [4:52:15<58:23,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [4:52:18<58:15,  3.42s/it]                                                     {'loss': 0.0, 'grad_norm': 0.006559303496032953, 'learning_rate': 8.661016949152541e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [4:52:18<58:15,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [4:52:22<59:04,  3.47s/it]                                                     {'loss': 0.0693, 'grad_norm': 3.3871912956237793, 'learning_rate': 8.652542372881356e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [4:52:22<59:04,  3.47s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [4:52:26<1:00:56,  3.58s/it]                                                       {'loss': 0.0938, 'grad_norm': 4.750421524047852, 'learning_rate': 8.644067796610169e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [4:52:26<1:00:56,  3.58s/it]Traceback (most recent call last):
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
    main()
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 104, in main
    trainer.train(resume_from_checkpoint=resume_checkpoint_dir)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 510, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 708, in training_step
    loss = self.gc(queries, targets, no_sync_except_last=_distributed)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 71, in __call__
    return self.cache_step(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 294, in cache_step
    self.forward_backward(model, x, model_cache, rnd_states, no_sync_except_last=no_sync_except_last)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 239, in forward_backward
    y = self.model_call(model, x)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 141, in model_call
    return model(**model_input)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 334, in forward
    tgt_reps = self.encode_input(tgt, self.tgt_chosen_layer) if tgt else None # (bsz_per_device, dim)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 110, in encode_input
    hidden_states = self.encoder(**input, return_dict=True, output_hidden_states=True)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/peft/peft_model.py", line 881, in forward
    return self.get_base_model()(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/vlm_backbone/qwen2_vl/modeling_qwen2_vl.py", line 1777, in forward
    logits = self.lm_head(hidden_states)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.56 GiB of which 781.00 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 20.06 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
[rank0]:     main()
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 104, in main
[rank0]:     trainer.train(resume_from_checkpoint=resume_checkpoint_dir)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 510, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 708, in training_step
[rank0]:     loss = self.gc(queries, targets, no_sync_except_last=_distributed)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 71, in __call__
[rank0]:     return self.cache_step(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 294, in cache_step
[rank0]:     self.forward_backward(model, x, model_cache, rnd_states, no_sync_except_last=no_sync_except_last)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 239, in forward_backward
[rank0]:     y = self.model_call(model, x)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 141, in model_call
[rank0]:     return model(**model_input)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 334, in forward
[rank0]:     tgt_reps = self.encode_input(tgt, self.tgt_chosen_layer) if tgt else None # (bsz_per_device, dim)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 110, in encode_input
[rank0]:     hidden_states = self.encoder(**input, return_dict=True, output_hidden_states=True)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/peft/peft_model.py", line 881, in forward
[rank0]:     return self.get_base_model()(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/vlm_backbone/qwen2_vl/modeling_qwen2_vl.py", line 1777, in forward
[rank0]:     logits = self.lm_head(hidden_states)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.56 GiB of which 781.00 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 20.06 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33moriginal-bs16-Qwen/Qwen2-VL-2B-Instruct[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/public/exps/train/original-bs16-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251019_233645-bjfxbo46/logs[0m
W1020 04:29:39.189000 125331774928704 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 212284 closing signal SIGTERM
E1020 04:29:39.704000 125331774928704 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 212283) of binary: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python3.10
Traceback (most recent call last):
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-20_04:29:39
  host      : node40.enst.fr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 212283)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Job finished at: lun. 20 oct. 2025 04:29:40 CEST
