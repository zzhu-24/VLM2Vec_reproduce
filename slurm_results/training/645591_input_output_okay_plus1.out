==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test4-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name test4-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test4-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test4-Qwen/Qwen2-VL-2B-Instruct/train.log
W1022 23:50:18.556000 137042557376320 torch/distributed/run.py:779] 
W1022 23:50:18.556000 137042557376320 torch/distributed/run.py:779] *****************************************
W1022 23:50:18.556000 137042557376320 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 23:50:18.556000 137042557376320 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-22 23:50:28,276] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.09it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.86it/s]
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test4-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251022_235028-tvunzrye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run test4-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/tvunzrye
[2025-10-22 23:50:29,838] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.18it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.02it/s]
[2025-10-22 23:50:30,514] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-10-22 23:50:39,464] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-22 23:50:40,689] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-22 23:50:40,690] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-22 23:50:44,997] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-22 23:50:44,998] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-22 23:50:45,845] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-22 23:50:45,845] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-22 23:50:45,846] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-22 23:50:45,847] INFO [src.utils:19] ==================================================
[2025-10-22 23:50:45,848] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-22 23:50:45,849] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-22 23:50:45,850] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-22 23:50:45,850] INFO [src.utils:19] ==================================================
[2025-10-22 23:50:47,596] INFO [src.trainer:342] ***** Running training *****
[2025-10-22 23:50:47,596] INFO [src.trainer:342] ***** Running training *****
[2025-10-22 23:50:47,596] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-22 23:50:47,596] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-22 23:50:47,596] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-22 23:50:47,596] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-22 23:50:47,597] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-22 23:50:47,597] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-22 23:50:47,597] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-22 23:50:47,597] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-22 23:50:47,598] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-22 23:50:47,598] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-22 23:50:47,598] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-22 23:50:47,599] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-22 23:50:47,605] INFO [src.trainer:351]   Number of trainable parameters = 9,205,248
[2025-10-22 23:50:47,606] INFO [src.trainer:351]   Number of trainable parameters = 9,205,248
[2025-10-22 23:50:47,613] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.tail_token', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-10-22 23:50:47,617] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.tail_token', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[2025-10-22 23:50:48,624] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:48,631] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:49,279] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:49,280] INFO [src.utils:19] 29
[2025-10-22 23:50:49,280] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:49,307] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:49,307] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:49,515] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:49,515] INFO [src.utils:19] 29
[2025-10-22 23:50:49,515] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:49,527] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:49,528] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:49,770] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:49,770] INFO [src.utils:19] 29
[2025-10-22 23:50:49,771] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:49,783] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:49,783] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:49,998] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:49,999] INFO [src.utils:19] 29
[2025-10-22 23:50:49,999] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:50,057] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:50,058] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:50,277] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:50,278] INFO [src.utils:19] 29
[2025-10-22 23:50:50,278] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:50,505] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:50,506] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:50,720] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:50,721] INFO [src.utils:19] 29
[2025-10-22 23:50:50,721] INFO [src.utils:19] torch.Size([8, 138, 1536])
[rank0]:[W1022 23:50:50.326957295 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1022 23:50:50.364912781 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2025-10-22 23:50:50,924] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:50,925] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:51,177] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:51,178] INFO [src.utils:19] 29
[2025-10-22 23:50:51,178] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:51,354] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:51,354] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:50:51,577] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:51,577] INFO [src.utils:19] 29
[2025-10-22 23:50:51,578] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 1/6000 [00:04<6:46:02,  4.06s/it]                                                  {'loss': 10.6769, 'grad_norm': 5219.6962890625, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<6:46:02,  4.06s/it][2025-10-22 23:50:51,895] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:51,895] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:52,199] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:52,200] INFO [src.utils:19] 29
[2025-10-22 23:50:52,200] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:52,212] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:52,213] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:52,425] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:52,425] INFO [src.utils:19] 29
[2025-10-22 23:50:52,425] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:52,438] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:52,438] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:52,648] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:52,649] INFO [src.utils:19] 29
[2025-10-22 23:50:52,649] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:52,660] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:52,661] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:52,871] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:52,872] INFO [src.utils:19] 29
[2025-10-22 23:50:52,872] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:52,885] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:52,885] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:53,137] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:53,137] INFO [src.utils:19] 29
[2025-10-22 23:50:53,137] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:53,314] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:53,314] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:53,526] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:53,527] INFO [src.utils:19] 29
[2025-10-22 23:50:53,527] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:53,728] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:53,729] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:53,941] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:53,941] INFO [src.utils:19] 29
[2025-10-22 23:50:53,941] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:54,123] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:54,124] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:54,341] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:54,342] INFO [src.utils:19] 29
[2025-10-22 23:50:54,342] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 2/6000 [00:06<5:25:29,  3.26s/it]                                                  {'loss': 8.7968, 'grad_norm': 5261.33056640625, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:06<5:25:29,  3.26s/it][2025-10-22 23:50:54,585] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:54,586] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:54,829] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:54,830] INFO [src.utils:19] 29
[2025-10-22 23:50:54,831] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:54,842] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:54,843] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:55,071] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:55,072] INFO [src.utils:19] 29
[2025-10-22 23:50:55,072] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:55,084] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:55,085] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:55,291] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:55,292] INFO [src.utils:19] 29
[2025-10-22 23:50:55,292] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:55,304] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:55,304] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:55,510] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:55,510] INFO [src.utils:19] 29
[2025-10-22 23:50:55,511] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:55,524] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:55,525] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:55,823] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:55,824] INFO [src.utils:19] 29
[2025-10-22 23:50:55,824] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:55,999] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:56,000] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:56,212] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:56,213] INFO [src.utils:19] 29
[2025-10-22 23:50:56,213] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:56,418] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:56,419] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:56,631] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:56,632] INFO [src.utils:19] 29
[2025-10-22 23:50:56,632] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:56,814] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:56,814] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:50:57,025] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:57,026] INFO [src.utils:19] 29
[2025-10-22 23:50:57,026] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 3/6000 [00:09<5:03:40,  3.04s/it]                                                  {'loss': 8.6943, 'grad_norm': 4452.48291015625, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:09<5:03:40,  3.04s/it][2025-10-22 23:50:57,366] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:57,367] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:57,648] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:57,649] INFO [src.utils:19] 29
[2025-10-22 23:50:57,649] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:57,660] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:57,661] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:57,873] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:57,874] INFO [src.utils:19] 29
[2025-10-22 23:50:57,874] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:57,886] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:57,886] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:58,122] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:58,122] INFO [src.utils:19] 29
[2025-10-22 23:50:58,122] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:58,137] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:58,137] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:58,368] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:58,369] INFO [src.utils:19] 29
[2025-10-22 23:50:58,369] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:58,385] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:58,385] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:58,601] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:58,602] INFO [src.utils:19] 29
[2025-10-22 23:50:58,602] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:58,775] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:58,775] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:58,988] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:58,989] INFO [src.utils:19] 29
[2025-10-22 23:50:58,989] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:50:59,193] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:59,194] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:59,432] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:59,432] INFO [src.utils:19] 29
[2025-10-22 23:50:59,433] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:59,618] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:50:59,618] INFO [src.utils:19] torch.Size([8, 187, 1536])
[2025-10-22 23:50:59,872] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:50:59,873] INFO [src.utils:19] 29
[2025-10-22 23:50:59,873] INFO [src.utils:19] torch.Size([8, 187, 1536])
  0%|          | 4/6000 [00:12<4:53:01,  2.93s/it]                                                  {'loss': 8.5831, 'grad_norm': 5051.95654296875, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:12<4:53:01,  2.93s/it][2025-10-22 23:51:00,137] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:00,137] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:00,497] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:00,497] INFO [src.utils:19] 29
[2025-10-22 23:51:00,498] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:00,511] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:00,512] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:00,731] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:00,731] INFO [src.utils:19] 29
[2025-10-22 23:51:00,732] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:00,745] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:00,746] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:00,957] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:00,958] INFO [src.utils:19] 29
[2025-10-22 23:51:00,958] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:00,969] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:00,970] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:01,175] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:01,175] INFO [src.utils:19] 29
[2025-10-22 23:51:01,176] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:01,189] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:01,189] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:01,408] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:01,409] INFO [src.utils:19] 29
[2025-10-22 23:51:01,409] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:01,586] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:01,587] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:01,808] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:01,808] INFO [src.utils:19] 29
[2025-10-22 23:51:01,808] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:02,011] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:02,012] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:02,221] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:02,221] INFO [src.utils:19] 29
[2025-10-22 23:51:02,222] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:02,398] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:02,399] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:02,608] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:02,609] INFO [src.utils:19] 29
[2025-10-22 23:51:02,609] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 5/6000 [00:15<4:45:25,  2.86s/it]                                                  {'loss': 8.3431, 'grad_norm': 4738.0625, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:15<4:45:25,  2.86s/it][2025-10-22 23:51:02,858] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:02,859] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:03,186] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:03,187] INFO [src.utils:19] 29
[2025-10-22 23:51:03,187] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:03,198] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:03,199] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:03,411] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:03,411] INFO [src.utils:19] 29
[2025-10-22 23:51:03,411] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:03,423] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:03,424] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:03,629] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:03,629] INFO [src.utils:19] 29
[2025-10-22 23:51:03,630] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:03,641] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:03,642] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:03,846] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:03,847] INFO [src.utils:19] 29
[2025-10-22 23:51:03,847] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:03,860] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:03,861] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:04,072] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:04,072] INFO [src.utils:19] 29
[2025-10-22 23:51:04,072] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:04,245] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:04,246] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:04,457] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:04,457] INFO [src.utils:19] 29
[2025-10-22 23:51:04,458] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:04,659] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:04,659] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:04,921] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:04,921] INFO [src.utils:19] 29
[2025-10-22 23:51:04,921] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:05,097] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:05,097] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:05,308] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:05,309] INFO [src.utils:19] 29
[2025-10-22 23:51:05,309] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 6/6000 [00:17<4:39:57,  2.80s/it]                                                  {'loss': 8.2489, 'grad_norm': 5359.07275390625, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:17<4:39:57,  2.80s/it][2025-10-22 23:51:05,556] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:05,556] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:05,884] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:05,885] INFO [src.utils:19] 29
[2025-10-22 23:51:05,886] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:05,897] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:05,898] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:06,105] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:06,105] INFO [src.utils:19] 29
[2025-10-22 23:51:06,106] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:06,117] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:06,118] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:06,333] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:06,333] INFO [src.utils:19] 29
[2025-10-22 23:51:06,334] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:06,347] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:06,348] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:06,566] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:06,567] INFO [src.utils:19] 29
[2025-10-22 23:51:06,567] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:06,581] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:06,581] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:06,792] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:06,793] INFO [src.utils:19] 29
[2025-10-22 23:51:06,793] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:06,967] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:06,968] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:07,183] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:07,183] INFO [src.utils:19] 29
[2025-10-22 23:51:07,184] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:07,399] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:07,400] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:07,624] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:07,625] INFO [src.utils:19] 29
[2025-10-22 23:51:07,625] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:07,811] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:07,811] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:08,034] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:08,035] INFO [src.utils:19] 29
[2025-10-22 23:51:08,035] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 7/6000 [00:20<4:37:36,  2.78s/it]                                                  {'loss': 7.1351, 'grad_norm': 3777.47900390625, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:20<4:37:36,  2.78s/it][2025-10-22 23:51:08,292] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:08,293] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:08,538] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:08,539] INFO [src.utils:19] 29
[2025-10-22 23:51:08,540] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:08,552] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:08,552] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:08,776] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:08,776] INFO [src.utils:19] 29
[2025-10-22 23:51:08,777] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:08,788] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:08,789] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:08,996] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:08,997] INFO [src.utils:19] 29
[2025-10-22 23:51:08,997] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:09,009] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:09,010] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:09,220] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:09,220] INFO [src.utils:19] 29
[2025-10-22 23:51:09,220] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:09,233] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:09,234] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:09,465] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:09,465] INFO [src.utils:19] 29
[2025-10-22 23:51:09,466] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:09,645] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:09,645] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:09,857] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:09,857] INFO [src.utils:19] 29
[2025-10-22 23:51:09,858] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:10,062] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:10,063] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:10,273] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:10,273] INFO [src.utils:19] 29
[2025-10-22 23:51:10,274] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:10,451] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:10,451] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:10,668] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:10,668] INFO [src.utils:19] 29
[2025-10-22 23:51:10,669] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 8/6000 [00:23<4:33:04,  2.73s/it]                                                  {'loss': 7.0201, 'grad_norm': 4707.9921875, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:23<4:33:04,  2.73s/it][2025-10-22 23:51:10,922] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:10,923] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:11,198] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:11,199] INFO [src.utils:19] 29
[2025-10-22 23:51:11,199] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:11,213] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:11,213] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:11,440] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:11,440] INFO [src.utils:19] 29
[2025-10-22 23:51:11,441] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:11,455] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:11,455] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:11,675] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:11,676] INFO [src.utils:19] 29
[2025-10-22 23:51:11,676] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:11,689] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:11,690] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:11,910] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:11,910] INFO [src.utils:19] 29
[2025-10-22 23:51:11,910] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:11,925] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:11,925] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:12,155] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:12,156] INFO [src.utils:19] 29
[2025-10-22 23:51:12,156] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:12,335] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:12,335] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:12,570] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:12,571] INFO [src.utils:19] 29
[2025-10-22 23:51:12,571] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:51:12,787] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:12,788] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:13,008] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:13,009] INFO [src.utils:19] 29
[2025-10-22 23:51:13,009] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:13,197] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:13,198] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:13,419] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:13,420] INFO [src.utils:19] 29
[2025-10-22 23:51:13,420] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 9/6000 [00:25<4:33:26,  2.74s/it]                                                  {'loss': 5.4401, 'grad_norm': 2511.109619140625, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:25<4:33:26,  2.74s/it][2025-10-22 23:51:13,679] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:13,680] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:14,016] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:14,016] INFO [src.utils:19] 29
[2025-10-22 23:51:14,017] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:14,028] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:14,028] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:14,237] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:14,237] INFO [src.utils:19] 29
[2025-10-22 23:51:14,238] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:14,249] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:14,250] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:14,457] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:14,457] INFO [src.utils:19] 29
[2025-10-22 23:51:14,458] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:14,469] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:14,469] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:14,675] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:14,676] INFO [src.utils:19] 29
[2025-10-22 23:51:14,676] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:14,689] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:14,690] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:14,905] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:14,906] INFO [src.utils:19] 29
[2025-10-22 23:51:14,906] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:15,079] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:15,079] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:15,292] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:15,292] INFO [src.utils:19] 29
[2025-10-22 23:51:15,293] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:15,495] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:15,496] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:15,706] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:15,706] INFO [src.utils:19] 29
[2025-10-22 23:51:15,707] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:15,883] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:15,883] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:16,094] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:16,095] INFO [src.utils:19] 29
[2025-10-22 23:51:16,095] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 10/6000 [00:28<4:31:15,  2.72s/it]                                                   {'loss': 5.5054, 'grad_norm': 2254.932373046875, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:28<4:31:15,  2.72s/it][2025-10-22 23:51:16,336] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:16,336] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:16,652] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:16,653] INFO [src.utils:19] 29
[2025-10-22 23:51:16,654] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:16,670] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:16,671] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:16,935] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:16,936] INFO [src.utils:19] 29
[2025-10-22 23:51:16,936] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:16,953] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:16,953] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:17,161] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:17,161] INFO [src.utils:19] 29
[2025-10-22 23:51:17,162] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:17,173] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:17,174] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:17,378] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:17,379] INFO [src.utils:19] 29
[2025-10-22 23:51:17,379] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:17,392] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:17,393] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:17,659] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:17,660] INFO [src.utils:19] 29
[2025-10-22 23:51:17,660] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:17,901] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:17,901] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:18,201] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:18,201] INFO [src.utils:19] 29
[2025-10-22 23:51:18,201] INFO [src.utils:19] torch.Size([8, 219, 1536])
[2025-10-22 23:51:18,472] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:18,473] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:18,694] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:18,694] INFO [src.utils:19] 29
[2025-10-22 23:51:18,695] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:18,877] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:18,877] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:19,087] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:19,088] INFO [src.utils:19] 29
[2025-10-22 23:51:19,088] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 11/6000 [00:31<4:39:26,  2.80s/it]                                                   {'loss': 5.7694, 'grad_norm': 2719.519287109375, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:31<4:39:26,  2.80s/it][2025-10-22 23:51:19,334] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:19,335] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:19,660] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:19,660] INFO [src.utils:19] 29
[2025-10-22 23:51:19,661] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:19,673] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:19,674] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:19,891] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:19,892] INFO [src.utils:19] 29
[2025-10-22 23:51:19,892] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:19,905] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:19,905] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:20,144] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:20,145] INFO [src.utils:19] 29
[2025-10-22 23:51:20,145] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:20,161] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:20,161] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:20,403] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:20,403] INFO [src.utils:19] 29
[2025-10-22 23:51:20,404] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:20,421] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:20,421] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:20,640] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:20,641] INFO [src.utils:19] 29
[2025-10-22 23:51:20,641] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:20,819] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:20,819] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:21,040] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:21,040] INFO [src.utils:19] 29
[2025-10-22 23:51:21,041] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:21,253] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:21,254] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:21,499] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:21,499] INFO [src.utils:19] 29
[2025-10-22 23:51:21,500] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:21,696] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:21,696] INFO [src.utils:19] torch.Size([8, 205, 1536])
[2025-10-22 23:51:21,963] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:21,963] INFO [src.utils:19] 29
[2025-10-22 23:51:21,964] INFO [src.utils:19] torch.Size([8, 205, 1536])
  0%|          | 12/6000 [00:34<4:42:50,  2.83s/it]                                                   {'loss': 5.1267, 'grad_norm': 1727.198974609375, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:34<4:42:50,  2.83s/it][2025-10-22 23:51:22,236] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:22,237] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:22,520] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:22,521] INFO [src.utils:19] 29
[2025-10-22 23:51:22,521] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:22,531] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:22,532] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:22,767] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:22,768] INFO [src.utils:19] 29
[2025-10-22 23:51:22,768] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:22,781] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:22,781] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:22,999] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:23,000] INFO [src.utils:19] 29
[2025-10-22 23:51:23,000] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:23,014] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:23,014] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:23,233] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:23,234] INFO [src.utils:19] 29
[2025-10-22 23:51:23,234] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:23,248] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:23,249] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:23,468] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:23,468] INFO [src.utils:19] 29
[2025-10-22 23:51:23,469] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:23,641] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:23,641] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:23,863] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:23,864] INFO [src.utils:19] 29
[2025-10-22 23:51:23,864] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:24,065] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:24,066] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:24,287] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:24,288] INFO [src.utils:19] 29
[2025-10-22 23:51:24,288] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:24,462] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:24,463] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:24,687] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:24,688] INFO [src.utils:19] 29
[2025-10-22 23:51:24,688] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 13/6000 [00:37<4:39:29,  2.80s/it]                                                   {'loss': 4.5011, 'grad_norm': 871.359619140625, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:37<4:39:29,  2.80s/it][2025-10-22 23:51:24,969] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:24,970] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:25,255] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:25,256] INFO [src.utils:19] 29
[2025-10-22 23:51:25,257] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:25,268] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:25,269] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:25,516] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:25,516] INFO [src.utils:19] 29
[2025-10-22 23:51:25,516] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:25,529] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:25,530] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:25,763] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:25,764] INFO [src.utils:19] 29
[2025-10-22 23:51:25,764] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:25,779] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:25,779] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:26,014] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:26,015] INFO [src.utils:19] 29
[2025-10-22 23:51:26,015] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:26,031] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:26,032] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:26,255] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:26,256] INFO [src.utils:19] 29
[2025-10-22 23:51:26,256] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:26,433] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:26,433] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:26,662] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:26,663] INFO [src.utils:19] 29
[2025-10-22 23:51:26,663] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:26,869] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:26,870] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:27,107] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:27,107] INFO [src.utils:19] 29
[2025-10-22 23:51:27,108] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:27,291] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:27,291] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:27,547] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:27,548] INFO [src.utils:19] 29
[2025-10-22 23:51:27,548] INFO [src.utils:19] torch.Size([8, 178, 1536])
  0%|          | 14/6000 [00:39<4:40:47,  2.81s/it]                                                   {'loss': 4.1598, 'grad_norm': 1246.652099609375, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:39<4:40:47,  2.81s/it][2025-10-22 23:51:27,806] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:27,807] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:28,112] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:28,113] INFO [src.utils:19] 29
[2025-10-22 23:51:28,113] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:28,124] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:28,125] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:28,339] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:28,339] INFO [src.utils:19] 29
[2025-10-22 23:51:28,340] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:28,352] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:28,352] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:28,569] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:28,570] INFO [src.utils:19] 29
[2025-10-22 23:51:28,570] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:28,583] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:28,584] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:28,805] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:28,806] INFO [src.utils:19] 29
[2025-10-22 23:51:28,806] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:28,821] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:28,821] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:29,039] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:29,040] INFO [src.utils:19] 29
[2025-10-22 23:51:29,040] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:29,213] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:29,214] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:29,428] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:29,429] INFO [src.utils:19] 29
[2025-10-22 23:51:29,429] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:29,635] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:29,635] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:29,861] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:29,861] INFO [src.utils:19] 29
[2025-10-22 23:51:29,862] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:30,037] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:30,038] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:30,263] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:30,263] INFO [src.utils:19] 29
[2025-10-22 23:51:30,263] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 15/6000 [00:42<4:37:13,  2.78s/it]                                                   {'loss': 3.5454, 'grad_norm': 997.446044921875, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:42<4:37:13,  2.78s/it][2025-10-22 23:51:30,514] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:30,515] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:30,836] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:30,837] INFO [src.utils:19] 29
[2025-10-22 23:51:30,837] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:30,845] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:30,846] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:31,058] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:31,059] INFO [src.utils:19] 29
[2025-10-22 23:51:31,059] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:31,071] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:31,072] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:31,293] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:31,294] INFO [src.utils:19] 29
[2025-10-22 23:51:31,294] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:31,307] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:31,307] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:31,524] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:31,525] INFO [src.utils:19] 29
[2025-10-22 23:51:31,525] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:31,539] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:31,540] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:31,753] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:31,753] INFO [src.utils:19] 29
[2025-10-22 23:51:31,753] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:31,926] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:31,926] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:32,140] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:32,140] INFO [src.utils:19] 29
[2025-10-22 23:51:32,140] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:32,343] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:32,344] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:32,567] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:32,567] INFO [src.utils:19] 29
[2025-10-22 23:51:32,567] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:32,745] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:32,745] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:32,968] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:32,969] INFO [src.utils:19] 29
[2025-10-22 23:51:32,969] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 16/6000 [00:45<4:35:03,  2.76s/it]                                                   {'loss': 3.3207, 'grad_norm': 1153.2603759765625, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:45<4:35:03,  2.76s/it][2025-10-22 23:51:33,212] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:33,213] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:33,522] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:33,525] INFO [src.utils:19] 29
[2025-10-22 23:51:33,526] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:33,531] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:33,531] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:33,740] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:33,740] INFO [src.utils:19] 29
[2025-10-22 23:51:33,741] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:33,752] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:33,753] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:33,960] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:33,961] INFO [src.utils:19] 29
[2025-10-22 23:51:33,961] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:33,973] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:33,973] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:34,180] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:34,181] INFO [src.utils:19] 29
[2025-10-22 23:51:34,181] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:34,194] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:34,195] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:34,406] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:34,406] INFO [src.utils:19] 29
[2025-10-22 23:51:34,407] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:34,580] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:34,580] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:34,792] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:34,793] INFO [src.utils:19] 29
[2025-10-22 23:51:34,793] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:34,997] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:34,997] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:35,209] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:35,210] INFO [src.utils:19] 29
[2025-10-22 23:51:35,210] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:35,385] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:35,386] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:35,598] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:35,599] INFO [src.utils:19] 29
[2025-10-22 23:51:35,599] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 17/6000 [00:48<4:32:42,  2.73s/it]                                                   {'loss': 3.0342, 'grad_norm': 925.65478515625, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:48<4:32:42,  2.73s/it][2025-10-22 23:51:35,903] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:35,903] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:36,227] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:36,227] INFO [src.utils:19] 29
[2025-10-22 23:51:36,228] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:36,236] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:36,236] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:36,446] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:36,446] INFO [src.utils:19] 29
[2025-10-22 23:51:36,446] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:36,458] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:36,459] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:36,680] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:36,681] INFO [src.utils:19] 29
[2025-10-22 23:51:36,681] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:36,694] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:36,694] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:36,912] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:36,912] INFO [src.utils:19] 29
[2025-10-22 23:51:36,912] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:36,927] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:36,928] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:37,140] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:37,141] INFO [src.utils:19] 29
[2025-10-22 23:51:37,141] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:37,313] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:37,313] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:37,530] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:37,531] INFO [src.utils:19] 29
[2025-10-22 23:51:37,531] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:37,735] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:37,736] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:37,961] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:37,961] INFO [src.utils:19] 29
[2025-10-22 23:51:37,962] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:38,139] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:38,139] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:51:38,365] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:38,366] INFO [src.utils:19] 29
[2025-10-22 23:51:38,366] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 18/6000 [00:50<4:32:49,  2.74s/it]                                                   {'loss': 2.9746, 'grad_norm': 901.1783447265625, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [00:50<4:32:49,  2.74s/it][2025-10-22 23:51:38,639] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:38,640] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:38,972] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:38,973] INFO [src.utils:19] 29
[2025-10-22 23:51:38,973] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:38,985] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:38,986] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:39,199] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:39,199] INFO [src.utils:19] 29
[2025-10-22 23:51:39,200] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:39,212] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:39,213] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:39,426] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:39,427] INFO [src.utils:19] 29
[2025-10-22 23:51:39,427] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:39,439] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:39,439] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:39,647] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:39,647] INFO [src.utils:19] 29
[2025-10-22 23:51:39,648] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:39,661] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:39,661] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:39,877] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:39,878] INFO [src.utils:19] 29
[2025-10-22 23:51:39,878] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:40,049] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:40,050] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:40,267] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:40,267] INFO [src.utils:19] 29
[2025-10-22 23:51:40,268] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:40,478] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:40,479] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:40,699] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:40,700] INFO [src.utils:19] 29
[2025-10-22 23:51:40,700] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:40,876] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:40,877] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:41,091] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:41,091] INFO [src.utils:19] 29
[2025-10-22 23:51:41,092] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 19/6000 [00:53<4:31:58,  2.73s/it]                                                   {'loss': 3.0929, 'grad_norm': 971.2664184570312, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [00:53<4:31:58,  2.73s/it][2025-10-22 23:51:41,352] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:41,352] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:41,646] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:41,647] INFO [src.utils:19] 29
[2025-10-22 23:51:41,649] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:41,667] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:41,668] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:41,889] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:41,889] INFO [src.utils:19] 29
[2025-10-22 23:51:41,890] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:41,903] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:41,903] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:42,112] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:42,113] INFO [src.utils:19] 29
[2025-10-22 23:51:42,113] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:42,125] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:42,125] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:42,334] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:42,334] INFO [src.utils:19] 29
[2025-10-22 23:51:42,335] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:42,348] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:42,348] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:42,568] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:42,569] INFO [src.utils:19] 29
[2025-10-22 23:51:42,569] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:42,741] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:42,741] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:42,973] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:42,974] INFO [src.utils:19] 29
[2025-10-22 23:51:42,974] INFO [src.utils:19] torch.Size([8, 147, 1536])
[2025-10-22 23:51:43,186] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:43,187] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:43,398] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:43,399] INFO [src.utils:19] 29
[2025-10-22 23:51:43,399] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:43,575] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:43,576] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:43,787] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:43,788] INFO [src.utils:19] 29
[2025-10-22 23:51:43,788] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 20/6000 [00:56<4:30:40,  2.72s/it]                                                   {'loss': 2.942, 'grad_norm': 406.77496337890625, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [00:56<4:30:40,  2.72s/it][2025-10-22 23:51:44,032] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:44,033] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:44,343] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:44,344] INFO [src.utils:19] 29
[2025-10-22 23:51:44,344] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:44,355] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:44,356] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:44,569] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:44,569] INFO [src.utils:19] 29
[2025-10-22 23:51:44,570] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:44,581] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:44,582] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:44,817] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:44,818] INFO [src.utils:19] 29
[2025-10-22 23:51:44,818] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:44,833] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:44,833] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:45,069] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:45,069] INFO [src.utils:19] 29
[2025-10-22 23:51:45,069] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:45,086] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:45,086] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:45,315] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:45,315] INFO [src.utils:19] 29
[2025-10-22 23:51:45,316] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:45,491] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:45,491] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:45,704] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:45,704] INFO [src.utils:19] 29
[2025-10-22 23:51:45,705] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:45,909] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:45,910] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:46,159] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:46,160] INFO [src.utils:19] 29
[2025-10-22 23:51:46,160] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:46,344] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:46,345] INFO [src.utils:19] torch.Size([8, 178, 1536])
[2025-10-22 23:51:46,604] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:46,604] INFO [src.utils:19] 29
[2025-10-22 23:51:46,604] INFO [src.utils:19] torch.Size([8, 178, 1536])
  0%|          | 21/6000 [00:59<4:34:13,  2.75s/it]                                                   {'loss': 2.8527, 'grad_norm': 270.86676025390625, 'learning_rate': 1.05e-05, 'epoch': 0.0}
  0%|          | 21/6000 [00:59<4:34:13,  2.75s/it][2025-10-22 23:51:46,879] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:46,880] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:47,207] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:47,207] INFO [src.utils:19] 29
[2025-10-22 23:51:47,207] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:47,219] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:47,220] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:47,430] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:47,431] INFO [src.utils:19] 29
[2025-10-22 23:51:47,431] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:47,443] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:47,444] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:47,652] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:47,652] INFO [src.utils:19] 29
[2025-10-22 23:51:47,653] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:47,665] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:47,666] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:47,880] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:47,881] INFO [src.utils:19] 29
[2025-10-22 23:51:47,881] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:47,895] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:47,895] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:48,124] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:48,124] INFO [src.utils:19] 29
[2025-10-22 23:51:48,125] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:48,305] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:48,306] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:48,524] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:48,525] INFO [src.utils:19] 29
[2025-10-22 23:51:48,525] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:48,735] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:48,735] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:49,042] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:49,043] INFO [src.utils:19] 29
[2025-10-22 23:51:49,043] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:49,229] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:49,229] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:49,442] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:49,443] INFO [src.utils:19] 29
[2025-10-22 23:51:49,443] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 22/6000 [01:01<4:36:11,  2.77s/it]                                                   {'loss': 2.823, 'grad_norm': 321.5390930175781, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}
  0%|          | 22/6000 [01:01<4:36:11,  2.77s/it][2025-10-22 23:51:49,683] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:49,684] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:49,986] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:49,988] INFO [src.utils:19] 29
[2025-10-22 23:51:49,988] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:50,003] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:50,003] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:50,231] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:50,231] INFO [src.utils:19] 29
[2025-10-22 23:51:50,231] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:50,245] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:50,246] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:50,459] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:50,460] INFO [src.utils:19] 29
[2025-10-22 23:51:50,460] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:50,473] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:50,473] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:50,681] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:50,681] INFO [src.utils:19] 29
[2025-10-22 23:51:50,682] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:50,695] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:50,695] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:50,918] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:50,919] INFO [src.utils:19] 29
[2025-10-22 23:51:50,919] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:51,096] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:51,097] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:51,330] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:51,331] INFO [src.utils:19] 29
[2025-10-22 23:51:51,331] INFO [src.utils:19] torch.Size([8, 156, 1536])
[2025-10-22 23:51:51,539] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:51,539] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:51,753] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:51,754] INFO [src.utils:19] 29
[2025-10-22 23:51:51,754] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:51,930] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:51,931] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:52,143] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:52,143] INFO [src.utils:19] 29
[2025-10-22 23:51:52,144] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 23/6000 [01:04<4:34:04,  2.75s/it]                                                   {'loss': 2.8848, 'grad_norm': 298.44769287109375, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.0}
  0%|          | 23/6000 [01:04<4:34:04,  2.75s/it][2025-10-22 23:51:52,393] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:52,394] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:52,706] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:52,707] INFO [src.utils:19] 29
[2025-10-22 23:51:52,707] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:52,719] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:52,719] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:52,921] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:52,922] INFO [src.utils:19] 29
[2025-10-22 23:51:52,922] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:52,934] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:52,934] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:53,147] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:53,148] INFO [src.utils:19] 29
[2025-10-22 23:51:53,148] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:53,161] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:53,161] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:53,369] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:53,370] INFO [src.utils:19] 29
[2025-10-22 23:51:53,370] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:53,383] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:53,384] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:53,617] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:53,617] INFO [src.utils:19] 29
[2025-10-22 23:51:53,617] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:53,793] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:53,793] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:53,997] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:53,998] INFO [src.utils:19] 29
[2025-10-22 23:51:53,998] INFO [src.utils:19] torch.Size([8, 129, 1536])
[2025-10-22 23:51:54,213] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:54,213] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:54,430] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:54,431] INFO [src.utils:19] 29
[2025-10-22 23:51:54,431] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:54,617] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:54,618] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:54,840] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:54,840] INFO [src.utils:19] 29
[2025-10-22 23:51:54,841] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 24/6000 [01:07<4:35:49,  2.77s/it]                                                   {'loss': 2.9979, 'grad_norm': 313.62677001953125, 'learning_rate': 1.2e-05, 'epoch': 0.0}
  0%|          | 24/6000 [01:07<4:35:49,  2.77s/it][2025-10-22 23:51:55,206] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:55,207] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:55,520] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:55,520] INFO [src.utils:19] 29
[2025-10-22 23:51:55,521] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:55,533] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:55,533] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:55,744] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:55,745] INFO [src.utils:19] 29
[2025-10-22 23:51:55,745] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:55,757] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:55,757] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:55,966] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:55,966] INFO [src.utils:19] 29
[2025-10-22 23:51:55,967] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:55,978] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:55,979] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:56,186] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:56,187] INFO [src.utils:19] 29
[2025-10-22 23:51:56,187] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:56,200] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:56,201] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:56,419] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:56,420] INFO [src.utils:19] 29
[2025-10-22 23:51:56,420] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:56,597] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:56,598] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:56,815] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:56,816] INFO [src.utils:19] 29
[2025-10-22 23:51:56,816] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:51:57,021] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:57,021] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:57,271] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:57,271] INFO [src.utils:19] 29
[2025-10-22 23:51:57,272] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:57,451] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:57,452] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:57,665] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:57,665] INFO [src.utils:19] 29
[2025-10-22 23:51:57,665] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 25/6000 [01:10<4:33:51,  2.75s/it]                                                   {'loss': 2.8266, 'grad_norm': 287.4931335449219, 'learning_rate': 1.25e-05, 'epoch': 0.0}
  0%|          | 25/6000 [01:10<4:33:51,  2.75s/it][2025-10-22 23:51:57,910] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:57,911] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:58,226] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:58,227] INFO [src.utils:19] 29
[2025-10-22 23:51:58,228] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:58,239] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:58,240] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:58,526] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:58,526] INFO [src.utils:19] 29
[2025-10-22 23:51:58,527] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:58,541] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:58,541] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:58,751] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:58,751] INFO [src.utils:19] 29
[2025-10-22 23:51:58,752] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:58,764] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:58,765] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:58,977] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:58,977] INFO [src.utils:19] 29
[2025-10-22 23:51:58,978] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:51:58,991] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:58,991] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:59,222] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:59,222] INFO [src.utils:19] 29
[2025-10-22 23:51:59,222] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:59,397] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:59,398] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:59,650] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:51:59,650] INFO [src.utils:19] 29
[2025-10-22 23:51:59,651] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:51:59,864] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:51:59,865] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:00,082] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:00,083] INFO [src.utils:19] 29
[2025-10-22 23:52:00,083] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:00,259] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:00,259] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:00,471] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:00,471] INFO [src.utils:19] 29
[2025-10-22 23:52:00,472] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 26/6000 [01:12<4:35:35,  2.77s/it]                                                   {'loss': 2.928, 'grad_norm': 489.4094543457031, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}
  0%|          | 26/6000 [01:12<4:35:35,  2.77s/it][2025-10-22 23:52:00,719] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:00,720] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:01,110] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:01,110] INFO [src.utils:19] 29
[2025-10-22 23:52:01,111] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:01,124] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:01,125] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:01,353] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:01,353] INFO [src.utils:19] 29
[2025-10-22 23:52:01,354] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:01,368] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:01,368] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:01,577] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:01,578] INFO [src.utils:19] 29
[2025-10-22 23:52:01,578] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:01,590] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:01,590] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:01,798] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:01,798] INFO [src.utils:19] 29
[2025-10-22 23:52:01,799] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:01,812] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:01,812] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:02,040] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:02,041] INFO [src.utils:19] 29
[2025-10-22 23:52:02,041] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:02,222] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:02,222] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:02,461] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:02,462] INFO [src.utils:19] 29
[2025-10-22 23:52:02,462] INFO [src.utils:19] torch.Size([8, 165, 1536])
[2025-10-22 23:52:02,671] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:02,672] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:02,886] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:02,887] INFO [src.utils:19] 29
[2025-10-22 23:52:02,887] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:03,065] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:03,066] INFO [src.utils:19] torch.Size([8, 133, 1536])
[2025-10-22 23:52:03,281] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:03,282] INFO [src.utils:19] 29
[2025-10-22 23:52:03,282] INFO [src.utils:19] torch.Size([8, 133, 1536])
  0%|          | 27/6000 [01:15<4:36:48,  2.78s/it]                                                   {'loss': 2.8775, 'grad_norm': 248.9082489013672, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.0}
  0%|          | 27/6000 [01:15<4:36:48,  2.78s/it][2025-10-22 23:52:03,524] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:03,524] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:03,886] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:03,887] INFO [src.utils:19] 29
[2025-10-22 23:52:03,887] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:03,901] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:03,902] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:04,132] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:04,132] INFO [src.utils:19] 29
[2025-10-22 23:52:04,132] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:04,147] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:04,147] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:04,366] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:04,367] INFO [src.utils:19] 29
[2025-10-22 23:52:04,367] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:04,380] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:04,380] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:04,598] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:04,599] INFO [src.utils:19] 29
[2025-10-22 23:52:04,599] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:04,614] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:04,614] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:05,003] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:05,003] INFO [src.utils:19] 29
[2025-10-22 23:52:05,004] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:05,181] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:05,181] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:05,436] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:05,436] INFO [src.utils:19] 29
[2025-10-22 23:52:05,437] INFO [src.utils:19] torch.Size([8, 174, 1536])
[2025-10-22 23:52:05,643] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:05,644] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:05,865] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:05,865] INFO [src.utils:19] 29
[2025-10-22 23:52:05,866] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:06,041] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:06,041] INFO [src.utils:19] torch.Size([8, 151, 1536])
[2025-10-22 23:52:06,271] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:06,271] INFO [src.utils:19] 29
[2025-10-22 23:52:06,272] INFO [src.utils:19] torch.Size([8, 151, 1536])
  0%|          | 28/6000 [01:19<5:00:51,  3.02s/it]                                                   {'loss': 2.8351, 'grad_norm': 276.1134948730469, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}
  0%|          | 28/6000 [01:19<5:00:51,  3.02s/it][2025-10-22 23:52:07,115] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:07,116] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:52:07,448] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:52:07,450] INFO [src.utils:19] 29
[2025-10-22 23:52:07,451] INFO [src.utils:19] torch.Size([8, 138, 1536])
[2025-10-22 23:52:07,458] INFO [src.utils:19] ALL_EMBEDS:
[2025-10-22 23:52:07,459] INFO [src.utils:19] torch.Size([8, 138, 1536])
