==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test6-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name test6-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test6-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token False --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test6-Qwen/Qwen2-VL-2B-Instruct/train.log
W1023 00:09:03.153000 129883461031744 torch/distributed/run.py:779] 
W1023 00:09:03.153000 129883461031744 torch/distributed/run.py:779] *****************************************
W1023 00:09:03.153000 129883461031744 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 00:09:03.153000 129883461031744 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-23 00:09:13,339] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.09it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.89it/s]
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test6-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251023_000913-583fvhni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run test6-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/583fvhni
[2025-10-23 00:09:14,838] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.15it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.97it/s]
[2025-10-23 00:09:15,476] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-10-23 00:09:24,429] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-23 00:09:25,666] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-23 00:09:25,667] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-23 00:09:29,924] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-23 00:09:29,925] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-23 00:09:30,910] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-23 00:09:30,910] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-23 00:09:30,911] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-23 00:09:30,912] INFO [src.utils:19] ==================================================
[2025-10-23 00:09:30,912] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-23 00:09:30,913] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-23 00:09:30,914] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-23 00:09:30,914] INFO [src.utils:19] ==================================================
[2025-10-23 00:09:32,682] INFO [src.trainer:342] ***** Running training *****
[2025-10-23 00:09:32,682] INFO [src.trainer:342] ***** Running training *****
[2025-10-23 00:09:32,683] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-23 00:09:32,683] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-23 00:09:32,683] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-23 00:09:32,683] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-23 00:09:32,683] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-23 00:09:32,683] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-23 00:09:32,683] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-23 00:09:32,684] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-23 00:09:32,684] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-23 00:09:32,684] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-23 00:09:32,684] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-23 00:09:32,685] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-23 00:09:32,691] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-23 00:09:32,692] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-23 00:09:32,697] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-10-23 00:09:32,700] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[2025-10-23 00:09:34,641] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:34,642] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:34,668] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:34,668] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:34,994] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:34,994] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:35,005] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:35,005] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:35,298] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:35,299] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:35,310] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:35,311] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:35,571] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:35,572] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:35,583] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:35,583] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:35,909] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:35,910] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:35,920] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:35,920] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:36,453] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:36,454] INFO [src.utils:19] torch.Size([8, 137, 1536])
[rank1]:[W1023 00:09:36.057700982 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2025-10-23 00:09:36,464] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:36,464] INFO [src.utils:19] torch.Size([8, 1536])
[rank0]:[W1023 00:09:36.061533789 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2025-10-23 00:09:36,957] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:36,957] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:36,968] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:36,969] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:37,422] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:37,422] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:37,433] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:37,434] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 1/6000 [00:04<8:04:05,  4.84s/it]                                                  {'loss': 20.6106, 'grad_norm': 1414.1409912109375, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<8:04:05,  4.84s/it][2025-10-23 00:09:38,088] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:38,089] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:38,099] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:38,099] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:38,404] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:38,405] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:38,415] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:38,416] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:38,737] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:38,738] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:38,748] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:38,748] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:39,016] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:39,017] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:39,027] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:39,027] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:39,305] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:39,306] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:39,316] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:39,316] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:39,793] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:39,793] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:39,803] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:39,804] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:40,330] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:40,331] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:40,341] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:40,342] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:40,784] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:40,785] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:40,795] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:40,795] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 2/6000 [00:08<6:33:21,  3.93s/it]                                                  {'loss': 17.9095, 'grad_norm': 2220.042236328125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:08<6:33:21,  3.93s/it][2025-10-23 00:09:41,428] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:41,430] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:41,439] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:41,440] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:41,717] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:41,718] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:41,728] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:41,729] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:42,008] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:42,009] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:42,019] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:42,019] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:42,317] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:42,318] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:42,328] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:42,329] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:42,729] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:42,729] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:42,740] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:42,740] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:43,180] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:43,181] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:43,191] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:43,192] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:43,671] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:43,672] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:43,682] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:43,683] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:44,151] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:44,152] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:44,162] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:44,163] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 3/6000 [00:11<6:12:24,  3.73s/it]                                                  {'loss': 16.0304, 'grad_norm': 2058.27734375, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:11<6:12:24,  3.73s/it][2025-10-23 00:09:44,862] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:44,863] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:44,873] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:44,873] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:45,135] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:45,136] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:45,146] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:45,146] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:45,488] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:45,488] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-23 00:09:45,502] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:45,502] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:45,859] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:45,859] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-23 00:09:45,873] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:45,873] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:46,133] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:46,133] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:46,144] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:46,144] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:46,572] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:46,573] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:46,583] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:46,584] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:47,219] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:47,220] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-23 00:09:47,232] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:47,233] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:47,776] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:47,776] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-23 00:09:47,789] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:47,790] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 4/6000 [00:15<6:04:22,  3.65s/it]                                                  {'loss': 16.247, 'grad_norm': 2010.970458984375, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:15<6:04:22,  3.65s/it][2025-10-23 00:09:48,444] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:48,445] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:09:48,457] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:48,457] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:48,724] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:48,725] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:09:48,736] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:48,737] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:49,004] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:49,005] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:49,015] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:49,016] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:49,343] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:49,344] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:49,354] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:49,355] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:49,668] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:49,668] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:09:49,679] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:49,680] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:50,123] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:50,124] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:09:50,135] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:50,136] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:50,600] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:50,600] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:50,611] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:50,612] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:51,127] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:51,128] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:51,138] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:51,139] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 5/6000 [00:18<5:53:40,  3.54s/it]                                                  {'loss': 16.2957, 'grad_norm': 2089.649169921875, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:18<5:53:40,  3.54s/it][2025-10-23 00:09:51,777] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:51,778] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:51,788] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:51,789] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:52,108] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:52,108] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:52,119] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:52,119] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:52,439] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:52,439] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:52,450] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:52,450] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:52,704] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:52,705] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:52,715] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:52,716] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:52,984] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:52,985] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:52,995] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:52,996] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:53,479] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:53,480] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:53,490] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:53,491] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:54,078] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:54,078] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:54,089] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:54,089] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:54,514] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:54,515] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:54,525] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:54,526] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 6/6000 [00:21<5:47:57,  3.48s/it]                                                  {'loss': 17.3852, 'grad_norm': 1560.3924560546875, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:21<5:47:57,  3.48s/it][2025-10-23 00:09:55,101] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:55,102] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:55,112] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:55,113] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:55,403] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:55,404] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:55,414] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:55,415] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:55,731] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:55,732] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:55,743] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:55,744] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:56,039] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:56,040] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:56,052] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:56,052] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:56,371] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:56,372] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:56,382] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:56,383] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:56,831] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:56,832] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:56,842] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:56,843] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:57,393] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:57,394] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:57,406] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:57,406] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:57,868] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:57,869] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:09:57,880] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:57,881] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 7/6000 [00:25<5:43:34,  3.44s/it]                                                  {'loss': 16.4705, 'grad_norm': 2160.5537109375, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:25<5:43:34,  3.44s/it][2025-10-23 00:09:58,483] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:58,484] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:58,494] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:58,495] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:58,782] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:58,782] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:58,793] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:58,793] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:59,107] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:59,107] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:59,117] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:59,118] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:59,400] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:59,401] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:09:59,411] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:59,412] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:09:59,684] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:09:59,685] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:09:59,695] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:09:59,696] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:00,153] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:00,154] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:00,164] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:00,165] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:00,698] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:00,699] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:00,709] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:00,710] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:01,161] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:01,161] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:01,172] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:01,172] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 8/6000 [00:28<5:39:02,  3.39s/it]                                                  {'loss': 16.4848, 'grad_norm': 1989.365234375, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:28<5:39:02,  3.39s/it][2025-10-23 00:10:01,805] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:01,806] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:10:01,818] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:01,819] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:02,120] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:02,121] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:10:02,134] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:02,134] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:02,480] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:02,480] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:02,492] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:02,492] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:02,800] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:02,801] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:02,812] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:02,813] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:03,087] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:03,087] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:10:03,100] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:03,100] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:03,573] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:03,574] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:10:03,586] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:03,586] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:04,120] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:04,121] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:04,133] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:04,133] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:04,609] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:04,610] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:04,621] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:04,622] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 9/6000 [00:31<5:40:28,  3.41s/it]                                                  {'loss': 12.484, 'grad_norm': 1607.1611328125, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:31<5:40:28,  3.41s/it][2025-10-23 00:10:05,294] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:05,295] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:05,305] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:05,306] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:05,557] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:05,557] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:05,568] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:05,568] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:05,778] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:05,779] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:05,789] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:05,790] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:06,123] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:06,124] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:06,134] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:06,135] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:06,493] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:06,493] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:06,504] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:06,504] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:06,919] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:06,919] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:06,930] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:06,930] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:07,335] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:07,336] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:07,346] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:07,347] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:07,848] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:07,849] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:07,859] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:07,860] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 10/6000 [00:35<5:36:01,  3.37s/it]                                                   {'loss': 14.5328, 'grad_norm': 1894.5224609375, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:35<5:36:01,  3.37s/it][2025-10-23 00:10:08,609] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:08,610] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:10:08,626] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:08,626] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:08,990] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:08,991] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:10:09,007] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:09,007] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:09,262] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:09,263] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:09,273] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:09,274] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:09,546] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:09,547] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:09,557] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:09,558] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:09,952] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:09,952] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:10:09,968] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:09,968] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:10,589] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:10,590] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:10:10,606] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:10,606] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:11,127] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:11,128] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:11,138] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:11,139] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:11,578] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:11,578] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:11,589] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:11,589] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 11/6000 [00:38<5:46:37,  3.47s/it]                                                   {'loss': 13.7928, 'grad_norm': 2202.59814453125, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:38<5:46:37,  3.47s/it][2025-10-23 00:10:12,246] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:12,246] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:12,258] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:12,259] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:12,559] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:12,560] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:12,571] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:12,572] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:12,890] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:12,890] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-23 00:10:12,905] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:12,906] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:13,223] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:13,223] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-23 00:10:13,238] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:13,239] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:13,553] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:13,553] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:13,565] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:13,566] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:14,029] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:14,030] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:14,041] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:14,041] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:14,560] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:14,560] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-23 00:10:14,575] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:14,576] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:15,101] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:15,101] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-23 00:10:15,116] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:15,116] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 12/6000 [00:42<5:48:39,  3.49s/it]                                                   {'loss': 11.1609, 'grad_norm': 2693.8662109375, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:42<5:48:39,  3.49s/it][2025-10-23 00:10:15,829] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:15,830] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:15,841] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:15,842] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:16,126] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:16,127] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:16,139] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:16,139] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:16,432] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:16,432] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:16,444] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:16,445] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:16,767] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:16,767] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:16,779] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:16,780] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:17,080] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:17,081] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:17,093] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:17,093] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:17,547] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:17,548] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:17,559] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:17,560] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:18,046] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:18,047] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:18,058] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:18,059] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:18,551] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:18,551] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:18,563] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:18,563] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 13/6000 [00:45<5:46:15,  3.47s/it]                                                   {'loss': 10.189, 'grad_norm': 7304.75732421875, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:45<5:46:15,  3.47s/it][2025-10-23 00:10:19,155] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:19,156] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:10:19,167] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:19,168] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:19,482] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:19,483] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:10:19,494] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:19,495] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:19,841] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:19,841] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:10:19,855] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:19,856] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:20,151] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:20,152] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:10:20,165] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:20,166] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:20,454] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:20,455] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:10:20,466] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:20,467] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:20,967] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:20,967] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:10:20,979] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:20,979] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:21,521] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:21,522] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:10:21,535] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:21,536] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:22,023] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:22,023] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:10:22,037] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:22,037] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 14/6000 [00:49<5:46:47,  3.48s/it]                                                   {'loss': 10.5942, 'grad_norm': 4493.1005859375, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:49<5:46:47,  3.48s/it][2025-10-23 00:10:22,737] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:22,737] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:22,748] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:22,749] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:23,024] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:23,025] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:23,036] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:23,036] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:23,321] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:23,321] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:23,333] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:23,334] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:23,662] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:23,663] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:23,675] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:23,675] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:23,983] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:23,983] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:23,994] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:23,994] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:24,430] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:24,431] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:24,441] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:24,442] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:24,919] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:24,919] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:24,931] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:24,931] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:25,426] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:25,426] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:25,438] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:25,439] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 15/6000 [00:52<5:44:09,  3.45s/it]                                                   {'loss': 6.1401, 'grad_norm': 1996.939453125, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:52<5:44:09,  3.45s/it][2025-10-23 00:10:26,095] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:26,096] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:26,107] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:26,107] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:26,380] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:26,381] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:26,392] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:26,392] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:26,680] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:26,681] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:26,692] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:26,693] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:27,007] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:27,008] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:27,020] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:27,020] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:27,323] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:27,324] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:27,335] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:27,335] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:27,775] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:27,775] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:27,786] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:27,786] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:28,325] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:28,326] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:28,338] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:28,338] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:28,819] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:28,819] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:28,831] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:28,831] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 16/6000 [00:56<5:42:34,  3.43s/it]                                                   {'loss': 4.7859, 'grad_norm': 6647.64794921875, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:56<5:42:34,  3.43s/it][2025-10-23 00:10:29,546] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:29,546] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:29,557] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:29,557] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:29,868] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:29,868] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:29,879] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:29,880] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:30,200] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:30,201] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:30,212] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:30,212] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:30,481] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:30,482] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:30,492] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:30,493] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:30,753] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:30,754] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:30,764] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:30,765] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:31,239] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:31,240] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:31,250] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:31,251] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:31,786] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:31,786] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:31,797] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:31,797] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:32,238] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:32,238] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:32,249] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:32,249] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 17/6000 [00:59<5:43:17,  3.44s/it]                                                   {'loss': 5.3262, 'grad_norm': 929.6424560546875, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:59<5:43:17,  3.44s/it][2025-10-23 00:10:33,005] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:33,006] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:33,017] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:33,017] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:33,305] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:33,306] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:33,316] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:33,317] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:33,650] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:33,650] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:33,662] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:33,663] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:33,964] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:33,965] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:33,977] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:33,977] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:34,239] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:34,240] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:34,250] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:34,251] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:34,711] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:34,712] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:34,723] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:34,723] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:35,265] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:35,266] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:35,278] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:35,278] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:35,749] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:35,749] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:10:35,761] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:35,762] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 18/6000 [01:03<5:44:35,  3.46s/it]                                                   {'loss': 4.4461, 'grad_norm': 820.4351806640625, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [01:03<5:44:35,  3.46s/it][2025-10-23 00:10:36,455] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:36,456] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:36,467] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:36,467] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:36,776] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:36,776] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:36,787] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:36,787] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:37,072] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:37,073] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:37,083] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:37,084] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:37,354] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:37,354] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:37,365] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:37,365] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:37,654] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:37,654] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:37,665] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:37,666] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:38,144] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:38,144] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:38,155] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:38,156] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:38,645] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:38,646] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:38,657] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:38,657] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:39,103] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:39,104] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:39,114] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:39,115] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 19/6000 [01:06<5:40:38,  3.42s/it]                                                   {'loss': 4.2099, 'grad_norm': 816.3438110351562, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [01:06<5:40:38,  3.42s/it][2025-10-23 00:10:39,833] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:39,834] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:39,846] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:39,847] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:40,176] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:40,176] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:40,188] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:40,189] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:40,444] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:40,445] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:40,455] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:40,456] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:40,709] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:40,710] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:40,720] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:40,721] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:41,069] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:41,069] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:41,081] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:41,082] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:41,580] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:41,581] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:10:41,592] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:41,593] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:42,045] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:42,046] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:42,056] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:42,057] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:42,480] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:42,481] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:10:42,491] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:42,492] INFO [src.utils:19] torch.Size([8, 1536])
  0%|          | 20/6000 [01:09<5:41:31,  3.43s/it]                                                   {'loss': 3.8466, 'grad_norm': 624.2307739257812, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [01:09<5:41:31,  3.43s/it][2025-10-23 00:10:43,246] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:43,246] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:43,257] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:43,258] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:43,529] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:43,529] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:10:43,540] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:43,541] INFO [src.utils:19] torch.Size([8, 1536])
[2025-10-23 00:10:43,840] INFO [src.utils:19] HIDDEN_STATES:
[2025-10-23 00:10:43,840] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:10:43,854] INFO [src.utils:19] POOLED_OUTPUT:
[2025-10-23 00:10:43,855] INFO [src.utils:19] torch.Size([8, 1536])
