==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name TailTokenPF-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token False --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/train.log
W1020 15:29:16.993000 131350605657920 torch/distributed/run.py:779] 
W1020 15:29:16.993000 131350605657920 torch/distributed/run.py:779] *****************************************
W1020 15:29:16.993000 131350605657920 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1020 15:29:16.993000 131350605657920 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!DropoutAddRMSNorm of flash_attn is not installed!!!

/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-20 15:29:26,293] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.09it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.86it/s]
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251020_152926-1mbu38js
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TailTokenPF-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/1mbu38js
[2025-10-20 15:29:27,850] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.14it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.92it/s]
[2025-10-20 15:29:28,616] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-10-20 15:29:37,695] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-20 15:29:38,880] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-20 15:29:38,881] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-20 15:29:43,490] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-20 15:29:43,491] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-20 15:29:44,385] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-20 15:29:44,386] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-20 15:29:44,386] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-20 15:29:44,387] INFO [src.utils:19] ==================================================
[2025-10-20 15:29:44,387] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-20 15:29:44,388] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-20 15:29:44,389] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-20 15:29:44,389] INFO [src.utils:19] ==================================================
[2025-10-20 15:29:46,299] INFO [src.trainer:342] ***** Running training *****
[2025-10-20 15:29:46,299] INFO [src.trainer:342] ***** Running training *****
[2025-10-20 15:29:46,299] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-20 15:29:46,299] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-20 15:29:46,300] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-20 15:29:46,300] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-20 15:29:46,300] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-20 15:29:46,300] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-20 15:29:46,300] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-20 15:29:46,301] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-20 15:29:46,301] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-20 15:29:46,301] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-20 15:29:46,301] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-20 15:29:46,302] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-20 15:29:46,308] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-20 15:29:46,310] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W1020 15:29:50.170407781 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1020 15:29:50.191828325 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/6000 [00:05<8:23:56,  5.04s/it]                                                  {'loss': 20.6106, 'grad_norm': 1435.35791015625, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:05<8:23:56,  5.04s/it]  0%|          | 2/6000 [00:08<6:43:32,  4.04s/it]                                                  {'loss': 17.9095, 'grad_norm': 2240.218017578125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:08<6:43:32,  4.04s/it]  0%|          | 3/6000 [00:11<6:15:42,  3.76s/it]                                                  {'loss': 15.569, 'grad_norm': 2074.07666015625, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:11<6:15:42,  3.76s/it]  0%|          | 4/6000 [00:15<6:04:39,  3.65s/it]                                                  {'loss': 16.4708, 'grad_norm': 2381.79833984375, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:15<6:04:39,  3.65s/it]  0%|          | 5/6000 [00:18<5:54:34,  3.55s/it]                                                  {'loss': 16.4438, 'grad_norm': 2031.4163818359375, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:18<5:54:34,  3.55s/it]  0%|          | 6/6000 [00:22<5:49:31,  3.50s/it]                                                  {'loss': 17.5614, 'grad_norm': 1772.6478271484375, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:22<5:49:31,  3.50s/it]  0%|          | 7/6000 [00:25<5:44:35,  3.45s/it]                                                  {'loss': 16.1948, 'grad_norm': 2434.404541015625, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:25<5:44:35,  3.45s/it]  0%|          | 8/6000 [00:28<5:38:39,  3.39s/it]                                                  {'loss': 16.8418, 'grad_norm': 1925.77197265625, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:28<5:38:39,  3.39s/it]  0%|          | 9/6000 [00:32<5:40:23,  3.41s/it]                                                  {'loss': 12.9494, 'grad_norm': 1835.55810546875, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:32<5:40:23,  3.41s/it]  0%|          | 10/6000 [00:35<5:36:26,  3.37s/it]                                                   {'loss': 14.0437, 'grad_norm': 2439.321044921875, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:35<5:36:26,  3.37s/it]  0%|          | 11/6000 [00:39<5:47:16,  3.48s/it]                                                   {'loss': 13.7255, 'grad_norm': 2411.858642578125, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:39<5:47:16,  3.48s/it]  0%|          | 12/6000 [00:42<5:47:32,  3.48s/it]                                                   {'loss': 10.7106, 'grad_norm': 3385.002685546875, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:42<5:47:32,  3.48s/it]  0%|          | 13/6000 [00:45<5:43:19,  3.44s/it]                                                   {'loss': 11.1137, 'grad_norm': 6326.1083984375, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:45<5:43:19,  3.44s/it]  0%|          | 14/6000 [00:49<5:44:24,  3.45s/it]                                                   {'loss': 9.6136, 'grad_norm': 1887.30908203125, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:49<5:44:24,  3.45s/it]  0%|          | 15/6000 [00:52<5:43:08,  3.44s/it]                                                   {'loss': 4.7779, 'grad_norm': 1006.7586669921875, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:52<5:43:08,  3.44s/it]  0%|          | 16/6000 [00:56<5:40:30,  3.41s/it]                                                   {'loss': 5.4664, 'grad_norm': 2585.34814453125, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:56<5:40:30,  3.41s/it]  0%|          | 17/6000 [00:59<5:41:46,  3.43s/it]                                                   {'loss': 4.9296, 'grad_norm': 1158.4591064453125, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:59<5:41:46,  3.43s/it]  0%|          | 18/6000 [01:03<5:42:02,  3.43s/it]                                                   {'loss': 4.2326, 'grad_norm': 555.842529296875, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [01:03<5:42:02,  3.43s/it]  0%|          | 19/6000 [01:06<5:37:30,  3.39s/it]                                                   {'loss': 3.9066, 'grad_norm': 566.8259887695312, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [01:06<5:37:30,  3.39s/it]  0%|          | 20/6000 [01:09<5:37:32,  3.39s/it]                                                   {'loss': 3.4768, 'grad_norm': 597.056396484375, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [01:09<5:37:32,  3.39s/it]  0%|          | 21/6000 [01:13<5:39:27,  3.41s/it]                                                   {'loss': 3.3391, 'grad_norm': 283.7372131347656, 'learning_rate': 1.05e-05, 'epoch': 0.0}
  0%|          | 21/6000 [01:13<5:39:27,  3.41s/it]  0%|          | 22/6000 [01:16<5:40:04,  3.41s/it]                                                   {'loss': 3.124, 'grad_norm': 413.41119384765625, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}
  0%|          | 22/6000 [01:16<5:40:04,  3.41s/it]  0%|          | 23/6000 [01:19<5:37:01,  3.38s/it]                                                   {'loss': 3.4833, 'grad_norm': 368.7564697265625, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.0}
  0%|          | 23/6000 [01:19<5:37:01,  3.38s/it]  0%|          | 24/6000 [01:23<5:42:48,  3.44s/it]                                                   {'loss': 3.5579, 'grad_norm': 375.2577209472656, 'learning_rate': 1.2e-05, 'epoch': 0.0}
  0%|          | 24/6000 [01:23<5:42:48,  3.44s/it]  0%|          | 25/6000 [01:26<5:42:13,  3.44s/it]                                                   {'loss': 3.0985, 'grad_norm': 307.3118896484375, 'learning_rate': 1.25e-05, 'epoch': 0.0}
  0%|          | 25/6000 [01:26<5:42:13,  3.44s/it]  0%|          | 26/6000 [01:30<5:43:20,  3.45s/it]                                                   {'loss': 3.1087, 'grad_norm': 204.6514892578125, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}
  0%|          | 26/6000 [01:30<5:43:20,  3.45s/it]  0%|          | 27/6000 [01:33<5:41:57,  3.44s/it]                                                   {'loss': 3.0497, 'grad_norm': 191.1136932373047, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.0}
  0%|          | 27/6000 [01:33<5:41:57,  3.44s/it]  0%|          | 28/6000 [01:38<6:09:02,  3.71s/it]                                                   {'loss': 3.1127, 'grad_norm': 231.8218231201172, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}
  0%|          | 28/6000 [01:38<6:09:02,  3.71s/it]  0%|          | 29/6000 [01:41<5:59:06,  3.61s/it]                                                   {'loss': 3.0357, 'grad_norm': 171.26150512695312, 'learning_rate': 1.45e-05, 'epoch': 0.0}
  0%|          | 29/6000 [01:41<5:59:06,  3.61s/it]  0%|          | 30/6000 [01:44<5:52:22,  3.54s/it]                                                   {'loss': 3.1818, 'grad_norm': 182.9561309814453, 'learning_rate': 1.5e-05, 'epoch': 0.01}
  0%|          | 30/6000 [01:44<5:52:22,  3.54s/it]  1%|          | 31/6000 [01:48<5:45:53,  3.48s/it]                                                   {'loss': 2.9629, 'grad_norm': 151.79537963867188, 'learning_rate': 1.55e-05, 'epoch': 0.01}
  1%|          | 31/6000 [01:48<5:45:53,  3.48s/it]  1%|          | 32/6000 [01:51<5:45:25,  3.47s/it]                                                   {'loss': 2.8733, 'grad_norm': 129.9967803955078, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}
  1%|          | 32/6000 [01:51<5:45:25,  3.47s/it]  1%|          | 33/6000 [01:55<5:44:08,  3.46s/it]                                                   {'loss': 2.9507, 'grad_norm': 154.57339477539062, 'learning_rate': 1.65e-05, 'epoch': 0.01}
  1%|          | 33/6000 [01:55<5:44:08,  3.46s/it]  1%|          | 34/6000 [01:58<5:42:28,  3.44s/it]                                                   {'loss': 2.9669, 'grad_norm': 119.46403503417969, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}
  1%|          | 34/6000 [01:58<5:42:28,  3.44s/it]  1%|          | 35/6000 [02:02<5:42:14,  3.44s/it]                                                   {'loss': 2.8802, 'grad_norm': 105.34165954589844, 'learning_rate': 1.75e-05, 'epoch': 0.01}
  1%|          | 35/6000 [02:02<5:42:14,  3.44s/it]  1%|          | 36/6000 [02:05<5:38:34,  3.41s/it]                                                   {'loss': 2.8387, 'grad_norm': 122.91388702392578, 'learning_rate': 1.8e-05, 'epoch': 0.01}
  1%|          | 36/6000 [02:05<5:38:34,  3.41s/it]  1%|          | 37/6000 [02:08<5:37:37,  3.40s/it]                                                   {'loss': 2.7353, 'grad_norm': 137.28700256347656, 'learning_rate': 1.85e-05, 'epoch': 0.01}
  1%|          | 37/6000 [02:08<5:37:37,  3.40s/it]  1%|          | 38/6000 [02:12<5:35:47,  3.38s/it]                                                   {'loss': 2.66, 'grad_norm': 104.52923583984375, 'learning_rate': 1.9e-05, 'epoch': 0.01}
  1%|          | 38/6000 [02:12<5:35:47,  3.38s/it]  1%|          | 39/6000 [02:15<5:35:52,  3.38s/it]                                                   {'loss': 2.6746, 'grad_norm': 125.23533630371094, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}
  1%|          | 39/6000 [02:15<5:35:52,  3.38s/it]  1%|          | 40/6000 [02:18<5:37:55,  3.40s/it]                                                   {'loss': 2.6839, 'grad_norm': 125.88648986816406, 'learning_rate': 2e-05, 'epoch': 0.01}
  1%|          | 40/6000 [02:18<5:37:55,  3.40s/it]  1%|          | 41/6000 [02:22<5:36:57,  3.39s/it]                                                   {'loss': 2.329, 'grad_norm': 149.32562255859375, 'learning_rate': 2.05e-05, 'epoch': 0.01}
  1%|          | 41/6000 [02:22<5:36:57,  3.39s/it]  1%|          | 42/6000 [02:25<5:35:47,  3.38s/it]                                                   {'loss': 2.1625, 'grad_norm': 87.65338134765625, 'learning_rate': 2.1e-05, 'epoch': 0.01}
  1%|          | 42/6000 [02:25<5:35:47,  3.38s/it]  1%|          | 43/6000 [02:30<6:07:12,  3.70s/it]                                                   {'loss': 1.7699, 'grad_norm': 175.64109802246094, 'learning_rate': 2.15e-05, 'epoch': 0.01}
  1%|          | 43/6000 [02:30<6:07:12,  3.70s/it]  1%|          | 44/6000 [02:33<6:12:05,  3.75s/it]                                                   {'loss': 1.9079, 'grad_norm': 141.4210205078125, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.01}
  1%|          | 44/6000 [02:33<6:12:05,  3.75s/it]  1%|          | 45/6000 [02:37<6:02:11,  3.65s/it]                                                   {'loss': 1.6337, 'grad_norm': 348.47601318359375, 'learning_rate': 2.25e-05, 'epoch': 0.01}
  1%|          | 45/6000 [02:37<6:02:11,  3.65s/it]  1%|          | 46/6000 [02:40<5:57:09,  3.60s/it]                                                   {'loss': 1.5105, 'grad_norm': 321.011962890625, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01}
  1%|          | 46/6000 [02:40<5:57:09,  3.60s/it]  1%|          | 47/6000 [02:44<5:51:58,  3.55s/it]                                                   {'loss': 1.4076, 'grad_norm': 109.81242370605469, 'learning_rate': 2.35e-05, 'epoch': 0.01}
  1%|          | 47/6000 [02:44<5:51:58,  3.55s/it]  1%|          | 48/6000 [02:47<5:50:53,  3.54s/it]                                                   {'loss': 0.9726, 'grad_norm': 72.33470153808594, 'learning_rate': 2.4e-05, 'epoch': 0.01}
  1%|          | 48/6000 [02:47<5:50:53,  3.54s/it]  1%|          | 49/6000 [02:51<5:45:05,  3.48s/it]                                                   {'loss': 0.9306, 'grad_norm': 112.58943939208984, 'learning_rate': 2.45e-05, 'epoch': 0.01}
  1%|          | 49/6000 [02:51<5:45:05,  3.48s/it]  1%|          | 50/6000 [02:54<5:47:13,  3.50s/it]                                                   {'loss': 0.7869, 'grad_norm': 101.85191345214844, 'learning_rate': 2.5e-05, 'epoch': 0.01}
  1%|          | 50/6000 [02:54<5:47:13,  3.50s/it][2025-10-20 15:32:41,154] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  1%|          | 51/6000 [03:00<6:48:09,  4.12s/it]                                                   {'loss': 0.5906, 'grad_norm': 59.45366668701172, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.01}
  1%|          | 51/6000 [03:00<6:48:09,  4.12s/it]  1%|          | 52/6000 [03:03<6:23:17,  3.87s/it]                                                   {'loss': 0.4807, 'grad_norm': 89.82882690429688, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}
  1%|          | 52/6000 [03:03<6:23:17,  3.87s/it]  1%|          | 53/6000 [03:06<6:10:51,  3.74s/it]                                                   {'loss': 0.5778, 'grad_norm': 49.92140197753906, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.01}
  1%|          | 53/6000 [03:06<6:10:51,  3.74s/it]  1%|          | 54/6000 [03:10<6:01:09,  3.64s/it]                                                   {'loss': 0.4842, 'grad_norm': 60.434776306152344, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}
  1%|          | 54/6000 [03:10<6:01:09,  3.64s/it]  1%|          | 55/6000 [03:13<5:53:58,  3.57s/it]                                                   {'loss': 0.5034, 'grad_norm': 44.13460159301758, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.01}
  1%|          | 55/6000 [03:13<5:53:58,  3.57s/it]  1%|          | 56/6000 [03:17<5:47:53,  3.51s/it]                                                   {'loss': 0.2111, 'grad_norm': 45.929927825927734, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}
  1%|          | 56/6000 [03:17<5:47:53,  3.51s/it]  1%|          | 57/6000 [03:20<5:43:48,  3.47s/it]                                                   {'loss': 0.3063, 'grad_norm': 37.63608932495117, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.01}
  1%|          | 57/6000 [03:20<5:43:48,  3.47s/it]  1%|          | 58/6000 [03:23<5:40:33,  3.44s/it]                                                   {'loss': 0.394, 'grad_norm': 77.7415542602539, 'learning_rate': 2.9e-05, 'epoch': 0.01}
  1%|          | 58/6000 [03:23<5:40:33,  3.44s/it]  1%|          | 59/6000 [03:27<5:36:40,  3.40s/it]                                                   {'loss': 0.293, 'grad_norm': 142.07325744628906, 'learning_rate': 2.95e-05, 'epoch': 0.01}
  1%|          | 59/6000 [03:27<5:36:40,  3.40s/it]  1%|          | 60/6000 [03:30<5:35:51,  3.39s/it]                                                   {'loss': 0.3464, 'grad_norm': 32.75944137573242, 'learning_rate': 3e-05, 'epoch': 0.01}
  1%|          | 60/6000 [03:30<5:35:51,  3.39s/it]  1%|          | 61/6000 [03:33<5:33:44,  3.37s/it]                                                   {'loss': 0.181, 'grad_norm': 20.30555534362793, 'learning_rate': 3.05e-05, 'epoch': 0.01}
  1%|          | 61/6000 [03:33<5:33:44,  3.37s/it]  1%|          | 62/6000 [03:37<5:33:58,  3.37s/it]                                                   {'loss': 0.1939, 'grad_norm': 26.27880096435547, 'learning_rate': 3.1e-05, 'epoch': 0.01}
  1%|          | 62/6000 [03:37<5:33:58,  3.37s/it]  1%|          | 63/6000 [03:40<5:35:25,  3.39s/it]                                                   {'loss': 0.1084, 'grad_norm': 13.045194625854492, 'learning_rate': 3.15e-05, 'epoch': 0.01}
  1%|          | 63/6000 [03:40<5:35:25,  3.39s/it]  1%|          | 64/6000 [03:43<5:31:44,  3.35s/it]                                                   {'loss': 0.107, 'grad_norm': 22.965944290161133, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.01}
  1%|          | 64/6000 [03:43<5:31:44,  3.35s/it]  1%|          | 65/6000 [03:47<5:30:51,  3.34s/it]                                                   {'loss': 0.199, 'grad_norm': 29.319135665893555, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.01}
  1%|          | 65/6000 [03:47<5:30:51,  3.34s/it]  1%|          | 66/6000 [03:51<5:45:38,  3.49s/it]                                                   {'loss': 0.186, 'grad_norm': 18.83931541442871, 'learning_rate': 3.3e-05, 'epoch': 0.01}
  1%|          | 66/6000 [03:51<5:45:38,  3.49s/it]  1%|          | 67/6000 [03:54<5:41:38,  3.45s/it]                                                   {'loss': 0.2212, 'grad_norm': 24.866283416748047, 'learning_rate': 3.35e-05, 'epoch': 0.01}
  1%|          | 67/6000 [03:54<5:41:38,  3.45s/it]  1%|          | 68/6000 [03:57<5:36:27,  3.40s/it]                                                   {'loss': 0.2022, 'grad_norm': 31.178377151489258, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.01}
  1%|          | 68/6000 [03:57<5:36:27,  3.40s/it]  1%|          | 69/6000 [04:01<5:35:53,  3.40s/it]                                                   {'loss': 0.4307, 'grad_norm': 25.128278732299805, 'learning_rate': 3.45e-05, 'epoch': 0.01}
  1%|          | 69/6000 [04:01<5:35:53,  3.40s/it]  1%|          | 70/6000 [04:04<5:46:20,  3.50s/it]                                                   {'loss': 0.1054, 'grad_norm': 16.30219268798828, 'learning_rate': 3.5e-05, 'epoch': 0.01}
  1%|          | 70/6000 [04:04<5:46:20,  3.50s/it]  1%|          | 71/6000 [04:08<5:39:57,  3.44s/it]                                                   {'loss': 0.0318, 'grad_norm': 11.899493217468262, 'learning_rate': 3.55e-05, 'epoch': 0.01}
  1%|          | 71/6000 [04:08<5:39:57,  3.44s/it]  1%|          | 72/6000 [04:11<5:49:58,  3.54s/it]                                                   {'loss': 0.1568, 'grad_norm': 19.366046905517578, 'learning_rate': 3.6e-05, 'epoch': 0.01}
  1%|          | 72/6000 [04:11<5:49:58,  3.54s/it]  1%|          | 73/6000 [04:15<5:48:01,  3.52s/it]                                                   {'loss': 0.3029, 'grad_norm': 41.26567840576172, 'learning_rate': 3.65e-05, 'epoch': 0.01}
  1%|          | 73/6000 [04:15<5:48:01,  3.52s/it]  1%|          | 74/6000 [04:18<5:41:25,  3.46s/it]                                                   {'loss': 0.2563, 'grad_norm': 19.345109939575195, 'learning_rate': 3.7e-05, 'epoch': 0.01}
  1%|          | 74/6000 [04:18<5:41:25,  3.46s/it]  1%|â–         | 75/6000 [04:22<5:36:11,  3.40s/it]                                                   {'loss': 0.0947, 'grad_norm': 14.861681938171387, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.01}
  1%|â–         | 75/6000 [04:22<5:36:11,  3.40s/it]  1%|â–         | 76/6000 [04:25<5:39:56,  3.44s/it]                                                   {'loss': 0.0687, 'grad_norm': 12.774601936340332, 'learning_rate': 3.8e-05, 'epoch': 0.01}
  1%|â–         | 76/6000 [04:25<5:39:56,  3.44s/it]  1%|â–         | 77/6000 [04:28<5:38:19,  3.43s/it]                                                   {'loss': 0.2033, 'grad_norm': 15.839957237243652, 'learning_rate': 3.85e-05, 'epoch': 0.01}
  1%|â–         | 77/6000 [04:28<5:38:19,  3.43s/it]  1%|â–         | 78/6000 [04:32<5:48:32,  3.53s/it]                                                   {'loss': 0.0262, 'grad_norm': 6.851423740386963, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 78/6000 [04:32<5:48:32,  3.53s/it]  1%|â–         | 79/6000 [04:36<5:43:09,  3.48s/it]                                                   {'loss': 0.1457, 'grad_norm': 24.271615982055664, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.01}
  1%|â–         | 79/6000 [04:36<5:43:09,  3.48s/it]  1%|â–         | 80/6000 [04:39<5:50:23,  3.55s/it]                                                   {'loss': 0.0946, 'grad_norm': 9.711074829101562, 'learning_rate': 4e-05, 'epoch': 0.01}
  1%|â–         | 80/6000 [04:39<5:50:23,  3.55s/it]  1%|â–         | 81/6000 [04:43<5:43:18,  3.48s/it]                                                   {'loss': 0.08, 'grad_norm': 15.882728576660156, 'learning_rate': 4.05e-05, 'epoch': 0.01}
  1%|â–         | 81/6000 [04:43<5:43:18,  3.48s/it]  1%|â–         | 82/6000 [04:46<5:41:43,  3.46s/it]                                                   {'loss': 0.3385, 'grad_norm': 89.4062728881836, 'learning_rate': 4.1e-05, 'epoch': 0.01}
  1%|â–         | 82/6000 [04:46<5:41:43,  3.46s/it]  1%|â–         | 83/6000 [04:49<5:40:34,  3.45s/it]                                                   {'loss': 0.1906, 'grad_norm': 29.319339752197266, 'learning_rate': 4.15e-05, 'epoch': 0.01}
  1%|â–         | 83/6000 [04:50<5:40:34,  3.45s/it]  1%|â–         | 84/6000 [04:53<5:41:03,  3.46s/it]                                                   {'loss': 0.0753, 'grad_norm': 12.408577919006348, 'learning_rate': 4.2e-05, 'epoch': 0.01}
  1%|â–         | 84/6000 [04:53<5:41:03,  3.46s/it]  1%|â–         | 85/6000 [04:57<5:49:42,  3.55s/it]                                                   {'loss': 0.0962, 'grad_norm': 17.702678680419922, 'learning_rate': 4.25e-05, 'epoch': 0.01}
  1%|â–         | 85/6000 [04:57<5:49:42,  3.55s/it]  1%|â–         | 86/6000 [05:00<5:45:40,  3.51s/it]                                                   {'loss': 0.1483, 'grad_norm': 16.429296493530273, 'learning_rate': 4.3e-05, 'epoch': 0.01}
  1%|â–         | 86/6000 [05:00<5:45:40,  3.51s/it]  1%|â–         | 87/6000 [05:03<5:39:26,  3.44s/it]                                                   {'loss': 0.0028, 'grad_norm': 0.5397030115127563, 'learning_rate': 4.35e-05, 'epoch': 0.01}
  1%|â–         | 87/6000 [05:03<5:39:26,  3.44s/it]  1%|â–         | 88/6000 [05:07<5:34:46,  3.40s/it]                                                   {'loss': 0.0864, 'grad_norm': 10.729168891906738, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 88/6000 [05:07<5:34:46,  3.40s/it]  1%|â–         | 89/6000 [05:10<5:31:06,  3.36s/it]                                                   {'loss': 0.0467, 'grad_norm': 16.80742835998535, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}
  1%|â–         | 89/6000 [05:10<5:31:06,  3.36s/it]  2%|â–         | 90/6000 [05:13<5:34:06,  3.39s/it]                                                   {'loss': 0.0133, 'grad_norm': 2.669306993484497, 'learning_rate': 4.5e-05, 'epoch': 0.01}
  2%|â–         | 90/6000 [05:13<5:34:06,  3.39s/it]  2%|â–         | 91/6000 [05:17<5:32:28,  3.38s/it]                                                   {'loss': 0.1804, 'grad_norm': 25.057336807250977, 'learning_rate': 4.55e-05, 'epoch': 0.02}
  2%|â–         | 91/6000 [05:17<5:32:28,  3.38s/it]  2%|â–         | 92/6000 [05:21<5:43:49,  3.49s/it]                                                   {'loss': 0.1964, 'grad_norm': 14.248345375061035, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.02}
  2%|â–         | 92/6000 [05:21<5:43:49,  3.49s/it]  2%|â–         | 93/6000 [05:24<5:47:25,  3.53s/it]                                                   {'loss': 0.0497, 'grad_norm': 12.764084815979004, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.02}
  2%|â–         | 93/6000 [05:24<5:47:25,  3.53s/it]  2%|â–         | 94/6000 [05:27<5:40:46,  3.46s/it]                                                   {'loss': 0.0966, 'grad_norm': 12.486672401428223, 'learning_rate': 4.7e-05, 'epoch': 0.02}
  2%|â–         | 94/6000 [05:27<5:40:46,  3.46s/it]  2%|â–         | 95/6000 [05:31<5:38:13,  3.44s/it]                                                   {'loss': 0.024, 'grad_norm': 6.6555962562561035, 'learning_rate': 4.75e-05, 'epoch': 0.02}
  2%|â–         | 95/6000 [05:31<5:38:13,  3.44s/it]  2%|â–         | 96/6000 [05:34<5:36:12,  3.42s/it]                                                   {'loss': 0.2508, 'grad_norm': 13.481673240661621, 'learning_rate': 4.8e-05, 'epoch': 0.02}
  2%|â–         | 96/6000 [05:34<5:36:12,  3.42s/it]  2%|â–         | 97/6000 [05:38<5:34:11,  3.40s/it]                                                   {'loss': 0.3453, 'grad_norm': 24.153291702270508, 'learning_rate': 4.85e-05, 'epoch': 0.02}
  2%|â–         | 97/6000 [05:38<5:34:11,  3.40s/it]  2%|â–         | 98/6000 [05:41<5:34:58,  3.41s/it]                                                   {'loss': 0.207, 'grad_norm': 18.75285530090332, 'learning_rate': 4.9e-05, 'epoch': 0.02}
  2%|â–         | 98/6000 [05:41<5:34:58,  3.41s/it]  2%|â–         | 99/6000 [05:44<5:32:07,  3.38s/it]                                                   {'loss': 0.1032, 'grad_norm': 13.507548332214355, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}
  2%|â–         | 99/6000 [05:44<5:32:07,  3.38s/it]  2%|â–         | 100/6000 [05:48<5:30:43,  3.36s/it]                                                    {'loss': 0.5122, 'grad_norm': 27.141687393188477, 'learning_rate': 5e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [05:48<5:30:43,  3.36s/it][2025-10-20 15:35:34,643] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  2%|â–         | 101/6000 [05:54<7:08:12,  4.36s/it]                                                    {'loss': 0.1345, 'grad_norm': 18.48455238342285, 'learning_rate': 4.9991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 101/6000 [05:54<7:08:12,  4.36s/it]  2%|â–         | 102/6000 [05:58<6:39:38,  4.07s/it]                                                    {'loss': 0.0687, 'grad_norm': 18.560075759887695, 'learning_rate': 4.998305084745763e-05, 'epoch': 0.02}
  2%|â–         | 102/6000 [05:58<6:39:38,  4.07s/it]  2%|â–         | 103/6000 [06:01<6:22:45,  3.89s/it]                                                    {'loss': 0.0473, 'grad_norm': 5.393182754516602, 'learning_rate': 4.997457627118644e-05, 'epoch': 0.02}
  2%|â–         | 103/6000 [06:01<6:22:45,  3.89s/it]  2%|â–         | 104/6000 [06:05<6:15:35,  3.82s/it]                                                    {'loss': 0.0865, 'grad_norm': 15.294173240661621, 'learning_rate': 4.9966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 104/6000 [06:05<6:15:35,  3.82s/it]  2%|â–         | 105/6000 [06:08<6:06:17,  3.73s/it]                                                    {'loss': 0.2086, 'grad_norm': 18.93593406677246, 'learning_rate': 4.9957627118644066e-05, 'epoch': 0.02}
  2%|â–         | 105/6000 [06:08<6:06:17,  3.73s/it]  2%|â–         | 106/6000 [06:12<6:02:19,  3.69s/it]                                                    {'loss': 0.0244, 'grad_norm': 8.7981595993042, 'learning_rate': 4.9949152542372884e-05, 'epoch': 0.02}
  2%|â–         | 106/6000 [06:12<6:02:19,  3.69s/it]  2%|â–         | 107/6000 [06:15<5:53:59,  3.60s/it]                                                    {'loss': 0.1459, 'grad_norm': 17.55146598815918, 'learning_rate': 4.9940677966101695e-05, 'epoch': 0.02}
  2%|â–         | 107/6000 [06:15<5:53:59,  3.60s/it]  2%|â–         | 108/6000 [06:19<5:52:38,  3.59s/it]                                                    {'loss': 0.1027, 'grad_norm': 13.752348899841309, 'learning_rate': 4.993220338983051e-05, 'epoch': 0.02}
  2%|â–         | 108/6000 [06:19<5:52:38,  3.59s/it]  2%|â–         | 109/6000 [06:23<5:59:52,  3.67s/it]                                                    {'loss': 0.1484, 'grad_norm': 14.649358749389648, 'learning_rate': 4.9923728813559324e-05, 'epoch': 0.02}
  2%|â–         | 109/6000 [06:23<5:59:52,  3.67s/it]  2%|â–         | 110/6000 [06:26<5:51:24,  3.58s/it]                                                    {'loss': 0.1483, 'grad_norm': 15.815383911132812, 'learning_rate': 4.991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 110/6000 [06:26<5:51:24,  3.58s/it]  2%|â–         | 111/6000 [06:30<5:49:21,  3.56s/it]                                                    {'loss': 0.2209, 'grad_norm': 17.21071434020996, 'learning_rate': 4.990677966101695e-05, 'epoch': 0.02}
  2%|â–         | 111/6000 [06:30<5:49:21,  3.56s/it]  2%|â–         | 112/6000 [06:34<6:01:35,  3.68s/it]                                                    {'loss': 0.089, 'grad_norm': 8.139243125915527, 'learning_rate': 4.9898305084745765e-05, 'epoch': 0.02}
  2%|â–         | 112/6000 [06:34<6:01:35,  3.68s/it]  2%|â–         | 113/6000 [06:37<5:55:10,  3.62s/it]                                                    {'loss': 0.0224, 'grad_norm': 4.223994731903076, 'learning_rate': 4.9889830508474576e-05, 'epoch': 0.02}
  2%|â–         | 113/6000 [06:37<5:55:10,  3.62s/it]  2%|â–         | 114/6000 [06:41<5:49:20,  3.56s/it]                                                    {'loss': 0.1582, 'grad_norm': 15.82746696472168, 'learning_rate': 4.9881355932203394e-05, 'epoch': 0.02}
  2%|â–         | 114/6000 [06:41<5:49:20,  3.56s/it]  2%|â–         | 115/6000 [06:44<5:44:22,  3.51s/it]                                                    {'loss': 0.1412, 'grad_norm': 30.868391036987305, 'learning_rate': 4.9872881355932206e-05, 'epoch': 0.02}
  2%|â–         | 115/6000 [06:44<5:44:22,  3.51s/it]  2%|â–         | 116/6000 [06:47<5:38:47,  3.45s/it]                                                    {'loss': 0.208, 'grad_norm': 31.779788970947266, 'learning_rate': 4.9864406779661024e-05, 'epoch': 0.02}
  2%|â–         | 116/6000 [06:47<5:38:47,  3.45s/it]  2%|â–         | 117/6000 [06:51<5:38:01,  3.45s/it]                                                    {'loss': 0.1517, 'grad_norm': 13.036932945251465, 'learning_rate': 4.9855932203389835e-05, 'epoch': 0.02}
  2%|â–         | 117/6000 [06:51<5:38:01,  3.45s/it]  2%|â–         | 118/6000 [06:55<5:55:29,  3.63s/it]                                                    {'loss': 0.2346, 'grad_norm': 54.0618896484375, 'learning_rate': 4.9847457627118646e-05, 'epoch': 0.02}
  2%|â–         | 118/6000 [06:55<5:55:29,  3.63s/it]  2%|â–         | 119/6000 [06:58<5:46:58,  3.54s/it]                                                    {'loss': 0.0673, 'grad_norm': 10.385315895080566, 'learning_rate': 4.983898305084746e-05, 'epoch': 0.02}
  2%|â–         | 119/6000 [06:58<5:46:58,  3.54s/it]  2%|â–         | 120/6000 [07:02<5:44:25,  3.51s/it]                                                    {'loss': 0.0604, 'grad_norm': 9.857912063598633, 'learning_rate': 4.9830508474576276e-05, 'epoch': 0.02}
  2%|â–         | 120/6000 [07:02<5:44:25,  3.51s/it]  2%|â–         | 121/6000 [07:05<5:43:20,  3.50s/it]                                                    {'loss': 0.0173, 'grad_norm': 4.127148151397705, 'learning_rate': 4.982203389830509e-05, 'epoch': 0.02}
  2%|â–         | 121/6000 [07:05<5:43:20,  3.50s/it]  2%|â–         | 122/6000 [07:09<5:45:26,  3.53s/it]                                                    {'loss': 0.1362, 'grad_norm': 11.614246368408203, 'learning_rate': 4.98135593220339e-05, 'epoch': 0.02}
  2%|â–         | 122/6000 [07:09<5:45:26,  3.53s/it]  2%|â–         | 123/6000 [07:12<5:39:28,  3.47s/it]                                                    {'loss': 0.0098, 'grad_norm': 1.5494972467422485, 'learning_rate': 4.9805084745762716e-05, 'epoch': 0.02}
  2%|â–         | 123/6000 [07:12<5:39:28,  3.47s/it]  2%|â–         | 124/6000 [07:15<5:35:47,  3.43s/it]                                                    {'loss': 0.1629, 'grad_norm': 10.925466537475586, 'learning_rate': 4.979661016949153e-05, 'epoch': 0.02}
  2%|â–         | 124/6000 [07:15<5:35:47,  3.43s/it]  2%|â–         | 125/6000 [07:19<5:42:54,  3.50s/it]                                                    {'loss': 0.0988, 'grad_norm': 13.144773483276367, 'learning_rate': 4.978813559322034e-05, 'epoch': 0.02}
  2%|â–         | 125/6000 [07:19<5:42:54,  3.50s/it]  2%|â–         | 126/6000 [07:22<5:41:22,  3.49s/it]                                                    {'loss': 0.2762, 'grad_norm': 25.366804122924805, 'learning_rate': 4.977966101694915e-05, 'epoch': 0.02}
  2%|â–         | 126/6000 [07:22<5:41:22,  3.49s/it]  2%|â–         | 127/6000 [07:26<5:45:31,  3.53s/it]                                                    {'loss': 0.2272, 'grad_norm': 17.122066497802734, 'learning_rate': 4.977118644067797e-05, 'epoch': 0.02}
  2%|â–         | 127/6000 [07:26<5:45:31,  3.53s/it]  2%|â–         | 128/6000 [07:29<5:40:41,  3.48s/it]                                                    {'loss': 0.055, 'grad_norm': 8.499150276184082, 'learning_rate': 4.976271186440678e-05, 'epoch': 0.02}
  2%|â–         | 128/6000 [07:29<5:40:41,  3.48s/it]  2%|â–         | 129/6000 [07:33<5:37:31,  3.45s/it]                                                    {'loss': 0.0683, 'grad_norm': 6.956010341644287, 'learning_rate': 4.97542372881356e-05, 'epoch': 0.02}
  2%|â–         | 129/6000 [07:33<5:37:31,  3.45s/it]  2%|â–         | 130/6000 [07:36<5:35:24,  3.43s/it]                                                    {'loss': 0.1407, 'grad_norm': 14.396361351013184, 'learning_rate': 4.974576271186441e-05, 'epoch': 0.02}
  2%|â–         | 130/6000 [07:36<5:35:24,  3.43s/it]  2%|â–         | 131/6000 [07:40<5:35:27,  3.43s/it]                                                    {'loss': 0.1743, 'grad_norm': 11.477622985839844, 'learning_rate': 4.973728813559323e-05, 'epoch': 0.02}
  2%|â–         | 131/6000 [07:40<5:35:27,  3.43s/it]  2%|â–         | 132/6000 [07:43<5:33:32,  3.41s/it]                                                    {'loss': 0.0342, 'grad_norm': 4.3429365158081055, 'learning_rate': 4.972881355932204e-05, 'epoch': 0.02}
  2%|â–         | 132/6000 [07:43<5:33:32,  3.41s/it]  2%|â–         | 133/6000 [07:46<5:34:09,  3.42s/it]                                                    {'loss': 0.3595, 'grad_norm': 24.148937225341797, 'learning_rate': 4.972033898305085e-05, 'epoch': 0.02}
  2%|â–         | 133/6000 [07:46<5:34:09,  3.42s/it]  2%|â–         | 134/6000 [07:50<5:38:28,  3.46s/it]                                                    {'loss': 0.1139, 'grad_norm': 9.708520889282227, 'learning_rate': 4.971186440677966e-05, 'epoch': 0.02}
  2%|â–         | 134/6000 [07:50<5:38:28,  3.46s/it]  2%|â–         | 135/6000 [07:53<5:35:37,  3.43s/it]                                                    {'loss': 0.1391, 'grad_norm': 10.791779518127441, 'learning_rate': 4.970338983050848e-05, 'epoch': 0.02}
  2%|â–         | 135/6000 [07:53<5:35:37,  3.43s/it]  2%|â–         | 136/6000 [07:57<5:32:11,  3.40s/it]                                                    {'loss': 0.0542, 'grad_norm': 6.170846939086914, 'learning_rate': 4.969491525423729e-05, 'epoch': 0.02}
  2%|â–         | 136/6000 [07:57<5:32:11,  3.40s/it]  2%|â–         | 137/6000 [08:01<5:47:19,  3.55s/it]                                                    {'loss': 0.0564, 'grad_norm': 9.211222648620605, 'learning_rate': 4.968644067796611e-05, 'epoch': 0.02}
  2%|â–         | 137/6000 [08:01<5:47:19,  3.55s/it]  2%|â–         | 138/6000 [08:04<5:40:25,  3.48s/it]                                                    {'loss': 0.1424, 'grad_norm': 15.06517505645752, 'learning_rate': 4.967796610169492e-05, 'epoch': 0.02}
  2%|â–         | 138/6000 [08:04<5:40:25,  3.48s/it]  2%|â–         | 139/6000 [08:07<5:42:44,  3.51s/it]                                                    {'loss': 0.1277, 'grad_norm': 11.988448143005371, 'learning_rate': 4.966949152542373e-05, 'epoch': 0.02}
  2%|â–         | 139/6000 [08:07<5:42:44,  3.51s/it]  2%|â–         | 140/6000 [08:11<5:53:42,  3.62s/it]                                                    {'loss': 0.2141, 'grad_norm': 17.12386131286621, 'learning_rate': 4.966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 140/6000 [08:11<5:53:42,  3.62s/it]  2%|â–         | 141/6000 [08:15<5:47:47,  3.56s/it]                                                    {'loss': 0.2945, 'grad_norm': 19.908584594726562, 'learning_rate': 4.965254237288136e-05, 'epoch': 0.02}
  2%|â–         | 141/6000 [08:15<5:47:47,  3.56s/it]  2%|â–         | 142/6000 [08:18<5:43:05,  3.51s/it]                                                    {'loss': 0.1001, 'grad_norm': 9.43969440460205, 'learning_rate': 4.964406779661017e-05, 'epoch': 0.02}
  2%|â–         | 142/6000 [08:18<5:43:05,  3.51s/it]  2%|â–         | 143/6000 [08:22<5:40:40,  3.49s/it]                                                    {'loss': 0.0354, 'grad_norm': 6.337362289428711, 'learning_rate': 4.963559322033898e-05, 'epoch': 0.02}
  2%|â–         | 143/6000 [08:22<5:40:40,  3.49s/it]  2%|â–         | 144/6000 [08:25<5:38:53,  3.47s/it]                                                    {'loss': 0.0131, 'grad_norm': 2.349517822265625, 'learning_rate': 4.96271186440678e-05, 'epoch': 0.02}
  2%|â–         | 144/6000 [08:25<5:38:53,  3.47s/it]  2%|â–         | 145/6000 [08:28<5:35:25,  3.44s/it]                                                    {'loss': 0.0153, 'grad_norm': 2.874105930328369, 'learning_rate': 4.961864406779661e-05, 'epoch': 0.02}
  2%|â–         | 145/6000 [08:28<5:35:25,  3.44s/it]  2%|â–         | 146/6000 [08:32<5:37:40,  3.46s/it]                                                    {'loss': 0.0917, 'grad_norm': 11.627979278564453, 'learning_rate': 4.961016949152543e-05, 'epoch': 0.02}
  2%|â–         | 146/6000 [08:32<5:37:40,  3.46s/it]  2%|â–         | 147/6000 [08:35<5:33:39,  3.42s/it]                                                    {'loss': 0.1319, 'grad_norm': 13.852014541625977, 'learning_rate': 4.9601694915254234e-05, 'epoch': 0.02}
  2%|â–         | 147/6000 [08:35<5:33:39,  3.42s/it]  2%|â–         | 148/6000 [08:39<5:40:21,  3.49s/it]                                                    {'loss': 0.0532, 'grad_norm': 7.141970634460449, 'learning_rate': 4.959322033898305e-05, 'epoch': 0.02}
  2%|â–         | 148/6000 [08:39<5:40:21,  3.49s/it]  2%|â–         | 149/6000 [08:42<5:37:38,  3.46s/it]                                                    {'loss': 0.0894, 'grad_norm': 13.639301300048828, 'learning_rate': 4.9584745762711864e-05, 'epoch': 0.02}
  2%|â–         | 149/6000 [08:42<5:37:38,  3.46s/it]  2%|â–Ž         | 150/6000 [08:46<5:36:09,  3.45s/it]                                                    {'loss': 0.0039, 'grad_norm': 0.5671954154968262, 'learning_rate': 4.957627118644068e-05, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [08:46<5:36:09,  3.45s/it][2025-10-20 15:38:32,626] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 151/6000 [08:51<6:41:54,  4.12s/it]                                                    {'loss': 0.1498, 'grad_norm': 10.975651741027832, 'learning_rate': 4.956779661016949e-05, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [08:51<6:41:54,  4.12s/it]  3%|â–Ž         | 152/6000 [08:55<6:22:23,  3.92s/it]                                                    {'loss': 0.1542, 'grad_norm': 15.966475486755371, 'learning_rate': 4.955932203389831e-05, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [08:55<6:22:23,  3.92s/it]  3%|â–Ž         | 153/6000 [08:58<6:05:00,  3.75s/it]                                                    {'loss': 0.0134, 'grad_norm': 1.1020046472549438, 'learning_rate': 4.955084745762712e-05, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [08:58<6:05:00,  3.75s/it]  3%|â–Ž         | 154/6000 [09:02<5:58:26,  3.68s/it]                                                    {'loss': 0.1703, 'grad_norm': 15.481245994567871, 'learning_rate': 4.9542372881355934e-05, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [09:02<5:58:26,  3.68s/it]  3%|â–Ž         | 155/6000 [09:05<5:51:04,  3.60s/it]                                                    {'loss': 0.0706, 'grad_norm': 5.901394844055176, 'learning_rate': 4.9533898305084745e-05, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [09:05<5:51:04,  3.60s/it]  3%|â–Ž         | 156/6000 [09:09<5:47:04,  3.56s/it]                                                    {'loss': 0.0204, 'grad_norm': 4.721062183380127, 'learning_rate': 4.952542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [09:09<5:47:04,  3.56s/it]  3%|â–Ž         | 157/6000 [09:12<5:58:19,  3.68s/it]                                                    {'loss': 0.0439, 'grad_norm': 4.0636162757873535, 'learning_rate': 4.9516949152542374e-05, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [09:12<5:58:19,  3.68s/it]  3%|â–Ž         | 158/6000 [09:16<5:48:33,  3.58s/it]                                                    {'loss': 0.0072, 'grad_norm': 0.969868004322052, 'learning_rate': 4.950847457627119e-05, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [09:16<5:48:33,  3.58s/it]  3%|â–Ž         | 159/6000 [09:19<5:42:13,  3.52s/it]                                                    {'loss': 0.1958, 'grad_norm': 14.452118873596191, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [09:19<5:42:13,  3.52s/it]  3%|â–Ž         | 160/6000 [09:23<5:58:19,  3.68s/it]                                                    {'loss': 0.0842, 'grad_norm': 8.081758499145508, 'learning_rate': 4.9491525423728815e-05, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [09:23<5:58:19,  3.68s/it]  3%|â–Ž         | 161/6000 [09:27<5:53:40,  3.63s/it]                                                    {'loss': 0.1398, 'grad_norm': 14.690592765808105, 'learning_rate': 4.9483050847457626e-05, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [09:27<5:53:40,  3.63s/it]  3%|â–Ž         | 162/6000 [09:30<5:45:45,  3.55s/it]                                                    {'loss': 0.011, 'grad_norm': 1.357038974761963, 'learning_rate': 4.9474576271186444e-05, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [09:30<5:45:45,  3.55s/it]  3%|â–Ž         | 163/6000 [09:34<6:00:40,  3.71s/it]                                                    {'loss': 0.0814, 'grad_norm': 11.532861709594727, 'learning_rate': 4.9466101694915256e-05, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [09:34<6:00:40,  3.71s/it]  3%|â–Ž         | 164/6000 [09:38<5:52:28,  3.62s/it]                                                    {'loss': 0.3237, 'grad_norm': 15.401776313781738, 'learning_rate': 4.945762711864407e-05, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [09:38<5:52:28,  3.62s/it]  3%|â–Ž         | 165/6000 [09:41<5:50:42,  3.61s/it]                                                    {'loss': 0.0357, 'grad_norm': 4.767435073852539, 'learning_rate': 4.9449152542372885e-05, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [09:41<5:50:42,  3.61s/it]  3%|â–Ž         | 166/6000 [09:45<5:42:25,  3.52s/it]                                                    {'loss': 0.1349, 'grad_norm': 8.808500289916992, 'learning_rate': 4.9440677966101696e-05, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [09:45<5:42:25,  3.52s/it]  3%|â–Ž         | 167/6000 [09:48<5:38:28,  3.48s/it]                                                    {'loss': 0.0309, 'grad_norm': 5.147429943084717, 'learning_rate': 4.9432203389830514e-05, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [09:48<5:38:28,  3.48s/it]  3%|â–Ž         | 168/6000 [09:51<5:36:43,  3.46s/it]                                                    {'loss': 0.1512, 'grad_norm': 10.066557884216309, 'learning_rate': 4.9423728813559326e-05, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [09:51<5:36:43,  3.46s/it]  3%|â–Ž         | 169/6000 [09:55<5:47:58,  3.58s/it]                                                    {'loss': 0.1793, 'grad_norm': 11.714554786682129, 'learning_rate': 4.941525423728814e-05, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [09:55<5:47:58,  3.58s/it]  3%|â–Ž         | 170/6000 [09:59<5:41:03,  3.51s/it]                                                    {'loss': 0.1046, 'grad_norm': 5.6401448249816895, 'learning_rate': 4.940677966101695e-05, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [09:59<5:41:03,  3.51s/it]  3%|â–Ž         | 171/6000 [10:02<5:36:32,  3.46s/it]                                                    {'loss': 0.0379, 'grad_norm': 3.954514741897583, 'learning_rate': 4.9398305084745766e-05, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [10:02<5:36:32,  3.46s/it]  3%|â–Ž         | 172/6000 [10:05<5:38:54,  3.49s/it]                                                    {'loss': 0.1605, 'grad_norm': 13.825765609741211, 'learning_rate': 4.938983050847458e-05, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [10:05<5:38:54,  3.49s/it]  3%|â–Ž         | 173/6000 [10:09<5:38:46,  3.49s/it]                                                    {'loss': 0.1586, 'grad_norm': 20.099769592285156, 'learning_rate': 4.9381355932203396e-05, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [10:09<5:38:46,  3.49s/it]  3%|â–Ž         | 174/6000 [10:13<5:59:01,  3.70s/it]                                                    {'loss': 0.0069, 'grad_norm': 1.261710524559021, 'learning_rate': 4.937288135593221e-05, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [10:13<5:59:01,  3.70s/it]  3%|â–Ž         | 175/6000 [10:17<5:50:33,  3.61s/it]                                                    {'loss': 0.1095, 'grad_norm': 14.903480529785156, 'learning_rate': 4.936440677966102e-05, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [10:17<5:50:33,  3.61s/it]  3%|â–Ž         | 176/6000 [10:20<5:54:42,  3.65s/it]                                                    {'loss': 0.0538, 'grad_norm': 8.684917449951172, 'learning_rate': 4.935593220338983e-05, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [10:20<5:54:42,  3.65s/it]  3%|â–Ž         | 177/6000 [10:24<5:46:37,  3.57s/it]                                                    {'loss': 0.025, 'grad_norm': 3.963144063949585, 'learning_rate': 4.934745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [10:24<5:46:37,  3.57s/it]  3%|â–Ž         | 178/6000 [10:27<5:42:13,  3.53s/it]                                                    {'loss': 0.0524, 'grad_norm': 7.30649995803833, 'learning_rate': 4.933898305084746e-05, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [10:27<5:42:13,  3.53s/it]  3%|â–Ž         | 179/6000 [10:30<5:37:41,  3.48s/it]                                                    {'loss': 0.0275, 'grad_norm': 1.930821180343628, 'learning_rate': 4.933050847457628e-05, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [10:30<5:37:41,  3.48s/it]  3%|â–Ž         | 180/6000 [10:34<5:37:44,  3.48s/it]                                                    {'loss': 0.2516, 'grad_norm': 12.726994514465332, 'learning_rate': 4.932203389830509e-05, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [10:34<5:37:44,  3.48s/it]  3%|â–Ž         | 181/6000 [10:37<5:35:45,  3.46s/it]                                                    {'loss': 0.3237, 'grad_norm': 18.17803382873535, 'learning_rate': 4.9313559322033906e-05, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [10:37<5:35:45,  3.46s/it]  3%|â–Ž         | 182/6000 [10:41<5:31:42,  3.42s/it]                                                    {'loss': 0.0207, 'grad_norm': 2.742513418197632, 'learning_rate': 4.930508474576271e-05, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [10:41<5:31:42,  3.42s/it]  3%|â–Ž         | 183/6000 [10:44<5:28:50,  3.39s/it]                                                    {'loss': 0.1686, 'grad_norm': 12.278801918029785, 'learning_rate': 4.929661016949153e-05, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [10:44<5:28:50,  3.39s/it]  3%|â–Ž         | 184/6000 [10:47<5:30:06,  3.41s/it]                                                    {'loss': 0.2193, 'grad_norm': 11.429643630981445, 'learning_rate': 4.928813559322034e-05, 'epoch': 0.03}
  3%|â–Ž         | 184/6000 [10:47<5:30:06,  3.41s/it]  3%|â–Ž         | 185/6000 [10:51<5:30:46,  3.41s/it]                                                    {'loss': 0.247, 'grad_norm': 11.554024696350098, 'learning_rate': 4.927966101694915e-05, 'epoch': 0.03}
  3%|â–Ž         | 185/6000 [10:51<5:30:46,  3.41s/it]  3%|â–Ž         | 186/6000 [10:54<5:30:52,  3.41s/it]                                                    {'loss': 0.0497, 'grad_norm': 8.6522855758667, 'learning_rate': 4.927118644067797e-05, 'epoch': 0.03}
  3%|â–Ž         | 186/6000 [10:54<5:30:52,  3.41s/it]  3%|â–Ž         | 187/6000 [10:58<5:31:40,  3.42s/it]                                                    {'loss': 0.0316, 'grad_norm': 5.737912178039551, 'learning_rate': 4.926271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 187/6000 [10:58<5:31:40,  3.42s/it]  3%|â–Ž         | 188/6000 [11:01<5:31:32,  3.42s/it]                                                    {'loss': 0.1099, 'grad_norm': 10.733758926391602, 'learning_rate': 4.92542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 188/6000 [11:01<5:31:32,  3.42s/it]  3%|â–Ž         | 189/6000 [11:05<5:31:40,  3.42s/it]                                                    {'loss': 0.1067, 'grad_norm': 8.799357414245605, 'learning_rate': 4.924576271186441e-05, 'epoch': 0.03}
  3%|â–Ž         | 189/6000 [11:05<5:31:40,  3.42s/it]  3%|â–Ž         | 190/6000 [11:08<5:28:32,  3.39s/it]                                                    {'loss': 0.034, 'grad_norm': 3.756558418273926, 'learning_rate': 4.923728813559322e-05, 'epoch': 0.03}
  3%|â–Ž         | 190/6000 [11:08<5:28:32,  3.39s/it]  3%|â–Ž         | 191/6000 [11:11<5:29:32,  3.40s/it]                                                    {'loss': 0.0272, 'grad_norm': 3.5979154109954834, 'learning_rate': 4.922881355932203e-05, 'epoch': 0.03}
  3%|â–Ž         | 191/6000 [11:11<5:29:32,  3.40s/it]  3%|â–Ž         | 192/6000 [11:15<5:49:17,  3.61s/it]                                                    {'loss': 0.0934, 'grad_norm': 9.818341255187988, 'learning_rate': 4.922033898305085e-05, 'epoch': 0.03}
  3%|â–Ž         | 192/6000 [11:15<5:49:17,  3.61s/it]  3%|â–Ž         | 193/6000 [11:19<5:53:34,  3.65s/it]                                                    {'loss': 0.1931, 'grad_norm': 10.28996753692627, 'learning_rate': 4.921186440677966e-05, 'epoch': 0.03}
  3%|â–Ž         | 193/6000 [11:19<5:53:34,  3.65s/it]  3%|â–Ž         | 194/6000 [11:23<5:44:37,  3.56s/it]                                                    {'loss': 0.1872, 'grad_norm': 9.659273147583008, 'learning_rate': 4.920338983050848e-05, 'epoch': 0.03}
  3%|â–Ž         | 194/6000 [11:23<5:44:37,  3.56s/it]  3%|â–Ž         | 195/6000 [11:26<5:41:52,  3.53s/it]                                                    {'loss': 0.0071, 'grad_norm': 0.950290322303772, 'learning_rate': 4.919491525423729e-05, 'epoch': 0.03}
  3%|â–Ž         | 195/6000 [11:26<5:41:52,  3.53s/it]  3%|â–Ž         | 196/6000 [11:29<5:38:21,  3.50s/it]                                                    {'loss': 0.0132, 'grad_norm': 2.7557990550994873, 'learning_rate': 4.91864406779661e-05, 'epoch': 0.03}
  3%|â–Ž         | 196/6000 [11:29<5:38:21,  3.50s/it]  3%|â–Ž         | 197/6000 [11:33<5:40:01,  3.52s/it]                                                    {'loss': 0.0421, 'grad_norm': 5.573667526245117, 'learning_rate': 4.9177966101694914e-05, 'epoch': 0.03}
  3%|â–Ž         | 197/6000 [11:33<5:40:01,  3.52s/it]  3%|â–Ž         | 198/6000 [11:37<5:41:08,  3.53s/it]                                                    {'loss': 0.0288, 'grad_norm': 4.519708633422852, 'learning_rate': 4.916949152542373e-05, 'epoch': 0.03}
  3%|â–Ž         | 198/6000 [11:37<5:41:08,  3.53s/it]  3%|â–Ž         | 199/6000 [11:40<5:36:02,  3.48s/it]                                                    {'loss': 0.0965, 'grad_norm': 7.6698737144470215, 'learning_rate': 4.916101694915254e-05, 'epoch': 0.03}
  3%|â–Ž         | 199/6000 [11:40<5:36:02,  3.48s/it]  3%|â–Ž         | 200/6000 [11:44<5:46:55,  3.59s/it]                                                    {'loss': 0.0903, 'grad_norm': 9.903265953063965, 'learning_rate': 4.915254237288136e-05, 'epoch': 0.03}
  3%|â–Ž         | 200/6000 [11:44<5:46:55,  3.59s/it][2025-10-20 15:41:30,740] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 201/6000 [11:49<6:46:31,  4.21s/it]                                                    {'loss': 0.2911, 'grad_norm': 18.70783042907715, 'learning_rate': 4.914406779661017e-05, 'epoch': 0.03}
  3%|â–Ž         | 201/6000 [11:49<6:46:31,  4.21s/it]  3%|â–Ž         | 202/6000 [11:53<6:21:21,  3.95s/it]                                                    {'loss': 0.1165, 'grad_norm': 8.002519607543945, 'learning_rate': 4.913559322033899e-05, 'epoch': 0.03}
  3%|â–Ž         | 202/6000 [11:53<6:21:21,  3.95s/it]  3%|â–Ž         | 203/6000 [11:56<6:06:38,  3.79s/it]                                                    {'loss': 0.0732, 'grad_norm': 6.6721110343933105, 'learning_rate': 4.91271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 203/6000 [11:56<6:06:38,  3.79s/it]  3%|â–Ž         | 204/6000 [12:00<5:57:46,  3.70s/it]                                                    {'loss': 0.1032, 'grad_norm': 6.125227928161621, 'learning_rate': 4.9118644067796607e-05, 'epoch': 0.03}
  3%|â–Ž         | 204/6000 [12:00<5:57:46,  3.70s/it]  3%|â–Ž         | 205/6000 [12:03<5:46:49,  3.59s/it]                                                    {'loss': 0.1673, 'grad_norm': 10.35258674621582, 'learning_rate': 4.9110169491525425e-05, 'epoch': 0.03}
  3%|â–Ž         | 205/6000 [12:03<5:46:49,  3.59s/it]  3%|â–Ž         | 206/6000 [12:06<5:39:58,  3.52s/it]                                                    {'loss': 0.0039, 'grad_norm': 0.9253072142601013, 'learning_rate': 4.9101694915254236e-05, 'epoch': 0.03}
  3%|â–Ž         | 206/6000 [12:06<5:39:58,  3.52s/it]  3%|â–Ž         | 207/6000 [12:10<5:39:23,  3.52s/it]                                                    {'loss': 0.0904, 'grad_norm': 10.047623634338379, 'learning_rate': 4.9093220338983054e-05, 'epoch': 0.03}
  3%|â–Ž         | 207/6000 [12:10<5:39:23,  3.52s/it]  3%|â–Ž         | 208/6000 [12:13<5:33:05,  3.45s/it]                                                    {'loss': 0.0588, 'grad_norm': 4.428057670593262, 'learning_rate': 4.9084745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 208/6000 [12:13<5:33:05,  3.45s/it]  3%|â–Ž         | 209/6000 [12:17<5:32:14,  3.44s/it]                                                    {'loss': 0.0253, 'grad_norm': 4.52716064453125, 'learning_rate': 4.907627118644068e-05, 'epoch': 0.03}
  3%|â–Ž         | 209/6000 [12:17<5:32:14,  3.44s/it]  4%|â–Ž         | 210/6000 [12:20<5:43:09,  3.56s/it]                                                    {'loss': 0.0356, 'grad_norm': 6.376646995544434, 'learning_rate': 4.9067796610169495e-05, 'epoch': 0.04}
  4%|â–Ž         | 210/6000 [12:20<5:43:09,  3.56s/it]  4%|â–Ž         | 211/6000 [12:24<5:44:11,  3.57s/it]                                                    {'loss': 0.036, 'grad_norm': 4.633805274963379, 'learning_rate': 4.9059322033898306e-05, 'epoch': 0.04}
  4%|â–Ž         | 211/6000 [12:24<5:44:11,  3.57s/it]  4%|â–Ž         | 212/6000 [12:28<5:51:25,  3.64s/it]                                                    {'loss': 0.1343, 'grad_norm': 7.12399959564209, 'learning_rate': 4.905084745762712e-05, 'epoch': 0.04}
  4%|â–Ž         | 212/6000 [12:28<5:51:25,  3.64s/it]  4%|â–Ž         | 213/6000 [12:31<5:45:53,  3.59s/it]                                                    {'loss': 0.0498, 'grad_norm': 5.380349636077881, 'learning_rate': 4.9042372881355935e-05, 'epoch': 0.04}
  4%|â–Ž         | 213/6000 [12:31<5:45:53,  3.59s/it]  4%|â–Ž         | 214/6000 [12:35<5:38:33,  3.51s/it]                                                    {'loss': 0.0223, 'grad_norm': 4.371865749359131, 'learning_rate': 4.9033898305084746e-05, 'epoch': 0.04}
  4%|â–Ž         | 214/6000 [12:35<5:38:33,  3.51s/it]  4%|â–Ž         | 215/6000 [12:38<5:35:40,  3.48s/it]                                                    {'loss': 0.021, 'grad_norm': 2.9504358768463135, 'learning_rate': 4.9025423728813565e-05, 'epoch': 0.04}
  4%|â–Ž         | 215/6000 [12:38<5:35:40,  3.48s/it]  4%|â–Ž         | 216/6000 [12:41<5:34:50,  3.47s/it]                                                    {'loss': 0.002, 'grad_norm': 0.20694763958454132, 'learning_rate': 4.9016949152542376e-05, 'epoch': 0.04}
  4%|â–Ž         | 216/6000 [12:41<5:34:50,  3.47s/it]  4%|â–Ž         | 217/6000 [12:45<5:39:10,  3.52s/it]                                                    {'loss': 0.0044, 'grad_norm': 0.8923385739326477, 'learning_rate': 4.9008474576271194e-05, 'epoch': 0.04}
  4%|â–Ž         | 217/6000 [12:45<5:39:10,  3.52s/it]  4%|â–Ž         | 218/6000 [12:49<5:36:55,  3.50s/it]                                                    {'loss': 0.0678, 'grad_norm': 9.588951110839844, 'learning_rate': 4.9e-05, 'epoch': 0.04}
  4%|â–Ž         | 218/6000 [12:49<5:36:55,  3.50s/it]  4%|â–Ž         | 219/6000 [12:52<5:34:21,  3.47s/it]                                                    {'loss': 0.1756, 'grad_norm': 14.851584434509277, 'learning_rate': 4.8991525423728816e-05, 'epoch': 0.04}
  4%|â–Ž         | 219/6000 [12:52<5:34:21,  3.47s/it]  4%|â–Ž         | 220/6000 [12:55<5:34:55,  3.48s/it]                                                    {'loss': 0.6278, 'grad_norm': 18.764841079711914, 'learning_rate': 4.898305084745763e-05, 'epoch': 0.04}
  4%|â–Ž         | 220/6000 [12:55<5:34:55,  3.48s/it]  4%|â–Ž         | 221/6000 [12:59<5:32:25,  3.45s/it]                                                    {'loss': 0.0128, 'grad_norm': 1.4241416454315186, 'learning_rate': 4.8974576271186446e-05, 'epoch': 0.04}
  4%|â–Ž         | 221/6000 [12:59<5:32:25,  3.45s/it]  4%|â–Ž         | 222/6000 [13:02<5:29:22,  3.42s/it]                                                    {'loss': 0.1991, 'grad_norm': 12.842411994934082, 'learning_rate': 4.896610169491526e-05, 'epoch': 0.04}
  4%|â–Ž         | 222/6000 [13:02<5:29:22,  3.42s/it]  4%|â–Ž         | 223/6000 [13:06<5:29:22,  3.42s/it]                                                    {'loss': 0.0782, 'grad_norm': 8.140707015991211, 'learning_rate': 4.8957627118644075e-05, 'epoch': 0.04}
  4%|â–Ž         | 223/6000 [13:06<5:29:22,  3.42s/it]  4%|â–Ž         | 224/6000 [13:09<5:34:08,  3.47s/it]                                                    {'loss': 0.0568, 'grad_norm': 5.378384590148926, 'learning_rate': 4.8949152542372886e-05, 'epoch': 0.04}
  4%|â–Ž         | 224/6000 [13:09<5:34:08,  3.47s/it]  4%|â–         | 225/6000 [13:13<5:34:19,  3.47s/it]                                                    {'loss': 0.2388, 'grad_norm': 14.31476879119873, 'learning_rate': 4.89406779661017e-05, 'epoch': 0.04}
  4%|â–         | 225/6000 [13:13<5:34:19,  3.47s/it]  4%|â–         | 226/6000 [13:17<5:47:23,  3.61s/it]                                                    {'loss': 0.0573, 'grad_norm': 7.457493782043457, 'learning_rate': 4.893220338983051e-05, 'epoch': 0.04}
  4%|â–         | 226/6000 [13:17<5:47:23,  3.61s/it]  4%|â–         | 227/6000 [13:20<5:40:48,  3.54s/it]                                                    {'loss': 0.1069, 'grad_norm': 12.463478088378906, 'learning_rate': 4.892372881355932e-05, 'epoch': 0.04}
  4%|â–         | 227/6000 [13:20<5:40:48,  3.54s/it]  4%|â–         | 228/6000 [13:23<5:37:40,  3.51s/it]                                                    {'loss': 0.0157, 'grad_norm': 2.96138072013855, 'learning_rate': 4.891525423728814e-05, 'epoch': 0.04}
  4%|â–         | 228/6000 [13:23<5:37:40,  3.51s/it]  4%|â–         | 229/6000 [13:27<5:33:11,  3.46s/it]                                                    {'loss': 0.0578, 'grad_norm': 5.136215686798096, 'learning_rate': 4.890677966101695e-05, 'epoch': 0.04}
  4%|â–         | 229/6000 [13:27<5:33:11,  3.46s/it]  4%|â–         | 230/6000 [13:30<5:34:10,  3.48s/it]                                                    {'loss': 0.1326, 'grad_norm': 15.538435935974121, 'learning_rate': 4.889830508474577e-05, 'epoch': 0.04}
  4%|â–         | 230/6000 [13:30<5:34:10,  3.48s/it]  4%|â–         | 231/6000 [13:34<5:30:16,  3.43s/it]                                                    {'loss': 0.0368, 'grad_norm': 4.218297958374023, 'learning_rate': 4.888983050847458e-05, 'epoch': 0.04}
  4%|â–         | 231/6000 [13:34<5:30:16,  3.43s/it]  4%|â–         | 232/6000 [13:37<5:28:33,  3.42s/it]                                                    {'loss': 0.2783, 'grad_norm': 21.999692916870117, 'learning_rate': 4.888135593220339e-05, 'epoch': 0.04}
  4%|â–         | 232/6000 [13:37<5:28:33,  3.42s/it]  4%|â–         | 233/6000 [13:41<5:40:20,  3.54s/it]                                                    {'loss': 0.1161, 'grad_norm': 12.219528198242188, 'learning_rate': 4.88728813559322e-05, 'epoch': 0.04}
  4%|â–         | 233/6000 [13:41<5:40:20,  3.54s/it]  4%|â–         | 234/6000 [13:45<5:44:40,  3.59s/it]                                                    {'loss': 0.0158, 'grad_norm': 2.2234225273132324, 'learning_rate': 4.886440677966102e-05, 'epoch': 0.04}
  4%|â–         | 234/6000 [13:45<5:44:40,  3.59s/it]  4%|â–         | 235/6000 [13:48<5:36:02,  3.50s/it]                                                    {'loss': 0.1419, 'grad_norm': 11.127666473388672, 'learning_rate': 4.885593220338983e-05, 'epoch': 0.04}
  4%|â–         | 235/6000 [13:48<5:36:02,  3.50s/it]  4%|â–         | 236/6000 [13:51<5:35:44,  3.49s/it]                                                    {'loss': 0.1761, 'grad_norm': 7.056906223297119, 'learning_rate': 4.884745762711865e-05, 'epoch': 0.04}
  4%|â–         | 236/6000 [13:51<5:35:44,  3.49s/it]  4%|â–         | 237/6000 [13:55<5:33:25,  3.47s/it]                                                    {'loss': 0.281, 'grad_norm': 12.898458480834961, 'learning_rate': 4.883898305084746e-05, 'epoch': 0.04}
  4%|â–         | 237/6000 [13:55<5:33:25,  3.47s/it]  4%|â–         | 238/6000 [13:59<5:46:00,  3.60s/it]                                                    {'loss': 0.1679, 'grad_norm': 5.053371906280518, 'learning_rate': 4.883050847457628e-05, 'epoch': 0.04}
  4%|â–         | 238/6000 [13:59<5:46:00,  3.60s/it]  4%|â–         | 239/6000 [14:02<5:43:18,  3.58s/it]                                                    {'loss': 0.0819, 'grad_norm': 9.595876693725586, 'learning_rate': 4.882203389830508e-05, 'epoch': 0.04}
  4%|â–         | 239/6000 [14:02<5:43:18,  3.58s/it]  4%|â–         | 240/6000 [14:06<5:39:08,  3.53s/it]                                                    {'loss': 0.0555, 'grad_norm': 9.287524223327637, 'learning_rate': 4.88135593220339e-05, 'epoch': 0.04}
  4%|â–         | 240/6000 [14:06<5:39:08,  3.53s/it]  4%|â–         | 241/6000 [14:09<5:38:32,  3.53s/it]                                                    {'loss': 0.0896, 'grad_norm': 8.289396286010742, 'learning_rate': 4.880508474576271e-05, 'epoch': 0.04}
  4%|â–         | 241/6000 [14:09<5:38:32,  3.53s/it]  4%|â–         | 242/6000 [14:12<5:34:11,  3.48s/it]                                                    {'loss': 0.0359, 'grad_norm': 4.56292200088501, 'learning_rate': 4.879661016949153e-05, 'epoch': 0.04}
  4%|â–         | 242/6000 [14:12<5:34:11,  3.48s/it]  4%|â–         | 243/6000 [14:16<5:41:42,  3.56s/it]                                                    {'loss': 0.1175, 'grad_norm': 6.30498743057251, 'learning_rate': 4.878813559322034e-05, 'epoch': 0.04}
  4%|â–         | 243/6000 [14:16<5:41:42,  3.56s/it]  4%|â–         | 244/6000 [14:20<5:36:41,  3.51s/it]                                                    {'loss': 0.0374, 'grad_norm': 5.115567684173584, 'learning_rate': 4.877966101694916e-05, 'epoch': 0.04}
  4%|â–         | 244/6000 [14:20<5:36:41,  3.51s/it]  4%|â–         | 245/6000 [14:23<5:34:00,  3.48s/it]                                                    {'loss': 0.0591, 'grad_norm': 6.733574390411377, 'learning_rate': 4.877118644067797e-05, 'epoch': 0.04}
  4%|â–         | 245/6000 [14:23<5:34:00,  3.48s/it]  4%|â–         | 246/6000 [14:27<5:35:22,  3.50s/it]                                                    {'loss': 0.0038, 'grad_norm': 1.1605280637741089, 'learning_rate': 4.876271186440678e-05, 'epoch': 0.04}
  4%|â–         | 246/6000 [14:27<5:35:22,  3.50s/it]  4%|â–         | 247/6000 [14:30<5:38:37,  3.53s/it]                                                    {'loss': 0.0477, 'grad_norm': 5.556127548217773, 'learning_rate': 4.8754237288135593e-05, 'epoch': 0.04}
  4%|â–         | 247/6000 [14:30<5:38:37,  3.53s/it]  4%|â–         | 248/6000 [14:34<5:39:04,  3.54s/it]                                                    {'loss': 0.0206, 'grad_norm': 3.8618626594543457, 'learning_rate': 4.8745762711864405e-05, 'epoch': 0.04}
  4%|â–         | 248/6000 [14:34<5:39:04,  3.54s/it]  4%|â–         | 249/6000 [14:37<5:32:03,  3.46s/it]                                                    {'loss': 0.0059, 'grad_norm': 1.6838754415512085, 'learning_rate': 4.873728813559322e-05, 'epoch': 0.04}
  4%|â–         | 249/6000 [14:37<5:32:03,  3.46s/it]  4%|â–         | 250/6000 [14:40<5:28:54,  3.43s/it]                                                    {'loss': 0.023, 'grad_norm': 2.0916872024536133, 'learning_rate': 4.8728813559322034e-05, 'epoch': 0.04}
  4%|â–         | 250/6000 [14:40<5:28:54,  3.43s/it][2025-10-20 15:44:27,341] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  4%|â–         | 251/6000 [14:46<6:29:14,  4.06s/it]                                                    {'loss': 0.0358, 'grad_norm': 4.589000225067139, 'learning_rate': 4.872033898305085e-05, 'epoch': 0.04}
  4%|â–         | 251/6000 [14:46<6:29:14,  4.06s/it]  4%|â–         | 252/6000 [14:50<6:19:16,  3.96s/it]                                                    {'loss': 0.0401, 'grad_norm': 7.936459541320801, 'learning_rate': 4.8711864406779663e-05, 'epoch': 0.04}
  4%|â–         | 252/6000 [14:50<6:19:16,  3.96s/it]  4%|â–         | 253/6000 [14:53<6:04:42,  3.81s/it]                                                    {'loss': 0.056, 'grad_norm': 6.882889747619629, 'learning_rate': 4.8703389830508475e-05, 'epoch': 0.04}
  4%|â–         | 253/6000 [14:53<6:04:42,  3.81s/it]  4%|â–         | 254/6000 [14:57<5:54:27,  3.70s/it]                                                    {'loss': 0.1327, 'grad_norm': 9.747159004211426, 'learning_rate': 4.8694915254237286e-05, 'epoch': 0.04}
  4%|â–         | 254/6000 [14:57<5:54:27,  3.70s/it]  4%|â–         | 255/6000 [15:00<5:46:07,  3.61s/it]                                                    {'loss': 0.0128, 'grad_norm': 1.9861079454421997, 'learning_rate': 4.8686440677966104e-05, 'epoch': 0.04}
  4%|â–         | 255/6000 [15:00<5:46:07,  3.61s/it]  4%|â–         | 256/6000 [15:04<5:52:52,  3.69s/it]                                                    {'loss': 0.0926, 'grad_norm': 10.742318153381348, 'learning_rate': 4.8677966101694915e-05, 'epoch': 0.04}
  4%|â–         | 256/6000 [15:04<5:52:52,  3.69s/it]  4%|â–         | 257/6000 [15:07<5:45:57,  3.61s/it]                                                    {'loss': 0.0146, 'grad_norm': 2.9796552658081055, 'learning_rate': 4.8669491525423733e-05, 'epoch': 0.04}
  4%|â–         | 257/6000 [15:07<5:45:57,  3.61s/it]  4%|â–         | 258/6000 [15:11<5:38:48,  3.54s/it]                                                    {'loss': 0.0245, 'grad_norm': 3.2114832401275635, 'learning_rate': 4.8661016949152545e-05, 'epoch': 0.04}
  4%|â–         | 258/6000 [15:11<5:38:48,  3.54s/it]  4%|â–         | 259/6000 [15:14<5:32:53,  3.48s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.1841354370117188, 'learning_rate': 4.865254237288136e-05, 'epoch': 0.04}
  4%|â–         | 259/6000 [15:14<5:32:53,  3.48s/it]  4%|â–         | 260/6000 [15:17<5:29:51,  3.45s/it]                                                    {'loss': 0.0127, 'grad_norm': 2.8831210136413574, 'learning_rate': 4.8644067796610174e-05, 'epoch': 0.04}
  4%|â–         | 260/6000 [15:17<5:29:51,  3.45s/it]  4%|â–         | 261/6000 [15:21<5:33:45,  3.49s/it]                                                    {'loss': 0.0294, 'grad_norm': 2.700561761856079, 'learning_rate': 4.8635593220338985e-05, 'epoch': 0.04}
  4%|â–         | 261/6000 [15:21<5:33:45,  3.49s/it]  4%|â–         | 262/6000 [15:24<5:29:57,  3.45s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.09103705734014511, 'learning_rate': 4.86271186440678e-05, 'epoch': 0.04}
  4%|â–         | 262/6000 [15:24<5:29:57,  3.45s/it]  4%|â–         | 263/6000 [15:28<5:40:02,  3.56s/it]                                                    {'loss': 0.0234, 'grad_norm': 4.09895658493042, 'learning_rate': 4.8618644067796615e-05, 'epoch': 0.04}
  4%|â–         | 263/6000 [15:28<5:40:02,  3.56s/it]  4%|â–         | 264/6000 [15:31<5:32:59,  3.48s/it]                                                    {'loss': 0.0355, 'grad_norm': 5.137681484222412, 'learning_rate': 4.8610169491525426e-05, 'epoch': 0.04}
  4%|â–         | 264/6000 [15:31<5:32:59,  3.48s/it]  4%|â–         | 265/6000 [15:35<5:34:48,  3.50s/it]                                                    {'loss': 0.0104, 'grad_norm': 1.8634333610534668, 'learning_rate': 4.8601694915254244e-05, 'epoch': 0.04}
  4%|â–         | 265/6000 [15:35<5:34:48,  3.50s/it]  4%|â–         | 266/6000 [15:38<5:34:00,  3.49s/it]                                                    {'loss': 0.0076, 'grad_norm': 1.4710965156555176, 'learning_rate': 4.8593220338983055e-05, 'epoch': 0.04}
  4%|â–         | 266/6000 [15:38<5:34:00,  3.49s/it]  4%|â–         | 267/6000 [15:42<5:29:30,  3.45s/it]                                                    {'loss': 0.0552, 'grad_norm': 5.282975196838379, 'learning_rate': 4.858474576271187e-05, 'epoch': 0.04}
  4%|â–         | 267/6000 [15:42<5:29:30,  3.45s/it]  4%|â–         | 268/6000 [15:45<5:29:25,  3.45s/it]                                                    {'loss': 0.0882, 'grad_norm': 11.34980583190918, 'learning_rate': 4.857627118644068e-05, 'epoch': 0.04}
  4%|â–         | 268/6000 [15:45<5:29:25,  3.45s/it]  4%|â–         | 269/6000 [15:49<5:33:15,  3.49s/it]                                                    {'loss': 0.0151, 'grad_norm': 2.2189102172851562, 'learning_rate': 4.856779661016949e-05, 'epoch': 0.04}
  4%|â–         | 269/6000 [15:49<5:33:15,  3.49s/it]  4%|â–         | 270/6000 [15:52<5:31:04,  3.47s/it]                                                    {'loss': 0.0368, 'grad_norm': 4.284501552581787, 'learning_rate': 4.855932203389831e-05, 'epoch': 0.04}
  4%|â–         | 270/6000 [15:52<5:31:04,  3.47s/it]  5%|â–         | 271/6000 [15:56<5:29:24,  3.45s/it]                                                    {'loss': 0.0046, 'grad_norm': 0.5551114678382874, 'learning_rate': 4.855084745762712e-05, 'epoch': 0.05}
  5%|â–         | 271/6000 [15:56<5:29:24,  3.45s/it]  5%|â–         | 272/6000 [15:59<5:26:58,  3.42s/it]                                                    {'loss': 0.0617, 'grad_norm': 7.313388347625732, 'learning_rate': 4.8542372881355937e-05, 'epoch': 0.05}
  5%|â–         | 272/6000 [15:59<5:26:58,  3.42s/it]  5%|â–         | 273/6000 [16:02<5:26:35,  3.42s/it]                                                    {'loss': 0.0087, 'grad_norm': 2.047718048095703, 'learning_rate': 4.853389830508475e-05, 'epoch': 0.05}
  5%|â–         | 273/6000 [16:02<5:26:35,  3.42s/it]  5%|â–         | 274/6000 [16:06<5:37:21,  3.53s/it]                                                    {'loss': 0.038, 'grad_norm': 3.997054100036621, 'learning_rate': 4.8525423728813566e-05, 'epoch': 0.05}
  5%|â–         | 274/6000 [16:06<5:37:21,  3.53s/it]  5%|â–         | 275/6000 [16:10<5:34:23,  3.50s/it]                                                    {'loss': 0.0993, 'grad_norm': 13.07939624786377, 'learning_rate': 4.851694915254237e-05, 'epoch': 0.05}
  5%|â–         | 275/6000 [16:10<5:34:23,  3.50s/it]  5%|â–         | 276/6000 [16:13<5:34:57,  3.51s/it]                                                    {'loss': 0.1318, 'grad_norm': 7.435197353363037, 'learning_rate': 4.850847457627119e-05, 'epoch': 0.05}
  5%|â–         | 276/6000 [16:13<5:34:57,  3.51s/it]  5%|â–         | 277/6000 [16:16<5:30:32,  3.47s/it]                                                    {'loss': 0.1018, 'grad_norm': 9.18871021270752, 'learning_rate': 4.85e-05, 'epoch': 0.05}
  5%|â–         | 277/6000 [16:17<5:30:32,  3.47s/it]  5%|â–         | 278/6000 [16:20<5:28:43,  3.45s/it]                                                    {'loss': 0.0084, 'grad_norm': 1.2663781642913818, 'learning_rate': 4.849152542372882e-05, 'epoch': 0.05}
  5%|â–         | 278/6000 [16:20<5:28:43,  3.45s/it]  5%|â–         | 279/6000 [16:23<5:28:26,  3.44s/it]                                                    {'loss': 0.2938, 'grad_norm': 12.58176040649414, 'learning_rate': 4.848305084745763e-05, 'epoch': 0.05}
  5%|â–         | 279/6000 [16:23<5:28:26,  3.44s/it]  5%|â–         | 280/6000 [16:27<5:28:29,  3.45s/it]                                                    {'loss': 0.0585, 'grad_norm': 7.68130350112915, 'learning_rate': 4.847457627118645e-05, 'epoch': 0.05}
  5%|â–         | 280/6000 [16:27<5:28:29,  3.45s/it]  5%|â–         | 281/6000 [16:30<5:27:47,  3.44s/it]                                                    {'loss': 0.4072, 'grad_norm': 14.95888614654541, 'learning_rate': 4.846610169491526e-05, 'epoch': 0.05}
  5%|â–         | 281/6000 [16:30<5:27:47,  3.44s/it]  5%|â–         | 282/6000 [16:34<5:40:17,  3.57s/it]                                                    {'loss': 0.1395, 'grad_norm': 9.768156051635742, 'learning_rate': 4.845762711864407e-05, 'epoch': 0.05}
  5%|â–         | 282/6000 [16:34<5:40:17,  3.57s/it]  5%|â–         | 283/6000 [16:38<5:46:26,  3.64s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.24372568726539612, 'learning_rate': 4.844915254237288e-05, 'epoch': 0.05}
  5%|â–         | 283/6000 [16:38<5:46:26,  3.64s/it]  5%|â–         | 284/6000 [16:42<5:58:52,  3.77s/it]                                                    {'loss': 0.071, 'grad_norm': 8.76037883758545, 'learning_rate': 4.84406779661017e-05, 'epoch': 0.05}
  5%|â–         | 284/6000 [16:42<5:58:52,  3.77s/it]  5%|â–         | 285/6000 [16:46<5:55:19,  3.73s/it]                                                    {'loss': 0.1358, 'grad_norm': 11.29918384552002, 'learning_rate': 4.843220338983051e-05, 'epoch': 0.05}
  5%|â–         | 285/6000 [16:46<5:55:19,  3.73s/it]  5%|â–         | 286/6000 [16:49<5:44:45,  3.62s/it]                                                    {'loss': 0.0938, 'grad_norm': 10.91128921508789, 'learning_rate': 4.842372881355933e-05, 'epoch': 0.05}
  5%|â–         | 286/6000 [16:49<5:44:45,  3.62s/it]  5%|â–         | 287/6000 [16:52<5:40:34,  3.58s/it]                                                    {'loss': 0.1434, 'grad_norm': 10.308134078979492, 'learning_rate': 4.841525423728814e-05, 'epoch': 0.05}
  5%|â–         | 287/6000 [16:52<5:40:34,  3.58s/it]  5%|â–         | 288/6000 [16:56<5:35:12,  3.52s/it]                                                    {'loss': 0.0052, 'grad_norm': 1.192589282989502, 'learning_rate': 4.840677966101695e-05, 'epoch': 0.05}
  5%|â–         | 288/6000 [16:56<5:35:12,  3.52s/it]  5%|â–         | 289/6000 [16:59<5:36:38,  3.54s/it]                                                    {'loss': 0.2019, 'grad_norm': 12.51185131072998, 'learning_rate': 4.839830508474576e-05, 'epoch': 0.05}
  5%|â–         | 289/6000 [16:59<5:36:38,  3.54s/it]  5%|â–         | 290/6000 [17:03<5:33:53,  3.51s/it]                                                    {'loss': 0.0101, 'grad_norm': 1.7850620746612549, 'learning_rate': 4.8389830508474574e-05, 'epoch': 0.05}
  5%|â–         | 290/6000 [17:03<5:33:53,  3.51s/it]  5%|â–         | 291/6000 [17:06<5:29:40,  3.46s/it]                                                    {'loss': 0.1621, 'grad_norm': 11.232556343078613, 'learning_rate': 4.838135593220339e-05, 'epoch': 0.05}
  5%|â–         | 291/6000 [17:06<5:29:40,  3.46s/it]  5%|â–         | 292/6000 [17:10<5:26:30,  3.43s/it]                                                    {'loss': 0.1598, 'grad_norm': 12.927419662475586, 'learning_rate': 4.83728813559322e-05, 'epoch': 0.05}
  5%|â–         | 292/6000 [17:10<5:26:30,  3.43s/it]  5%|â–         | 293/6000 [17:13<5:25:50,  3.43s/it]                                                    {'loss': 0.053, 'grad_norm': 5.831978797912598, 'learning_rate': 4.836440677966102e-05, 'epoch': 0.05}
  5%|â–         | 293/6000 [17:13<5:25:50,  3.43s/it]  5%|â–         | 294/6000 [17:16<5:25:15,  3.42s/it]                                                    {'loss': 0.4664, 'grad_norm': 21.67964744567871, 'learning_rate': 4.835593220338983e-05, 'epoch': 0.05}
  5%|â–         | 294/6000 [17:16<5:25:15,  3.42s/it]  5%|â–         | 295/6000 [17:20<5:22:59,  3.40s/it]                                                    {'loss': 0.1203, 'grad_norm': 7.7709527015686035, 'learning_rate': 4.834745762711865e-05, 'epoch': 0.05}
  5%|â–         | 295/6000 [17:20<5:22:59,  3.40s/it]  5%|â–         | 296/6000 [17:23<5:29:59,  3.47s/it]                                                    {'loss': 0.1588, 'grad_norm': 13.784862518310547, 'learning_rate': 4.833898305084746e-05, 'epoch': 0.05}
  5%|â–         | 296/6000 [17:23<5:29:59,  3.47s/it]  5%|â–         | 297/6000 [17:27<5:29:29,  3.47s/it]                                                    {'loss': 0.0227, 'grad_norm': 2.3632848262786865, 'learning_rate': 4.833050847457627e-05, 'epoch': 0.05}
  5%|â–         | 297/6000 [17:27<5:29:29,  3.47s/it]  5%|â–         | 298/6000 [17:30<5:33:18,  3.51s/it]                                                    {'loss': 0.0599, 'grad_norm': 3.7455697059631348, 'learning_rate': 4.8322033898305084e-05, 'epoch': 0.05}
  5%|â–         | 298/6000 [17:30<5:33:18,  3.51s/it]  5%|â–         | 299/6000 [17:35<5:56:50,  3.76s/it]                                                    {'loss': 0.0535, 'grad_norm': 5.4173264503479, 'learning_rate': 4.83135593220339e-05, 'epoch': 0.05}
  5%|â–         | 299/6000 [17:35<5:56:50,  3.76s/it]  5%|â–Œ         | 300/6000 [17:38<5:47:57,  3.66s/it]                                                    {'loss': 0.0223, 'grad_norm': 4.482462406158447, 'learning_rate': 4.8305084745762714e-05, 'epoch': 0.05}
  5%|â–Œ         | 300/6000 [17:38<5:47:57,  3.66s/it][2025-10-20 15:47:25,180] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  5%|â–Œ         | 301/6000 [17:44<6:53:15,  4.35s/it]                                                    {'loss': 0.088, 'grad_norm': 9.467418670654297, 'learning_rate': 4.829661016949153e-05, 'epoch': 0.05}
  5%|â–Œ         | 301/6000 [17:44<6:53:15,  4.35s/it]  5%|â–Œ         | 302/6000 [17:48<6:26:55,  4.07s/it]                                                    {'loss': 0.0889, 'grad_norm': 12.887701988220215, 'learning_rate': 4.828813559322034e-05, 'epoch': 0.05}
  5%|â–Œ         | 302/6000 [17:48<6:26:55,  4.07s/it]  5%|â–Œ         | 303/6000 [17:51<6:08:37,  3.88s/it]                                                    {'loss': 0.0502, 'grad_norm': 7.574833393096924, 'learning_rate': 4.8279661016949154e-05, 'epoch': 0.05}
  5%|â–Œ         | 303/6000 [17:51<6:08:37,  3.88s/it]  5%|â–Œ         | 304/6000 [17:55<5:57:43,  3.77s/it]                                                    {'loss': 0.1151, 'grad_norm': 10.311033248901367, 'learning_rate': 4.8271186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 304/6000 [17:55<5:57:43,  3.77s/it]  5%|â–Œ         | 305/6000 [17:58<5:45:06,  3.64s/it]                                                    {'loss': 0.21, 'grad_norm': 14.76954174041748, 'learning_rate': 4.8262711864406784e-05, 'epoch': 0.05}
  5%|â–Œ         | 305/6000 [17:58<5:45:06,  3.64s/it]  5%|â–Œ         | 306/6000 [18:01<5:36:44,  3.55s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.33347317576408386, 'learning_rate': 4.8254237288135595e-05, 'epoch': 0.05}
  5%|â–Œ         | 306/6000 [18:01<5:36:44,  3.55s/it]  5%|â–Œ         | 307/6000 [18:05<5:31:43,  3.50s/it]                                                    {'loss': 0.0161, 'grad_norm': 3.166158676147461, 'learning_rate': 4.824576271186441e-05, 'epoch': 0.05}
  5%|â–Œ         | 307/6000 [18:05<5:31:43,  3.50s/it]  5%|â–Œ         | 308/6000 [18:08<5:30:21,  3.48s/it]                                                    {'loss': 0.0581, 'grad_norm': 3.7031805515289307, 'learning_rate': 4.8237288135593224e-05, 'epoch': 0.05}
  5%|â–Œ         | 308/6000 [18:08<5:30:21,  3.48s/it]  5%|â–Œ         | 309/6000 [18:12<5:32:44,  3.51s/it]                                                    {'loss': 0.1503, 'grad_norm': 11.861114501953125, 'learning_rate': 4.8228813559322036e-05, 'epoch': 0.05}
  5%|â–Œ         | 309/6000 [18:12<5:32:44,  3.51s/it]  5%|â–Œ         | 310/6000 [18:15<5:28:49,  3.47s/it]                                                    {'loss': 0.0138, 'grad_norm': 2.0775721073150635, 'learning_rate': 4.822033898305085e-05, 'epoch': 0.05}
  5%|â–Œ         | 310/6000 [18:15<5:28:49,  3.47s/it]  5%|â–Œ         | 311/6000 [18:18<5:25:41,  3.43s/it]                                                    {'loss': 0.1028, 'grad_norm': 6.545821666717529, 'learning_rate': 4.821186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 311/6000 [18:18<5:25:41,  3.43s/it]  5%|â–Œ         | 312/6000 [18:22<5:24:34,  3.42s/it]                                                    {'loss': 0.2174, 'grad_norm': 11.519556999206543, 'learning_rate': 4.8203389830508476e-05, 'epoch': 0.05}
  5%|â–Œ         | 312/6000 [18:22<5:24:34,  3.42s/it]  5%|â–Œ         | 313/6000 [18:25<5:25:05,  3.43s/it]                                                    {'loss': 0.1043, 'grad_norm': 7.126884937286377, 'learning_rate': 4.819491525423729e-05, 'epoch': 0.05}
  5%|â–Œ         | 313/6000 [18:25<5:25:05,  3.43s/it]  5%|â–Œ         | 314/6000 [18:29<5:24:23,  3.42s/it]                                                    {'loss': 0.0692, 'grad_norm': 3.925898551940918, 'learning_rate': 4.8186440677966105e-05, 'epoch': 0.05}
  5%|â–Œ         | 314/6000 [18:29<5:24:23,  3.42s/it]  5%|â–Œ         | 315/6000 [18:32<5:21:55,  3.40s/it]                                                    {'loss': 0.0504, 'grad_norm': 2.8125274181365967, 'learning_rate': 4.817796610169492e-05, 'epoch': 0.05}
  5%|â–Œ         | 315/6000 [18:32<5:21:55,  3.40s/it]  5%|â–Œ         | 316/6000 [18:35<5:20:48,  3.39s/it]                                                    {'loss': 0.0133, 'grad_norm': 2.435117721557617, 'learning_rate': 4.8169491525423735e-05, 'epoch': 0.05}
  5%|â–Œ         | 316/6000 [18:35<5:20:48,  3.39s/it]  5%|â–Œ         | 317/6000 [18:39<5:27:39,  3.46s/it]                                                    {'loss': 0.0779, 'grad_norm': 9.940089225769043, 'learning_rate': 4.8161016949152546e-05, 'epoch': 0.05}
  5%|â–Œ         | 317/6000 [18:39<5:27:39,  3.46s/it]  5%|â–Œ         | 318/6000 [18:43<5:34:26,  3.53s/it]                                                    {'loss': 0.0079, 'grad_norm': 0.8743554353713989, 'learning_rate': 4.815254237288136e-05, 'epoch': 0.05}
  5%|â–Œ         | 318/6000 [18:43<5:34:26,  3.53s/it]  5%|â–Œ         | 319/6000 [18:46<5:30:43,  3.49s/it]                                                    {'loss': 0.5194, 'grad_norm': 17.387035369873047, 'learning_rate': 4.814406779661017e-05, 'epoch': 0.05}
  5%|â–Œ         | 319/6000 [18:46<5:30:43,  3.49s/it]  5%|â–Œ         | 320/6000 [18:49<5:30:56,  3.50s/it]                                                    {'loss': 0.1327, 'grad_norm': 12.245253562927246, 'learning_rate': 4.813559322033899e-05, 'epoch': 0.05}
  5%|â–Œ         | 320/6000 [18:50<5:30:56,  3.50s/it]  5%|â–Œ         | 321/6000 [18:53<5:41:53,  3.61s/it]                                                    {'loss': 0.0252, 'grad_norm': 4.400452136993408, 'learning_rate': 4.81271186440678e-05, 'epoch': 0.05}
  5%|â–Œ         | 321/6000 [18:53<5:41:53,  3.61s/it]  5%|â–Œ         | 322/6000 [18:57<5:35:12,  3.54s/it]                                                    {'loss': 0.0799, 'grad_norm': 8.38450813293457, 'learning_rate': 4.8118644067796616e-05, 'epoch': 0.05}
  5%|â–Œ         | 322/6000 [18:57<5:35:12,  3.54s/it]  5%|â–Œ         | 323/6000 [19:01<5:49:13,  3.69s/it]                                                    {'loss': 0.0627, 'grad_norm': 7.4147233963012695, 'learning_rate': 4.811016949152543e-05, 'epoch': 0.05}
  5%|â–Œ         | 323/6000 [19:01<5:49:13,  3.69s/it]  5%|â–Œ         | 324/6000 [19:04<5:39:45,  3.59s/it]                                                    {'loss': 0.1583, 'grad_norm': 10.594513893127441, 'learning_rate': 4.810169491525424e-05, 'epoch': 0.05}
  5%|â–Œ         | 324/6000 [19:04<5:39:45,  3.59s/it]  5%|â–Œ         | 325/6000 [19:08<5:33:41,  3.53s/it]                                                    {'loss': 0.0685, 'grad_norm': 8.640475273132324, 'learning_rate': 4.809322033898305e-05, 'epoch': 0.05}
  5%|â–Œ         | 325/6000 [19:08<5:33:41,  3.53s/it]  5%|â–Œ         | 326/6000 [19:11<5:28:19,  3.47s/it]                                                    {'loss': 0.1565, 'grad_norm': 18.278602600097656, 'learning_rate': 4.808474576271187e-05, 'epoch': 0.05}
  5%|â–Œ         | 326/6000 [19:11<5:28:19,  3.47s/it]  5%|â–Œ         | 327/6000 [19:14<5:24:04,  3.43s/it]                                                    {'loss': 0.0689, 'grad_norm': 5.726800441741943, 'learning_rate': 4.807627118644068e-05, 'epoch': 0.05}
  5%|â–Œ         | 327/6000 [19:14<5:24:04,  3.43s/it]  5%|â–Œ         | 328/6000 [19:18<5:24:28,  3.43s/it]                                                    {'loss': 0.0048, 'grad_norm': 1.0707334280014038, 'learning_rate': 4.80677966101695e-05, 'epoch': 0.05}
  5%|â–Œ         | 328/6000 [19:18<5:24:28,  3.43s/it]  5%|â–Œ         | 329/6000 [19:21<5:23:28,  3.42s/it]                                                    {'loss': 0.1083, 'grad_norm': 12.219998359680176, 'learning_rate': 4.805932203389831e-05, 'epoch': 0.05}
  5%|â–Œ         | 329/6000 [19:21<5:23:28,  3.42s/it]  6%|â–Œ         | 330/6000 [19:24<5:23:46,  3.43s/it]                                                    {'loss': 0.0285, 'grad_norm': 3.290152072906494, 'learning_rate': 4.805084745762712e-05, 'epoch': 0.06}
  6%|â–Œ         | 330/6000 [19:24<5:23:46,  3.43s/it]  6%|â–Œ         | 331/6000 [19:28<5:23:37,  3.43s/it]                                                    {'loss': 0.1366, 'grad_norm': 15.663968086242676, 'learning_rate': 4.804237288135594e-05, 'epoch': 0.06}
  6%|â–Œ         | 331/6000 [19:28<5:23:37,  3.43s/it]  6%|â–Œ         | 332/6000 [19:31<5:27:15,  3.46s/it]                                                    {'loss': 0.0541, 'grad_norm': 3.701744556427002, 'learning_rate': 4.803389830508474e-05, 'epoch': 0.06}
  6%|â–Œ         | 332/6000 [19:31<5:27:15,  3.46s/it]  6%|â–Œ         | 333/6000 [19:35<5:23:26,  3.42s/it]                                                    {'loss': 0.009, 'grad_norm': 2.0291640758514404, 'learning_rate': 4.802542372881356e-05, 'epoch': 0.06}
  6%|â–Œ         | 333/6000 [19:35<5:23:26,  3.42s/it]  6%|â–Œ         | 334/6000 [19:38<5:24:02,  3.43s/it]                                                    {'loss': 0.0252, 'grad_norm': 2.364452838897705, 'learning_rate': 4.801694915254237e-05, 'epoch': 0.06}
  6%|â–Œ         | 334/6000 [19:38<5:24:02,  3.43s/it]  6%|â–Œ         | 335/6000 [19:42<5:24:42,  3.44s/it]                                                    {'loss': 0.012, 'grad_norm': 1.7674355506896973, 'learning_rate': 4.800847457627119e-05, 'epoch': 0.06}
  6%|â–Œ         | 335/6000 [19:42<5:24:42,  3.44s/it]  6%|â–Œ         | 336/6000 [19:45<5:21:31,  3.41s/it]                                                    {'loss': 0.1076, 'grad_norm': 9.224323272705078, 'learning_rate': 4.8e-05, 'epoch': 0.06}
  6%|â–Œ         | 336/6000 [19:45<5:21:31,  3.41s/it]  6%|â–Œ         | 337/6000 [19:49<5:25:44,  3.45s/it]                                                    {'loss': 0.0182, 'grad_norm': 1.0222375392913818, 'learning_rate': 4.799152542372882e-05, 'epoch': 0.06}
  6%|â–Œ         | 337/6000 [19:49<5:25:44,  3.45s/it]  6%|â–Œ         | 338/6000 [19:52<5:22:45,  3.42s/it]                                                    {'loss': 0.0738, 'grad_norm': 4.559621810913086, 'learning_rate': 4.798305084745763e-05, 'epoch': 0.06}
  6%|â–Œ         | 338/6000 [19:52<5:22:45,  3.42s/it]  6%|â–Œ         | 339/6000 [19:55<5:22:29,  3.42s/it]                                                    {'loss': 0.0078, 'grad_norm': 1.8863775730133057, 'learning_rate': 4.797457627118644e-05, 'epoch': 0.06}
  6%|â–Œ         | 339/6000 [19:55<5:22:29,  3.42s/it]  6%|â–Œ         | 340/6000 [19:59<5:29:44,  3.50s/it]                                                    {'loss': 0.0558, 'grad_norm': 6.047287464141846, 'learning_rate': 4.796610169491525e-05, 'epoch': 0.06}
  6%|â–Œ         | 340/6000 [19:59<5:29:44,  3.50s/it]  6%|â–Œ         | 341/6000 [20:02<5:25:20,  3.45s/it]                                                    {'loss': 0.0204, 'grad_norm': 4.078092098236084, 'learning_rate': 4.795762711864407e-05, 'epoch': 0.06}
  6%|â–Œ         | 341/6000 [20:02<5:25:20,  3.45s/it]  6%|â–Œ         | 342/6000 [20:06<5:23:39,  3.43s/it]                                                    {'loss': 0.293, 'grad_norm': 11.852926254272461, 'learning_rate': 4.794915254237288e-05, 'epoch': 0.06}
  6%|â–Œ         | 342/6000 [20:06<5:23:39,  3.43s/it]  6%|â–Œ         | 343/6000 [20:10<5:42:51,  3.64s/it]                                                    {'loss': 0.0451, 'grad_norm': 8.077245712280273, 'learning_rate': 4.79406779661017e-05, 'epoch': 0.06}
  6%|â–Œ         | 343/6000 [20:10<5:42:51,  3.64s/it]  6%|â–Œ         | 344/6000 [20:13<5:36:30,  3.57s/it]                                                    {'loss': 0.0513, 'grad_norm': 5.693458080291748, 'learning_rate': 4.793220338983051e-05, 'epoch': 0.06}
  6%|â–Œ         | 344/6000 [20:13<5:36:30,  3.57s/it]  6%|â–Œ         | 345/6000 [20:17<5:30:44,  3.51s/it]                                                    {'loss': 0.2079, 'grad_norm': 15.999927520751953, 'learning_rate': 4.792372881355933e-05, 'epoch': 0.06}
  6%|â–Œ         | 345/6000 [20:17<5:30:44,  3.51s/it]  6%|â–Œ         | 346/6000 [20:20<5:30:30,  3.51s/it]                                                    {'loss': 0.0657, 'grad_norm': 5.825066089630127, 'learning_rate': 4.7915254237288134e-05, 'epoch': 0.06}
  6%|â–Œ         | 346/6000 [20:20<5:30:30,  3.51s/it]  6%|â–Œ         | 347/6000 [20:23<5:24:45,  3.45s/it]                                                    {'loss': 0.0217, 'grad_norm': 3.981584310531616, 'learning_rate': 4.790677966101695e-05, 'epoch': 0.06}
  6%|â–Œ         | 347/6000 [20:23<5:24:45,  3.45s/it]  6%|â–Œ         | 348/6000 [20:27<5:26:21,  3.46s/it]                                                    {'loss': 0.1025, 'grad_norm': 9.179316520690918, 'learning_rate': 4.7898305084745764e-05, 'epoch': 0.06}
  6%|â–Œ         | 348/6000 [20:27<5:26:21,  3.46s/it]  6%|â–Œ         | 349/6000 [20:30<5:25:40,  3.46s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.8201784491539001, 'learning_rate': 4.788983050847458e-05, 'epoch': 0.06}
  6%|â–Œ         | 349/6000 [20:30<5:25:40,  3.46s/it]  6%|â–Œ         | 350/6000 [20:34<5:25:02,  3.45s/it]                                                    {'loss': 0.1492, 'grad_norm': 9.552885055541992, 'learning_rate': 4.788135593220339e-05, 'epoch': 0.06}
  6%|â–Œ         | 350/6000 [20:34<5:25:02,  3.45s/it][2025-10-20 15:50:20,828] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  6%|â–Œ         | 351/6000 [20:40<6:35:03,  4.20s/it]                                                    {'loss': 0.0967, 'grad_norm': 9.375947952270508, 'learning_rate': 4.7872881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 351/6000 [20:40<6:35:03,  4.20s/it]  6%|â–Œ         | 352/6000 [20:43<6:10:54,  3.94s/it]                                                    {'loss': 0.0943, 'grad_norm': 9.101288795471191, 'learning_rate': 4.786440677966102e-05, 'epoch': 0.06}
  6%|â–Œ         | 352/6000 [20:43<6:10:54,  3.94s/it]  6%|â–Œ         | 353/6000 [20:46<5:53:25,  3.76s/it]                                                    {'loss': 0.059, 'grad_norm': 4.591945171356201, 'learning_rate': 4.7855932203389834e-05, 'epoch': 0.06}
  6%|â–Œ         | 353/6000 [20:46<5:53:25,  3.76s/it]  6%|â–Œ         | 354/6000 [20:50<5:42:14,  3.64s/it]                                                    {'loss': 0.0217, 'grad_norm': 2.4965569972991943, 'learning_rate': 4.7847457627118645e-05, 'epoch': 0.06}
  6%|â–Œ         | 354/6000 [20:50<5:42:14,  3.64s/it]  6%|â–Œ         | 355/6000 [20:53<5:34:19,  3.55s/it]                                                    {'loss': 0.0101, 'grad_norm': 2.209383249282837, 'learning_rate': 4.7838983050847456e-05, 'epoch': 0.06}
  6%|â–Œ         | 355/6000 [20:53<5:34:19,  3.55s/it]  6%|â–Œ         | 356/6000 [20:57<5:36:50,  3.58s/it]                                                    {'loss': 0.1313, 'grad_norm': 17.50465965270996, 'learning_rate': 4.7830508474576274e-05, 'epoch': 0.06}
  6%|â–Œ         | 356/6000 [20:57<5:36:50,  3.58s/it]  6%|â–Œ         | 357/6000 [21:00<5:32:36,  3.54s/it]                                                    {'loss': 0.0747, 'grad_norm': 9.35706615447998, 'learning_rate': 4.7822033898305086e-05, 'epoch': 0.06}
  6%|â–Œ         | 357/6000 [21:00<5:32:36,  3.54s/it]  6%|â–Œ         | 358/6000 [21:04<5:25:30,  3.46s/it]                                                    {'loss': 0.0254, 'grad_norm': 3.0602049827575684, 'learning_rate': 4.7813559322033904e-05, 'epoch': 0.06}
  6%|â–Œ         | 358/6000 [21:04<5:25:30,  3.46s/it]  6%|â–Œ         | 359/6000 [21:07<5:24:20,  3.45s/it]                                                    {'loss': 0.0207, 'grad_norm': 3.5305728912353516, 'learning_rate': 4.7805084745762715e-05, 'epoch': 0.06}
  6%|â–Œ         | 359/6000 [21:07<5:24:20,  3.45s/it]  6%|â–Œ         | 360/6000 [21:10<5:21:35,  3.42s/it]                                                    {'loss': 0.2432, 'grad_norm': 12.419671058654785, 'learning_rate': 4.7796610169491526e-05, 'epoch': 0.06}
  6%|â–Œ         | 360/6000 [21:10<5:21:35,  3.42s/it]  6%|â–Œ         | 361/6000 [21:14<5:19:56,  3.40s/it]                                                    {'loss': 0.2914, 'grad_norm': 13.779435157775879, 'learning_rate': 4.778813559322034e-05, 'epoch': 0.06}
  6%|â–Œ         | 361/6000 [21:14<5:19:56,  3.40s/it]  6%|â–Œ         | 362/6000 [21:17<5:18:09,  3.39s/it]                                                    {'loss': 0.2504, 'grad_norm': 8.751189231872559, 'learning_rate': 4.7779661016949156e-05, 'epoch': 0.06}
  6%|â–Œ         | 362/6000 [21:17<5:18:09,  3.39s/it]  6%|â–Œ         | 363/6000 [21:20<5:17:25,  3.38s/it]                                                    {'loss': 0.0108, 'grad_norm': 1.1398425102233887, 'learning_rate': 4.777118644067797e-05, 'epoch': 0.06}
  6%|â–Œ         | 363/6000 [21:20<5:17:25,  3.38s/it]  6%|â–Œ         | 364/6000 [21:24<5:22:12,  3.43s/it]                                                    {'loss': 0.116, 'grad_norm': 11.17715072631836, 'learning_rate': 4.7762711864406785e-05, 'epoch': 0.06}
  6%|â–Œ         | 364/6000 [21:24<5:22:12,  3.43s/it]  6%|â–Œ         | 365/6000 [21:27<5:21:17,  3.42s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.287858247756958, 'learning_rate': 4.7754237288135596e-05, 'epoch': 0.06}
  6%|â–Œ         | 365/6000 [21:27<5:21:17,  3.42s/it]  6%|â–Œ         | 366/6000 [21:31<5:19:20,  3.40s/it]                                                    {'loss': 0.0143, 'grad_norm': 1.5618031024932861, 'learning_rate': 4.7745762711864414e-05, 'epoch': 0.06}
  6%|â–Œ         | 366/6000 [21:31<5:19:20,  3.40s/it]  6%|â–Œ         | 367/6000 [21:34<5:18:53,  3.40s/it]                                                    {'loss': 0.0142, 'grad_norm': 2.277329206466675, 'learning_rate': 4.773728813559322e-05, 'epoch': 0.06}
  6%|â–Œ         | 367/6000 [21:34<5:18:53,  3.40s/it]  6%|â–Œ         | 368/6000 [21:38<5:30:59,  3.53s/it]                                                    {'loss': 0.0935, 'grad_norm': 7.462841510772705, 'learning_rate': 4.772881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 368/6000 [21:38<5:30:59,  3.53s/it]  6%|â–Œ         | 369/6000 [21:41<5:25:11,  3.47s/it]                                                    {'loss': 0.0681, 'grad_norm': 5.322922229766846, 'learning_rate': 4.772033898305085e-05, 'epoch': 0.06}
  6%|â–Œ         | 369/6000 [21:41<5:25:11,  3.47s/it]  6%|â–Œ         | 370/6000 [21:45<5:24:26,  3.46s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.17048262059688568, 'learning_rate': 4.7711864406779666e-05, 'epoch': 0.06}
  6%|â–Œ         | 370/6000 [21:45<5:24:26,  3.46s/it]  6%|â–Œ         | 371/6000 [21:48<5:21:27,  3.43s/it]                                                    {'loss': 0.0181, 'grad_norm': 2.3646340370178223, 'learning_rate': 4.770338983050848e-05, 'epoch': 0.06}
  6%|â–Œ         | 371/6000 [21:48<5:21:27,  3.43s/it]  6%|â–Œ         | 372/6000 [21:51<5:18:39,  3.40s/it]                                                    {'loss': 0.0042, 'grad_norm': 0.6795356869697571, 'learning_rate': 4.769491525423729e-05, 'epoch': 0.06}
  6%|â–Œ         | 372/6000 [21:51<5:18:39,  3.40s/it]  6%|â–Œ         | 373/6000 [21:55<5:17:55,  3.39s/it]                                                    {'loss': 0.002, 'grad_norm': 0.3395968973636627, 'learning_rate': 4.768644067796611e-05, 'epoch': 0.06}
  6%|â–Œ         | 373/6000 [21:55<5:17:55,  3.39s/it]  6%|â–Œ         | 374/6000 [21:58<5:18:34,  3.40s/it]                                                    {'loss': 0.4245, 'grad_norm': 17.346284866333008, 'learning_rate': 4.767796610169492e-05, 'epoch': 0.06}
  6%|â–Œ         | 374/6000 [21:58<5:18:34,  3.40s/it]  6%|â–‹         | 375/6000 [22:01<5:17:45,  3.39s/it]                                                    {'loss': 0.0402, 'grad_norm': 4.777357578277588, 'learning_rate': 4.766949152542373e-05, 'epoch': 0.06}
  6%|â–‹         | 375/6000 [22:01<5:17:45,  3.39s/it]  6%|â–‹         | 376/6000 [22:05<5:16:07,  3.37s/it]                                                    {'loss': 0.0278, 'grad_norm': 3.381000518798828, 'learning_rate': 4.766101694915254e-05, 'epoch': 0.06}
  6%|â–‹         | 376/6000 [22:05<5:16:07,  3.37s/it]  6%|â–‹         | 377/6000 [22:08<5:15:34,  3.37s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.5188694596290588, 'learning_rate': 4.765254237288136e-05, 'epoch': 0.06}
  6%|â–‹         | 377/6000 [22:08<5:15:34,  3.37s/it]  6%|â–‹         | 378/6000 [22:12<5:19:40,  3.41s/it]                                                    {'loss': 0.0787, 'grad_norm': 5.366199970245361, 'learning_rate': 4.764406779661017e-05, 'epoch': 0.06}
  6%|â–‹         | 378/6000 [22:12<5:19:40,  3.41s/it]  6%|â–‹         | 379/6000 [22:15<5:21:30,  3.43s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.45274490118026733, 'learning_rate': 4.763559322033899e-05, 'epoch': 0.06}
  6%|â–‹         | 379/6000 [22:15<5:21:30,  3.43s/it]  6%|â–‹         | 380/6000 [22:19<5:32:18,  3.55s/it]                                                    {'loss': 0.121, 'grad_norm': 9.640983581542969, 'learning_rate': 4.76271186440678e-05, 'epoch': 0.06}
  6%|â–‹         | 380/6000 [22:19<5:32:18,  3.55s/it]  6%|â–‹         | 381/6000 [22:23<5:37:07,  3.60s/it]                                                    {'loss': 0.0147, 'grad_norm': 1.952817440032959, 'learning_rate': 4.761864406779661e-05, 'epoch': 0.06}
  6%|â–‹         | 381/6000 [22:23<5:37:07,  3.60s/it]  6%|â–‹         | 382/6000 [22:26<5:31:03,  3.54s/it]                                                    {'loss': 0.0362, 'grad_norm': 6.024020195007324, 'learning_rate': 4.761016949152542e-05, 'epoch': 0.06}
  6%|â–‹         | 382/6000 [22:26<5:31:03,  3.54s/it]  6%|â–‹         | 383/6000 [22:30<5:27:59,  3.50s/it]                                                    {'loss': 0.0997, 'grad_norm': 8.640795707702637, 'learning_rate': 4.760169491525424e-05, 'epoch': 0.06}
  6%|â–‹         | 383/6000 [22:30<5:27:59,  3.50s/it]  6%|â–‹         | 384/6000 [22:33<5:27:26,  3.50s/it]                                                    {'loss': 0.0224, 'grad_norm': 3.611311912536621, 'learning_rate': 4.759322033898305e-05, 'epoch': 0.06}
  6%|â–‹         | 384/6000 [22:33<5:27:26,  3.50s/it]  6%|â–‹         | 385/6000 [22:37<5:35:07,  3.58s/it]                                                    {'loss': 0.007, 'grad_norm': 2.3185553550720215, 'learning_rate': 4.758474576271187e-05, 'epoch': 0.06}
  6%|â–‹         | 385/6000 [22:37<5:35:07,  3.58s/it]  6%|â–‹         | 386/6000 [22:40<5:32:27,  3.55s/it]                                                    {'loss': 0.0255, 'grad_norm': 5.2554240226745605, 'learning_rate': 4.757627118644068e-05, 'epoch': 0.06}
  6%|â–‹         | 386/6000 [22:40<5:32:27,  3.55s/it]  6%|â–‹         | 387/6000 [22:44<5:41:40,  3.65s/it]                                                    {'loss': 0.0141, 'grad_norm': 1.9663240909576416, 'learning_rate': 4.75677966101695e-05, 'epoch': 0.06}
  6%|â–‹         | 387/6000 [22:44<5:41:40,  3.65s/it]  6%|â–‹         | 388/6000 [22:48<5:39:35,  3.63s/it]                                                    {'loss': 0.0302, 'grad_norm': 4.493522644042969, 'learning_rate': 4.755932203389831e-05, 'epoch': 0.06}
  6%|â–‹         | 388/6000 [22:48<5:39:35,  3.63s/it]  6%|â–‹         | 389/6000 [22:51<5:31:10,  3.54s/it]                                                    {'loss': 0.0178, 'grad_norm': 2.852199077606201, 'learning_rate': 4.755084745762712e-05, 'epoch': 0.06}
  6%|â–‹         | 389/6000 [22:51<5:31:10,  3.54s/it]  6%|â–‹         | 390/6000 [22:55<5:28:58,  3.52s/it]                                                    {'loss': 0.0044, 'grad_norm': 0.5495786666870117, 'learning_rate': 4.754237288135593e-05, 'epoch': 0.07}
  6%|â–‹         | 390/6000 [22:55<5:28:58,  3.52s/it]  7%|â–‹         | 391/6000 [22:58<5:22:56,  3.45s/it]                                                    {'loss': 0.3967, 'grad_norm': 15.199315071105957, 'learning_rate': 4.7533898305084744e-05, 'epoch': 0.07}
  7%|â–‹         | 391/6000 [22:58<5:22:56,  3.45s/it]  7%|â–‹         | 392/6000 [23:01<5:24:43,  3.47s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.05870574712753296, 'learning_rate': 4.752542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 392/6000 [23:01<5:24:43,  3.47s/it]  7%|â–‹         | 393/6000 [23:05<5:24:50,  3.48s/it]                                                    {'loss': 0.0222, 'grad_norm': 3.7815401554107666, 'learning_rate': 4.751694915254237e-05, 'epoch': 0.07}
  7%|â–‹         | 393/6000 [23:05<5:24:50,  3.48s/it]  7%|â–‹         | 394/6000 [23:08<5:24:26,  3.47s/it]                                                    {'loss': 0.0544, 'grad_norm': 5.529382705688477, 'learning_rate': 4.750847457627119e-05, 'epoch': 0.07}
  7%|â–‹         | 394/6000 [23:08<5:24:26,  3.47s/it]  7%|â–‹         | 395/6000 [23:12<5:22:29,  3.45s/it]                                                    {'loss': 0.0137, 'grad_norm': 2.037128210067749, 'learning_rate': 4.75e-05, 'epoch': 0.07}
  7%|â–‹         | 395/6000 [23:12<5:22:29,  3.45s/it]  7%|â–‹         | 396/6000 [23:15<5:20:36,  3.43s/it]                                                    {'loss': 0.0289, 'grad_norm': 2.023798704147339, 'learning_rate': 4.7491525423728814e-05, 'epoch': 0.07}
  7%|â–‹         | 396/6000 [23:15<5:20:36,  3.43s/it]  7%|â–‹         | 397/6000 [23:19<5:34:39,  3.58s/it]                                                    {'loss': 0.0791, 'grad_norm': 2.675079584121704, 'learning_rate': 4.7483050847457625e-05, 'epoch': 0.07}
  7%|â–‹         | 397/6000 [23:19<5:34:39,  3.58s/it]  7%|â–‹         | 398/6000 [23:22<5:28:07,  3.51s/it]                                                    {'loss': 0.0708, 'grad_norm': 4.042320251464844, 'learning_rate': 4.747457627118644e-05, 'epoch': 0.07}
  7%|â–‹         | 398/6000 [23:22<5:28:07,  3.51s/it]  7%|â–‹         | 399/6000 [23:26<5:25:18,  3.48s/it]                                                    {'loss': 0.1, 'grad_norm': 7.833995342254639, 'learning_rate': 4.7466101694915255e-05, 'epoch': 0.07}
  7%|â–‹         | 399/6000 [23:26<5:25:18,  3.48s/it]  7%|â–‹         | 400/6000 [23:29<5:22:54,  3.46s/it]                                                    {'loss': 0.0053, 'grad_norm': 0.7111095786094666, 'learning_rate': 4.745762711864407e-05, 'epoch': 0.07}
  7%|â–‹         | 400/6000 [23:29<5:22:54,  3.46s/it][2025-10-20 15:53:16,200] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  7%|â–‹         | 401/6000 [23:35<6:19:39,  4.07s/it]                                                    {'loss': 0.0172, 'grad_norm': 1.244810700416565, 'learning_rate': 4.7449152542372884e-05, 'epoch': 0.07}
  7%|â–‹         | 401/6000 [23:35<6:19:39,  4.07s/it]  7%|â–‹         | 402/6000 [23:38<5:58:49,  3.85s/it]                                                    {'loss': 0.1137, 'grad_norm': 8.491856575012207, 'learning_rate': 4.74406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 402/6000 [23:38<5:58:49,  3.85s/it]  7%|â–‹         | 403/6000 [23:41<5:46:56,  3.72s/it]                                                    {'loss': 0.1367, 'grad_norm': 10.42720890045166, 'learning_rate': 4.7432203389830506e-05, 'epoch': 0.07}
  7%|â–‹         | 403/6000 [23:41<5:46:56,  3.72s/it]  7%|â–‹         | 404/6000 [23:45<5:42:21,  3.67s/it]                                                    {'loss': 0.2469, 'grad_norm': 11.594687461853027, 'learning_rate': 4.7423728813559325e-05, 'epoch': 0.07}
  7%|â–‹         | 404/6000 [23:45<5:42:21,  3.67s/it]  7%|â–‹         | 405/6000 [23:48<5:33:46,  3.58s/it]                                                    {'loss': 0.0192, 'grad_norm': 2.7956085205078125, 'learning_rate': 4.7415254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 405/6000 [23:48<5:33:46,  3.58s/it]  7%|â–‹         | 406/6000 [23:52<5:28:05,  3.52s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.04719718173146248, 'learning_rate': 4.7406779661016954e-05, 'epoch': 0.07}
  7%|â–‹         | 406/6000 [23:52<5:28:05,  3.52s/it]  7%|â–‹         | 407/6000 [23:55<5:24:36,  3.48s/it]                                                    {'loss': 0.0203, 'grad_norm': 3.157736301422119, 'learning_rate': 4.7398305084745765e-05, 'epoch': 0.07}
  7%|â–‹         | 407/6000 [23:55<5:24:36,  3.48s/it]  7%|â–‹         | 408/6000 [23:59<5:43:10,  3.68s/it]                                                    {'loss': 0.0851, 'grad_norm': 9.199111938476562, 'learning_rate': 4.738983050847458e-05, 'epoch': 0.07}
  7%|â–‹         | 408/6000 [23:59<5:43:10,  3.68s/it]  7%|â–‹         | 409/6000 [24:03<5:37:37,  3.62s/it]                                                    {'loss': 0.0572, 'grad_norm': 6.283699035644531, 'learning_rate': 4.7381355932203395e-05, 'epoch': 0.07}
  7%|â–‹         | 409/6000 [24:03<5:37:37,  3.62s/it]  7%|â–‹         | 410/6000 [24:06<5:30:35,  3.55s/it]                                                    {'loss': 0.1188, 'grad_norm': 9.186006546020508, 'learning_rate': 4.7372881355932206e-05, 'epoch': 0.07}
  7%|â–‹         | 410/6000 [24:06<5:30:35,  3.55s/it]  7%|â–‹         | 411/6000 [24:10<5:48:29,  3.74s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.42023932933807373, 'learning_rate': 4.736440677966102e-05, 'epoch': 0.07}
  7%|â–‹         | 411/6000 [24:10<5:48:29,  3.74s/it]  7%|â–‹         | 412/6000 [24:14<5:37:14,  3.62s/it]                                                    {'loss': 0.1323, 'grad_norm': 7.099143981933594, 'learning_rate': 4.735593220338983e-05, 'epoch': 0.07}
  7%|â–‹         | 412/6000 [24:14<5:37:14,  3.62s/it]  7%|â–‹         | 413/6000 [24:17<5:35:41,  3.61s/it]                                                    {'loss': 0.2485, 'grad_norm': 10.187793731689453, 'learning_rate': 4.7347457627118646e-05, 'epoch': 0.07}
  7%|â–‹         | 413/6000 [24:17<5:35:41,  3.61s/it]  7%|â–‹         | 414/6000 [24:21<5:28:00,  3.52s/it]                                                    {'loss': 0.0304, 'grad_norm': 4.2051472663879395, 'learning_rate': 4.733898305084746e-05, 'epoch': 0.07}
  7%|â–‹         | 414/6000 [24:21<5:28:00,  3.52s/it]  7%|â–‹         | 415/6000 [24:24<5:29:33,  3.54s/it]                                                    {'loss': 0.0623, 'grad_norm': 6.141145706176758, 'learning_rate': 4.7330508474576276e-05, 'epoch': 0.07}
  7%|â–‹         | 415/6000 [24:24<5:29:33,  3.54s/it]  7%|â–‹         | 416/6000 [24:28<5:33:50,  3.59s/it]                                                    {'loss': 0.0116, 'grad_norm': 2.6945078372955322, 'learning_rate': 4.732203389830509e-05, 'epoch': 0.07}
  7%|â–‹         | 416/6000 [24:28<5:33:50,  3.59s/it]  7%|â–‹         | 417/6000 [24:31<5:27:53,  3.52s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.12190370261669159, 'learning_rate': 4.73135593220339e-05, 'epoch': 0.07}
  7%|â–‹         | 417/6000 [24:31<5:27:53,  3.52s/it]  7%|â–‹         | 418/6000 [24:35<5:24:25,  3.49s/it]                                                    {'loss': 0.0354, 'grad_norm': 3.8543882369995117, 'learning_rate': 4.730508474576271e-05, 'epoch': 0.07}
  7%|â–‹         | 418/6000 [24:35<5:24:25,  3.49s/it]  7%|â–‹         | 419/6000 [24:39<5:36:44,  3.62s/it]                                                    {'loss': 0.0233, 'grad_norm': 2.915963649749756, 'learning_rate': 4.729661016949153e-05, 'epoch': 0.07}
  7%|â–‹         | 419/6000 [24:39<5:36:44,  3.62s/it]  7%|â–‹         | 420/6000 [24:42<5:32:46,  3.58s/it]                                                    {'loss': 0.0009, 'grad_norm': 0.11654756218194962, 'learning_rate': 4.728813559322034e-05, 'epoch': 0.07}
  7%|â–‹         | 420/6000 [24:42<5:32:46,  3.58s/it]  7%|â–‹         | 421/6000 [24:45<5:28:09,  3.53s/it]                                                    {'loss': 0.2885, 'grad_norm': 12.177342414855957, 'learning_rate': 4.727966101694916e-05, 'epoch': 0.07}
  7%|â–‹         | 421/6000 [24:45<5:28:09,  3.53s/it]  7%|â–‹         | 422/6000 [24:49<5:22:24,  3.47s/it]                                                    {'loss': 0.0986, 'grad_norm': 8.438261985778809, 'learning_rate': 4.727118644067797e-05, 'epoch': 0.07}
  7%|â–‹         | 422/6000 [24:49<5:22:24,  3.47s/it]  7%|â–‹         | 423/6000 [24:52<5:20:38,  3.45s/it]                                                    {'loss': 0.0406, 'grad_norm': 3.5205328464508057, 'learning_rate': 4.7262711864406786e-05, 'epoch': 0.07}
  7%|â–‹         | 423/6000 [24:52<5:20:38,  3.45s/it]  7%|â–‹         | 424/6000 [24:56<5:18:55,  3.43s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.4420565962791443, 'learning_rate': 4.72542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 424/6000 [24:56<5:18:55,  3.43s/it]  7%|â–‹         | 425/6000 [24:59<5:18:09,  3.42s/it]                                                    {'loss': 0.0429, 'grad_norm': 3.386246681213379, 'learning_rate': 4.724576271186441e-05, 'epoch': 0.07}
  7%|â–‹         | 425/6000 [24:59<5:18:09,  3.42s/it]  7%|â–‹         | 426/6000 [25:02<5:16:51,  3.41s/it]                                                    {'loss': 0.012, 'grad_norm': 1.323782205581665, 'learning_rate': 4.723728813559322e-05, 'epoch': 0.07}
  7%|â–‹         | 426/6000 [25:02<5:16:51,  3.41s/it]  7%|â–‹         | 427/6000 [25:06<5:18:18,  3.43s/it]                                                    {'loss': 0.1525, 'grad_norm': 7.391855716705322, 'learning_rate': 4.722881355932204e-05, 'epoch': 0.07}
  7%|â–‹         | 427/6000 [25:06<5:18:18,  3.43s/it]  7%|â–‹         | 428/6000 [25:09<5:17:55,  3.42s/it]                                                    {'loss': 0.0143, 'grad_norm': 2.168901205062866, 'learning_rate': 4.722033898305085e-05, 'epoch': 0.07}
  7%|â–‹         | 428/6000 [25:09<5:17:55,  3.42s/it]  7%|â–‹         | 429/6000 [25:13<5:16:47,  3.41s/it]                                                    {'loss': 0.0128, 'grad_norm': 1.3797284364700317, 'learning_rate': 4.721186440677967e-05, 'epoch': 0.07}
  7%|â–‹         | 429/6000 [25:13<5:16:47,  3.41s/it]  7%|â–‹         | 430/6000 [25:16<5:16:16,  3.41s/it]                                                    {'loss': 0.1239, 'grad_norm': 11.646254539489746, 'learning_rate': 4.720338983050848e-05, 'epoch': 0.07}
  7%|â–‹         | 430/6000 [25:16<5:16:16,  3.41s/it]  7%|â–‹         | 431/6000 [25:19<5:15:40,  3.40s/it]                                                    {'loss': 0.2303, 'grad_norm': 9.182058334350586, 'learning_rate': 4.719491525423729e-05, 'epoch': 0.07}
  7%|â–‹         | 431/6000 [25:19<5:15:40,  3.40s/it]  7%|â–‹         | 432/6000 [25:23<5:17:40,  3.42s/it]                                                    {'loss': 0.0934, 'grad_norm': 5.462840557098389, 'learning_rate': 4.71864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 432/6000 [25:23<5:17:40,  3.42s/it]  7%|â–‹         | 433/6000 [25:26<5:14:32,  3.39s/it]                                                    {'loss': 0.0187, 'grad_norm': 4.37355899810791, 'learning_rate': 4.717796610169491e-05, 'epoch': 0.07}
  7%|â–‹         | 433/6000 [25:26<5:14:32,  3.39s/it]  7%|â–‹         | 434/6000 [25:30<5:14:31,  3.39s/it]                                                    {'loss': 0.005, 'grad_norm': 0.6234023571014404, 'learning_rate': 4.716949152542373e-05, 'epoch': 0.07}
  7%|â–‹         | 434/6000 [25:30<5:14:31,  3.39s/it]  7%|â–‹         | 435/6000 [25:33<5:14:44,  3.39s/it]                                                    {'loss': 0.0102, 'grad_norm': 2.864511728286743, 'learning_rate': 4.716101694915254e-05, 'epoch': 0.07}
  7%|â–‹         | 435/6000 [25:33<5:14:44,  3.39s/it]  7%|â–‹         | 436/6000 [25:36<5:16:28,  3.41s/it]                                                    {'loss': 0.0153, 'grad_norm': 2.4340691566467285, 'learning_rate': 4.715254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 436/6000 [25:36<5:16:28,  3.41s/it]  7%|â–‹         | 437/6000 [25:40<5:17:15,  3.42s/it]                                                    {'loss': 0.0871, 'grad_norm': 6.821569919586182, 'learning_rate': 4.714406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 437/6000 [25:40<5:17:15,  3.42s/it]  7%|â–‹         | 438/6000 [25:43<5:20:35,  3.46s/it]                                                    {'loss': 0.0246, 'grad_norm': 2.069733142852783, 'learning_rate': 4.713559322033898e-05, 'epoch': 0.07}
  7%|â–‹         | 438/6000 [25:43<5:20:35,  3.46s/it]  7%|â–‹         | 439/6000 [25:47<5:18:02,  3.43s/it]                                                    {'loss': 0.0299, 'grad_norm': 3.849435329437256, 'learning_rate': 4.7127118644067794e-05, 'epoch': 0.07}
  7%|â–‹         | 439/6000 [25:47<5:18:02,  3.43s/it]  7%|â–‹         | 440/6000 [25:50<5:19:04,  3.44s/it]                                                    {'loss': 0.0064, 'grad_norm': 0.909173846244812, 'learning_rate': 4.711864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 440/6000 [25:50<5:19:04,  3.44s/it]  7%|â–‹         | 441/6000 [25:54<5:24:52,  3.51s/it]                                                    {'loss': 0.0086, 'grad_norm': 1.5801852941513062, 'learning_rate': 4.7110169491525423e-05, 'epoch': 0.07}
  7%|â–‹         | 441/6000 [25:54<5:24:52,  3.51s/it]  7%|â–‹         | 442/6000 [25:58<5:30:33,  3.57s/it]                                                    {'loss': 0.0203, 'grad_norm': 3.631650924682617, 'learning_rate': 4.710169491525424e-05, 'epoch': 0.07}
  7%|â–‹         | 442/6000 [25:58<5:30:33,  3.57s/it]  7%|â–‹         | 443/6000 [26:01<5:26:44,  3.53s/it]                                                    {'loss': 0.0061, 'grad_norm': 1.0231332778930664, 'learning_rate': 4.709322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 443/6000 [26:01<5:26:44,  3.53s/it]  7%|â–‹         | 444/6000 [26:04<5:22:23,  3.48s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.6181948184967041, 'learning_rate': 4.708474576271187e-05, 'epoch': 0.07}
  7%|â–‹         | 444/6000 [26:04<5:22:23,  3.48s/it]  7%|â–‹         | 445/6000 [26:08<5:22:36,  3.48s/it]                                                    {'loss': 0.0898, 'grad_norm': 8.71372127532959, 'learning_rate': 4.707627118644068e-05, 'epoch': 0.07}
  7%|â–‹         | 445/6000 [26:08<5:22:36,  3.48s/it]  7%|â–‹         | 446/6000 [26:11<5:19:19,  3.45s/it]                                                    {'loss': 0.0446, 'grad_norm': 6.814301013946533, 'learning_rate': 4.7067796610169493e-05, 'epoch': 0.07}
  7%|â–‹         | 446/6000 [26:11<5:19:19,  3.45s/it]  7%|â–‹         | 447/6000 [26:15<5:19:18,  3.45s/it]                                                    {'loss': 0.1406, 'grad_norm': 10.37849235534668, 'learning_rate': 4.7059322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 447/6000 [26:15<5:19:18,  3.45s/it]  7%|â–‹         | 448/6000 [26:18<5:16:13,  3.42s/it]                                                    {'loss': 0.0056, 'grad_norm': 0.9246364831924438, 'learning_rate': 4.705084745762712e-05, 'epoch': 0.07}
  7%|â–‹         | 448/6000 [26:18<5:16:13,  3.42s/it]  7%|â–‹         | 449/6000 [26:22<5:16:49,  3.42s/it]                                                    {'loss': 0.0517, 'grad_norm': 6.715259075164795, 'learning_rate': 4.7042372881355934e-05, 'epoch': 0.07}
  7%|â–‹         | 449/6000 [26:22<5:16:49,  3.42s/it]  8%|â–Š         | 450/6000 [26:25<5:18:32,  3.44s/it]                                                    {'loss': 0.0465, 'grad_norm': 5.696375370025635, 'learning_rate': 4.703389830508475e-05, 'epoch': 0.07}
  8%|â–Š         | 450/6000 [26:25<5:18:32,  3.44s/it][2025-10-20 15:56:12,026] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 451/6000 [26:31<6:19:38,  4.10s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.2695588767528534, 'learning_rate': 4.702542372881356e-05, 'epoch': 0.08}
  8%|â–Š         | 451/6000 [26:31<6:19:38,  4.10s/it]  8%|â–Š         | 452/6000 [26:34<6:09:01,  3.99s/it]                                                    {'loss': 0.132, 'grad_norm': 3.8134753704071045, 'learning_rate': 4.7016949152542375e-05, 'epoch': 0.08}
  8%|â–Š         | 452/6000 [26:34<6:09:01,  3.99s/it]  8%|â–Š         | 453/6000 [26:38<5:50:16,  3.79s/it]                                                    {'loss': 0.1451, 'grad_norm': 10.402871131896973, 'learning_rate': 4.7008474576271186e-05, 'epoch': 0.08}
  8%|â–Š         | 453/6000 [26:38<5:50:16,  3.79s/it]  8%|â–Š         | 454/6000 [26:41<5:46:16,  3.75s/it]                                                    {'loss': 0.0946, 'grad_norm': 7.8995466232299805, 'learning_rate': 4.7e-05, 'epoch': 0.08}
  8%|â–Š         | 454/6000 [26:41<5:46:16,  3.75s/it]  8%|â–Š         | 455/6000 [26:45<5:33:40,  3.61s/it]                                                    {'loss': 0.0092, 'grad_norm': 1.0216493606567383, 'learning_rate': 4.6991525423728815e-05, 'epoch': 0.08}
  8%|â–Š         | 455/6000 [26:45<5:33:40,  3.61s/it]  8%|â–Š         | 456/6000 [26:48<5:28:03,  3.55s/it]                                                    {'loss': 0.3204, 'grad_norm': 13.42591667175293, 'learning_rate': 4.6983050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 456/6000 [26:48<5:28:03,  3.55s/it]  8%|â–Š         | 457/6000 [26:51<5:21:33,  3.48s/it]                                                    {'loss': 0.0638, 'grad_norm': 7.269100189208984, 'learning_rate': 4.6974576271186445e-05, 'epoch': 0.08}
  8%|â–Š         | 457/6000 [26:51<5:21:33,  3.48s/it]  8%|â–Š         | 458/6000 [26:55<5:17:50,  3.44s/it]                                                    {'loss': 0.0301, 'grad_norm': 5.912436008453369, 'learning_rate': 4.6966101694915256e-05, 'epoch': 0.08}
  8%|â–Š         | 458/6000 [26:55<5:17:50,  3.44s/it]  8%|â–Š         | 459/6000 [26:58<5:16:44,  3.43s/it]                                                    {'loss': 0.2257, 'grad_norm': 9.427234649658203, 'learning_rate': 4.6957627118644074e-05, 'epoch': 0.08}
  8%|â–Š         | 459/6000 [26:58<5:16:44,  3.43s/it]  8%|â–Š         | 460/6000 [27:01<5:14:10,  3.40s/it]                                                    {'loss': 0.0299, 'grad_norm': 3.3883020877838135, 'learning_rate': 4.694915254237288e-05, 'epoch': 0.08}
  8%|â–Š         | 460/6000 [27:01<5:14:10,  3.40s/it]  8%|â–Š         | 461/6000 [27:05<5:13:17,  3.39s/it]                                                    {'loss': 0.0463, 'grad_norm': 4.839973449707031, 'learning_rate': 4.6940677966101697e-05, 'epoch': 0.08}
  8%|â–Š         | 461/6000 [27:05<5:13:17,  3.39s/it]  8%|â–Š         | 462/6000 [27:08<5:11:16,  3.37s/it]                                                    {'loss': 0.0601, 'grad_norm': 3.7057411670684814, 'learning_rate': 4.693220338983051e-05, 'epoch': 0.08}
  8%|â–Š         | 462/6000 [27:08<5:11:16,  3.37s/it]  8%|â–Š         | 463/6000 [27:12<5:12:15,  3.38s/it]                                                    {'loss': 0.095, 'grad_norm': 8.330615997314453, 'learning_rate': 4.6923728813559326e-05, 'epoch': 0.08}
  8%|â–Š         | 463/6000 [27:12<5:12:15,  3.38s/it]  8%|â–Š         | 464/6000 [27:15<5:10:54,  3.37s/it]                                                    {'loss': 0.226, 'grad_norm': 13.609366416931152, 'learning_rate': 4.691525423728814e-05, 'epoch': 0.08}
  8%|â–Š         | 464/6000 [27:15<5:10:54,  3.37s/it]  8%|â–Š         | 465/6000 [27:18<5:16:03,  3.43s/it]                                                    {'loss': 0.1417, 'grad_norm': 12.256858825683594, 'learning_rate': 4.6906779661016955e-05, 'epoch': 0.08}
  8%|â–Š         | 465/6000 [27:18<5:16:03,  3.43s/it]  8%|â–Š         | 466/6000 [27:22<5:14:01,  3.40s/it]                                                    {'loss': 0.0526, 'grad_norm': 5.446758270263672, 'learning_rate': 4.6898305084745767e-05, 'epoch': 0.08}
  8%|â–Š         | 466/6000 [27:22<5:14:01,  3.40s/it]  8%|â–Š         | 467/6000 [27:25<5:16:41,  3.43s/it]                                                    {'loss': 0.0882, 'grad_norm': 7.085406303405762, 'learning_rate': 4.688983050847458e-05, 'epoch': 0.08}
  8%|â–Š         | 467/6000 [27:25<5:16:41,  3.43s/it]  8%|â–Š         | 468/6000 [27:29<5:19:35,  3.47s/it]                                                    {'loss': 0.0879, 'grad_norm': 4.562289714813232, 'learning_rate': 4.688135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 468/6000 [27:29<5:19:35,  3.47s/it]  8%|â–Š         | 469/6000 [27:32<5:17:01,  3.44s/it]                                                    {'loss': 0.2089, 'grad_norm': 11.674177169799805, 'learning_rate': 4.687288135593221e-05, 'epoch': 0.08}
  8%|â–Š         | 469/6000 [27:32<5:17:01,  3.44s/it]  8%|â–Š         | 470/6000 [27:36<5:14:59,  3.42s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.1832808405160904, 'learning_rate': 4.686440677966102e-05, 'epoch': 0.08}
  8%|â–Š         | 470/6000 [27:36<5:14:59,  3.42s/it]  8%|â–Š         | 471/6000 [27:39<5:11:23,  3.38s/it]                                                    {'loss': 0.2737, 'grad_norm': 16.31180763244629, 'learning_rate': 4.6855932203389837e-05, 'epoch': 0.08}
  8%|â–Š         | 471/6000 [27:39<5:11:23,  3.38s/it]  8%|â–Š         | 472/6000 [27:42<5:10:52,  3.37s/it]                                                    {'loss': 0.2047, 'grad_norm': 8.816167831420898, 'learning_rate': 4.684745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 472/6000 [27:42<5:10:52,  3.37s/it]  8%|â–Š         | 473/6000 [27:46<5:12:01,  3.39s/it]                                                    {'loss': 0.1784, 'grad_norm': 10.309823989868164, 'learning_rate': 4.6838983050847466e-05, 'epoch': 0.08}
  8%|â–Š         | 473/6000 [27:46<5:12:01,  3.39s/it]  8%|â–Š         | 474/6000 [27:49<5:09:15,  3.36s/it]                                                    {'loss': 0.0181, 'grad_norm': 1.3047970533370972, 'learning_rate': 4.683050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 474/6000 [27:49<5:09:15,  3.36s/it]  8%|â–Š         | 475/6000 [27:52<5:10:44,  3.37s/it]                                                    {'loss': 0.1434, 'grad_norm': 5.426859378814697, 'learning_rate': 4.682203389830508e-05, 'epoch': 0.08}
  8%|â–Š         | 475/6000 [27:52<5:10:44,  3.37s/it]  8%|â–Š         | 476/6000 [27:56<5:12:19,  3.39s/it]                                                    {'loss': 0.0312, 'grad_norm': 5.020480155944824, 'learning_rate': 4.68135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 476/6000 [27:56<5:12:19,  3.39s/it]  8%|â–Š         | 477/6000 [27:59<5:11:45,  3.39s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.7844052314758301, 'learning_rate': 4.680508474576271e-05, 'epoch': 0.08}
  8%|â–Š         | 477/6000 [27:59<5:11:45,  3.39s/it]  8%|â–Š         | 478/6000 [28:03<5:12:16,  3.39s/it]                                                    {'loss': 0.0037, 'grad_norm': 0.7881474494934082, 'learning_rate': 4.679661016949153e-05, 'epoch': 0.08}
  8%|â–Š         | 478/6000 [28:03<5:12:16,  3.39s/it]  8%|â–Š         | 479/6000 [28:06<5:12:32,  3.40s/it]                                                    {'loss': 0.0851, 'grad_norm': 11.268744468688965, 'learning_rate': 4.678813559322034e-05, 'epoch': 0.08}
  8%|â–Š         | 479/6000 [28:06<5:12:32,  3.40s/it]  8%|â–Š         | 480/6000 [28:09<5:12:18,  3.39s/it]                                                    {'loss': 0.0201, 'grad_norm': 2.445828437805176, 'learning_rate': 4.677966101694916e-05, 'epoch': 0.08}
  8%|â–Š         | 480/6000 [28:09<5:12:18,  3.39s/it]  8%|â–Š         | 481/6000 [28:13<5:19:04,  3.47s/it]                                                    {'loss': 0.014, 'grad_norm': 2.5244762897491455, 'learning_rate': 4.677118644067797e-05, 'epoch': 0.08}
  8%|â–Š         | 481/6000 [28:13<5:19:04,  3.47s/it]  8%|â–Š         | 482/6000 [28:16<5:17:57,  3.46s/it]                                                    {'loss': 0.0166, 'grad_norm': 2.6073970794677734, 'learning_rate': 4.676271186440678e-05, 'epoch': 0.08}
  8%|â–Š         | 482/6000 [28:16<5:17:57,  3.46s/it]  8%|â–Š         | 483/6000 [28:20<5:16:36,  3.44s/it]                                                    {'loss': 0.0764, 'grad_norm': 5.5248494148254395, 'learning_rate': 4.675423728813559e-05, 'epoch': 0.08}
  8%|â–Š         | 483/6000 [28:20<5:16:36,  3.44s/it]  8%|â–Š         | 484/6000 [28:23<5:20:30,  3.49s/it]                                                    {'loss': 0.0024, 'grad_norm': 0.44462859630584717, 'learning_rate': 4.674576271186441e-05, 'epoch': 0.08}
  8%|â–Š         | 484/6000 [28:23<5:20:30,  3.49s/it]  8%|â–Š         | 485/6000 [28:27<5:32:02,  3.61s/it]                                                    {'loss': 0.0158, 'grad_norm': 2.4766435623168945, 'learning_rate': 4.673728813559322e-05, 'epoch': 0.08}
  8%|â–Š         | 485/6000 [28:27<5:32:02,  3.61s/it]  8%|â–Š         | 486/6000 [28:31<5:25:14,  3.54s/it]                                                    {'loss': 0.0011, 'grad_norm': 0.200003519654274, 'learning_rate': 4.672881355932204e-05, 'epoch': 0.08}
  8%|â–Š         | 486/6000 [28:31<5:25:14,  3.54s/it]  8%|â–Š         | 487/6000 [28:34<5:26:22,  3.55s/it]                                                    {'loss': 0.2593, 'grad_norm': 9.190932273864746, 'learning_rate': 4.672033898305085e-05, 'epoch': 0.08}
  8%|â–Š         | 487/6000 [28:34<5:26:22,  3.55s/it]  8%|â–Š         | 488/6000 [28:38<5:28:52,  3.58s/it]                                                    {'loss': 0.469, 'grad_norm': 14.247685432434082, 'learning_rate': 4.671186440677966e-05, 'epoch': 0.08}
  8%|â–Š         | 488/6000 [28:38<5:28:52,  3.58s/it]  8%|â–Š         | 489/6000 [28:42<5:27:29,  3.57s/it]                                                    {'loss': 0.0855, 'grad_norm': 6.210770606994629, 'learning_rate': 4.6703389830508474e-05, 'epoch': 0.08}
  8%|â–Š         | 489/6000 [28:42<5:27:29,  3.57s/it]  8%|â–Š         | 490/6000 [28:45<5:23:57,  3.53s/it]                                                    {'loss': 0.1369, 'grad_norm': 10.270133018493652, 'learning_rate': 4.669491525423729e-05, 'epoch': 0.08}
  8%|â–Š         | 490/6000 [28:45<5:23:57,  3.53s/it]  8%|â–Š         | 491/6000 [28:49<5:25:18,  3.54s/it]                                                    {'loss': 0.1891, 'grad_norm': 12.568516731262207, 'learning_rate': 4.66864406779661e-05, 'epoch': 0.08}
  8%|â–Š         | 491/6000 [28:49<5:25:18,  3.54s/it]  8%|â–Š         | 492/6000 [28:52<5:21:42,  3.50s/it]                                                    {'loss': 0.0321, 'grad_norm': 4.395465850830078, 'learning_rate': 4.667796610169492e-05, 'epoch': 0.08}
  8%|â–Š         | 492/6000 [28:52<5:21:42,  3.50s/it]  8%|â–Š         | 493/6000 [28:55<5:21:56,  3.51s/it]                                                    {'loss': 0.0682, 'grad_norm': 4.488597869873047, 'learning_rate': 4.666949152542373e-05, 'epoch': 0.08}
  8%|â–Š         | 493/6000 [28:55<5:21:56,  3.51s/it]  8%|â–Š         | 494/6000 [28:59<5:18:23,  3.47s/it]                                                    {'loss': 0.0245, 'grad_norm': 3.625229835510254, 'learning_rate': 4.666101694915255e-05, 'epoch': 0.08}
  8%|â–Š         | 494/6000 [28:59<5:18:23,  3.47s/it]  8%|â–Š         | 495/6000 [29:02<5:22:43,  3.52s/it]                                                    {'loss': 0.0913, 'grad_norm': 5.636215686798096, 'learning_rate': 4.6652542372881355e-05, 'epoch': 0.08}
  8%|â–Š         | 495/6000 [29:02<5:22:43,  3.52s/it]  8%|â–Š         | 496/6000 [29:06<5:20:27,  3.49s/it]                                                    {'loss': 0.0578, 'grad_norm': 7.940625190734863, 'learning_rate': 4.6644067796610166e-05, 'epoch': 0.08}
  8%|â–Š         | 496/6000 [29:06<5:20:27,  3.49s/it]  8%|â–Š         | 497/6000 [29:09<5:16:21,  3.45s/it]                                                    {'loss': 0.0042, 'grad_norm': 1.0352489948272705, 'learning_rate': 4.6635593220338984e-05, 'epoch': 0.08}
  8%|â–Š         | 497/6000 [29:09<5:16:21,  3.45s/it]  8%|â–Š         | 498/6000 [29:13<5:15:52,  3.44s/it]                                                    {'loss': 0.0758, 'grad_norm': 5.3722686767578125, 'learning_rate': 4.6627118644067795e-05, 'epoch': 0.08}
  8%|â–Š         | 498/6000 [29:13<5:15:52,  3.44s/it]  8%|â–Š         | 499/6000 [29:16<5:14:59,  3.44s/it]                                                    {'loss': 0.0442, 'grad_norm': 1.8187662363052368, 'learning_rate': 4.6618644067796614e-05, 'epoch': 0.08}
  8%|â–Š         | 499/6000 [29:16<5:14:59,  3.44s/it]  8%|â–Š         | 500/6000 [29:20<5:22:33,  3.52s/it]                                                    {'loss': 0.1053, 'grad_norm': 7.921666622161865, 'learning_rate': 4.6610169491525425e-05, 'epoch': 0.08}
  8%|â–Š         | 500/6000 [29:20<5:22:33,  3.52s/it][2025-10-20 15:59:06,805] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 501/6000 [29:25<6:20:27,  4.15s/it]                                                    {'loss': 0.073, 'grad_norm': 6.796992301940918, 'learning_rate': 4.660169491525424e-05, 'epoch': 0.08}
  8%|â–Š         | 501/6000 [29:25<6:20:27,  4.15s/it]  8%|â–Š         | 502/6000 [29:29<6:06:39,  4.00s/it]                                                    {'loss': 0.0278, 'grad_norm': 5.215848445892334, 'learning_rate': 4.6593220338983054e-05, 'epoch': 0.08}
  8%|â–Š         | 502/6000 [29:29<6:06:39,  4.00s/it]  8%|â–Š         | 503/6000 [29:32<5:49:20,  3.81s/it]                                                    {'loss': 0.0452, 'grad_norm': 4.536998748779297, 'learning_rate': 4.6584745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 503/6000 [29:32<5:49:20,  3.81s/it]  8%|â–Š         | 504/6000 [29:36<5:36:47,  3.68s/it]                                                    {'loss': 0.0462, 'grad_norm': 4.855947494506836, 'learning_rate': 4.657627118644068e-05, 'epoch': 0.08}
  8%|â–Š         | 504/6000 [29:36<5:36:47,  3.68s/it]  8%|â–Š         | 505/6000 [29:39<5:30:19,  3.61s/it]                                                    {'loss': 0.0499, 'grad_norm': 4.987804889678955, 'learning_rate': 4.6567796610169495e-05, 'epoch': 0.08}
  8%|â–Š         | 505/6000 [29:39<5:30:19,  3.61s/it]  8%|â–Š         | 506/6000 [29:43<5:35:23,  3.66s/it]                                                    {'loss': 0.1813, 'grad_norm': 13.440914154052734, 'learning_rate': 4.6559322033898306e-05, 'epoch': 0.08}
  8%|â–Š         | 506/6000 [29:43<5:35:23,  3.66s/it]  8%|â–Š         | 507/6000 [29:47<5:29:55,  3.60s/it]                                                    {'loss': 0.097, 'grad_norm': 9.250168800354004, 'learning_rate': 4.6550847457627124e-05, 'epoch': 0.08}
  8%|â–Š         | 507/6000 [29:47<5:29:55,  3.60s/it]  8%|â–Š         | 508/6000 [29:50<5:22:56,  3.53s/it]                                                    {'loss': 0.0765, 'grad_norm': 6.810420036315918, 'learning_rate': 4.6542372881355935e-05, 'epoch': 0.08}
  8%|â–Š         | 508/6000 [29:50<5:22:56,  3.53s/it]  8%|â–Š         | 509/6000 [29:53<5:16:09,  3.45s/it]                                                    {'loss': 0.0515, 'grad_norm': 4.7065749168396, 'learning_rate': 4.653389830508475e-05, 'epoch': 0.08}
  8%|â–Š         | 509/6000 [29:53<5:16:09,  3.45s/it]  8%|â–Š         | 510/6000 [29:57<5:16:28,  3.46s/it]                                                    {'loss': 0.0261, 'grad_norm': 4.940399169921875, 'learning_rate': 4.652542372881356e-05, 'epoch': 0.09}
  8%|â–Š         | 510/6000 [29:57<5:16:28,  3.46s/it]  9%|â–Š         | 511/6000 [30:00<5:16:28,  3.46s/it]                                                    {'loss': 0.0579, 'grad_norm': 2.533763885498047, 'learning_rate': 4.6516949152542376e-05, 'epoch': 0.09}
  9%|â–Š         | 511/6000 [30:00<5:16:28,  3.46s/it]  9%|â–Š         | 512/6000 [30:03<5:14:45,  3.44s/it]                                                    {'loss': 0.0448, 'grad_norm': 7.235456466674805, 'learning_rate': 4.650847457627119e-05, 'epoch': 0.09}
  9%|â–Š         | 512/6000 [30:04<5:14:45,  3.44s/it]  9%|â–Š         | 513/6000 [30:07<5:18:46,  3.49s/it]                                                    {'loss': 0.0057, 'grad_norm': 1.0305804014205933, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.09}
  9%|â–Š         | 513/6000 [30:07<5:18:46,  3.49s/it]  9%|â–Š         | 514/6000 [30:11<5:18:22,  3.48s/it]                                                    {'loss': 0.0097, 'grad_norm': 6.737348556518555, 'learning_rate': 4.649152542372882e-05, 'epoch': 0.09}
  9%|â–Š         | 514/6000 [30:11<5:18:22,  3.48s/it]  9%|â–Š         | 515/6000 [30:14<5:15:27,  3.45s/it]                                                    {'loss': 0.1088, 'grad_norm': 6.178427696228027, 'learning_rate': 4.6483050847457635e-05, 'epoch': 0.09}
  9%|â–Š         | 515/6000 [30:14<5:15:27,  3.45s/it]  9%|â–Š         | 516/6000 [30:18<5:21:19,  3.52s/it]                                                    {'loss': 0.1293, 'grad_norm': 12.149396896362305, 'learning_rate': 4.6474576271186446e-05, 'epoch': 0.09}
  9%|â–Š         | 516/6000 [30:18<5:21:19,  3.52s/it]  9%|â–Š         | 517/6000 [30:21<5:19:17,  3.49s/it]                                                    {'loss': 0.0003, 'grad_norm': 0.029637105762958527, 'learning_rate': 4.646610169491525e-05, 'epoch': 0.09}
  9%|â–Š         | 517/6000 [30:21<5:19:17,  3.49s/it]  9%|â–Š         | 518/6000 [30:24<5:16:03,  3.46s/it]                                                    {'loss': 0.2528, 'grad_norm': 11.600882530212402, 'learning_rate': 4.645762711864407e-05, 'epoch': 0.09}
  9%|â–Š         | 518/6000 [30:24<5:16:03,  3.46s/it]  9%|â–Š         | 519/6000 [30:28<5:16:12,  3.46s/it]                                                    {'loss': 0.0054, 'grad_norm': 0.5772755742073059, 'learning_rate': 4.644915254237288e-05, 'epoch': 0.09}
  9%|â–Š         | 519/6000 [30:28<5:16:12,  3.46s/it]  9%|â–Š         | 520/6000 [30:32<5:21:12,  3.52s/it]                                                    {'loss': 0.0604, 'grad_norm': 5.934189319610596, 'learning_rate': 4.64406779661017e-05, 'epoch': 0.09}
  9%|â–Š         | 520/6000 [30:32<5:21:12,  3.52s/it]  9%|â–Š         | 521/6000 [30:35<5:16:13,  3.46s/it]                                                    {'loss': 0.1087, 'grad_norm': 9.058582305908203, 'learning_rate': 4.643220338983051e-05, 'epoch': 0.09}
  9%|â–Š         | 521/6000 [30:35<5:16:13,  3.46s/it]  9%|â–Š         | 522/6000 [30:38<5:13:03,  3.43s/it]                                                    {'loss': 0.0052, 'grad_norm': 0.8806899785995483, 'learning_rate': 4.642372881355933e-05, 'epoch': 0.09}
  9%|â–Š         | 522/6000 [30:38<5:13:03,  3.43s/it]  9%|â–Š         | 523/6000 [30:42<5:15:41,  3.46s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.7893291115760803, 'learning_rate': 4.641525423728814e-05, 'epoch': 0.09}
  9%|â–Š         | 523/6000 [30:42<5:15:41,  3.46s/it]  9%|â–Š         | 524/6000 [30:45<5:14:16,  3.44s/it]                                                    {'loss': 0.1865, 'grad_norm': 13.028426170349121, 'learning_rate': 4.640677966101695e-05, 'epoch': 0.09}
  9%|â–Š         | 524/6000 [30:45<5:14:16,  3.44s/it]  9%|â–‰         | 525/6000 [30:49<5:12:07,  3.42s/it]                                                    {'loss': 0.0827, 'grad_norm': 8.18423080444336, 'learning_rate': 4.639830508474576e-05, 'epoch': 0.09}
  9%|â–‰         | 525/6000 [30:49<5:12:07,  3.42s/it]  9%|â–‰         | 526/6000 [30:52<5:11:14,  3.41s/it]                                                    {'loss': 0.0692, 'grad_norm': 7.516129493713379, 'learning_rate': 4.638983050847458e-05, 'epoch': 0.09}
  9%|â–‰         | 526/6000 [30:52<5:11:14,  3.41s/it]  9%|â–‰         | 527/6000 [30:55<5:11:16,  3.41s/it]                                                    {'loss': 0.0443, 'grad_norm': 6.118282318115234, 'learning_rate': 4.638135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 527/6000 [30:55<5:11:16,  3.41s/it]  9%|â–‰         | 528/6000 [30:59<5:13:55,  3.44s/it]                                                    {'loss': 0.124, 'grad_norm': 7.388605117797852, 'learning_rate': 4.637288135593221e-05, 'epoch': 0.09}
  9%|â–‰         | 528/6000 [30:59<5:13:55,  3.44s/it]  9%|â–‰         | 529/6000 [31:02<5:11:50,  3.42s/it]                                                    {'loss': 0.0034, 'grad_norm': 0.7465119957923889, 'learning_rate': 4.636440677966102e-05, 'epoch': 0.09}
  9%|â–‰         | 529/6000 [31:02<5:11:50,  3.42s/it]  9%|â–‰         | 530/6000 [31:06<5:13:18,  3.44s/it]                                                    {'loss': 0.0074, 'grad_norm': 1.100846767425537, 'learning_rate': 4.635593220338984e-05, 'epoch': 0.09}
  9%|â–‰         | 530/6000 [31:06<5:13:18,  3.44s/it]  9%|â–‰         | 531/6000 [31:09<5:10:36,  3.41s/it]                                                    {'loss': 0.1278, 'grad_norm': 9.264850616455078, 'learning_rate': 4.634745762711864e-05, 'epoch': 0.09}
  9%|â–‰         | 531/6000 [31:09<5:10:36,  3.41s/it]  9%|â–‰         | 532/6000 [31:12<5:11:08,  3.41s/it]                                                    {'loss': 0.1122, 'grad_norm': 12.270711898803711, 'learning_rate': 4.633898305084746e-05, 'epoch': 0.09}
  9%|â–‰         | 532/6000 [31:12<5:11:08,  3.41s/it]  9%|â–‰         | 533/6000 [31:16<5:14:14,  3.45s/it]                                                    {'loss': 0.0112, 'grad_norm': 1.6793370246887207, 'learning_rate': 4.633050847457627e-05, 'epoch': 0.09}
  9%|â–‰         | 533/6000 [31:16<5:14:14,  3.45s/it]  9%|â–‰         | 534/6000 [31:19<5:14:11,  3.45s/it]                                                    {'loss': 0.0194, 'grad_norm': 1.9012328386306763, 'learning_rate': 4.632203389830509e-05, 'epoch': 0.09}
  9%|â–‰         | 534/6000 [31:19<5:14:11,  3.45s/it]  9%|â–‰         | 535/6000 [31:23<5:15:01,  3.46s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.2204594612121582, 'learning_rate': 4.63135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 535/6000 [31:23<5:15:01,  3.46s/it]  9%|â–‰         | 536/6000 [31:26<5:15:12,  3.46s/it]                                                    {'loss': 0.1698, 'grad_norm': 10.289193153381348, 'learning_rate': 4.630508474576272e-05, 'epoch': 0.09}
  9%|â–‰         | 536/6000 [31:26<5:15:12,  3.46s/it]  9%|â–‰         | 537/6000 [31:30<5:14:18,  3.45s/it]                                                    {'loss': 0.0218, 'grad_norm': 3.10538649559021, 'learning_rate': 4.629661016949153e-05, 'epoch': 0.09}
  9%|â–‰         | 537/6000 [31:30<5:14:18,  3.45s/it]  9%|â–‰         | 538/6000 [31:33<5:12:11,  3.43s/it]                                                    {'loss': 0.0085, 'grad_norm': 1.3827251195907593, 'learning_rate': 4.628813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 538/6000 [31:33<5:12:11,  3.43s/it]  9%|â–‰         | 539/6000 [31:37<5:09:15,  3.40s/it]                                                    {'loss': 0.0003, 'grad_norm': 0.0441628061234951, 'learning_rate': 4.627966101694915e-05, 'epoch': 0.09}
  9%|â–‰         | 539/6000 [31:37<5:09:15,  3.40s/it]  9%|â–‰         | 540/6000 [31:40<5:06:02,  3.36s/it]                                                    {'loss': 0.0733, 'grad_norm': 7.885047435760498, 'learning_rate': 4.6271186440677964e-05, 'epoch': 0.09}
  9%|â–‰         | 540/6000 [31:40<5:06:02,  3.36s/it]  9%|â–‰         | 541/6000 [31:43<5:10:26,  3.41s/it]                                                    {'loss': 0.0138, 'grad_norm': 2.7900166511535645, 'learning_rate': 4.626271186440678e-05, 'epoch': 0.09}
  9%|â–‰         | 541/6000 [31:43<5:10:26,  3.41s/it]  9%|â–‰         | 542/6000 [31:47<5:10:08,  3.41s/it]                                                    {'loss': 0.0081, 'grad_norm': 1.3994452953338623, 'learning_rate': 4.6254237288135594e-05, 'epoch': 0.09}
  9%|â–‰         | 542/6000 [31:47<5:10:08,  3.41s/it]  9%|â–‰         | 543/6000 [31:50<5:10:29,  3.41s/it]                                                    {'loss': 0.1188, 'grad_norm': 11.029927253723145, 'learning_rate': 4.624576271186441e-05, 'epoch': 0.09}
  9%|â–‰         | 543/6000 [31:50<5:10:29,  3.41s/it]  9%|â–‰         | 544/6000 [31:54<5:10:05,  3.41s/it]                                                    {'loss': 0.1826, 'grad_norm': 10.705135345458984, 'learning_rate': 4.623728813559322e-05, 'epoch': 0.09}
  9%|â–‰         | 544/6000 [31:54<5:10:05,  3.41s/it]  9%|â–‰         | 545/6000 [31:57<5:11:28,  3.43s/it]                                                    {'loss': 0.075, 'grad_norm': 10.216241836547852, 'learning_rate': 4.6228813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 545/6000 [31:57<5:11:28,  3.43s/it]  9%|â–‰         | 546/6000 [32:01<5:14:10,  3.46s/it]                                                    {'loss': 0.0184, 'grad_norm': 2.2994544506073, 'learning_rate': 4.6220338983050846e-05, 'epoch': 0.09}
  9%|â–‰         | 546/6000 [32:01<5:14:10,  3.46s/it]  9%|â–‰         | 547/6000 [32:04<5:16:26,  3.48s/it]                                                    {'loss': 0.0233, 'grad_norm': 4.124533653259277, 'learning_rate': 4.6211864406779664e-05, 'epoch': 0.09}
  9%|â–‰         | 547/6000 [32:04<5:16:26,  3.48s/it]  9%|â–‰         | 548/6000 [32:08<5:16:29,  3.48s/it]                                                    {'loss': 0.0429, 'grad_norm': 6.068314552307129, 'learning_rate': 4.6203389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 548/6000 [32:08<5:16:29,  3.48s/it]  9%|â–‰         | 549/6000 [32:11<5:13:05,  3.45s/it]                                                    {'loss': 0.0471, 'grad_norm': 5.464925765991211, 'learning_rate': 4.619491525423729e-05, 'epoch': 0.09}
  9%|â–‰         | 549/6000 [32:11<5:13:05,  3.45s/it]  9%|â–‰         | 550/6000 [32:14<5:11:16,  3.43s/it]                                                    {'loss': 0.3269, 'grad_norm': 11.628875732421875, 'learning_rate': 4.6186440677966104e-05, 'epoch': 0.09}
  9%|â–‰         | 550/6000 [32:14<5:11:16,  3.43s/it][2025-10-20 16:02:01,307] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  9%|â–‰         | 551/6000 [32:21<6:37:08,  4.37s/it]                                                    {'loss': 0.0216, 'grad_norm': 4.270991325378418, 'learning_rate': 4.617796610169492e-05, 'epoch': 0.09}
  9%|â–‰         | 551/6000 [32:21<6:37:08,  4.37s/it]  9%|â–‰         | 552/6000 [32:24<6:13:00,  4.11s/it]                                                    {'loss': 0.0035, 'grad_norm': 1.4641929864883423, 'learning_rate': 4.6169491525423734e-05, 'epoch': 0.09}
  9%|â–‰         | 552/6000 [32:24<6:13:00,  4.11s/it]  9%|â–‰         | 553/6000 [32:28<5:57:38,  3.94s/it]                                                    {'loss': 0.1878, 'grad_norm': 7.159192085266113, 'learning_rate': 4.6161016949152545e-05, 'epoch': 0.09}
  9%|â–‰         | 553/6000 [32:28<5:57:38,  3.94s/it]  9%|â–‰         | 554/6000 [32:31<5:41:00,  3.76s/it]                                                    {'loss': 0.2572, 'grad_norm': 11.330860137939453, 'learning_rate': 4.6152542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 554/6000 [32:31<5:41:00,  3.76s/it]  9%|â–‰         | 555/6000 [32:35<5:28:33,  3.62s/it]                                                    {'loss': 0.0588, 'grad_norm': 5.186097145080566, 'learning_rate': 4.6144067796610174e-05, 'epoch': 0.09}
  9%|â–‰         | 555/6000 [32:35<5:28:33,  3.62s/it]  9%|â–‰         | 556/6000 [32:38<5:22:43,  3.56s/it]                                                    {'loss': 0.0309, 'grad_norm': 2.08027982711792, 'learning_rate': 4.6135593220338986e-05, 'epoch': 0.09}
  9%|â–‰         | 556/6000 [32:38<5:22:43,  3.56s/it]  9%|â–‰         | 557/6000 [32:41<5:17:54,  3.50s/it]                                                    {'loss': 0.041, 'grad_norm': 2.8032472133636475, 'learning_rate': 4.6127118644067804e-05, 'epoch': 0.09}
  9%|â–‰         | 557/6000 [32:41<5:17:54,  3.50s/it]  9%|â–‰         | 558/6000 [32:45<5:18:14,  3.51s/it]                                                    {'loss': 0.0647, 'grad_norm': 7.376642227172852, 'learning_rate': 4.6118644067796615e-05, 'epoch': 0.09}
  9%|â–‰         | 558/6000 [32:45<5:18:14,  3.51s/it]  9%|â–‰         | 559/6000 [32:48<5:20:25,  3.53s/it]                                                    {'loss': 0.0549, 'grad_norm': 4.871034622192383, 'learning_rate': 4.6110169491525426e-05, 'epoch': 0.09}
  9%|â–‰         | 559/6000 [32:48<5:20:25,  3.53s/it]  9%|â–‰         | 560/6000 [32:52<5:16:59,  3.50s/it]                                                    {'loss': 0.1316, 'grad_norm': 9.467106819152832, 'learning_rate': 4.610169491525424e-05, 'epoch': 0.09}
  9%|â–‰         | 560/6000 [32:52<5:16:59,  3.50s/it]  9%|â–‰         | 561/6000 [32:56<5:28:45,  3.63s/it]                                                    {'loss': 0.0336, 'grad_norm': 4.2305803298950195, 'learning_rate': 4.609322033898305e-05, 'epoch': 0.09}
  9%|â–‰         | 561/6000 [32:56<5:28:45,  3.63s/it]  9%|â–‰         | 562/6000 [32:59<5:19:19,  3.52s/it]                                                    {'loss': 0.2728, 'grad_norm': 8.859548568725586, 'learning_rate': 4.608474576271187e-05, 'epoch': 0.09}
  9%|â–‰         | 562/6000 [32:59<5:19:19,  3.52s/it]  9%|â–‰         | 563/6000 [33:03<5:16:41,  3.49s/it]                                                    {'loss': 0.0087, 'grad_norm': 1.3622809648513794, 'learning_rate': 4.607627118644068e-05, 'epoch': 0.09}
  9%|â–‰         | 563/6000 [33:03<5:16:41,  3.49s/it]  9%|â–‰         | 564/6000 [33:06<5:13:49,  3.46s/it]                                                    {'loss': 0.0071, 'grad_norm': 0.9047889709472656, 'learning_rate': 4.6067796610169496e-05, 'epoch': 0.09}
  9%|â–‰         | 564/6000 [33:06<5:13:49,  3.46s/it]  9%|â–‰         | 565/6000 [33:10<5:18:09,  3.51s/it]                                                    {'loss': 0.009, 'grad_norm': 1.0955381393432617, 'learning_rate': 4.605932203389831e-05, 'epoch': 0.09}
  9%|â–‰         | 565/6000 [33:10<5:18:09,  3.51s/it]  9%|â–‰         | 566/6000 [33:13<5:14:13,  3.47s/it]                                                    {'loss': 0.0256, 'grad_norm': 3.323622226715088, 'learning_rate': 4.605084745762712e-05, 'epoch': 0.09}
  9%|â–‰         | 566/6000 [33:13<5:14:13,  3.47s/it]  9%|â–‰         | 567/6000 [33:17<5:25:46,  3.60s/it]                                                    {'loss': 0.1353, 'grad_norm': 5.93487024307251, 'learning_rate': 4.604237288135593e-05, 'epoch': 0.09}
  9%|â–‰         | 567/6000 [33:17<5:25:46,  3.60s/it]  9%|â–‰         | 568/6000 [33:20<5:22:58,  3.57s/it]                                                    {'loss': 0.0432, 'grad_norm': 3.45729398727417, 'learning_rate': 4.603389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 568/6000 [33:20<5:22:58,  3.57s/it]  9%|â–‰         | 569/6000 [33:24<5:20:35,  3.54s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.7757034301757812, 'learning_rate': 4.602542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 569/6000 [33:24<5:20:35,  3.54s/it] 10%|â–‰         | 570/6000 [33:27<5:17:23,  3.51s/it]                                                    {'loss': 0.11, 'grad_norm': 7.202034950256348, 'learning_rate': 4.601694915254238e-05, 'epoch': 0.1}
 10%|â–‰         | 570/6000 [33:27<5:17:23,  3.51s/it] 10%|â–‰         | 571/6000 [33:32<5:52:52,  3.90s/it]                                                    {'loss': 0.1082, 'grad_norm': 9.624833106994629, 'learning_rate': 4.600847457627119e-05, 'epoch': 0.1}
 10%|â–‰         | 571/6000 [33:32<5:52:52,  3.90s/it] 10%|â–‰         | 572/6000 [33:35<5:38:37,  3.74s/it]                                                    {'loss': 0.3182, 'grad_norm': 8.435712814331055, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.1}
 10%|â–‰         | 572/6000 [33:35<5:38:37,  3.74s/it] 10%|â–‰         | 573/6000 [33:39<5:27:31,  3.62s/it]                                                    {'loss': 0.1509, 'grad_norm': 8.047767639160156, 'learning_rate': 4.599152542372882e-05, 'epoch': 0.1}
 10%|â–‰         | 573/6000 [33:39<5:27:31,  3.62s/it] 10%|â–‰         | 574/6000 [33:42<5:23:36,  3.58s/it]                                                    {'loss': 0.4571, 'grad_norm': 14.865667343139648, 'learning_rate': 4.598305084745763e-05, 'epoch': 0.1}
 10%|â–‰         | 574/6000 [33:42<5:23:36,  3.58s/it] 10%|â–‰         | 575/6000 [33:46<5:19:02,  3.53s/it]                                                    {'loss': 0.0593, 'grad_norm': 6.8129987716674805, 'learning_rate': 4.597457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 575/6000 [33:46<5:19:02,  3.53s/it] 10%|â–‰         | 576/6000 [33:49<5:18:37,  3.52s/it]                                                    {'loss': 0.06, 'grad_norm': 8.173559188842773, 'learning_rate': 4.596610169491526e-05, 'epoch': 0.1}
 10%|â–‰         | 576/6000 [33:49<5:18:37,  3.52s/it] 10%|â–‰         | 577/6000 [33:53<5:21:28,  3.56s/it]                                                    {'loss': 0.0613, 'grad_norm': 3.399966239929199, 'learning_rate': 4.595762711864407e-05, 'epoch': 0.1}
 10%|â–‰         | 577/6000 [33:53<5:21:28,  3.56s/it] 10%|â–‰         | 578/6000 [33:57<5:36:19,  3.72s/it]                                                    {'loss': 0.3294, 'grad_norm': 9.706854820251465, 'learning_rate': 4.594915254237288e-05, 'epoch': 0.1}
 10%|â–‰         | 578/6000 [33:57<5:36:19,  3.72s/it] 10%|â–‰         | 579/6000 [34:01<5:41:12,  3.78s/it]                                                    {'loss': 0.0204, 'grad_norm': 2.1956534385681152, 'learning_rate': 4.59406779661017e-05, 'epoch': 0.1}
 10%|â–‰         | 579/6000 [34:01<5:41:12,  3.78s/it] 10%|â–‰         | 580/6000 [34:04<5:33:14,  3.69s/it]                                                    {'loss': 0.1395, 'grad_norm': 5.594322681427002, 'learning_rate': 4.593220338983051e-05, 'epoch': 0.1}
 10%|â–‰         | 580/6000 [34:04<5:33:14,  3.69s/it] 10%|â–‰         | 581/6000 [34:09<5:49:42,  3.87s/it]                                                    {'loss': 0.2649, 'grad_norm': 9.331764221191406, 'learning_rate': 4.592372881355932e-05, 'epoch': 0.1}
 10%|â–‰         | 581/6000 [34:09<5:49:42,  3.87s/it] 10%|â–‰         | 582/6000 [34:13<6:07:12,  4.07s/it]                                                    {'loss': 0.1452, 'grad_norm': 10.16871452331543, 'learning_rate': 4.591525423728813e-05, 'epoch': 0.1}
 10%|â–‰         | 582/6000 [34:13<6:07:12,  4.07s/it] 10%|â–‰         | 583/6000 [34:17<5:52:05,  3.90s/it]                                                    {'loss': 0.0118, 'grad_norm': 1.8878730535507202, 'learning_rate': 4.590677966101695e-05, 'epoch': 0.1}
 10%|â–‰         | 583/6000 [34:17<5:52:05,  3.90s/it] 10%|â–‰         | 584/6000 [34:20<5:45:16,  3.83s/it]                                                    {'loss': 0.4718, 'grad_norm': 11.293126106262207, 'learning_rate': 4.589830508474576e-05, 'epoch': 0.1}
 10%|â–‰         | 584/6000 [34:20<5:45:16,  3.83s/it] 10%|â–‰         | 585/6000 [34:24<5:49:16,  3.87s/it]                                                    {'loss': 0.0024, 'grad_norm': 0.2697819173336029, 'learning_rate': 4.588983050847458e-05, 'epoch': 0.1}
 10%|â–‰         | 585/6000 [34:24<5:49:16,  3.87s/it] 10%|â–‰         | 586/6000 [34:28<5:36:35,  3.73s/it]                                                    {'loss': 0.082, 'grad_norm': 8.491741180419922, 'learning_rate': 4.588135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 586/6000 [34:28<5:36:35,  3.73s/it] 10%|â–‰         | 587/6000 [34:31<5:25:01,  3.60s/it]                                                    {'loss': 0.0442, 'grad_norm': 2.601013660430908, 'learning_rate': 4.587288135593221e-05, 'epoch': 0.1}
 10%|â–‰         | 587/6000 [34:31<5:25:01,  3.60s/it] 10%|â–‰         | 588/6000 [34:34<5:19:20,  3.54s/it]                                                    {'loss': 0.0288, 'grad_norm': 5.278824806213379, 'learning_rate': 4.5864406779661014e-05, 'epoch': 0.1}
 10%|â–‰         | 588/6000 [34:34<5:19:20,  3.54s/it] 10%|â–‰         | 589/6000 [34:38<5:18:01,  3.53s/it]                                                    {'loss': 0.0068, 'grad_norm': 1.1576036214828491, 'learning_rate': 4.585593220338983e-05, 'epoch': 0.1}
 10%|â–‰         | 589/6000 [34:38<5:18:01,  3.53s/it] 10%|â–‰         | 590/6000 [34:41<5:17:48,  3.52s/it]                                                    {'loss': 0.0533, 'grad_norm': 3.9553110599517822, 'learning_rate': 4.5847457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 590/6000 [34:41<5:17:48,  3.52s/it] 10%|â–‰         | 591/6000 [34:45<5:14:20,  3.49s/it]                                                    {'loss': 0.0663, 'grad_norm': 5.186858654022217, 'learning_rate': 4.583898305084746e-05, 'epoch': 0.1}
 10%|â–‰         | 591/6000 [34:45<5:14:20,  3.49s/it] 10%|â–‰         | 592/6000 [34:48<5:10:51,  3.45s/it]                                                    {'loss': 0.0693, 'grad_norm': 6.442526817321777, 'learning_rate': 4.583050847457627e-05, 'epoch': 0.1}
 10%|â–‰         | 592/6000 [34:48<5:10:51,  3.45s/it] 10%|â–‰         | 593/6000 [34:52<5:10:25,  3.44s/it]                                                    {'loss': 0.0146, 'grad_norm': 1.5952380895614624, 'learning_rate': 4.582203389830509e-05, 'epoch': 0.1}
 10%|â–‰         | 593/6000 [34:52<5:10:25,  3.44s/it] 10%|â–‰         | 594/6000 [34:55<5:14:00,  3.49s/it]                                                    {'loss': 0.0313, 'grad_norm': 5.358417987823486, 'learning_rate': 4.58135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 594/6000 [34:55<5:14:00,  3.49s/it] 10%|â–‰         | 595/6000 [34:59<5:23:02,  3.59s/it]                                                    {'loss': 0.0476, 'grad_norm': 6.307962894439697, 'learning_rate': 4.5805084745762714e-05, 'epoch': 0.1}
 10%|â–‰         | 595/6000 [34:59<5:23:02,  3.59s/it] 10%|â–‰         | 596/6000 [35:03<5:43:16,  3.81s/it]                                                    {'loss': 0.0604, 'grad_norm': 1.860395908355713, 'learning_rate': 4.5796610169491525e-05, 'epoch': 0.1}
 10%|â–‰         | 596/6000 [35:03<5:43:16,  3.81s/it] 10%|â–‰         | 597/6000 [35:07<5:29:30,  3.66s/it]                                                    {'loss': 0.0274, 'grad_norm': 2.3100836277008057, 'learning_rate': 4.578813559322034e-05, 'epoch': 0.1}
 10%|â–‰         | 597/6000 [35:07<5:29:30,  3.66s/it] 10%|â–‰         | 598/6000 [35:10<5:21:58,  3.58s/it]                                                    {'loss': 0.0998, 'grad_norm': 10.163853645324707, 'learning_rate': 4.5779661016949154e-05, 'epoch': 0.1}
 10%|â–‰         | 598/6000 [35:10<5:21:58,  3.58s/it] 10%|â–‰         | 599/6000 [35:13<5:15:45,  3.51s/it]                                                    {'loss': 0.0135, 'grad_norm': 0.7830401062965393, 'learning_rate': 4.5771186440677966e-05, 'epoch': 0.1}
 10%|â–‰         | 599/6000 [35:13<5:15:45,  3.51s/it] 10%|â–ˆ         | 600/6000 [35:17<5:13:54,  3.49s/it]                                                    {'loss': 0.0169, 'grad_norm': 2.8669168949127197, 'learning_rate': 4.5762711864406784e-05, 'epoch': 0.1}
 10%|â–ˆ         | 600/6000 [35:17<5:13:54,  3.49s/it][2025-10-20 16:05:03,735] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 10%|â–ˆ         | 601/6000 [35:22<6:11:27,  4.13s/it]                                                    {'loss': 0.1494, 'grad_norm': 9.85190486907959, 'learning_rate': 4.5754237288135595e-05, 'epoch': 0.1}
 10%|â–ˆ         | 601/6000 [35:22<6:11:27,  4.13s/it] 10%|â–ˆ         | 602/6000 [35:26<5:53:30,  3.93s/it]                                                    {'loss': 0.0106, 'grad_norm': 1.7360434532165527, 'learning_rate': 4.5745762711864406e-05, 'epoch': 0.1}
 10%|â–ˆ         | 602/6000 [35:26<5:53:30,  3.93s/it] 10%|â–ˆ         | 603/6000 [35:29<5:40:09,  3.78s/it]                                                    {'loss': 0.1252, 'grad_norm': 8.429701805114746, 'learning_rate': 4.573728813559322e-05, 'epoch': 0.1}
 10%|â–ˆ         | 603/6000 [35:29<5:40:09,  3.78s/it] 10%|â–ˆ         | 604/6000 [35:33<5:46:33,  3.85s/it]                                                    {'loss': 0.0381, 'grad_norm': 4.2034502029418945, 'learning_rate': 4.5728813559322036e-05, 'epoch': 0.1}
 10%|â–ˆ         | 604/6000 [35:33<5:46:33,  3.85s/it] 10%|â–ˆ         | 605/6000 [35:37<5:35:57,  3.74s/it]                                                    {'loss': 0.0298, 'grad_norm': 2.9097251892089844, 'learning_rate': 4.572033898305085e-05, 'epoch': 0.1}
 10%|â–ˆ         | 605/6000 [35:37<5:35:57,  3.74s/it] 10%|â–ˆ         | 606/6000 [35:40<5:33:08,  3.71s/it]                                                    {'loss': 0.004, 'grad_norm': 0.5716204047203064, 'learning_rate': 4.5711864406779665e-05, 'epoch': 0.1}
 10%|â–ˆ         | 606/6000 [35:40<5:33:08,  3.71s/it] 10%|â–ˆ         | 607/6000 [35:44<5:23:36,  3.60s/it]                                                    {'loss': 0.0283, 'grad_norm': 4.806507110595703, 'learning_rate': 4.5703389830508476e-05, 'epoch': 0.1}
 10%|â–ˆ         | 607/6000 [35:44<5:23:36,  3.60s/it] 10%|â–ˆ         | 608/6000 [35:47<5:22:47,  3.59s/it]                                                    {'loss': 0.1108, 'grad_norm': 8.71986198425293, 'learning_rate': 4.5694915254237294e-05, 'epoch': 0.1}
 10%|â–ˆ         | 608/6000 [35:47<5:22:47,  3.59s/it] 10%|â–ˆ         | 609/6000 [35:51<5:15:47,  3.51s/it]                                                    {'loss': 0.0838, 'grad_norm': 6.308904647827148, 'learning_rate': 4.5686440677966106e-05, 'epoch': 0.1}
 10%|â–ˆ         | 609/6000 [35:51<5:15:47,  3.51s/it] 10%|â–ˆ         | 610/6000 [35:54<5:13:36,  3.49s/it]                                                    {'loss': 0.0134, 'grad_norm': 1.7859858274459839, 'learning_rate': 4.567796610169492e-05, 'epoch': 0.1}
 10%|â–ˆ         | 610/6000 [35:54<5:13:36,  3.49s/it] 10%|â–ˆ         | 611/6000 [35:57<5:09:47,  3.45s/it]                                                    {'loss': 0.2425, 'grad_norm': 12.196627616882324, 'learning_rate': 4.566949152542373e-05, 'epoch': 0.1}
 10%|â–ˆ         | 611/6000 [35:57<5:09:47,  3.45s/it] 10%|â–ˆ         | 612/6000 [36:01<5:18:34,  3.55s/it]                                                    {'loss': 0.0676, 'grad_norm': 4.4749345779418945, 'learning_rate': 4.5661016949152546e-05, 'epoch': 0.1}
 10%|â–ˆ         | 612/6000 [36:01<5:18:34,  3.55s/it] 10%|â–ˆ         | 613/6000 [36:05<5:18:16,  3.54s/it]                                                    {'loss': 0.1212, 'grad_norm': 6.252608299255371, 'learning_rate': 4.565254237288136e-05, 'epoch': 0.1}
 10%|â–ˆ         | 613/6000 [36:05<5:18:16,  3.54s/it] 10%|â–ˆ         | 614/6000 [36:08<5:14:19,  3.50s/it]                                                    {'loss': 0.0094, 'grad_norm': 2.067824125289917, 'learning_rate': 4.5644067796610176e-05, 'epoch': 0.1}
 10%|â–ˆ         | 614/6000 [36:08<5:14:19,  3.50s/it] 10%|â–ˆ         | 615/6000 [36:12<5:11:31,  3.47s/it]                                                    {'loss': 0.149, 'grad_norm': 9.784401893615723, 'learning_rate': 4.563559322033899e-05, 'epoch': 0.1}
 10%|â–ˆ         | 615/6000 [36:12<5:11:31,  3.47s/it] 10%|â–ˆ         | 616/6000 [36:15<5:08:36,  3.44s/it]                                                    {'loss': 0.0691, 'grad_norm': 3.7869317531585693, 'learning_rate': 4.56271186440678e-05, 'epoch': 0.1}
 10%|â–ˆ         | 616/6000 [36:15<5:08:36,  3.44s/it] 10%|â–ˆ         | 617/6000 [36:18<5:08:20,  3.44s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.23060689866542816, 'learning_rate': 4.561864406779661e-05, 'epoch': 0.1}
 10%|â–ˆ         | 617/6000 [36:18<5:08:20,  3.44s/it] 10%|â–ˆ         | 618/6000 [36:22<5:07:50,  3.43s/it]                                                    {'loss': 0.0686, 'grad_norm': 6.789052486419678, 'learning_rate': 4.561016949152543e-05, 'epoch': 0.1}
 10%|â–ˆ         | 618/6000 [36:22<5:07:50,  3.43s/it] 10%|â–ˆ         | 619/6000 [36:25<5:06:10,  3.41s/it]                                                    {'loss': 0.132, 'grad_norm': 9.086334228515625, 'learning_rate': 4.560169491525424e-05, 'epoch': 0.1}
 10%|â–ˆ         | 619/6000 [36:25<5:06:10,  3.41s/it] 10%|â–ˆ         | 620/6000 [36:28<5:04:40,  3.40s/it]                                                    {'loss': 0.0567, 'grad_norm': 5.016904830932617, 'learning_rate': 4.559322033898305e-05, 'epoch': 0.1}
 10%|â–ˆ         | 620/6000 [36:29<5:04:40,  3.40s/it] 10%|â–ˆ         | 621/6000 [36:32<5:02:21,  3.37s/it]                                                    {'loss': 0.0101, 'grad_norm': 1.0791308879852295, 'learning_rate': 4.558474576271187e-05, 'epoch': 0.1}
 10%|â–ˆ         | 621/6000 [36:32<5:02:21,  3.37s/it] 10%|â–ˆ         | 622/6000 [36:35<5:01:38,  3.37s/it]                                                    {'loss': 0.128, 'grad_norm': 7.812145709991455, 'learning_rate': 4.557627118644068e-05, 'epoch': 0.1}
 10%|â–ˆ         | 622/6000 [36:35<5:01:38,  3.37s/it] 10%|â–ˆ         | 623/6000 [36:39<5:01:41,  3.37s/it]                                                    {'loss': 0.1962, 'grad_norm': 8.089903831481934, 'learning_rate': 4.556779661016949e-05, 'epoch': 0.1}
 10%|â–ˆ         | 623/6000 [36:39<5:01:41,  3.37s/it] 10%|â–ˆ         | 624/6000 [36:42<5:01:04,  3.36s/it]                                                    {'loss': 0.1121, 'grad_norm': 8.191646575927734, 'learning_rate': 4.55593220338983e-05, 'epoch': 0.1}
 10%|â–ˆ         | 624/6000 [36:42<5:01:04,  3.36s/it] 10%|â–ˆ         | 625/6000 [36:46<5:10:03,  3.46s/it]                                                    {'loss': 0.0041, 'grad_norm': 0.6107795834541321, 'learning_rate': 4.555084745762712e-05, 'epoch': 0.1}
 10%|â–ˆ         | 625/6000 [36:46<5:10:03,  3.46s/it] 10%|â–ˆ         | 626/6000 [36:49<5:08:51,  3.45s/it]                                                    {'loss': 0.0636, 'grad_norm': 4.907650947570801, 'learning_rate': 4.554237288135593e-05, 'epoch': 0.1}
 10%|â–ˆ         | 626/6000 [36:49<5:08:51,  3.45s/it] 10%|â–ˆ         | 627/6000 [36:53<5:30:07,  3.69s/it]                                                    {'loss': 0.0211, 'grad_norm': 2.6613786220550537, 'learning_rate': 4.553389830508475e-05, 'epoch': 0.1}
 10%|â–ˆ         | 627/6000 [36:53<5:30:07,  3.69s/it] 10%|â–ˆ         | 628/6000 [36:57<5:23:47,  3.62s/it]                                                    {'loss': 0.1306, 'grad_norm': 7.909178256988525, 'learning_rate': 4.552542372881356e-05, 'epoch': 0.1}
 10%|â–ˆ         | 628/6000 [36:57<5:23:47,  3.62s/it] 10%|â–ˆ         | 629/6000 [37:00<5:17:22,  3.55s/it]                                                    {'loss': 0.0133, 'grad_norm': 1.471693992614746, 'learning_rate': 4.551694915254238e-05, 'epoch': 0.1}
 10%|â–ˆ         | 629/6000 [37:00<5:17:22,  3.55s/it] 10%|â–ˆ         | 630/6000 [37:03<5:12:01,  3.49s/it]                                                    {'loss': 0.4161, 'grad_norm': 9.863920211791992, 'learning_rate': 4.550847457627119e-05, 'epoch': 0.1}
 10%|â–ˆ         | 630/6000 [37:03<5:12:01,  3.49s/it] 11%|â–ˆ         | 631/6000 [37:07<5:09:08,  3.45s/it]                                                    {'loss': 0.1363, 'grad_norm': 8.154691696166992, 'learning_rate': 4.55e-05, 'epoch': 0.11}
 11%|â–ˆ         | 631/6000 [37:07<5:09:08,  3.45s/it] 11%|â–ˆ         | 632/6000 [37:10<5:11:23,  3.48s/it]                                                    {'loss': 0.0823, 'grad_norm': 6.529348373413086, 'learning_rate': 4.549152542372881e-05, 'epoch': 0.11}
 11%|â–ˆ         | 632/6000 [37:10<5:11:23,  3.48s/it] 11%|â–ˆ         | 633/6000 [37:14<5:13:18,  3.50s/it]                                                    {'loss': 0.0606, 'grad_norm': 2.324331283569336, 'learning_rate': 4.548305084745763e-05, 'epoch': 0.11}
 11%|â–ˆ         | 633/6000 [37:14<5:13:18,  3.50s/it] 11%|â–ˆ         | 634/6000 [37:18<5:21:14,  3.59s/it]                                                    {'loss': 0.0065, 'grad_norm': 0.7894580960273743, 'learning_rate': 4.547457627118644e-05, 'epoch': 0.11}
 11%|â–ˆ         | 634/6000 [37:18<5:21:14,  3.59s/it] 11%|â–ˆ         | 635/6000 [37:21<5:21:43,  3.60s/it]                                                    {'loss': 0.0084, 'grad_norm': 0.9684445261955261, 'learning_rate': 4.546610169491526e-05, 'epoch': 0.11}
 11%|â–ˆ         | 635/6000 [37:21<5:21:43,  3.60s/it] 11%|â–ˆ         | 636/6000 [37:25<5:18:08,  3.56s/it]                                                    {'loss': 0.0037, 'grad_norm': 0.5490765571594238, 'learning_rate': 4.545762711864407e-05, 'epoch': 0.11}
 11%|â–ˆ         | 636/6000 [37:25<5:18:08,  3.56s/it] 11%|â–ˆ         | 637/6000 [37:28<5:15:18,  3.53s/it]                                                    {'loss': 0.0106, 'grad_norm': 1.226561188697815, 'learning_rate': 4.544915254237288e-05, 'epoch': 0.11}
 11%|â–ˆ         | 637/6000 [37:28<5:15:18,  3.53s/it] 11%|â–ˆ         | 638/6000 [37:32<5:27:48,  3.67s/it]                                                    {'loss': 0.0351, 'grad_norm': 5.162944316864014, 'learning_rate': 4.5440677966101694e-05, 'epoch': 0.11}
 11%|â–ˆ         | 638/6000 [37:32<5:27:48,  3.67s/it] 11%|â–ˆ         | 639/6000 [37:36<5:22:23,  3.61s/it]                                                    {'loss': 0.0289, 'grad_norm': 3.905109405517578, 'learning_rate': 4.543220338983051e-05, 'epoch': 0.11}
 11%|â–ˆ         | 639/6000 [37:36<5:22:23,  3.61s/it] 11%|â–ˆ         | 640/6000 [37:40<5:29:02,  3.68s/it]                                                    {'loss': 0.0231, 'grad_norm': 2.9514286518096924, 'learning_rate': 4.542372881355932e-05, 'epoch': 0.11}
 11%|â–ˆ         | 640/6000 [37:40<5:29:02,  3.68s/it] 11%|â–ˆ         | 641/6000 [37:44<5:36:20,  3.77s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.12988656759262085, 'learning_rate': 4.5415254237288135e-05, 'epoch': 0.11}
 11%|â–ˆ         | 641/6000 [37:44<5:36:20,  3.77s/it] 11%|â–ˆ         | 642/6000 [37:47<5:24:25,  3.63s/it]                                                    {'loss': 0.0282, 'grad_norm': 3.47598934173584, 'learning_rate': 4.540677966101695e-05, 'epoch': 0.11}
 11%|â–ˆ         | 642/6000 [37:47<5:24:25,  3.63s/it] 11%|â–ˆ         | 643/6000 [37:50<5:19:10,  3.57s/it]                                                    {'loss': 0.0308, 'grad_norm': 2.4684324264526367, 'learning_rate': 4.5398305084745764e-05, 'epoch': 0.11}
 11%|â–ˆ         | 643/6000 [37:50<5:19:10,  3.57s/it] 11%|â–ˆ         | 644/6000 [37:54<5:16:16,  3.54s/it]                                                    {'loss': 0.0182, 'grad_norm': 2.9401872158050537, 'learning_rate': 4.538983050847458e-05, 'epoch': 0.11}
 11%|â–ˆ         | 644/6000 [37:54<5:16:16,  3.54s/it] 11%|â–ˆ         | 645/6000 [37:57<5:12:12,  3.50s/it]                                                    {'loss': 0.1074, 'grad_norm': 5.769485950469971, 'learning_rate': 4.5381355932203387e-05, 'epoch': 0.11}
 11%|â–ˆ         | 645/6000 [37:57<5:12:12,  3.50s/it] 11%|â–ˆ         | 646/6000 [38:01<5:18:59,  3.57s/it]                                                    {'loss': 0.105, 'grad_norm': 7.4030938148498535, 'learning_rate': 4.5372881355932205e-05, 'epoch': 0.11}
 11%|â–ˆ         | 646/6000 [38:01<5:18:59,  3.57s/it] 11%|â–ˆ         | 647/6000 [38:04<5:13:04,  3.51s/it]                                                    {'loss': 0.0969, 'grad_norm': 6.488980770111084, 'learning_rate': 4.5364406779661016e-05, 'epoch': 0.11}
 11%|â–ˆ         | 647/6000 [38:04<5:13:04,  3.51s/it] 11%|â–ˆ         | 648/6000 [38:08<5:23:29,  3.63s/it]                                                    {'loss': 0.0371, 'grad_norm': 2.609483242034912, 'learning_rate': 4.5355932203389834e-05, 'epoch': 0.11}
 11%|â–ˆ         | 648/6000 [38:08<5:23:29,  3.63s/it] 11%|â–ˆ         | 649/6000 [38:12<5:17:00,  3.55s/it]                                                    {'loss': 0.0075, 'grad_norm': 1.3737801313400269, 'learning_rate': 4.5347457627118645e-05, 'epoch': 0.11}
 11%|â–ˆ         | 649/6000 [38:12<5:17:00,  3.55s/it] 11%|â–ˆ         | 650/6000 [38:15<5:11:27,  3.49s/it]                                                    {'loss': 0.0889, 'grad_norm': 6.901454925537109, 'learning_rate': 4.533898305084746e-05, 'epoch': 0.11}
 11%|â–ˆ         | 650/6000 [38:15<5:11:27,  3.49s/it][2025-10-20 16:08:01,877] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 11%|â–ˆ         | 651/6000 [38:20<6:05:49,  4.10s/it]                                                    {'loss': 0.1098, 'grad_norm': 7.480514049530029, 'learning_rate': 4.5330508474576275e-05, 'epoch': 0.11}
 11%|â–ˆ         | 651/6000 [38:20<6:05:49,  4.10s/it] 11%|â–ˆ         | 652/6000 [38:24<5:57:37,  4.01s/it]                                                    {'loss': 0.02, 'grad_norm': 3.583334445953369, 'learning_rate': 4.5322033898305086e-05, 'epoch': 0.11}
 11%|â–ˆ         | 652/6000 [38:24<5:57:37,  4.01s/it] 11%|â–ˆ         | 653/6000 [38:28<5:45:00,  3.87s/it]                                                    {'loss': 0.2627, 'grad_norm': 9.086923599243164, 'learning_rate': 4.53135593220339e-05, 'epoch': 0.11}
 11%|â–ˆ         | 653/6000 [38:28<5:45:00,  3.87s/it] 11%|â–ˆ         | 654/6000 [38:31<5:30:10,  3.71s/it]                                                    {'loss': 0.0018, 'grad_norm': 0.17460748553276062, 'learning_rate': 4.5305084745762715e-05, 'epoch': 0.11}
 11%|â–ˆ         | 654/6000 [38:31<5:30:10,  3.71s/it] 11%|â–ˆ         | 655/6000 [38:34<5:19:43,  3.59s/it]                                                    {'loss': 0.0635, 'grad_norm': 4.785358428955078, 'learning_rate': 4.5296610169491527e-05, 'epoch': 0.11}
 11%|â–ˆ         | 655/6000 [38:34<5:19:43,  3.59s/it] 11%|â–ˆ         | 656/6000 [38:38<5:13:05,  3.52s/it]                                                    {'loss': 0.1465, 'grad_norm': 8.73990249633789, 'learning_rate': 4.5288135593220345e-05, 'epoch': 0.11}
 11%|â–ˆ         | 656/6000 [38:38<5:13:05,  3.52s/it] 11%|â–ˆ         | 657/6000 [38:41<5:14:41,  3.53s/it]                                                    {'loss': 0.056, 'grad_norm': 1.633872151374817, 'learning_rate': 4.5279661016949156e-05, 'epoch': 0.11}
 11%|â–ˆ         | 657/6000 [38:41<5:14:41,  3.53s/it] 11%|â–ˆ         | 658/6000 [38:45<5:22:02,  3.62s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.20166216790676117, 'learning_rate': 4.5271186440677974e-05, 'epoch': 0.11}
 11%|â–ˆ         | 658/6000 [38:45<5:22:02,  3.62s/it] 11%|â–ˆ         | 659/6000 [38:48<5:13:49,  3.53s/it]                                                    {'loss': 0.0011, 'grad_norm': 0.22140033543109894, 'learning_rate': 4.526271186440678e-05, 'epoch': 0.11}
 11%|â–ˆ         | 659/6000 [38:48<5:13:49,  3.53s/it] 11%|â–ˆ         | 660/6000 [38:52<5:11:30,  3.50s/it]                                                    {'loss': 0.023, 'grad_norm': 3.4249675273895264, 'learning_rate': 4.5254237288135596e-05, 'epoch': 0.11}
 11%|â–ˆ         | 660/6000 [38:52<5:11:30,  3.50s/it] 11%|â–ˆ         | 661/6000 [38:55<5:07:19,  3.45s/it]                                                    {'loss': 0.0036, 'grad_norm': 0.5546291470527649, 'learning_rate': 4.524576271186441e-05, 'epoch': 0.11}
 11%|â–ˆ         | 661/6000 [38:55<5:07:19,  3.45s/it] 11%|â–ˆ         | 662/6000 [38:59<5:06:09,  3.44s/it]                                                    {'loss': 0.0525, 'grad_norm': 3.8954520225524902, 'learning_rate': 4.523728813559322e-05, 'epoch': 0.11}
 11%|â–ˆ         | 662/6000 [38:59<5:06:09,  3.44s/it] 11%|â–ˆ         | 663/6000 [39:02<5:02:33,  3.40s/it]                                                    {'loss': 0.1029, 'grad_norm': 8.989765167236328, 'learning_rate': 4.522881355932204e-05, 'epoch': 0.11}
 11%|â–ˆ         | 663/6000 [39:02<5:02:33,  3.40s/it] 11%|â–ˆ         | 664/6000 [39:05<5:06:01,  3.44s/it]                                                    {'loss': 0.0485, 'grad_norm': 5.935506343841553, 'learning_rate': 4.522033898305085e-05, 'epoch': 0.11}
 11%|â–ˆ         | 664/6000 [39:05<5:06:01,  3.44s/it] 11%|â–ˆ         | 665/6000 [39:09<5:05:02,  3.43s/it]                                                    {'loss': 0.0594, 'grad_norm': 4.895768642425537, 'learning_rate': 4.5211864406779666e-05, 'epoch': 0.11}
 11%|â–ˆ         | 665/6000 [39:09<5:05:02,  3.43s/it] 11%|â–ˆ         | 666/6000 [39:12<5:07:54,  3.46s/it]                                                    {'loss': 0.0795, 'grad_norm': 7.4822306632995605, 'learning_rate': 4.520338983050848e-05, 'epoch': 0.11}
 11%|â–ˆ         | 666/6000 [39:12<5:07:54,  3.46s/it] 11%|â–ˆ         | 667/6000 [39:16<5:09:53,  3.49s/it]                                                    {'loss': 0.109, 'grad_norm': 8.593464851379395, 'learning_rate': 4.519491525423729e-05, 'epoch': 0.11}
 11%|â–ˆ         | 667/6000 [39:16<5:09:53,  3.49s/it] 11%|â–ˆ         | 668/6000 [39:20<5:14:00,  3.53s/it]                                                    {'loss': 0.0123, 'grad_norm': 1.84339439868927, 'learning_rate': 4.51864406779661e-05, 'epoch': 0.11}
 11%|â–ˆ         | 668/6000 [39:20<5:14:00,  3.53s/it] 11%|â–ˆ         | 669/6000 [39:23<5:07:35,  3.46s/it]                                                    {'loss': 0.006, 'grad_norm': 0.7610263824462891, 'learning_rate': 4.517796610169492e-05, 'epoch': 0.11}
 11%|â–ˆ         | 669/6000 [39:23<5:07:35,  3.46s/it] 11%|â–ˆ         | 670/6000 [39:26<5:10:49,  3.50s/it]                                                    {'loss': 0.0258, 'grad_norm': 3.6449501514434814, 'learning_rate': 4.516949152542373e-05, 'epoch': 0.11}
 11%|â–ˆ         | 670/6000 [39:26<5:10:49,  3.50s/it] 11%|â–ˆ         | 671/6000 [39:30<5:08:11,  3.47s/it]                                                    {'loss': 0.0487, 'grad_norm': 5.808177947998047, 'learning_rate': 4.516101694915255e-05, 'epoch': 0.11}
 11%|â–ˆ         | 671/6000 [39:30<5:08:11,  3.47s/it] 11%|â–ˆ         | 672/6000 [39:33<5:04:10,  3.43s/it]                                                    {'loss': 0.088, 'grad_norm': 9.700684547424316, 'learning_rate': 4.515254237288136e-05, 'epoch': 0.11}
 11%|â–ˆ         | 672/6000 [39:33<5:04:10,  3.43s/it] 11%|â–ˆ         | 673/6000 [39:37<5:03:26,  3.42s/it]                                                    {'loss': 0.0598, 'grad_norm': 4.457550048828125, 'learning_rate': 4.514406779661017e-05, 'epoch': 0.11}
 11%|â–ˆ         | 673/6000 [39:37<5:03:26,  3.42s/it] 11%|â–ˆ         | 674/6000 [39:40<5:00:23,  3.38s/it]                                                    {'loss': 0.0231, 'grad_norm': 1.2504634857177734, 'learning_rate': 4.513559322033898e-05, 'epoch': 0.11}
 11%|â–ˆ         | 674/6000 [39:40<5:00:23,  3.38s/it] 11%|â–ˆâ–        | 675/6000 [39:43<4:59:35,  3.38s/it]                                                    {'loss': 0.0912, 'grad_norm': 7.591640472412109, 'learning_rate': 4.51271186440678e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 675/6000 [39:43<4:59:35,  3.38s/it] 11%|â–ˆâ–        | 676/6000 [39:47<5:00:29,  3.39s/it]                                                    {'loss': 0.0425, 'grad_norm': 3.8409018516540527, 'learning_rate': 4.511864406779661e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 676/6000 [39:47<5:00:29,  3.39s/it] 11%|â–ˆâ–        | 677/6000 [39:50<4:57:45,  3.36s/it]                                                    {'loss': 0.0255, 'grad_norm': 3.6605284214019775, 'learning_rate': 4.511016949152543e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 677/6000 [39:50<4:57:45,  3.36s/it] 11%|â–ˆâ–        | 678/6000 [39:53<4:59:20,  3.37s/it]                                                    {'loss': 0.0225, 'grad_norm': 2.070833683013916, 'learning_rate': 4.510169491525424e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 678/6000 [39:53<4:59:20,  3.37s/it] 11%|â–ˆâ–        | 679/6000 [39:57<4:56:51,  3.35s/it]                                                    {'loss': 0.0395, 'grad_norm': 4.072015762329102, 'learning_rate': 4.509322033898306e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 679/6000 [39:57<4:56:51,  3.35s/it] 11%|â–ˆâ–        | 680/6000 [40:00<4:57:43,  3.36s/it]                                                    {'loss': 0.0161, 'grad_norm': 1.8554097414016724, 'learning_rate': 4.508474576271187e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 680/6000 [40:00<4:57:43,  3.36s/it] 11%|â–ˆâ–        | 681/6000 [40:04<5:11:03,  3.51s/it]                                                    {'loss': 0.0049, 'grad_norm': 0.6553726196289062, 'learning_rate': 4.507627118644068e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 681/6000 [40:04<5:11:03,  3.51s/it] 11%|â–ˆâ–        | 682/6000 [40:07<5:10:05,  3.50s/it]                                                    {'loss': 0.0134, 'grad_norm': 2.938066244125366, 'learning_rate': 4.506779661016949e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 682/6000 [40:07<5:10:05,  3.50s/it] 11%|â–ˆâ–        | 683/6000 [40:11<5:09:01,  3.49s/it]                                                    {'loss': 0.0385, 'grad_norm': 4.0177531242370605, 'learning_rate': 4.5059322033898304e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 683/6000 [40:11<5:09:01,  3.49s/it] 11%|â–ˆâ–        | 684/6000 [40:14<5:05:02,  3.44s/it]                                                    {'loss': 0.2239, 'grad_norm': 12.16140079498291, 'learning_rate': 4.505084745762712e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 684/6000 [40:14<5:05:02,  3.44s/it] 11%|â–ˆâ–        | 685/6000 [40:18<5:03:55,  3.43s/it]                                                    {'loss': 0.1392, 'grad_norm': 10.037510871887207, 'learning_rate': 4.504237288135593e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 685/6000 [40:18<5:03:55,  3.43s/it] 11%|â–ˆâ–        | 686/6000 [40:22<5:20:12,  3.62s/it]                                                    {'loss': 0.1888, 'grad_norm': 8.601656913757324, 'learning_rate': 4.503389830508475e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 686/6000 [40:22<5:20:12,  3.62s/it] 11%|â–ˆâ–        | 687/6000 [40:25<5:12:57,  3.53s/it]                                                    {'loss': 0.0513, 'grad_norm': 8.179906845092773, 'learning_rate': 4.502542372881356e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 687/6000 [40:25<5:12:57,  3.53s/it] 11%|â–ˆâ–        | 688/6000 [40:28<5:08:21,  3.48s/it]                                                    {'loss': 0.0504, 'grad_norm': 6.231082916259766, 'learning_rate': 4.5016949152542373e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 688/6000 [40:28<5:08:21,  3.48s/it] 11%|â–ˆâ–        | 689/6000 [40:32<5:08:06,  3.48s/it]                                                    {'loss': 0.2802, 'grad_norm': 13.305794715881348, 'learning_rate': 4.5008474576271185e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 689/6000 [40:32<5:08:06,  3.48s/it] 12%|â–ˆâ–        | 690/6000 [40:35<5:06:24,  3.46s/it]                                                    {'loss': 0.0325, 'grad_norm': 2.0740966796875, 'learning_rate': 4.5e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 690/6000 [40:35<5:06:24,  3.46s/it] 12%|â–ˆâ–        | 691/6000 [40:39<5:13:09,  3.54s/it]                                                    {'loss': 0.0269, 'grad_norm': 4.31353235244751, 'learning_rate': 4.4991525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 691/6000 [40:39<5:13:09,  3.54s/it] 12%|â–ˆâ–        | 692/6000 [40:42<5:11:18,  3.52s/it]                                                    {'loss': 0.3456, 'grad_norm': 12.858034133911133, 'learning_rate': 4.498305084745763e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 692/6000 [40:42<5:11:18,  3.52s/it] 12%|â–ˆâ–        | 693/6000 [40:46<5:06:24,  3.46s/it]                                                    {'loss': 0.15, 'grad_norm': 10.047121047973633, 'learning_rate': 4.4974576271186443e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 693/6000 [40:46<5:06:24,  3.46s/it] 12%|â–ˆâ–        | 694/6000 [40:49<5:04:55,  3.45s/it]                                                    {'loss': 0.0039, 'grad_norm': 1.0376819372177124, 'learning_rate': 4.4966101694915255e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 694/6000 [40:49<5:04:55,  3.45s/it] 12%|â–ˆâ–        | 695/6000 [40:53<5:04:29,  3.44s/it]                                                    {'loss': 0.0252, 'grad_norm': 5.118794918060303, 'learning_rate': 4.4957627118644066e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 695/6000 [40:53<5:04:29,  3.44s/it] 12%|â–ˆâ–        | 696/6000 [40:56<5:12:45,  3.54s/it]                                                    {'loss': 0.0659, 'grad_norm': 7.8258161544799805, 'learning_rate': 4.4949152542372884e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 696/6000 [40:56<5:12:45,  3.54s/it] 12%|â–ˆâ–        | 697/6000 [41:00<5:08:51,  3.49s/it]                                                    {'loss': 0.0244, 'grad_norm': 2.8605220317840576, 'learning_rate': 4.4940677966101695e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 697/6000 [41:00<5:08:51,  3.49s/it] 12%|â–ˆâ–        | 698/6000 [41:03<5:06:51,  3.47s/it]                                                    {'loss': 0.0154, 'grad_norm': 1.9418630599975586, 'learning_rate': 4.4932203389830513e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 698/6000 [41:03<5:06:51,  3.47s/it] 12%|â–ˆâ–        | 699/6000 [41:07<5:05:19,  3.46s/it]                                                    {'loss': 0.0255, 'grad_norm': 3.3153343200683594, 'learning_rate': 4.4923728813559325e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 699/6000 [41:07<5:05:19,  3.46s/it] 12%|â–ˆâ–        | 700/6000 [41:10<5:06:46,  3.47s/it]                                                    {'loss': 0.0104, 'grad_norm': 1.4524235725402832, 'learning_rate': 4.491525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 700/6000 [41:10<5:06:46,  3.47s/it][2025-10-20 16:10:57,097] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|â–ˆâ–        | 701/6000 [41:16<6:06:46,  4.15s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.42986708879470825, 'learning_rate': 4.4906779661016954e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 701/6000 [41:16<6:06:46,  4.15s/it] 12%|â–ˆâ–        | 702/6000 [41:20<6:00:22,  4.08s/it]                                                    {'loss': 0.0744, 'grad_norm': 4.8366522789001465, 'learning_rate': 4.4898305084745765e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 702/6000 [41:20<6:00:22,  4.08s/it] 12%|â–ˆâ–        | 703/6000 [41:23<5:43:18,  3.89s/it]                                                    {'loss': 0.0588, 'grad_norm': 6.790745258331299, 'learning_rate': 4.488983050847458e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 703/6000 [41:23<5:43:18,  3.89s/it] 12%|â–ˆâ–        | 704/6000 [41:27<5:44:15,  3.90s/it]                                                    {'loss': 0.0086, 'grad_norm': 1.2764737606048584, 'learning_rate': 4.488135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 704/6000 [41:27<5:44:15,  3.90s/it] 12%|â–ˆâ–        | 705/6000 [41:31<5:34:19,  3.79s/it]                                                    {'loss': 0.2499, 'grad_norm': 9.764708518981934, 'learning_rate': 4.4872881355932206e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 705/6000 [41:31<5:34:19,  3.79s/it] 12%|â–ˆâ–        | 706/6000 [41:34<5:22:42,  3.66s/it]                                                    {'loss': 0.0604, 'grad_norm': 4.403493881225586, 'learning_rate': 4.486440677966102e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 706/6000 [41:34<5:22:42,  3.66s/it] 12%|â–ˆâ–        | 707/6000 [41:37<5:17:48,  3.60s/it]                                                    {'loss': 0.0658, 'grad_norm': 8.014172554016113, 'learning_rate': 4.4855932203389835e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 707/6000 [41:37<5:17:48,  3.60s/it] 12%|â–ˆâ–        | 708/6000 [41:41<5:13:20,  3.55s/it]                                                    {'loss': 0.0077, 'grad_norm': 1.12618887424469, 'learning_rate': 4.484745762711865e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 708/6000 [41:41<5:13:20,  3.55s/it] 12%|â–ˆâ–        | 709/6000 [41:44<5:09:25,  3.51s/it]                                                    {'loss': 0.0413, 'grad_norm': 6.327323913574219, 'learning_rate': 4.483898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 709/6000 [41:44<5:09:25,  3.51s/it] 12%|â–ˆâ–        | 710/6000 [41:48<5:15:02,  3.57s/it]                                                    {'loss': 0.0274, 'grad_norm': 2.9245517253875732, 'learning_rate': 4.483050847457627e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 710/6000 [41:48<5:15:02,  3.57s/it] 12%|â–ˆâ–        | 711/6000 [41:51<5:10:05,  3.52s/it]                                                    {'loss': 0.0027, 'grad_norm': 0.6627108454704285, 'learning_rate': 4.482203389830509e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 711/6000 [41:51<5:10:05,  3.52s/it] 12%|â–ˆâ–        | 712/6000 [41:55<5:09:47,  3.52s/it]                                                    {'loss': 0.0124, 'grad_norm': 1.7839547395706177, 'learning_rate': 4.48135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 712/6000 [41:55<5:09:47,  3.52s/it] 12%|â–ˆâ–        | 713/6000 [41:58<5:06:06,  3.47s/it]                                                    {'loss': 0.0469, 'grad_norm': 2.4747025966644287, 'learning_rate': 4.480508474576272e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 713/6000 [41:58<5:06:06,  3.47s/it] 12%|â–ˆâ–        | 714/6000 [42:02<5:04:43,  3.46s/it]                                                    {'loss': 0.0249, 'grad_norm': 3.5973668098449707, 'learning_rate': 4.479661016949153e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 714/6000 [42:02<5:04:43,  3.46s/it] 12%|â–ˆâ–        | 715/6000 [42:05<5:02:35,  3.44s/it]                                                    {'loss': 0.0142, 'grad_norm': 2.1782302856445312, 'learning_rate': 4.4788135593220346e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 715/6000 [42:05<5:02:35,  3.44s/it] 12%|â–ˆâ–        | 716/6000 [42:08<5:00:45,  3.42s/it]                                                    {'loss': 0.0437, 'grad_norm': 4.515082836151123, 'learning_rate': 4.477966101694915e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 716/6000 [42:09<5:00:45,  3.42s/it] 12%|â–ˆâ–        | 717/6000 [42:12<5:10:53,  3.53s/it]                                                    {'loss': 0.0542, 'grad_norm': 4.521027088165283, 'learning_rate': 4.477118644067797e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 717/6000 [42:12<5:10:53,  3.53s/it] 12%|â–ˆâ–        | 718/6000 [42:16<5:03:59,  3.45s/it]                                                    {'loss': 0.0261, 'grad_norm': 4.388664722442627, 'learning_rate': 4.476271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 718/6000 [42:16<5:03:59,  3.45s/it] 12%|â–ˆâ–        | 719/6000 [42:19<5:04:05,  3.45s/it]                                                    {'loss': 0.1242, 'grad_norm': 9.762191772460938, 'learning_rate': 4.47542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 719/6000 [42:19<5:04:05,  3.45s/it] 12%|â–ˆâ–        | 720/6000 [42:22<5:01:48,  3.43s/it]                                                    {'loss': 0.0064, 'grad_norm': 1.1212259531021118, 'learning_rate': 4.474576271186441e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 720/6000 [42:22<5:01:48,  3.43s/it] 12%|â–ˆâ–        | 721/6000 [42:26<5:05:04,  3.47s/it]                                                    {'loss': 0.0437, 'grad_norm': 3.4836623668670654, 'learning_rate': 4.473728813559323e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 721/6000 [42:26<5:05:04,  3.47s/it] 12%|â–ˆâ–        | 722/6000 [42:29<5:04:46,  3.46s/it]                                                    {'loss': 0.1046, 'grad_norm': 5.462803840637207, 'learning_rate': 4.472881355932204e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 722/6000 [42:29<5:04:46,  3.46s/it] 12%|â–ˆâ–        | 723/6000 [42:33<5:17:16,  3.61s/it]                                                    {'loss': 0.0066, 'grad_norm': 0.924515962600708, 'learning_rate': 4.472033898305085e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 723/6000 [42:33<5:17:16,  3.61s/it] 12%|â–ˆâ–        | 724/6000 [42:37<5:09:31,  3.52s/it]                                                    {'loss': 0.0968, 'grad_norm': 8.360345840454102, 'learning_rate': 4.471186440677966e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 724/6000 [42:37<5:09:31,  3.52s/it] 12%|â–ˆâ–        | 725/6000 [42:40<5:05:12,  3.47s/it]                                                    {'loss': 0.0399, 'grad_norm': 5.522711753845215, 'learning_rate': 4.470338983050847e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 725/6000 [42:40<5:05:12,  3.47s/it] 12%|â–ˆâ–        | 726/6000 [42:43<5:04:28,  3.46s/it]                                                    {'loss': 0.0028, 'grad_norm': 0.21789512038230896, 'learning_rate': 4.469491525423729e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 726/6000 [42:43<5:04:28,  3.46s/it] 12%|â–ˆâ–        | 727/6000 [42:47<5:02:32,  3.44s/it]                                                    {'loss': 0.0837, 'grad_norm': 7.600893497467041, 'learning_rate': 4.46864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 727/6000 [42:47<5:02:32,  3.44s/it] 12%|â–ˆâ–        | 728/6000 [42:50<5:00:37,  3.42s/it]                                                    {'loss': 0.0067, 'grad_norm': 0.8960725665092468, 'learning_rate': 4.467796610169492e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 728/6000 [42:50<5:00:37,  3.42s/it] 12%|â–ˆâ–        | 729/6000 [42:54<4:59:41,  3.41s/it]                                                    {'loss': 0.0082, 'grad_norm': 3.7398576736450195, 'learning_rate': 4.466949152542373e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 729/6000 [42:54<4:59:41,  3.41s/it] 12%|â–ˆâ–        | 730/6000 [42:57<4:57:45,  3.39s/it]                                                    {'loss': 0.1162, 'grad_norm': 8.065784454345703, 'learning_rate': 4.466101694915254e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 730/6000 [42:57<4:57:45,  3.39s/it] 12%|â–ˆâ–        | 731/6000 [43:00<4:56:50,  3.38s/it]                                                    {'loss': 0.0052, 'grad_norm': 0.7281467318534851, 'learning_rate': 4.4652542372881354e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 731/6000 [43:00<4:56:50,  3.38s/it] 12%|â–ˆâ–        | 732/6000 [43:04<5:01:21,  3.43s/it]                                                    {'loss': 0.046, 'grad_norm': 3.3543131351470947, 'learning_rate': 4.464406779661017e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 732/6000 [43:04<5:01:21,  3.43s/it] 12%|â–ˆâ–        | 733/6000 [43:08<5:06:51,  3.50s/it]                                                    {'loss': 0.0192, 'grad_norm': 2.9165759086608887, 'learning_rate': 4.463559322033898e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 733/6000 [43:08<5:06:51,  3.50s/it] 12%|â–ˆâ–        | 734/6000 [43:12<5:19:41,  3.64s/it]                                                    {'loss': 0.0118, 'grad_norm': 2.815300464630127, 'learning_rate': 4.46271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 734/6000 [43:12<5:19:41,  3.64s/it] 12%|â–ˆâ–        | 735/6000 [43:15<5:12:18,  3.56s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.09268689155578613, 'learning_rate': 4.461864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 735/6000 [43:15<5:12:18,  3.56s/it] 12%|â–ˆâ–        | 736/6000 [43:18<5:06:20,  3.49s/it]                                                    {'loss': 0.0606, 'grad_norm': 4.183833599090576, 'learning_rate': 4.461016949152543e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 736/6000 [43:18<5:06:20,  3.49s/it] 12%|â–ˆâ–        | 737/6000 [43:22<5:04:41,  3.47s/it]                                                    {'loss': 0.1163, 'grad_norm': 7.2512969970703125, 'learning_rate': 4.460169491525424e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 737/6000 [43:22<5:04:41,  3.47s/it] 12%|â–ˆâ–        | 738/6000 [43:25<5:01:24,  3.44s/it]                                                    {'loss': 0.1894, 'grad_norm': 12.360797882080078, 'learning_rate': 4.459322033898305e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 738/6000 [43:25<5:01:24,  3.44s/it] 12%|â–ˆâ–        | 739/6000 [43:28<5:00:49,  3.43s/it]                                                    {'loss': 0.0475, 'grad_norm': 4.4920430183410645, 'learning_rate': 4.4584745762711864e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 739/6000 [43:28<5:00:49,  3.43s/it] 12%|â–ˆâ–        | 740/6000 [43:32<5:00:38,  3.43s/it]                                                    {'loss': 0.1953, 'grad_norm': 7.3623223304748535, 'learning_rate': 4.457627118644068e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 740/6000 [43:32<5:00:38,  3.43s/it] 12%|â–ˆâ–        | 741/6000 [43:35<5:01:47,  3.44s/it]                                                    {'loss': 0.0577, 'grad_norm': 4.133238315582275, 'learning_rate': 4.4567796610169494e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 741/6000 [43:35<5:01:47,  3.44s/it] 12%|â–ˆâ–        | 742/6000 [43:39<5:00:07,  3.42s/it]                                                    {'loss': 0.0093, 'grad_norm': 1.4956918954849243, 'learning_rate': 4.455932203389831e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 742/6000 [43:39<5:00:07,  3.42s/it] 12%|â–ˆâ–        | 743/6000 [43:42<4:57:15,  3.39s/it]                                                    {'loss': 0.1199, 'grad_norm': 8.563104629516602, 'learning_rate': 4.455084745762712e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 743/6000 [43:42<4:57:15,  3.39s/it] 12%|â–ˆâ–        | 744/6000 [43:45<4:55:33,  3.37s/it]                                                    {'loss': 0.0132, 'grad_norm': 1.3363144397735596, 'learning_rate': 4.4542372881355934e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 744/6000 [43:45<4:55:33,  3.37s/it] 12%|â–ˆâ–        | 745/6000 [43:49<4:55:00,  3.37s/it]                                                    {'loss': 0.1411, 'grad_norm': 6.7786970138549805, 'learning_rate': 4.4533898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 745/6000 [43:49<4:55:00,  3.37s/it] 12%|â–ˆâ–        | 746/6000 [43:52<4:55:17,  3.37s/it]                                                    {'loss': 0.4523, 'grad_norm': 10.241873741149902, 'learning_rate': 4.452542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 746/6000 [43:52<4:55:17,  3.37s/it] 12%|â–ˆâ–        | 747/6000 [43:55<4:56:45,  3.39s/it]                                                    {'loss': 0.0491, 'grad_norm': 5.49423885345459, 'learning_rate': 4.4516949152542375e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 747/6000 [43:56<4:56:45,  3.39s/it] 12%|â–ˆâ–        | 748/6000 [43:59<5:00:12,  3.43s/it]                                                    {'loss': 0.055, 'grad_norm': 7.391324520111084, 'learning_rate': 4.4508474576271186e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 748/6000 [43:59<5:00:12,  3.43s/it] 12%|â–ˆâ–        | 749/6000 [44:03<5:22:09,  3.68s/it]                                                    {'loss': 0.0624, 'grad_norm': 8.369291305541992, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 749/6000 [44:03<5:22:09,  3.68s/it] 12%|â–ˆâ–Ž        | 750/6000 [44:07<5:23:50,  3.70s/it]                                                    {'loss': 0.2103, 'grad_norm': 9.097326278686523, 'learning_rate': 4.4491525423728816e-05, 'epoch': 0.12}
 12%|â–ˆâ–Ž        | 750/6000 [44:07<5:23:50,  3.70s/it][2025-10-20 16:13:54,037] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 751/6000 [44:13<6:16:23,  4.30s/it]                                                    {'loss': 0.0154, 'grad_norm': 1.4464093446731567, 'learning_rate': 4.448305084745763e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 751/6000 [44:13<6:16:23,  4.30s/it] 13%|â–ˆâ–Ž        | 752/6000 [44:17<6:06:05,  4.19s/it]                                                    {'loss': 0.0209, 'grad_norm': 3.461362600326538, 'learning_rate': 4.447457627118644e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 752/6000 [44:17<6:06:05,  4.19s/it] 13%|â–ˆâ–Ž        | 753/6000 [44:20<5:54:44,  4.06s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.07801875472068787, 'learning_rate': 4.4466101694915256e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 753/6000 [44:20<5:54:44,  4.06s/it] 13%|â–ˆâ–Ž        | 754/6000 [44:24<5:38:59,  3.88s/it]                                                    {'loss': 0.045, 'grad_norm': 3.735990524291992, 'learning_rate': 4.445762711864407e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 754/6000 [44:24<5:38:59,  3.88s/it] 13%|â–ˆâ–Ž        | 755/6000 [44:27<5:24:21,  3.71s/it]                                                    {'loss': 0.0009, 'grad_norm': 0.13139039278030396, 'learning_rate': 4.4449152542372886e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 755/6000 [44:27<5:24:21,  3.71s/it] 13%|â–ˆâ–Ž        | 756/6000 [44:31<5:13:53,  3.59s/it]                                                    {'loss': 0.0195, 'grad_norm': 4.234029769897461, 'learning_rate': 4.44406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 756/6000 [44:31<5:13:53,  3.59s/it] 13%|â–ˆâ–Ž        | 757/6000 [44:34<5:15:44,  3.61s/it]                                                    {'loss': 0.0072, 'grad_norm': 1.5491893291473389, 'learning_rate': 4.4432203389830515e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 757/6000 [44:34<5:15:44,  3.61s/it] 13%|â–ˆâ–Ž        | 758/6000 [44:38<5:12:06,  3.57s/it]                                                    {'loss': 0.0336, 'grad_norm': 7.554325580596924, 'learning_rate': 4.4423728813559326e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 758/6000 [44:38<5:12:06,  3.57s/it] 13%|â–ˆâ–Ž        | 759/6000 [44:41<5:06:38,  3.51s/it]                                                    {'loss': 0.2032, 'grad_norm': 9.601200103759766, 'learning_rate': 4.441525423728814e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 759/6000 [44:41<5:06:38,  3.51s/it] 13%|â–ˆâ–Ž        | 760/6000 [44:44<5:04:05,  3.48s/it]                                                    {'loss': 0.0205, 'grad_norm': 3.7708256244659424, 'learning_rate': 4.440677966101695e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 760/6000 [44:44<5:04:05,  3.48s/it] 13%|â–ˆâ–Ž        | 761/6000 [44:48<5:03:22,  3.47s/it]                                                    {'loss': 0.0501, 'grad_norm': 3.8965353965759277, 'learning_rate': 4.439830508474577e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 761/6000 [44:48<5:03:22,  3.47s/it] 13%|â–ˆâ–Ž        | 762/6000 [44:51<5:06:04,  3.51s/it]                                                    {'loss': 0.1151, 'grad_norm': 7.977245807647705, 'learning_rate': 4.438983050847458e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 762/6000 [44:51<5:06:04,  3.51s/it] 13%|â–ˆâ–Ž        | 763/6000 [44:55<5:01:22,  3.45s/it]                                                    {'loss': 0.145, 'grad_norm': 6.047240734100342, 'learning_rate': 4.4381355932203396e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 763/6000 [44:55<5:01:22,  3.45s/it] 13%|â–ˆâ–Ž        | 764/6000 [44:58<4:58:21,  3.42s/it]                                                    {'loss': 0.0884, 'grad_norm': 7.65450382232666, 'learning_rate': 4.437288135593221e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 764/6000 [44:58<4:58:21,  3.42s/it] 13%|â–ˆâ–Ž        | 765/6000 [45:01<4:56:05,  3.39s/it]                                                    {'loss': 0.0241, 'grad_norm': 3.1255016326904297, 'learning_rate': 4.436440677966102e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 765/6000 [45:01<4:56:05,  3.39s/it] 13%|â–ˆâ–Ž        | 766/6000 [45:05<5:05:36,  3.50s/it]                                                    {'loss': 0.0009, 'grad_norm': 0.17903415858745575, 'learning_rate': 4.435593220338983e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 766/6000 [45:05<5:05:36,  3.50s/it] 13%|â–ˆâ–Ž        | 767/6000 [45:09<5:13:26,  3.59s/it]                                                    {'loss': 0.0035, 'grad_norm': 0.6138113737106323, 'learning_rate': 4.434745762711864e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 767/6000 [45:09<5:13:26,  3.59s/it] 13%|â–ˆâ–Ž        | 768/6000 [45:12<5:08:49,  3.54s/it]                                                    {'loss': 0.0061, 'grad_norm': 0.955247700214386, 'learning_rate': 4.433898305084746e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 768/6000 [45:12<5:08:49,  3.54s/it] 13%|â–ˆâ–Ž        | 769/6000 [45:16<5:12:23,  3.58s/it]                                                    {'loss': 0.0409, 'grad_norm': 2.0380213260650635, 'learning_rate': 4.433050847457627e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 769/6000 [45:16<5:12:23,  3.58s/it] 13%|â–ˆâ–Ž        | 770/6000 [45:20<5:07:27,  3.53s/it]                                                    {'loss': 0.0744, 'grad_norm': 5.510018825531006, 'learning_rate': 4.432203389830509e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 770/6000 [45:20<5:07:27,  3.53s/it] 13%|â–ˆâ–Ž        | 771/6000 [45:23<5:03:49,  3.49s/it]                                                    {'loss': 0.0023, 'grad_norm': 0.328875869512558, 'learning_rate': 4.43135593220339e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 771/6000 [45:23<5:03:49,  3.49s/it] 13%|â–ˆâ–Ž        | 772/6000 [45:26<4:59:31,  3.44s/it]                                                    {'loss': 0.0512, 'grad_norm': 6.653709411621094, 'learning_rate': 4.430508474576272e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 772/6000 [45:26<4:59:31,  3.44s/it] 13%|â–ˆâ–Ž        | 773/6000 [45:30<4:57:26,  3.41s/it]                                                    {'loss': 0.0921, 'grad_norm': 8.241349220275879, 'learning_rate': 4.429661016949152e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 773/6000 [45:30<4:57:26,  3.41s/it] 13%|â–ˆâ–Ž        | 774/6000 [45:33<4:57:22,  3.41s/it]                                                    {'loss': 0.0052, 'grad_norm': 0.5656832456588745, 'learning_rate': 4.428813559322034e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 774/6000 [45:33<4:57:22,  3.41s/it] 13%|â–ˆâ–Ž        | 775/6000 [45:37<5:02:41,  3.48s/it]                                                    {'loss': 0.0034, 'grad_norm': 0.47219517827033997, 'learning_rate': 4.427966101694915e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 775/6000 [45:37<5:02:41,  3.48s/it] 13%|â–ˆâ–Ž        | 776/6000 [45:40<5:02:52,  3.48s/it]                                                    {'loss': 0.0681, 'grad_norm': 7.032652854919434, 'learning_rate': 4.427118644067797e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 776/6000 [45:40<5:02:52,  3.48s/it] 13%|â–ˆâ–Ž        | 777/6000 [45:44<5:08:12,  3.54s/it]                                                    {'loss': 0.0149, 'grad_norm': 2.5691654682159424, 'learning_rate': 4.426271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 777/6000 [45:44<5:08:12,  3.54s/it] 13%|â–ˆâ–Ž        | 778/6000 [45:48<5:12:37,  3.59s/it]                                                    {'loss': 0.0905, 'grad_norm': 2.8892502784729004, 'learning_rate': 4.42542372881356e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 778/6000 [45:48<5:12:37,  3.59s/it] 13%|â–ˆâ–Ž        | 779/6000 [45:51<5:06:42,  3.52s/it]                                                    {'loss': 0.0827, 'grad_norm': 7.5084452629089355, 'learning_rate': 4.424576271186441e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 779/6000 [45:51<5:06:42,  3.52s/it] 13%|â–ˆâ–Ž        | 780/6000 [45:54<5:03:12,  3.49s/it]                                                    {'loss': 0.0492, 'grad_norm': 5.469540596008301, 'learning_rate': 4.423728813559322e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 780/6000 [45:54<5:03:12,  3.49s/it] 13%|â–ˆâ–Ž        | 781/6000 [45:58<5:02:27,  3.48s/it]                                                    {'loss': 0.0695, 'grad_norm': 7.483862400054932, 'learning_rate': 4.422881355932203e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 781/6000 [45:58<5:02:27,  3.48s/it] 13%|â–ˆâ–Ž        | 782/6000 [46:01<4:58:10,  3.43s/it]                                                    {'loss': 0.0798, 'grad_norm': 10.491325378417969, 'learning_rate': 4.422033898305085e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 782/6000 [46:01<4:58:10,  3.43s/it] 13%|â–ˆâ–Ž        | 783/6000 [46:04<4:55:40,  3.40s/it]                                                    {'loss': 0.0283, 'grad_norm': 4.332488059997559, 'learning_rate': 4.421186440677966e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 783/6000 [46:04<4:55:40,  3.40s/it] 13%|â–ˆâ–Ž        | 784/6000 [46:08<4:53:41,  3.38s/it]                                                    {'loss': 0.1447, 'grad_norm': 6.34981107711792, 'learning_rate': 4.420338983050848e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 784/6000 [46:08<4:53:41,  3.38s/it] 13%|â–ˆâ–Ž        | 785/6000 [46:11<4:52:44,  3.37s/it]                                                    {'loss': 0.3782, 'grad_norm': 14.360993385314941, 'learning_rate': 4.419491525423729e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 785/6000 [46:11<4:52:44,  3.37s/it] 13%|â–ˆâ–Ž        | 786/6000 [46:14<4:52:03,  3.36s/it]                                                    {'loss': 0.0326, 'grad_norm': 4.664737224578857, 'learning_rate': 4.41864406779661e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 786/6000 [46:14<4:52:03,  3.36s/it] 13%|â–ˆâ–Ž        | 787/6000 [46:18<4:53:28,  3.38s/it]                                                    {'loss': 0.0114, 'grad_norm': 1.6183618307113647, 'learning_rate': 4.4177966101694914e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 787/6000 [46:18<4:53:28,  3.38s/it] 13%|â–ˆâ–Ž        | 788/6000 [46:21<4:54:17,  3.39s/it]                                                    {'loss': 0.0111, 'grad_norm': 1.129982352256775, 'learning_rate': 4.4169491525423726e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 788/6000 [46:21<4:54:17,  3.39s/it] 13%|â–ˆâ–Ž        | 789/6000 [46:25<4:57:58,  3.43s/it]                                                    {'loss': 0.0602, 'grad_norm': 6.653845310211182, 'learning_rate': 4.4161016949152544e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 789/6000 [46:25<4:57:58,  3.43s/it] 13%|â–ˆâ–Ž        | 790/6000 [46:28<4:54:40,  3.39s/it]                                                    {'loss': 0.0954, 'grad_norm': 5.857333660125732, 'learning_rate': 4.4152542372881355e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 790/6000 [46:28<4:54:40,  3.39s/it] 13%|â–ˆâ–Ž        | 791/6000 [46:31<4:54:51,  3.40s/it]                                                    {'loss': 0.0474, 'grad_norm': 3.8583152294158936, 'learning_rate': 4.414406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 791/6000 [46:31<4:54:51,  3.40s/it] 13%|â–ˆâ–Ž        | 792/6000 [46:35<4:55:21,  3.40s/it]                                                    {'loss': 0.0393, 'grad_norm': 5.397071838378906, 'learning_rate': 4.4135593220338984e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 792/6000 [46:35<4:55:21,  3.40s/it] 13%|â–ˆâ–Ž        | 793/6000 [46:38<4:53:38,  3.38s/it]                                                    {'loss': 0.0042, 'grad_norm': 0.9128631353378296, 'learning_rate': 4.41271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 793/6000 [46:38<4:53:38,  3.38s/it] 13%|â–ˆâ–Ž        | 794/6000 [46:42<4:56:32,  3.42s/it]                                                    {'loss': 0.0385, 'grad_norm': 4.921965599060059, 'learning_rate': 4.4118644067796614e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 794/6000 [46:42<4:56:32,  3.42s/it] 13%|â–ˆâ–Ž        | 795/6000 [46:45<5:05:18,  3.52s/it]                                                    {'loss': 0.0693, 'grad_norm': 7.628490924835205, 'learning_rate': 4.4110169491525425e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 795/6000 [46:45<5:05:18,  3.52s/it] 13%|â–ˆâ–Ž        | 796/6000 [46:49<5:00:48,  3.47s/it]                                                    {'loss': 0.1331, 'grad_norm': 7.011102199554443, 'learning_rate': 4.4101694915254236e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 796/6000 [46:49<5:00:48,  3.47s/it] 13%|â–ˆâ–Ž        | 797/6000 [46:52<5:00:48,  3.47s/it]                                                    {'loss': 0.048, 'grad_norm': 5.37666654586792, 'learning_rate': 4.4093220338983054e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 797/6000 [46:52<5:00:48,  3.47s/it] 13%|â–ˆâ–Ž        | 798/6000 [46:56<4:56:58,  3.43s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.1432833969593048, 'learning_rate': 4.4084745762711866e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 798/6000 [46:56<4:56:58,  3.43s/it] 13%|â–ˆâ–Ž        | 799/6000 [46:59<4:57:20,  3.43s/it]                                                    {'loss': 0.1518, 'grad_norm': 7.894773483276367, 'learning_rate': 4.4076271186440684e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 799/6000 [46:59<4:57:20,  3.43s/it] 13%|â–ˆâ–Ž        | 800/6000 [47:03<4:58:22,  3.44s/it]                                                    {'loss': 0.0314, 'grad_norm': 4.040035247802734, 'learning_rate': 4.4067796610169495e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 800/6000 [47:03<4:58:22,  3.44s/it][2025-10-20 16:16:49,533] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 801/6000 [47:08<5:56:30,  4.11s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.07103390991687775, 'learning_rate': 4.4059322033898306e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 801/6000 [47:08<5:56:30,  4.11s/it] 13%|â–ˆâ–Ž        | 802/6000 [47:12<5:41:27,  3.94s/it]                                                    {'loss': 0.041, 'grad_norm': 6.475236415863037, 'learning_rate': 4.405084745762712e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 802/6000 [47:12<5:41:27,  3.94s/it] 13%|â–ˆâ–Ž        | 803/6000 [47:15<5:24:46,  3.75s/it]                                                    {'loss': 0.1621, 'grad_norm': 5.2793803215026855, 'learning_rate': 4.4042372881355936e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 803/6000 [47:15<5:24:46,  3.75s/it] 13%|â–ˆâ–Ž        | 804/6000 [47:18<5:14:53,  3.64s/it]                                                    {'loss': 0.1663, 'grad_norm': 9.67625617980957, 'learning_rate': 4.403389830508475e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 804/6000 [47:18<5:14:53,  3.64s/it] 13%|â–ˆâ–Ž        | 805/6000 [47:22<5:09:45,  3.58s/it]                                                    {'loss': 0.0094, 'grad_norm': 1.2325612306594849, 'learning_rate': 4.4025423728813565e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 805/6000 [47:22<5:09:45,  3.58s/it] 13%|â–ˆâ–Ž        | 806/6000 [47:25<5:08:47,  3.57s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.07616741955280304, 'learning_rate': 4.4016949152542376e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 806/6000 [47:25<5:08:47,  3.57s/it] 13%|â–ˆâ–Ž        | 807/6000 [47:29<5:03:24,  3.51s/it]                                                    {'loss': 0.0048, 'grad_norm': 1.314816951751709, 'learning_rate': 4.400847457627119e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 807/6000 [47:29<5:03:24,  3.51s/it] 13%|â–ˆâ–Ž        | 808/6000 [47:32<5:00:15,  3.47s/it]                                                    {'loss': 0.0078, 'grad_norm': 1.7423900365829468, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 808/6000 [47:32<5:00:15,  3.47s/it] 13%|â–ˆâ–Ž        | 809/6000 [47:36<4:57:25,  3.44s/it]                                                    {'loss': 0.0008, 'grad_norm': 0.07995988428592682, 'learning_rate': 4.399152542372881e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 809/6000 [47:36<4:57:25,  3.44s/it] 14%|â–ˆâ–Ž        | 810/6000 [47:39<4:58:46,  3.45s/it]                                                    {'loss': 0.4175, 'grad_norm': 11.698171615600586, 'learning_rate': 4.398305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 810/6000 [47:39<4:58:46,  3.45s/it] 14%|â–ˆâ–Ž        | 811/6000 [47:42<4:57:18,  3.44s/it]                                                    {'loss': 0.0294, 'grad_norm': 2.865734338760376, 'learning_rate': 4.397457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 811/6000 [47:42<4:57:18,  3.44s/it] 14%|â–ˆâ–Ž        | 812/6000 [47:46<4:54:23,  3.40s/it]                                                    {'loss': 0.0094, 'grad_norm': 1.6324896812438965, 'learning_rate': 4.396610169491526e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 812/6000 [47:46<4:54:23,  3.40s/it] 14%|â–ˆâ–Ž        | 813/6000 [47:50<5:14:39,  3.64s/it]                                                    {'loss': 0.0923, 'grad_norm': 5.903406620025635, 'learning_rate': 4.395762711864407e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 813/6000 [47:50<5:14:39,  3.64s/it] 14%|â–ˆâ–Ž        | 814/6000 [47:53<5:09:12,  3.58s/it]                                                    {'loss': 0.0424, 'grad_norm': 4.447099208831787, 'learning_rate': 4.394915254237289e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 814/6000 [47:53<5:09:12,  3.58s/it] 14%|â–ˆâ–Ž        | 815/6000 [47:57<5:03:50,  3.52s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.39125341176986694, 'learning_rate': 4.39406779661017e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 815/6000 [47:57<5:03:50,  3.52s/it] 14%|â–ˆâ–Ž        | 816/6000 [48:00<4:58:47,  3.46s/it]                                                    {'loss': 0.1053, 'grad_norm': 9.162288665771484, 'learning_rate': 4.393220338983051e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 816/6000 [48:00<4:58:47,  3.46s/it] 14%|â–ˆâ–Ž        | 817/6000 [48:04<5:18:26,  3.69s/it]                                                    {'loss': 0.1324, 'grad_norm': 8.482536315917969, 'learning_rate': 4.392372881355932e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 817/6000 [48:04<5:18:26,  3.69s/it] 14%|â–ˆâ–Ž        | 818/6000 [48:08<5:11:03,  3.60s/it]                                                    {'loss': 0.0141, 'grad_norm': 2.6720902919769287, 'learning_rate': 4.391525423728814e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 818/6000 [48:08<5:11:03,  3.60s/it] 14%|â–ˆâ–Ž        | 819/6000 [48:11<5:07:36,  3.56s/it]                                                    {'loss': 0.0572, 'grad_norm': 4.125397682189941, 'learning_rate': 4.390677966101695e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 819/6000 [48:11<5:07:36,  3.56s/it] 14%|â–ˆâ–Ž        | 820/6000 [48:15<5:03:35,  3.52s/it]                                                    {'loss': 0.0178, 'grad_norm': 2.3017385005950928, 'learning_rate': 4.389830508474577e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 820/6000 [48:15<5:03:35,  3.52s/it] 14%|â–ˆâ–Ž        | 821/6000 [48:18<5:03:04,  3.51s/it]                                                    {'loss': 0.0034, 'grad_norm': 0.5463200807571411, 'learning_rate': 4.388983050847458e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 821/6000 [48:18<5:03:04,  3.51s/it] 14%|â–ˆâ–Ž        | 822/6000 [48:21<4:59:16,  3.47s/it]                                                    {'loss': 0.0023, 'grad_norm': 0.5223298072814941, 'learning_rate': 4.388135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 822/6000 [48:21<4:59:16,  3.47s/it] 14%|â–ˆâ–Ž        | 823/6000 [48:25<4:57:00,  3.44s/it]                                                    {'loss': 0.0511, 'grad_norm': 5.136628150939941, 'learning_rate': 4.38728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 823/6000 [48:25<4:57:00,  3.44s/it] 14%|â–ˆâ–Ž        | 824/6000 [48:28<4:54:06,  3.41s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.05346399545669556, 'learning_rate': 4.386440677966102e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 824/6000 [48:28<4:54:06,  3.41s/it] 14%|â–ˆâ–        | 825/6000 [48:32<4:59:49,  3.48s/it]                                                    {'loss': 0.1007, 'grad_norm': 6.663735866546631, 'learning_rate': 4.385593220338983e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 825/6000 [48:32<4:59:49,  3.48s/it] 14%|â–ˆâ–        | 826/6000 [48:35<4:56:28,  3.44s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.06409004330635071, 'learning_rate': 4.384745762711865e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 826/6000 [48:35<4:56:28,  3.44s/it] 14%|â–ˆâ–        | 827/6000 [48:38<4:54:03,  3.41s/it]                                                    {'loss': 0.0361, 'grad_norm': 4.989660739898682, 'learning_rate': 4.383898305084746e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 827/6000 [48:38<4:54:03,  3.41s/it] 14%|â–ˆâ–        | 828/6000 [48:42<4:54:06,  3.41s/it]                                                    {'loss': 0.4079, 'grad_norm': 11.04621410369873, 'learning_rate': 4.383050847457627e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 828/6000 [48:42<4:54:06,  3.41s/it] 14%|â–ˆâ–        | 829/6000 [48:45<4:55:12,  3.43s/it]                                                    {'loss': 0.0725, 'grad_norm': 1.654452919960022, 'learning_rate': 4.382203389830509e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 829/6000 [48:45<4:55:12,  3.43s/it] 14%|â–ˆâ–        | 830/6000 [48:50<5:19:19,  3.71s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.0937872976064682, 'learning_rate': 4.38135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 830/6000 [48:50<5:19:19,  3.71s/it] 14%|â–ˆâ–        | 831/6000 [48:53<5:14:21,  3.65s/it]                                                    {'loss': 0.0436, 'grad_norm': 6.6944451332092285, 'learning_rate': 4.380508474576271e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 831/6000 [48:53<5:14:21,  3.65s/it] 14%|â–ˆâ–        | 832/6000 [48:57<5:06:58,  3.56s/it]                                                    {'loss': 0.1587, 'grad_norm': 10.399407386779785, 'learning_rate': 4.3796610169491524e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 832/6000 [48:57<5:06:58,  3.56s/it] 14%|â–ˆâ–        | 833/6000 [49:00<5:00:45,  3.49s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.5775259733200073, 'learning_rate': 4.378813559322034e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 833/6000 [49:00<5:00:45,  3.49s/it] 14%|â–ˆâ–        | 834/6000 [49:03<4:57:08,  3.45s/it]                                                    {'loss': 0.0563, 'grad_norm': 5.229254722595215, 'learning_rate': 4.377966101694915e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 834/6000 [49:03<4:57:08,  3.45s/it] 14%|â–ˆâ–        | 835/6000 [49:07<5:08:17,  3.58s/it]                                                    {'loss': 0.0158, 'grad_norm': 2.178380012512207, 'learning_rate': 4.377118644067797e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 835/6000 [49:07<5:08:17,  3.58s/it] 14%|â–ˆâ–        | 836/6000 [49:10<5:00:37,  3.49s/it]                                                    {'loss': 0.1123, 'grad_norm': 8.005446434020996, 'learning_rate': 4.376271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 836/6000 [49:10<5:00:37,  3.49s/it] 14%|â–ˆâ–        | 837/6000 [49:15<5:24:31,  3.77s/it]                                                    {'loss': 0.0438, 'grad_norm': 5.761866569519043, 'learning_rate': 4.3754237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 837/6000 [49:15<5:24:31,  3.77s/it] 14%|â–ˆâ–        | 838/6000 [49:19<5:26:11,  3.79s/it]                                                    {'loss': 0.0946, 'grad_norm': 9.403032302856445, 'learning_rate': 4.3745762711864405e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 838/6000 [49:19<5:26:11,  3.79s/it] 14%|â–ˆâ–        | 839/6000 [49:22<5:16:34,  3.68s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.360233873128891, 'learning_rate': 4.373728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 839/6000 [49:22<5:16:34,  3.68s/it] 14%|â–ˆâ–        | 840/6000 [49:26<5:11:22,  3.62s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.0196760855615139, 'learning_rate': 4.3728813559322035e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 840/6000 [49:26<5:11:22,  3.62s/it] 14%|â–ˆâ–        | 841/6000 [49:29<5:18:03,  3.70s/it]                                                    {'loss': 0.0492, 'grad_norm': 5.098117351531982, 'learning_rate': 4.372033898305085e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 841/6000 [49:29<5:18:03,  3.70s/it] 14%|â–ˆâ–        | 842/6000 [49:33<5:09:47,  3.60s/it]                                                    {'loss': 0.0629, 'grad_norm': 6.665890693664551, 'learning_rate': 4.3711864406779664e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 842/6000 [49:33<5:09:47,  3.60s/it] 14%|â–ˆâ–        | 843/6000 [49:36<5:01:32,  3.51s/it]                                                    {'loss': 0.016, 'grad_norm': 2.7880499362945557, 'learning_rate': 4.370338983050848e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 843/6000 [49:36<5:01:32,  3.51s/it] 14%|â–ˆâ–        | 844/6000 [49:40<5:06:46,  3.57s/it]                                                    {'loss': 0.0208, 'grad_norm': 3.6122231483459473, 'learning_rate': 4.3694915254237286e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 844/6000 [49:40<5:06:46,  3.57s/it] 14%|â–ˆâ–        | 845/6000 [49:43<5:00:47,  3.50s/it]                                                    {'loss': 0.0121, 'grad_norm': 1.614271879196167, 'learning_rate': 4.3686440677966105e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 845/6000 [49:43<5:00:47,  3.50s/it] 14%|â–ˆâ–        | 846/6000 [49:47<4:59:02,  3.48s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.4026761054992676, 'learning_rate': 4.3677966101694916e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 846/6000 [49:47<4:59:02,  3.48s/it] 14%|â–ˆâ–        | 847/6000 [49:50<4:56:42,  3.45s/it]                                                    {'loss': 0.0541, 'grad_norm': 3.5344491004943848, 'learning_rate': 4.3669491525423734e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 847/6000 [49:50<4:56:42,  3.45s/it] 14%|â–ˆâ–        | 848/6000 [49:54<5:07:19,  3.58s/it]                                                    {'loss': 0.0824, 'grad_norm': 3.498502254486084, 'learning_rate': 4.3661016949152545e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 848/6000 [49:54<5:07:19,  3.58s/it] 14%|â–ˆâ–        | 849/6000 [49:57<5:05:35,  3.56s/it]                                                    {'loss': 0.0261, 'grad_norm': 3.340815782546997, 'learning_rate': 4.3652542372881356e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 849/6000 [49:57<5:05:35,  3.56s/it] 14%|â–ˆâ–        | 850/6000 [50:01<5:02:17,  3.52s/it]                                                    {'loss': 0.0183, 'grad_norm': 1.841174602508545, 'learning_rate': 4.3644067796610175e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 850/6000 [50:01<5:02:17,  3.52s/it][2025-10-20 16:19:47,842] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 14%|â–ˆâ–        | 851/6000 [50:07<6:01:51,  4.22s/it]                                                    {'loss': 0.0767, 'grad_norm': 5.970950126647949, 'learning_rate': 4.3635593220338986e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 851/6000 [50:07<6:01:51,  4.22s/it] 14%|â–ˆâ–        | 852/6000 [50:10<5:40:11,  3.96s/it]                                                    {'loss': 0.1581, 'grad_norm': 7.858361721038818, 'learning_rate': 4.36271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 852/6000 [50:10<5:40:11,  3.96s/it] 14%|â–ˆâ–        | 853/6000 [50:13<5:24:42,  3.79s/it]                                                    {'loss': 0.0076, 'grad_norm': 1.0707919597625732, 'learning_rate': 4.361864406779661e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 853/6000 [50:13<5:24:42,  3.79s/it] 14%|â–ˆâ–        | 854/6000 [50:17<5:16:09,  3.69s/it]                                                    {'loss': 0.0172, 'grad_norm': 2.398203134536743, 'learning_rate': 4.3610169491525426e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 854/6000 [50:17<5:16:09,  3.69s/it] 14%|â–ˆâ–        | 855/6000 [50:20<5:09:11,  3.61s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.286676287651062, 'learning_rate': 4.360169491525424e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 855/6000 [50:20<5:09:11,  3.61s/it] 14%|â–ˆâ–        | 856/6000 [50:24<5:07:14,  3.58s/it]                                                    {'loss': 0.1725, 'grad_norm': 9.337059020996094, 'learning_rate': 4.3593220338983056e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 856/6000 [50:24<5:07:14,  3.58s/it] 14%|â–ˆâ–        | 857/6000 [50:27<5:00:20,  3.50s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.26682794094085693, 'learning_rate': 4.358474576271187e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 857/6000 [50:27<5:00:20,  3.50s/it] 14%|â–ˆâ–        | 858/6000 [50:31<4:56:53,  3.46s/it]                                                    {'loss': 0.0175, 'grad_norm': 1.4961689710617065, 'learning_rate': 4.357627118644068e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 858/6000 [50:31<4:56:53,  3.46s/it] 14%|â–ˆâ–        | 859/6000 [50:34<4:53:28,  3.43s/it]                                                    {'loss': 0.0044, 'grad_norm': 0.6451484560966492, 'learning_rate': 4.356779661016949e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 859/6000 [50:34<4:53:28,  3.43s/it] 14%|â–ˆâ–        | 860/6000 [50:38<5:04:13,  3.55s/it]                                                    {'loss': 0.1611, 'grad_norm': 7.676370620727539, 'learning_rate': 4.355932203389831e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 860/6000 [50:38<5:04:13,  3.55s/it] 14%|â–ˆâ–        | 861/6000 [50:41<4:59:03,  3.49s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.5380420684814453, 'learning_rate': 4.355084745762712e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 861/6000 [50:41<4:59:03,  3.49s/it] 14%|â–ˆâ–        | 862/6000 [50:44<4:55:41,  3.45s/it]                                                    {'loss': 0.1541, 'grad_norm': 10.508533477783203, 'learning_rate': 4.354237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 862/6000 [50:44<4:55:41,  3.45s/it] 14%|â–ˆâ–        | 863/6000 [50:48<4:56:14,  3.46s/it]                                                    {'loss': 0.0233, 'grad_norm': 3.5021932125091553, 'learning_rate': 4.353389830508475e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 863/6000 [50:48<4:56:14,  3.46s/it] 14%|â–ˆâ–        | 864/6000 [50:51<4:54:19,  3.44s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.025154059752821922, 'learning_rate': 4.3525423728813566e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 864/6000 [50:51<4:54:19,  3.44s/it] 14%|â–ˆâ–        | 865/6000 [50:55<5:03:06,  3.54s/it]                                                    {'loss': 0.1698, 'grad_norm': 9.943557739257812, 'learning_rate': 4.351694915254238e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 865/6000 [50:55<5:03:06,  3.54s/it] 14%|â–ˆâ–        | 866/6000 [50:58<4:58:56,  3.49s/it]                                                    {'loss': 0.083, 'grad_norm': 8.022388458251953, 'learning_rate': 4.350847457627119e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 866/6000 [50:58<4:58:56,  3.49s/it] 14%|â–ˆâ–        | 867/6000 [51:02<4:57:51,  3.48s/it]                                                    {'loss': 0.3522, 'grad_norm': 10.767074584960938, 'learning_rate': 4.35e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 867/6000 [51:02<4:57:51,  3.48s/it] 14%|â–ˆâ–        | 868/6000 [51:05<4:53:17,  3.43s/it]                                                    {'loss': 0.1724, 'grad_norm': 8.638251304626465, 'learning_rate': 4.349152542372882e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 868/6000 [51:05<4:53:17,  3.43s/it] 14%|â–ˆâ–        | 869/6000 [51:09<4:51:45,  3.41s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.13690690696239471, 'learning_rate': 4.348305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 869/6000 [51:09<4:51:45,  3.41s/it] 14%|â–ˆâ–        | 870/6000 [51:12<4:51:06,  3.40s/it]                                                    {'loss': 0.0416, 'grad_norm': 4.135385513305664, 'learning_rate': 4.347457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 870/6000 [51:12<4:51:06,  3.40s/it] 15%|â–ˆâ–        | 871/6000 [51:15<4:52:22,  3.42s/it]                                                    {'loss': 0.0206, 'grad_norm': 3.4361376762390137, 'learning_rate': 4.346610169491526e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 871/6000 [51:15<4:52:22,  3.42s/it] 15%|â–ˆâ–        | 872/6000 [51:19<4:53:04,  3.43s/it]                                                    {'loss': 0.1322, 'grad_norm': 7.9420576095581055, 'learning_rate': 4.345762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 872/6000 [51:19<4:53:04,  3.43s/it] 15%|â–ˆâ–        | 873/6000 [51:22<4:54:24,  3.45s/it]                                                    {'loss': 0.1145, 'grad_norm': 7.887545108795166, 'learning_rate': 4.344915254237288e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 873/6000 [51:22<4:54:24,  3.45s/it] 15%|â–ˆâ–        | 874/6000 [51:26<4:52:18,  3.42s/it]                                                    {'loss': 0.1254, 'grad_norm': 8.486478805541992, 'learning_rate': 4.344067796610169e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 874/6000 [51:26<4:52:18,  3.42s/it] 15%|â–ˆâ–        | 875/6000 [51:29<4:59:27,  3.51s/it]                                                    {'loss': 0.1407, 'grad_norm': 9.621004104614258, 'learning_rate': 4.343220338983051e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 875/6000 [51:29<4:59:27,  3.51s/it] 15%|â–ˆâ–        | 876/6000 [51:33<4:56:15,  3.47s/it]                                                    {'loss': 0.0158, 'grad_norm': 2.6431963443756104, 'learning_rate': 4.342372881355932e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 876/6000 [51:33<4:56:15,  3.47s/it] 15%|â–ˆâ–        | 877/6000 [51:36<4:55:36,  3.46s/it]                                                    {'loss': 0.172, 'grad_norm': 9.753035545349121, 'learning_rate': 4.341525423728814e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 877/6000 [51:36<4:55:36,  3.46s/it] 15%|â–ˆâ–        | 878/6000 [51:40<4:54:40,  3.45s/it]                                                    {'loss': 0.0462, 'grad_norm': 5.141143798828125, 'learning_rate': 4.340677966101695e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 878/6000 [51:40<4:54:40,  3.45s/it] 15%|â–ˆâ–        | 879/6000 [51:44<5:07:25,  3.60s/it]                                                    {'loss': 0.0849, 'grad_norm': 4.821645259857178, 'learning_rate': 4.339830508474576e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 879/6000 [51:44<5:07:25,  3.60s/it] 15%|â–ˆâ–        | 880/6000 [51:47<5:02:48,  3.55s/it]                                                    {'loss': 0.3559, 'grad_norm': 13.95379638671875, 'learning_rate': 4.3389830508474574e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 880/6000 [51:47<5:02:48,  3.55s/it] 15%|â–ˆâ–        | 881/6000 [51:50<4:58:45,  3.50s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.11610029637813568, 'learning_rate': 4.338135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 881/6000 [51:50<4:58:45,  3.50s/it] 15%|â–ˆâ–        | 882/6000 [51:54<4:59:13,  3.51s/it]                                                    {'loss': 0.0313, 'grad_norm': 3.5069358348846436, 'learning_rate': 4.3372881355932203e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 882/6000 [51:54<4:59:13,  3.51s/it] 15%|â–ˆâ–        | 883/6000 [51:57<4:56:47,  3.48s/it]                                                    {'loss': 0.027, 'grad_norm': 2.77885103225708, 'learning_rate': 4.336440677966102e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 883/6000 [51:57<4:56:47,  3.48s/it] 15%|â–ˆâ–        | 884/6000 [52:01<5:01:52,  3.54s/it]                                                    {'loss': 0.1208, 'grad_norm': 7.34416389465332, 'learning_rate': 4.335593220338983e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 884/6000 [52:01<5:01:52,  3.54s/it] 15%|â–ˆâ–        | 885/6000 [52:05<4:59:53,  3.52s/it]                                                    {'loss': 0.0167, 'grad_norm': 4.016027927398682, 'learning_rate': 4.334745762711865e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 885/6000 [52:05<4:59:53,  3.52s/it] 15%|â–ˆâ–        | 886/6000 [52:08<4:59:55,  3.52s/it]                                                    {'loss': 0.0572, 'grad_norm': 7.057415008544922, 'learning_rate': 4.333898305084746e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 886/6000 [52:08<4:59:55,  3.52s/it] 15%|â–ˆâ–        | 887/6000 [52:12<4:59:57,  3.52s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.572288990020752, 'learning_rate': 4.3330508474576273e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 887/6000 [52:12<4:59:57,  3.52s/it] 15%|â–ˆâ–        | 888/6000 [52:15<5:00:08,  3.52s/it]                                                    {'loss': 0.0046, 'grad_norm': 0.59205162525177, 'learning_rate': 4.3322033898305085e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 888/6000 [52:15<5:00:08,  3.52s/it] 15%|â–ˆâ–        | 889/6000 [52:19<4:57:35,  3.49s/it]                                                    {'loss': 0.1411, 'grad_norm': 8.137090682983398, 'learning_rate': 4.33135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 889/6000 [52:19<4:57:35,  3.49s/it] 15%|â–ˆâ–        | 890/6000 [52:22<4:55:35,  3.47s/it]                                                    {'loss': 0.009, 'grad_norm': 1.1806349754333496, 'learning_rate': 4.3305084745762714e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 890/6000 [52:22<4:55:35,  3.47s/it] 15%|â–ˆâ–        | 891/6000 [52:25<4:51:28,  3.42s/it]                                                    {'loss': 0.0293, 'grad_norm': 2.3625543117523193, 'learning_rate': 4.3296610169491525e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 891/6000 [52:25<4:51:28,  3.42s/it] 15%|â–ˆâ–        | 892/6000 [52:29<4:50:33,  3.41s/it]                                                    {'loss': 0.0876, 'grad_norm': 5.877362251281738, 'learning_rate': 4.3288135593220343e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 892/6000 [52:29<4:50:33,  3.41s/it] 15%|â–ˆâ–        | 893/6000 [52:32<4:49:06,  3.40s/it]                                                    {'loss': 0.1557, 'grad_norm': 8.799027442932129, 'learning_rate': 4.3279661016949155e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 893/6000 [52:32<4:49:06,  3.40s/it] 15%|â–ˆâ–        | 894/6000 [52:35<4:51:14,  3.42s/it]                                                    {'loss': 0.0116, 'grad_norm': 1.242377519607544, 'learning_rate': 4.3271186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 894/6000 [52:36<4:51:14,  3.42s/it] 15%|â–ˆâ–        | 895/6000 [52:39<4:48:47,  3.39s/it]                                                    {'loss': 0.031, 'grad_norm': 3.3725156784057617, 'learning_rate': 4.326271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 895/6000 [52:39<4:48:47,  3.39s/it] 15%|â–ˆâ–        | 896/6000 [52:42<4:48:37,  3.39s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.023172983899712563, 'learning_rate': 4.3254237288135595e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 896/6000 [52:42<4:48:37,  3.39s/it] 15%|â–ˆâ–        | 897/6000 [52:46<4:48:54,  3.40s/it]                                                    {'loss': 0.0231, 'grad_norm': 2.487532377243042, 'learning_rate': 4.3245762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 897/6000 [52:46<4:48:54,  3.40s/it] 15%|â–ˆâ–        | 898/6000 [52:49<4:47:39,  3.38s/it]                                                    {'loss': 0.1046, 'grad_norm': 4.794072151184082, 'learning_rate': 4.3237288135593225e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 898/6000 [52:49<4:47:39,  3.38s/it] 15%|â–ˆâ–        | 899/6000 [52:53<5:10:25,  3.65s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.1375790238380432, 'learning_rate': 4.3228813559322036e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 899/6000 [52:53<5:10:25,  3.65s/it] 15%|â–ˆâ–Œ        | 900/6000 [52:57<5:06:14,  3.60s/it]                                                    {'loss': 0.0882, 'grad_norm': 6.466819763183594, 'learning_rate': 4.3220338983050854e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 900/6000 [52:57<5:06:14,  3.60s/it][2025-10-20 16:22:43,730] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|â–ˆâ–Œ        | 901/6000 [53:03<6:06:25,  4.31s/it]                                                    {'loss': 0.0759, 'grad_norm': 7.98574686050415, 'learning_rate': 4.321186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 901/6000 [53:03<6:06:25,  4.31s/it] 15%|â–ˆâ–Œ        | 902/6000 [53:06<5:41:02,  4.01s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.1714104562997818, 'learning_rate': 4.3203389830508477e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 902/6000 [53:06<5:41:02,  4.01s/it] 15%|â–ˆâ–Œ        | 903/6000 [53:09<5:25:19,  3.83s/it]                                                    {'loss': 0.0769, 'grad_norm': 3.6260406970977783, 'learning_rate': 4.319491525423729e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 903/6000 [53:09<5:25:19,  3.83s/it] 15%|â–ˆâ–Œ        | 904/6000 [53:13<5:15:16,  3.71s/it]                                                    {'loss': 0.2489, 'grad_norm': 6.916816234588623, 'learning_rate': 4.3186440677966106e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 904/6000 [53:13<5:15:16,  3.71s/it] 15%|â–ˆâ–Œ        | 905/6000 [53:17<5:24:28,  3.82s/it]                                                    {'loss': 0.0777, 'grad_norm': 7.720898151397705, 'learning_rate': 4.317796610169492e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 905/6000 [53:17<5:24:28,  3.82s/it] 15%|â–ˆâ–Œ        | 906/6000 [53:21<5:18:49,  3.76s/it]                                                    {'loss': 0.0132, 'grad_norm': 2.147778034210205, 'learning_rate': 4.3169491525423735e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 906/6000 [53:21<5:18:49,  3.76s/it] 15%|â–ˆâ–Œ        | 907/6000 [53:24<5:20:38,  3.78s/it]                                                    {'loss': 0.149, 'grad_norm': 5.5714263916015625, 'learning_rate': 4.3161016949152547e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 907/6000 [53:24<5:20:38,  3.78s/it] 15%|â–ˆâ–Œ        | 908/6000 [53:28<5:20:00,  3.77s/it]                                                    {'loss': 0.1432, 'grad_norm': 7.78866720199585, 'learning_rate': 4.315254237288136e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 908/6000 [53:28<5:20:00,  3.77s/it] 15%|â–ˆâ–Œ        | 909/6000 [53:31<5:09:24,  3.65s/it]                                                    {'loss': 0.0392, 'grad_norm': 4.356975555419922, 'learning_rate': 4.314406779661017e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 909/6000 [53:31<5:09:24,  3.65s/it] 15%|â–ˆâ–Œ        | 910/6000 [53:35<5:03:20,  3.58s/it]                                                    {'loss': 0.0084, 'grad_norm': 1.2629215717315674, 'learning_rate': 4.313559322033899e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 910/6000 [53:35<5:03:20,  3.58s/it] 15%|â–ˆâ–Œ        | 911/6000 [53:38<5:00:19,  3.54s/it]                                                    {'loss': 0.0872, 'grad_norm': 7.853867530822754, 'learning_rate': 4.31271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 911/6000 [53:38<5:00:19,  3.54s/it] 15%|â–ˆâ–Œ        | 912/6000 [53:42<4:56:57,  3.50s/it]                                                    {'loss': 0.0317, 'grad_norm': 3.962097644805908, 'learning_rate': 4.311864406779661e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 912/6000 [53:42<4:56:57,  3.50s/it] 15%|â–ˆâ–Œ        | 913/6000 [53:45<4:51:53,  3.44s/it]                                                    {'loss': 0.0197, 'grad_norm': 1.1432950496673584, 'learning_rate': 4.311016949152543e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 913/6000 [53:45<4:51:53,  3.44s/it] 15%|â–ˆâ–Œ        | 914/6000 [53:49<5:02:00,  3.56s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.7977123856544495, 'learning_rate': 4.310169491525424e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 914/6000 [53:49<5:02:00,  3.56s/it] 15%|â–ˆâ–Œ        | 915/6000 [53:53<5:21:30,  3.79s/it]                                                    {'loss': 0.0701, 'grad_norm': 3.2932701110839844, 'learning_rate': 4.309322033898305e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 915/6000 [53:53<5:21:30,  3.79s/it] 15%|â–ˆâ–Œ        | 916/6000 [53:57<5:11:48,  3.68s/it]                                                    {'loss': 0.0475, 'grad_norm': 3.8311357498168945, 'learning_rate': 4.308474576271186e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 916/6000 [53:57<5:11:48,  3.68s/it] 15%|â–ˆâ–Œ        | 917/6000 [54:00<5:03:42,  3.58s/it]                                                    {'loss': 0.0037, 'grad_norm': 0.5813287496566772, 'learning_rate': 4.307627118644068e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 917/6000 [54:00<5:03:42,  3.58s/it] 15%|â–ˆâ–Œ        | 918/6000 [54:03<4:58:19,  3.52s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.6235091686248779, 'learning_rate': 4.306779661016949e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 918/6000 [54:03<4:58:19,  3.52s/it] 15%|â–ˆâ–Œ        | 919/6000 [54:07<4:56:01,  3.50s/it]                                                    {'loss': 0.0836, 'grad_norm': 3.2067220211029053, 'learning_rate': 4.305932203389831e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 919/6000 [54:07<4:56:01,  3.50s/it] 15%|â–ˆâ–Œ        | 920/6000 [54:10<4:59:19,  3.54s/it]                                                    {'loss': 0.0281, 'grad_norm': 4.263150691986084, 'learning_rate': 4.305084745762712e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 920/6000 [54:11<4:59:19,  3.54s/it] 15%|â–ˆâ–Œ        | 921/6000 [54:14<5:02:44,  3.58s/it]                                                    {'loss': 0.1856, 'grad_norm': 7.0975022315979, 'learning_rate': 4.304237288135594e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 921/6000 [54:14<5:02:44,  3.58s/it] 15%|â–ˆâ–Œ        | 922/6000 [54:18<4:59:20,  3.54s/it]                                                    {'loss': 0.0065, 'grad_norm': 0.90778648853302, 'learning_rate': 4.303389830508475e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 922/6000 [54:18<4:59:20,  3.54s/it] 15%|â–ˆâ–Œ        | 923/6000 [54:21<4:56:29,  3.50s/it]                                                    {'loss': 0.0501, 'grad_norm': 3.6500089168548584, 'learning_rate': 4.302542372881356e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 923/6000 [54:21<4:56:29,  3.50s/it] 15%|â–ˆâ–Œ        | 924/6000 [54:24<4:51:14,  3.44s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.1713029444217682, 'learning_rate': 4.301694915254237e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 924/6000 [54:24<4:51:14,  3.44s/it] 15%|â–ˆâ–Œ        | 925/6000 [54:28<4:49:20,  3.42s/it]                                                    {'loss': 0.045, 'grad_norm': 4.210811138153076, 'learning_rate': 4.300847457627119e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 925/6000 [54:28<4:49:20,  3.42s/it] 15%|â–ˆâ–Œ        | 926/6000 [54:31<4:52:24,  3.46s/it]                                                    {'loss': 0.1335, 'grad_norm': 10.62904167175293, 'learning_rate': 4.3e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 926/6000 [54:31<4:52:24,  3.46s/it] 15%|â–ˆâ–Œ        | 927/6000 [54:35<4:49:14,  3.42s/it]                                                    {'loss': 0.2385, 'grad_norm': 7.812496662139893, 'learning_rate': 4.299152542372882e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 927/6000 [54:35<4:49:14,  3.42s/it] 15%|â–ˆâ–Œ        | 928/6000 [54:38<4:49:01,  3.42s/it]                                                    {'loss': 0.1008, 'grad_norm': 6.877840518951416, 'learning_rate': 4.298305084745763e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 928/6000 [54:38<4:49:01,  3.42s/it] 15%|â–ˆâ–Œ        | 929/6000 [54:41<4:50:37,  3.44s/it]                                                    {'loss': 0.0466, 'grad_norm': 4.300449371337891, 'learning_rate': 4.297457627118644e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 929/6000 [54:41<4:50:37,  3.44s/it] 16%|â–ˆâ–Œ        | 930/6000 [54:45<4:49:10,  3.42s/it]                                                    {'loss': 0.2321, 'grad_norm': 8.637007713317871, 'learning_rate': 4.2966101694915254e-05, 'epoch': 0.15}
 16%|â–ˆâ–Œ        | 930/6000 [54:45<4:49:10,  3.42s/it] 16%|â–ˆâ–Œ        | 931/6000 [54:48<4:48:23,  3.41s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.0167162418365479, 'learning_rate': 4.2957627118644065e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 931/6000 [54:48<4:48:23,  3.41s/it] 16%|â–ˆâ–Œ        | 932/6000 [54:52<4:48:38,  3.42s/it]                                                    {'loss': 0.0036, 'grad_norm': 0.3588973879814148, 'learning_rate': 4.294915254237288e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 932/6000 [54:52<4:48:38,  3.42s/it] 16%|â–ˆâ–Œ        | 933/6000 [54:55<4:47:00,  3.40s/it]                                                    {'loss': 0.0138, 'grad_norm': 3.132556200027466, 'learning_rate': 4.2940677966101694e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 933/6000 [54:55<4:47:00,  3.40s/it] 16%|â–ˆâ–Œ        | 934/6000 [54:59<4:58:55,  3.54s/it]                                                    {'loss': 0.0461, 'grad_norm': 4.093594074249268, 'learning_rate': 4.293220338983051e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 934/6000 [54:59<4:58:55,  3.54s/it] 16%|â–ˆâ–Œ        | 935/6000 [55:02<4:54:22,  3.49s/it]                                                    {'loss': 0.006, 'grad_norm': 0.43092969059944153, 'learning_rate': 4.2923728813559324e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 935/6000 [55:02<4:54:22,  3.49s/it] 16%|â–ˆâ–Œ        | 936/6000 [55:06<4:50:42,  3.44s/it]                                                    {'loss': 0.0745, 'grad_norm': 6.660849094390869, 'learning_rate': 4.291525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 936/6000 [55:06<4:50:42,  3.44s/it] 16%|â–ˆâ–Œ        | 937/6000 [55:09<4:50:46,  3.45s/it]                                                    {'loss': 0.0477, 'grad_norm': 4.689648628234863, 'learning_rate': 4.2906779661016946e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 937/6000 [55:09<4:50:46,  3.45s/it] 16%|â–ˆâ–Œ        | 938/6000 [55:12<4:50:08,  3.44s/it]                                                    {'loss': 0.0047, 'grad_norm': 0.8717057108879089, 'learning_rate': 4.2898305084745764e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 938/6000 [55:12<4:50:08,  3.44s/it] 16%|â–ˆâ–Œ        | 939/6000 [55:16<4:51:13,  3.45s/it]                                                    {'loss': 0.0132, 'grad_norm': 1.6533857583999634, 'learning_rate': 4.2889830508474575e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 939/6000 [55:16<4:51:13,  3.45s/it] 16%|â–ˆâ–Œ        | 940/6000 [55:19<4:49:53,  3.44s/it]                                                    {'loss': 0.0021, 'grad_norm': 0.29288429021835327, 'learning_rate': 4.2881355932203394e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 940/6000 [55:19<4:49:53,  3.44s/it] 16%|â–ˆâ–Œ        | 941/6000 [55:23<5:05:51,  3.63s/it]                                                    {'loss': 0.0104, 'grad_norm': 1.9366438388824463, 'learning_rate': 4.2872881355932205e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 941/6000 [55:23<5:05:51,  3.63s/it] 16%|â–ˆâ–Œ        | 942/6000 [55:27<4:59:15,  3.55s/it]                                                    {'loss': 0.0718, 'grad_norm': 10.670615196228027, 'learning_rate': 4.286440677966102e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 942/6000 [55:27<4:59:15,  3.55s/it] 16%|â–ˆâ–Œ        | 943/6000 [55:30<4:56:44,  3.52s/it]                                                    {'loss': 0.0121, 'grad_norm': 1.6636440753936768, 'learning_rate': 4.2855932203389834e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 943/6000 [55:30<4:56:44,  3.52s/it] 16%|â–ˆâ–Œ        | 944/6000 [55:34<4:53:19,  3.48s/it]                                                    {'loss': 0.037, 'grad_norm': 1.9218087196350098, 'learning_rate': 4.2847457627118645e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 944/6000 [55:34<4:53:19,  3.48s/it] 16%|â–ˆâ–Œ        | 945/6000 [55:37<4:59:53,  3.56s/it]                                                    {'loss': 0.1545, 'grad_norm': 9.126324653625488, 'learning_rate': 4.283898305084746e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 945/6000 [55:37<4:59:53,  3.56s/it] 16%|â–ˆâ–Œ        | 946/6000 [55:41<4:56:12,  3.52s/it]                                                    {'loss': 0.0341, 'grad_norm': 4.95196008682251, 'learning_rate': 4.2830508474576275e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 946/6000 [55:41<4:56:12,  3.52s/it] 16%|â–ˆâ–Œ        | 947/6000 [55:44<4:52:56,  3.48s/it]                                                    {'loss': 0.0907, 'grad_norm': 4.941071510314941, 'learning_rate': 4.2822033898305086e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 947/6000 [55:44<4:52:56,  3.48s/it] 16%|â–ˆâ–Œ        | 948/6000 [55:48<4:56:08,  3.52s/it]                                                    {'loss': 0.136, 'grad_norm': 9.382210731506348, 'learning_rate': 4.2813559322033904e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 948/6000 [55:48<4:56:08,  3.52s/it] 16%|â–ˆâ–Œ        | 949/6000 [55:52<5:04:01,  3.61s/it]                                                    {'loss': 0.065, 'grad_norm': 7.279062747955322, 'learning_rate': 4.2805084745762715e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 949/6000 [55:52<5:04:01,  3.61s/it] 16%|â–ˆâ–Œ        | 950/6000 [55:55<5:00:26,  3.57s/it]                                                    {'loss': 0.0085, 'grad_norm': 1.7008651494979858, 'learning_rate': 4.279661016949153e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 950/6000 [55:55<5:00:26,  3.57s/it][2025-10-20 16:25:42,074] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 16%|â–ˆâ–Œ        | 951/6000 [56:01<5:51:01,  4.17s/it]                                                    {'loss': 0.0447, 'grad_norm': 3.262840747833252, 'learning_rate': 4.278813559322034e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 951/6000 [56:01<5:51:01,  4.17s/it] 16%|â–ˆâ–Œ        | 952/6000 [56:04<5:30:43,  3.93s/it]                                                    {'loss': 0.1696, 'grad_norm': 7.041541576385498, 'learning_rate': 4.277966101694915e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 952/6000 [56:04<5:30:43,  3.93s/it] 16%|â–ˆâ–Œ        | 953/6000 [56:08<5:21:30,  3.82s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.0656043291091919, 'learning_rate': 4.277118644067797e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 953/6000 [56:08<5:21:30,  3.82s/it] 16%|â–ˆâ–Œ        | 954/6000 [56:11<5:11:23,  3.70s/it]                                                    {'loss': 0.0149, 'grad_norm': 2.140047311782837, 'learning_rate': 4.276271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 954/6000 [56:11<5:11:23,  3.70s/it] 16%|â–ˆâ–Œ        | 955/6000 [56:14<5:04:28,  3.62s/it]                                                    {'loss': 0.1223, 'grad_norm': 6.713665962219238, 'learning_rate': 4.27542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 955/6000 [56:14<5:04:28,  3.62s/it] 16%|â–ˆâ–Œ        | 956/6000 [56:18<5:03:28,  3.61s/it]                                                    {'loss': 0.085, 'grad_norm': 6.9640889167785645, 'learning_rate': 4.274576271186441e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 956/6000 [56:18<5:03:28,  3.61s/it] 16%|â–ˆâ–Œ        | 957/6000 [56:21<4:56:02,  3.52s/it]                                                    {'loss': 0.0167, 'grad_norm': 1.7486685514450073, 'learning_rate': 4.2737288135593226e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 957/6000 [56:21<4:56:02,  3.52s/it] 16%|â–ˆâ–Œ        | 958/6000 [56:25<4:57:34,  3.54s/it]                                                    {'loss': 0.1341, 'grad_norm': 5.9321722984313965, 'learning_rate': 4.272881355932204e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 958/6000 [56:25<4:57:34,  3.54s/it] 16%|â–ˆâ–Œ        | 959/6000 [56:28<4:51:16,  3.47s/it]                                                    {'loss': 0.054, 'grad_norm': 4.441114902496338, 'learning_rate': 4.272033898305085e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 959/6000 [56:28<4:51:16,  3.47s/it] 16%|â–ˆâ–Œ        | 960/6000 [56:32<4:51:00,  3.46s/it]                                                    {'loss': 0.3947, 'grad_norm': 11.637489318847656, 'learning_rate': 4.271186440677966e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 960/6000 [56:32<4:51:00,  3.46s/it] 16%|â–ˆâ–Œ        | 961/6000 [56:35<4:52:25,  3.48s/it]                                                    {'loss': 0.017, 'grad_norm': 2.1730077266693115, 'learning_rate': 4.270338983050848e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 961/6000 [56:35<4:52:25,  3.48s/it] 16%|â–ˆâ–Œ        | 962/6000 [56:39<5:01:54,  3.60s/it]                                                    {'loss': 0.1109, 'grad_norm': 7.668073654174805, 'learning_rate': 4.269491525423729e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 962/6000 [56:39<5:01:54,  3.60s/it] 16%|â–ˆâ–Œ        | 963/6000 [56:42<4:56:18,  3.53s/it]                                                    {'loss': 0.1019, 'grad_norm': 6.490415573120117, 'learning_rate': 4.268644067796611e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 963/6000 [56:42<4:56:18,  3.53s/it] 16%|â–ˆâ–Œ        | 964/6000 [56:46<4:51:38,  3.47s/it]                                                    {'loss': 0.1666, 'grad_norm': 12.055562019348145, 'learning_rate': 4.267796610169492e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 964/6000 [56:46<4:51:38,  3.47s/it] 16%|â–ˆâ–Œ        | 965/6000 [56:49<4:51:48,  3.48s/it]                                                    {'loss': 0.0741, 'grad_norm': 5.242941379547119, 'learning_rate': 4.266949152542373e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 965/6000 [56:49<4:51:48,  3.48s/it] 16%|â–ˆâ–Œ        | 966/6000 [56:53<4:54:16,  3.51s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.031668711453676224, 'learning_rate': 4.266101694915254e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 966/6000 [56:53<4:54:16,  3.51s/it] 16%|â–ˆâ–Œ        | 967/6000 [56:56<4:53:54,  3.50s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.15867793560028076, 'learning_rate': 4.265254237288136e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 967/6000 [56:56<4:53:54,  3.50s/it] 16%|â–ˆâ–Œ        | 968/6000 [57:00<5:00:39,  3.58s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.5143539309501648, 'learning_rate': 4.264406779661017e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 968/6000 [57:00<5:00:39,  3.58s/it] 16%|â–ˆâ–Œ        | 969/6000 [57:04<4:56:08,  3.53s/it]                                                    {'loss': 0.0138, 'grad_norm': 2.53424334526062, 'learning_rate': 4.263559322033899e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 969/6000 [57:04<4:56:08,  3.53s/it] 16%|â–ˆâ–Œ        | 970/6000 [57:07<4:57:08,  3.54s/it]                                                    {'loss': 0.0651, 'grad_norm': 6.0899739265441895, 'learning_rate': 4.26271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 970/6000 [57:07<4:57:08,  3.54s/it] 16%|â–ˆâ–Œ        | 971/6000 [57:10<4:51:27,  3.48s/it]                                                    {'loss': 0.1371, 'grad_norm': 6.130194187164307, 'learning_rate': 4.261864406779662e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 971/6000 [57:10<4:51:27,  3.48s/it] 16%|â–ˆâ–Œ        | 972/6000 [57:14<4:49:37,  3.46s/it]                                                    {'loss': 0.1333, 'grad_norm': 7.310168743133545, 'learning_rate': 4.261016949152542e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 972/6000 [57:14<4:49:37,  3.46s/it] 16%|â–ˆâ–Œ        | 973/6000 [57:17<4:48:35,  3.44s/it]                                                    {'loss': 0.0906, 'grad_norm': 5.114890098571777, 'learning_rate': 4.2601694915254234e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 973/6000 [57:17<4:48:35,  3.44s/it] 16%|â–ˆâ–Œ        | 974/6000 [57:21<4:48:22,  3.44s/it]                                                    {'loss': 0.0316, 'grad_norm': 5.949828624725342, 'learning_rate': 4.259322033898305e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 974/6000 [57:21<4:48:22,  3.44s/it] 16%|â–ˆâ–‹        | 975/6000 [57:24<4:45:48,  3.41s/it]                                                    {'loss': 0.0568, 'grad_norm': 2.1101386547088623, 'learning_rate': 4.258474576271186e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 975/6000 [57:24<4:45:48,  3.41s/it] 16%|â–ˆâ–‹        | 976/6000 [57:28<4:47:49,  3.44s/it]                                                    {'loss': 0.0003, 'grad_norm': 0.02580172009766102, 'learning_rate': 4.257627118644068e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 976/6000 [57:28<4:47:49,  3.44s/it] 16%|â–ˆâ–‹        | 977/6000 [57:31<4:45:06,  3.41s/it]                                                    {'loss': 0.0599, 'grad_norm': 6.3561859130859375, 'learning_rate': 4.256779661016949e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 977/6000 [57:31<4:45:06,  3.41s/it] 16%|â–ˆâ–‹        | 978/6000 [57:34<4:44:09,  3.39s/it]                                                    {'loss': 0.0325, 'grad_norm': 2.48715877532959, 'learning_rate': 4.255932203389831e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 978/6000 [57:34<4:44:09,  3.39s/it] 16%|â–ˆâ–‹        | 979/6000 [57:38<4:43:19,  3.39s/it]                                                    {'loss': 0.0301, 'grad_norm': 2.8270344734191895, 'learning_rate': 4.255084745762712e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 979/6000 [57:38<4:43:19,  3.39s/it] 16%|â–ˆâ–‹        | 980/6000 [57:41<4:46:48,  3.43s/it]                                                    {'loss': 0.1498, 'grad_norm': 7.546477794647217, 'learning_rate': 4.254237288135593e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 980/6000 [57:41<4:46:48,  3.43s/it] 16%|â–ˆâ–‹        | 981/6000 [57:45<4:47:08,  3.43s/it]                                                    {'loss': 0.0226, 'grad_norm': 2.1271145343780518, 'learning_rate': 4.2533898305084744e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 981/6000 [57:45<4:47:08,  3.43s/it] 16%|â–ˆâ–‹        | 982/6000 [57:48<4:49:45,  3.46s/it]                                                    {'loss': 0.0467, 'grad_norm': 2.4689273834228516, 'learning_rate': 4.252542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 982/6000 [57:48<4:49:45,  3.46s/it] 16%|â–ˆâ–‹        | 983/6000 [57:52<4:48:58,  3.46s/it]                                                    {'loss': 0.0163, 'grad_norm': 2.0900447368621826, 'learning_rate': 4.2516949152542374e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 983/6000 [57:52<4:48:58,  3.46s/it] 16%|â–ˆâ–‹        | 984/6000 [57:55<4:46:33,  3.43s/it]                                                    {'loss': 0.0621, 'grad_norm': 4.009223461151123, 'learning_rate': 4.250847457627119e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 984/6000 [57:55<4:46:33,  3.43s/it] 16%|â–ˆâ–‹        | 985/6000 [57:58<4:49:31,  3.46s/it]                                                    {'loss': 0.0544, 'grad_norm': 3.3631534576416016, 'learning_rate': 4.25e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 985/6000 [57:58<4:49:31,  3.46s/it] 16%|â–ˆâ–‹        | 986/6000 [58:02<4:45:26,  3.42s/it]                                                    {'loss': 0.0721, 'grad_norm': 3.4857165813446045, 'learning_rate': 4.2491525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 986/6000 [58:02<4:45:26,  3.42s/it] 16%|â–ˆâ–‹        | 987/6000 [58:05<4:49:22,  3.46s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.09844349324703217, 'learning_rate': 4.2483050847457626e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 987/6000 [58:05<4:49:22,  3.46s/it] 16%|â–ˆâ–‹        | 988/6000 [58:09<4:46:05,  3.42s/it]                                                    {'loss': 0.0624, 'grad_norm': 3.419970750808716, 'learning_rate': 4.2474576271186444e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 988/6000 [58:09<4:46:05,  3.42s/it] 16%|â–ˆâ–‹        | 989/6000 [58:12<4:45:37,  3.42s/it]                                                    {'loss': 0.0577, 'grad_norm': 5.046961307525635, 'learning_rate': 4.2466101694915255e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 989/6000 [58:12<4:45:37,  3.42s/it] 16%|â–ˆâ–‹        | 990/6000 [58:16<4:45:48,  3.42s/it]                                                    {'loss': 0.0908, 'grad_norm': 7.492607116699219, 'learning_rate': 4.245762711864407e-05, 'epoch': 0.17}
 16%|â–ˆâ–‹        | 990/6000 [58:16<4:45:48,  3.42s/it] 17%|â–ˆâ–‹        | 991/6000 [58:19<4:59:22,  3.59s/it]                                                    {'loss': 0.012, 'grad_norm': 0.8833613991737366, 'learning_rate': 4.2449152542372884e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 991/6000 [58:19<4:59:22,  3.59s/it] 17%|â–ˆâ–‹        | 992/6000 [58:23<4:54:57,  3.53s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.11136507242918015, 'learning_rate': 4.24406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 992/6000 [58:23<4:54:57,  3.53s/it] 17%|â–ˆâ–‹        | 993/6000 [58:26<4:52:55,  3.51s/it]                                                    {'loss': 0.0166, 'grad_norm': 1.7380876541137695, 'learning_rate': 4.2432203389830514e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 993/6000 [58:26<4:52:55,  3.51s/it] 17%|â–ˆâ–‹        | 994/6000 [58:30<4:52:12,  3.50s/it]                                                    {'loss': 0.0056, 'grad_norm': 0.7177656292915344, 'learning_rate': 4.242372881355932e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 994/6000 [58:30<4:52:12,  3.50s/it] 17%|â–ˆâ–‹        | 995/6000 [58:33<4:50:09,  3.48s/it]                                                    {'loss': 0.0523, 'grad_norm': 5.029452800750732, 'learning_rate': 4.2415254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 995/6000 [58:33<4:50:09,  3.48s/it] 17%|â–ˆâ–‹        | 996/6000 [58:37<4:48:51,  3.46s/it]                                                    {'loss': 0.0037, 'grad_norm': 0.571924090385437, 'learning_rate': 4.240677966101695e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 996/6000 [58:37<4:48:51,  3.46s/it] 17%|â–ˆâ–‹        | 997/6000 [58:40<4:49:41,  3.47s/it]                                                    {'loss': 0.1157, 'grad_norm': 4.85067081451416, 'learning_rate': 4.2398305084745766e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 997/6000 [58:40<4:49:41,  3.47s/it] 17%|â–ˆâ–‹        | 998/6000 [58:44<4:51:47,  3.50s/it]                                                    {'loss': 0.1606, 'grad_norm': 8.463652610778809, 'learning_rate': 4.238983050847458e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 998/6000 [58:44<4:51:47,  3.50s/it] 17%|â–ˆâ–‹        | 999/6000 [58:47<4:48:06,  3.46s/it]                                                    {'loss': 0.0253, 'grad_norm': 2.6071054935455322, 'learning_rate': 4.2381355932203395e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 999/6000 [58:47<4:48:06,  3.46s/it] 17%|â–ˆâ–‹        | 1000/6000 [58:51<4:48:49,  3.47s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.06957389414310455, 'learning_rate': 4.2372881355932206e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1000/6000 [58:51<4:48:49,  3.47s/it][2025-10-20 16:28:37,572] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 5287a330-a79d-454e-97c6-5a0d393ea8c4)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 16:28:47,735] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 5287a330-a79d-454e-97c6-5a0d393ea8c4)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 16:28:47,736] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 17%|â–ˆâ–‹        | 1001/6000 [59:07<10:19:18,  7.43s/it]                                                      {'loss': 0.3928, 'grad_norm': 8.481971740722656, 'learning_rate': 4.236440677966102e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1001/6000 [59:07<10:19:18,  7.43s/it] 17%|â–ˆâ–‹        | 1002/6000 [59:11<8:38:07,  6.22s/it]                                                      {'loss': 0.0028, 'grad_norm': 0.6101791858673096, 'learning_rate': 4.235593220338983e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1002/6000 [59:11<8:38:07,  6.22s/it] 17%|â–ˆâ–‹        | 1003/6000 [59:14<7:24:31,  5.34s/it]                                                     {'loss': 0.1953, 'grad_norm': 10.422871589660645, 'learning_rate': 4.234745762711865e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1003/6000 [59:14<7:24:31,  5.34s/it] 17%|â–ˆâ–‹        | 1004/6000 [59:17<6:33:51,  4.73s/it]                                                     {'loss': 0.0042, 'grad_norm': 0.392250657081604, 'learning_rate': 4.233898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1004/6000 [59:17<6:33:51,  4.73s/it] 17%|â–ˆâ–‹        | 1005/6000 [59:21<5:59:34,  4.32s/it]                                                     {'loss': 0.0195, 'grad_norm': 1.8610007762908936, 'learning_rate': 4.2330508474576276e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1005/6000 [59:21<5:59:34,  4.32s/it] 17%|â–ˆâ–‹        | 1006/6000 [59:24<5:41:23,  4.10s/it]                                                     {'loss': 0.0838, 'grad_norm': 7.637643814086914, 'learning_rate': 4.232203389830509e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1006/6000 [59:24<5:41:23,  4.10s/it] 17%|â–ˆâ–‹        | 1007/6000 [59:28<5:24:12,  3.90s/it]                                                     {'loss': 0.0599, 'grad_norm': 5.258059501647949, 'learning_rate': 4.23135593220339e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1007/6000 [59:28<5:24:12,  3.90s/it] 17%|â–ˆâ–‹        | 1008/6000 [59:31<5:12:24,  3.75s/it]                                                     {'loss': 0.0068, 'grad_norm': 1.052538514137268, 'learning_rate': 4.230508474576271e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1008/6000 [59:31<5:12:24,  3.75s/it] 17%|â–ˆâ–‹        | 1009/6000 [59:34<5:04:10,  3.66s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.5717699527740479, 'learning_rate': 4.229661016949153e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1009/6000 [59:34<5:04:10,  3.66s/it] 17%|â–ˆâ–‹        | 1010/6000 [59:38<4:55:52,  3.56s/it]                                                     {'loss': 0.1259, 'grad_norm': 6.839993953704834, 'learning_rate': 4.228813559322034e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1010/6000 [59:38<4:55:52,  3.56s/it] 17%|â–ˆâ–‹        | 1011/6000 [59:41<4:52:15,  3.51s/it]                                                     {'loss': 0.067, 'grad_norm': 3.4793033599853516, 'learning_rate': 4.227966101694916e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1011/6000 [59:41<4:52:15,  3.51s/it] 17%|â–ˆâ–‹        | 1012/6000 [59:45<4:53:25,  3.53s/it]                                                     {'loss': 0.0078, 'grad_norm': 0.9886032342910767, 'learning_rate': 4.227118644067797e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1012/6000 [59:45<4:53:25,  3.53s/it] 17%|â–ˆâ–‹        | 1013/6000 [59:48<4:48:45,  3.47s/it]                                                     {'loss': 0.0772, 'grad_norm': 5.828945636749268, 'learning_rate': 4.226271186440679e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1013/6000 [59:48<4:48:45,  3.47s/it] 17%|â–ˆâ–‹        | 1014/6000 [59:51<4:43:41,  3.41s/it]                                                     {'loss': 0.3366, 'grad_norm': 8.461845397949219, 'learning_rate': 4.22542372881356e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1014/6000 [59:51<4:43:41,  3.41s/it] 17%|â–ˆâ–‹        | 1015/6000 [59:55<4:43:07,  3.41s/it]                                                     {'loss': 0.0295, 'grad_norm': 5.374699592590332, 'learning_rate': 4.224576271186441e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1015/6000 [59:55<4:43:07,  3.41s/it] 17%|â–ˆâ–‹        | 1016/6000 [59:58<4:44:15,  3.42s/it]                                                     {'loss': 0.0399, 'grad_norm': 3.627364158630371, 'learning_rate': 4.223728813559322e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1016/6000 [59:58<4:44:15,  3.42s/it] 17%|â–ˆâ–‹        | 1017/6000 [1:00:02<4:44:53,  3.43s/it]                                                       {'loss': 0.067, 'grad_norm': 2.82975172996521, 'learning_rate': 4.222881355932203e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1017/6000 [1:00:02<4:44:53,  3.43s/it] 17%|â–ˆâ–‹        | 1018/6000 [1:00:05<4:44:54,  3.43s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.5874794125556946, 'learning_rate': 4.222033898305085e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1018/6000 [1:00:05<4:44:54,  3.43s/it] 17%|â–ˆâ–‹        | 1019/6000 [1:00:08<4:42:38,  3.40s/it]                                                       {'loss': 0.0747, 'grad_norm': 6.487890243530273, 'learning_rate': 4.221186440677966e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1019/6000 [1:00:08<4:42:38,  3.40s/it] 17%|â–ˆâ–‹        | 1020/6000 [1:00:12<4:42:46,  3.41s/it]                                                       {'loss': 0.1463, 'grad_norm': 8.316137313842773, 'learning_rate': 4.220338983050848e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1020/6000 [1:00:12<4:42:46,  3.41s/it] 17%|â–ˆâ–‹        | 1021/6000 [1:00:15<4:43:05,  3.41s/it]                                                       {'loss': 0.0633, 'grad_norm': 4.421696662902832, 'learning_rate': 4.219491525423729e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1021/6000 [1:00:15<4:43:05,  3.41s/it] 17%|â–ˆâ–‹        | 1022/6000 [1:00:19<4:49:25,  3.49s/it]                                                       {'loss': 0.0732, 'grad_norm': 8.194558143615723, 'learning_rate': 4.21864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1022/6000 [1:00:19<4:49:25,  3.49s/it] 17%|â–ˆâ–‹        | 1023/6000 [1:00:22<4:47:27,  3.47s/it]                                                       {'loss': 0.1003, 'grad_norm': 7.368908405303955, 'learning_rate': 4.217796610169491e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1023/6000 [1:00:22<4:47:27,  3.47s/it] 17%|â–ˆâ–‹        | 1024/6000 [1:00:26<4:45:10,  3.44s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.14584103226661682, 'learning_rate': 4.216949152542373e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1024/6000 [1:00:26<4:45:10,  3.44s/it] 17%|â–ˆâ–‹        | 1025/6000 [1:00:29<4:43:12,  3.42s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.11215471476316452, 'learning_rate': 4.216101694915254e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1025/6000 [1:00:29<4:43:12,  3.42s/it] 17%|â–ˆâ–‹        | 1026/6000 [1:00:33<4:42:45,  3.41s/it]                                                       {'loss': 0.0803, 'grad_norm': 7.531357765197754, 'learning_rate': 4.215254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1026/6000 [1:00:33<4:42:45,  3.41s/it] 17%|â–ˆâ–‹        | 1027/6000 [1:00:36<4:42:02,  3.40s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.1823999881744385, 'learning_rate': 4.214406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1027/6000 [1:00:36<4:42:02,  3.40s/it] 17%|â–ˆâ–‹        | 1028/6000 [1:00:39<4:39:36,  3.37s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1617901772260666, 'learning_rate': 4.213559322033899e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1028/6000 [1:00:39<4:39:36,  3.37s/it] 17%|â–ˆâ–‹        | 1029/6000 [1:00:43<4:39:09,  3.37s/it]                                                       {'loss': 0.006, 'grad_norm': 0.8684440851211548, 'learning_rate': 4.2127118644067795e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1029/6000 [1:00:43<4:39:09,  3.37s/it] 17%|â–ˆâ–‹        | 1030/6000 [1:00:46<4:38:43,  3.36s/it]                                                       {'loss': 0.0797, 'grad_norm': 7.047772407531738, 'learning_rate': 4.211864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1030/6000 [1:00:46<4:38:43,  3.36s/it] 17%|â–ˆâ–‹        | 1031/6000 [1:00:49<4:39:44,  3.38s/it]                                                       {'loss': 0.0215, 'grad_norm': 2.855574369430542, 'learning_rate': 4.2110169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1031/6000 [1:00:49<4:39:44,  3.38s/it] 17%|â–ˆâ–‹        | 1032/6000 [1:00:53<4:38:10,  3.36s/it]                                                       {'loss': 0.019, 'grad_norm': 2.476916551589966, 'learning_rate': 4.210169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1032/6000 [1:00:53<4:38:10,  3.36s/it] 17%|â–ˆâ–‹        | 1033/6000 [1:00:56<4:38:33,  3.36s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.1684829443693161, 'learning_rate': 4.209322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1033/6000 [1:00:56<4:38:33,  3.36s/it] 17%|â–ˆâ–‹        | 1034/6000 [1:00:59<4:37:34,  3.35s/it]                                                       {'loss': 0.0941, 'grad_norm': 3.8023908138275146, 'learning_rate': 4.208474576271187e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1034/6000 [1:00:59<4:37:34,  3.35s/it] 17%|â–ˆâ–‹        | 1035/6000 [1:01:03<4:40:07,  3.39s/it]                                                       {'loss': 0.0299, 'grad_norm': 1.979505181312561, 'learning_rate': 4.207627118644068e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1035/6000 [1:01:03<4:40:07,  3.39s/it] 17%|â–ˆâ–‹        | 1036/6000 [1:01:06<4:41:26,  3.40s/it]                                                       {'loss': 0.1092, 'grad_norm': 6.228555202484131, 'learning_rate': 4.2067796610169494e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1036/6000 [1:01:06<4:41:26,  3.40s/it] 17%|â–ˆâ–‹        | 1037/6000 [1:01:10<4:43:48,  3.43s/it]                                                       {'loss': 0.0663, 'grad_norm': 8.275372505187988, 'learning_rate': 4.2059322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1037/6000 [1:01:10<4:43:48,  3.43s/it] 17%|â–ˆâ–‹        | 1038/6000 [1:01:14<4:54:00,  3.56s/it]                                                       {'loss': 0.0498, 'grad_norm': 6.9101972579956055, 'learning_rate': 4.2050847457627116e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1038/6000 [1:01:14<4:54:00,  3.56s/it] 17%|â–ˆâ–‹        | 1039/6000 [1:01:17<4:54:23,  3.56s/it]                                                       {'loss': 0.0283, 'grad_norm': 3.3531947135925293, 'learning_rate': 4.2042372881355934e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1039/6000 [1:01:17<4:54:23,  3.56s/it] 17%|â–ˆâ–‹        | 1040/6000 [1:01:21<4:52:44,  3.54s/it]                                                       {'loss': 0.0452, 'grad_norm': 3.486182689666748, 'learning_rate': 4.2033898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1040/6000 [1:01:21<4:52:44,  3.54s/it] 17%|â–ˆâ–‹        | 1041/6000 [1:01:24<4:47:34,  3.48s/it]                                                       {'loss': 0.1653, 'grad_norm': 8.524140357971191, 'learning_rate': 4.2025423728813564e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1041/6000 [1:01:24<4:47:34,  3.48s/it] 17%|â–ˆâ–‹        | 1042/6000 [1:01:27<4:47:14,  3.48s/it]                                                       {'loss': 0.0173, 'grad_norm': 2.799110174179077, 'learning_rate': 4.2016949152542375e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1042/6000 [1:01:27<4:47:14,  3.48s/it] 17%|â–ˆâ–‹        | 1043/6000 [1:01:31<4:43:32,  3.43s/it]                                                       {'loss': 0.1248, 'grad_norm': 7.814366340637207, 'learning_rate': 4.2008474576271186e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1043/6000 [1:01:31<4:43:32,  3.43s/it] 17%|â–ˆâ–‹        | 1044/6000 [1:01:34<4:44:52,  3.45s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.2169911861419678, 'learning_rate': 4.2e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1044/6000 [1:01:34<4:44:52,  3.45s/it] 17%|â–ˆâ–‹        | 1045/6000 [1:01:38<4:46:37,  3.47s/it]                                                       {'loss': 0.1686, 'grad_norm': 10.306709289550781, 'learning_rate': 4.1991525423728816e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1045/6000 [1:01:38<4:46:37,  3.47s/it] 17%|â–ˆâ–‹        | 1046/6000 [1:01:41<4:45:51,  3.46s/it]                                                       {'loss': 0.1306, 'grad_norm': 8.00817584991455, 'learning_rate': 4.198305084745763e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1046/6000 [1:01:41<4:45:51,  3.46s/it] 17%|â–ˆâ–‹        | 1047/6000 [1:01:45<4:53:50,  3.56s/it]                                                       {'loss': 0.2448, 'grad_norm': 10.056262016296387, 'learning_rate': 4.1974576271186445e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1047/6000 [1:01:45<4:53:50,  3.56s/it] 17%|â–ˆâ–‹        | 1048/6000 [1:01:48<4:48:58,  3.50s/it]                                                       {'loss': 0.0179, 'grad_norm': 2.861891508102417, 'learning_rate': 4.1966101694915256e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1048/6000 [1:01:48<4:48:58,  3.50s/it] 17%|â–ˆâ–‹        | 1049/6000 [1:01:52<4:45:23,  3.46s/it]                                                       {'loss': 0.1505, 'grad_norm': 6.05773401260376, 'learning_rate': 4.1957627118644074e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1049/6000 [1:01:52<4:45:23,  3.46s/it] 18%|â–ˆâ–Š        | 1050/6000 [1:01:56<5:03:18,  3.68s/it]                                                       {'loss': 0.0165, 'grad_norm': 1.735355257987976, 'learning_rate': 4.1949152542372886e-05, 'epoch': 0.17}
 18%|â–ˆâ–Š        | 1050/6000 [1:01:56<5:03:18,  3.68s/it][2025-10-20 16:31:42,935] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1051/6000 [1:02:02<5:49:50,  4.24s/it]                                                       {'loss': 0.1272, 'grad_norm': 6.7036285400390625, 'learning_rate': 4.19406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1051/6000 [1:02:02<5:49:50,  4.24s/it] 18%|â–ˆâ–Š        | 1052/6000 [1:02:05<5:28:20,  3.98s/it]                                                       {'loss': 0.0348, 'grad_norm': 4.046945571899414, 'learning_rate': 4.193220338983051e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1052/6000 [1:02:05<5:28:20,  3.98s/it] 18%|â–ˆâ–Š        | 1053/6000 [1:02:09<5:20:27,  3.89s/it]                                                       {'loss': 0.028, 'grad_norm': 2.1485259532928467, 'learning_rate': 4.1923728813559326e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1053/6000 [1:02:09<5:20:27,  3.89s/it] 18%|â–ˆâ–Š        | 1054/6000 [1:02:12<5:11:04,  3.77s/it]                                                       {'loss': 0.0194, 'grad_norm': 1.8574012517929077, 'learning_rate': 4.191525423728814e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1054/6000 [1:02:12<5:11:04,  3.77s/it] 18%|â–ˆâ–Š        | 1055/6000 [1:02:15<5:00:00,  3.64s/it]                                                       {'loss': 0.1062, 'grad_norm': 6.902036190032959, 'learning_rate': 4.1906779661016956e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1055/6000 [1:02:15<5:00:00,  3.64s/it] 18%|â–ˆâ–Š        | 1056/6000 [1:02:19<4:53:16,  3.56s/it]                                                       {'loss': 0.0693, 'grad_norm': 4.6932549476623535, 'learning_rate': 4.189830508474577e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1056/6000 [1:02:19<4:53:16,  3.56s/it] 18%|â–ˆâ–Š        | 1057/6000 [1:02:22<4:47:40,  3.49s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.14320437610149384, 'learning_rate': 4.188983050847458e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1057/6000 [1:02:22<4:47:40,  3.49s/it] 18%|â–ˆâ–Š        | 1058/6000 [1:02:25<4:44:05,  3.45s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.5666824579238892, 'learning_rate': 4.188135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1058/6000 [1:02:25<4:44:05,  3.45s/it] 18%|â–ˆâ–Š        | 1059/6000 [1:02:29<4:44:18,  3.45s/it]                                                       {'loss': 0.0464, 'grad_norm': 4.644073963165283, 'learning_rate': 4.18728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1059/6000 [1:02:29<4:44:18,  3.45s/it] 18%|â–ˆâ–Š        | 1060/6000 [1:02:32<4:41:39,  3.42s/it]                                                       {'loss': 0.002, 'grad_norm': 0.1614174246788025, 'learning_rate': 4.186440677966102e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1060/6000 [1:02:32<4:41:39,  3.42s/it] 18%|â–ˆâ–Š        | 1061/6000 [1:02:36<4:51:24,  3.54s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.5867654085159302, 'learning_rate': 4.185593220338983e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1061/6000 [1:02:36<4:51:24,  3.54s/it] 18%|â–ˆâ–Š        | 1062/6000 [1:02:40<4:50:23,  3.53s/it]                                                       {'loss': 0.0459, 'grad_norm': 4.887564182281494, 'learning_rate': 4.184745762711865e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1062/6000 [1:02:40<4:50:23,  3.53s/it] 18%|â–ˆâ–Š        | 1063/6000 [1:02:43<4:46:09,  3.48s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016575878486037254, 'learning_rate': 4.183898305084746e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1063/6000 [1:02:43<4:46:09,  3.48s/it] 18%|â–ˆâ–Š        | 1064/6000 [1:02:46<4:47:10,  3.49s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.8389976024627686, 'learning_rate': 4.183050847457628e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1064/6000 [1:02:46<4:47:10,  3.49s/it] 18%|â–ˆâ–Š        | 1065/6000 [1:02:50<4:42:22,  3.43s/it]                                                       {'loss': 0.0598, 'grad_norm': 3.7028181552886963, 'learning_rate': 4.182203389830508e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1065/6000 [1:02:50<4:42:22,  3.43s/it] 18%|â–ˆâ–Š        | 1066/6000 [1:02:53<4:42:17,  3.43s/it]                                                       {'loss': 0.0625, 'grad_norm': 8.71798038482666, 'learning_rate': 4.18135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1066/6000 [1:02:53<4:42:17,  3.43s/it] 18%|â–ˆâ–Š        | 1067/6000 [1:02:57<4:43:01,  3.44s/it]                                                       {'loss': 0.0517, 'grad_norm': 6.316241264343262, 'learning_rate': 4.180508474576271e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1067/6000 [1:02:57<4:43:01,  3.44s/it] 18%|â–ˆâ–Š        | 1068/6000 [1:03:00<4:39:03,  3.39s/it]                                                       {'loss': 0.0231, 'grad_norm': 3.413135290145874, 'learning_rate': 4.179661016949153e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1068/6000 [1:03:00<4:39:03,  3.39s/it] 18%|â–ˆâ–Š        | 1069/6000 [1:03:03<4:38:22,  3.39s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.8125723600387573, 'learning_rate': 4.178813559322034e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1069/6000 [1:03:03<4:38:22,  3.39s/it] 18%|â–ˆâ–Š        | 1070/6000 [1:03:07<4:39:19,  3.40s/it]                                                       {'loss': 0.1321, 'grad_norm': 7.418898582458496, 'learning_rate': 4.177966101694916e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1070/6000 [1:03:07<4:39:19,  3.40s/it] 18%|â–ˆâ–Š        | 1071/6000 [1:03:10<4:40:24,  3.41s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1879625916481018, 'learning_rate': 4.177118644067797e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1071/6000 [1:03:10<4:40:24,  3.41s/it] 18%|â–ˆâ–Š        | 1072/6000 [1:03:14<4:39:07,  3.40s/it]                                                       {'loss': 0.0428, 'grad_norm': 4.453555107116699, 'learning_rate': 4.176271186440678e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1072/6000 [1:03:14<4:39:07,  3.40s/it] 18%|â–ˆâ–Š        | 1073/6000 [1:03:17<4:41:00,  3.42s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.7427287101745605, 'learning_rate': 4.175423728813559e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1073/6000 [1:03:17<4:41:00,  3.42s/it] 18%|â–ˆâ–Š        | 1074/6000 [1:03:20<4:40:22,  3.42s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2560182213783264, 'learning_rate': 4.174576271186441e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1074/6000 [1:03:20<4:40:22,  3.42s/it] 18%|â–ˆâ–Š        | 1075/6000 [1:03:24<4:45:36,  3.48s/it]                                                       {'loss': 0.0565, 'grad_norm': 5.1018967628479, 'learning_rate': 4.173728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1075/6000 [1:03:24<4:45:36,  3.48s/it] 18%|â–ˆâ–Š        | 1076/6000 [1:03:27<4:44:51,  3.47s/it]                                                       {'loss': 0.0151, 'grad_norm': 2.1817562580108643, 'learning_rate': 4.172881355932204e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1076/6000 [1:03:27<4:44:51,  3.47s/it] 18%|â–ˆâ–Š        | 1077/6000 [1:03:31<4:42:47,  3.45s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.7097889184951782, 'learning_rate': 4.172033898305085e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1077/6000 [1:03:31<4:42:47,  3.45s/it] 18%|â–ˆâ–Š        | 1078/6000 [1:03:34<4:41:51,  3.44s/it]                                                       {'loss': 0.1179, 'grad_norm': 11.131490707397461, 'learning_rate': 4.171186440677966e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1078/6000 [1:03:34<4:41:51,  3.44s/it] 18%|â–ˆâ–Š        | 1079/6000 [1:03:38<4:51:10,  3.55s/it]                                                       {'loss': 0.2744, 'grad_norm': 8.095768928527832, 'learning_rate': 4.1703389830508474e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1079/6000 [1:03:38<4:51:10,  3.55s/it] 18%|â–ˆâ–Š        | 1080/6000 [1:03:41<4:46:55,  3.50s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.7244031429290771, 'learning_rate': 4.1694915254237285e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1080/6000 [1:03:41<4:46:55,  3.50s/it] 18%|â–ˆâ–Š        | 1081/6000 [1:03:45<4:43:08,  3.45s/it]                                                       {'loss': 0.0952, 'grad_norm': 7.303400993347168, 'learning_rate': 4.16864406779661e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1081/6000 [1:03:45<4:43:08,  3.45s/it] 18%|â–ˆâ–Š        | 1082/6000 [1:03:48<4:42:48,  3.45s/it]                                                       {'loss': 0.1321, 'grad_norm': 8.700824737548828, 'learning_rate': 4.1677966101694915e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1082/6000 [1:03:48<4:42:48,  3.45s/it] 18%|â–ˆâ–Š        | 1083/6000 [1:03:52<4:39:45,  3.41s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.4743684530258179, 'learning_rate': 4.166949152542373e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1083/6000 [1:03:52<4:39:45,  3.41s/it] 18%|â–ˆâ–Š        | 1084/6000 [1:03:55<4:42:04,  3.44s/it]                                                       {'loss': 0.1569, 'grad_norm': 7.858859062194824, 'learning_rate': 4.1661016949152544e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1084/6000 [1:03:55<4:42:04,  3.44s/it] 18%|â–ˆâ–Š        | 1085/6000 [1:03:58<4:40:04,  3.42s/it]                                                       {'loss': 0.0304, 'grad_norm': 1.8149795532226562, 'learning_rate': 4.165254237288136e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1085/6000 [1:03:58<4:40:04,  3.42s/it] 18%|â–ˆâ–Š        | 1086/6000 [1:04:02<4:46:45,  3.50s/it]                                                       {'loss': 0.0294, 'grad_norm': 4.505710601806641, 'learning_rate': 4.164406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1086/6000 [1:04:02<4:46:45,  3.50s/it] 18%|â–ˆâ–Š        | 1087/6000 [1:04:06<4:44:19,  3.47s/it]                                                       {'loss': 0.0368, 'grad_norm': 4.814310550689697, 'learning_rate': 4.1635593220338985e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1087/6000 [1:04:06<4:44:19,  3.47s/it] 18%|â–ˆâ–Š        | 1088/6000 [1:04:09<4:41:42,  3.44s/it]                                                       {'loss': 0.1363, 'grad_norm': 8.001509666442871, 'learning_rate': 4.1627118644067796e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1088/6000 [1:04:09<4:41:42,  3.44s/it] 18%|â–ˆâ–Š        | 1089/6000 [1:04:13<5:05:27,  3.73s/it]                                                       {'loss': 0.2551, 'grad_norm': 11.172272682189941, 'learning_rate': 4.1618644067796614e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1089/6000 [1:04:13<5:05:27,  3.73s/it] 18%|â–ˆâ–Š        | 1090/6000 [1:04:17<5:01:09,  3.68s/it]                                                       {'loss': 0.0354, 'grad_norm': 5.085002422332764, 'learning_rate': 4.1610169491525425e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1090/6000 [1:04:17<5:01:09,  3.68s/it] 18%|â–ˆâ–Š        | 1091/6000 [1:04:20<4:55:00,  3.61s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.9810590744018555, 'learning_rate': 4.160169491525424e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1091/6000 [1:04:20<4:55:00,  3.61s/it] 18%|â–ˆâ–Š        | 1092/6000 [1:04:24<4:48:15,  3.52s/it]                                                       {'loss': 0.1725, 'grad_norm': 19.700523376464844, 'learning_rate': 4.1593220338983055e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1092/6000 [1:04:24<4:48:15,  3.52s/it] 18%|â–ˆâ–Š        | 1093/6000 [1:04:27<4:43:15,  3.46s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05955716222524643, 'learning_rate': 4.1584745762711866e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1093/6000 [1:04:27<4:43:15,  3.46s/it] 18%|â–ˆâ–Š        | 1094/6000 [1:04:30<4:42:33,  3.46s/it]                                                       {'loss': 0.0754, 'grad_norm': 4.679876804351807, 'learning_rate': 4.157627118644068e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1094/6000 [1:04:30<4:42:33,  3.46s/it] 18%|â–ˆâ–Š        | 1095/6000 [1:04:34<4:39:39,  3.42s/it]                                                       {'loss': 0.0155, 'grad_norm': 1.6622042655944824, 'learning_rate': 4.1567796610169495e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1095/6000 [1:04:34<4:39:39,  3.42s/it] 18%|â–ˆâ–Š        | 1096/6000 [1:04:37<4:42:33,  3.46s/it]                                                       {'loss': 0.044, 'grad_norm': 4.153764247894287, 'learning_rate': 4.1559322033898307e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1096/6000 [1:04:37<4:42:33,  3.46s/it] 18%|â–ˆâ–Š        | 1097/6000 [1:04:41<4:41:00,  3.44s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5268238186836243, 'learning_rate': 4.1550847457627125e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1097/6000 [1:04:41<4:41:00,  3.44s/it] 18%|â–ˆâ–Š        | 1098/6000 [1:04:45<4:55:05,  3.61s/it]                                                       {'loss': 0.1941, 'grad_norm': 9.384827613830566, 'learning_rate': 4.1542372881355936e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1098/6000 [1:04:45<4:55:05,  3.61s/it] 18%|â–ˆâ–Š        | 1099/6000 [1:04:49<5:06:46,  3.76s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.220039501786232, 'learning_rate': 4.153389830508475e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1099/6000 [1:04:49<5:06:46,  3.76s/it] 18%|â–ˆâ–Š        | 1100/6000 [1:04:52<4:57:19,  3.64s/it]                                                       {'loss': 0.0827, 'grad_norm': 8.496207237243652, 'learning_rate': 4.152542372881356e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1100/6000 [1:04:52<4:57:19,  3.64s/it][2025-10-20 16:34:39,187] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1101/6000 [1:04:58<5:45:03,  4.23s/it]                                                       {'loss': 0.0439, 'grad_norm': 6.094783306121826, 'learning_rate': 4.151694915254237e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1101/6000 [1:04:58<5:45:03,  4.23s/it] 18%|â–ˆâ–Š        | 1102/6000 [1:05:01<5:22:48,  3.95s/it]                                                       {'loss': 0.0143, 'grad_norm': 2.204901695251465, 'learning_rate': 4.150847457627119e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1102/6000 [1:05:01<5:22:48,  3.95s/it] 18%|â–ˆâ–Š        | 1103/6000 [1:05:04<5:08:49,  3.78s/it]                                                       {'loss': 0.0625, 'grad_norm': 4.205019950866699, 'learning_rate': 4.15e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1103/6000 [1:05:05<5:08:49,  3.78s/it] 18%|â–ˆâ–Š        | 1104/6000 [1:05:08<4:59:45,  3.67s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.2726999521255493, 'learning_rate': 4.149152542372882e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1104/6000 [1:05:08<4:59:45,  3.67s/it] 18%|â–ˆâ–Š        | 1105/6000 [1:05:11<4:51:44,  3.58s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.4085972011089325, 'learning_rate': 4.148305084745763e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1105/6000 [1:05:11<4:51:44,  3.58s/it] 18%|â–ˆâ–Š        | 1106/6000 [1:05:15<4:46:44,  3.52s/it]                                                       {'loss': 0.0719, 'grad_norm': 6.611383438110352, 'learning_rate': 4.1474576271186446e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1106/6000 [1:05:15<4:46:44,  3.52s/it] 18%|â–ˆâ–Š        | 1107/6000 [1:05:18<4:44:48,  3.49s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.9344654083251953, 'learning_rate': 4.146610169491526e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1107/6000 [1:05:18<4:44:48,  3.49s/it] 18%|â–ˆâ–Š        | 1108/6000 [1:05:22<4:46:17,  3.51s/it]                                                       {'loss': 0.0584, 'grad_norm': 5.948454856872559, 'learning_rate': 4.145762711864407e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1108/6000 [1:05:22<4:46:17,  3.51s/it] 18%|â–ˆâ–Š        | 1109/6000 [1:05:25<4:43:15,  3.47s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.1491925716400146, 'learning_rate': 4.144915254237288e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1109/6000 [1:05:25<4:43:15,  3.47s/it] 18%|â–ˆâ–Š        | 1110/6000 [1:05:28<4:40:46,  3.45s/it]                                                       {'loss': 0.1323, 'grad_norm': 6.588746547698975, 'learning_rate': 4.14406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1110/6000 [1:05:28<4:40:46,  3.45s/it] 19%|â–ˆâ–Š        | 1111/6000 [1:05:32<4:39:07,  3.43s/it]                                                       {'loss': 0.1224, 'grad_norm': 6.749263763427734, 'learning_rate': 4.143220338983051e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1111/6000 [1:05:32<4:39:07,  3.43s/it] 19%|â–ˆâ–Š        | 1112/6000 [1:05:35<4:36:23,  3.39s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3148043155670166, 'learning_rate': 4.142372881355933e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1112/6000 [1:05:35<4:36:23,  3.39s/it] 19%|â–ˆâ–Š        | 1113/6000 [1:05:38<4:35:47,  3.39s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.440833806991577, 'learning_rate': 4.141525423728814e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1113/6000 [1:05:38<4:35:47,  3.39s/it] 19%|â–ˆâ–Š        | 1114/6000 [1:05:42<4:33:51,  3.36s/it]                                                       {'loss': 0.0763, 'grad_norm': 6.143846035003662, 'learning_rate': 4.140677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1114/6000 [1:05:42<4:33:51,  3.36s/it] 19%|â–ˆâ–Š        | 1115/6000 [1:05:45<4:35:50,  3.39s/it]                                                       {'loss': 0.2648, 'grad_norm': 9.579818725585938, 'learning_rate': 4.139830508474576e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1115/6000 [1:05:45<4:35:50,  3.39s/it] 19%|â–ˆâ–Š        | 1116/6000 [1:05:49<4:35:49,  3.39s/it]                                                       {'loss': 0.1814, 'grad_norm': 9.498799324035645, 'learning_rate': 4.138983050847458e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1116/6000 [1:05:49<4:35:49,  3.39s/it] 19%|â–ˆâ–Š        | 1117/6000 [1:05:52<4:38:21,  3.42s/it]                                                       {'loss': 0.002, 'grad_norm': 0.38177162408828735, 'learning_rate': 4.138135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1117/6000 [1:05:52<4:38:21,  3.42s/it] 19%|â–ˆâ–Š        | 1118/6000 [1:05:56<4:38:33,  3.42s/it]                                                       {'loss': 0.3694, 'grad_norm': 13.964035034179688, 'learning_rate': 4.13728813559322e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1118/6000 [1:05:56<4:38:33,  3.42s/it] 19%|â–ˆâ–Š        | 1119/6000 [1:05:59<4:40:48,  3.45s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.452250599861145, 'learning_rate': 4.136440677966102e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1119/6000 [1:05:59<4:40:48,  3.45s/it] 19%|â–ˆâ–Š        | 1120/6000 [1:06:02<4:40:14,  3.45s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4689459502696991, 'learning_rate': 4.135593220338983e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1120/6000 [1:06:02<4:40:14,  3.45s/it] 19%|â–ˆâ–Š        | 1121/6000 [1:06:06<4:38:58,  3.43s/it]                                                       {'loss': 0.0331, 'grad_norm': 2.9061243534088135, 'learning_rate': 4.134745762711865e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1121/6000 [1:06:06<4:38:58,  3.43s/it] 19%|â–ˆâ–Š        | 1122/6000 [1:06:09<4:39:31,  3.44s/it]                                                       {'loss': 0.0335, 'grad_norm': 5.277613639831543, 'learning_rate': 4.1338983050847454e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1122/6000 [1:06:09<4:39:31,  3.44s/it] 19%|â–ˆâ–Š        | 1123/6000 [1:06:13<4:39:12,  3.43s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4224526584148407, 'learning_rate': 4.133050847457627e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1123/6000 [1:06:13<4:39:12,  3.43s/it] 19%|â–ˆâ–Š        | 1124/6000 [1:06:17<4:47:38,  3.54s/it]                                                       {'loss': 0.0701, 'grad_norm': 7.663204193115234, 'learning_rate': 4.1322033898305084e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1124/6000 [1:06:17<4:47:38,  3.54s/it] 19%|â–ˆâ–‰        | 1125/6000 [1:06:20<4:46:18,  3.52s/it]                                                       {'loss': 0.0511, 'grad_norm': 3.422175407409668, 'learning_rate': 4.13135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1125/6000 [1:06:20<4:46:18,  3.52s/it] 19%|â–ˆâ–‰        | 1126/6000 [1:06:23<4:42:28,  3.48s/it]                                                       {'loss': 0.3716, 'grad_norm': 12.897594451904297, 'learning_rate': 4.130508474576271e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1126/6000 [1:06:23<4:42:28,  3.48s/it] 19%|â–ˆâ–‰        | 1127/6000 [1:06:27<4:40:49,  3.46s/it]                                                       {'loss': 0.0373, 'grad_norm': 3.6881802082061768, 'learning_rate': 4.129661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1127/6000 [1:06:27<4:40:49,  3.46s/it] 19%|â–ˆâ–‰        | 1128/6000 [1:06:30<4:39:00,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025289302691817284, 'learning_rate': 4.128813559322034e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1128/6000 [1:06:30<4:39:00,  3.44s/it] 19%|â–ˆâ–‰        | 1129/6000 [1:06:34<4:37:57,  3.42s/it]                                                       {'loss': 0.03, 'grad_norm': 2.4810359477996826, 'learning_rate': 4.1279661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1129/6000 [1:06:34<4:37:57,  3.42s/it] 19%|â–ˆâ–‰        | 1130/6000 [1:06:37<4:37:19,  3.42s/it]                                                       {'loss': 0.0754, 'grad_norm': 2.6759068965911865, 'learning_rate': 4.1271186440677965e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1130/6000 [1:06:37<4:37:19,  3.42s/it] 19%|â–ˆâ–‰        | 1131/6000 [1:06:40<4:35:00,  3.39s/it]                                                       {'loss': 0.1861, 'grad_norm': 9.393427848815918, 'learning_rate': 4.126271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1131/6000 [1:06:40<4:35:00,  3.39s/it] 19%|â–ˆâ–‰        | 1132/6000 [1:06:44<4:34:37,  3.38s/it]                                                       {'loss': 0.0587, 'grad_norm': 4.480762481689453, 'learning_rate': 4.1254237288135594e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1132/6000 [1:06:44<4:34:37,  3.38s/it] 19%|â–ˆâ–‰        | 1133/6000 [1:06:47<4:44:35,  3.51s/it]                                                       {'loss': 0.011, 'grad_norm': 1.5185314416885376, 'learning_rate': 4.124576271186441e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1133/6000 [1:06:47<4:44:35,  3.51s/it] 19%|â–ˆâ–‰        | 1134/6000 [1:06:51<4:54:23,  3.63s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.6152564883232117, 'learning_rate': 4.1237288135593223e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1134/6000 [1:06:51<4:54:23,  3.63s/it] 19%|â–ˆâ–‰        | 1135/6000 [1:06:55<4:48:49,  3.56s/it]                                                       {'loss': 0.0291, 'grad_norm': 3.5392825603485107, 'learning_rate': 4.1228813559322035e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1135/6000 [1:06:55<4:48:49,  3.56s/it] 19%|â–ˆâ–‰        | 1136/6000 [1:06:58<4:45:08,  3.52s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2450505495071411, 'learning_rate': 4.1220338983050846e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1136/6000 [1:06:58<4:45:08,  3.52s/it] 19%|â–ˆâ–‰        | 1137/6000 [1:07:02<4:41:54,  3.48s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.13862942159175873, 'learning_rate': 4.1211864406779664e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1137/6000 [1:07:02<4:41:54,  3.48s/it] 19%|â–ˆâ–‰        | 1138/6000 [1:07:05<4:38:05,  3.43s/it]                                                       {'loss': 0.1143, 'grad_norm': 24.160818099975586, 'learning_rate': 4.1203389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1138/6000 [1:07:05<4:38:05,  3.43s/it] 19%|â–ˆâ–‰        | 1139/6000 [1:07:08<4:38:15,  3.43s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.32080134749412537, 'learning_rate': 4.119491525423729e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1139/6000 [1:07:08<4:38:15,  3.43s/it] 19%|â–ˆâ–‰        | 1140/6000 [1:07:12<4:42:14,  3.48s/it]                                                       {'loss': 0.1159, 'grad_norm': 9.247808456420898, 'learning_rate': 4.1186440677966105e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1140/6000 [1:07:12<4:42:14,  3.48s/it] 19%|â–ˆâ–‰        | 1141/6000 [1:07:15<4:41:00,  3.47s/it]                                                       {'loss': 0.2236, 'grad_norm': 9.520732879638672, 'learning_rate': 4.1177966101694916e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1141/6000 [1:07:15<4:41:00,  3.47s/it] 19%|â–ˆâ–‰        | 1142/6000 [1:07:19<4:41:46,  3.48s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.0286766290664673, 'learning_rate': 4.1169491525423734e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1142/6000 [1:07:19<4:41:46,  3.48s/it] 19%|â–ˆâ–‰        | 1143/6000 [1:07:22<4:38:18,  3.44s/it]                                                       {'loss': 0.2584, 'grad_norm': 10.302754402160645, 'learning_rate': 4.1161016949152545e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1143/6000 [1:07:22<4:38:18,  3.44s/it] 19%|â–ˆâ–‰        | 1144/6000 [1:07:26<4:40:48,  3.47s/it]                                                       {'loss': 0.0227, 'grad_norm': 1.6198813915252686, 'learning_rate': 4.115254237288136e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1144/6000 [1:07:26<4:40:48,  3.47s/it] 19%|â–ˆâ–‰        | 1145/6000 [1:07:29<4:38:12,  3.44s/it]                                                       {'loss': 0.1024, 'grad_norm': 7.144702911376953, 'learning_rate': 4.114406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1145/6000 [1:07:29<4:38:12,  3.44s/it] 19%|â–ˆâ–‰        | 1146/6000 [1:07:33<4:40:11,  3.46s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.7626782059669495, 'learning_rate': 4.1135593220338986e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1146/6000 [1:07:33<4:40:11,  3.46s/it] 19%|â–ˆâ–‰        | 1147/6000 [1:07:36<4:37:54,  3.44s/it]                                                       {'loss': 0.1225, 'grad_norm': 9.029150009155273, 'learning_rate': 4.11271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1147/6000 [1:07:36<4:37:54,  3.44s/it] 19%|â–ˆâ–‰        | 1148/6000 [1:07:39<4:36:26,  3.42s/it]                                                       {'loss': 0.1078, 'grad_norm': 8.699673652648926, 'learning_rate': 4.1118644067796615e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1148/6000 [1:07:39<4:36:26,  3.42s/it] 19%|â–ˆâ–‰        | 1149/6000 [1:07:43<4:46:27,  3.54s/it]                                                       {'loss': 0.0754, 'grad_norm': 3.5394949913024902, 'learning_rate': 4.111016949152543e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1149/6000 [1:07:43<4:46:27,  3.54s/it] 19%|â–ˆâ–‰        | 1150/6000 [1:07:47<4:45:46,  3.54s/it]                                                       {'loss': 0.0512, 'grad_norm': 4.458242416381836, 'learning_rate': 4.110169491525424e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1150/6000 [1:07:47<4:45:46,  3.54s/it][2025-10-20 16:37:33,774] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 19%|â–ˆâ–‰        | 1151/6000 [1:07:53<5:41:44,  4.23s/it]                                                       {'loss': 0.0495, 'grad_norm': 4.068057060241699, 'learning_rate': 4.109322033898305e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1151/6000 [1:07:53<5:41:44,  4.23s/it] 19%|â–ˆâ–‰        | 1152/6000 [1:07:56<5:20:51,  3.97s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.050912998616695404, 'learning_rate': 4.108474576271187e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1152/6000 [1:07:56<5:20:51,  3.97s/it] 19%|â–ˆâ–‰        | 1153/6000 [1:08:00<5:12:43,  3.87s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.21351778507232666, 'learning_rate': 4.107627118644068e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1153/6000 [1:08:00<5:12:43,  3.87s/it] 19%|â–ˆâ–‰        | 1154/6000 [1:08:03<5:01:03,  3.73s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.5177809000015259, 'learning_rate': 4.10677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1154/6000 [1:08:03<5:01:03,  3.73s/it] 19%|â–ˆâ–‰        | 1155/6000 [1:08:06<4:53:13,  3.63s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.6832537651062012, 'learning_rate': 4.105932203389831e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1155/6000 [1:08:06<4:53:13,  3.63s/it] 19%|â–ˆâ–‰        | 1156/6000 [1:08:10<4:45:44,  3.54s/it]                                                       {'loss': 0.2034, 'grad_norm': 8.95017147064209, 'learning_rate': 4.1050847457627126e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1156/6000 [1:08:10<4:45:44,  3.54s/it] 19%|â–ˆâ–‰        | 1157/6000 [1:08:13<4:43:26,  3.51s/it]                                                       {'loss': 0.0959, 'grad_norm': 5.718207359313965, 'learning_rate': 4.104237288135593e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1157/6000 [1:08:13<4:43:26,  3.51s/it] 19%|â–ˆâ–‰        | 1158/6000 [1:08:17<4:40:14,  3.47s/it]                                                       {'loss': 0.0464, 'grad_norm': 6.686894416809082, 'learning_rate': 4.103389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1158/6000 [1:08:17<4:40:14,  3.47s/it] 19%|â–ˆâ–‰        | 1159/6000 [1:08:20<4:38:09,  3.45s/it]                                                       {'loss': 0.0251, 'grad_norm': 2.9796602725982666, 'learning_rate': 4.102542372881356e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1159/6000 [1:08:20<4:38:09,  3.45s/it] 19%|â–ˆâ–‰        | 1160/6000 [1:08:23<4:36:45,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.059339139610528946, 'learning_rate': 4.101694915254237e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1160/6000 [1:08:23<4:36:45,  3.43s/it] 19%|â–ˆâ–‰        | 1161/6000 [1:08:27<4:35:23,  3.41s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.5841941833496094, 'learning_rate': 4.100847457627119e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1161/6000 [1:08:27<4:35:23,  3.41s/it] 19%|â–ˆâ–‰        | 1162/6000 [1:08:30<4:31:58,  3.37s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5407205820083618, 'learning_rate': 4.1e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1162/6000 [1:08:30<4:31:58,  3.37s/it] 19%|â–ˆâ–‰        | 1163/6000 [1:08:33<4:32:03,  3.37s/it]                                                       {'loss': 0.031, 'grad_norm': 4.342516899108887, 'learning_rate': 4.099152542372882e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1163/6000 [1:08:33<4:32:03,  3.37s/it] 19%|â–ˆâ–‰        | 1164/6000 [1:08:37<4:31:07,  3.36s/it]                                                       {'loss': 0.0717, 'grad_norm': 5.531598091125488, 'learning_rate': 4.098305084745763e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1164/6000 [1:08:37<4:31:07,  3.36s/it] 19%|â–ˆâ–‰        | 1165/6000 [1:08:40<4:33:51,  3.40s/it]                                                       {'loss': 0.0386, 'grad_norm': 3.446834087371826, 'learning_rate': 4.097457627118644e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1165/6000 [1:08:40<4:33:51,  3.40s/it] 19%|â–ˆâ–‰        | 1166/6000 [1:08:44<4:32:00,  3.38s/it]                                                       {'loss': 0.0346, 'grad_norm': 1.4180837869644165, 'learning_rate': 4.096610169491525e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1166/6000 [1:08:44<4:32:00,  3.38s/it] 19%|â–ˆâ–‰        | 1167/6000 [1:08:47<4:45:29,  3.54s/it]                                                       {'loss': 0.034, 'grad_norm': 4.544768333435059, 'learning_rate': 4.095762711864407e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1167/6000 [1:08:47<4:45:29,  3.54s/it] 19%|â–ˆâ–‰        | 1168/6000 [1:08:51<4:41:12,  3.49s/it]                                                       {'loss': 0.0372, 'grad_norm': 4.13039493560791, 'learning_rate': 4.094915254237288e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1168/6000 [1:08:51<4:41:12,  3.49s/it] 19%|â–ˆâ–‰        | 1169/6000 [1:08:54<4:38:55,  3.46s/it]                                                       {'loss': 0.0692, 'grad_norm': 6.173000335693359, 'learning_rate': 4.09406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1169/6000 [1:08:54<4:38:55,  3.46s/it] 20%|â–ˆâ–‰        | 1170/6000 [1:08:58<4:36:53,  3.44s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.36901402473449707, 'learning_rate': 4.093220338983051e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1170/6000 [1:08:58<4:36:53,  3.44s/it] 20%|â–ˆâ–‰        | 1171/6000 [1:09:01<4:39:29,  3.47s/it]                                                       {'loss': 0.0251, 'grad_norm': 2.568329095840454, 'learning_rate': 4.092372881355932e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1171/6000 [1:09:01<4:39:29,  3.47s/it] 20%|â–ˆâ–‰        | 1172/6000 [1:09:05<4:39:49,  3.48s/it]                                                       {'loss': 0.0346, 'grad_norm': 5.322987079620361, 'learning_rate': 4.0915254237288134e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1172/6000 [1:09:05<4:39:49,  3.48s/it] 20%|â–ˆâ–‰        | 1173/6000 [1:09:08<4:38:07,  3.46s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.5146641731262207, 'learning_rate': 4.090677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1173/6000 [1:09:08<4:38:07,  3.46s/it] 20%|â–ˆâ–‰        | 1174/6000 [1:09:12<4:44:41,  3.54s/it]                                                       {'loss': 0.1211, 'grad_norm': 7.41735315322876, 'learning_rate': 4.089830508474576e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1174/6000 [1:09:12<4:44:41,  3.54s/it] 20%|â–ˆâ–‰        | 1175/6000 [1:09:15<4:42:22,  3.51s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.3734338283538818, 'learning_rate': 4.088983050847458e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1175/6000 [1:09:15<4:42:22,  3.51s/it] 20%|â–ˆâ–‰        | 1176/6000 [1:09:19<4:39:01,  3.47s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0468137226998806, 'learning_rate': 4.088135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1176/6000 [1:09:19<4:39:01,  3.47s/it] 20%|â–ˆâ–‰        | 1177/6000 [1:09:22<4:36:42,  3.44s/it]                                                       {'loss': 0.1569, 'grad_norm': 5.368038177490234, 'learning_rate': 4.087288135593221e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1177/6000 [1:09:22<4:36:42,  3.44s/it] 20%|â–ˆâ–‰        | 1178/6000 [1:09:26<4:48:41,  3.59s/it]                                                       {'loss': 0.0622, 'grad_norm': 2.3936800956726074, 'learning_rate': 4.086440677966102e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1178/6000 [1:09:26<4:48:41,  3.59s/it] 20%|â–ˆâ–‰        | 1179/6000 [1:09:30<4:54:25,  3.66s/it]                                                       {'loss': 0.029, 'grad_norm': 3.1204724311828613, 'learning_rate': 4.085593220338983e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1179/6000 [1:09:30<4:54:25,  3.66s/it] 20%|â–ˆâ–‰        | 1180/6000 [1:09:34<4:56:56,  3.70s/it]                                                       {'loss': 0.0409, 'grad_norm': 1.655797004699707, 'learning_rate': 4.0847457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1180/6000 [1:09:34<4:56:56,  3.70s/it] 20%|â–ˆâ–‰        | 1181/6000 [1:09:37<4:50:56,  3.62s/it]                                                       {'loss': 0.0441, 'grad_norm': 4.539506435394287, 'learning_rate': 4.0838983050847456e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1181/6000 [1:09:37<4:50:56,  3.62s/it] 20%|â–ˆâ–‰        | 1182/6000 [1:09:41<5:09:21,  3.85s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.23563136160373688, 'learning_rate': 4.0830508474576274e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1182/6000 [1:09:41<5:09:21,  3.85s/it] 20%|â–ˆâ–‰        | 1183/6000 [1:09:45<4:56:15,  3.69s/it]                                                       {'loss': 0.0305, 'grad_norm': 5.519381999969482, 'learning_rate': 4.0822033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1183/6000 [1:09:45<4:56:15,  3.69s/it] 20%|â–ˆâ–‰        | 1184/6000 [1:09:48<4:48:14,  3.59s/it]                                                       {'loss': 0.196, 'grad_norm': 5.974435329437256, 'learning_rate': 4.08135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1184/6000 [1:09:48<4:48:14,  3.59s/it] 20%|â–ˆâ–‰        | 1185/6000 [1:09:51<4:41:51,  3.51s/it]                                                       {'loss': 0.0254, 'grad_norm': 2.789116382598877, 'learning_rate': 4.0805084745762714e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1185/6000 [1:09:51<4:41:51,  3.51s/it] 20%|â–ˆâ–‰        | 1186/6000 [1:09:55<4:37:30,  3.46s/it]                                                       {'loss': 0.2234, 'grad_norm': 6.170352935791016, 'learning_rate': 4.0796610169491526e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1186/6000 [1:09:55<4:37:30,  3.46s/it] 20%|â–ˆâ–‰        | 1187/6000 [1:09:58<4:37:10,  3.46s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.6750073432922363, 'learning_rate': 4.078813559322034e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1187/6000 [1:09:58<4:37:10,  3.46s/it] 20%|â–ˆâ–‰        | 1188/6000 [1:10:01<4:32:44,  3.40s/it]                                                       {'loss': 0.0327, 'grad_norm': 3.6703848838806152, 'learning_rate': 4.0779661016949155e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1188/6000 [1:10:01<4:32:44,  3.40s/it] 20%|â–ˆâ–‰        | 1189/6000 [1:10:05<4:31:51,  3.39s/it]                                                       {'loss': 0.0894, 'grad_norm': 6.823155879974365, 'learning_rate': 4.0771186440677966e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1189/6000 [1:10:05<4:31:51,  3.39s/it] 20%|â–ˆâ–‰        | 1190/6000 [1:10:08<4:36:33,  3.45s/it]                                                       {'loss': 0.0108, 'grad_norm': 1.242207646369934, 'learning_rate': 4.0762711864406784e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1190/6000 [1:10:08<4:36:33,  3.45s/it] 20%|â–ˆâ–‰        | 1191/6000 [1:10:12<4:37:22,  3.46s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.46233969926834106, 'learning_rate': 4.0754237288135596e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1191/6000 [1:10:12<4:37:22,  3.46s/it] 20%|â–ˆâ–‰        | 1192/6000 [1:10:15<4:37:55,  3.47s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.54951411485672, 'learning_rate': 4.0745762711864414e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1192/6000 [1:10:15<4:37:55,  3.47s/it] 20%|â–ˆâ–‰        | 1193/6000 [1:10:19<4:35:54,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06068811193108559, 'learning_rate': 4.073728813559322e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1193/6000 [1:10:19<4:35:54,  3.44s/it] 20%|â–ˆâ–‰        | 1194/6000 [1:10:22<4:37:37,  3.47s/it]                                                       {'loss': 0.0619, 'grad_norm': 5.9102396965026855, 'learning_rate': 4.0728813559322036e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1194/6000 [1:10:22<4:37:37,  3.47s/it] 20%|â–ˆâ–‰        | 1195/6000 [1:10:26<4:35:33,  3.44s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.244284525513649, 'learning_rate': 4.072033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1195/6000 [1:10:26<4:35:33,  3.44s/it] 20%|â–ˆâ–‰        | 1196/6000 [1:10:29<4:33:44,  3.42s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08175342530012131, 'learning_rate': 4.0711864406779666e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1196/6000 [1:10:29<4:33:44,  3.42s/it] 20%|â–ˆâ–‰        | 1197/6000 [1:10:33<4:35:19,  3.44s/it]                                                       {'loss': 0.0215, 'grad_norm': 2.090831756591797, 'learning_rate': 4.070338983050848e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1197/6000 [1:10:33<4:35:19,  3.44s/it] 20%|â–ˆâ–‰        | 1198/6000 [1:10:36<4:36:26,  3.45s/it]                                                       {'loss': 0.1216, 'grad_norm': 7.899249076843262, 'learning_rate': 4.0694915254237295e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1198/6000 [1:10:36<4:36:26,  3.45s/it] 20%|â–ˆâ–‰        | 1199/6000 [1:10:39<4:33:27,  3.42s/it]                                                       {'loss': 0.042, 'grad_norm': 5.134405136108398, 'learning_rate': 4.0686440677966106e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1199/6000 [1:10:39<4:33:27,  3.42s/it] 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:43<4:31:54,  3.40s/it]                                                       {'loss': 0.1392, 'grad_norm': 7.858733177185059, 'learning_rate': 4.067796610169492e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:43<4:31:54,  3.40s/it][2025-10-20 16:40:29,691] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:48<5:24:52,  4.06s/it]                                                       {'loss': 0.2103, 'grad_norm': 6.740228652954102, 'learning_rate': 4.066949152542373e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:48<5:24:52,  4.06s/it] 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:52<5:07:27,  3.84s/it]                                                       {'loss': 0.0198, 'grad_norm': 3.6076748371124268, 'learning_rate': 4.066101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:52<5:07:27,  3.84s/it] 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:55<4:55:45,  3.70s/it]                                                       {'loss': 0.1596, 'grad_norm': 7.133103847503662, 'learning_rate': 4.065254237288136e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:55<4:55:45,  3.70s/it] 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:59<4:58:26,  3.73s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.10585391521453857, 'learning_rate': 4.064406779661017e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:59<4:58:26,  3.73s/it] 20%|â–ˆâ–ˆ        | 1205/6000 [1:11:02<4:50:03,  3.63s/it]                                                       {'loss': 0.0924, 'grad_norm': 5.91773796081543, 'learning_rate': 4.063559322033899e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1205/6000 [1:11:02<4:50:03,  3.63s/it] 20%|â–ˆâ–ˆ        | 1206/6000 [1:11:06<4:44:17,  3.56s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.6474006772041321, 'learning_rate': 4.06271186440678e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1206/6000 [1:11:06<4:44:17,  3.56s/it] 20%|â–ˆâ–ˆ        | 1207/6000 [1:11:09<4:40:48,  3.52s/it]                                                       {'loss': 0.0369, 'grad_norm': 2.13116455078125, 'learning_rate': 4.061864406779661e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1207/6000 [1:11:09<4:40:48,  3.52s/it] 20%|â–ˆâ–ˆ        | 1208/6000 [1:11:12<4:39:59,  3.51s/it]                                                       {'loss': 0.0431, 'grad_norm': 2.1407225131988525, 'learning_rate': 4.061016949152542e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1208/6000 [1:11:12<4:39:59,  3.51s/it] 20%|â–ˆâ–ˆ        | 1209/6000 [1:11:16<4:35:39,  3.45s/it]                                                       {'loss': 0.0494, 'grad_norm': 4.902721881866455, 'learning_rate': 4.060169491525424e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1209/6000 [1:11:16<4:35:39,  3.45s/it] 20%|â–ˆâ–ˆ        | 1210/6000 [1:11:19<4:36:18,  3.46s/it]                                                       {'loss': 0.1399, 'grad_norm': 9.790569305419922, 'learning_rate': 4.059322033898305e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1210/6000 [1:11:19<4:36:18,  3.46s/it] 20%|â–ˆâ–ˆ        | 1211/6000 [1:11:23<4:34:20,  3.44s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.728412926197052, 'learning_rate': 4.058474576271187e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1211/6000 [1:11:23<4:34:20,  3.44s/it] 20%|â–ˆâ–ˆ        | 1212/6000 [1:11:26<4:33:21,  3.43s/it]                                                       {'loss': 0.0749, 'grad_norm': 7.809738636016846, 'learning_rate': 4.057627118644068e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1212/6000 [1:11:26<4:33:21,  3.43s/it] 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:29<4:31:32,  3.40s/it]                                                       {'loss': 0.0264, 'grad_norm': 2.9314234256744385, 'learning_rate': 4.05677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:29<4:31:32,  3.40s/it] 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:33<4:32:57,  3.42s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.4956270456314087, 'learning_rate': 4.055932203389831e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:33<4:32:57,  3.42s/it] 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:36<4:32:58,  3.42s/it]                                                       {'loss': 0.0454, 'grad_norm': 5.5948076248168945, 'learning_rate': 4.055084745762712e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:36<4:32:58,  3.42s/it] 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:40<4:30:44,  3.40s/it]                                                       {'loss': 0.0275, 'grad_norm': 1.7405359745025635, 'learning_rate': 4.054237288135593e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:40<4:30:44,  3.40s/it] 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:44<4:41:32,  3.53s/it]                                                       {'loss': 0.1694, 'grad_norm': 8.410017013549805, 'learning_rate': 4.053389830508475e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:44<4:41:32,  3.53s/it] 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:47<4:37:55,  3.49s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.4658440351486206, 'learning_rate': 4.052542372881356e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:47<4:37:55,  3.49s/it] 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:51<4:43:38,  3.56s/it]                                                       {'loss': 0.0449, 'grad_norm': 5.500406742095947, 'learning_rate': 4.051694915254238e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:51<4:43:38,  3.56s/it] 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:54<4:39:47,  3.51s/it]                                                       {'loss': 0.0236, 'grad_norm': 2.9974567890167236, 'learning_rate': 4.050847457627119e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:54<4:39:47,  3.51s/it] 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:58<4:40:21,  3.52s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.04852794110774994, 'learning_rate': 4.05e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:58<4:40:21,  3.52s/it] 20%|â–ˆâ–ˆ        | 1222/6000 [1:12:01<4:38:23,  3.50s/it]                                                       {'loss': 0.0742, 'grad_norm': 5.063867092132568, 'learning_rate': 4.049152542372881e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1222/6000 [1:12:01<4:38:23,  3.50s/it] 20%|â–ˆâ–ˆ        | 1223/6000 [1:12:04<4:34:44,  3.45s/it]                                                       {'loss': 0.095, 'grad_norm': 6.824557781219482, 'learning_rate': 4.0483050847457624e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1223/6000 [1:12:04<4:34:44,  3.45s/it] 20%|â–ˆâ–ˆ        | 1224/6000 [1:12:08<4:33:39,  3.44s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.4473494291305542, 'learning_rate': 4.047457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1224/6000 [1:12:08<4:33:39,  3.44s/it] 20%|â–ˆâ–ˆ        | 1225/6000 [1:12:11<4:37:25,  3.49s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1326325535774231, 'learning_rate': 4.0466101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1225/6000 [1:12:11<4:37:25,  3.49s/it] 20%|â–ˆâ–ˆ        | 1226/6000 [1:12:15<4:43:57,  3.57s/it]                                                       {'loss': 0.1599, 'grad_norm': 7.827595233917236, 'learning_rate': 4.045762711864407e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1226/6000 [1:12:15<4:43:57,  3.57s/it] 20%|â–ˆâ–ˆ        | 1227/6000 [1:12:19<4:50:26,  3.65s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.7215753793716431, 'learning_rate': 4.044915254237288e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1227/6000 [1:12:19<4:50:26,  3.65s/it] 20%|â–ˆâ–ˆ        | 1228/6000 [1:12:22<4:44:01,  3.57s/it]                                                       {'loss': 0.0635, 'grad_norm': 2.6017589569091797, 'learning_rate': 4.0440677966101694e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1228/6000 [1:12:22<4:44:01,  3.57s/it] 20%|â–ˆâ–ˆ        | 1229/6000 [1:12:26<4:38:06,  3.50s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.20421509444713593, 'learning_rate': 4.0432203389830506e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1229/6000 [1:12:26<4:38:06,  3.50s/it] 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:29<4:33:43,  3.44s/it]                                                       {'loss': 0.1162, 'grad_norm': 6.961615562438965, 'learning_rate': 4.0423728813559324e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:29<4:33:43,  3.44s/it] 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:32<4:32:40,  3.43s/it]                                                       {'loss': 0.1702, 'grad_norm': 9.280901908874512, 'learning_rate': 4.0415254237288135e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:32<4:32:40,  3.43s/it] 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:36<4:37:52,  3.50s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.17869919538497925, 'learning_rate': 4.040677966101695e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:36<4:37:52,  3.50s/it] 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:40<4:42:33,  3.56s/it]                                                       {'loss': 0.0177, 'grad_norm': 2.781263828277588, 'learning_rate': 4.0398305084745764e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:40<4:42:33,  3.56s/it] 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:44<4:50:14,  3.65s/it]                                                       {'loss': 0.1278, 'grad_norm': 8.80351448059082, 'learning_rate': 4.038983050847458e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:44<4:50:14,  3.65s/it] 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:47<4:44:14,  3.58s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.26972144842147827, 'learning_rate': 4.0381355932203394e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:47<4:44:14,  3.58s/it] 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:50<4:39:24,  3.52s/it]                                                       {'loss': 0.1905, 'grad_norm': 10.338689804077148, 'learning_rate': 4.0372881355932205e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:50<4:39:24,  3.52s/it] 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:54<4:36:39,  3.49s/it]                                                       {'loss': 0.0542, 'grad_norm': 5.44303035736084, 'learning_rate': 4.0364406779661016e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:54<4:36:39,  3.49s/it] 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:57<4:34:07,  3.45s/it]                                                       {'loss': 0.0581, 'grad_norm': 5.9505438804626465, 'learning_rate': 4.0355932203389834e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:57<4:34:07,  3.45s/it] 21%|â–ˆâ–ˆ        | 1239/6000 [1:13:00<4:30:51,  3.41s/it]                                                       {'loss': 0.0167, 'grad_norm': 1.8985430002212524, 'learning_rate': 4.0347457627118646e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1239/6000 [1:13:00<4:30:51,  3.41s/it] 21%|â–ˆâ–ˆ        | 1240/6000 [1:13:04<4:30:57,  3.42s/it]                                                       {'loss': 0.0404, 'grad_norm': 2.489921808242798, 'learning_rate': 4.0338983050847464e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1240/6000 [1:13:04<4:30:57,  3.42s/it] 21%|â–ˆâ–ˆ        | 1241/6000 [1:13:07<4:29:25,  3.40s/it]                                                       {'loss': 0.0129, 'grad_norm': 2.180436849594116, 'learning_rate': 4.0330508474576275e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1241/6000 [1:13:07<4:29:25,  3.40s/it] 21%|â–ˆâ–ˆ        | 1242/6000 [1:13:11<4:32:58,  3.44s/it]                                                       {'loss': 0.2729, 'grad_norm': 12.330046653747559, 'learning_rate': 4.0322033898305086e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1242/6000 [1:13:11<4:32:58,  3.44s/it] 21%|â–ˆâ–ˆ        | 1243/6000 [1:13:14<4:32:41,  3.44s/it]                                                       {'loss': 0.0492, 'grad_norm': 4.298923969268799, 'learning_rate': 4.03135593220339e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1243/6000 [1:13:14<4:32:41,  3.44s/it] 21%|â–ˆâ–ˆ        | 1244/6000 [1:13:18<4:32:13,  3.43s/it]                                                       {'loss': 0.1373, 'grad_norm': 6.605473518371582, 'learning_rate': 4.030508474576271e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1244/6000 [1:13:18<4:32:13,  3.43s/it] 21%|â–ˆâ–ˆ        | 1245/6000 [1:13:21<4:29:19,  3.40s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.27608758211135864, 'learning_rate': 4.029661016949153e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1245/6000 [1:13:21<4:29:19,  3.40s/it] 21%|â–ˆâ–ˆ        | 1246/6000 [1:13:24<4:28:07,  3.38s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.6711603999137878, 'learning_rate': 4.028813559322034e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1246/6000 [1:13:24<4:28:07,  3.38s/it] 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:28<4:28:02,  3.38s/it]                                                       {'loss': 0.0388, 'grad_norm': 1.9575364589691162, 'learning_rate': 4.0279661016949156e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:28<4:28:02,  3.38s/it] 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:31<4:28:44,  3.39s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.033674370497465134, 'learning_rate': 4.027118644067797e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:31<4:28:44,  3.39s/it] 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:35<4:28:41,  3.39s/it]                                                       {'loss': 0.0735, 'grad_norm': 4.7944536209106445, 'learning_rate': 4.0262711864406786e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:35<4:28:41,  3.39s/it] 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:38<4:25:48,  3.36s/it]                                                       {'loss': 0.0954, 'grad_norm': 7.78200626373291, 'learning_rate': 4.025423728813559e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:38<4:25:48,  3.36s/it][2025-10-20 16:43:24,796] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:43<5:18:40,  4.03s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03374501317739487, 'learning_rate': 4.024576271186441e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:43<5:18:40,  4.03s/it] 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:47<5:03:10,  3.83s/it]                                                       {'loss': 0.1406, 'grad_norm': 5.276327610015869, 'learning_rate': 4.023728813559322e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:47<5:03:10,  3.83s/it] 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:51<5:06:59,  3.88s/it]                                                       {'loss': 0.0275, 'grad_norm': 2.116206407546997, 'learning_rate': 4.022881355932204e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:51<5:06:59,  3.88s/it] 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:54<4:53:12,  3.71s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.5443158745765686, 'learning_rate': 4.022033898305085e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:54<4:53:12,  3.71s/it] 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:57<4:46:45,  3.63s/it]                                                       {'loss': 0.0397, 'grad_norm': 7.775938034057617, 'learning_rate': 4.021186440677967e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:58<4:46:45,  3.63s/it] 21%|â–ˆâ–ˆ        | 1256/6000 [1:14:01<4:43:02,  3.58s/it]                                                       {'loss': 0.0407, 'grad_norm': 4.057584285736084, 'learning_rate': 4.020338983050848e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1256/6000 [1:14:01<4:43:02,  3.58s/it] 21%|â–ˆâ–ˆ        | 1257/6000 [1:14:04<4:37:45,  3.51s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5626371502876282, 'learning_rate': 4.019491525423729e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1257/6000 [1:14:04<4:37:45,  3.51s/it] 21%|â–ˆâ–ˆ        | 1258/6000 [1:14:08<4:43:38,  3.59s/it]                                                       {'loss': 0.0157, 'grad_norm': 1.2393540143966675, 'learning_rate': 4.01864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1258/6000 [1:14:08<4:43:38,  3.59s/it] 21%|â–ˆâ–ˆ        | 1259/6000 [1:14:11<4:38:56,  3.53s/it]                                                       {'loss': 0.4547, 'grad_norm': 11.377459526062012, 'learning_rate': 4.017796610169492e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1259/6000 [1:14:11<4:38:56,  3.53s/it] 21%|â–ˆâ–ˆ        | 1260/6000 [1:14:15<4:34:47,  3.48s/it]                                                       {'loss': 0.0315, 'grad_norm': 1.9023489952087402, 'learning_rate': 4.016949152542373e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1260/6000 [1:14:15<4:34:47,  3.48s/it] 21%|â–ˆâ–ˆ        | 1261/6000 [1:14:18<4:33:44,  3.47s/it]                                                       {'loss': 0.0774, 'grad_norm': 8.28360652923584, 'learning_rate': 4.016101694915255e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1261/6000 [1:14:18<4:33:44,  3.47s/it] 21%|â–ˆâ–ˆ        | 1262/6000 [1:14:22<4:42:11,  3.57s/it]                                                       {'loss': 0.0853, 'grad_norm': 4.346258640289307, 'learning_rate': 4.015254237288136e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1262/6000 [1:14:22<4:42:11,  3.57s/it] 21%|â–ˆâ–ˆ        | 1263/6000 [1:14:26<4:40:28,  3.55s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06819288432598114, 'learning_rate': 4.014406779661017e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1263/6000 [1:14:26<4:40:28,  3.55s/it] 21%|â–ˆâ–ˆ        | 1264/6000 [1:14:29<4:38:24,  3.53s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.3777236938476562, 'learning_rate': 4.013559322033898e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1264/6000 [1:14:29<4:38:24,  3.53s/it] 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:33<4:36:55,  3.51s/it]                                                       {'loss': 0.1053, 'grad_norm': 5.479029178619385, 'learning_rate': 4.012711864406779e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:33<4:36:55,  3.51s/it] 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:36<4:34:28,  3.48s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.1282312870025635, 'learning_rate': 4.011864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:36<4:34:28,  3.48s/it] 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:40<4:42:26,  3.58s/it]                                                       {'loss': 0.0534, 'grad_norm': 5.547396659851074, 'learning_rate': 4.011016949152542e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:40<4:42:26,  3.58s/it] 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:43<4:36:31,  3.51s/it]                                                       {'loss': 0.1525, 'grad_norm': 12.823339462280273, 'learning_rate': 4.010169491525424e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:43<4:36:31,  3.51s/it] 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:47<4:34:18,  3.48s/it]                                                       {'loss': 0.0928, 'grad_norm': 10.258808135986328, 'learning_rate': 4.009322033898305e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:47<4:34:18,  3.48s/it] 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:50<4:32:13,  3.45s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1079932302236557, 'learning_rate': 4.008474576271187e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:50<4:32:13,  3.45s/it] 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:53<4:33:39,  3.47s/it]                                                       {'loss': 0.0595, 'grad_norm': 5.7957963943481445, 'learning_rate': 4.007627118644068e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:53<4:33:39,  3.47s/it] 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:57<4:40:59,  3.57s/it]                                                       {'loss': 0.021, 'grad_norm': 3.092790365219116, 'learning_rate': 4.006779661016949e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:57<4:40:59,  3.57s/it] 21%|â–ˆâ–ˆ        | 1273/6000 [1:15:01<4:36:01,  3.50s/it]                                                       {'loss': 0.0368, 'grad_norm': 2.2771918773651123, 'learning_rate': 4.0059322033898304e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1273/6000 [1:15:01<4:36:01,  3.50s/it] 21%|â–ˆâ–ˆ        | 1274/6000 [1:15:04<4:31:46,  3.45s/it]                                                       {'loss': 0.026, 'grad_norm': 5.629977226257324, 'learning_rate': 4.005084745762712e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1274/6000 [1:15:04<4:31:46,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:15:07<4:31:31,  3.45s/it]                                                       {'loss': 0.1778, 'grad_norm': 6.6177849769592285, 'learning_rate': 4.004237288135593e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:15:07<4:31:31,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:15:11<4:33:54,  3.48s/it]                                                       {'loss': 0.1457, 'grad_norm': 8.455504417419434, 'learning_rate': 4.003389830508475e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:15:11<4:33:54,  3.48s/it] 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:15:14<4:33:17,  3.47s/it]                                                       {'loss': 0.2685, 'grad_norm': 15.081536293029785, 'learning_rate': 4.002542372881356e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:15:14<4:33:17,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:15:18<4:32:53,  3.47s/it]                                                       {'loss': 0.1878, 'grad_norm': 7.231716156005859, 'learning_rate': 4.0016949152542374e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:15:18<4:32:53,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:15:21<4:31:12,  3.45s/it]                                                       {'loss': 0.2286, 'grad_norm': 8.668303489685059, 'learning_rate': 4.0008474576271185e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:15:21<4:31:12,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:15:25<4:32:30,  3.46s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3296038806438446, 'learning_rate': 4e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:15:25<4:32:30,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:15:28<4:33:19,  3.48s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.7864272594451904, 'learning_rate': 3.9991525423728815e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:15:28<4:33:19,  3.48s/it] 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:32<4:30:47,  3.44s/it]                                                       {'loss': 0.0495, 'grad_norm': 3.64361572265625, 'learning_rate': 3.998305084745763e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:32<4:30:47,  3.44s/it] 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:35<4:27:24,  3.40s/it]                                                       {'loss': 0.044, 'grad_norm': 3.656770944595337, 'learning_rate': 3.9974576271186444e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:35<4:27:24,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:38<4:27:08,  3.40s/it]                                                       {'loss': 0.0313, 'grad_norm': 3.217064142227173, 'learning_rate': 3.996610169491526e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:38<4:27:08,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:42<4:26:15,  3.39s/it]                                                       {'loss': 0.0341, 'grad_norm': 2.4431915283203125, 'learning_rate': 3.9957627118644066e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:42<4:26:15,  3.39s/it] 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:45<4:28:24,  3.42s/it]                                                       {'loss': 0.0465, 'grad_norm': 4.194433212280273, 'learning_rate': 3.994915254237288e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:45<4:28:24,  3.42s/it] 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:49<4:32:24,  3.47s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2051885575056076, 'learning_rate': 3.9940677966101696e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:49<4:32:24,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:52<4:31:19,  3.45s/it]                                                       {'loss': 0.0786, 'grad_norm': 6.023061752319336, 'learning_rate': 3.993220338983051e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:52<4:31:19,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:55<4:28:19,  3.42s/it]                                                       {'loss': 0.0281, 'grad_norm': 3.3952479362487793, 'learning_rate': 3.9923728813559325e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:55<4:28:19,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:59<4:28:09,  3.42s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.44184985756874084, 'learning_rate': 3.9915254237288136e-05, 'epoch': 0.21}
 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:59<4:28:09,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:16:02<4:27:29,  3.41s/it]                                                       {'loss': 0.0302, 'grad_norm': 2.5554001331329346, 'learning_rate': 3.9906779661016955e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:16:02<4:27:29,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:16:06<4:25:55,  3.39s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.42762258648872375, 'learning_rate': 3.9898305084745766e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:16:06<4:25:55,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:16:09<4:28:21,  3.42s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.26318350434303284, 'learning_rate': 3.988983050847458e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:16:09<4:28:21,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:16:12<4:26:47,  3.40s/it]                                                       {'loss': 0.0345, 'grad_norm': 2.6264491081237793, 'learning_rate': 3.988135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:16:12<4:26:47,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:16:16<4:24:27,  3.37s/it]                                                       {'loss': 0.0673, 'grad_norm': 7.233452796936035, 'learning_rate': 3.9872881355932206e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:16:16<4:24:27,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:16:19<4:25:06,  3.38s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.41149652004241943, 'learning_rate': 3.986440677966102e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:16:19<4:25:06,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:16:23<4:32:37,  3.48s/it]                                                       {'loss': 0.0277, 'grad_norm': 4.558234214782715, 'learning_rate': 3.9855932203389836e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:16:23<4:32:37,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:16:26<4:31:02,  3.46s/it]                                                       {'loss': 0.0849, 'grad_norm': 5.119114398956299, 'learning_rate': 3.984745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:16:26<4:31:02,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:30<4:29:23,  3.44s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6592402458190918, 'learning_rate': 3.983898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:30<4:29:23,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:33<4:28:04,  3.42s/it]                                                       {'loss': 0.0703, 'grad_norm': 5.960893154144287, 'learning_rate': 3.983050847457627e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:33<4:28:04,  3.42s/it][2025-10-20 16:46:20,059] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 9f1c8837-1b0f-4b31-9e7f-d3c1f3c63962)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 16:46:30,220] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 9f1c8837-1b0f-4b31-9e7f-d3c1f3c63962)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 16:46:30,221] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:50<9:42:01,  7.43s/it]                                                       {'loss': 0.011, 'grad_norm': 1.5304360389709473, 'learning_rate': 3.982203389830509e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:50<9:42:01,  7.43s/it] 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:53<8:06:08,  6.21s/it]                                                       {'loss': 0.0355, 'grad_norm': 2.5186095237731934, 'learning_rate': 3.98135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:53<8:06:08,  6.21s/it] 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:57<6:59:45,  5.36s/it]                                                       {'loss': 0.004, 'grad_norm': 0.5718199014663696, 'learning_rate': 3.980508474576272e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:57<6:59:45,  5.36s/it] 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:17:00<6:14:15,  4.78s/it]                                                       {'loss': 0.1138, 'grad_norm': 9.405486106872559, 'learning_rate': 3.979661016949153e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:17:00<6:14:15,  4.78s/it] 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:17:04<5:44:55,  4.41s/it]                                                       {'loss': 0.0622, 'grad_norm': 6.5199971199035645, 'learning_rate': 3.978813559322034e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:17:04<5:44:55,  4.41s/it] 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:17:07<5:23:24,  4.13s/it]                                                       {'loss': 0.0573, 'grad_norm': 4.47961950302124, 'learning_rate': 3.977966101694916e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:17:07<5:23:24,  4.13s/it] 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:17:10<5:04:48,  3.90s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.39630821347236633, 'learning_rate': 3.977118644067796e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:17:10<5:04:48,  3.90s/it] 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:17:14<4:54:32,  3.77s/it]                                                       {'loss': 0.1339, 'grad_norm': 10.72632884979248, 'learning_rate': 3.976271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:17:14<4:54:32,  3.77s/it] 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:17:17<4:45:52,  3.66s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.8356279134750366, 'learning_rate': 3.975423728813559e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:17:17<4:45:52,  3.66s/it] 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:17:21<4:39:34,  3.58s/it]                                                       {'loss': 0.074, 'grad_norm': 5.5865254402160645, 'learning_rate': 3.974576271186441e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:17:21<4:39:34,  3.58s/it] 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:17:24<4:32:37,  3.49s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.9475701451301575, 'learning_rate': 3.973728813559322e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:17:24<4:32:37,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:17:27<4:28:58,  3.44s/it]                                                       {'loss': 0.4255, 'grad_norm': 13.253002166748047, 'learning_rate': 3.972881355932204e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:17:27<4:28:58,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:17:31<4:27:15,  3.42s/it]                                                       {'loss': 0.0928, 'grad_norm': 5.245026588439941, 'learning_rate': 3.972033898305085e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:17:31<4:27:15,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:17:34<4:25:55,  3.40s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.6018015146255493, 'learning_rate': 3.971186440677966e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:17:34<4:25:55,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:17:37<4:24:15,  3.38s/it]                                                       {'loss': 0.2067, 'grad_norm': 5.984017848968506, 'learning_rate': 3.970338983050847e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:17:37<4:24:15,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:41<4:26:20,  3.41s/it]                                                       {'loss': 0.2679, 'grad_norm': 7.5775275230407715, 'learning_rate': 3.969491525423729e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:41<4:26:20,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:44<4:24:40,  3.39s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.08179100602865219, 'learning_rate': 3.96864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:44<4:24:40,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:48<4:24:57,  3.40s/it]                                                       {'loss': 0.0225, 'grad_norm': 2.079219102859497, 'learning_rate': 3.967796610169492e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:48<4:24:57,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:51<4:24:29,  3.39s/it]                                                       {'loss': 0.2581, 'grad_norm': 5.701136589050293, 'learning_rate': 3.966949152542373e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:51<4:24:29,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:54<4:25:28,  3.40s/it]                                                       {'loss': 0.064, 'grad_norm': 7.284287452697754, 'learning_rate': 3.966101694915255e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:54<4:25:28,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:58<4:27:14,  3.43s/it]                                                       {'loss': 0.0598, 'grad_norm': 7.42404317855835, 'learning_rate': 3.9652542372881354e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:58<4:27:14,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:18:02<4:38:28,  3.57s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.0292446613311768, 'learning_rate': 3.964406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:18:02<4:38:28,  3.57s/it] 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:18:05<4:37:15,  3.56s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.45896008610725403, 'learning_rate': 3.9635593220338983e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:18:05<4:37:15,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:18:09<4:33:17,  3.51s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.0350292921066284, 'learning_rate': 3.96271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:18:09<4:33:17,  3.51s/it] 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:18:12<4:29:01,  3.45s/it]                                                       {'loss': 0.0687, 'grad_norm': 4.204458713531494, 'learning_rate': 3.961864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:18:12<4:29:01,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:18:15<4:27:39,  3.44s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.020831823348999, 'learning_rate': 3.9610169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:18:15<4:27:39,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:18:19<4:27:19,  3.43s/it]                                                       {'loss': 0.0155, 'grad_norm': 2.1003365516662598, 'learning_rate': 3.960169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:18:19<4:27:19,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:18:22<4:27:17,  3.43s/it]                                                       {'loss': 0.038, 'grad_norm': 5.133124828338623, 'learning_rate': 3.9593220338983053e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:18:22<4:27:17,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:18:26<4:35:44,  3.54s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.7728413343429565, 'learning_rate': 3.9584745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:18:26<4:35:44,  3.54s/it] 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:18:29<4:33:04,  3.51s/it]                                                       {'loss': 0.1434, 'grad_norm': 5.7585930824279785, 'learning_rate': 3.9576271186440676e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:18:29<4:33:04,  3.51s/it] 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:18:33<4:32:30,  3.50s/it]                                                       {'loss': 0.0837, 'grad_norm': 7.010855197906494, 'learning_rate': 3.9567796610169494e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:18:33<4:32:30,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:18:36<4:28:34,  3.45s/it]                                                       {'loss': 0.0879, 'grad_norm': 6.82871150970459, 'learning_rate': 3.9559322033898305e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:18:36<4:28:34,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:40<4:29:24,  3.46s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.0914936065673828, 'learning_rate': 3.9550847457627123e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:40<4:29:24,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:43<4:29:19,  3.46s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.20531192421913147, 'learning_rate': 3.9542372881355935e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:43<4:29:19,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:47<4:26:03,  3.42s/it]                                                       {'loss': 0.1239, 'grad_norm': 6.019425392150879, 'learning_rate': 3.9533898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:47<4:26:03,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:50<4:23:59,  3.40s/it]                                                       {'loss': 0.0442, 'grad_norm': 6.092187881469727, 'learning_rate': 3.952542372881356e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:50<4:23:59,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:53<4:22:42,  3.38s/it]                                                       {'loss': 0.1389, 'grad_norm': 6.028584957122803, 'learning_rate': 3.9516949152542375e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:53<4:22:42,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:57<4:22:47,  3.38s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.1722099781036377, 'learning_rate': 3.9508474576271187e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:57<4:22:47,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:19:00<4:21:42,  3.37s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.1091089248657227, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:19:00<4:21:42,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:19:03<4:22:14,  3.38s/it]                                                       {'loss': 0.1272, 'grad_norm': 13.601963996887207, 'learning_rate': 3.9491525423728816e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:19:03<4:22:14,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:19:07<4:23:58,  3.40s/it]                                                       {'loss': 0.1985, 'grad_norm': 8.0054292678833, 'learning_rate': 3.9483050847457634e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:19:07<4:23:58,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:19:11<4:38:58,  3.59s/it]                                                       {'loss': 0.1677, 'grad_norm': 9.287947654724121, 'learning_rate': 3.9474576271186445e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:19:11<4:38:58,  3.59s/it] 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:19:15<4:44:21,  3.66s/it]                                                       {'loss': 0.0828, 'grad_norm': 5.56390380859375, 'learning_rate': 3.9466101694915257e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:19:15<4:44:21,  3.66s/it] 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:19:18<4:38:23,  3.59s/it]                                                       {'loss': 0.0048, 'grad_norm': 1.0770846605300903, 'learning_rate': 3.945762711864407e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:19:18<4:38:23,  3.59s/it] 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:19:22<4:42:08,  3.64s/it]                                                       {'loss': 0.1021, 'grad_norm': 5.291828632354736, 'learning_rate': 3.9449152542372886e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:19:22<4:42:08,  3.64s/it] 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:19:25<4:37:10,  3.57s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.7546041011810303, 'learning_rate': 3.94406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:19:25<4:37:10,  3.57s/it] 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:19:29<4:35:42,  3.56s/it]                                                       {'loss': 0.0052, 'grad_norm': 1.0257821083068848, 'learning_rate': 3.943220338983051e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:19:29<4:35:42,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:19:32<4:30:55,  3.49s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.6837756037712097, 'learning_rate': 3.9423728813559327e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:19:32<4:30:55,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:19:36<4:38:19,  3.59s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07792895287275314, 'learning_rate': 3.941525423728814e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:19:36<4:38:19,  3.59s/it] 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:40<4:38:59,  3.60s/it]                                                       {'loss': 0.0264, 'grad_norm': 3.2575130462646484, 'learning_rate': 3.940677966101695e-05, 'epoch': 0.23}
 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:40<4:38:59,  3.60s/it][2025-10-20 16:49:26,588] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:45<5:24:39,  4.19s/it]                                                       {'loss': 0.0, 'grad_norm': 0.003723874920979142, 'learning_rate': 3.939830508474576e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:45<5:24:39,  4.19s/it] 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:49<5:07:50,  3.97s/it]                                                       {'loss': 0.101, 'grad_norm': 6.239341735839844, 'learning_rate': 3.938983050847458e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:49<5:07:50,  3.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:52<4:58:58,  3.86s/it]                                                       {'loss': 0.0708, 'grad_norm': 7.446100234985352, 'learning_rate': 3.938135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:52<4:58:58,  3.86s/it] 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:56<4:49:16,  3.74s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.5006006360054016, 'learning_rate': 3.937288135593221e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:56<4:49:16,  3.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:59<4:44:09,  3.67s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7146063446998596, 'learning_rate': 3.936440677966102e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:59<4:44:09,  3.67s/it] 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:20:03<4:52:12,  3.78s/it]                                                       {'loss': 0.0094, 'grad_norm': 0.9976865649223328, 'learning_rate': 3.935593220338983e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:20:03<4:52:12,  3.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:20:07<4:47:19,  3.71s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.6066834926605225, 'learning_rate': 3.934745762711864e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:20:07<4:47:19,  3.71s/it] 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:20:10<4:41:28,  3.64s/it]                                                       {'loss': 0.0339, 'grad_norm': 3.691399335861206, 'learning_rate': 3.933898305084746e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:20:10<4:41:28,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:20:14<4:42:42,  3.65s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.18761596083641052, 'learning_rate': 3.933050847457627e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:20:14<4:42:42,  3.65s/it] 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:20:17<4:34:30,  3.55s/it]                                                       {'loss': 0.1337, 'grad_norm': 5.04359769821167, 'learning_rate': 3.932203389830509e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:20:17<4:34:30,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:20:21<4:30:00,  3.49s/it]                                                       {'loss': 0.1583, 'grad_norm': 10.745782852172852, 'learning_rate': 3.93135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:20:21<4:30:00,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:20:24<4:31:55,  3.52s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.8451719284057617, 'learning_rate': 3.930508474576272e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:20:24<4:31:55,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:20:28<4:30:27,  3.50s/it]                                                       {'loss': 0.001, 'grad_norm': 0.25338640809059143, 'learning_rate': 3.929661016949153e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:20:28<4:30:27,  3.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:20:31<4:26:35,  3.45s/it]                                                       {'loss': 0.0531, 'grad_norm': 5.2513227462768555, 'learning_rate': 3.928813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:20:31<4:26:35,  3.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:20:35<4:34:16,  3.55s/it]                                                       {'loss': 0.0227, 'grad_norm': 4.860089302062988, 'learning_rate': 3.927966101694915e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:20:35<4:34:16,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:20:39<4:42:33,  3.66s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.17353729903697968, 'learning_rate': 3.927118644067797e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:20:39<4:42:33,  3.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:43<4:47:28,  3.72s/it]                                                       {'loss': 0.1534, 'grad_norm': 6.735820293426514, 'learning_rate': 3.926271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:43<4:47:28,  3.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:46<4:39:51,  3.63s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.18586565554141998, 'learning_rate': 3.925423728813559e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:46<4:39:51,  3.63s/it] 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:49<4:34:54,  3.56s/it]                                                       {'loss': 0.0409, 'grad_norm': 3.643815040588379, 'learning_rate': 3.924576271186441e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:49<4:34:54,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:54<4:53:24,  3.80s/it]                                                       {'loss': 0.19, 'grad_norm': 5.140664577484131, 'learning_rate': 3.923728813559322e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:54<4:53:24,  3.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:57<4:46:57,  3.72s/it]                                                       {'loss': 0.1043, 'grad_norm': 6.287807464599609, 'learning_rate': 3.9228813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:57<4:46:57,  3.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:21:01<4:39:19,  3.62s/it]                                                       {'loss': 0.0187, 'grad_norm': 2.7587382793426514, 'learning_rate': 3.9220338983050845e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:21:01<4:39:19,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:21:04<4:37:31,  3.60s/it]                                                       {'loss': 0.075, 'grad_norm': 7.3234357833862305, 'learning_rate': 3.921186440677966e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:21:04<4:37:31,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:21:08<4:37:46,  3.60s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.05907251685857773, 'learning_rate': 3.9203389830508474e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:21:08<4:37:46,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:21:11<4:32:56,  3.54s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.8387101888656616, 'learning_rate': 3.919491525423729e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:21:11<4:32:56,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:21:15<4:34:50,  3.57s/it]                                                       {'loss': 0.3359, 'grad_norm': 14.33130931854248, 'learning_rate': 3.9186440677966104e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:21:15<4:34:50,  3.57s/it] 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:21:18<4:30:22,  3.51s/it]                                                       {'loss': 0.1269, 'grad_norm': 5.80757474899292, 'learning_rate': 3.917796610169492e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:21:18<4:30:22,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:21:22<4:25:53,  3.45s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.1907923221588135, 'learning_rate': 3.9169491525423726e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:21:22<4:25:53,  3.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:21:25<4:24:30,  3.43s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.1999177932739258, 'learning_rate': 3.9161016949152544e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:21:25<4:24:30,  3.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:21:28<4:21:52,  3.40s/it]                                                       {'loss': 0.0496, 'grad_norm': 3.392305612564087, 'learning_rate': 3.9152542372881355e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:21:28<4:21:52,  3.40s/it] 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:21:32<4:30:02,  3.51s/it]                                                       {'loss': 0.3295, 'grad_norm': 12.407483100891113, 'learning_rate': 3.9144067796610174e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:21:32<4:30:02,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:21:35<4:29:57,  3.51s/it]                                                       {'loss': 0.1865, 'grad_norm': 6.668079853057861, 'learning_rate': 3.9135593220338985e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:21:35<4:29:57,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:21:39<4:30:58,  3.52s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.46188464760780334, 'learning_rate': 3.91271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:21:39<4:30:58,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:43<4:41:11,  3.66s/it]                                                       {'loss': 0.1628, 'grad_norm': 4.37266206741333, 'learning_rate': 3.9118644067796614e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:43<4:41:11,  3.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:46<4:35:59,  3.59s/it]                                                       {'loss': 0.0407, 'grad_norm': 4.388225078582764, 'learning_rate': 3.9110169491525425e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:46<4:35:59,  3.59s/it] 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:50<4:33:21,  3.55s/it]                                                       {'loss': 0.1224, 'grad_norm': 8.331428527832031, 'learning_rate': 3.910169491525424e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:50<4:33:21,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:53<4:28:31,  3.49s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.0207849740982056, 'learning_rate': 3.9093220338983055e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:53<4:28:31,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:57<4:29:47,  3.51s/it]                                                       {'loss': 0.1323, 'grad_norm': 6.935400485992432, 'learning_rate': 3.9084745762711866e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:57<4:29:47,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:22:01<4:45:34,  3.72s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07653100043535233, 'learning_rate': 3.907627118644068e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:22:01<4:45:34,  3.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:22:04<4:38:06,  3.62s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02116689644753933, 'learning_rate': 3.9067796610169495e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:22:04<4:38:06,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:22:08<4:32:08,  3.54s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.059309720993042, 'learning_rate': 3.905932203389831e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:22:08<4:32:08,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:22:11<4:29:38,  3.51s/it]                                                       {'loss': 0.0311, 'grad_norm': 4.109460353851318, 'learning_rate': 3.905084745762712e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:22:11<4:29:38,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:22:15<4:29:17,  3.51s/it]                                                       {'loss': 0.0232, 'grad_norm': 2.2183070182800293, 'learning_rate': 3.904237288135593e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:22:15<4:29:17,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:22:18<4:25:41,  3.46s/it]                                                       {'loss': 0.0811, 'grad_norm': 3.70698881149292, 'learning_rate': 3.903389830508475e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:22:18<4:25:41,  3.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:22:22<4:25:48,  3.46s/it]                                                       {'loss': 0.2168, 'grad_norm': 6.55880880355835, 'learning_rate': 3.902542372881356e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:22:22<4:25:48,  3.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:22:25<4:24:57,  3.45s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09699949622154236, 'learning_rate': 3.901694915254238e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:22:25<4:24:57,  3.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:22:28<4:23:45,  3.44s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.631698727607727, 'learning_rate': 3.900847457627119e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:22:28<4:23:45,  3.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:22:32<4:22:02,  3.42s/it]                                                       {'loss': 0.0886, 'grad_norm': 6.946213245391846, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:22:32<4:22:02,  3.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:22:35<4:20:14,  3.39s/it]                                                       {'loss': 0.2632, 'grad_norm': 6.736028671264648, 'learning_rate': 3.899152542372882e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:22:35<4:20:14,  3.39s/it] 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:22:38<4:19:18,  3.38s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.245011329650879, 'learning_rate': 3.898305084745763e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:22:38<4:19:18,  3.38s/it][2025-10-20 16:52:25,413] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:44<5:10:26,  4.05s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.700165867805481, 'learning_rate': 3.897457627118644e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:44<5:10:26,  4.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:47<4:55:56,  3.86s/it]                                                       {'loss': 0.2518, 'grad_norm': 8.555957794189453, 'learning_rate': 3.896610169491526e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:47<4:55:56,  3.86s/it] 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:51<4:44:12,  3.71s/it]                                                       {'loss': 0.0186, 'grad_norm': 3.1591169834136963, 'learning_rate': 3.895762711864407e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:51<4:44:12,  3.71s/it] 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:54<4:36:26,  3.61s/it]                                                       {'loss': 0.0509, 'grad_norm': 2.797913074493408, 'learning_rate': 3.894915254237289e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:54<4:36:26,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:58<4:31:24,  3.54s/it]                                                       {'loss': 0.1395, 'grad_norm': 6.440431594848633, 'learning_rate': 3.89406779661017e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:58<4:31:24,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:23:01<4:29:14,  3.52s/it]                                                       {'loss': 0.0525, 'grad_norm': 3.2605104446411133, 'learning_rate': 3.893220338983051e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:23:01<4:29:14,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:23:05<4:36:08,  3.61s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.2623947560787201, 'learning_rate': 3.892372881355932e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:23:05<4:36:08,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:23:08<4:32:50,  3.56s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07388333231210709, 'learning_rate': 3.891525423728814e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:23:08<4:32:50,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:23:12<4:29:02,  3.52s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4121597707271576, 'learning_rate': 3.890677966101695e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:23:12<4:29:02,  3.52s/it] 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:23:15<4:34:30,  3.59s/it]                                                       {'loss': 0.0364, 'grad_norm': 2.0471668243408203, 'learning_rate': 3.889830508474576e-05, 'epoch': 0.23}
 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:23:15<4:34:30,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:23:19<4:31:17,  3.55s/it]                                                       {'loss': 0.0114, 'grad_norm': 0.9505535364151001, 'learning_rate': 3.888983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:23:19<4:31:17,  3.55s/it] 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:23:23<4:41:01,  3.68s/it]                                                       {'loss': 0.0963, 'grad_norm': 6.777745246887207, 'learning_rate': 3.888135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:23:23<4:41:01,  3.68s/it] 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:23:26<4:32:58,  3.57s/it]                                                       {'loss': 0.003, 'grad_norm': 0.436691015958786, 'learning_rate': 3.88728813559322e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:23:26<4:32:58,  3.57s/it] 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:23:30<4:27:35,  3.50s/it]                                                       {'loss': 0.2513, 'grad_norm': 6.743534564971924, 'learning_rate': 3.8864406779661014e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:23:30<4:27:35,  3.50s/it] 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:23:33<4:34:18,  3.59s/it]                                                       {'loss': 0.0676, 'grad_norm': 6.97780179977417, 'learning_rate': 3.885593220338983e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:23:33<4:34:18,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:23:37<4:29:23,  3.53s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5700104832649231, 'learning_rate': 3.884745762711864e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:23:37<4:29:23,  3.53s/it] 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:23:40<4:30:16,  3.54s/it]                                                       {'loss': 0.1029, 'grad_norm': 5.556420803070068, 'learning_rate': 3.883898305084746e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:23:40<4:30:16,  3.54s/it] 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:44<4:27:42,  3.51s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.13129059970378876, 'learning_rate': 3.883050847457627e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:44<4:27:42,  3.51s/it] 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:47<4:30:34,  3.54s/it]                                                       {'loss': 0.0634, 'grad_norm': 3.107386827468872, 'learning_rate': 3.882203389830509e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:47<4:30:34,  3.54s/it] 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:51<4:27:08,  3.50s/it]                                                       {'loss': 0.0476, 'grad_norm': 2.2638473510742188, 'learning_rate': 3.88135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:51<4:27:08,  3.50s/it] 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:54<4:25:41,  3.48s/it]                                                       {'loss': 0.0144, 'grad_norm': 0.9937430620193481, 'learning_rate': 3.880508474576271e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:54<4:25:41,  3.48s/it] 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:58<4:24:19,  3.46s/it]                                                       {'loss': 0.0929, 'grad_norm': 9.848457336425781, 'learning_rate': 3.8796610169491524e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:58<4:24:19,  3.46s/it] 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:24:01<4:22:30,  3.44s/it]                                                       {'loss': 0.026, 'grad_norm': 3.1857733726501465, 'learning_rate': 3.878813559322034e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:24:01<4:22:30,  3.44s/it] 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:24:04<4:21:35,  3.43s/it]                                                       {'loss': 0.2759, 'grad_norm': 9.671354293823242, 'learning_rate': 3.8779661016949154e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:24:04<4:21:35,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:24:08<4:24:12,  3.47s/it]                                                       {'loss': 0.1571, 'grad_norm': 10.122115135192871, 'learning_rate': 3.877118644067797e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:24:08<4:24:12,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:24:12<4:31:29,  3.56s/it]                                                       {'loss': 0.1203, 'grad_norm': 6.535243988037109, 'learning_rate': 3.876271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:24:12<4:31:29,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:24:15<4:28:25,  3.52s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.1759530305862427, 'learning_rate': 3.8754237288135594e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:24:15<4:28:25,  3.52s/it] 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:24:19<4:27:26,  3.51s/it]                                                       {'loss': 0.1973, 'grad_norm': 10.025284767150879, 'learning_rate': 3.8745762711864406e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:24:19<4:27:26,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:24:22<4:25:01,  3.48s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.5170459747314453, 'learning_rate': 3.8737288135593224e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:24:22<4:25:01,  3.48s/it] 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:24:25<4:22:49,  3.45s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.8903500437736511, 'learning_rate': 3.8728813559322035e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:24:25<4:22:49,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:24:29<4:22:55,  3.45s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.1352543830871582, 'learning_rate': 3.8720338983050846e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:24:29<4:22:55,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:24:32<4:21:04,  3.43s/it]                                                       {'loss': 0.0158, 'grad_norm': 3.186640977859497, 'learning_rate': 3.8711864406779664e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:24:32<4:21:04,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:24:36<4:32:19,  3.58s/it]                                                       {'loss': 0.027, 'grad_norm': 2.7675669193267822, 'learning_rate': 3.8703389830508476e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:24:36<4:32:19,  3.58s/it] 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:24:40<4:31:03,  3.56s/it]                                                       {'loss': 0.0101, 'grad_norm': 0.9017928242683411, 'learning_rate': 3.8694915254237294e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:24:40<4:31:03,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:43<4:26:06,  3.50s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.18532122671604156, 'learning_rate': 3.86864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:43<4:26:06,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:47<4:30:29,  3.56s/it]                                                       {'loss': 0.0542, 'grad_norm': 3.0464518070220947, 'learning_rate': 3.8677966101694916e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:47<4:30:29,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:50<4:29:09,  3.54s/it]                                                       {'loss': 0.0992, 'grad_norm': 4.496631145477295, 'learning_rate': 3.866949152542373e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:50<4:29:09,  3.54s/it] 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:54<4:26:25,  3.50s/it]                                                       {'loss': 0.0179, 'grad_norm': 1.4448723793029785, 'learning_rate': 3.8661016949152546e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:54<4:26:25,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:57<4:24:04,  3.47s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.561648428440094, 'learning_rate': 3.865254237288136e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:57<4:24:04,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:25:00<4:22:07,  3.45s/it]                                                       {'loss': 0.0433, 'grad_norm': 5.169166564941406, 'learning_rate': 3.8644067796610175e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:25:00<4:22:07,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:25:04<4:18:54,  3.41s/it]                                                       {'loss': 0.1169, 'grad_norm': 5.668966770172119, 'learning_rate': 3.8635593220338986e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:25:04<4:18:54,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:25:07<4:20:52,  3.43s/it]                                                       {'loss': 0.2003, 'grad_norm': 9.637240409851074, 'learning_rate': 3.86271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:25:07<4:20:52,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:25:11<4:17:32,  3.39s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.188291311264038, 'learning_rate': 3.861864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:25:11<4:17:32,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:25:14<4:17:04,  3.39s/it]                                                       {'loss': 0.0251, 'grad_norm': 2.7763142585754395, 'learning_rate': 3.861016949152543e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:25:14<4:17:04,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:25:17<4:15:43,  3.37s/it]                                                       {'loss': 0.1106, 'grad_norm': 9.314473152160645, 'learning_rate': 3.860169491525424e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:25:17<4:15:43,  3.37s/it] 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:25:21<4:14:45,  3.36s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.4204914569854736, 'learning_rate': 3.8593220338983056e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:25:21<4:14:45,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:25:24<4:14:10,  3.35s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.1170611381530762, 'learning_rate': 3.858474576271187e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:25:24<4:14:10,  3.35s/it] 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:25:27<4:14:36,  3.36s/it]                                                       {'loss': 0.7449, 'grad_norm': 15.354247093200684, 'learning_rate': 3.8576271186440686e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:25:27<4:14:36,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:25:31<4:15:14,  3.37s/it]                                                       {'loss': 0.006, 'grad_norm': 0.5543031096458435, 'learning_rate': 3.856779661016949e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:25:31<4:15:14,  3.37s/it] 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:25:34<4:14:31,  3.36s/it]                                                       {'loss': 0.0434, 'grad_norm': 3.109912633895874, 'learning_rate': 3.855932203389831e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:25:34<4:14:31,  3.36s/it][2025-10-20 16:55:21,036] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:25:41<5:45:43,  4.56s/it]                                                       {'loss': 0.0499, 'grad_norm': 3.381070137023926, 'learning_rate': 3.855084745762712e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:25:41<5:45:43,  4.56s/it] 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:25:45<5:18:42,  4.20s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.156351089477539, 'learning_rate': 3.854237288135593e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:25:45<5:18:42,  4.20s/it] 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:48<4:58:56,  3.94s/it]                                                       {'loss': 0.2155, 'grad_norm': 8.74717903137207, 'learning_rate': 3.853389830508475e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:48<4:58:56,  3.94s/it] 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:51<4:45:41,  3.77s/it]                                                       {'loss': 0.0427, 'grad_norm': 2.0695853233337402, 'learning_rate': 3.852542372881356e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:51<4:45:41,  3.77s/it] 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:55<4:35:31,  3.64s/it]                                                       {'loss': 0.0497, 'grad_norm': 2.1664929389953613, 'learning_rate': 3.851694915254238e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:55<4:35:31,  3.64s/it] 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:58<4:32:03,  3.59s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2509164810180664, 'learning_rate': 3.850847457627119e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:58<4:32:03,  3.59s/it] 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:26:02<4:27:33,  3.53s/it]                                                       {'loss': 0.0571, 'grad_norm': 4.273733615875244, 'learning_rate': 3.85e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:26:02<4:27:33,  3.53s/it] 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:26:05<4:25:41,  3.51s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07051201909780502, 'learning_rate': 3.849152542372881e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:26:05<4:25:41,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:26:09<4:27:43,  3.54s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.4299964904785156, 'learning_rate': 3.848305084745763e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:26:09<4:27:43,  3.54s/it] 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:26:12<4:22:46,  3.47s/it]                                                       {'loss': 0.1704, 'grad_norm': 19.409332275390625, 'learning_rate': 3.847457627118644e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:26:12<4:22:46,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:26:16<4:29:50,  3.57s/it]                                                       {'loss': 0.0388, 'grad_norm': 1.3861703872680664, 'learning_rate': 3.846610169491526e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:26:16<4:29:50,  3.57s/it] 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:26:19<4:25:48,  3.51s/it]                                                       {'loss': 0.0168, 'grad_norm': 2.4711427688598633, 'learning_rate': 3.845762711864407e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:26:19<4:25:48,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:26:23<4:24:31,  3.50s/it]                                                       {'loss': 0.0974, 'grad_norm': 6.101795196533203, 'learning_rate': 3.844915254237288e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:26:23<4:24:31,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:26:26<4:20:39,  3.45s/it]                                                       {'loss': 0.2058, 'grad_norm': 11.104400634765625, 'learning_rate': 3.844067796610169e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:26:26<4:20:39,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:26:30<4:21:23,  3.46s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.327709913253784, 'learning_rate': 3.843220338983051e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:26:30<4:21:23,  3.46s/it] 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:26:33<4:18:59,  3.43s/it]                                                       {'loss': 0.0626, 'grad_norm': 4.948564529418945, 'learning_rate': 3.842372881355932e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:26:33<4:18:59,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:26:36<4:19:13,  3.43s/it]                                                       {'loss': 0.0266, 'grad_norm': 1.669670820236206, 'learning_rate': 3.841525423728814e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:26:36<4:19:13,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:26:40<4:18:50,  3.43s/it]                                                       {'loss': 0.1797, 'grad_norm': 10.62961483001709, 'learning_rate': 3.840677966101695e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:26:40<4:18:50,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:26:43<4:25:39,  3.52s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.2771706581115723, 'learning_rate': 3.839830508474577e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:26:43<4:25:39,  3.52s/it] 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:47<4:23:57,  3.50s/it]                                                       {'loss': 0.196, 'grad_norm': 9.031394004821777, 'learning_rate': 3.838983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:47<4:23:57,  3.50s/it] 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:50<4:23:00,  3.48s/it]                                                       {'loss': 0.2066, 'grad_norm': 9.598482131958008, 'learning_rate': 3.838135593220339e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:50<4:23:00,  3.48s/it] 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:54<4:21:16,  3.46s/it]                                                       {'loss': 0.0151, 'grad_norm': 1.9680135250091553, 'learning_rate': 3.8372881355932204e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:54<4:21:16,  3.46s/it] 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:57<4:19:45,  3.44s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.3700029850006104, 'learning_rate': 3.8364406779661015e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:57<4:19:45,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:27:01<4:16:58,  3.41s/it]                                                       {'loss': 0.0117, 'grad_norm': 2.0389649868011475, 'learning_rate': 3.835593220338983e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:27:01<4:16:58,  3.41s/it] 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:27:05<4:33:03,  3.62s/it]                                                       {'loss': 0.1791, 'grad_norm': 8.0737943649292, 'learning_rate': 3.8347457627118644e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:27:05<4:33:03,  3.62s/it] 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:27:08<4:27:06,  3.54s/it]                                                       {'loss': 0.0615, 'grad_norm': 3.8186893463134766, 'learning_rate': 3.833898305084746e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:27:08<4:27:06,  3.54s/it] 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:27:11<4:23:27,  3.50s/it]                                                       {'loss': 0.0561, 'grad_norm': 6.204940319061279, 'learning_rate': 3.8330508474576274e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:27:11<4:23:27,  3.50s/it] 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:27:15<4:20:10,  3.45s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.6570867300033569, 'learning_rate': 3.8322033898305085e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:27:15<4:20:10,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:27:18<4:19:34,  3.44s/it]                                                       {'loss': 0.1468, 'grad_norm': 7.835840225219727, 'learning_rate': 3.8313559322033896e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:27:18<4:19:34,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:27:22<4:17:54,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3593912422657013, 'learning_rate': 3.8305084745762714e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:27:22<4:17:54,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:27:25<4:15:12,  3.39s/it]                                                       {'loss': 0.1277, 'grad_norm': 7.460060119628906, 'learning_rate': 3.8296610169491526e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:27:25<4:15:12,  3.39s/it] 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:27:28<4:15:00,  3.39s/it]                                                       {'loss': 0.1251, 'grad_norm': 6.264351844787598, 'learning_rate': 3.8288135593220344e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:27:28<4:15:00,  3.39s/it] 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:27:32<4:15:20,  3.39s/it]                                                       {'loss': 0.0306, 'grad_norm': 3.5305254459381104, 'learning_rate': 3.8279661016949155e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:27:32<4:15:20,  3.39s/it] 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:27:35<4:13:34,  3.37s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.45381036400794983, 'learning_rate': 3.8271186440677966e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:27:35<4:13:34,  3.37s/it] 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:27:38<4:15:25,  3.39s/it]                                                       {'loss': 0.2531, 'grad_norm': 7.281516075134277, 'learning_rate': 3.826271186440678e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:27:38<4:15:25,  3.39s/it] 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:27:42<4:16:06,  3.40s/it]                                                       {'loss': 0.0199, 'grad_norm': 3.8325324058532715, 'learning_rate': 3.8254237288135596e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:27:42<4:16:06,  3.40s/it] 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:46<4:25:32,  3.53s/it]                                                       {'loss': 0.1509, 'grad_norm': 6.205417156219482, 'learning_rate': 3.824576271186441e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:46<4:25:32,  3.53s/it] 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:49<4:22:14,  3.49s/it]                                                       {'loss': 0.0267, 'grad_norm': 2.750779390335083, 'learning_rate': 3.8237288135593225e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:49<4:22:14,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:53<4:29:09,  3.58s/it]                                                       {'loss': 0.1002, 'grad_norm': 6.134499549865723, 'learning_rate': 3.8228813559322036e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:53<4:29:09,  3.58s/it] 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:56<4:28:54,  3.58s/it]                                                       {'loss': 0.1002, 'grad_norm': 4.824256420135498, 'learning_rate': 3.8220338983050854e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:56<4:28:54,  3.58s/it] 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:28:00<4:25:30,  3.53s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.8142581582069397, 'learning_rate': 3.8211864406779666e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:28:00<4:25:30,  3.53s/it] 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:28:04<4:33:13,  3.64s/it]                                                       {'loss': 0.016, 'grad_norm': 1.2263188362121582, 'learning_rate': 3.820338983050848e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:28:04<4:33:13,  3.64s/it] 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:28:07<4:26:05,  3.54s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.6086924076080322, 'learning_rate': 3.819491525423729e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:28:07<4:26:05,  3.54s/it] 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:28:10<4:22:19,  3.49s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4267898201942444, 'learning_rate': 3.81864406779661e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:28:10<4:22:19,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:28:14<4:19:02,  3.45s/it]                                                       {'loss': 0.191, 'grad_norm': 8.240904808044434, 'learning_rate': 3.817796610169492e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:28:14<4:19:02,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:28:17<4:19:16,  3.45s/it]                                                       {'loss': 0.149, 'grad_norm': 6.752102375030518, 'learning_rate': 3.816949152542373e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:28:17<4:19:16,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:28:21<4:19:29,  3.46s/it]                                                       {'loss': 0.2129, 'grad_norm': 10.952317237854004, 'learning_rate': 3.816101694915255e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:28:21<4:19:29,  3.46s/it] 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:28:24<4:18:07,  3.44s/it]                                                       {'loss': 0.0437, 'grad_norm': 3.416027307510376, 'learning_rate': 3.815254237288136e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:28:24<4:18:07,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:28:27<4:16:59,  3.43s/it]                                                       {'loss': 0.005, 'grad_norm': 0.5643967986106873, 'learning_rate': 3.814406779661017e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:28:27<4:16:59,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:28:31<4:17:18,  3.43s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3564528822898865, 'learning_rate': 3.813559322033898e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:28:31<4:17:18,  3.43s/it][2025-10-20 16:58:17,907] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:28:37<5:09:08,  4.12s/it]                                                       {'loss': 0.0356, 'grad_norm': 2.7116315364837646, 'learning_rate': 3.81271186440678e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:28:37<5:09:08,  4.12s/it] 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:28:40<4:54:55,  3.93s/it]                                                       {'loss': 0.1024, 'grad_norm': 21.437541961669922, 'learning_rate': 3.811864406779661e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:28:40<4:54:55,  3.93s/it] 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:28:43<4:40:57,  3.75s/it]                                                       {'loss': 0.1005, 'grad_norm': 4.601918697357178, 'learning_rate': 3.811016949152543e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:28:43<4:40:57,  3.75s/it] 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:47<4:34:03,  3.66s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5986955165863037, 'learning_rate': 3.810169491525424e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:47<4:34:03,  3.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:50<4:28:06,  3.58s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0667426735162735, 'learning_rate': 3.809322033898306e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:50<4:28:06,  3.58s/it] 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:54<4:25:22,  3.54s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.9514997601509094, 'learning_rate': 3.808474576271186e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:54<4:25:22,  3.54s/it] 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:57<4:23:19,  3.52s/it]                                                       {'loss': 0.1637, 'grad_norm': 6.55642557144165, 'learning_rate': 3.807627118644068e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:57<4:23:19,  3.52s/it] 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:29:01<4:23:01,  3.51s/it]                                                       {'loss': 0.0434, 'grad_norm': 3.5574023723602295, 'learning_rate': 3.806779661016949e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:29:01<4:23:01,  3.51s/it] 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:29:04<4:21:03,  3.49s/it]                                                       {'loss': 0.0847, 'grad_norm': 7.446863651275635, 'learning_rate': 3.805932203389831e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:29:04<4:21:03,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:29:08<4:22:58,  3.51s/it]                                                       {'loss': 0.0654, 'grad_norm': 3.3450653553009033, 'learning_rate': 3.805084745762712e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:29:08<4:22:58,  3.51s/it] 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:29:11<4:20:09,  3.48s/it]                                                       {'loss': 0.0576, 'grad_norm': 7.0854997634887695, 'learning_rate': 3.804237288135594e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:29:11<4:20:09,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:29:15<4:18:29,  3.46s/it]                                                       {'loss': 0.0828, 'grad_norm': 6.638324737548828, 'learning_rate': 3.803389830508475e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:29:15<4:18:29,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:29:18<4:20:16,  3.48s/it]                                                       {'loss': 0.0672, 'grad_norm': 5.156335830688477, 'learning_rate': 3.802542372881356e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:29:18<4:20:16,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:29:21<4:17:33,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.29856422543525696, 'learning_rate': 3.801694915254237e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:29:21<4:17:33,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:29:25<4:15:23,  3.42s/it]                                                       {'loss': 0.0456, 'grad_norm': 4.658865451812744, 'learning_rate': 3.8008474576271184e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:29:25<4:15:23,  3.42s/it] 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:29:28<4:15:43,  3.42s/it]                                                       {'loss': 0.1453, 'grad_norm': 6.842827320098877, 'learning_rate': 3.8e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:29:28<4:15:43,  3.42s/it] 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:29:32<4:21:45,  3.50s/it]                                                       {'loss': 0.1409, 'grad_norm': 6.927421569824219, 'learning_rate': 3.799152542372881e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:29:32<4:21:45,  3.50s/it] 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:29:35<4:19:02,  3.47s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.058959722518921, 'learning_rate': 3.798305084745763e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:29:35<4:19:02,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:29:39<4:16:19,  3.43s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.0257236957550049, 'learning_rate': 3.797457627118644e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:29:39<4:16:19,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:29:42<4:20:25,  3.49s/it]                                                       {'loss': 0.0642, 'grad_norm': 4.152466297149658, 'learning_rate': 3.7966101694915254e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:29:42<4:20:25,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:46<4:17:42,  3.45s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.2045851945877075, 'learning_rate': 3.7957627118644065e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:46<4:17:42,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:49<4:16:53,  3.44s/it]                                                       {'loss': 0.1613, 'grad_norm': 5.4465861320495605, 'learning_rate': 3.794915254237288e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:49<4:16:53,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:52<4:15:22,  3.42s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.316864490509033, 'learning_rate': 3.7940677966101695e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:52<4:15:22,  3.42s/it] 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:56<4:14:29,  3.41s/it]                                                       {'loss': 0.143, 'grad_norm': 7.666022777557373, 'learning_rate': 3.793220338983051e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:56<4:14:29,  3.41s/it] 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:59<4:17:53,  3.46s/it]                                                       {'loss': 0.0383, 'grad_norm': 2.5669052600860596, 'learning_rate': 3.7923728813559324e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:59<4:17:53,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:30:03<4:18:39,  3.47s/it]                                                       {'loss': 0.0126, 'grad_norm': 1.5134090185165405, 'learning_rate': 3.791525423728814e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:30:03<4:18:39,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:30:07<4:26:37,  3.58s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.7211050987243652, 'learning_rate': 3.790677966101695e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:30:07<4:26:37,  3.58s/it] 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:30:11<4:36:32,  3.71s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.40273451805114746, 'learning_rate': 3.7898305084745765e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:30:11<4:36:32,  3.71s/it] 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:30:14<4:28:17,  3.60s/it]                                                       {'loss': 0.0233, 'grad_norm': 3.58506441116333, 'learning_rate': 3.7889830508474576e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:30:14<4:28:17,  3.60s/it] 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:30:18<4:34:30,  3.68s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09354289621114731, 'learning_rate': 3.7881355932203394e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:30:18<4:34:30,  3.68s/it] 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:30:21<4:27:48,  3.60s/it]                                                       {'loss': 0.0208, 'grad_norm': 2.2387683391571045, 'learning_rate': 3.7872881355932205e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:30:21<4:27:48,  3.60s/it] 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:30:25<4:21:28,  3.51s/it]                                                       {'loss': 0.0963, 'grad_norm': 5.123606204986572, 'learning_rate': 3.786440677966102e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:30:25<4:21:28,  3.51s/it] 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:30:28<4:17:56,  3.46s/it]                                                       {'loss': 0.0377, 'grad_norm': 3.4288244247436523, 'learning_rate': 3.7855932203389835e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:30:28<4:17:56,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:30:31<4:15:33,  3.43s/it]                                                       {'loss': 0.059, 'grad_norm': 5.189263343811035, 'learning_rate': 3.7847457627118646e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:30:31<4:15:33,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:30:35<4:13:14,  3.40s/it]                                                       {'loss': 0.0747, 'grad_norm': 5.101355075836182, 'learning_rate': 3.783898305084746e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:30:35<4:13:14,  3.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:30:38<4:10:13,  3.36s/it]                                                       {'loss': 0.1174, 'grad_norm': 6.983700752258301, 'learning_rate': 3.783050847457627e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:30:38<4:10:13,  3.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:30:41<4:11:20,  3.38s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.0966598987579346, 'learning_rate': 3.7822033898305087e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:30:41<4:11:20,  3.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:45<4:15:44,  3.44s/it]                                                       {'loss': 0.0498, 'grad_norm': 1.6529029607772827, 'learning_rate': 3.78135593220339e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:45<4:15:44,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:49<4:19:26,  3.49s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.26428312063217163, 'learning_rate': 3.7805084745762716e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:49<4:19:26,  3.49s/it] 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:52<4:18:53,  3.48s/it]                                                       {'loss': 0.1617, 'grad_norm': 7.289057731628418, 'learning_rate': 3.779661016949153e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:52<4:18:53,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:56<4:22:35,  3.53s/it]                                                       {'loss': 0.1316, 'grad_norm': 7.7462592124938965, 'learning_rate': 3.778813559322034e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:56<4:22:35,  3.53s/it] 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:59<4:18:41,  3.48s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.1184578612446785, 'learning_rate': 3.777966101694915e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:59<4:18:41,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:31:03<4:18:41,  3.48s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0038746497593820095, 'learning_rate': 3.777118644067797e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:31:03<4:18:41,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:31:06<4:16:40,  3.46s/it]                                                       {'loss': 0.0617, 'grad_norm': 6.112326622009277, 'learning_rate': 3.776271186440678e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:31:06<4:16:40,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:31:09<4:16:00,  3.45s/it]                                                       {'loss': 0.1412, 'grad_norm': 4.329684734344482, 'learning_rate': 3.77542372881356e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:31:09<4:16:00,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:31:13<4:16:24,  3.45s/it]                                                       {'loss': 0.0316, 'grad_norm': 4.383584499359131, 'learning_rate': 3.774576271186441e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:31:13<4:16:24,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:31:16<4:14:23,  3.43s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.337857961654663, 'learning_rate': 3.7737288135593226e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:31:16<4:14:23,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:31:20<4:13:18,  3.41s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.1615253686904907, 'learning_rate': 3.772881355932204e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:31:20<4:13:18,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:31:23<4:13:47,  3.42s/it]                                                       {'loss': 0.029, 'grad_norm': 2.757117748260498, 'learning_rate': 3.772033898305085e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:31:23<4:13:47,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:31:26<4:14:12,  3.43s/it]                                                       {'loss': 0.049, 'grad_norm': 5.09774112701416, 'learning_rate': 3.771186440677966e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:31:26<4:14:12,  3.43s/it][2025-10-20 17:01:13,430] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:31:32<5:01:26,  4.07s/it]                                                       {'loss': 0.0254, 'grad_norm': 0.676588237285614, 'learning_rate': 3.770338983050848e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:31:32<5:01:26,  4.07s/it] 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:31:35<4:46:34,  3.87s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.0103065967559814, 'learning_rate': 3.769491525423729e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:31:35<4:46:34,  3.87s/it] 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:31:39<4:33:30,  3.69s/it]                                                       {'loss': 0.0741, 'grad_norm': 3.829516649246216, 'learning_rate': 3.768644067796611e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:31:39<4:33:30,  3.69s/it] 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:31:42<4:27:06,  3.60s/it]                                                       {'loss': 0.0614, 'grad_norm': 5.10531759262085, 'learning_rate': 3.767796610169492e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:31:42<4:27:06,  3.60s/it] 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:31:45<4:20:20,  3.51s/it]                                                       {'loss': 0.0263, 'grad_norm': 2.158623218536377, 'learning_rate': 3.766949152542373e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:31:45<4:20:20,  3.51s/it] 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:49<4:16:06,  3.46s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.2985395193099976, 'learning_rate': 3.766101694915254e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:49<4:16:06,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:52<4:14:51,  3.44s/it]                                                       {'loss': 0.1091, 'grad_norm': 5.365916728973389, 'learning_rate': 3.765254237288135e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:52<4:14:51,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:55<4:13:31,  3.42s/it]                                                       {'loss': 0.0368, 'grad_norm': 1.9086848497390747, 'learning_rate': 3.764406779661017e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:55<4:13:31,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:59<4:23:18,  3.56s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.8255347013473511, 'learning_rate': 3.763559322033898e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:59<4:23:18,  3.56s/it] 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:32:03<4:20:18,  3.52s/it]                                                       {'loss': 0.0671, 'grad_norm': 4.370532989501953, 'learning_rate': 3.76271186440678e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:32:03<4:20:18,  3.52s/it] 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:32:06<4:19:00,  3.50s/it]                                                       {'loss': 0.0566, 'grad_norm': 1.8593872785568237, 'learning_rate': 3.761864406779661e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:32:06<4:19:00,  3.50s/it] 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:32:10<4:19:51,  3.51s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.460478276014328, 'learning_rate': 3.761016949152543e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:32:10<4:19:51,  3.51s/it] 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:32:13<4:16:27,  3.47s/it]                                                       {'loss': 0.0343, 'grad_norm': 4.185353755950928, 'learning_rate': 3.7601694915254234e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:32:13<4:16:27,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:32:17<4:14:50,  3.45s/it]                                                       {'loss': 0.0748, 'grad_norm': 5.926108360290527, 'learning_rate': 3.759322033898305e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:32:17<4:14:50,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:32:20<4:11:44,  3.41s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0374436154961586, 'learning_rate': 3.7584745762711864e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:32:20<4:11:44,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:32:24<4:17:04,  3.48s/it]                                                       {'loss': 0.0546, 'grad_norm': 5.470603942871094, 'learning_rate': 3.757627118644068e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:32:24<4:17:04,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:32:27<4:15:32,  3.46s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.036875564604997635, 'learning_rate': 3.756779661016949e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:32:27<4:15:32,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:32:30<4:13:08,  3.43s/it]                                                       {'loss': 0.0766, 'grad_norm': 5.538788795471191, 'learning_rate': 3.755932203389831e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:32:30<4:13:08,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:32:34<4:11:11,  3.40s/it]                                                       {'loss': 0.038, 'grad_norm': 4.32335901260376, 'learning_rate': 3.755084745762712e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:32:34<4:11:11,  3.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:32:37<4:12:59,  3.43s/it]                                                       {'loss': 0.1309, 'grad_norm': 6.238409519195557, 'learning_rate': 3.7542372881355934e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:32:37<4:12:59,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:32:41<4:13:56,  3.44s/it]                                                       {'loss': 0.0306, 'grad_norm': 1.277907371520996, 'learning_rate': 3.7533898305084745e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:32:41<4:13:56,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:32:44<4:12:29,  3.42s/it]                                                       {'loss': 0.0359, 'grad_norm': 4.509335041046143, 'learning_rate': 3.752542372881356e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:32:44<4:12:29,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:47<4:11:53,  3.41s/it]                                                       {'loss': 0.0381, 'grad_norm': 2.7392771244049072, 'learning_rate': 3.7516949152542374e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:47<4:11:53,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:51<4:13:27,  3.44s/it]                                                       {'loss': 0.021, 'grad_norm': 3.2472429275512695, 'learning_rate': 3.750847457627119e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:51<4:13:27,  3.44s/it] 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:54<4:11:13,  3.41s/it]                                                       {'loss': 0.007, 'grad_norm': 0.8753159642219543, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:54<4:11:13,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:58<4:12:58,  3.43s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.8854941725730896, 'learning_rate': 3.7491525423728815e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:58<4:12:58,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:33:01<4:12:50,  3.43s/it]                                                       {'loss': 0.2276, 'grad_norm': 7.666365146636963, 'learning_rate': 3.7483050847457626e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:33:01<4:12:50,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:33:05<4:13:06,  3.43s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7316339612007141, 'learning_rate': 3.747457627118644e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:33:05<4:13:06,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:33:08<4:12:42,  3.43s/it]                                                       {'loss': 0.0484, 'grad_norm': 5.334107875823975, 'learning_rate': 3.7466101694915255e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:33:08<4:12:42,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:33:11<4:09:23,  3.39s/it]                                                       {'loss': 0.1981, 'grad_norm': 8.074201583862305, 'learning_rate': 3.745762711864407e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:33:11<4:09:23,  3.39s/it] 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:33:15<4:20:16,  3.53s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.1973210722208023, 'learning_rate': 3.7449152542372885e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:33:15<4:20:16,  3.53s/it] 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:33:19<4:17:00,  3.49s/it]                                                       {'loss': 0.0489, 'grad_norm': 4.96928596496582, 'learning_rate': 3.7440677966101696e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:33:19<4:17:00,  3.49s/it] 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:33:22<4:13:58,  3.45s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.6189672946929932, 'learning_rate': 3.7432203389830514e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:33:22<4:13:58,  3.45s/it] 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:33:25<4:12:04,  3.42s/it]                                                       {'loss': 0.1038, 'grad_norm': 8.765016555786133, 'learning_rate': 3.7423728813559325e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:33:25<4:12:04,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:33:29<4:11:25,  3.42s/it]                                                       {'loss': 0.0091, 'grad_norm': 2.386631965637207, 'learning_rate': 3.741525423728814e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:33:29<4:11:25,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:33:32<4:10:15,  3.40s/it]                                                       {'loss': 0.0217, 'grad_norm': 1.6732724905014038, 'learning_rate': 3.740677966101695e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:33:32<4:10:15,  3.40s/it] 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:33:35<4:11:03,  3.41s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.220999002456665, 'learning_rate': 3.7398305084745766e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:33:35<4:11:03,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:33:39<4:10:02,  3.40s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.3615938425064087, 'learning_rate': 3.738983050847458e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:33:39<4:10:02,  3.40s/it] 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:33:43<4:19:52,  3.53s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05110738053917885, 'learning_rate': 3.7381355932203395e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:33:43<4:19:52,  3.53s/it] 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:33:46<4:15:18,  3.47s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.297227144241333, 'learning_rate': 3.737288135593221e-05, 'epoch': 0.27}
 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:33:46<4:15:18,  3.47s/it] 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:49<4:12:36,  3.44s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.2874224185943604, 'learning_rate': 3.736440677966102e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:49<4:12:36,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:53<4:11:09,  3.42s/it]                                                       {'loss': 0.0646, 'grad_norm': 3.7311134338378906, 'learning_rate': 3.735593220338983e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:53<4:11:09,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:56<4:11:03,  3.42s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05701069161295891, 'learning_rate': 3.734745762711865e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:56<4:11:03,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:34:00<4:14:04,  3.46s/it]                                                       {'loss': 0.017, 'grad_norm': 2.6266026496887207, 'learning_rate': 3.733898305084746e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:34:00<4:14:04,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:34:03<4:13:32,  3.45s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2920466959476471, 'learning_rate': 3.733050847457628e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:34:03<4:13:32,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:34:07<4:13:02,  3.45s/it]                                                       {'loss': 0.1491, 'grad_norm': 4.989822864532471, 'learning_rate': 3.732203389830509e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:34:07<4:13:02,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:34:10<4:13:09,  3.45s/it]                                                       {'loss': 0.0671, 'grad_norm': 5.267946720123291, 'learning_rate': 3.73135593220339e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:34:10<4:13:09,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:34:13<4:11:55,  3.43s/it]                                                       {'loss': 0.268, 'grad_norm': 9.707480430603027, 'learning_rate': 3.730508474576272e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:34:13<4:11:55,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:34:17<4:12:12,  3.44s/it]                                                       {'loss': 0.0956, 'grad_norm': 6.1197004318237305, 'learning_rate': 3.729661016949152e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:34:17<4:12:12,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:34:20<4:15:59,  3.49s/it]                                                       {'loss': 0.0893, 'grad_norm': 6.031519412994385, 'learning_rate': 3.728813559322034e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:34:20<4:15:59,  3.49s/it][2025-10-20 17:04:07,460] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:34:26<5:08:34,  4.21s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.631406307220459, 'learning_rate': 3.727966101694915e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:34:26<5:08:34,  4.21s/it] 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:34:30<5:01:02,  4.11s/it]                                                       {'loss': 0.0631, 'grad_norm': 5.4889607429504395, 'learning_rate': 3.727118644067797e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:34:30<5:01:02,  4.11s/it] 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:34:34<4:52:33,  3.99s/it]                                                       {'loss': 0.0233, 'grad_norm': 2.7749149799346924, 'learning_rate': 3.726271186440678e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:34:34<4:52:33,  3.99s/it] 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:34:38<4:57:13,  4.06s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.5443198680877686, 'learning_rate': 3.72542372881356e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:34:38<4:57:13,  4.06s/it] 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:34:42<4:54:32,  4.02s/it]                                                       {'loss': 0.0364, 'grad_norm': 4.040271282196045, 'learning_rate': 3.724576271186441e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:34:42<4:54:32,  4.02s/it] 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:34:45<4:37:31,  3.79s/it]                                                       {'loss': 0.0576, 'grad_norm': 6.984532833099365, 'learning_rate': 3.723728813559322e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:34:45<4:37:31,  3.79s/it] 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:49<4:28:37,  3.67s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.722345232963562, 'learning_rate': 3.722881355932203e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:49<4:28:37,  3.67s/it] 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:52<4:30:46,  3.70s/it]                                                       {'loss': 0.0412, 'grad_norm': 5.7477216720581055, 'learning_rate': 3.722033898305085e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:53<4:30:46,  3.70s/it] 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:56<4:23:31,  3.60s/it]                                                       {'loss': 0.0094, 'grad_norm': 2.5148303508758545, 'learning_rate': 3.721186440677966e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:56<4:23:31,  3.60s/it] 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:59<4:18:57,  3.54s/it]                                                       {'loss': 0.0126, 'grad_norm': 2.2336575984954834, 'learning_rate': 3.720338983050848e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:59<4:18:57,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:35:03<4:16:59,  3.51s/it]                                                       {'loss': 0.097, 'grad_norm': 5.885136604309082, 'learning_rate': 3.719491525423729e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:35:03<4:16:59,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:35:06<4:12:12,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.048281196504831314, 'learning_rate': 3.71864406779661e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:35:06<4:12:12,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:35:09<4:09:08,  3.41s/it]                                                       {'loss': 0.0812, 'grad_norm': 9.239792823791504, 'learning_rate': 3.7177966101694914e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:35:09<4:09:08,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:35:13<4:10:18,  3.42s/it]                                                       {'loss': 0.0971, 'grad_norm': 5.180604934692383, 'learning_rate': 3.716949152542373e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:35:13<4:10:18,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:35:16<4:09:19,  3.41s/it]                                                       {'loss': 0.0392, 'grad_norm': 4.159056186676025, 'learning_rate': 3.716101694915254e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:35:16<4:09:19,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:35:20<4:12:44,  3.46s/it]                                                       {'loss': 0.0229, 'grad_norm': 1.827154517173767, 'learning_rate': 3.715254237288136e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:35:20<4:12:44,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:35:23<4:10:33,  3.43s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3457409739494324, 'learning_rate': 3.714406779661017e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:35:23<4:10:33,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:35:27<4:19:30,  3.55s/it]                                                       {'loss': 0.0769, 'grad_norm': 6.610054969787598, 'learning_rate': 3.7135593220338984e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:35:27<4:19:30,  3.55s/it] 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:35:30<4:18:17,  3.54s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.1905452013015747, 'learning_rate': 3.71271186440678e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:35:30<4:18:17,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:35:34<4:18:34,  3.54s/it]                                                       {'loss': 0.0447, 'grad_norm': 3.5491576194763184, 'learning_rate': 3.711864406779661e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:35:34<4:18:34,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:35:38<4:30:48,  3.71s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.612065076828003, 'learning_rate': 3.7110169491525424e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:35:38<4:30:48,  3.71s/it] 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:35:41<4:22:17,  3.59s/it]                                                       {'loss': 0.1146, 'grad_norm': 6.925172805786133, 'learning_rate': 3.7101694915254236e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:35:41<4:22:17,  3.59s/it] 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:35:45<4:19:09,  3.55s/it]                                                       {'loss': 0.0593, 'grad_norm': 6.8155083656311035, 'learning_rate': 3.7093220338983054e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:35:45<4:19:09,  3.55s/it] 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:48<4:18:16,  3.54s/it]                                                       {'loss': 0.1478, 'grad_norm': 6.687402248382568, 'learning_rate': 3.7084745762711865e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:48<4:18:16,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:52<4:17:54,  3.54s/it]                                                       {'loss': 0.087, 'grad_norm': 6.787580490112305, 'learning_rate': 3.707627118644068e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:52<4:17:54,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:55<4:14:51,  3.50s/it]                                                       {'loss': 0.0412, 'grad_norm': 3.0327744483947754, 'learning_rate': 3.7067796610169494e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:55<4:14:51,  3.50s/it] 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:59<4:12:20,  3.46s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.0910753011703491, 'learning_rate': 3.7059322033898306e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:59<4:12:20,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:36:02<4:14:33,  3.49s/it]                                                       {'loss': 0.0281, 'grad_norm': 3.678931951522827, 'learning_rate': 3.705084745762712e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:36:02<4:14:33,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:36:06<4:14:28,  3.49s/it]                                                       {'loss': 0.0826, 'grad_norm': 7.793295860290527, 'learning_rate': 3.7042372881355935e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:36:06<4:14:28,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:36:09<4:15:32,  3.51s/it]                                                       {'loss': 0.2235, 'grad_norm': 8.501643180847168, 'learning_rate': 3.7033898305084746e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:36:09<4:15:32,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:36:13<4:17:44,  3.54s/it]                                                       {'loss': 0.122, 'grad_norm': 7.855027675628662, 'learning_rate': 3.7025423728813564e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:36:13<4:17:44,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:36:16<4:13:05,  3.48s/it]                                                       {'loss': 0.0821, 'grad_norm': 4.9315595626831055, 'learning_rate': 3.7016949152542376e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:36:16<4:13:05,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:36:20<4:10:20,  3.44s/it]                                                       {'loss': 0.1243, 'grad_norm': 4.367093086242676, 'learning_rate': 3.7008474576271194e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:36:20<4:10:20,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:36:23<4:08:04,  3.41s/it]                                                       {'loss': 0.1666, 'grad_norm': 7.106385707855225, 'learning_rate': 3.7e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:36:23<4:08:04,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:36:27<4:18:39,  3.56s/it]                                                       {'loss': 0.0263, 'grad_norm': 3.3928627967834473, 'learning_rate': 3.6991525423728816e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:36:27<4:18:39,  3.56s/it] 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:36:31<4:22:00,  3.60s/it]                                                       {'loss': 0.1343, 'grad_norm': 13.369598388671875, 'learning_rate': 3.698305084745763e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:36:31<4:22:00,  3.60s/it] 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:36:34<4:18:14,  3.55s/it]                                                       {'loss': 0.0788, 'grad_norm': 6.062178611755371, 'learning_rate': 3.6974576271186446e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:36:34<4:18:14,  3.55s/it] 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:36:37<4:13:48,  3.49s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.6327192783355713, 'learning_rate': 3.696610169491526e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:36:37<4:13:48,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:36:41<4:11:17,  3.46s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.8748342394828796, 'learning_rate': 3.695762711864407e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:36:41<4:11:17,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:36:44<4:09:29,  3.43s/it]                                                       {'loss': 0.0379, 'grad_norm': 4.376789569854736, 'learning_rate': 3.6949152542372886e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:36:44<4:09:29,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:48<4:13:40,  3.49s/it]                                                       {'loss': 0.1903, 'grad_norm': 5.614398956298828, 'learning_rate': 3.69406779661017e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:48<4:13:40,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:51<4:11:37,  3.46s/it]                                                       {'loss': 0.0708, 'grad_norm': 6.172284126281738, 'learning_rate': 3.693220338983051e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:51<4:11:37,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:55<4:10:00,  3.44s/it]                                                       {'loss': 0.2859, 'grad_norm': 11.192901611328125, 'learning_rate': 3.692372881355932e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:55<4:10:00,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:58<4:06:29,  3.40s/it]                                                       {'loss': 0.068, 'grad_norm': 4.814962863922119, 'learning_rate': 3.691525423728814e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:58<4:06:29,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:37:01<4:06:58,  3.40s/it]                                                       {'loss': 0.0214, 'grad_norm': 2.8842015266418457, 'learning_rate': 3.690677966101695e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:37:01<4:06:58,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:37:04<4:04:07,  3.36s/it]                                                       {'loss': 0.3164, 'grad_norm': 8.141600608825684, 'learning_rate': 3.689830508474577e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:37:05<4:04:07,  3.36s/it] 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:37:08<4:04:30,  3.37s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.4411654472351074, 'learning_rate': 3.688983050847458e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:37:08<4:04:30,  3.37s/it] 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:37:11<4:03:24,  3.36s/it]                                                       {'loss': 0.4635, 'grad_norm': 9.68313980102539, 'learning_rate': 3.688135593220339e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:37:11<4:03:24,  3.36s/it] 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:37:15<4:03:33,  3.36s/it]                                                       {'loss': 0.1274, 'grad_norm': 4.589990139007568, 'learning_rate': 3.68728813559322e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:37:15<4:03:33,  3.36s/it] 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:37:18<4:04:28,  3.37s/it]                                                       {'loss': 0.1263, 'grad_norm': 7.640431880950928, 'learning_rate': 3.686440677966102e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:37:18<4:04:28,  3.37s/it][2025-10-20 17:07:04,956] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:37:23<4:51:04,  4.02s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.7630715370178223, 'learning_rate': 3.685593220338983e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:37:23<4:51:04,  4.02s/it] 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:37:28<4:51:42,  4.03s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.035932302474975586, 'learning_rate': 3.684745762711865e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:37:28<4:51:42,  4.03s/it] 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:37:31<4:38:40,  3.85s/it]                                                       {'loss': 0.1351, 'grad_norm': 7.557628154754639, 'learning_rate': 3.683898305084746e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:37:31<4:38:40,  3.85s/it] 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:37:34<4:28:46,  3.71s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.4001939296722412, 'learning_rate': 3.683050847457628e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:37:34<4:28:46,  3.71s/it] 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:37:38<4:29:11,  3.72s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.1340980529785156, 'learning_rate': 3.682203389830509e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:37:38<4:29:11,  3.72s/it] 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:37:42<4:25:37,  3.67s/it]                                                       {'loss': 0.0646, 'grad_norm': 5.330255031585693, 'learning_rate': 3.68135593220339e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:37:42<4:25:37,  3.67s/it] 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:37:45<4:24:15,  3.65s/it]                                                       {'loss': 0.0398, 'grad_norm': 4.563832759857178, 'learning_rate': 3.680508474576271e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:37:45<4:24:15,  3.65s/it] 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:49<4:17:07,  3.55s/it]                                                       {'loss': 0.0118, 'grad_norm': 0.7835603356361389, 'learning_rate': 3.679661016949153e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:49<4:17:07,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:53<4:40:26,  3.88s/it]                                                       {'loss': 0.1054, 'grad_norm': 8.481987953186035, 'learning_rate': 3.678813559322034e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:53<4:40:26,  3.88s/it] 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:57<4:36:37,  3.82s/it]                                                       {'loss': 0.0614, 'grad_norm': 5.553665637969971, 'learning_rate': 3.677966101694915e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:57<4:36:37,  3.82s/it] 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:38:00<4:27:46,  3.70s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5531144142150879, 'learning_rate': 3.677118644067797e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:38:00<4:27:46,  3.70s/it] 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:38:04<4:22:42,  3.63s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.6731610894203186, 'learning_rate': 3.676271186440678e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:38:04<4:22:42,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:38:07<4:16:56,  3.55s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.3694494962692261, 'learning_rate': 3.675423728813559e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:38:07<4:16:56,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:38:11<4:14:39,  3.52s/it]                                                       {'loss': 0.0541, 'grad_norm': 4.61053991317749, 'learning_rate': 3.6745762711864404e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:38:11<4:14:39,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:38:14<4:12:01,  3.49s/it]                                                       {'loss': 0.0659, 'grad_norm': 3.274395227432251, 'learning_rate': 3.673728813559322e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:38:14<4:12:01,  3.49s/it] 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:38:18<4:17:36,  3.57s/it]                                                       {'loss': 0.0609, 'grad_norm': 5.021258354187012, 'learning_rate': 3.6728813559322034e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:38:18<4:17:36,  3.57s/it] 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:38:22<4:23:17,  3.65s/it]                                                       {'loss': 0.012, 'grad_norm': 1.889423131942749, 'learning_rate': 3.672033898305085e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:38:22<4:23:17,  3.65s/it] 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:38:25<4:16:32,  3.55s/it]                                                       {'loss': 0.0553, 'grad_norm': 6.130899906158447, 'learning_rate': 3.671186440677966e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:38:25<4:16:32,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:38:28<4:12:17,  3.50s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.7510875463485718, 'learning_rate': 3.6703389830508474e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:38:28<4:12:17,  3.50s/it] 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:38:32<4:08:48,  3.45s/it]                                                       {'loss': 0.1465, 'grad_norm': 8.04566478729248, 'learning_rate': 3.6694915254237286e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:38:32<4:08:48,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:38:35<4:05:21,  3.40s/it]                                                       {'loss': 0.0666, 'grad_norm': 3.711010456085205, 'learning_rate': 3.6686440677966104e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:38:35<4:05:21,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:38:38<4:07:19,  3.43s/it]                                                       {'loss': 0.0586, 'grad_norm': 5.2748703956604, 'learning_rate': 3.6677966101694915e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:38:38<4:07:19,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:38:42<4:05:01,  3.40s/it]                                                       {'loss': 0.0422, 'grad_norm': 4.950502872467041, 'learning_rate': 3.666949152542373e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:38:42<4:05:01,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:38:45<4:04:39,  3.39s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3422422409057617, 'learning_rate': 3.6661016949152544e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:38:45<4:04:39,  3.39s/it] 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:49<4:05:03,  3.40s/it]                                                       {'loss': 0.0822, 'grad_norm': 5.168595790863037, 'learning_rate': 3.665254237288136e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:49<4:05:03,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:52<4:04:15,  3.39s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.23392216861248016, 'learning_rate': 3.6644067796610174e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:52<4:04:15,  3.39s/it] 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:55<4:07:43,  3.44s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.759291648864746, 'learning_rate': 3.6635593220338985e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:55<4:07:43,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:59<4:04:46,  3.40s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.030857563018799, 'learning_rate': 3.6627118644067796e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:59<4:04:46,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:39:03<4:22:48,  3.65s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.577691674232483, 'learning_rate': 3.661864406779661e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:39:03<4:22:48,  3.65s/it] 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:39:06<4:16:07,  3.56s/it]                                                       {'loss': 0.0094, 'grad_norm': 0.8898950815200806, 'learning_rate': 3.6610169491525426e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:39:06<4:16:07,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:39:10<4:10:28,  3.48s/it]                                                       {'loss': 0.0809, 'grad_norm': 5.986203670501709, 'learning_rate': 3.660169491525424e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:39:10<4:10:28,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:39:13<4:07:48,  3.44s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.4803391695022583, 'learning_rate': 3.6593220338983055e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:39:13<4:07:48,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:39:16<4:06:05,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.18428972363471985, 'learning_rate': 3.6584745762711866e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:39:16<4:06:05,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:39:20<4:08:40,  3.46s/it]                                                       {'loss': 0.0405, 'grad_norm': 4.808795928955078, 'learning_rate': 3.657627118644068e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:39:20<4:08:40,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:39:23<4:06:55,  3.43s/it]                                                       {'loss': 0.055, 'grad_norm': 5.371421813964844, 'learning_rate': 3.656779661016949e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:39:23<4:06:55,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:39:27<4:05:17,  3.41s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.8702160120010376, 'learning_rate': 3.655932203389831e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:39:27<4:05:17,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:39:31<4:22:40,  3.65s/it]                                                       {'loss': 0.0176, 'grad_norm': 1.98151695728302, 'learning_rate': 3.655084745762712e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:39:31<4:22:40,  3.65s/it] 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:39:34<4:19:25,  3.61s/it]                                                       {'loss': 0.1859, 'grad_norm': 6.806979656219482, 'learning_rate': 3.6542372881355936e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:39:34<4:19:25,  3.61s/it] 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:39:38<4:14:48,  3.55s/it]                                                       {'loss': 0.1009, 'grad_norm': 6.872568130493164, 'learning_rate': 3.653389830508475e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:39:38<4:14:48,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:39:41<4:14:26,  3.54s/it]                                                       {'loss': 0.1162, 'grad_norm': 7.46550178527832, 'learning_rate': 3.6525423728813566e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:39:41<4:14:26,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:39:45<4:15:01,  3.55s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.3803596496582031, 'learning_rate': 3.651694915254237e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:39:45<4:15:01,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:48<4:16:12,  3.57s/it]                                                       {'loss': 0.0238, 'grad_norm': 2.273350715637207, 'learning_rate': 3.650847457627119e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:48<4:16:12,  3.57s/it] 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:52<4:20:42,  3.63s/it]                                                       {'loss': 0.0618, 'grad_norm': 5.2491044998168945, 'learning_rate': 3.65e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:52<4:20:42,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:56<4:14:29,  3.55s/it]                                                       {'loss': 0.0529, 'grad_norm': 3.8082163333892822, 'learning_rate': 3.649152542372882e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:56<4:14:29,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:59<4:13:45,  3.54s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.35397952795028687, 'learning_rate': 3.648305084745763e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:59<4:13:45,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:40:02<4:08:18,  3.46s/it]                                                       {'loss': 0.1275, 'grad_norm': 4.678738117218018, 'learning_rate': 3.647457627118645e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:40:02<4:08:18,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:40:06<4:06:16,  3.43s/it]                                                       {'loss': 0.0666, 'grad_norm': 4.017547607421875, 'learning_rate': 3.646610169491526e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:40:06<4:06:16,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:40:09<4:06:34,  3.44s/it]                                                       {'loss': 0.1251, 'grad_norm': 6.796748638153076, 'learning_rate': 3.645762711864407e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:40:09<4:06:34,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:40:13<4:05:46,  3.43s/it]                                                       {'loss': 0.0326, 'grad_norm': 2.8527348041534424, 'learning_rate': 3.644915254237288e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:40:13<4:05:46,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:40:16<4:04:17,  3.41s/it]                                                       {'loss': 0.1517, 'grad_norm': 7.668449878692627, 'learning_rate': 3.644067796610169e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:40:16<4:04:17,  3.41s/it][2025-10-20 17:10:03,000] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:40:22<5:03:21,  4.23s/it]                                                       {'loss': 0.2988, 'grad_norm': 7.793737888336182, 'learning_rate': 3.643220338983051e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:40:22<5:03:21,  4.23s/it] 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:40:26<4:44:47,  3.98s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19203804433345795, 'learning_rate': 3.642372881355932e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:40:26<4:44:47,  3.98s/it] 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:40:29<4:33:08,  3.81s/it]                                                       {'loss': 0.1882, 'grad_norm': 6.682553768157959, 'learning_rate': 3.641525423728814e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:40:29<4:33:08,  3.81s/it] 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:40:32<4:23:19,  3.68s/it]                                                       {'loss': 0.536, 'grad_norm': 9.1840181350708, 'learning_rate': 3.640677966101695e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:40:32<4:23:19,  3.68s/it] 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:40:36<4:14:54,  3.56s/it]                                                       {'loss': 0.0528, 'grad_norm': 4.524418830871582, 'learning_rate': 3.639830508474576e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:40:36<4:14:54,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:40:39<4:09:32,  3.49s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.0189460515975952, 'learning_rate': 3.638983050847457e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:40:39<4:09:32,  3.49s/it] 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:40:42<4:06:47,  3.45s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.7926490306854248, 'learning_rate': 3.638135593220339e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:40:42<4:06:47,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:40:46<4:06:33,  3.45s/it]                                                       {'loss': 0.0133, 'grad_norm': 2.576467514038086, 'learning_rate': 3.63728813559322e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:40:46<4:06:33,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:49<4:02:44,  3.39s/it]                                                       {'loss': 0.0933, 'grad_norm': 5.260130405426025, 'learning_rate': 3.636440677966102e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:49<4:02:44,  3.39s/it] 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:52<4:02:55,  3.40s/it]                                                       {'loss': 0.0483, 'grad_norm': 6.82499361038208, 'learning_rate': 3.635593220338983e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:52<4:02:55,  3.40s/it] 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:56<4:05:42,  3.44s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.1336123943328857, 'learning_rate': 3.634745762711865e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:56<4:05:42,  3.44s/it] 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:59<4:04:17,  3.42s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.2656422853469849, 'learning_rate': 3.633898305084746e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:59<4:04:17,  3.42s/it] 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:41:03<4:01:39,  3.38s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3388238549232483, 'learning_rate': 3.633050847457627e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:41:03<4:01:39,  3.38s/it] 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:41:06<4:10:21,  3.50s/it]                                                       {'loss': 0.0536, 'grad_norm': 4.760597229003906, 'learning_rate': 3.6322033898305084e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:41:06<4:10:21,  3.50s/it] 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:41:10<4:09:34,  3.49s/it]                                                       {'loss': 0.0258, 'grad_norm': 2.17914080619812, 'learning_rate': 3.63135593220339e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:41:10<4:09:34,  3.49s/it] 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:41:13<4:08:00,  3.47s/it]                                                       {'loss': 0.1269, 'grad_norm': 6.987461090087891, 'learning_rate': 3.630508474576271e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:41:13<4:08:00,  3.47s/it] 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:41:17<4:04:36,  3.43s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.0712578296661377, 'learning_rate': 3.629661016949153e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:41:17<4:04:36,  3.43s/it] 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:41:20<4:02:14,  3.39s/it]                                                       {'loss': 0.0588, 'grad_norm': 2.641796350479126, 'learning_rate': 3.628813559322034e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:41:20<4:02:14,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:41:23<4:01:08,  3.38s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.194028377532959, 'learning_rate': 3.6279661016949154e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:41:23<4:01:08,  3.38s/it] 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:41:27<4:00:19,  3.37s/it]                                                       {'loss': 0.0383, 'grad_norm': 4.1662116050720215, 'learning_rate': 3.6271186440677965e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:41:27<4:00:19,  3.37s/it] 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:41:30<4:02:53,  3.41s/it]                                                       {'loss': 0.023, 'grad_norm': 3.5290262699127197, 'learning_rate': 3.6262711864406777e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:41:30<4:02:53,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:41:33<4:02:06,  3.40s/it]                                                       {'loss': 0.001, 'grad_norm': 0.12318188697099686, 'learning_rate': 3.6254237288135595e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:41:33<4:02:06,  3.40s/it] 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:41:37<4:01:44,  3.39s/it]                                                       {'loss': 0.0448, 'grad_norm': 3.81439471244812, 'learning_rate': 3.6245762711864406e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:41:37<4:01:44,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:41:40<4:04:43,  3.43s/it]                                                       {'loss': 0.0711, 'grad_norm': 2.7355849742889404, 'learning_rate': 3.6237288135593224e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:41:40<4:04:43,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:41:44<4:04:14,  3.43s/it]                                                       {'loss': 0.126, 'grad_norm': 5.790416717529297, 'learning_rate': 3.6228813559322035e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:41:44<4:04:14,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:47<4:03:13,  3.41s/it]                                                       {'loss': 0.0104, 'grad_norm': 2.2017102241516113, 'learning_rate': 3.622033898305085e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:47<4:03:13,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:51<4:03:02,  3.41s/it]                                                       {'loss': 0.0261, 'grad_norm': 2.554971218109131, 'learning_rate': 3.621186440677966e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:51<4:03:02,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:54<4:02:39,  3.41s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.6282713413238525, 'learning_rate': 3.6203389830508476e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:54<4:02:39,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:57<4:02:04,  3.40s/it]                                                       {'loss': 0.1088, 'grad_norm': 7.357742786407471, 'learning_rate': 3.619491525423729e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:57<4:02:04,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:42:01<4:01:18,  3.39s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.7969335317611694, 'learning_rate': 3.6186440677966105e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:42:01<4:01:18,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:42:04<4:00:42,  3.38s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.2257816791534424, 'learning_rate': 3.6177966101694916e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:42:04<4:00:42,  3.38s/it] 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:42:08<4:02:39,  3.41s/it]                                                       {'loss': 0.001, 'grad_norm': 0.09646224230527878, 'learning_rate': 3.6169491525423735e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:42:08<4:02:39,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:42:11<4:12:00,  3.54s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.1689139604568481, 'learning_rate': 3.6161016949152546e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:42:11<4:12:00,  3.54s/it] 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:42:15<4:08:40,  3.50s/it]                                                       {'loss': 0.1295, 'grad_norm': 9.09226131439209, 'learning_rate': 3.615254237288136e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:42:15<4:08:40,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:42:18<4:08:50,  3.50s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.24331378936767578, 'learning_rate': 3.614406779661017e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:42:18<4:08:50,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:42:22<4:08:13,  3.49s/it]                                                       {'loss': 0.009, 'grad_norm': 0.9841120839118958, 'learning_rate': 3.6135593220338986e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:42:22<4:08:13,  3.49s/it] 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:42:25<4:07:24,  3.48s/it]                                                       {'loss': 0.0214, 'grad_norm': 2.503314733505249, 'learning_rate': 3.61271186440678e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:42:25<4:07:24,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:42:29<4:06:57,  3.48s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.3470386564731598, 'learning_rate': 3.6118644067796616e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:42:29<4:06:57,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:42:33<4:13:49,  3.57s/it]                                                       {'loss': 0.18, 'grad_norm': 10.007866859436035, 'learning_rate': 3.611016949152543e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:42:33<4:13:49,  3.57s/it] 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:42:36<4:18:18,  3.64s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.8138151168823242, 'learning_rate': 3.610169491525424e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:42:36<4:18:18,  3.64s/it] 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:42:40<4:11:42,  3.55s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5220186114311218, 'learning_rate': 3.609322033898305e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:42:40<4:11:42,  3.55s/it] 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:42:43<4:08:53,  3.51s/it]                                                       {'loss': 0.0981, 'grad_norm': 5.599363803863525, 'learning_rate': 3.608474576271186e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:42:43<4:08:53,  3.51s/it] 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:47<4:07:16,  3.49s/it]                                                       {'loss': 0.2644, 'grad_norm': 11.081110954284668, 'learning_rate': 3.607627118644068e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:47<4:07:16,  3.49s/it] 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:50<4:05:26,  3.46s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.0902295112609863, 'learning_rate': 3.606779661016949e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:50<4:05:26,  3.46s/it] 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:53<4:02:29,  3.42s/it]                                                       {'loss': 0.0304, 'grad_norm': 2.1368954181671143, 'learning_rate': 3.605932203389831e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:53<4:02:29,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:57<4:00:12,  3.39s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06117065250873566, 'learning_rate': 3.605084745762712e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:57<4:00:12,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:43:00<3:59:57,  3.39s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13160346448421478, 'learning_rate': 3.604237288135594e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:43:00<3:59:57,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:43:03<3:59:17,  3.38s/it]                                                       {'loss': 0.1163, 'grad_norm': 8.577672004699707, 'learning_rate': 3.603389830508475e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:43:03<3:59:17,  3.38s/it] 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:43:07<4:01:37,  3.41s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6660851836204529, 'learning_rate': 3.602542372881356e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:43:07<4:01:37,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:43:11<4:12:20,  3.56s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5428776144981384, 'learning_rate': 3.601694915254237e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:43:11<4:12:20,  3.56s/it][2025-10-20 17:12:57,704] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:43:17<5:06:35,  4.33s/it]                                                       {'loss': 0.0268, 'grad_norm': 3.6451594829559326, 'learning_rate': 3.600847457627119e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:43:17<5:06:35,  4.33s/it] 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:43:20<4:47:02,  4.05s/it]                                                       {'loss': 0.105, 'grad_norm': 9.309704780578613, 'learning_rate': 3.6e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:43:20<4:47:02,  4.05s/it] 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:43:24<4:32:35,  3.85s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3343871533870697, 'learning_rate': 3.599152542372882e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:43:24<4:32:35,  3.85s/it] 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:43:27<4:23:39,  3.73s/it]                                                       {'loss': 0.0565, 'grad_norm': 4.7432990074157715, 'learning_rate': 3.598305084745763e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:43:27<4:23:39,  3.73s/it] 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:43:31<4:24:41,  3.74s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.27444615960121155, 'learning_rate': 3.597457627118644e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:43:31<4:24:41,  3.74s/it] 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:43:34<4:19:19,  3.67s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.9654285907745361, 'learning_rate': 3.596610169491525e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:43:34<4:19:19,  3.67s/it] 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:43:38<4:13:00,  3.58s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0029390898998826742, 'learning_rate': 3.595762711864407e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:43:38<4:13:00,  3.58s/it] 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:43:41<4:08:57,  3.52s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.10107611119747162, 'learning_rate': 3.594915254237288e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:43:41<4:08:57,  3.52s/it] 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:43:45<4:07:47,  3.51s/it]                                                       {'loss': 0.1613, 'grad_norm': 8.400243759155273, 'learning_rate': 3.59406779661017e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:43:45<4:07:47,  3.51s/it] 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:43:48<4:06:05,  3.48s/it]                                                       {'loss': 0.1908, 'grad_norm': 8.251856803894043, 'learning_rate': 3.593220338983051e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:43:48<4:06:05,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:52<4:08:23,  3.52s/it]                                                       {'loss': 0.06, 'grad_norm': 3.9379799365997314, 'learning_rate': 3.592372881355933e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:52<4:08:23,  3.52s/it] 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:55<4:16:52,  3.64s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.0932440757751465, 'learning_rate': 3.5915254237288134e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:55<4:16:52,  3.64s/it] 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:59<4:11:59,  3.57s/it]                                                       {'loss': 0.1093, 'grad_norm': 5.919220447540283, 'learning_rate': 3.5906779661016945e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:59<4:11:59,  3.57s/it] 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:44:03<4:29:12,  3.81s/it]                                                       {'loss': 0.2004, 'grad_norm': 10.084827423095703, 'learning_rate': 3.5898305084745763e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:44:03<4:29:12,  3.81s/it] 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:44:08<4:44:58,  4.04s/it]                                                       {'loss': 0.1182, 'grad_norm': 7.909878730773926, 'learning_rate': 3.5889830508474575e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:44:08<4:44:58,  4.04s/it] 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:44:11<4:33:49,  3.88s/it]                                                       {'loss': 0.0283, 'grad_norm': 1.9278721809387207, 'learning_rate': 3.588135593220339e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:44:11<4:33:49,  3.88s/it] 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:44:15<4:28:00,  3.80s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03095768578350544, 'learning_rate': 3.5872881355932204e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:44:15<4:28:00,  3.80s/it] 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:44:19<4:35:12,  3.90s/it]                                                       {'loss': 0.0453, 'grad_norm': 4.231298923492432, 'learning_rate': 3.586440677966102e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:44:19<4:35:12,  3.90s/it] 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:44:22<4:22:49,  3.73s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5822170376777649, 'learning_rate': 3.5855932203389833e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:44:22<4:22:49,  3.73s/it] 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:44:26<4:18:47,  3.67s/it]                                                       {'loss': 0.0584, 'grad_norm': 4.414266586303711, 'learning_rate': 3.5847457627118645e-05, 'epoch': 0.29}
 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:44:26<4:18:47,  3.67s/it] 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:44:30<4:21:24,  3.71s/it]                                                       {'loss': 0.0409, 'grad_norm': 4.093660831451416, 'learning_rate': 3.5838983050847456e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:44:30<4:21:24,  3.71s/it] 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:44:33<4:13:51,  3.60s/it]                                                       {'loss': 0.2665, 'grad_norm': 10.4738130569458, 'learning_rate': 3.5830508474576274e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:44:33<4:13:51,  3.60s/it] 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:44:36<4:07:28,  3.51s/it]                                                       {'loss': 0.0861, 'grad_norm': 4.865109443664551, 'learning_rate': 3.5822033898305085e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:44:36<4:07:28,  3.51s/it] 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:44:40<4:06:20,  3.50s/it]                                                       {'loss': 0.0291, 'grad_norm': 3.6206905841827393, 'learning_rate': 3.5813559322033903e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:44:40<4:06:20,  3.50s/it] 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:44:44<4:10:33,  3.56s/it]                                                       {'loss': 0.0219, 'grad_norm': 3.5197343826293945, 'learning_rate': 3.5805084745762715e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:44:44<4:10:33,  3.56s/it] 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:44:47<4:05:28,  3.49s/it]                                                       {'loss': 0.0598, 'grad_norm': 2.5933873653411865, 'learning_rate': 3.5796610169491526e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:44:47<4:05:28,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:50<4:03:41,  3.46s/it]                                                       {'loss': 0.1096, 'grad_norm': 4.9322123527526855, 'learning_rate': 3.578813559322034e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:50<4:03:41,  3.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:54<4:05:50,  3.49s/it]                                                       {'loss': 0.1158, 'grad_norm': 7.4592108726501465, 'learning_rate': 3.5779661016949155e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:54<4:05:50,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:57<4:04:21,  3.47s/it]                                                       {'loss': 0.0186, 'grad_norm': 1.5418996810913086, 'learning_rate': 3.577118644067797e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:57<4:04:21,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:45:01<4:02:32,  3.45s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.6940515041351318, 'learning_rate': 3.5762711864406785e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:45:01<4:02:32,  3.45s/it] 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:45:04<4:02:37,  3.45s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11186659336090088, 'learning_rate': 3.5754237288135596e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:45:04<4:02:37,  3.45s/it] 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:45:08<4:03:13,  3.46s/it]                                                       {'loss': 0.0354, 'grad_norm': 2.153066635131836, 'learning_rate': 3.5745762711864414e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:45:08<4:03:13,  3.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:45:11<4:01:03,  3.43s/it]                                                       {'loss': 0.011, 'grad_norm': 1.615250587463379, 'learning_rate': 3.5737288135593225e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:45:11<4:01:03,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:45:14<4:01:23,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.34161198139190674, 'learning_rate': 3.572881355932203e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:45:14<4:01:23,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:45:18<3:59:18,  3.41s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.09726371616125107, 'learning_rate': 3.572033898305085e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:45:18<3:59:18,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:45:22<4:06:50,  3.51s/it]                                                       {'loss': 0.0535, 'grad_norm': 6.0467047691345215, 'learning_rate': 3.571186440677966e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:45:22<4:06:50,  3.51s/it] 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:45:25<4:04:42,  3.48s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4655468463897705, 'learning_rate': 3.570338983050848e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:45:25<4:04:42,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:45:28<4:01:45,  3.44s/it]                                                       {'loss': 0.0648, 'grad_norm': 7.41204833984375, 'learning_rate': 3.569491525423729e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:45:28<4:01:45,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:45:32<3:59:19,  3.41s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.4277113676071167, 'learning_rate': 3.5686440677966107e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:45:32<3:59:19,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:45:35<3:58:40,  3.40s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6008894443511963, 'learning_rate': 3.567796610169492e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:45:35<3:58:40,  3.40s/it] 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:45:38<3:57:08,  3.38s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.4257456064224243, 'learning_rate': 3.566949152542373e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:45:38<3:57:08,  3.38s/it] 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:45:42<3:59:29,  3.41s/it]                                                       {'loss': 0.0872, 'grad_norm': 4.138075351715088, 'learning_rate': 3.566101694915254e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:45:42<3:59:29,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:45:45<3:59:59,  3.42s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09988287091255188, 'learning_rate': 3.565254237288136e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:45:45<3:59:59,  3.42s/it] 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:49<3:57:15,  3.38s/it]                                                       {'loss': 0.0119, 'grad_norm': 2.072779893875122, 'learning_rate': 3.564406779661017e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:49<3:57:15,  3.38s/it] 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:52<3:57:22,  3.39s/it]                                                       {'loss': 0.1476, 'grad_norm': 7.172619819641113, 'learning_rate': 3.563559322033899e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:52<3:57:22,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:55<3:57:27,  3.39s/it]                                                       {'loss': 0.0223, 'grad_norm': 3.214015007019043, 'learning_rate': 3.56271186440678e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:55<3:57:27,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:59<3:56:29,  3.38s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.3352763056755066, 'learning_rate': 3.561864406779661e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:59<3:56:29,  3.38s/it] 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:46:02<3:55:15,  3.36s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.4123252630233765, 'learning_rate': 3.561016949152542e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:46:02<3:55:15,  3.36s/it] 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:46:05<3:55:46,  3.37s/it]                                                       {'loss': 0.0497, 'grad_norm': 3.142073392868042, 'learning_rate': 3.560169491525424e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:46:05<3:55:46,  3.37s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:46:09<4:10:05,  3.57s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11256421357393265, 'learning_rate': 3.559322033898305e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:46:09<4:10:05,  3.57s/it][2025-10-20 17:15:56,464] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:46:15<4:52:18,  4.18s/it]                                                       {'loss': 0.0772, 'grad_norm': 6.444001197814941, 'learning_rate': 3.558474576271187e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:46:15<4:52:18,  4.18s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:46:18<4:36:38,  3.95s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.026493849232792854, 'learning_rate': 3.557627118644068e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:46:18<4:36:38,  3.95s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:46:22<4:25:18,  3.79s/it]                                                       {'loss': 0.1112, 'grad_norm': 7.521648406982422, 'learning_rate': 3.55677966101695e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:46:22<4:25:18,  3.79s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:46:25<4:17:41,  3.68s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04328799620270729, 'learning_rate': 3.555932203389831e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:46:25<4:17:41,  3.68s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:46:29<4:11:27,  3.60s/it]                                                       {'loss': 0.086, 'grad_norm': 7.829422950744629, 'learning_rate': 3.555084745762712e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:46:29<4:11:27,  3.60s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:46:32<4:05:47,  3.52s/it]                                                       {'loss': 0.0956, 'grad_norm': 7.261159896850586, 'learning_rate': 3.554237288135593e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:46:32<4:05:47,  3.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:46:35<4:02:29,  3.47s/it]                                                       {'loss': 0.1096, 'grad_norm': 3.673274278640747, 'learning_rate': 3.5533898305084744e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:46:35<4:02:29,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:46:39<4:01:09,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.045777227729558945, 'learning_rate': 3.552542372881356e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:46:39<4:01:09,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:46:42<4:01:23,  3.46s/it]                                                       {'loss': 0.1335, 'grad_norm': 6.282140731811523, 'learning_rate': 3.551694915254237e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:46:42<4:01:23,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:46:46<4:08:19,  3.56s/it]                                                       {'loss': 0.0263, 'grad_norm': 3.725684642791748, 'learning_rate': 3.550847457627119e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:46:46<4:08:19,  3.56s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:49<4:03:41,  3.49s/it]                                                       {'loss': 0.0814, 'grad_norm': 9.368535041809082, 'learning_rate': 3.55e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:49<4:03:41,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:53<4:02:55,  3.48s/it]                                                       {'loss': 0.1138, 'grad_norm': 6.0293169021606445, 'learning_rate': 3.5491525423728814e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:53<4:02:55,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:56<4:01:48,  3.47s/it]                                                       {'loss': 0.0633, 'grad_norm': 5.04457426071167, 'learning_rate': 3.5483050847457625e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:56<4:01:48,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:47:00<4:02:53,  3.48s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9992902278900146, 'learning_rate': 3.547457627118644e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:47:00<4:02:53,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:47:03<4:02:05,  3.47s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.5129991769790649, 'learning_rate': 3.5466101694915254e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:47:03<4:02:05,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:47:07<4:02:05,  3.47s/it]                                                       {'loss': 0.1479, 'grad_norm': 8.931282043457031, 'learning_rate': 3.545762711864407e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:47:07<4:02:05,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:47:10<4:01:14,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.21358156204223633, 'learning_rate': 3.5449152542372884e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:47:10<4:01:14,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:47:14<4:00:06,  3.44s/it]                                                       {'loss': 0.0269, 'grad_norm': 4.188382148742676, 'learning_rate': 3.54406779661017e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:47:14<4:00:06,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:47:17<4:06:16,  3.53s/it]                                                       {'loss': 0.1528, 'grad_norm': 5.286774635314941, 'learning_rate': 3.5432203389830506e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:47:17<4:06:16,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:47:21<4:04:06,  3.50s/it]                                                       {'loss': 0.0624, 'grad_norm': 3.8366196155548096, 'learning_rate': 3.5423728813559324e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:47:21<4:04:06,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:47:24<3:59:59,  3.45s/it]                                                       {'loss': 0.2011, 'grad_norm': 8.565789222717285, 'learning_rate': 3.5415254237288135e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:47:24<3:59:59,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:47:28<3:59:43,  3.44s/it]                                                       {'loss': 0.0834, 'grad_norm': 6.583699703216553, 'learning_rate': 3.5406779661016954e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:47:28<3:59:43,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:47:31<4:00:37,  3.46s/it]                                                       {'loss': 0.0503, 'grad_norm': 5.285418510437012, 'learning_rate': 3.5398305084745765e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:47:31<4:00:37,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:47:34<3:59:57,  3.45s/it]                                                       {'loss': 0.0497, 'grad_norm': 4.517124176025391, 'learning_rate': 3.538983050847458e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:47:34<3:59:57,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:47:38<4:04:33,  3.51s/it]                                                       {'loss': 0.0293, 'grad_norm': 1.5308204889297485, 'learning_rate': 3.5381355932203394e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:47:38<4:04:33,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:47:42<4:04:20,  3.51s/it]                                                       {'loss': 0.0784, 'grad_norm': 5.623070240020752, 'learning_rate': 3.5372881355932205e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:47:42<4:04:20,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:47:45<4:05:37,  3.53s/it]                                                       {'loss': 0.0197, 'grad_norm': 2.887740135192871, 'learning_rate': 3.536440677966102e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:47:45<4:05:37,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:49<4:02:48,  3.49s/it]                                                       {'loss': 0.0354, 'grad_norm': 3.3884992599487305, 'learning_rate': 3.535593220338983e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:49<4:02:48,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:52<4:01:15,  3.47s/it]                                                       {'loss': 0.0318, 'grad_norm': 3.467158079147339, 'learning_rate': 3.5347457627118646e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:52<4:01:15,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:56<4:10:51,  3.61s/it]                                                       {'loss': 0.0248, 'grad_norm': 3.087125778198242, 'learning_rate': 3.533898305084746e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:56<4:10:51,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:59<4:06:35,  3.55s/it]                                                       {'loss': 0.0443, 'grad_norm': 7.287195682525635, 'learning_rate': 3.5330508474576275e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:59<4:06:35,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:48:03<4:06:56,  3.55s/it]                                                       {'loss': 0.1514, 'grad_norm': 6.930264472961426, 'learning_rate': 3.532203389830509e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:48:03<4:06:56,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:48:06<4:03:38,  3.51s/it]                                                       {'loss': 0.0475, 'grad_norm': 4.6453962326049805, 'learning_rate': 3.53135593220339e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:48:06<4:03:38,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:48:10<3:59:13,  3.45s/it]                                                       {'loss': 0.012, 'grad_norm': 1.4186935424804688, 'learning_rate': 3.530508474576271e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:48:10<3:59:13,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:48:13<3:58:00,  3.43s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5027145147323608, 'learning_rate': 3.529661016949153e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:48:13<3:58:00,  3.43s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:48:17<4:00:40,  3.47s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.6366814374923706, 'learning_rate': 3.528813559322034e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:48:17<4:00:40,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:48:20<4:02:16,  3.49s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.8086462020874023, 'learning_rate': 3.527966101694916e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:48:20<4:02:16,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:48:24<4:02:25,  3.49s/it]                                                       {'loss': 0.002, 'grad_norm': 0.28816989064216614, 'learning_rate': 3.527118644067797e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:48:24<4:02:25,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:48:27<4:01:41,  3.48s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.326748251914978, 'learning_rate': 3.5262711864406786e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:48:27<4:01:41,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:48:31<4:10:21,  3.61s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.9541074633598328, 'learning_rate': 3.52542372881356e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:48:31<4:10:21,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:48:34<4:05:46,  3.55s/it]                                                       {'loss': 0.236, 'grad_norm': 8.863799095153809, 'learning_rate': 3.524576271186441e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:48:34<4:05:46,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:48:38<4:02:34,  3.50s/it]                                                       {'loss': 0.049, 'grad_norm': 3.029256820678711, 'learning_rate': 3.523728813559322e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:48:38<4:02:34,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:48:41<4:06:55,  3.56s/it]                                                       {'loss': 0.0103, 'grad_norm': 2.041407823562622, 'learning_rate': 3.522881355932204e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:48:41<4:06:55,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:48:45<4:01:48,  3.49s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.6509654521942139, 'learning_rate': 3.522033898305085e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:48:45<4:01:48,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:49<4:07:31,  3.57s/it]                                                       {'loss': 0.1144, 'grad_norm': 5.299921035766602, 'learning_rate': 3.521186440677967e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:49<4:07:31,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:52<4:07:28,  3.57s/it]                                                       {'loss': 0.0451, 'grad_norm': 3.2213571071624756, 'learning_rate': 3.520338983050848e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:52<4:07:28,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:56<4:04:25,  3.53s/it]                                                       {'loss': 0.0212, 'grad_norm': 2.5732054710388184, 'learning_rate': 3.519491525423729e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:56<4:04:25,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:59<4:02:06,  3.50s/it]                                                       {'loss': 0.0176, 'grad_norm': 3.202796697616577, 'learning_rate': 3.51864406779661e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:59<4:02:06,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:49:03<4:03:06,  3.51s/it]                                                       {'loss': 0.0706, 'grad_norm': 5.6029229164123535, 'learning_rate': 3.517796610169491e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:49:03<4:03:06,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:49:07<4:19:10,  3.75s/it]                                                       {'loss': 0.128, 'grad_norm': 5.845698356628418, 'learning_rate': 3.516949152542373e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:49:07<4:19:10,  3.75s/it][2025-10-20 17:18:53,829] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:49:13<4:59:54,  4.34s/it]                                                       {'loss': 0.0719, 'grad_norm': 5.482744216918945, 'learning_rate': 3.516101694915254e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:49:13<4:59:54,  4.34s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:49:16<4:45:53,  4.14s/it]                                                       {'loss': 0.007, 'grad_norm': 1.150818109512329, 'learning_rate': 3.515254237288136e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:49:16<4:45:53,  4.14s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:49:20<4:29:15,  3.90s/it]                                                       {'loss': 0.1686, 'grad_norm': 6.035192012786865, 'learning_rate': 3.514406779661017e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:49:20<4:29:15,  3.90s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:49:23<4:18:18,  3.74s/it]                                                       {'loss': 0.2161, 'grad_norm': 7.669491291046143, 'learning_rate': 3.513559322033899e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:49:23<4:18:18,  3.74s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:49:26<4:10:38,  3.63s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16839510202407837, 'learning_rate': 3.5127118644067794e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:49:26<4:10:38,  3.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:49:30<4:07:51,  3.59s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.5738840103149414, 'learning_rate': 3.511864406779661e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:49:30<4:07:51,  3.59s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:49:34<4:25:46,  3.85s/it]                                                       {'loss': 0.2005, 'grad_norm': 9.079781532287598, 'learning_rate': 3.511016949152542e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:49:34<4:25:46,  3.85s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:49:38<4:14:11,  3.68s/it]                                                       {'loss': 0.0634, 'grad_norm': 5.038390636444092, 'learning_rate': 3.510169491525424e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:49:38<4:14:11,  3.68s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:49:41<4:17:09,  3.73s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.8101041316986084, 'learning_rate': 3.509322033898305e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:49:41<4:17:09,  3.73s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:49:45<4:10:29,  3.63s/it]                                                       {'loss': 0.1035, 'grad_norm': 5.75369930267334, 'learning_rate': 3.508474576271187e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:49:45<4:10:29,  3.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:49:48<4:05:13,  3.55s/it]                                                       {'loss': 0.0052, 'grad_norm': 1.0311774015426636, 'learning_rate': 3.507627118644068e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:49:48<4:05:13,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:52<4:18:41,  3.75s/it]                                                       {'loss': 0.0676, 'grad_norm': 6.858609199523926, 'learning_rate': 3.506779661016949e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:52<4:18:41,  3.75s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:56<4:11:49,  3.65s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.2482260465621948, 'learning_rate': 3.5059322033898304e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:56<4:11:49,  3.65s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:59<4:06:42,  3.58s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.398681879043579, 'learning_rate': 3.505084745762712e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:59<4:06:42,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:50:03<4:01:53,  3.51s/it]                                                       {'loss': 0.2906, 'grad_norm': 5.589123249053955, 'learning_rate': 3.5042372881355934e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:50:03<4:01:53,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:50:06<4:04:38,  3.55s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.8110728859901428, 'learning_rate': 3.5033898305084745e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:50:06<4:04:38,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:50:10<4:10:43,  3.64s/it]                                                       {'loss': 0.0133, 'grad_norm': 2.7361905574798584, 'learning_rate': 3.502542372881356e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:50:10<4:10:43,  3.64s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:50:13<4:05:42,  3.57s/it]                                                       {'loss': 0.0154, 'grad_norm': 1.12847101688385, 'learning_rate': 3.5016949152542374e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:50:13<4:05:42,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:50:17<4:03:49,  3.54s/it]                                                       {'loss': 0.0348, 'grad_norm': 3.507925510406494, 'learning_rate': 3.5008474576271186e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:50:17<4:03:49,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:50:20<4:02:23,  3.52s/it]                                                       {'loss': 0.0117, 'grad_norm': 0.9546613693237305, 'learning_rate': 3.5e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:50:20<4:02:23,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:50:24<4:01:54,  3.52s/it]                                                       {'loss': 0.2013, 'grad_norm': 7.682616233825684, 'learning_rate': 3.4991525423728815e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:50:24<4:01:54,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:50:28<4:09:32,  3.63s/it]                                                       {'loss': 0.0937, 'grad_norm': 4.037755012512207, 'learning_rate': 3.4983050847457626e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:50:28<4:09:32,  3.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:50:31<4:08:48,  3.62s/it]                                                       {'loss': 0.0731, 'grad_norm': 6.971640586853027, 'learning_rate': 3.4974576271186444e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:50:31<4:08:48,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:50:35<4:06:18,  3.58s/it]                                                       {'loss': 0.0163, 'grad_norm': 2.0198686122894287, 'learning_rate': 3.4966101694915256e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:50:35<4:06:18,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:50:38<4:02:10,  3.52s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.6813138127326965, 'learning_rate': 3.4957627118644074e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:50:38<4:02:10,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:50:42<4:09:07,  3.62s/it]                                                       {'loss': 0.1442, 'grad_norm': 7.859845161437988, 'learning_rate': 3.4949152542372885e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:50:42<4:09:07,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:50:46<4:07:46,  3.61s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.3906533122062683, 'learning_rate': 3.4940677966101696e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:50:46<4:07:46,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:50:49<4:02:17,  3.53s/it]                                                       {'loss': 0.0286, 'grad_norm': 2.9675912857055664, 'learning_rate': 3.493220338983051e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:50:49<4:02:17,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:52<3:59:51,  3.49s/it]                                                       {'loss': 0.0443, 'grad_norm': 2.818756341934204, 'learning_rate': 3.4923728813559326e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:52<3:59:51,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:56<4:00:15,  3.50s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.320083349943161, 'learning_rate': 3.491525423728814e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:56<4:00:15,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:59<3:57:32,  3.46s/it]                                                       {'loss': 0.0464, 'grad_norm': 4.721955299377441, 'learning_rate': 3.4906779661016955e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:59<3:57:32,  3.46s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:51:03<3:54:50,  3.42s/it]                                                       {'loss': 0.0131, 'grad_norm': 1.386094093322754, 'learning_rate': 3.4898305084745766e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:51:03<3:54:50,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:51:06<3:55:35,  3.43s/it]                                                       {'loss': 0.004, 'grad_norm': 0.47653764486312866, 'learning_rate': 3.488983050847458e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:51:06<3:55:35,  3.43s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:51:10<3:56:39,  3.45s/it]                                                       {'loss': 0.0542, 'grad_norm': 6.96876859664917, 'learning_rate': 3.488135593220339e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:51:10<3:56:39,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:51:13<4:04:22,  3.56s/it]                                                       {'loss': 0.0674, 'grad_norm': 5.3047614097595215, 'learning_rate': 3.487288135593221e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:51:13<4:04:22,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:51:17<4:00:29,  3.51s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.2285892963409424, 'learning_rate': 3.486440677966102e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:51:17<4:00:29,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:51:20<3:58:38,  3.48s/it]                                                       {'loss': 0.0782, 'grad_norm': 3.6453006267547607, 'learning_rate': 3.485593220338983e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:51:20<3:58:38,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:51:24<3:57:48,  3.47s/it]                                                       {'loss': 0.0566, 'grad_norm': 6.02924919128418, 'learning_rate': 3.484745762711865e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:51:24<3:57:48,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:51:27<4:05:09,  3.58s/it]                                                       {'loss': 0.0828, 'grad_norm': 3.1636595726013184, 'learning_rate': 3.483898305084746e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:51:28<4:05:09,  3.58s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:51:31<4:03:12,  3.55s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.8395887613296509, 'learning_rate': 3.483050847457627e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:51:31<4:03:12,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:51:35<4:03:26,  3.55s/it]                                                       {'loss': 0.006, 'grad_norm': 0.7765355110168457, 'learning_rate': 3.482203389830508e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:51:35<4:03:26,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:51:38<4:00:54,  3.52s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.4459195137023926, 'learning_rate': 3.48135593220339e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:51:38<4:00:54,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:51:41<3:57:07,  3.46s/it]                                                       {'loss': 0.009, 'grad_norm': 1.0277162790298462, 'learning_rate': 3.480508474576271e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:51:41<3:57:07,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:51:45<4:01:13,  3.52s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.906514048576355, 'learning_rate': 3.479661016949153e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:51:45<4:01:13,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:51:49<4:12:26,  3.69s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.722665786743164, 'learning_rate': 3.478813559322034e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:51:49<4:12:26,  3.69s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:52<4:04:45,  3.58s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.8589765429496765, 'learning_rate': 3.477966101694916e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:52<4:04:45,  3.58s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:56<4:00:25,  3.52s/it]                                                       {'loss': 0.0511, 'grad_norm': 3.145883321762085, 'learning_rate': 3.477118644067797e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:56<4:00:25,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:59<3:56:53,  3.47s/it]                                                       {'loss': 0.006, 'grad_norm': 0.6216700077056885, 'learning_rate': 3.476271186440678e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:59<3:56:53,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:52:02<3:53:55,  3.42s/it]                                                       {'loss': 0.1475, 'grad_norm': 8.591322898864746, 'learning_rate': 3.475423728813559e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:52:02<3:53:55,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:52:06<3:52:28,  3.40s/it]                                                       {'loss': 0.0619, 'grad_norm': 5.584100723266602, 'learning_rate': 3.474576271186441e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:52:06<3:52:28,  3.40s/it][2025-10-20 17:21:52,775] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 902487c3-da9f-4f81-aa59-62dcf69db325)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 17:22:02,945] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 902487c3-da9f-4f81-aa59-62dcf69db325)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 17:22:02,947] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:52:22<8:25:02,  7.39s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.307775616645813, 'learning_rate': 3.473728813559322e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:52:22<8:25:02,  7.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:52:27<7:25:53,  6.53s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.8848485350608826, 'learning_rate': 3.472881355932204e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:52:27<7:25:53,  6.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:52:30<6:21:00,  5.58s/it]                                                       {'loss': 0.0957, 'grad_norm': 2.5385632514953613, 'learning_rate': 3.472033898305085e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:52:30<6:21:00,  5.58s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:52:34<5:45:12,  5.06s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4923994243144989, 'learning_rate': 3.471186440677966e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:52:34<5:45:12,  5.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:52:38<5:19:56,  4.69s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.21560721099376678, 'learning_rate': 3.470338983050847e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:52:38<5:19:56,  4.69s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:52:41<4:50:55,  4.26s/it]                                                       {'loss': 0.128, 'grad_norm': 6.369208335876465, 'learning_rate': 3.469491525423729e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:52:41<4:50:55,  4.26s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:52:45<4:34:16,  4.02s/it]                                                       {'loss': 0.0301, 'grad_norm': 3.8978302478790283, 'learning_rate': 3.46864406779661e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:52:45<4:34:16,  4.02s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:52:48<4:19:56,  3.81s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.3332794904708862, 'learning_rate': 3.4677966101694914e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:52:48<4:19:56,  3.81s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:52:51<4:09:24,  3.66s/it]                                                       {'loss': 0.0258, 'grad_norm': 3.630666732788086, 'learning_rate': 3.466949152542373e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:52:51<4:09:24,  3.66s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:52:55<4:05:58,  3.61s/it]                                                       {'loss': 0.0648, 'grad_norm': 6.883111476898193, 'learning_rate': 3.466101694915254e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:52:55<4:05:58,  3.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:52:58<3:59:41,  3.52s/it]                                                       {'loss': 0.0106, 'grad_norm': 3.0068938732147217, 'learning_rate': 3.465254237288136e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:52:58<3:59:41,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:53:02<3:57:20,  3.48s/it]                                                       {'loss': 0.0653, 'grad_norm': 5.290616512298584, 'learning_rate': 3.4644067796610166e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:53:02<3:57:20,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:53:05<3:57:52,  3.49s/it]                                                       {'loss': 0.081, 'grad_norm': 4.982947826385498, 'learning_rate': 3.4635593220338984e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:53:05<3:57:52,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:53:08<3:54:58,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08737453073263168, 'learning_rate': 3.4627118644067795e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:53:08<3:54:58,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:53:12<3:54:56,  3.45s/it]                                                       {'loss': 0.0155, 'grad_norm': 1.1606028079986572, 'learning_rate': 3.461864406779661e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:53:12<3:54:56,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:53:15<3:55:32,  3.46s/it]                                                       {'loss': 0.1446, 'grad_norm': 10.529582977294922, 'learning_rate': 3.4610169491525425e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:53:15<3:55:32,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:53:19<3:52:37,  3.42s/it]                                                       {'loss': 0.062, 'grad_norm': 8.743878364562988, 'learning_rate': 3.460169491525424e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:53:19<3:52:37,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:53:22<3:52:12,  3.41s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.7436298727989197, 'learning_rate': 3.4593220338983054e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:53:22<3:52:12,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:53:26<3:57:29,  3.49s/it]                                                       {'loss': 0.1347, 'grad_norm': 3.7921769618988037, 'learning_rate': 3.4584745762711865e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:53:26<3:57:29,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:53:29<3:55:05,  3.46s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05263590067625046, 'learning_rate': 3.4576271186440676e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:53:29<3:55:05,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:53:33<3:54:31,  3.45s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3232446014881134, 'learning_rate': 3.4567796610169494e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:53:33<3:54:31,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:53:36<3:51:20,  3.40s/it]                                                       {'loss': 0.1991, 'grad_norm': 7.869276523590088, 'learning_rate': 3.4559322033898306e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:53:36<3:51:20,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:53:39<3:49:42,  3.38s/it]                                                       {'loss': 0.1363, 'grad_norm': 3.795558214187622, 'learning_rate': 3.4550847457627124e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:53:39<3:49:42,  3.38s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:53:43<3:53:33,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04720712825655937, 'learning_rate': 3.4542372881355935e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:53:43<3:53:33,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:53:46<3:52:28,  3.42s/it]                                                       {'loss': 0.0833, 'grad_norm': 5.187614917755127, 'learning_rate': 3.4533898305084746e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:53:46<3:52:28,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:53:50<3:55:12,  3.46s/it]                                                       {'loss': 0.0363, 'grad_norm': 2.3824260234832764, 'learning_rate': 3.452542372881356e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:53:50<3:55:12,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:53:53<3:55:39,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14642171561717987, 'learning_rate': 3.4516949152542376e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:53:53<3:55:39,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:53:57<3:53:35,  3.44s/it]                                                       {'loss': 0.0939, 'grad_norm': 5.392667293548584, 'learning_rate': 3.450847457627119e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:53:57<3:53:35,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:54:00<3:52:09,  3.42s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.1375819891691208, 'learning_rate': 3.45e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:54:00<3:52:09,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:54:03<3:54:18,  3.45s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3722979724407196, 'learning_rate': 3.4491525423728816e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:54:03<3:54:18,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:54:07<3:58:12,  3.51s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2647494077682495, 'learning_rate': 3.448305084745763e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:54:07<3:58:12,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:54:10<3:53:39,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.022779610008001328, 'learning_rate': 3.4474576271186446e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:54:10<3:53:39,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:54:14<3:52:23,  3.43s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.107922911643982, 'learning_rate': 3.446610169491526e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:54:14<3:52:23,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:54:17<3:49:01,  3.38s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.739332675933838, 'learning_rate': 3.445762711864407e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:54:17<3:49:01,  3.38s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:54:20<3:49:34,  3.39s/it]                                                       {'loss': 0.0298, 'grad_norm': 0.9820730090141296, 'learning_rate': 3.444915254237288e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:54:20<3:49:34,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:54:24<3:50:01,  3.40s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.939417839050293, 'learning_rate': 3.44406779661017e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:54:24<3:50:01,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:54:27<3:49:51,  3.39s/it]                                                       {'loss': 0.015, 'grad_norm': 3.872051477432251, 'learning_rate': 3.443220338983051e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:54:27<3:49:51,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:54:31<4:00:25,  3.55s/it]                                                       {'loss': 0.018, 'grad_norm': 2.083570718765259, 'learning_rate': 3.442372881355933e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:54:31<4:00:25,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:54:35<3:55:47,  3.48s/it]                                                       {'loss': 0.0453, 'grad_norm': 4.366950511932373, 'learning_rate': 3.441525423728814e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:54:35<3:55:47,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:54:38<3:55:10,  3.48s/it]                                                       {'loss': 0.07, 'grad_norm': 6.3475494384765625, 'learning_rate': 3.440677966101695e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:54:38<3:55:10,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:54:41<3:52:14,  3.43s/it]                                                       {'loss': 0.1588, 'grad_norm': 8.089430809020996, 'learning_rate': 3.439830508474576e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:54:41<3:52:14,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:54:45<3:52:04,  3.43s/it]                                                       {'loss': 0.1262, 'grad_norm': 6.323768138885498, 'learning_rate': 3.438983050847458e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:54:45<3:52:04,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:54:48<3:50:34,  3.41s/it]                                                       {'loss': 0.0199, 'grad_norm': 3.788835287094116, 'learning_rate': 3.438135593220339e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:54:48<3:50:34,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:54:52<3:53:39,  3.46s/it]                                                       {'loss': 0.0852, 'grad_norm': 9.02650260925293, 'learning_rate': 3.437288135593221e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:54:52<3:53:39,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:54:55<3:59:20,  3.54s/it]                                                       {'loss': 0.0953, 'grad_norm': 6.877119064331055, 'learning_rate': 3.436440677966102e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:54:55<3:59:20,  3.54s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:54:59<3:54:01,  3.46s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.4935653507709503, 'learning_rate': 3.435593220338984e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:54:59<3:54:01,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:55:02<3:54:05,  3.47s/it]                                                       {'loss': 0.1014, 'grad_norm': 5.159809589385986, 'learning_rate': 3.434745762711864e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:55:02<3:54:05,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:55:06<3:55:37,  3.49s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1314457207918167, 'learning_rate': 3.433898305084746e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:55:06<3:55:37,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:55:10<4:02:24,  3.59s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.6669210195541382, 'learning_rate': 3.433050847457627e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:55:10<4:02:24,  3.59s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:55:13<3:57:28,  3.52s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.0241568088531494, 'learning_rate': 3.432203389830508e-05, 'epoch': 0.33}
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:55:13<3:57:28,  3.52s/it][2025-10-20 17:24:59,894] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:55:19<4:42:11,  4.18s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.2587254047393799, 'learning_rate': 3.43135593220339e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:55:19<4:42:11,  4.18s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:55:22<4:25:27,  3.93s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.0907678604125977, 'learning_rate': 3.430508474576271e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:55:22<4:25:27,  3.93s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:55:25<4:14:03,  3.77s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.48931461572647095, 'learning_rate': 3.429661016949153e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:55:25<4:14:03,  3.77s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:55:29<4:07:59,  3.68s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.5419119596481323, 'learning_rate': 3.428813559322034e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:55:29<4:07:59,  3.68s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:55:32<4:02:02,  3.59s/it]                                                       {'loss': 0.0219, 'grad_norm': 2.5986995697021484, 'learning_rate': 3.427966101694915e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:55:32<4:02:02,  3.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:55:36<4:00:21,  3.57s/it]                                                       {'loss': 0.0313, 'grad_norm': 2.4513444900512695, 'learning_rate': 3.4271186440677964e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:55:36<4:00:21,  3.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:55:39<3:56:47,  3.51s/it]                                                       {'loss': 0.1054, 'grad_norm': 5.0422163009643555, 'learning_rate': 3.426271186440678e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:55:39<3:56:47,  3.51s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:55:42<3:53:15,  3.46s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.08514142036438, 'learning_rate': 3.4254237288135593e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:55:42<3:53:15,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:55:46<4:00:29,  3.57s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06573013216257095, 'learning_rate': 3.424576271186441e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:55:46<4:00:29,  3.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:55:50<3:58:57,  3.55s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06769920885562897, 'learning_rate': 3.423728813559322e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:55:50<3:58:57,  3.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:55:53<3:54:24,  3.48s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.6231753826141357, 'learning_rate': 3.4228813559322034e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:55:53<3:54:24,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:55:57<3:57:40,  3.53s/it]                                                       {'loss': 0.2233, 'grad_norm': 9.766550064086914, 'learning_rate': 3.4220338983050845e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:55:57<3:57:40,  3.53s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:56:00<3:54:03,  3.48s/it]                                                       {'loss': 0.0348, 'grad_norm': 4.027957916259766, 'learning_rate': 3.421186440677966e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:56:00<3:54:03,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:56:03<3:51:37,  3.44s/it]                                                       {'loss': 0.0434, 'grad_norm': 2.663357734680176, 'learning_rate': 3.4203389830508475e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:56:03<3:51:37,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:56:07<3:49:32,  3.41s/it]                                                       {'loss': 0.0435, 'grad_norm': 4.202550411224365, 'learning_rate': 3.419491525423729e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:56:07<3:49:32,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:56:11<4:02:30,  3.61s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.9539886116981506, 'learning_rate': 3.4186440677966104e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:56:11<4:02:30,  3.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:56:14<3:58:01,  3.54s/it]                                                       {'loss': 0.0783, 'grad_norm': 6.584413051605225, 'learning_rate': 3.417796610169492e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:56:14<3:58:01,  3.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:56:18<3:56:55,  3.53s/it]                                                       {'loss': 0.2032, 'grad_norm': 9.12700366973877, 'learning_rate': 3.416949152542373e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:56:18<3:56:55,  3.53s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:56:21<3:55:15,  3.50s/it]                                                       {'loss': 0.1117, 'grad_norm': 5.458737373352051, 'learning_rate': 3.4161016949152545e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:56:21<3:55:15,  3.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:56:25<4:01:02,  3.59s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.019579680636525154, 'learning_rate': 3.4152542372881356e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:56:25<4:01:02,  3.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:56:28<3:56:35,  3.52s/it]                                                       {'loss': 0.0202, 'grad_norm': 2.623561382293701, 'learning_rate': 3.414406779661017e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:56:28<3:56:35,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:56:32<3:52:52,  3.47s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.029594898223877, 'learning_rate': 3.4135593220338985e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:56:32<3:52:52,  3.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:56:35<3:51:17,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04050502926111221, 'learning_rate': 3.4127118644067797e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:56:35<3:51:17,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:56:39<3:51:42,  3.45s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.4662673473358154, 'learning_rate': 3.4118644067796615e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:56:39<3:51:42,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:56:42<3:53:25,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09810462594032288, 'learning_rate': 3.4110169491525426e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:56:42<3:53:25,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:56:45<3:51:00,  3.44s/it]                                                       {'loss': 0.0516, 'grad_norm': 5.422023296356201, 'learning_rate': 3.410169491525424e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:56:45<3:51:00,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:56:49<3:49:55,  3.43s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3477639853954315, 'learning_rate': 3.409322033898305e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:56:49<3:49:55,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:56:52<3:49:23,  3.42s/it]                                                       {'loss': 0.0202, 'grad_norm': 3.4145045280456543, 'learning_rate': 3.4084745762711867e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:56:52<3:49:23,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:56:56<3:50:30,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.30873745679855347, 'learning_rate': 3.407627118644068e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:56:56<3:50:30,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:56:59<3:50:09,  3.44s/it]                                                       {'loss': 0.0242, 'grad_norm': 1.0876901149749756, 'learning_rate': 3.4067796610169496e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:56:59<3:50:09,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:57:02<3:47:33,  3.40s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4003002345561981, 'learning_rate': 3.405932203389831e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:57:02<3:47:33,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:57:06<3:48:17,  3.41s/it]                                                       {'loss': 0.0663, 'grad_norm': 7.4458513259887695, 'learning_rate': 3.4050847457627125e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:57:06<3:48:17,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:57:09<3:49:55,  3.43s/it]                                                       {'loss': 0.1212, 'grad_norm': 9.582940101623535, 'learning_rate': 3.404237288135593e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:57:09<3:49:55,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:57:13<3:54:32,  3.50s/it]                                                       {'loss': 0.1032, 'grad_norm': 6.962941646575928, 'learning_rate': 3.403389830508475e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:57:13<3:54:32,  3.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:57:16<3:51:24,  3.46s/it]                                                       {'loss': 0.0243, 'grad_norm': 3.818459987640381, 'learning_rate': 3.402542372881356e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:57:16<3:51:24,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:57:20<3:51:31,  3.46s/it]                                                       {'loss': 0.2122, 'grad_norm': 10.033064842224121, 'learning_rate': 3.401694915254238e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:57:20<3:51:31,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:57:23<3:51:42,  3.46s/it]                                                       {'loss': 0.0179, 'grad_norm': 2.3671152591705322, 'learning_rate': 3.400847457627119e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:57:23<3:51:42,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:57:27<3:51:25,  3.46s/it]                                                       {'loss': 0.1232, 'grad_norm': 6.33976411819458, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:57:27<3:51:25,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:57:30<3:52:01,  3.47s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.1785402297973633, 'learning_rate': 3.399152542372882e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:57:30<3:52:01,  3.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:57:34<3:49:55,  3.44s/it]                                                       {'loss': 0.089, 'grad_norm': 6.813467025756836, 'learning_rate': 3.398305084745763e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:57:34<3:49:55,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:57:37<3:49:00,  3.43s/it]                                                       {'loss': 0.0255, 'grad_norm': 1.9003782272338867, 'learning_rate': 3.397457627118644e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:57:37<3:49:00,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:57:40<3:47:06,  3.40s/it]                                                       {'loss': 0.0771, 'grad_norm': 5.112605094909668, 'learning_rate': 3.396610169491525e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:57:40<3:47:06,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:57:44<3:46:21,  3.39s/it]                                                       {'loss': 0.0474, 'grad_norm': 6.332733154296875, 'learning_rate': 3.395762711864407e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:57:44<3:46:21,  3.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:57:47<3:44:09,  3.36s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2816588580608368, 'learning_rate': 3.394915254237288e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:57:47<3:44:09,  3.36s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:57:51<3:47:35,  3.41s/it]                                                       {'loss': 0.1767, 'grad_norm': 7.210011959075928, 'learning_rate': 3.39406779661017e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:57:51<3:47:35,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:57:54<3:47:01,  3.40s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.6764421463012695, 'learning_rate': 3.393220338983051e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:57:54<3:47:01,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:57:57<3:47:35,  3.41s/it]                                                       {'loss': 0.0423, 'grad_norm': 4.642543315887451, 'learning_rate': 3.392372881355932e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:57:57<3:47:35,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:58:01<3:48:53,  3.43s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.5362285375595093, 'learning_rate': 3.391525423728813e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:58:01<3:48:53,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:58:05<3:59:08,  3.59s/it]                                                       {'loss': 0.011, 'grad_norm': 1.0806896686553955, 'learning_rate': 3.390677966101695e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:58:05<3:59:08,  3.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:58:09<4:06:15,  3.69s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.28531619906425476, 'learning_rate': 3.389830508474576e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:58:09<4:06:15,  3.69s/it][2025-10-20 17:27:55,773] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: fbfa2597-0a64-4c5f-877b-5f87927294f8)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 17:28:05,833] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: fbfa2597-0a64-4c5f-877b-5f87927294f8)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 17:28:05,835] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:58:26<8:28:44,  7.63s/it]                                                       {'loss': 0.0324, 'grad_norm': 3.654265880584717, 'learning_rate': 3.388983050847458e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:58:26<8:28:44,  7.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:58:29<7:02:50,  6.35s/it]                                                       {'loss': 0.0327, 'grad_norm': 3.197049140930176, 'learning_rate': 3.388135593220339e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:58:29<7:02:50,  6.35s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:58:32<6:01:21,  5.42s/it]                                                       {'loss': 0.041, 'grad_norm': 4.6685872077941895, 'learning_rate': 3.387288135593221e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:58:32<6:01:21,  5.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:58:36<5:21:00,  4.82s/it]                                                       {'loss': 0.0, 'grad_norm': 0.006920502055436373, 'learning_rate': 3.386440677966102e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:58:36<5:21:00,  4.82s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:58:39<4:53:09,  4.40s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.808463990688324, 'learning_rate': 3.385593220338983e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:58:39<4:53:09,  4.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:58:43<4:39:18,  4.20s/it]                                                       {'loss': 0.0892, 'grad_norm': 4.564425468444824, 'learning_rate': 3.3847457627118644e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:58:43<4:39:18,  4.20s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:58:46<4:26:35,  4.01s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6287181973457336, 'learning_rate': 3.383898305084746e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:58:46<4:26:35,  4.01s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:58:50<4:18:54,  3.89s/it]                                                       {'loss': 0.0832, 'grad_norm': 3.888997793197632, 'learning_rate': 3.383050847457627e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:58:50<4:18:54,  3.89s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:58:53<4:07:00,  3.71s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.6101767420768738, 'learning_rate': 3.382203389830509e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:58:53<4:07:00,  3.71s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:58:57<4:10:38,  3.77s/it]                                                       {'loss': 0.0823, 'grad_norm': 5.643516540527344, 'learning_rate': 3.38135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:58:57<4:10:38,  3.77s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:59:01<4:02:24,  3.65s/it]                                                       {'loss': 0.0171, 'grad_norm': 1.9776248931884766, 'learning_rate': 3.3805084745762714e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:59:01<4:02:24,  3.65s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:59:04<3:55:01,  3.54s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.499529629945755, 'learning_rate': 3.3796610169491525e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:59:04<3:55:01,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:59:07<3:51:33,  3.48s/it]                                                       {'loss': 0.2732, 'grad_norm': 11.368531227111816, 'learning_rate': 3.3788135593220336e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:59:07<3:51:33,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:59:11<3:48:43,  3.44s/it]                                                       {'loss': 0.0657, 'grad_norm': 5.823380470275879, 'learning_rate': 3.3779661016949154e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:59:11<3:48:43,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:59:14<3:47:43,  3.43s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.7631280422210693, 'learning_rate': 3.3771186440677965e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:59:14<3:47:43,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:59:17<3:47:53,  3.43s/it]                                                       {'loss': 0.0375, 'grad_norm': 3.3522517681121826, 'learning_rate': 3.3762711864406784e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:59:17<3:47:53,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:59:21<3:48:25,  3.44s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.0158660411834717, 'learning_rate': 3.3754237288135595e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:59:21<3:48:25,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:59:24<3:46:49,  3.42s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.31630104780197144, 'learning_rate': 3.3745762711864406e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:59:24<3:46:49,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:59:28<3:49:43,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.039195869117975235, 'learning_rate': 3.373728813559322e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:59:28<3:49:43,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:59:32<3:56:50,  3.57s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.47016650438308716, 'learning_rate': 3.3728813559322035e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:59:32<3:56:50,  3.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:59:35<3:51:11,  3.49s/it]                                                       {'loss': 0.1109, 'grad_norm': 7.960353851318359, 'learning_rate': 3.372033898305085e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:59:35<3:51:11,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:59:38<3:48:36,  3.45s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06043855473399162, 'learning_rate': 3.3711864406779665e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:59:38<3:48:36,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:59:42<3:49:31,  3.46s/it]                                                       {'loss': 0.0127, 'grad_norm': 2.156710624694824, 'learning_rate': 3.3703389830508476e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:59:42<3:49:31,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:59:45<3:47:36,  3.43s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2524794638156891, 'learning_rate': 3.3694915254237294e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:59:45<3:47:36,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:59:48<3:45:46,  3.41s/it]                                                       {'loss': 0.0464, 'grad_norm': 5.212048530578613, 'learning_rate': 3.3686440677966105e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:59:48<3:45:46,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:59:52<3:47:00,  3.43s/it]                                                       {'loss': 0.002, 'grad_norm': 0.308688759803772, 'learning_rate': 3.367796610169492e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:59:52<3:47:00,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:59:55<3:44:41,  3.39s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.725422739982605, 'learning_rate': 3.366949152542373e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:59:55<3:44:41,  3.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:59:59<3:43:53,  3.38s/it]                                                       {'loss': 0.0478, 'grad_norm': 3.8270318508148193, 'learning_rate': 3.3661016949152546e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:59:59<3:43:53,  3.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [2:00:02<3:47:04,  3.43s/it]                                                       {'loss': 0.0773, 'grad_norm': 8.873268127441406, 'learning_rate': 3.365254237288136e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [2:00:02<3:47:04,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [2:00:06<4:03:53,  3.69s/it]                                                       {'loss': 0.0777, 'grad_norm': 5.521542549133301, 'learning_rate': 3.3644067796610175e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [2:00:06<4:03:53,  3.69s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [2:00:10<3:56:48,  3.58s/it]                                                       {'loss': 0.1064, 'grad_norm': 8.362114906311035, 'learning_rate': 3.363559322033899e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [2:00:10<3:56:48,  3.58s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [2:00:13<3:54:01,  3.54s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.9848400354385376, 'learning_rate': 3.36271186440678e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [2:00:13<3:54:01,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [2:00:17<3:54:45,  3.55s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.2465438842773438, 'learning_rate': 3.361864406779661e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [2:00:17<3:54:45,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [2:00:20<3:52:56,  3.52s/it]                                                       {'loss': 0.031, 'grad_norm': 2.973966121673584, 'learning_rate': 3.361016949152542e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [2:00:20<3:52:56,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [2:00:24<3:59:05,  3.62s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.44159626960754395, 'learning_rate': 3.360169491525424e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [2:00:24<3:59:05,  3.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [2:00:27<3:54:21,  3.55s/it]                                                       {'loss': 0.1897, 'grad_norm': 9.343071937561035, 'learning_rate': 3.359322033898305e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [2:00:27<3:54:21,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [2:00:31<3:50:16,  3.49s/it]                                                       {'loss': 0.0198, 'grad_norm': 3.1332435607910156, 'learning_rate': 3.358474576271187e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [2:00:31<3:50:16,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [2:00:34<3:48:30,  3.46s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.2842779159545898, 'learning_rate': 3.357627118644068e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [2:00:34<3:48:30,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [2:00:37<3:45:29,  3.42s/it]                                                       {'loss': 0.0246, 'grad_norm': 4.8828911781311035, 'learning_rate': 3.35677966101695e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [2:00:37<3:45:29,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [2:00:41<3:51:36,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.023018818348646164, 'learning_rate': 3.35593220338983e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [2:00:41<3:51:36,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [2:00:44<3:46:50,  3.44s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.5711935758590698, 'learning_rate': 3.355084745762712e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [2:00:44<3:46:50,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [2:00:48<3:44:04,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02866954356431961, 'learning_rate': 3.354237288135593e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [2:00:48<3:44:04,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [2:00:51<3:43:34,  3.39s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3552180230617523, 'learning_rate': 3.353389830508475e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [2:00:51<3:43:34,  3.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [2:00:55<3:44:14,  3.40s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.7384771108627319, 'learning_rate': 3.352542372881356e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [2:00:55<3:44:14,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [2:00:58<3:42:13,  3.37s/it]                                                       {'loss': 0.0275, 'grad_norm': 2.793208599090576, 'learning_rate': 3.351694915254238e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [2:00:58<3:42:13,  3.37s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [2:01:01<3:45:34,  3.42s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.760615587234497, 'learning_rate': 3.350847457627119e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [2:01:01<3:45:34,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [2:01:05<3:47:11,  3.45s/it]                                                       {'loss': 0.05, 'grad_norm': 6.136454105377197, 'learning_rate': 3.35e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [2:01:05<3:47:11,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [2:01:09<3:50:18,  3.50s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.35382878780365, 'learning_rate': 3.349152542372881e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [2:01:09<3:50:18,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:01:12<3:46:33,  3.44s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.5259142518043518, 'learning_rate': 3.348305084745763e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:01:12<3:46:33,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:01:15<3:45:10,  3.42s/it]                                                       {'loss': 0.2762, 'grad_norm': 10.22471809387207, 'learning_rate': 3.347457627118644e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:01:15<3:45:10,  3.42s/it][2025-10-20 17:31:02,221] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:01:21<4:36:17,  4.20s/it]                                                       {'loss': 0.0208, 'grad_norm': 2.8807871341705322, 'learning_rate': 3.346610169491526e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:01:21<4:36:17,  4.20s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:01:25<4:23:41,  4.01s/it]                                                       {'loss': 0.1366, 'grad_norm': 6.1228814125061035, 'learning_rate': 3.345762711864407e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:01:25<4:23:41,  4.01s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:01:28<4:10:06,  3.80s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.093019962310791, 'learning_rate': 3.344915254237288e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:01:28<4:10:06,  3.80s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:01:31<4:01:36,  3.67s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.6807695627212524, 'learning_rate': 3.3440677966101694e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:01:31<4:01:36,  3.67s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:01:35<4:02:32,  3.69s/it]                                                       {'loss': 0.1776, 'grad_norm': 7.182470321655273, 'learning_rate': 3.3432203389830505e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:01:35<4:02:32,  3.69s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:01:39<3:56:13,  3.59s/it]                                                       {'loss': 0.0244, 'grad_norm': 3.2036936283111572, 'learning_rate': 3.342372881355932e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:01:39<3:56:13,  3.59s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:01:43<4:09:34,  3.80s/it]                                                       {'loss': 0.0513, 'grad_norm': 6.2906599044799805, 'learning_rate': 3.3415254237288134e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:01:43<4:09:34,  3.80s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:01:46<4:01:19,  3.67s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.43046095967292786, 'learning_rate': 3.340677966101695e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:01:46<4:01:19,  3.67s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:01:50<3:54:59,  3.58s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.124839425086975, 'learning_rate': 3.3398305084745764e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:01:50<3:54:59,  3.58s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:01:53<3:52:05,  3.53s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.20206712186336517, 'learning_rate': 3.338983050847458e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:01:53<3:52:05,  3.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:01:57<3:51:13,  3.52s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.39059922099113464, 'learning_rate': 3.338135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:01:57<3:51:13,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:02:00<3:48:40,  3.48s/it]                                                       {'loss': 0.1159, 'grad_norm': 5.194418430328369, 'learning_rate': 3.3372881355932204e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:02:00<3:48:40,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:02:03<3:46:48,  3.46s/it]                                                       {'loss': 0.0295, 'grad_norm': 2.498340606689453, 'learning_rate': 3.3364406779661016e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:02:03<3:46:48,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:02:07<3:46:29,  3.45s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.105518102645874, 'learning_rate': 3.3355932203389834e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:02:07<3:46:29,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:02:11<3:53:06,  3.55s/it]                                                       {'loss': 0.1111, 'grad_norm': 7.992259502410889, 'learning_rate': 3.3347457627118645e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:02:11<3:53:06,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:02:15<4:01:56,  3.69s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.048584382981061935, 'learning_rate': 3.333898305084746e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:02:15<4:01:56,  3.69s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:02:18<3:55:15,  3.59s/it]                                                       {'loss': 0.0523, 'grad_norm': 5.222320079803467, 'learning_rate': 3.3330508474576274e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:02:18<3:55:15,  3.59s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:02:21<3:50:42,  3.52s/it]                                                       {'loss': 0.1074, 'grad_norm': 9.94607925415039, 'learning_rate': 3.3322033898305086e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:02:21<3:50:42,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:02:26<4:05:24,  3.75s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.7686631083488464, 'learning_rate': 3.33135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:02:26<4:05:24,  3.75s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:02:29<3:58:53,  3.65s/it]                                                       {'loss': 0.21, 'grad_norm': 8.458232879638672, 'learning_rate': 3.3305084745762715e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:02:29<3:58:53,  3.65s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:02:32<3:53:40,  3.57s/it]                                                       {'loss': 0.0672, 'grad_norm': 5.980149745941162, 'learning_rate': 3.3296610169491526e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:02:32<3:53:40,  3.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:02:36<3:50:29,  3.52s/it]                                                       {'loss': 0.0672, 'grad_norm': 3.96418833732605, 'learning_rate': 3.3288135593220344e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:02:36<3:50:29,  3.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:02:39<3:45:38,  3.45s/it]                                                       {'loss': 0.0532, 'grad_norm': 5.568660259246826, 'learning_rate': 3.3279661016949156e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:02:39<3:45:38,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:02:43<3:50:19,  3.52s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.9387019872665405, 'learning_rate': 3.327118644067797e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:02:43<3:50:19,  3.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:02:46<3:52:54,  3.56s/it]                                                       {'loss': 0.0813, 'grad_norm': 6.851113796234131, 'learning_rate': 3.326271186440678e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:02:46<3:52:54,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:02:50<3:49:15,  3.51s/it]                                                       {'loss': 0.0935, 'grad_norm': 5.699029445648193, 'learning_rate': 3.325423728813559e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:02:50<3:49:15,  3.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:02:53<3:47:30,  3.48s/it]                                                       {'loss': 0.001, 'grad_norm': 0.15509635210037231, 'learning_rate': 3.324576271186441e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:02:53<3:47:30,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:02:57<3:45:32,  3.45s/it]                                                       {'loss': 0.1833, 'grad_norm': 7.70369291305542, 'learning_rate': 3.323728813559322e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:02:57<3:45:32,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:03:00<3:43:01,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014658436179161072, 'learning_rate': 3.322881355932204e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:03:00<3:43:01,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:03:03<3:42:59,  3.41s/it]                                                       {'loss': 0.0262, 'grad_norm': 3.0035555362701416, 'learning_rate': 3.322033898305085e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:03:03<3:42:59,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:03:07<3:42:30,  3.41s/it]                                                       {'loss': 0.1717, 'grad_norm': 11.864691734313965, 'learning_rate': 3.3211864406779666e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:03:07<3:42:30,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:03:10<3:43:51,  3.43s/it]                                                       {'loss': 0.014, 'grad_norm': 1.8400439023971558, 'learning_rate': 3.320338983050848e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:03:10<3:43:51,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:03:13<3:41:56,  3.40s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5233311653137207, 'learning_rate': 3.319491525423729e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:03:14<3:41:56,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:03:17<3:42:14,  3.41s/it]                                                       {'loss': 0.0737, 'grad_norm': 7.4576616287231445, 'learning_rate': 3.31864406779661e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:03:17<3:42:14,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:03:21<3:50:18,  3.53s/it]                                                       {'loss': 0.0159, 'grad_norm': 3.013833522796631, 'learning_rate': 3.317796610169492e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:03:21<3:50:18,  3.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:03:24<3:49:57,  3.53s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4838901162147522, 'learning_rate': 3.316949152542373e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:03:24<3:49:57,  3.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:03:28<3:55:20,  3.61s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.7298185229301453, 'learning_rate': 3.316101694915255e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:03:28<3:55:20,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:03:31<3:49:18,  3.52s/it]                                                       {'loss': 0.077, 'grad_norm': 7.226921558380127, 'learning_rate': 3.315254237288136e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:03:31<3:49:18,  3.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:03:35<3:45:56,  3.47s/it]                                                       {'loss': 0.1415, 'grad_norm': 7.699739456176758, 'learning_rate': 3.314406779661017e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:03:35<3:45:56,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:03:38<3:43:54,  3.44s/it]                                                       {'loss': 0.1826, 'grad_norm': 9.21642017364502, 'learning_rate': 3.313559322033898e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:03:38<3:43:54,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:03:41<3:43:03,  3.42s/it]                                                       {'loss': 0.0388, 'grad_norm': 4.373377799987793, 'learning_rate': 3.31271186440678e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:03:41<3:43:03,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:03:45<3:42:34,  3.42s/it]                                                       {'loss': 0.0315, 'grad_norm': 4.07332706451416, 'learning_rate': 3.311864406779661e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:03:45<3:42:34,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:03:48<3:43:25,  3.43s/it]                                                       {'loss': 0.1188, 'grad_norm': 9.703221321105957, 'learning_rate': 3.311016949152543e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:03:48<3:43:25,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:03:52<3:46:29,  3.48s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.49806681275367737, 'learning_rate': 3.310169491525424e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:03:52<3:46:29,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:03:56<3:55:24,  3.62s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.1985551118850708, 'learning_rate': 3.309322033898305e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:03:56<3:55:24,  3.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:03:59<3:50:10,  3.54s/it]                                                       {'loss': 0.0558, 'grad_norm': 3.938387393951416, 'learning_rate': 3.308474576271187e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:03:59<3:50:10,  3.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:04:03<3:55:24,  3.62s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4941042959690094, 'learning_rate': 3.3076271186440674e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:04:03<3:55:24,  3.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:04:06<3:51:00,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04621405526995659, 'learning_rate': 3.306779661016949e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:04:06<3:51:00,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:04:10<3:53:41,  3.59s/it]                                                       {'loss': 0.0228, 'grad_norm': 3.5471737384796143, 'learning_rate': 3.30593220338983e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:04:10<3:53:41,  3.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:04:13<3:48:58,  3.52s/it]                                                       {'loss': 0.0859, 'grad_norm': 7.735024452209473, 'learning_rate': 3.305084745762712e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:04:13<3:48:58,  3.52s/it][2025-10-20 17:34:00,455] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:04:19<4:30:09,  4.16s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.623561680316925, 'learning_rate': 3.304237288135593e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:04:19<4:30:09,  4.16s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:04:22<4:13:10,  3.90s/it]                                                       {'loss': 0.0322, 'grad_norm': 3.2352986335754395, 'learning_rate': 3.303389830508475e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:04:22<4:13:10,  3.90s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:04:26<4:01:59,  3.73s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.18132661283016205, 'learning_rate': 3.302542372881356e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:04:26<4:01:59,  3.73s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:04:29<3:55:13,  3.62s/it]                                                       {'loss': 0.1083, 'grad_norm': 6.160306453704834, 'learning_rate': 3.301694915254237e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:04:29<3:55:13,  3.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:04:33<3:51:22,  3.56s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.058724235743284225, 'learning_rate': 3.3008474576271184e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:04:33<3:51:22,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:04:36<3:46:05,  3.48s/it]                                                       {'loss': 0.1281, 'grad_norm': 9.158112525939941, 'learning_rate': 3.3e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:04:36<3:46:05,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:04:39<3:45:06,  3.47s/it]                                                       {'loss': 0.0118, 'grad_norm': 0.8667862415313721, 'learning_rate': 3.2991525423728814e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:04:39<3:45:06,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:04:43<3:44:03,  3.45s/it]                                                       {'loss': 0.1753, 'grad_norm': 7.357852935791016, 'learning_rate': 3.298305084745763e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:04:43<3:44:03,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:04:46<3:44:35,  3.46s/it]                                                       {'loss': 0.2625, 'grad_norm': 6.304932117462158, 'learning_rate': 3.297457627118644e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:04:46<3:44:35,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:04:50<3:53:54,  3.61s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.3440028131008148, 'learning_rate': 3.296610169491526e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:04:50<3:53:54,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:04:54<3:49:54,  3.55s/it]                                                       {'loss': 0.0663, 'grad_norm': 7.170238494873047, 'learning_rate': 3.2957627118644066e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:04:54<3:49:54,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:04:57<3:53:54,  3.61s/it]                                                       {'loss': 0.2497, 'grad_norm': 9.244767189025879, 'learning_rate': 3.2949152542372884e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:04:57<3:53:54,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:05:01<3:50:24,  3.56s/it]                                                       {'loss': 0.018, 'grad_norm': 1.745179533958435, 'learning_rate': 3.2940677966101695e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:05:01<3:50:24,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:05:04<3:45:49,  3.49s/it]                                                       {'loss': 0.0164, 'grad_norm': 1.940443992614746, 'learning_rate': 3.293220338983051e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:05:04<3:45:49,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:05:07<3:43:38,  3.45s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.22421050071716309, 'learning_rate': 3.2923728813559324e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:05:07<3:43:38,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:05:11<3:42:44,  3.44s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.302441954612732, 'learning_rate': 3.2915254237288136e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:05:11<3:42:44,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:05:14<3:42:29,  3.44s/it]                                                       {'loss': 0.2813, 'grad_norm': 9.555603981018066, 'learning_rate': 3.2906779661016954e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:05:14<3:42:29,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:05:18<3:41:16,  3.42s/it]                                                       {'loss': 0.0775, 'grad_norm': 6.24312162399292, 'learning_rate': 3.2898305084745765e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:05:18<3:41:16,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:05:21<3:41:37,  3.43s/it]                                                       {'loss': 0.0233, 'grad_norm': 2.1364858150482178, 'learning_rate': 3.2889830508474576e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:05:21<3:41:37,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:05:24<3:40:50,  3.42s/it]                                                       {'loss': 0.0626, 'grad_norm': 5.952665328979492, 'learning_rate': 3.288135593220339e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:05:24<3:40:50,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:05:28<3:41:06,  3.42s/it]                                                       {'loss': 0.1221, 'grad_norm': 8.860218048095703, 'learning_rate': 3.2872881355932206e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:05:28<3:41:06,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:05:32<3:52:29,  3.60s/it]                                                       {'loss': 0.0746, 'grad_norm': 6.809251308441162, 'learning_rate': 3.286440677966102e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:05:32<3:52:29,  3.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:05:35<3:49:07,  3.55s/it]                                                       {'loss': 0.0315, 'grad_norm': 2.586580753326416, 'learning_rate': 3.2855932203389835e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:05:35<3:49:07,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:05:39<3:44:38,  3.48s/it]                                                       {'loss': 0.2151, 'grad_norm': 10.293550491333008, 'learning_rate': 3.2847457627118646e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:05:39<3:44:38,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:05:42<3:41:40,  3.43s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2393079549074173, 'learning_rate': 3.283898305084746e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:05:42<3:41:40,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:05:45<3:40:38,  3.42s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.22626610100269318, 'learning_rate': 3.283050847457627e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:05:45<3:40:38,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:05:49<3:42:17,  3.44s/it]                                                       {'loss': 0.0782, 'grad_norm': 4.821640968322754, 'learning_rate': 3.282203389830509e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:05:49<3:42:17,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:05:52<3:40:29,  3.42s/it]                                                       {'loss': 0.1532, 'grad_norm': 6.419960975646973, 'learning_rate': 3.28135593220339e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:05:52<3:40:29,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:05:56<3:41:07,  3.43s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.16195392608642578, 'learning_rate': 3.2805084745762716e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:05:56<3:41:07,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:05:59<3:39:46,  3.41s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.0658928155899048, 'learning_rate': 3.279661016949153e-05, 'epoch': 0.35}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:05:59<3:39:46,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:06:02<3:39:28,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.023383084684610367, 'learning_rate': 3.2788135593220346e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:06:02<3:39:28,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:06:06<3:39:21,  3.40s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.0533158779144287, 'learning_rate': 3.277966101694916e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:06:06<3:39:21,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:06:10<3:48:06,  3.54s/it]                                                       {'loss': 0.0256, 'grad_norm': 2.9073286056518555, 'learning_rate': 3.277118644067797e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:06:10<3:48:06,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:06:13<3:45:06,  3.49s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.421566367149353, 'learning_rate': 3.276271186440678e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:06:13<3:45:06,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:06:16<3:41:57,  3.45s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.3443524837493896, 'learning_rate': 3.27542372881356e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:06:16<3:41:57,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:06:20<3:44:20,  3.48s/it]                                                       {'loss': 0.0645, 'grad_norm': 6.089812278747559, 'learning_rate': 3.274576271186441e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:06:20<3:44:20,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:06:23<3:43:29,  3.47s/it]                                                       {'loss': 0.011, 'grad_norm': 2.154714822769165, 'learning_rate': 3.273728813559322e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:06:23<3:43:29,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:06:27<3:40:49,  3.43s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.7446358799934387, 'learning_rate': 3.272881355932204e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:06:27<3:40:49,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:06:30<3:38:02,  3.39s/it]                                                       {'loss': 0.0131, 'grad_norm': 1.3997302055358887, 'learning_rate': 3.272033898305085e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:06:30<3:38:02,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:06:33<3:36:52,  3.37s/it]                                                       {'loss': 0.2793, 'grad_norm': 9.955286979675293, 'learning_rate': 3.271186440677966e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:06:33<3:36:52,  3.37s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:06:37<3:37:57,  3.39s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.13503463566303253, 'learning_rate': 3.270338983050847e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:06:37<3:37:57,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:06:40<3:40:06,  3.42s/it]                                                       {'loss': 0.0084, 'grad_norm': 0.8127555251121521, 'learning_rate': 3.269491525423729e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:06:40<3:40:06,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:06:44<3:47:17,  3.54s/it]                                                       {'loss': 0.0328, 'grad_norm': 4.882544040679932, 'learning_rate': 3.26864406779661e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:06:44<3:47:17,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:06:48<3:45:01,  3.50s/it]                                                       {'loss': 0.0944, 'grad_norm': 6.333867073059082, 'learning_rate': 3.267796610169492e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:06:48<3:45:01,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:06:51<3:43:21,  3.48s/it]                                                       {'loss': 0.0736, 'grad_norm': 6.445523738861084, 'learning_rate': 3.266949152542373e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:06:51<3:43:21,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:06:54<3:41:37,  3.45s/it]                                                       {'loss': 0.026, 'grad_norm': 5.197620391845703, 'learning_rate': 3.266101694915254e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:06:54<3:41:37,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:06:58<3:40:21,  3.43s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.8630315661430359, 'learning_rate': 3.265254237288135e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:06:58<3:40:21,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:07:01<3:40:57,  3.44s/it]                                                       {'loss': 0.3027, 'grad_norm': 8.796798706054688, 'learning_rate': 3.264406779661017e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:07:01<3:40:57,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:07:05<3:38:53,  3.41s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.15205609798431396, 'learning_rate': 3.263559322033898e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:07:05<3:38:53,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:07:08<3:37:47,  3.39s/it]                                                       {'loss': 0.3521, 'grad_norm': 8.289416313171387, 'learning_rate': 3.26271186440678e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:07:08<3:37:47,  3.39s/it][2025-10-20 17:36:54,875] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:07:14<4:33:00,  4.26s/it]                                                       {'loss': 0.005, 'grad_norm': 0.9193246364593506, 'learning_rate': 3.261864406779661e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:07:14<4:33:00,  4.26s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:07:18<4:16:20,  4.00s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.41800567507743835, 'learning_rate': 3.261016949152543e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:07:18<4:16:20,  4.00s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:07:21<4:04:55,  3.82s/it]                                                       {'loss': 0.0187, 'grad_norm': 3.37111759185791, 'learning_rate': 3.260169491525424e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:07:21<4:04:55,  3.82s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:07:24<3:59:28,  3.74s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.6797230243682861, 'learning_rate': 3.259322033898305e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:07:24<3:59:28,  3.74s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:07:28<3:53:27,  3.64s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.9797563552856445, 'learning_rate': 3.2584745762711864e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:07:28<3:53:27,  3.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:07:31<3:48:10,  3.56s/it]                                                       {'loss': 0.0538, 'grad_norm': 4.507205009460449, 'learning_rate': 3.257627118644068e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:07:31<3:48:10,  3.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:07:35<3:45:39,  3.52s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.2102423906326294, 'learning_rate': 3.256779661016949e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:07:35<3:45:39,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:07:38<3:42:30,  3.47s/it]                                                       {'loss': 0.0302, 'grad_norm': 3.32332706451416, 'learning_rate': 3.2559322033898305e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:07:38<3:42:30,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:07:42<3:41:47,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.21311315894126892, 'learning_rate': 3.255084745762712e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:07:42<3:41:47,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:07:45<3:43:06,  3.49s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.8483693599700928, 'learning_rate': 3.2542372881355934e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:07:45<3:43:06,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:07:48<3:40:55,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.47025614976882935, 'learning_rate': 3.2533898305084745e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:07:48<3:40:55,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:07:52<3:37:26,  3.40s/it]                                                       {'loss': 0.0602, 'grad_norm': 5.9034247398376465, 'learning_rate': 3.2525423728813557e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:07:52<3:37:26,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:07:56<3:46:01,  3.53s/it]                                                       {'loss': 0.0416, 'grad_norm': 6.786179542541504, 'learning_rate': 3.2516949152542375e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:07:56<3:46:01,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:07:59<3:41:34,  3.47s/it]                                                       {'loss': 0.0554, 'grad_norm': 4.351111888885498, 'learning_rate': 3.2508474576271186e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:07:59<3:41:34,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:08:02<3:40:17,  3.45s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.4996484518051147, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:08:02<3:40:17,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:08:06<3:38:29,  3.42s/it]                                                       {'loss': 0.0536, 'grad_norm': 7.999496936798096, 'learning_rate': 3.2491525423728815e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:08:06<3:38:29,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:08:09<3:37:36,  3.41s/it]                                                       {'loss': 0.0286, 'grad_norm': 5.61187219619751, 'learning_rate': 3.248305084745763e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:08:09<3:37:36,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:08:12<3:38:15,  3.42s/it]                                                       {'loss': 0.0243, 'grad_norm': 3.5198957920074463, 'learning_rate': 3.247457627118644e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:08:12<3:38:15,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:08:16<3:37:29,  3.41s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.35570672154426575, 'learning_rate': 3.2466101694915256e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:08:16<3:37:29,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:08:19<3:39:51,  3.44s/it]                                                       {'loss': 0.0316, 'grad_norm': 3.7362208366394043, 'learning_rate': 3.245762711864407e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:08:19<3:39:51,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:08:23<3:38:43,  3.43s/it]                                                       {'loss': 0.065, 'grad_norm': 3.1145706176757812, 'learning_rate': 3.2449152542372885e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:08:23<3:38:43,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:08:26<3:43:04,  3.50s/it]                                                       {'loss': 0.02, 'grad_norm': 1.8700553178787231, 'learning_rate': 3.2440677966101696e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:08:26<3:43:04,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:08:30<3:40:06,  3.45s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2859993577003479, 'learning_rate': 3.2432203389830515e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:08:30<3:40:06,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:08:33<3:42:41,  3.49s/it]                                                       {'loss': 0.0234, 'grad_norm': 2.7391550540924072, 'learning_rate': 3.2423728813559326e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:08:33<3:42:41,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:08:37<3:41:39,  3.48s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.17974676191806793, 'learning_rate': 3.241525423728814e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:08:37<3:41:39,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:08:40<3:40:20,  3.46s/it]                                                       {'loss': 0.0754, 'grad_norm': 6.4921441078186035, 'learning_rate': 3.240677966101695e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:08:40<3:40:20,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:08:44<3:42:36,  3.49s/it]                                                       {'loss': 0.0434, 'grad_norm': 3.695377826690674, 'learning_rate': 3.2398305084745766e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:08:44<3:42:36,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:08:47<3:44:55,  3.53s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.659252405166626, 'learning_rate': 3.238983050847458e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:08:47<3:44:55,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:08:51<3:41:34,  3.48s/it]                                                       {'loss': 0.1285, 'grad_norm': 6.464419841766357, 'learning_rate': 3.238135593220339e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:08:51<3:41:34,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:08:54<3:39:15,  3.44s/it]                                                       {'loss': 0.0413, 'grad_norm': 3.2208926677703857, 'learning_rate': 3.237288135593221e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:08:54<3:39:15,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:08:58<3:39:38,  3.45s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.173028364777565, 'learning_rate': 3.236440677966102e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:08:58<3:39:38,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:09:01<3:41:11,  3.48s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.3154797554016113, 'learning_rate': 3.235593220338983e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:09:01<3:41:11,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:09:05<3:51:20,  3.64s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.153079554438591, 'learning_rate': 3.234745762711864e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:09:05<3:51:20,  3.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:09:09<3:47:44,  3.58s/it]                                                       {'loss': 0.0941, 'grad_norm': 5.085480213165283, 'learning_rate': 3.233898305084746e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:09:09<3:47:44,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:09:12<3:44:19,  3.53s/it]                                                       {'loss': 0.001, 'grad_norm': 0.12570737302303314, 'learning_rate': 3.233050847457627e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:09:12<3:44:19,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:09:16<3:48:13,  3.59s/it]                                                       {'loss': 0.0499, 'grad_norm': 6.504357814788818, 'learning_rate': 3.232203389830509e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:09:16<3:48:13,  3.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:09:20<3:52:27,  3.66s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.571519374847412, 'learning_rate': 3.23135593220339e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:09:20<3:52:27,  3.66s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:09:23<3:48:31,  3.60s/it]                                                       {'loss': 0.1278, 'grad_norm': 6.985819339752197, 'learning_rate': 3.230508474576272e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:09:23<3:48:31,  3.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:09:26<3:44:55,  3.54s/it]                                                       {'loss': 0.1412, 'grad_norm': 8.36009407043457, 'learning_rate': 3.229661016949153e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:09:26<3:44:55,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:09:30<3:42:40,  3.51s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6046848297119141, 'learning_rate': 3.228813559322034e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:09:30<3:42:40,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:09:33<3:40:02,  3.47s/it]                                                       {'loss': 0.1736, 'grad_norm': 7.6488847732543945, 'learning_rate': 3.227966101694915e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:09:33<3:40:02,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:09:37<3:39:41,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013906537555158138, 'learning_rate': 3.227118644067797e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:09:37<3:39:41,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:09:40<3:36:21,  3.41s/it]                                                       {'loss': 0.0334, 'grad_norm': 4.470498561859131, 'learning_rate': 3.226271186440678e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:09:40<3:36:21,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:09:43<3:39:13,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04330543056130409, 'learning_rate': 3.22542372881356e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:09:43<3:39:13,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:09:47<3:38:05,  3.44s/it]                                                       {'loss': 0.0248, 'grad_norm': 2.776967763900757, 'learning_rate': 3.224576271186441e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:09:47<3:38:05,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:09:50<3:40:08,  3.47s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3475396931171417, 'learning_rate': 3.223728813559322e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:09:50<3:40:08,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:09:54<3:36:43,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.5045663714408875, 'learning_rate': 3.222881355932203e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:09:54<3:36:43,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:09:57<3:35:58,  3.41s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.2120929956436157, 'learning_rate': 3.222033898305085e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:09:57<3:35:58,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:10:01<3:36:36,  3.42s/it]                                                       {'loss': 0.2029, 'grad_norm': 10.762561798095703, 'learning_rate': 3.221186440677966e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:10:01<3:36:36,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:10:04<3:44:23,  3.54s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.045116901397705, 'learning_rate': 3.2203389830508473e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:10:04<3:44:23,  3.54s/it][2025-10-20 17:39:51,375] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:10:10<4:24:30,  4.18s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.7443634271621704, 'learning_rate': 3.219491525423729e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:10:10<4:24:30,  4.18s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:10:13<4:09:56,  3.95s/it]                                                       {'loss': 0.0892, 'grad_norm': 3.928351879119873, 'learning_rate': 3.21864406779661e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:10:13<4:09:56,  3.95s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:10:17<4:00:55,  3.81s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.7683507204055786, 'learning_rate': 3.2177966101694914e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:10:17<4:00:55,  3.81s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:10:20<3:53:53,  3.70s/it]                                                       {'loss': 0.1285, 'grad_norm': 8.606898307800293, 'learning_rate': 3.2169491525423725e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:10:20<3:53:53,  3.70s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:10:24<3:48:58,  3.62s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07345302402973175, 'learning_rate': 3.2161016949152543e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:10:24<3:48:58,  3.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:10:28<4:02:16,  3.83s/it]                                                       {'loss': 0.0882, 'grad_norm': 5.672934055328369, 'learning_rate': 3.2152542372881355e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:10:28<4:02:16,  3.83s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:10:32<3:54:15,  3.71s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.29450008273124695, 'learning_rate': 3.214406779661017e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:10:32<3:54:15,  3.71s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:10:35<3:50:21,  3.64s/it]                                                       {'loss': 0.3909, 'grad_norm': 9.840438842773438, 'learning_rate': 3.2135593220338984e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:10:35<3:50:21,  3.64s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:10:38<3:44:49,  3.56s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.1849653720855713, 'learning_rate': 3.21271186440678e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:10:38<3:44:49,  3.56s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:10:42<3:42:08,  3.52s/it]                                                       {'loss': 0.0593, 'grad_norm': 5.592102527618408, 'learning_rate': 3.2118644067796613e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:10:42<3:42:08,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:10:45<3:39:17,  3.47s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3819235861301422, 'learning_rate': 3.2110169491525425e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:10:45<3:39:17,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:10:49<3:43:35,  3.54s/it]                                                       {'loss': 0.0546, 'grad_norm': 6.203973770141602, 'learning_rate': 3.2101694915254236e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:10:49<3:43:35,  3.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:10:52<3:41:08,  3.50s/it]                                                       {'loss': 0.0848, 'grad_norm': 7.59733247756958, 'learning_rate': 3.2093220338983054e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:10:52<3:41:08,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:10:56<3:37:45,  3.45s/it]                                                       {'loss': 0.0413, 'grad_norm': 3.847567319869995, 'learning_rate': 3.2084745762711865e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:10:56<3:37:45,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:10:59<3:36:45,  3.44s/it]                                                       {'loss': 0.008, 'grad_norm': 1.1695902347564697, 'learning_rate': 3.2076271186440683e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:10:59<3:36:45,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:11:03<3:39:52,  3.49s/it]                                                       {'loss': 0.0176, 'grad_norm': 3.0622236728668213, 'learning_rate': 3.2067796610169495e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:11:03<3:39:52,  3.49s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:11:06<3:38:04,  3.46s/it]                                                       {'loss': 0.2461, 'grad_norm': 8.82097053527832, 'learning_rate': 3.2059322033898306e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:11:06<3:38:04,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:11:09<3:37:50,  3.46s/it]                                                       {'loss': 0.1583, 'grad_norm': 9.232954978942871, 'learning_rate': 3.205084745762712e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:11:10<3:37:50,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:11:13<3:37:37,  3.45s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.36286941170692444, 'learning_rate': 3.2042372881355935e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:11:13<3:37:37,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:11:16<3:36:26,  3.44s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6519136428833008, 'learning_rate': 3.203389830508475e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:11:16<3:36:26,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:11:20<3:37:23,  3.45s/it]                                                       {'loss': 0.003, 'grad_norm': 0.46203601360321045, 'learning_rate': 3.202542372881356e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:11:20<3:37:23,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:11:23<3:39:49,  3.49s/it]                                                       {'loss': 0.0234, 'grad_norm': 3.4582464694976807, 'learning_rate': 3.2016949152542376e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:11:23<3:39:49,  3.49s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:11:27<3:42:43,  3.54s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1504392921924591, 'learning_rate': 3.200847457627119e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:11:27<3:42:43,  3.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:11:30<3:38:11,  3.47s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.11294090747833252, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:11:30<3:38:11,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:11:34<3:35:51,  3.43s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.5651144981384277, 'learning_rate': 3.199152542372881e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:11:34<3:35:51,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:11:37<3:34:14,  3.41s/it]                                                       {'loss': 0.1885, 'grad_norm': 9.06729793548584, 'learning_rate': 3.198305084745763e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:11:37<3:34:14,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:11:40<3:34:21,  3.41s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.3512437343597412, 'learning_rate': 3.197457627118644e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:11:40<3:34:21,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:11:44<3:36:56,  3.45s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.6602939367294312, 'learning_rate': 3.196610169491526e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:11:44<3:36:56,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:11:47<3:34:47,  3.42s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.0360599756240845, 'learning_rate': 3.195762711864407e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:11:47<3:34:47,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:11:51<3:41:55,  3.53s/it]                                                       {'loss': 0.0578, 'grad_norm': 5.545083045959473, 'learning_rate': 3.1949152542372887e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:11:51<3:41:55,  3.53s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:11:55<3:40:44,  3.51s/it]                                                       {'loss': 0.0155, 'grad_norm': 1.924846887588501, 'learning_rate': 3.19406779661017e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:11:55<3:40:44,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:11:58<3:40:38,  3.51s/it]                                                       {'loss': 0.157, 'grad_norm': 10.095277786254883, 'learning_rate': 3.193220338983051e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:11:58<3:40:38,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:12:02<3:37:56,  3.47s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.406160831451416, 'learning_rate': 3.192372881355932e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:12:02<3:37:56,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:12:05<3:46:00,  3.60s/it]                                                       {'loss': 0.0354, 'grad_norm': 3.3236470222473145, 'learning_rate': 3.191525423728814e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:12:05<3:46:00,  3.60s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:12:09<3:41:02,  3.52s/it]                                                       {'loss': 0.3612, 'grad_norm': 9.351349830627441, 'learning_rate': 3.190677966101695e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:12:09<3:41:02,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:12:12<3:38:12,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03862609714269638, 'learning_rate': 3.189830508474577e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:12:12<3:38:12,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:12:16<3:38:10,  3.48s/it]                                                       {'loss': 0.2278, 'grad_norm': 8.037110328674316, 'learning_rate': 3.188983050847458e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:12:16<3:38:10,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:12:19<3:36:57,  3.46s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.7849364280700684, 'learning_rate': 3.18813559322034e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:12:19<3:36:57,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:12:22<3:35:15,  3.43s/it]                                                       {'loss': 0.1426, 'grad_norm': 9.180438041687012, 'learning_rate': 3.18728813559322e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:12:22<3:35:15,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:12:26<3:34:23,  3.42s/it]                                                       {'loss': 0.0758, 'grad_norm': 5.918344020843506, 'learning_rate': 3.186440677966101e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:12:26<3:34:23,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:12:29<3:37:48,  3.48s/it]                                                       {'loss': 0.0137, 'grad_norm': 2.0363411903381348, 'learning_rate': 3.185593220338983e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:12:29<3:37:48,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:12:33<3:44:00,  3.58s/it]                                                       {'loss': 0.0304, 'grad_norm': 4.736884117126465, 'learning_rate': 3.184745762711864e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:12:33<3:44:00,  3.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:12:37<3:39:13,  3.50s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.0011790990829468, 'learning_rate': 3.183898305084746e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:12:37<3:39:13,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:12:40<3:36:18,  3.46s/it]                                                       {'loss': 0.1909, 'grad_norm': 6.837434768676758, 'learning_rate': 3.183050847457627e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:12:40<3:36:18,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:12:43<3:36:26,  3.46s/it]                                                       {'loss': 0.0577, 'grad_norm': 6.172398567199707, 'learning_rate': 3.182203389830509e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:12:43<3:36:26,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:12:47<3:33:12,  3.41s/it]                                                       {'loss': 0.0235, 'grad_norm': 2.6474967002868652, 'learning_rate': 3.18135593220339e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:12:47<3:33:12,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:12:50<3:32:05,  3.39s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.069384574890137, 'learning_rate': 3.180508474576271e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:12:50<3:32:05,  3.39s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:12:53<3:31:36,  3.38s/it]                                                       {'loss': 0.0571, 'grad_norm': 3.211655378341675, 'learning_rate': 3.1796610169491524e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:12:53<3:31:36,  3.38s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:12:57<3:40:22,  3.53s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4145389199256897, 'learning_rate': 3.178813559322034e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:12:57<3:40:22,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:13:01<3:38:31,  3.50s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.11845959722995758, 'learning_rate': 3.177966101694915e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:13:01<3:38:31,  3.50s/it][2025-10-20 17:42:47,630] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:13:06<4:20:17,  4.17s/it]                                                       {'loss': 0.1291, 'grad_norm': 9.017894744873047, 'learning_rate': 3.177118644067797e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:13:06<4:20:17,  4.17s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:13:10<4:04:44,  3.92s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.26290586590766907, 'learning_rate': 3.176271186440678e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:13:10<4:04:44,  3.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:13:13<3:54:34,  3.76s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4532988369464874, 'learning_rate': 3.1754237288135594e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:13:13<3:54:34,  3.76s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:13:17<4:05:02,  3.92s/it]                                                       {'loss': 0.0289, 'grad_norm': 3.046499729156494, 'learning_rate': 3.1745762711864405e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:13:17<4:05:02,  3.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:13:21<3:54:43,  3.76s/it]                                                       {'loss': 0.0878, 'grad_norm': 6.278093338012695, 'learning_rate': 3.173728813559322e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:13:21<3:54:43,  3.76s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:13:24<3:46:51,  3.64s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.7715950012207031, 'learning_rate': 3.1728813559322034e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:13:24<3:46:51,  3.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:13:28<3:43:34,  3.58s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.8193907141685486, 'learning_rate': 3.172033898305085e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:13:28<3:43:34,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:13:31<3:39:36,  3.52s/it]                                                       {'loss': 0.1013, 'grad_norm': 6.39936637878418, 'learning_rate': 3.1711864406779664e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:13:31<3:39:36,  3.52s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:13:34<3:38:05,  3.50s/it]                                                       {'loss': 0.0395, 'grad_norm': 4.582080841064453, 'learning_rate': 3.170338983050848e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:13:34<3:38:05,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:13:38<3:35:40,  3.46s/it]                                                       {'loss': 0.0996, 'grad_norm': 5.838047981262207, 'learning_rate': 3.169491525423729e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:13:38<3:35:40,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:13:42<3:47:23,  3.65s/it]                                                       {'loss': 0.0455, 'grad_norm': 4.413295269012451, 'learning_rate': 3.16864406779661e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:13:42<3:47:23,  3.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:13:45<3:43:37,  3.59s/it]                                                       {'loss': 0.0742, 'grad_norm': 2.6452620029449463, 'learning_rate': 3.1677966101694916e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:13:45<3:43:37,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:13:49<3:42:33,  3.57s/it]                                                       {'loss': 0.2695, 'grad_norm': 8.651114463806152, 'learning_rate': 3.166949152542373e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:13:49<3:42:33,  3.57s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:13:53<3:46:45,  3.64s/it]                                                       {'loss': 0.0371, 'grad_norm': 4.51194953918457, 'learning_rate': 3.1661016949152545e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:13:53<3:46:45,  3.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:13:56<3:43:37,  3.59s/it]                                                       {'loss': 0.0655, 'grad_norm': 4.823511600494385, 'learning_rate': 3.1652542372881356e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:13:56<3:43:37,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:14:00<3:39:50,  3.53s/it]                                                       {'loss': 0.0551, 'grad_norm': 5.024403095245361, 'learning_rate': 3.1644067796610174e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:14:00<3:39:50,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:14:03<3:36:37,  3.48s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014999057166278362, 'learning_rate': 3.1635593220338985e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:14:03<3:36:37,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:14:06<3:34:34,  3.45s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.2874078750610352, 'learning_rate': 3.16271186440678e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:14:06<3:34:34,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:14:10<3:33:30,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011643425561487675, 'learning_rate': 3.161864406779661e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:14:10<3:33:30,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:14:14<3:44:10,  3.61s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.3969684839248657, 'learning_rate': 3.1610169491525426e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:14:14<3:44:10,  3.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:14:17<3:42:16,  3.58s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2776688039302826, 'learning_rate': 3.160169491525424e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:14:17<3:42:16,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:14:21<3:37:36,  3.50s/it]                                                       {'loss': 0.0279, 'grad_norm': 2.439661741256714, 'learning_rate': 3.1593220338983055e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:14:21<3:37:36,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:14:24<3:34:57,  3.46s/it]                                                       {'loss': 0.0251, 'grad_norm': 3.1037893295288086, 'learning_rate': 3.158474576271187e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:14:24<3:34:57,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:14:27<3:34:47,  3.46s/it]                                                       {'loss': 0.0995, 'grad_norm': 7.529186725616455, 'learning_rate': 3.157627118644068e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:14:27<3:34:47,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:14:31<3:35:02,  3.46s/it]                                                       {'loss': 0.0478, 'grad_norm': 4.784100532531738, 'learning_rate': 3.156779661016949e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:14:31<3:35:02,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:14:34<3:36:37,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02511500008404255, 'learning_rate': 3.155932203389831e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:14:34<3:36:37,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:14:38<3:34:15,  3.45s/it]                                                       {'loss': 0.0709, 'grad_norm': 7.195022106170654, 'learning_rate': 3.155084745762712e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:14:38<3:34:15,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:14:41<3:32:18,  3.42s/it]                                                       {'loss': 0.0294, 'grad_norm': 4.862644672393799, 'learning_rate': 3.154237288135594e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:14:41<3:32:18,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:14:44<3:29:52,  3.38s/it]                                                       {'loss': 0.0506, 'grad_norm': 5.6741180419921875, 'learning_rate': 3.153389830508475e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:14:44<3:29:52,  3.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:14:48<3:31:49,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05757751315832138, 'learning_rate': 3.1525423728813566e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:14:48<3:31:49,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:14:51<3:30:58,  3.40s/it]                                                       {'loss': 0.0494, 'grad_norm': 5.192715167999268, 'learning_rate': 3.151694915254238e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:14:51<3:30:58,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:14:55<3:30:41,  3.40s/it]                                                       {'loss': 0.009, 'grad_norm': 1.4548704624176025, 'learning_rate': 3.150847457627118e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:14:55<3:30:41,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:14:58<3:30:34,  3.40s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.7742292284965515, 'learning_rate': 3.15e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:14:58<3:30:34,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:15:01<3:30:46,  3.40s/it]                                                       {'loss': 0.0397, 'grad_norm': 4.417909145355225, 'learning_rate': 3.149152542372881e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:15:01<3:30:46,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:15:05<3:30:33,  3.40s/it]                                                       {'loss': 0.1458, 'grad_norm': 9.280925750732422, 'learning_rate': 3.148305084745763e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:15:05<3:30:33,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:15:08<3:31:31,  3.42s/it]                                                       {'loss': 0.0442, 'grad_norm': 6.498476982116699, 'learning_rate': 3.147457627118644e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:15:08<3:31:31,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:15:12<3:34:14,  3.46s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.44908276200294495, 'learning_rate': 3.146610169491526e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:15:12<3:34:14,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:15:15<3:32:42,  3.44s/it]                                                       {'loss': 0.1117, 'grad_norm': 6.395294189453125, 'learning_rate': 3.145762711864407e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:15:15<3:32:42,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:15:19<3:31:04,  3.41s/it]                                                       {'loss': 0.1139, 'grad_norm': 7.272030353546143, 'learning_rate': 3.144915254237288e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:15:19<3:31:04,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:15:22<3:37:33,  3.52s/it]                                                       {'loss': 0.1086, 'grad_norm': 5.795100688934326, 'learning_rate': 3.144067796610169e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:15:22<3:37:33,  3.52s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:15:26<3:33:22,  3.45s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.0553256273269653, 'learning_rate': 3.143220338983051e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:15:26<3:33:22,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:15:29<3:31:10,  3.42s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.2991403639316559, 'learning_rate': 3.142372881355932e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:15:29<3:31:10,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:15:32<3:30:09,  3.40s/it]                                                       {'loss': 0.0758, 'grad_norm': 2.3272364139556885, 'learning_rate': 3.141525423728814e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:15:32<3:30:09,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:15:36<3:31:03,  3.42s/it]                                                       {'loss': 0.0586, 'grad_norm': 6.405643463134766, 'learning_rate': 3.140677966101695e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:15:36<3:31:03,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:15:39<3:31:55,  3.43s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.843672513961792, 'learning_rate': 3.139830508474577e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:15:39<3:31:55,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:15:43<3:35:43,  3.49s/it]                                                       {'loss': 0.1947, 'grad_norm': 7.5802836418151855, 'learning_rate': 3.1389830508474574e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:15:43<3:35:43,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:15:47<3:41:01,  3.58s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.255439519882202, 'learning_rate': 3.138135593220339e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:15:47<3:41:01,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:15:51<3:55:36,  3.82s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.3625651597976685, 'learning_rate': 3.13728813559322e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:15:51<3:55:36,  3.82s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:15:55<3:49:46,  3.73s/it]                                                       {'loss': 0.1003, 'grad_norm': 4.910127639770508, 'learning_rate': 3.136440677966102e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:15:55<3:49:46,  3.73s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:15:58<3:42:33,  3.61s/it]                                                       {'loss': 0.0332, 'grad_norm': 3.8747243881225586, 'learning_rate': 3.135593220338983e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:15:58<3:42:33,  3.61s/it][2025-10-20 17:45:44,906] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:16:04<4:22:07,  4.25s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.007665916346013546, 'learning_rate': 3.134745762711865e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:16:04<4:22:07,  4.25s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:16:07<4:05:46,  3.99s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5445403456687927, 'learning_rate': 3.133898305084746e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:16:07<4:05:46,  3.99s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:16:10<3:53:26,  3.79s/it]                                                       {'loss': 0.1948, 'grad_norm': 7.6687140464782715, 'learning_rate': 3.133050847457627e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:16:10<3:53:26,  3.79s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:16:14<3:46:19,  3.67s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.9060078859329224, 'learning_rate': 3.1322033898305084e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:16:14<3:46:19,  3.67s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:16:17<3:43:01,  3.62s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.4017379879951477, 'learning_rate': 3.1313559322033896e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:16:17<3:43:01,  3.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:16:21<3:40:52,  3.59s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.053512316197156906, 'learning_rate': 3.1305084745762714e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:16:21<3:40:52,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:16:25<3:46:35,  3.68s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4740169942378998, 'learning_rate': 3.1296610169491525e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:16:25<3:46:35,  3.68s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:16:28<3:42:37,  3.62s/it]                                                       {'loss': 0.0955, 'grad_norm': 6.2587480545043945, 'learning_rate': 3.128813559322034e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:16:28<3:42:37,  3.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:16:32<3:38:29,  3.55s/it]                                                       {'loss': 0.1806, 'grad_norm': 9.053471565246582, 'learning_rate': 3.1279661016949154e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:16:32<3:38:29,  3.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:16:35<3:35:22,  3.50s/it]                                                       {'loss': 0.1334, 'grad_norm': 7.334275722503662, 'learning_rate': 3.1271186440677966e-05, 'epoch': 0.39}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:16:35<3:35:22,  3.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:16:38<3:33:47,  3.48s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.6117353439331055, 'learning_rate': 3.126271186440678e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:16:38<3:33:47,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:16:42<3:32:14,  3.45s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.4141473174095154, 'learning_rate': 3.1254237288135595e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:16:42<3:32:14,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:16:45<3:31:56,  3.45s/it]                                                       {'loss': 0.0334, 'grad_norm': 3.297589063644409, 'learning_rate': 3.1245762711864406e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:16:45<3:31:56,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:16:49<3:30:46,  3.43s/it]                                                       {'loss': 0.0254, 'grad_norm': 1.9669042825698853, 'learning_rate': 3.1237288135593224e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:16:49<3:30:46,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:16:52<3:31:14,  3.44s/it]                                                       {'loss': 0.0294, 'grad_norm': 3.5348219871520996, 'learning_rate': 3.1228813559322036e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:16:52<3:31:14,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:16:55<3:30:16,  3.42s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.640418529510498, 'learning_rate': 3.1220338983050854e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:16:55<3:30:16,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:16:59<3:27:23,  3.38s/it]                                                       {'loss': 0.3307, 'grad_norm': 8.708480834960938, 'learning_rate': 3.1211864406779665e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:16:59<3:27:23,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:17:02<3:31:02,  3.44s/it]                                                       {'loss': 0.0136, 'grad_norm': 2.4256174564361572, 'learning_rate': 3.1203389830508476e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:17:02<3:31:02,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:17:06<3:30:51,  3.44s/it]                                                       {'loss': 0.1282, 'grad_norm': 6.201775074005127, 'learning_rate': 3.119491525423729e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:17:06<3:30:51,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:17:09<3:30:27,  3.43s/it]                                                       {'loss': 0.0421, 'grad_norm': 6.271431922912598, 'learning_rate': 3.1186440677966106e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:17:09<3:30:27,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:17:12<3:29:23,  3.41s/it]                                                       {'loss': 0.16, 'grad_norm': 10.40656566619873, 'learning_rate': 3.117796610169492e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:17:12<3:29:23,  3.41s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:17:16<3:26:54,  3.38s/it]                                                       {'loss': 0.0228, 'grad_norm': 1.988049030303955, 'learning_rate': 3.1169491525423735e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:17:16<3:26:54,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:17:19<3:28:42,  3.41s/it]                                                       {'loss': 0.2086, 'grad_norm': 9.793512344360352, 'learning_rate': 3.1161016949152546e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:17:19<3:28:42,  3.41s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:17:23<3:27:34,  3.39s/it]                                                       {'loss': 0.0572, 'grad_norm': 5.664907932281494, 'learning_rate': 3.115254237288136e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:17:23<3:27:34,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:17:26<3:25:51,  3.36s/it]                                                       {'loss': 0.0916, 'grad_norm': 5.67220401763916, 'learning_rate': 3.114406779661017e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:17:26<3:25:51,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:17:29<3:25:38,  3.36s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.11541667580604553, 'learning_rate': 3.113559322033898e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:17:29<3:25:38,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:17:33<3:25:41,  3.36s/it]                                                       {'loss': 0.0473, 'grad_norm': 6.776653289794922, 'learning_rate': 3.11271186440678e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:17:33<3:25:41,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:17:36<3:25:38,  3.36s/it]                                                       {'loss': 0.2796, 'grad_norm': 11.348127365112305, 'learning_rate': 3.111864406779661e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:17:36<3:25:38,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:17:41<3:56:37,  3.87s/it]                                                       {'loss': 0.1198, 'grad_norm': 7.971240997314453, 'learning_rate': 3.111016949152543e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:17:41<3:56:37,  3.87s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:17:44<3:46:11,  3.70s/it]                                                       {'loss': 0.0294, 'grad_norm': 3.2332680225372314, 'learning_rate': 3.110169491525424e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:17:44<3:46:11,  3.70s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:17:48<3:40:10,  3.60s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08330316096544266, 'learning_rate': 3.109322033898305e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:17:48<3:40:10,  3.60s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:17:51<3:35:44,  3.53s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.8286264538764954, 'learning_rate': 3.108474576271186e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:17:51<3:35:44,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:17:54<3:32:45,  3.48s/it]                                                       {'loss': 0.0616, 'grad_norm': 6.90716552734375, 'learning_rate': 3.107627118644068e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:17:54<3:32:45,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:17:58<3:31:42,  3.46s/it]                                                       {'loss': 0.047, 'grad_norm': 3.5013012886047363, 'learning_rate': 3.106779661016949e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:17:58<3:31:42,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:18:01<3:30:38,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1099904328584671, 'learning_rate': 3.105932203389831e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:18:01<3:30:38,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:18:05<3:29:31,  3.43s/it]                                                       {'loss': 0.1762, 'grad_norm': 7.410635471343994, 'learning_rate': 3.105084745762712e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:18:05<3:29:31,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:18:08<3:35:21,  3.53s/it]                                                       {'loss': 0.1246, 'grad_norm': 6.314932346343994, 'learning_rate': 3.104237288135594e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:18:08<3:35:21,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:18:12<3:41:46,  3.63s/it]                                                       {'loss': 0.1087, 'grad_norm': 5.278630256652832, 'learning_rate': 3.103389830508475e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:18:12<3:41:46,  3.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:18:16<3:37:23,  3.56s/it]                                                       {'loss': 0.008, 'grad_norm': 1.340380311012268, 'learning_rate': 3.102542372881356e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:18:16<3:37:23,  3.56s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:18:19<3:34:14,  3.51s/it]                                                       {'loss': 0.0822, 'grad_norm': 7.961539268493652, 'learning_rate': 3.101694915254237e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:18:19<3:34:14,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:18:22<3:31:01,  3.46s/it]                                                       {'loss': 0.0557, 'grad_norm': 5.71004581451416, 'learning_rate': 3.100847457627119e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:18:22<3:31:01,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:18:26<3:40:28,  3.62s/it]                                                       {'loss': 0.1035, 'grad_norm': 7.524392127990723, 'learning_rate': 3.1e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:18:26<3:40:28,  3.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:18:30<3:36:55,  3.56s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.7268176078796387, 'learning_rate': 3.099152542372882e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:18:30<3:36:55,  3.56s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:18:34<3:39:05,  3.60s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.8185247182846069, 'learning_rate': 3.098305084745763e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:18:34<3:39:05,  3.60s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:18:37<3:37:34,  3.57s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.23929622769355774, 'learning_rate': 3.097457627118644e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:18:37<3:37:34,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:18:40<3:34:47,  3.53s/it]                                                       {'loss': 0.336, 'grad_norm': 8.895223617553711, 'learning_rate': 3.096610169491525e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:18:40<3:34:47,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:18:44<3:33:52,  3.51s/it]                                                       {'loss': 0.0117, 'grad_norm': 2.1230273246765137, 'learning_rate': 3.0957627118644065e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:18:44<3:33:52,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:18:47<3:30:21,  3.46s/it]                                                       {'loss': 0.0215, 'grad_norm': 3.8336377143859863, 'learning_rate': 3.094915254237288e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:18:47<3:30:21,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:18:51<3:35:40,  3.54s/it]                                                       {'loss': 0.0035, 'grad_norm': 1.0268933773040771, 'learning_rate': 3.0940677966101694e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:18:51<3:35:40,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:18:55<3:39:49,  3.61s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.027161188423633575, 'learning_rate': 3.093220338983051e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:18:55<3:39:49,  3.61s/it][2025-10-20 17:48:41,770] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2350
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 5299f580-d919-4f2e-919c-1d9751656d84)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 17:48:51,823] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 5299f580-d919-4f2e-919c-1d9751656d84)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 17:48:51,823] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:19:11<7:38:23,  7.54s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3578815460205078, 'learning_rate': 3.092372881355932e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:19:11<7:38:23,  7.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:19:15<6:22:23,  6.29s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.6085956692695618, 'learning_rate': 3.091525423728814e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:19:15<6:22:23,  6.29s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:19:19<5:36:10,  5.53s/it]                                                       {'loss': 0.1014, 'grad_norm': 6.667243480682373, 'learning_rate': 3.0906779661016946e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:19:19<5:36:10,  5.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:19:22<5:00:14,  4.94s/it]                                                       {'loss': 0.1071, 'grad_norm': 7.031253814697266, 'learning_rate': 3.0898305084745764e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:19:22<5:00:14,  4.94s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:19:26<4:40:30,  4.62s/it]                                                       {'loss': 0.0868, 'grad_norm': 6.5189666748046875, 'learning_rate': 3.0889830508474575e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:19:26<4:40:30,  4.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:19:30<4:25:06,  4.37s/it]                                                       {'loss': 0.0908, 'grad_norm': 13.287612915039062, 'learning_rate': 3.088135593220339e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:19:30<4:25:06,  4.37s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:19:33<4:08:35,  4.09s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025911834090948105, 'learning_rate': 3.0872881355932205e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:19:33<4:08:35,  4.09s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:19:37<3:55:00,  3.87s/it]                                                       {'loss': 0.0132, 'grad_norm': 0.8427668809890747, 'learning_rate': 3.086440677966102e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:19:37<3:55:00,  3.87s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:19:40<3:47:44,  3.75s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2928447723388672, 'learning_rate': 3.0855932203389834e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:19:40<3:47:44,  3.75s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:19:44<3:44:29,  3.70s/it]                                                       {'loss': 0.1305, 'grad_norm': 6.5454607009887695, 'learning_rate': 3.0847457627118645e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:19:44<3:44:29,  3.70s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:19:47<3:46:16,  3.73s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07615698128938675, 'learning_rate': 3.0838983050847456e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:19:47<3:46:16,  3.73s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:19:51<3:40:13,  3.63s/it]                                                       {'loss': 0.0311, 'grad_norm': 1.9753360748291016, 'learning_rate': 3.0830508474576275e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:19:51<3:40:13,  3.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:19:54<3:37:47,  3.59s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06194986775517464, 'learning_rate': 3.0822033898305086e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:19:54<3:37:47,  3.59s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:19:58<3:35:03,  3.55s/it]                                                       {'loss': 0.0429, 'grad_norm': 3.6100497245788574, 'learning_rate': 3.0813559322033904e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:19:58<3:35:03,  3.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:20:01<3:35:59,  3.57s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.6959520578384399, 'learning_rate': 3.0805084745762715e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:20:01<3:35:59,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:20:05<3:33:23,  3.52s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.5881974697113037, 'learning_rate': 3.0796610169491526e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:20:05<3:33:23,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:20:08<3:31:07,  3.49s/it]                                                       {'loss': 0.0622, 'grad_norm': 4.9099249839782715, 'learning_rate': 3.078813559322034e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:20:08<3:31:07,  3.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:20:12<3:31:15,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06899754703044891, 'learning_rate': 3.077966101694915e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:20:12<3:31:15,  3.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:20:15<3:30:22,  3.48s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.9323437809944153, 'learning_rate': 3.077118644067797e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:20:15<3:30:22,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:20:19<3:28:08,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0527731329202652, 'learning_rate': 3.076271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:20:19<3:28:08,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:20:22<3:26:22,  3.41s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.7146565914154053, 'learning_rate': 3.0754237288135596e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:20:22<3:26:22,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:20:25<3:25:20,  3.40s/it]                                                       {'loss': 0.1919, 'grad_norm': 10.946432113647461, 'learning_rate': 3.074576271186441e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:20:25<3:25:20,  3.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:20:29<3:27:57,  3.44s/it]                                                       {'loss': 0.0325, 'grad_norm': 1.4765115976333618, 'learning_rate': 3.0737288135593226e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:20:29<3:27:57,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:20:32<3:26:57,  3.42s/it]                                                       {'loss': 0.0238, 'grad_norm': 2.774644136428833, 'learning_rate': 3.072881355932204e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:20:32<3:26:57,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:20:36<3:27:01,  3.43s/it]                                                       {'loss': 0.1137, 'grad_norm': 7.023934841156006, 'learning_rate': 3.072033898305085e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:20:36<3:27:01,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:20:39<3:27:28,  3.44s/it]                                                       {'loss': 0.0317, 'grad_norm': 2.8220293521881104, 'learning_rate': 3.071186440677966e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:20:39<3:27:28,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:20:43<3:27:25,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04236709699034691, 'learning_rate': 3.070338983050848e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:20:43<3:27:25,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:20:46<3:26:42,  3.42s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3152918219566345, 'learning_rate': 3.069491525423729e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:20:46<3:26:42,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:20:49<3:26:53,  3.43s/it]                                                       {'loss': 0.0514, 'grad_norm': 5.308884143829346, 'learning_rate': 3.068644067796611e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:20:49<3:26:53,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:20:53<3:26:37,  3.42s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.3117343187332153, 'learning_rate': 3.067796610169492e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:20:53<3:26:37,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:20:56<3:25:31,  3.41s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.423821359872818, 'learning_rate': 3.066949152542373e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:20:56<3:25:31,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:21:00<3:29:13,  3.47s/it]                                                       {'loss': 0.002, 'grad_norm': 0.22984111309051514, 'learning_rate': 3.066101694915254e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:21:00<3:29:13,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:21:03<3:27:09,  3.44s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.6908228397369385, 'learning_rate': 3.065254237288136e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:21:03<3:27:09,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:21:06<3:25:27,  3.41s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09847085922956467, 'learning_rate': 3.064406779661017e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:21:06<3:25:27,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:21:10<3:24:13,  3.39s/it]                                                       {'loss': 0.1114, 'grad_norm': 7.993301868438721, 'learning_rate': 3.063559322033899e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:21:10<3:24:13,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:21:13<3:24:52,  3.40s/it]                                                       {'loss': 0.0131, 'grad_norm': 1.7002452611923218, 'learning_rate': 3.06271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:21:13<3:24:52,  3.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:21:17<3:29:24,  3.48s/it]                                                       {'loss': 0.1818, 'grad_norm': 8.972420692443848, 'learning_rate': 3.061864406779661e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:21:17<3:29:24,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:21:20<3:29:42,  3.48s/it]                                                       {'loss': 0.1824, 'grad_norm': 7.2848005294799805, 'learning_rate': 3.061016949152543e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:21:20<3:29:42,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:21:24<3:27:24,  3.45s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.6163626313209534, 'learning_rate': 3.0601694915254233e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:21:24<3:27:24,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:21:27<3:28:42,  3.47s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.6391626000404358, 'learning_rate': 3.059322033898305e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:21:27<3:28:42,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:21:31<3:27:39,  3.45s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.1900726556777954, 'learning_rate': 3.058474576271186e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:21:31<3:27:39,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:21:34<3:26:43,  3.44s/it]                                                       {'loss': 0.106, 'grad_norm': 5.1181745529174805, 'learning_rate': 3.057627118644068e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:21:34<3:26:43,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:21:37<3:24:42,  3.41s/it]                                                       {'loss': 0.0274, 'grad_norm': 3.453110694885254, 'learning_rate': 3.056779661016949e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:21:37<3:24:42,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:21:41<3:26:47,  3.44s/it]                                                       {'loss': 0.0491, 'grad_norm': 3.05435848236084, 'learning_rate': 3.055932203389831e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:21:41<3:26:47,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:21:44<3:25:08,  3.41s/it]                                                       {'loss': 0.0162, 'grad_norm': 2.674793004989624, 'learning_rate': 3.055084745762712e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:21:44<3:25:08,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:21:48<3:31:18,  3.52s/it]                                                       {'loss': 0.0337, 'grad_norm': 2.680448055267334, 'learning_rate': 3.054237288135593e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:21:48<3:31:18,  3.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:21:52<3:31:59,  3.53s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7912884950637817, 'learning_rate': 3.0533898305084744e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:21:52<3:31:59,  3.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:21:55<3:30:00,  3.50s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.36119118332862854, 'learning_rate': 3.052542372881356e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:21:55<3:30:00,  3.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:21:58<3:28:07,  3.47s/it]                                                       {'loss': 0.0636, 'grad_norm': 2.466129779815674, 'learning_rate': 3.0516949152542373e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:21:58<3:28:07,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:22:02<3:26:39,  3.44s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.6841646432876587, 'learning_rate': 3.050847457627119e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:22:02<3:26:39,  3.44s/it][2025-10-20 17:51:48,816] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:22:07<4:05:51,  4.10s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2663094997406006, 'learning_rate': 3.05e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:22:07<4:05:51,  4.10s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:22:11<3:55:44,  3.93s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04278140142560005, 'learning_rate': 3.0491525423728817e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:22:11<3:55:44,  3.93s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:22:14<3:45:53,  3.77s/it]                                                       {'loss': 0.0791, 'grad_norm': 7.860545635223389, 'learning_rate': 3.048305084745763e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:22:14<3:45:53,  3.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:22:18<3:38:32,  3.65s/it]                                                       {'loss': 0.0199, 'grad_norm': 2.1655631065368652, 'learning_rate': 3.0474576271186443e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:22:18<3:38:32,  3.65s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:22:21<3:33:52,  3.57s/it]                                                       {'loss': 0.0677, 'grad_norm': 5.996722221374512, 'learning_rate': 3.0466101694915255e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:22:21<3:33:52,  3.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:22:25<3:30:51,  3.52s/it]                                                       {'loss': 0.1863, 'grad_norm': 8.818357467651367, 'learning_rate': 3.0457627118644066e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:22:25<3:30:51,  3.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:22:28<3:28:46,  3.49s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.20312076807022095, 'learning_rate': 3.0449152542372884e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:22:28<3:28:46,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:22:31<3:26:49,  3.45s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.43715327978134155, 'learning_rate': 3.0440677966101695e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:22:31<3:26:49,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:22:35<3:24:13,  3.41s/it]                                                       {'loss': 0.0556, 'grad_norm': 6.283529758453369, 'learning_rate': 3.043220338983051e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:22:35<3:24:13,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:22:38<3:26:20,  3.45s/it]                                                       {'loss': 0.0953, 'grad_norm': 4.927466869354248, 'learning_rate': 3.042372881355932e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:22:38<3:26:20,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:22:42<3:25:29,  3.44s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09260687977075577, 'learning_rate': 3.041525423728814e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:22:42<3:25:29,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:22:45<3:27:30,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.00916225928813219, 'learning_rate': 3.0406779661016947e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:22:45<3:27:30,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:22:49<3:26:32,  3.45s/it]                                                       {'loss': 0.09, 'grad_norm': 4.821789741516113, 'learning_rate': 3.0398305084745765e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:22:49<3:26:32,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:22:52<3:25:04,  3.43s/it]                                                       {'loss': 0.137, 'grad_norm': 6.374968528747559, 'learning_rate': 3.0389830508474577e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:22:52<3:25:04,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:22:55<3:24:55,  3.43s/it]                                                       {'loss': 0.1371, 'grad_norm': 5.9065093994140625, 'learning_rate': 3.038135593220339e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:22:55<3:24:55,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:22:59<3:24:00,  3.42s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.872148334980011, 'learning_rate': 3.0372881355932203e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:22:59<3:24:00,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:23:02<3:24:40,  3.43s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.4730505645275116, 'learning_rate': 3.036440677966102e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:23:02<3:24:40,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:23:06<3:23:46,  3.41s/it]                                                       {'loss': 0.1849, 'grad_norm': 8.88474178314209, 'learning_rate': 3.0355932203389832e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:23:06<3:23:46,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:23:09<3:24:39,  3.43s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.2306628227233887, 'learning_rate': 3.0347457627118647e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:23:09<3:24:39,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:23:13<3:31:18,  3.54s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.6291553378105164, 'learning_rate': 3.0338983050847458e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:23:13<3:31:18,  3.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:23:16<3:29:53,  3.52s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.9596993923187256, 'learning_rate': 3.0330508474576276e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:23:16<3:29:53,  3.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:23:20<3:27:54,  3.49s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.0427989959716797, 'learning_rate': 3.0322033898305087e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:23:20<3:27:54,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:23:23<3:25:50,  3.45s/it]                                                       {'loss': 0.1141, 'grad_norm': 4.573727607727051, 'learning_rate': 3.0313559322033902e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:23:23<3:25:50,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:23:26<3:23:36,  3.42s/it]                                                       {'loss': 0.1957, 'grad_norm': 10.061593055725098, 'learning_rate': 3.0305084745762713e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:23:26<3:23:36,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:23:30<3:26:56,  3.47s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.26172786951065063, 'learning_rate': 3.0296610169491528e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:23:30<3:26:56,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:23:33<3:23:58,  3.42s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.9869422912597656, 'learning_rate': 3.028813559322034e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:23:33<3:23:58,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:23:37<3:24:28,  3.43s/it]                                                       {'loss': 0.004, 'grad_norm': 0.7588371634483337, 'learning_rate': 3.027966101694915e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:23:37<3:24:28,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:23:40<3:27:31,  3.49s/it]                                                       {'loss': 0.0777, 'grad_norm': 5.8672776222229, 'learning_rate': 3.027118644067797e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:23:40<3:27:31,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:23:44<3:27:30,  3.49s/it]                                                       {'loss': 0.0313, 'grad_norm': 5.363853931427002, 'learning_rate': 3.026271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:23:44<3:27:30,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:23:47<3:28:55,  3.51s/it]                                                       {'loss': 0.017, 'grad_norm': 2.341413974761963, 'learning_rate': 3.0254237288135594e-05, 'epoch': 0.41}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:23:47<3:28:55,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:23:51<3:30:02,  3.53s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011744664050638676, 'learning_rate': 3.0245762711864406e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:23:51<3:30:02,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:23:54<3:26:04,  3.47s/it]                                                       {'loss': 0.0369, 'grad_norm': 5.01372766494751, 'learning_rate': 3.0237288135593224e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:23:54<3:26:04,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:23:58<3:24:44,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.029468558728694916, 'learning_rate': 3.0228813559322035e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:23:58<3:24:44,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:24:01<3:30:28,  3.54s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.49359792470932007, 'learning_rate': 3.022033898305085e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:24:02<3:30:28,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:24:05<3:27:53,  3.50s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.486024856567383, 'learning_rate': 3.021186440677966e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:24:05<3:27:53,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:24:08<3:25:14,  3.46s/it]                                                       {'loss': 0.0292, 'grad_norm': 1.9273048639297485, 'learning_rate': 3.0203389830508476e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:24:08<3:25:14,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:24:12<3:23:39,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09166880697011948, 'learning_rate': 3.0194915254237287e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:24:12<3:23:39,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:24:15<3:23:25,  3.43s/it]                                                       {'loss': 0.0395, 'grad_norm': 3.7267487049102783, 'learning_rate': 3.0186440677966105e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:24:15<3:23:25,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:24:19<3:30:26,  3.55s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.7266626954078674, 'learning_rate': 3.0177966101694916e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:24:19<3:30:26,  3.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:24:22<3:27:16,  3.49s/it]                                                       {'loss': 0.0514, 'grad_norm': 4.718911170959473, 'learning_rate': 3.016949152542373e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:24:22<3:27:16,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:24:26<3:32:38,  3.58s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.9177891612052917, 'learning_rate': 3.0161016949152542e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:24:26<3:32:38,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:24:29<3:27:45,  3.50s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.7708508968353271, 'learning_rate': 3.015254237288136e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:24:29<3:27:45,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:24:33<3:25:57,  3.47s/it]                                                       {'loss': 0.0153, 'grad_norm': 1.877099633216858, 'learning_rate': 3.014406779661017e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:24:33<3:25:57,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:24:36<3:22:40,  3.42s/it]                                                       {'loss': 0.1655, 'grad_norm': 7.591342926025391, 'learning_rate': 3.0135593220338986e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:24:36<3:22:40,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:24:40<3:25:15,  3.46s/it]                                                       {'loss': 0.1713, 'grad_norm': 7.96370267868042, 'learning_rate': 3.0127118644067798e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:24:40<3:25:15,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:24:43<3:23:31,  3.44s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.9538611769676208, 'learning_rate': 3.0118644067796616e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:24:43<3:23:31,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:24:46<3:23:25,  3.44s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.24928006529808044, 'learning_rate': 3.0110169491525424e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:24:46<3:23:25,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:24:50<3:28:36,  3.52s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0421471893787384, 'learning_rate': 3.0101694915254235e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:24:50<3:28:36,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:24:54<3:25:42,  3.48s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.7319858074188232, 'learning_rate': 3.0093220338983053e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:24:54<3:25:42,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:24:57<3:24:08,  3.45s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.8299480676651, 'learning_rate': 3.0084745762711864e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:24:57<3:24:08,  3.45s/it][2025-10-20 17:54:43,901] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:25:03<4:03:05,  4.11s/it]                                                       {'loss': 0.0271, 'grad_norm': 3.607229709625244, 'learning_rate': 3.007627118644068e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:25:03<4:03:05,  4.11s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:25:06<3:51:24,  3.91s/it]                                                       {'loss': 0.0298, 'grad_norm': 2.5463762283325195, 'learning_rate': 3.006779661016949e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:25:06<3:51:24,  3.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:25:10<3:45:26,  3.81s/it]                                                       {'loss': 0.1496, 'grad_norm': 6.097400188446045, 'learning_rate': 3.0059322033898308e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:25:10<3:45:26,  3.81s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:25:13<3:36:43,  3.67s/it]                                                       {'loss': 0.0227, 'grad_norm': 3.6166388988494873, 'learning_rate': 3.005084745762712e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:25:13<3:36:43,  3.67s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:25:16<3:31:19,  3.58s/it]                                                       {'loss': 0.132, 'grad_norm': 4.2635087966918945, 'learning_rate': 3.0042372881355934e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:25:16<3:31:19,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:25:20<3:27:17,  3.51s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3113154470920563, 'learning_rate': 3.0033898305084745e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:25:20<3:27:17,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:25:23<3:26:20,  3.49s/it]                                                       {'loss': 0.1083, 'grad_norm': 5.687894821166992, 'learning_rate': 3.0025423728813564e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:25:23<3:26:20,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:25:26<3:24:06,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.0070114098489284515, 'learning_rate': 3.001694915254237e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:25:26<3:24:06,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:25:30<3:30:40,  3.57s/it]                                                       {'loss': 0.0208, 'grad_norm': 2.2795679569244385, 'learning_rate': 3.000847457627119e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:25:30<3:30:40,  3.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:25:34<3:26:51,  3.51s/it]                                                       {'loss': 0.065, 'grad_norm': 5.692142963409424, 'learning_rate': 3e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:25:34<3:26:51,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:25:37<3:29:38,  3.55s/it]                                                       {'loss': 0.0497, 'grad_norm': 3.3860981464385986, 'learning_rate': 2.9991525423728815e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:25:37<3:29:38,  3.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:25:41<3:26:04,  3.49s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11281034350395203, 'learning_rate': 2.9983050847457627e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:25:41<3:26:04,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:25:44<3:24:01,  3.46s/it]                                                       {'loss': 0.0406, 'grad_norm': 4.845109462738037, 'learning_rate': 2.9974576271186445e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:25:44<3:24:01,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:25:48<3:24:14,  3.47s/it]                                                       {'loss': 0.2168, 'grad_norm': 9.273521423339844, 'learning_rate': 2.9966101694915256e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:25:48<3:24:14,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:25:51<3:30:49,  3.58s/it]                                                       {'loss': 0.0268, 'grad_norm': 4.865237712860107, 'learning_rate': 2.995762711864407e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:25:51<3:30:49,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:25:55<3:28:47,  3.54s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.465303659439087, 'learning_rate': 2.9949152542372882e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:25:55<3:28:47,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:25:58<3:24:07,  3.47s/it]                                                       {'loss': 0.0452, 'grad_norm': 4.8661322593688965, 'learning_rate': 2.99406779661017e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:25:58<3:24:07,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:26:01<3:22:05,  3.43s/it]                                                       {'loss': 0.0305, 'grad_norm': 1.8696208000183105, 'learning_rate': 2.993220338983051e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:26:01<3:22:05,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:26:05<3:19:16,  3.39s/it]                                                       {'loss': 0.0557, 'grad_norm': 7.079464912414551, 'learning_rate': 2.992372881355932e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:26:05<3:19:16,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:26:08<3:20:09,  3.40s/it]                                                       {'loss': 0.0813, 'grad_norm': 6.295257091522217, 'learning_rate': 2.9915254237288137e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:26:08<3:20:09,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:26:12<3:19:53,  3.40s/it]                                                       {'loss': 0.0686, 'grad_norm': 6.0123820304870605, 'learning_rate': 2.990677966101695e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:26:12<3:19:53,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:26:15<3:24:05,  3.47s/it]                                                       {'loss': 0.268, 'grad_norm': 15.614998817443848, 'learning_rate': 2.9898305084745763e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:26:15<3:24:05,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:26:19<3:21:17,  3.42s/it]                                                       {'loss': 0.1147, 'grad_norm': 7.593319416046143, 'learning_rate': 2.9889830508474575e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:26:19<3:21:17,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:26:22<3:20:00,  3.40s/it]                                                       {'loss': 0.1411, 'grad_norm': 5.623615264892578, 'learning_rate': 2.9881355932203393e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:26:22<3:20:00,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:26:25<3:19:20,  3.39s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.7973846793174744, 'learning_rate': 2.9872881355932204e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:26:25<3:19:20,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:26:29<3:19:25,  3.40s/it]                                                       {'loss': 0.1103, 'grad_norm': 5.178687572479248, 'learning_rate': 2.986440677966102e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:26:29<3:19:25,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:26:32<3:18:47,  3.39s/it]                                                       {'loss': 0.0633, 'grad_norm': 5.395596504211426, 'learning_rate': 2.985593220338983e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:26:32<3:18:47,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:26:35<3:19:28,  3.40s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.4557045698165894, 'learning_rate': 2.9847457627118648e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:26:35<3:19:28,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:26:39<3:19:36,  3.40s/it]                                                       {'loss': 0.053, 'grad_norm': 5.948094367980957, 'learning_rate': 2.983898305084746e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:26:39<3:19:36,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:26:42<3:20:44,  3.42s/it]                                                       {'loss': 0.0, 'grad_norm': 0.004575746599584818, 'learning_rate': 2.9830508474576274e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:26:42<3:20:44,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:26:46<3:18:57,  3.39s/it]                                                       {'loss': 0.0406, 'grad_norm': 5.872481822967529, 'learning_rate': 2.9822033898305085e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:26:46<3:18:57,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:26:49<3:17:49,  3.37s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3447158634662628, 'learning_rate': 2.98135593220339e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:26:49<3:17:49,  3.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:26:53<3:26:48,  3.53s/it]                                                       {'loss': 0.0589, 'grad_norm': 4.437185764312744, 'learning_rate': 2.980508474576271e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:26:53<3:26:48,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:26:57<3:31:39,  3.61s/it]                                                       {'loss': 0.2202, 'grad_norm': 8.101961135864258, 'learning_rate': 2.979661016949153e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:26:57<3:31:39,  3.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:27:00<3:29:54,  3.58s/it]                                                       {'loss': 0.0458, 'grad_norm': 3.9583072662353516, 'learning_rate': 2.978813559322034e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:27:00<3:29:54,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:27:04<3:26:41,  3.53s/it]                                                       {'loss': 0.0361, 'grad_norm': 4.034192085266113, 'learning_rate': 2.9779661016949155e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:27:04<3:26:41,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:27:07<3:25:15,  3.51s/it]                                                       {'loss': 0.0429, 'grad_norm': 3.3152427673339844, 'learning_rate': 2.9771186440677966e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:27:07<3:25:15,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:27:11<3:24:15,  3.49s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.02310906909406185, 'learning_rate': 2.9762711864406785e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:27:11<3:24:15,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:27:14<3:21:28,  3.44s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.804703414440155, 'learning_rate': 2.9754237288135596e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:27:14<3:21:28,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:27:17<3:22:23,  3.46s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.105011463165283, 'learning_rate': 2.9745762711864407e-05, 'epoch': 0.41}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:27:17<3:22:23,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:27:21<3:20:04,  3.42s/it]                                                       {'loss': 0.011, 'grad_norm': 1.4408773183822632, 'learning_rate': 2.9737288135593222e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:27:21<3:20:04,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:27:24<3:19:40,  3.42s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.0580480098724365, 'learning_rate': 2.9728813559322033e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:27:24<3:19:40,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:27:27<3:18:28,  3.40s/it]                                                       {'loss': 0.2808, 'grad_norm': 9.484881401062012, 'learning_rate': 2.9720338983050848e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:27:27<3:18:28,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:27:31<3:18:07,  3.39s/it]                                                       {'loss': 0.2145, 'grad_norm': 9.554386138916016, 'learning_rate': 2.971186440677966e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:27:31<3:18:07,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:27:35<3:24:27,  3.50s/it]                                                       {'loss': 0.0604, 'grad_norm': 3.9434659481048584, 'learning_rate': 2.9703389830508477e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:27:35<3:24:27,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:27:38<3:29:45,  3.59s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.056918755173683167, 'learning_rate': 2.969491525423729e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:27:38<3:29:45,  3.59s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:27:42<3:27:33,  3.55s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.3957815170288086, 'learning_rate': 2.9686440677966103e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:27:42<3:27:33,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:27:46<3:31:28,  3.62s/it]                                                       {'loss': 0.0936, 'grad_norm': 5.761997699737549, 'learning_rate': 2.9677966101694914e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:27:46<3:31:28,  3.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:27:49<3:26:26,  3.54s/it]                                                       {'loss': 0.0487, 'grad_norm': 6.348818302154541, 'learning_rate': 2.9669491525423732e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:27:49<3:26:26,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:27:52<3:24:28,  3.51s/it]                                                       {'loss': 0.005, 'grad_norm': 1.2464654445648193, 'learning_rate': 2.9661016949152544e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:27:52<3:24:28,  3.51s/it][2025-10-20 17:57:39,372] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:27:58<4:03:53,  4.18s/it]                                                       {'loss': 0.081, 'grad_norm': 5.502964496612549, 'learning_rate': 2.965254237288136e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:27:58<4:03:53,  4.18s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:28:01<3:49:20,  3.93s/it]                                                       {'loss': 0.2846, 'grad_norm': 8.931023597717285, 'learning_rate': 2.964406779661017e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:28:01<3:49:20,  3.93s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:28:05<3:39:40,  3.77s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05998016521334648, 'learning_rate': 2.9635593220338988e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:28:05<3:39:40,  3.77s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:28:08<3:31:57,  3.64s/it]                                                       {'loss': 0.2462, 'grad_norm': 8.838168144226074, 'learning_rate': 2.9627118644067796e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:28:08<3:31:57,  3.64s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:28:12<3:28:32,  3.58s/it]                                                       {'loss': 0.0171, 'grad_norm': 1.416207194328308, 'learning_rate': 2.9618644067796614e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:28:12<3:28:32,  3.58s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:28:15<3:25:11,  3.52s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2633007764816284, 'learning_rate': 2.9610169491525425e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:28:15<3:25:11,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:28:19<3:23:59,  3.50s/it]                                                       {'loss': 0.0356, 'grad_norm': 2.280590534210205, 'learning_rate': 2.960169491525424e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:28:19<3:23:59,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:28:22<3:20:45,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02908615581691265, 'learning_rate': 2.959322033898305e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:28:22<3:20:45,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:28:25<3:20:16,  3.44s/it]                                                       {'loss': 0.0894, 'grad_norm': 5.576870441436768, 'learning_rate': 2.958474576271187e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:28:25<3:20:16,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:28:29<3:22:14,  3.48s/it]                                                       {'loss': 0.002, 'grad_norm': 0.34466585516929626, 'learning_rate': 2.957627118644068e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:28:29<3:22:14,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:28:33<3:28:21,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04820544272661209, 'learning_rate': 2.956779661016949e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:28:33<3:28:21,  3.58s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:28:36<3:24:30,  3.52s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.2556319832801819, 'learning_rate': 2.9559322033898306e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:28:36<3:24:30,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:28:40<3:26:45,  3.56s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.8843358755111694, 'learning_rate': 2.9550847457627118e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:28:40<3:26:45,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:28:43<3:24:13,  3.51s/it]                                                       {'loss': 0.089, 'grad_norm': 6.019047260284424, 'learning_rate': 2.9542372881355936e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:28:43<3:24:13,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:28:47<3:23:55,  3.51s/it]                                                       {'loss': 0.378, 'grad_norm': 9.695659637451172, 'learning_rate': 2.9533898305084743e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:28:47<3:23:55,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:28:50<3:21:38,  3.47s/it]                                                       {'loss': 0.1076, 'grad_norm': 6.382001876831055, 'learning_rate': 2.952542372881356e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:28:50<3:21:38,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:28:54<3:26:10,  3.55s/it]                                                       {'loss': 0.0822, 'grad_norm': 8.312453269958496, 'learning_rate': 2.9516949152542373e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:28:54<3:26:10,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:28:57<3:23:55,  3.51s/it]                                                       {'loss': 0.1715, 'grad_norm': 6.989037036895752, 'learning_rate': 2.9508474576271187e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:28:57<3:23:55,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:29:00<3:21:15,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0748777687549591, 'learning_rate': 2.95e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:29:00<3:21:15,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:29:04<3:19:34,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.032712966203689575, 'learning_rate': 2.9491525423728817e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:29:04<3:19:34,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:29:07<3:18:36,  3.43s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.4485915899276733, 'learning_rate': 2.9483050847457628e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:29:07<3:18:36,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:29:11<3:26:22,  3.56s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.0481842756271362, 'learning_rate': 2.9474576271186443e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:29:11<3:26:22,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:29:15<3:23:44,  3.52s/it]                                                       {'loss': 0.1423, 'grad_norm': 5.2412919998168945, 'learning_rate': 2.9466101694915254e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:29:15<3:23:44,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:29:18<3:20:18,  3.46s/it]                                                       {'loss': 0.0387, 'grad_norm': 4.228970050811768, 'learning_rate': 2.9457627118644072e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:29:18<3:20:18,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:29:21<3:19:57,  3.45s/it]                                                       {'loss': 0.0447, 'grad_norm': 4.203794002532959, 'learning_rate': 2.9449152542372883e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:29:21<3:19:57,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:29:25<3:29:53,  3.63s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.0174874067306519, 'learning_rate': 2.9440677966101698e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:29:25<3:29:53,  3.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:29:29<3:34:37,  3.71s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.372112512588501, 'learning_rate': 2.943220338983051e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:29:29<3:34:37,  3.71s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:29:33<3:30:44,  3.64s/it]                                                       {'loss': 0.1086, 'grad_norm': 4.4129767417907715, 'learning_rate': 2.9423728813559327e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:29:33<3:30:44,  3.64s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:29:36<3:25:11,  3.55s/it]                                                       {'loss': 0.0251, 'grad_norm': 3.180025100708008, 'learning_rate': 2.9415254237288135e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:29:36<3:25:11,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:29:40<3:24:49,  3.54s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.0720716714859009, 'learning_rate': 2.9406779661016953e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:29:40<3:24:49,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:29:43<3:23:10,  3.51s/it]                                                       {'loss': 0.0327, 'grad_norm': 2.9663429260253906, 'learning_rate': 2.9398305084745765e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:29:43<3:23:10,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:29:46<3:21:11,  3.48s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06954620778560638, 'learning_rate': 2.9389830508474576e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:29:46<3:21:11,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:29:50<3:20:32,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.10665599256753922, 'learning_rate': 2.938135593220339e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:29:50<3:20:32,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:29:53<3:18:33,  3.44s/it]                                                       {'loss': 0.1184, 'grad_norm': 7.731949806213379, 'learning_rate': 2.9372881355932202e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:29:53<3:18:33,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:29:57<3:17:54,  3.43s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.14968465268611908, 'learning_rate': 2.936440677966102e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:29:57<3:17:54,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:30:00<3:17:23,  3.42s/it]                                                       {'loss': 0.003, 'grad_norm': 0.6261356472969055, 'learning_rate': 2.935593220338983e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:30:00<3:17:23,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:30:03<3:16:28,  3.40s/it]                                                       {'loss': 0.0164, 'grad_norm': 2.1772234439849854, 'learning_rate': 2.9347457627118646e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:30:03<3:16:28,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:30:07<3:16:39,  3.41s/it]                                                       {'loss': 0.0292, 'grad_norm': 3.6761276721954346, 'learning_rate': 2.9338983050847457e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:30:07<3:16:39,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:30:10<3:15:25,  3.39s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.1171620637178421, 'learning_rate': 2.9330508474576275e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:30:10<3:15:25,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:30:14<3:16:35,  3.41s/it]                                                       {'loss': 0.1602, 'grad_norm': 6.80754280090332, 'learning_rate': 2.9322033898305083e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:30:14<3:16:35,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:30:17<3:15:44,  3.40s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.4898992776870728, 'learning_rate': 2.93135593220339e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:30:17<3:15:44,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:30:20<3:14:11,  3.37s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.15090397000312805, 'learning_rate': 2.9305084745762713e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:30:20<3:14:11,  3.37s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:30:24<3:14:17,  3.37s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.317863702774048, 'learning_rate': 2.9296610169491527e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:30:24<3:14:17,  3.37s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:30:27<3:14:39,  3.38s/it]                                                       {'loss': 0.1274, 'grad_norm': 7.753181457519531, 'learning_rate': 2.928813559322034e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:30:27<3:14:39,  3.38s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:30:30<3:14:32,  3.38s/it]                                                       {'loss': 0.112, 'grad_norm': 6.033720016479492, 'learning_rate': 2.9279661016949157e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:30:30<3:14:32,  3.38s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:30:34<3:16:37,  3.42s/it]                                                       {'loss': 0.0505, 'grad_norm': 2.494978189468384, 'learning_rate': 2.9271186440677968e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:30:34<3:16:37,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:30:37<3:16:32,  3.42s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.571004629135132, 'learning_rate': 2.9262711864406783e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:30:37<3:16:32,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:30:41<3:21:29,  3.50s/it]                                                       {'loss': 0.0755, 'grad_norm': 5.533506393432617, 'learning_rate': 2.9254237288135594e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:30:41<3:21:29,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:30:45<3:20:47,  3.49s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5777987837791443, 'learning_rate': 2.9245762711864412e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:30:45<3:20:47,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:30:48<3:22:53,  3.53s/it]                                                       {'loss': 0.1117, 'grad_norm': 4.700956344604492, 'learning_rate': 2.9237288135593223e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:30:48<3:22:53,  3.53s/it][2025-10-20 18:00:35,138] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:30:54<3:58:39,  4.15s/it]                                                       {'loss': 0.1297, 'grad_norm': 8.528467178344727, 'learning_rate': 2.9228813559322038e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:30:54<3:58:39,  4.15s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:30:57<3:45:56,  3.93s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11616869270801544, 'learning_rate': 2.922033898305085e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:30:57<3:45:56,  3.93s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:31:00<3:35:09,  3.75s/it]                                                       {'loss': 0.0508, 'grad_norm': 4.256832122802734, 'learning_rate': 2.921186440677966e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:31:00<3:35:09,  3.75s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:31:04<3:36:28,  3.77s/it]                                                       {'loss': 0.0823, 'grad_norm': 5.055516242980957, 'learning_rate': 2.9203389830508475e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:31:04<3:36:28,  3.77s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:31:08<3:28:21,  3.63s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.23157399892807007, 'learning_rate': 2.9194915254237286e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:31:08<3:28:21,  3.63s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:31:11<3:24:43,  3.57s/it]                                                       {'loss': 0.149, 'grad_norm': 8.128936767578125, 'learning_rate': 2.9186440677966104e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:31:11<3:24:43,  3.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:31:14<3:21:54,  3.52s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5485691428184509, 'learning_rate': 2.9177966101694916e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:31:14<3:21:54,  3.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:31:18<3:20:56,  3.50s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09713809192180634, 'learning_rate': 2.916949152542373e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:31:18<3:20:56,  3.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:31:21<3:19:09,  3.47s/it]                                                       {'loss': 0.1875, 'grad_norm': 7.60396671295166, 'learning_rate': 2.916101694915254e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:31:21<3:19:09,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:31:25<3:19:46,  3.48s/it]                                                       {'loss': 0.0619, 'grad_norm': 5.267253875732422, 'learning_rate': 2.915254237288136e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:31:25<3:19:46,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:31:28<3:19:23,  3.48s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4174814224243164, 'learning_rate': 2.914406779661017e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:31:28<3:19:23,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:31:32<3:18:20,  3.46s/it]                                                       {'loss': 0.1439, 'grad_norm': 6.618870258331299, 'learning_rate': 2.9135593220338986e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:31:32<3:18:20,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:31:35<3:15:13,  3.41s/it]                                                       {'loss': 0.1471, 'grad_norm': 7.332645893096924, 'learning_rate': 2.9127118644067797e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:31:35<3:15:13,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:31:39<3:18:08,  3.46s/it]                                                       {'loss': 0.022, 'grad_norm': 2.464164972305298, 'learning_rate': 2.911864406779661e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:31:39<3:18:08,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:31:42<3:16:35,  3.43s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.8071721196174622, 'learning_rate': 2.9110169491525423e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:31:42<3:16:35,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:31:45<3:15:11,  3.41s/it]                                                       {'loss': 0.1764, 'grad_norm': 6.988685607910156, 'learning_rate': 2.910169491525424e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:31:45<3:15:11,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:31:49<3:16:44,  3.44s/it]                                                       {'loss': 0.0106, 'grad_norm': 2.2390079498291016, 'learning_rate': 2.9093220338983052e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:31:49<3:16:44,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:31:52<3:20:18,  3.50s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.198645830154419, 'learning_rate': 2.9084745762711867e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:31:52<3:20:18,  3.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:31:56<3:19:44,  3.49s/it]                                                       {'loss': 0.1445, 'grad_norm': 8.590253829956055, 'learning_rate': 2.9076271186440678e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:31:56<3:19:44,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:31:59<3:18:14,  3.47s/it]                                                       {'loss': 0.0446, 'grad_norm': 3.9221739768981934, 'learning_rate': 2.9067796610169496e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:31:59<3:18:14,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:32:03<3:17:07,  3.45s/it]                                                       {'loss': 0.0108, 'grad_norm': 1.2681504487991333, 'learning_rate': 2.9059322033898308e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:32:03<3:17:07,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:32:06<3:15:47,  3.43s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5202028751373291, 'learning_rate': 2.9050847457627122e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:32:06<3:15:47,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:32:09<3:13:34,  3.39s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4646543264389038, 'learning_rate': 2.9042372881355934e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:32:09<3:13:34,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:32:13<3:13:49,  3.39s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19614830613136292, 'learning_rate': 2.9033898305084745e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:32:13<3:13:49,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:32:16<3:15:24,  3.42s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.4000041484832764, 'learning_rate': 2.902542372881356e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:32:16<3:15:24,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:32:20<3:13:34,  3.39s/it]                                                       {'loss': 0.1242, 'grad_norm': 8.459898948669434, 'learning_rate': 2.901694915254237e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:32:20<3:13:34,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:32:23<3:13:28,  3.39s/it]                                                       {'loss': 0.1582, 'grad_norm': 7.383028030395508, 'learning_rate': 2.900847457627119e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:32:23<3:13:28,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:32:26<3:13:55,  3.40s/it]                                                       {'loss': 0.0274, 'grad_norm': 4.473700046539307, 'learning_rate': 2.9e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:32:26<3:13:55,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:32:30<3:13:43,  3.40s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4916273355484009, 'learning_rate': 2.8991525423728815e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:32:30<3:13:43,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:32:33<3:14:34,  3.41s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.6450238227844238, 'learning_rate': 2.8983050847457626e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:32:33<3:14:34,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:32:37<3:16:52,  3.46s/it]                                                       {'loss': 0.0468, 'grad_norm': 5.536334991455078, 'learning_rate': 2.8974576271186444e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:32:37<3:16:52,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:32:41<3:21:53,  3.54s/it]                                                       {'loss': 0.1847, 'grad_norm': 8.928435325622559, 'learning_rate': 2.8966101694915255e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:32:41<3:21:53,  3.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:32:44<3:18:53,  3.49s/it]                                                       {'loss': 0.2263, 'grad_norm': 7.710210800170898, 'learning_rate': 2.895762711864407e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:32:44<3:18:53,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:32:47<3:16:14,  3.45s/it]                                                       {'loss': 0.0941, 'grad_norm': 6.93989372253418, 'learning_rate': 2.894915254237288e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:32:47<3:16:14,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:32:51<3:16:02,  3.44s/it]                                                       {'loss': 0.1633, 'grad_norm': 4.697310924530029, 'learning_rate': 2.89406779661017e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:32:51<3:16:02,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:32:54<3:14:21,  3.42s/it]                                                       {'loss': 0.1744, 'grad_norm': 6.1374053955078125, 'learning_rate': 2.8932203389830507e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:32:54<3:14:21,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:32:57<3:12:50,  3.39s/it]                                                       {'loss': 0.0416, 'grad_norm': 4.392693042755127, 'learning_rate': 2.8923728813559325e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:32:57<3:12:50,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:33:01<3:21:55,  3.55s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.021027296781539917, 'learning_rate': 2.8915254237288137e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:33:01<3:21:55,  3.55s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:33:05<3:18:51,  3.50s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3243710994720459, 'learning_rate': 2.890677966101695e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:33:05<3:18:51,  3.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:33:08<3:17:42,  3.48s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.4406919479370117, 'learning_rate': 2.8898305084745763e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:33:08<3:17:42,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:33:11<3:15:19,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.5031925439834595, 'learning_rate': 2.888983050847458e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:33:12<3:15:19,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:33:15<3:14:13,  3.42s/it]                                                       {'loss': 0.0639, 'grad_norm': 7.467976093292236, 'learning_rate': 2.8881355932203392e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:33:15<3:14:13,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:33:18<3:13:53,  3.41s/it]                                                       {'loss': 0.0111, 'grad_norm': 2.1043484210968018, 'learning_rate': 2.8872881355932203e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:33:18<3:13:53,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:33:22<3:12:34,  3.39s/it]                                                       {'loss': 0.0181, 'grad_norm': 2.8551814556121826, 'learning_rate': 2.8864406779661018e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:33:22<3:12:34,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:33:25<3:13:31,  3.41s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19040516018867493, 'learning_rate': 2.885593220338983e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:33:25<3:13:31,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:33:29<3:15:14,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07381205260753632, 'learning_rate': 2.8847457627118647e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:33:29<3:15:14,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:33:32<3:17:56,  3.49s/it]                                                       {'loss': 0.0611, 'grad_norm': 4.237929821014404, 'learning_rate': 2.8838983050847455e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:33:32<3:17:56,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:33:36<3:15:14,  3.44s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.057124264538288116, 'learning_rate': 2.8830508474576273e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:33:36<3:15:14,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:33:39<3:14:41,  3.43s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.26496657729148865, 'learning_rate': 2.8822033898305085e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:33:39<3:14:41,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:33:42<3:12:40,  3.40s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4345375597476959, 'learning_rate': 2.88135593220339e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:33:42<3:12:40,  3.40s/it][2025-10-20 18:03:29,248] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:33:48<3:56:13,  4.17s/it]                                                       {'loss': 0.1599, 'grad_norm': 6.772718906402588, 'learning_rate': 2.880508474576271e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:33:48<3:56:13,  4.17s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:33:52<3:41:32,  3.91s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.9749036431312561, 'learning_rate': 2.879661016949153e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:33:52<3:41:32,  3.91s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:33:55<3:31:46,  3.74s/it]                                                       {'loss': 0.0601, 'grad_norm': 4.05329704284668, 'learning_rate': 2.878813559322034e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:33:55<3:31:46,  3.74s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:33:58<3:25:53,  3.64s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.0321934223175049, 'learning_rate': 2.8779661016949155e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:33:58<3:25:53,  3.64s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:34:02<3:22:29,  3.58s/it]                                                       {'loss': 0.0662, 'grad_norm': 2.6323764324188232, 'learning_rate': 2.8771186440677966e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:34:02<3:22:29,  3.58s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:34:05<3:18:32,  3.51s/it]                                                       {'loss': 0.0201, 'grad_norm': 1.4836801290512085, 'learning_rate': 2.8762711864406784e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:34:05<3:18:32,  3.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:34:08<3:16:12,  3.47s/it]                                                       {'loss': 0.0571, 'grad_norm': 6.4316534996032715, 'learning_rate': 2.8754237288135595e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:34:08<3:16:12,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:34:12<3:15:07,  3.45s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.9027106761932373, 'learning_rate': 2.874576271186441e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:34:12<3:15:07,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:34:15<3:13:53,  3.43s/it]                                                       {'loss': 0.0261, 'grad_norm': 4.46414041519165, 'learning_rate': 2.873728813559322e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:34:15<3:13:53,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:34:19<3:13:10,  3.42s/it]                                                       {'loss': 0.0894, 'grad_norm': 5.948278427124023, 'learning_rate': 2.8728813559322036e-05, 'epoch': 0.43}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:34:19<3:13:10,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:34:22<3:13:46,  3.43s/it]                                                       {'loss': 0.1186, 'grad_norm': 4.809112071990967, 'learning_rate': 2.8720338983050847e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:34:22<3:13:46,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:34:25<3:12:00,  3.40s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0008404863183386624, 'learning_rate': 2.8711864406779665e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:34:25<3:12:00,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:34:29<3:18:11,  3.51s/it]                                                       {'loss': 0.058, 'grad_norm': 4.025457382202148, 'learning_rate': 2.8703389830508476e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:34:29<3:18:11,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:34:33<3:15:15,  3.46s/it]                                                       {'loss': 0.0218, 'grad_norm': 2.192408800125122, 'learning_rate': 2.8694915254237288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:34:33<3:15:15,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:34:36<3:13:09,  3.42s/it]                                                       {'loss': 0.0245, 'grad_norm': 3.2829349040985107, 'learning_rate': 2.8686440677966102e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:34:36<3:13:09,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:34:39<3:14:02,  3.44s/it]                                                       {'loss': 0.2279, 'grad_norm': 6.608847141265869, 'learning_rate': 2.8677966101694914e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:34:39<3:14:02,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:34:43<3:12:41,  3.42s/it]                                                       {'loss': 0.0119, 'grad_norm': 1.891166090965271, 'learning_rate': 2.8669491525423732e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:34:43<3:12:41,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:34:46<3:13:08,  3.43s/it]                                                       {'loss': 0.0353, 'grad_norm': 6.593767166137695, 'learning_rate': 2.8661016949152543e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:34:46<3:13:08,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:34:50<3:15:52,  3.48s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.585723876953125, 'learning_rate': 2.8652542372881358e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:34:50<3:15:52,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:34:53<3:18:39,  3.53s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.76991605758667, 'learning_rate': 2.864406779661017e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:34:53<3:18:39,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:34:57<3:18:55,  3.53s/it]                                                       {'loss': 0.2188, 'grad_norm': 10.827914237976074, 'learning_rate': 2.8635593220338984e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:34:57<3:18:55,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:35:00<3:18:14,  3.52s/it]                                                       {'loss': 0.1238, 'grad_norm': 5.281207084655762, 'learning_rate': 2.8627118644067795e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:35:00<3:18:14,  3.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:35:04<3:15:27,  3.47s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.215300440788269, 'learning_rate': 2.8618644067796613e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:35:04<3:15:27,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:35:07<3:14:35,  3.46s/it]                                                       {'loss': 0.0225, 'grad_norm': 3.5686662197113037, 'learning_rate': 2.8610169491525424e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:35:07<3:14:35,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:35:11<3:15:19,  3.47s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3408550024032593, 'learning_rate': 2.860169491525424e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:35:11<3:15:19,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:35:14<3:16:48,  3.50s/it]                                                       {'loss': 0.1333, 'grad_norm': 9.716344833374023, 'learning_rate': 2.859322033898305e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:35:14<3:16:48,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:35:18<3:22:35,  3.60s/it]                                                       {'loss': 0.1352, 'grad_norm': 6.7611236572265625, 'learning_rate': 2.858474576271187e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:35:18<3:22:35,  3.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:35:21<3:17:32,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.015307393856346607, 'learning_rate': 2.857627118644068e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:35:21<3:17:32,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:35:25<3:15:09,  3.47s/it]                                                       {'loss': 0.0265, 'grad_norm': 3.6125025749206543, 'learning_rate': 2.8567796610169494e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:35:25<3:15:09,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:35:28<3:13:35,  3.45s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011465170420706272, 'learning_rate': 2.8559322033898306e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:35:28<3:13:35,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:35:32<3:11:47,  3.42s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.716754674911499, 'learning_rate': 2.8550847457627124e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:35:32<3:11:47,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:35:35<3:10:28,  3.39s/it]                                                       {'loss': 0.1716, 'grad_norm': 7.690454483032227, 'learning_rate': 2.854237288135593e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:35:35<3:10:28,  3.39s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:35:38<3:08:54,  3.37s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.18838615715503693, 'learning_rate': 2.853389830508475e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:35:38<3:08:54,  3.37s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:35:42<3:11:16,  3.41s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.46877551078796387, 'learning_rate': 2.852542372881356e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:35:42<3:11:16,  3.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:35:45<3:12:56,  3.44s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.339916467666626, 'learning_rate': 2.8516949152542372e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:35:45<3:12:56,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:35:49<3:26:33,  3.68s/it]                                                       {'loss': 0.0463, 'grad_norm': 2.558497428894043, 'learning_rate': 2.8508474576271187e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:35:49<3:26:33,  3.68s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:35:53<3:23:31,  3.63s/it]                                                       {'loss': 0.2007, 'grad_norm': 7.035552978515625, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:35:53<3:23:31,  3.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:35:56<3:20:31,  3.58s/it]                                                       {'loss': 0.0691, 'grad_norm': 3.4413671493530273, 'learning_rate': 2.8491525423728816e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:35:56<3:20:31,  3.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:36:00<3:17:58,  3.53s/it]                                                       {'loss': 0.1109, 'grad_norm': 5.593434810638428, 'learning_rate': 2.8483050847457628e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:36:00<3:17:58,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:36:03<3:19:22,  3.56s/it]                                                       {'loss': 0.1336, 'grad_norm': 7.870495796203613, 'learning_rate': 2.8474576271186442e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:36:03<3:19:22,  3.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:36:07<3:26:11,  3.68s/it]                                                       {'loss': 0.1487, 'grad_norm': 7.815771579742432, 'learning_rate': 2.8466101694915253e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:36:07<3:26:11,  3.68s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:36:11<3:20:51,  3.59s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.015366315841675, 'learning_rate': 2.845762711864407e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:36:11<3:20:51,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:36:14<3:17:23,  3.53s/it]                                                       {'loss': 0.022, 'grad_norm': 3.1307895183563232, 'learning_rate': 2.844915254237288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:36:14<3:17:23,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:36:18<3:13:43,  3.46s/it]                                                       {'loss': 0.1348, 'grad_norm': 7.814051151275635, 'learning_rate': 2.8440677966101698e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:36:18<3:13:43,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:36:21<3:13:12,  3.46s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.9108293056488037, 'learning_rate': 2.843220338983051e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:36:21<3:13:12,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:36:24<3:12:01,  3.44s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.0042893886566162, 'learning_rate': 2.8423728813559323e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:36:24<3:12:01,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:36:28<3:12:33,  3.45s/it]                                                       {'loss': 0.0401, 'grad_norm': 3.4935455322265625, 'learning_rate': 2.8415254237288135e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:36:28<3:12:33,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:36:31<3:10:02,  3.40s/it]                                                       {'loss': 0.2538, 'grad_norm': 9.23666000366211, 'learning_rate': 2.8406779661016953e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:36:31<3:10:02,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:36:35<3:11:13,  3.42s/it]                                                       {'loss': 0.0878, 'grad_norm': 6.608569145202637, 'learning_rate': 2.8398305084745764e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:36:35<3:11:13,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:36:38<3:10:18,  3.41s/it]                                                       {'loss': 0.0108, 'grad_norm': 1.275476336479187, 'learning_rate': 2.838983050847458e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:36:38<3:10:18,  3.41s/it][2025-10-20 18:06:24,936] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:36:44<3:46:14,  4.05s/it]                                                       {'loss': 0.0509, 'grad_norm': 6.405335426330566, 'learning_rate': 2.838135593220339e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:36:44<3:46:14,  4.05s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:36:47<3:37:20,  3.90s/it]                                                       {'loss': 0.0812, 'grad_norm': 6.391842365264893, 'learning_rate': 2.8372881355932208e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:36:47<3:37:20,  3.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:36:51<3:37:54,  3.91s/it]                                                       {'loss': 0.0582, 'grad_norm': 2.019350051879883, 'learning_rate': 2.836440677966102e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:36:51<3:37:54,  3.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:36:54<3:28:47,  3.74s/it]                                                       {'loss': 0.0313, 'grad_norm': 3.4349265098571777, 'learning_rate': 2.8355932203389834e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:36:54<3:28:47,  3.74s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:36:58<3:23:09,  3.64s/it]                                                       {'loss': 0.031, 'grad_norm': 3.537843704223633, 'learning_rate': 2.8347457627118645e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:36:58<3:23:09,  3.64s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:37:01<3:17:37,  3.55s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.5209974646568298, 'learning_rate': 2.8338983050847457e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:37:01<3:17:37,  3.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:37:05<3:24:58,  3.68s/it]                                                       {'loss': 0.1057, 'grad_norm': 5.3297529220581055, 'learning_rate': 2.833050847457627e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:37:05<3:24:58,  3.68s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:37:08<3:19:31,  3.58s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.8291031718254089, 'learning_rate': 2.8322033898305083e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:37:08<3:19:31,  3.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:37:12<3:24:01,  3.66s/it]                                                       {'loss': 0.0318, 'grad_norm': 1.7669260501861572, 'learning_rate': 2.83135593220339e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:37:12<3:24:01,  3.66s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:37:16<3:26:28,  3.71s/it]                                                       {'loss': 0.0244, 'grad_norm': 4.96673583984375, 'learning_rate': 2.8305084745762712e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:37:16<3:26:28,  3.71s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:37:19<3:21:17,  3.62s/it]                                                       {'loss': 0.093, 'grad_norm': 8.607284545898438, 'learning_rate': 2.8296610169491527e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:37:19<3:21:17,  3.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:37:23<3:17:37,  3.55s/it]                                                       {'loss': 0.0792, 'grad_norm': 6.772639751434326, 'learning_rate': 2.8288135593220338e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:37:23<3:17:37,  3.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:37:26<3:14:38,  3.50s/it]                                                       {'loss': 0.0858, 'grad_norm': 5.181438446044922, 'learning_rate': 2.8279661016949156e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:37:26<3:14:38,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:37:30<3:12:34,  3.46s/it]                                                       {'loss': 0.0174, 'grad_norm': 3.0941848754882812, 'learning_rate': 2.8271186440677967e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:37:30<3:12:34,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:37:33<3:14:38,  3.50s/it]                                                       {'loss': 0.041, 'grad_norm': 4.545270919799805, 'learning_rate': 2.8262711864406782e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:37:33<3:14:38,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:37:37<3:13:31,  3.48s/it]                                                       {'loss': 0.1235, 'grad_norm': 5.485610008239746, 'learning_rate': 2.8254237288135593e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:37:37<3:13:31,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:37:40<3:14:49,  3.51s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013713768683373928, 'learning_rate': 2.824576271186441e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:37:40<3:14:49,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:37:44<3:19:13,  3.59s/it]                                                       {'loss': 0.0473, 'grad_norm': 7.6870574951171875, 'learning_rate': 2.823728813559322e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:37:44<3:19:13,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:37:47<3:17:27,  3.56s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.3895645141601562, 'learning_rate': 2.8228813559322037e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:37:47<3:17:27,  3.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:37:51<3:13:49,  3.49s/it]                                                       {'loss': 0.1747, 'grad_norm': 5.240199565887451, 'learning_rate': 2.822033898305085e-05, 'epoch': 0.45}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:37:51<3:13:49,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:37:54<3:12:07,  3.46s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.74867582321167, 'learning_rate': 2.8211864406779663e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:37:54<3:12:07,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:37:58<3:11:48,  3.46s/it]                                                       {'loss': 0.0216, 'grad_norm': 1.9771074056625366, 'learning_rate': 2.8203389830508475e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:37:58<3:11:48,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:38:01<3:10:28,  3.44s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09851788729429245, 'learning_rate': 2.8194915254237293e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:38:01<3:10:28,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:38:04<3:10:15,  3.43s/it]                                                       {'loss': 0.0221, 'grad_norm': 1.9224718809127808, 'learning_rate': 2.8186440677966104e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:38:04<3:10:15,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:38:08<3:15:53,  3.53s/it]                                                       {'loss': 0.0997, 'grad_norm': 4.926687717437744, 'learning_rate': 2.817796610169492e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:38:08<3:15:53,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:38:12<3:12:30,  3.47s/it]                                                       {'loss': 0.0174, 'grad_norm': 1.2512575387954712, 'learning_rate': 2.816949152542373e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:38:12<3:12:30,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:38:15<3:13:02,  3.49s/it]                                                       {'loss': 0.0513, 'grad_norm': 4.240717887878418, 'learning_rate': 2.816101694915254e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:38:15<3:13:02,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:38:19<3:12:30,  3.48s/it]                                                       {'loss': 0.1201, 'grad_norm': 7.146389961242676, 'learning_rate': 2.815254237288136e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:38:19<3:12:30,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:38:22<3:10:38,  3.44s/it]                                                       {'loss': 0.1026, 'grad_norm': 6.779879570007324, 'learning_rate': 2.8144067796610167e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:38:22<3:10:38,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:38:25<3:11:58,  3.47s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.6004315614700317, 'learning_rate': 2.8135593220338985e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:38:26<3:11:58,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:38:29<3:13:43,  3.50s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.42900609970092773, 'learning_rate': 2.8127118644067796e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:38:29<3:13:43,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:38:32<3:12:11,  3.48s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.025743842124939, 'learning_rate': 2.811864406779661e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:38:32<3:12:11,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:38:36<3:10:37,  3.45s/it]                                                       {'loss': 0.0335, 'grad_norm': 3.730499267578125, 'learning_rate': 2.8110169491525422e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:38:36<3:10:37,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:38:39<3:08:37,  3.41s/it]                                                       {'loss': 0.5665, 'grad_norm': 11.824804306030273, 'learning_rate': 2.810169491525424e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:38:39<3:08:37,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:38:43<3:07:42,  3.40s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.12326676398515701, 'learning_rate': 2.8093220338983052e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:38:43<3:07:42,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:38:46<3:08:44,  3.42s/it]                                                       {'loss': 0.1364, 'grad_norm': 4.152377605438232, 'learning_rate': 2.8084745762711866e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:38:46<3:08:44,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:38:49<3:07:37,  3.40s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.5816115140914917, 'learning_rate': 2.8076271186440678e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:38:49<3:07:37,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:38:53<3:07:41,  3.40s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.6884058713912964, 'learning_rate': 2.8067796610169496e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:38:53<3:07:41,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:38:56<3:07:19,  3.39s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.092830777168274, 'learning_rate': 2.8059322033898307e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:38:56<3:07:19,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:38:59<3:06:26,  3.38s/it]                                                       {'loss': 0.0974, 'grad_norm': 6.203123092651367, 'learning_rate': 2.8050847457627122e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:38:59<3:06:26,  3.38s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:39:03<3:07:05,  3.39s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.15658913552761078, 'learning_rate': 2.8042372881355933e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:39:03<3:07:05,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:39:06<3:07:40,  3.40s/it]                                                       {'loss': 0.0382, 'grad_norm': 4.828789234161377, 'learning_rate': 2.8033898305084748e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:39:06<3:07:40,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:39:10<3:08:24,  3.42s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2556901276111603, 'learning_rate': 2.802542372881356e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:39:10<3:08:24,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:39:14<3:14:06,  3.52s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.006085515953600407, 'learning_rate': 2.8016949152542377e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:39:14<3:14:06,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:39:17<3:16:15,  3.56s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.8063907027244568, 'learning_rate': 2.8008474576271188e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:39:17<3:16:15,  3.56s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:39:21<3:14:22,  3.53s/it]                                                       {'loss': 0.1184, 'grad_norm': 8.201071739196777, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:39:21<3:14:22,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:39:24<3:13:46,  3.52s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.3053032159805298, 'learning_rate': 2.7991525423728814e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:39:24<3:13:46,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:39:28<3:11:18,  3.48s/it]                                                       {'loss': 0.0305, 'grad_norm': 1.3611611127853394, 'learning_rate': 2.7983050847457626e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:39:28<3:11:18,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:39:31<3:09:56,  3.45s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.9356179237365723, 'learning_rate': 2.7974576271186444e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:39:31<3:09:56,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:39:34<3:09:12,  3.44s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5876872539520264, 'learning_rate': 2.7966101694915255e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:39:34<3:09:12,  3.44s/it][2025-10-20 18:09:21,321] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:39:40<3:51:33,  4.21s/it]                                                       {'loss': 0.0514, 'grad_norm': 4.676191329956055, 'learning_rate': 2.795762711864407e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:39:40<3:51:33,  4.21s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:39:44<3:44:54,  4.09s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.18114051222801208, 'learning_rate': 2.794915254237288e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:39:44<3:44:54,  4.09s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:39:47<3:32:19,  3.86s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.7798984050750732, 'learning_rate': 2.7940677966101696e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:39:47<3:32:19,  3.86s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:39:51<3:25:45,  3.75s/it]                                                       {'loss': 0.1637, 'grad_norm': 5.5320539474487305, 'learning_rate': 2.7932203389830507e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:39:51<3:25:45,  3.75s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:39:54<3:22:18,  3.68s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03691421076655388, 'learning_rate': 2.7923728813559325e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:39:54<3:22:18,  3.68s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:39:58<3:17:23,  3.60s/it]                                                       {'loss': 0.1969, 'grad_norm': 14.756086349487305, 'learning_rate': 2.7915254237288136e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:39:58<3:17:23,  3.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:40:01<3:13:38,  3.53s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.6525313258171082, 'learning_rate': 2.790677966101695e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:40:01<3:13:38,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:40:05<3:19:52,  3.64s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2506987154483795, 'learning_rate': 2.7898305084745762e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:40:05<3:19:52,  3.64s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:40:09<3:19:04,  3.63s/it]                                                       {'loss': 0.0649, 'grad_norm': 5.383578300476074, 'learning_rate': 2.788983050847458e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:40:09<3:19:04,  3.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:40:12<3:16:13,  3.58s/it]                                                       {'loss': 0.06, 'grad_norm': 3.670058250427246, 'learning_rate': 2.788135593220339e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:40:12<3:16:13,  3.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:40:16<3:12:44,  3.52s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.30882054567337036, 'learning_rate': 2.7872881355932206e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:40:16<3:12:44,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:40:19<3:12:50,  3.52s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.8115841150283813, 'learning_rate': 2.7864406779661017e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:40:19<3:12:50,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:40:22<3:10:08,  3.47s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.214794397354126, 'learning_rate': 2.7855932203389835e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:40:22<3:10:08,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:40:26<3:09:17,  3.46s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3079063892364502, 'learning_rate': 2.7847457627118643e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:40:26<3:09:17,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:40:29<3:10:44,  3.48s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.71578049659729, 'learning_rate': 2.783898305084746e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:40:29<3:10:44,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:40:33<3:11:27,  3.50s/it]                                                       {'loss': 0.0977, 'grad_norm': 7.900557518005371, 'learning_rate': 2.7830508474576273e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:40:33<3:11:27,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:40:36<3:08:41,  3.45s/it]                                                       {'loss': 0.0145, 'grad_norm': 1.3440760374069214, 'learning_rate': 2.7822033898305087e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:40:36<3:08:41,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:40:40<3:06:21,  3.41s/it]                                                       {'loss': 0.0145, 'grad_norm': 2.111405611038208, 'learning_rate': 2.78135593220339e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:40:40<3:06:21,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:40:43<3:07:23,  3.43s/it]                                                       {'loss': 0.1717, 'grad_norm': 7.856103897094727, 'learning_rate': 2.780508474576271e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:40:43<3:07:23,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:40:47<3:10:35,  3.49s/it]                                                       {'loss': 0.0394, 'grad_norm': 4.118741512298584, 'learning_rate': 2.7796610169491528e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:40:47<3:10:35,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:40:50<3:09:16,  3.46s/it]                                                       {'loss': 0.0167, 'grad_norm': 2.150251865386963, 'learning_rate': 2.778813559322034e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:40:50<3:09:16,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:40:54<3:08:44,  3.45s/it]                                                       {'loss': 0.2653, 'grad_norm': 9.403905868530273, 'learning_rate': 2.7779661016949154e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:40:54<3:08:44,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:40:57<3:07:31,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.020767610520124435, 'learning_rate': 2.7771186440677965e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:40:57<3:07:31,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:41:00<3:06:43,  3.42s/it]                                                       {'loss': 0.0458, 'grad_norm': 4.415950775146484, 'learning_rate': 2.7762711864406783e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:41:00<3:06:43,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:41:04<3:08:01,  3.44s/it]                                                       {'loss': 0.0715, 'grad_norm': 6.0912861824035645, 'learning_rate': 2.775423728813559e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:41:04<3:08:01,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:41:07<3:08:14,  3.45s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.2351038157939911, 'learning_rate': 2.774576271186441e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:41:07<3:08:14,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:41:11<3:06:55,  3.43s/it]                                                       {'loss': 0.0395, 'grad_norm': 8.170788764953613, 'learning_rate': 2.773728813559322e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:41:11<3:06:55,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:41:14<3:06:00,  3.41s/it]                                                       {'loss': 0.0595, 'grad_norm': 6.0933837890625, 'learning_rate': 2.7728813559322035e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:41:14<3:06:00,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:41:18<3:06:44,  3.43s/it]                                                       {'loss': 0.051, 'grad_norm': 4.0369110107421875, 'learning_rate': 2.7720338983050847e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:41:18<3:06:44,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:41:21<3:05:53,  3.41s/it]                                                       {'loss': 0.002, 'grad_norm': 0.36198118329048157, 'learning_rate': 2.7711864406779665e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:41:21<3:05:53,  3.41s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:41:24<3:06:13,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05692315846681595, 'learning_rate': 2.7703389830508476e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:41:24<3:06:13,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:41:28<3:06:24,  3.42s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.8411210775375366, 'learning_rate': 2.769491525423729e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:41:28<3:06:24,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:41:31<3:05:34,  3.41s/it]                                                       {'loss': 0.3039, 'grad_norm': 10.03189754486084, 'learning_rate': 2.7686440677966102e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:41:31<3:05:34,  3.41s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:41:35<3:11:08,  3.51s/it]                                                       {'loss': 0.0119, 'grad_norm': 2.5465104579925537, 'learning_rate': 2.767796610169492e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:41:35<3:11:08,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:41:38<3:10:25,  3.50s/it]                                                       {'loss': 0.0146, 'grad_norm': 2.399667739868164, 'learning_rate': 2.766949152542373e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:41:38<3:10:25,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:41:42<3:14:03,  3.57s/it]                                                       {'loss': 0.0434, 'grad_norm': 2.833307981491089, 'learning_rate': 2.7661016949152546e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:41:42<3:14:03,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:41:46<3:11:47,  3.53s/it]                                                       {'loss': 0.0603, 'grad_norm': 5.997481346130371, 'learning_rate': 2.7652542372881357e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:41:46<3:11:47,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:41:49<3:10:09,  3.50s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.018162712454795837, 'learning_rate': 2.7644067796610172e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:41:49<3:10:09,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:41:52<3:10:31,  3.51s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.5285932421684265, 'learning_rate': 2.7635593220338983e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:41:52<3:10:31,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:41:56<3:08:09,  3.46s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.26508426666259766, 'learning_rate': 2.7627118644067794e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:41:56<3:08:09,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:41:59<3:08:38,  3.47s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.4555322229862213, 'learning_rate': 2.7618644067796612e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:41:59<3:08:38,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:42:03<3:05:39,  3.42s/it]                                                       {'loss': 0.0994, 'grad_norm': 7.071377754211426, 'learning_rate': 2.7610169491525424e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:42:03<3:05:39,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:42:06<3:04:38,  3.40s/it]                                                       {'loss': 0.0369, 'grad_norm': 3.342127799987793, 'learning_rate': 2.760169491525424e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:42:06<3:04:38,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:42:09<3:03:16,  3.38s/it]                                                       {'loss': 0.0209, 'grad_norm': 1.6409400701522827, 'learning_rate': 2.759322033898305e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:42:09<3:03:16,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:42:13<3:06:14,  3.43s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.8113373517990112, 'learning_rate': 2.7584745762711868e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:42:13<3:06:14,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:42:17<3:14:06,  3.58s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.3746445178985596, 'learning_rate': 2.757627118644068e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:42:17<3:14:06,  3.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:42:21<3:18:29,  3.66s/it]                                                       {'loss': 0.055, 'grad_norm': 5.007349491119385, 'learning_rate': 2.7567796610169494e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:42:21<3:18:29,  3.66s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:42:24<3:13:58,  3.58s/it]                                                       {'loss': 0.0821, 'grad_norm': 5.199699878692627, 'learning_rate': 2.7559322033898305e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:42:24<3:13:58,  3.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:42:27<3:10:27,  3.52s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5964972376823425, 'learning_rate': 2.755084745762712e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:42:27<3:10:27,  3.52s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:42:31<3:07:32,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06842987984418869, 'learning_rate': 2.754237288135593e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:42:31<3:07:32,  3.46s/it][2025-10-20 18:12:17,711] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2750
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 32927ede-5066-4922-8415-560d4ea8b8ce)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 18:12:27,857] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 32927ede-5066-4922-8415-560d4ea8b8ce)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 18:12:27,858] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:42:47<6:41:52,  7.42s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.017773643136024475, 'learning_rate': 2.753389830508475e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:42:47<6:41:52,  7.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:42:51<5:37:08,  6.23s/it]                                                       {'loss': 0.002, 'grad_norm': 0.24894411861896515, 'learning_rate': 2.752542372881356e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:42:51<5:37:08,  6.23s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:42:54<4:51:08,  5.38s/it]                                                       {'loss': 0.1571, 'grad_norm': 5.364330768585205, 'learning_rate': 2.7516949152542375e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:42:54<4:51:08,  5.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:42:58<4:26:30,  4.93s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04434140771627426, 'learning_rate': 2.7508474576271186e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:42:58<4:26:30,  4.93s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:43:02<4:04:01,  4.51s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4037501811981201, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:43:02<4:04:01,  4.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:43:05<3:49:50,  4.25s/it]                                                       {'loss': 0.0321, 'grad_norm': 3.9984219074249268, 'learning_rate': 2.7491525423728816e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:43:05<3:49:50,  4.25s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:43:09<3:35:27,  3.99s/it]                                                       {'loss': 0.048, 'grad_norm': 4.091411590576172, 'learning_rate': 2.748305084745763e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:43:09<3:35:27,  3.99s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:43:12<3:24:26,  3.78s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.4950823783874512, 'learning_rate': 2.747457627118644e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:43:12<3:24:26,  3.78s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:43:16<3:21:34,  3.73s/it]                                                       {'loss': 0.0559, 'grad_norm': 4.203418254852295, 'learning_rate': 2.746610169491526e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:43:16<3:21:34,  3.73s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:43:19<3:15:50,  3.63s/it]                                                       {'loss': 0.0926, 'grad_norm': 5.692009925842285, 'learning_rate': 2.7457627118644068e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:43:19<3:15:50,  3.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:43:22<3:13:47,  3.59s/it]                                                       {'loss': 0.1832, 'grad_norm': 7.331636905670166, 'learning_rate': 2.744915254237288e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:43:22<3:13:47,  3.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:43:26<3:10:28,  3.53s/it]                                                       {'loss': 0.2536, 'grad_norm': 9.349209785461426, 'learning_rate': 2.7440677966101697e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:43:26<3:10:28,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:43:29<3:07:11,  3.47s/it]                                                       {'loss': 0.1411, 'grad_norm': 6.931521892547607, 'learning_rate': 2.7432203389830508e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:43:29<3:07:11,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:43:33<3:08:02,  3.49s/it]                                                       {'loss': 0.0225, 'grad_norm': 2.9463367462158203, 'learning_rate': 2.7423728813559323e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:43:33<3:08:02,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:43:36<3:08:51,  3.50s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.4850861728191376, 'learning_rate': 2.7415254237288134e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:43:36<3:08:51,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:43:40<3:10:27,  3.53s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.046745482832193375, 'learning_rate': 2.7406779661016952e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:43:40<3:10:27,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:43:43<3:11:25,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.092664435505867, 'learning_rate': 2.7398305084745764e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:43:43<3:11:25,  3.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:43:47<3:08:26,  3.50s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.6118805408477783, 'learning_rate': 2.7389830508474578e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:43:47<3:08:26,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:43:50<3:08:42,  3.50s/it]                                                       {'loss': 0.1968, 'grad_norm': 6.230804443359375, 'learning_rate': 2.738135593220339e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:43:50<3:08:42,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:43:54<3:07:31,  3.48s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.778459072113037, 'learning_rate': 2.7372881355932208e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:43:54<3:07:31,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:43:57<3:07:09,  3.48s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.7048931121826172, 'learning_rate': 2.7364406779661015e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:43:57<3:07:09,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:44:01<3:05:10,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.019687987864017487, 'learning_rate': 2.7355932203389833e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:44:01<3:05:10,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:44:05<3:14:18,  3.61s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07673954963684082, 'learning_rate': 2.7347457627118645e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:44:05<3:14:18,  3.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:44:08<3:09:48,  3.53s/it]                                                       {'loss': 0.0408, 'grad_norm': 4.30044412612915, 'learning_rate': 2.733898305084746e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:44:08<3:09:48,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:44:11<3:06:00,  3.46s/it]                                                       {'loss': 0.2731, 'grad_norm': 5.505288600921631, 'learning_rate': 2.733050847457627e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:44:11<3:06:00,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:44:15<3:07:37,  3.49s/it]                                                       {'loss': 0.1066, 'grad_norm': 5.425691604614258, 'learning_rate': 2.732203389830509e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:44:15<3:07:37,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:44:18<3:04:55,  3.44s/it]                                                       {'loss': 0.0177, 'grad_norm': 2.374566078186035, 'learning_rate': 2.73135593220339e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:44:18<3:04:55,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:44:22<3:05:44,  3.46s/it]                                                       {'loss': 0.1224, 'grad_norm': 6.796244144439697, 'learning_rate': 2.7305084745762715e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:44:22<3:05:44,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:44:25<3:04:36,  3.44s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.270291566848755, 'learning_rate': 2.7296610169491526e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:44:25<3:04:36,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:44:28<3:03:17,  3.42s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.9488251209259033, 'learning_rate': 2.7288135593220337e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:44:28<3:03:17,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:44:32<3:06:20,  3.47s/it]                                                       {'loss': 0.0358, 'grad_norm': 3.2004048824310303, 'learning_rate': 2.7279661016949155e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:44:32<3:06:20,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:44:35<3:04:15,  3.44s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4240666925907135, 'learning_rate': 2.7271186440677963e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:44:35<3:04:15,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:44:39<3:01:30,  3.39s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.6899293661117554, 'learning_rate': 2.726271186440678e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:44:39<3:01:30,  3.39s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:44:42<3:03:47,  3.43s/it]                                                       {'loss': 0.0314, 'grad_norm': 3.0817012786865234, 'learning_rate': 2.7254237288135593e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:44:42<3:03:47,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:44:46<3:09:19,  3.53s/it]                                                       {'loss': 0.014, 'grad_norm': 1.9486783742904663, 'learning_rate': 2.7245762711864407e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:44:46<3:09:19,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:44:50<3:10:27,  3.56s/it]                                                       {'loss': 0.081, 'grad_norm': 7.672183990478516, 'learning_rate': 2.723728813559322e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:44:50<3:10:27,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:44:53<3:08:45,  3.52s/it]                                                       {'loss': 0.1583, 'grad_norm': 7.426115989685059, 'learning_rate': 2.7228813559322037e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:44:53<3:08:45,  3.52s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:44:57<3:09:31,  3.54s/it]                                                       {'loss': 0.1257, 'grad_norm': 6.321544170379639, 'learning_rate': 2.7220338983050848e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:44:57<3:09:31,  3.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:45:00<3:05:23,  3.46s/it]                                                       {'loss': 0.1999, 'grad_norm': 10.82858657836914, 'learning_rate': 2.7211864406779663e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:45:00<3:05:23,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:45:03<3:03:42,  3.43s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.877472460269928, 'learning_rate': 2.7203389830508474e-05, 'epoch': 0.47}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:45:03<3:03:42,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:45:07<3:04:29,  3.45s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3196643888950348, 'learning_rate': 2.7194915254237292e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:45:07<3:04:29,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:45:10<3:04:12,  3.45s/it]                                                       {'loss': 0.0552, 'grad_norm': 5.1227850914001465, 'learning_rate': 2.7186440677966103e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:45:10<3:04:12,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:45:14<3:04:18,  3.45s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.6087982654571533, 'learning_rate': 2.7177966101694918e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:45:14<3:04:18,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:45:17<3:11:13,  3.58s/it]                                                       {'loss': 0.0116, 'grad_norm': 0.7671246528625488, 'learning_rate': 2.716949152542373e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:45:17<3:11:13,  3.58s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:45:21<3:07:40,  3.51s/it]                                                       {'loss': 0.154, 'grad_norm': 8.701116561889648, 'learning_rate': 2.7161016949152547e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:45:21<3:07:40,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:45:24<3:05:06,  3.47s/it]                                                       {'loss': 0.2022, 'grad_norm': 9.583751678466797, 'learning_rate': 2.7152542372881355e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:45:24<3:05:06,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:45:28<3:05:18,  3.47s/it]                                                       {'loss': 0.0492, 'grad_norm': 4.818256855010986, 'learning_rate': 2.7144067796610173e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:45:28<3:05:18,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:45:31<3:04:55,  3.47s/it]                                                       {'loss': 0.0885, 'grad_norm': 3.20231032371521, 'learning_rate': 2.7135593220338985e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:45:31<3:04:55,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:45:35<3:05:09,  3.47s/it]                                                       {'loss': 0.0088, 'grad_norm': 2.2071726322174072, 'learning_rate': 2.71271186440678e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:45:35<3:05:09,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:45:38<3:02:36,  3.42s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3990819752216339, 'learning_rate': 2.711864406779661e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:45:38<3:02:36,  3.42s/it][2025-10-20 18:15:24,897] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:45:44<3:38:59,  4.11s/it]                                                       {'loss': 0.0707, 'grad_norm': 4.920287609100342, 'learning_rate': 2.7110169491525422e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:45:44<3:38:59,  4.11s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:45:47<3:27:08,  3.89s/it]                                                       {'loss': 0.0275, 'grad_norm': 1.6502834558486938, 'learning_rate': 2.710169491525424e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:45:47<3:27:08,  3.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:45:50<3:17:54,  3.71s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.224344491958618, 'learning_rate': 2.709322033898305e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:45:50<3:17:54,  3.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:45:54<3:13:27,  3.63s/it]                                                       {'loss': 0.0905, 'grad_norm': 5.528127670288086, 'learning_rate': 2.7084745762711866e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:45:54<3:13:27,  3.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:45:57<3:14:27,  3.65s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.08849672973155975, 'learning_rate': 2.7076271186440677e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:45:57<3:14:27,  3.65s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:46:01<3:10:04,  3.57s/it]                                                       {'loss': 0.0392, 'grad_norm': 2.924531936645508, 'learning_rate': 2.7067796610169495e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:46:01<3:10:04,  3.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:46:04<3:08:58,  3.55s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.018792403861880302, 'learning_rate': 2.7059322033898303e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:46:04<3:08:58,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:46:08<3:04:51,  3.47s/it]                                                       {'loss': 0.0442, 'grad_norm': 1.4884339570999146, 'learning_rate': 2.705084745762712e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:46:08<3:04:51,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:46:11<3:03:11,  3.44s/it]                                                       {'loss': 0.1937, 'grad_norm': 8.501727104187012, 'learning_rate': 2.7042372881355932e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:46:11<3:03:11,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:46:15<3:12:38,  3.62s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3414606750011444, 'learning_rate': 2.7033898305084747e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:46:15<3:12:38,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:46:19<3:11:20,  3.60s/it]                                                       {'loss': 0.0695, 'grad_norm': 6.978887557983398, 'learning_rate': 2.702542372881356e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:46:19<3:11:20,  3.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:46:22<3:07:17,  3.52s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.43390071392059326, 'learning_rate': 2.7016949152542376e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:46:22<3:07:17,  3.52s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:46:25<3:05:05,  3.48s/it]                                                       {'loss': 0.0517, 'grad_norm': 5.3892340660095215, 'learning_rate': 2.7008474576271188e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:46:25<3:05:05,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:46:29<3:03:11,  3.45s/it]                                                       {'loss': 0.2085, 'grad_norm': 7.19349479675293, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:46:29<3:03:11,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:46:32<3:03:17,  3.45s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2557717561721802, 'learning_rate': 2.6991525423728814e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:46:32<3:03:17,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:46:36<3:02:23,  3.44s/it]                                                       {'loss': 0.0876, 'grad_norm': 6.475000381469727, 'learning_rate': 2.6983050847457632e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:46:36<3:02:23,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:46:39<3:05:56,  3.51s/it]                                                       {'loss': 0.0426, 'grad_norm': 5.993831157684326, 'learning_rate': 2.6974576271186443e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:46:39<3:05:56,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:46:43<3:06:40,  3.52s/it]                                                       {'loss': 0.1095, 'grad_norm': 7.542200565338135, 'learning_rate': 2.6966101694915258e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:46:43<3:06:40,  3.52s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:46:46<3:05:28,  3.50s/it]                                                       {'loss': 0.0219, 'grad_norm': 1.9779503345489502, 'learning_rate': 2.695762711864407e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:46:46<3:05:28,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:46:50<3:16:25,  3.71s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.3289666175842285, 'learning_rate': 2.6949152542372884e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:46:50<3:16:25,  3.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:46:54<3:12:40,  3.64s/it]                                                       {'loss': 0.0261, 'grad_norm': 4.751077651977539, 'learning_rate': 2.6940677966101695e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:46:54<3:12:40,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:46:57<3:07:42,  3.54s/it]                                                       {'loss': 0.0857, 'grad_norm': 3.2466938495635986, 'learning_rate': 2.6932203389830506e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:46:57<3:07:42,  3.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:47:01<3:04:30,  3.48s/it]                                                       {'loss': 0.1078, 'grad_norm': 6.020148277282715, 'learning_rate': 2.6923728813559324e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:47:01<3:04:30,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:47:04<3:03:24,  3.46s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.34700345993042, 'learning_rate': 2.6915254237288136e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:47:04<3:03:24,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:47:07<3:03:44,  3.47s/it]                                                       {'loss': 0.0366, 'grad_norm': 3.4547061920166016, 'learning_rate': 2.690677966101695e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:47:07<3:03:44,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:47:11<3:03:14,  3.46s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.8833966851234436, 'learning_rate': 2.689830508474576e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:47:11<3:03:14,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:47:14<3:02:45,  3.46s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.9938620328903198, 'learning_rate': 2.688983050847458e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:47:14<3:02:45,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:47:18<3:02:09,  3.45s/it]                                                       {'loss': 0.0531, 'grad_norm': 5.756058216094971, 'learning_rate': 2.688135593220339e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:47:18<3:02:09,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:47:21<3:01:32,  3.44s/it]                                                       {'loss': 0.195, 'grad_norm': 12.597411155700684, 'learning_rate': 2.6872881355932206e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:47:21<3:01:32,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:47:25<3:02:21,  3.45s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.31212225556373596, 'learning_rate': 2.6864406779661017e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:47:25<3:02:21,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:47:28<3:01:35,  3.44s/it]                                                       {'loss': 0.001, 'grad_norm': 0.12496358156204224, 'learning_rate': 2.685593220338983e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:47:28<3:01:35,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:47:31<2:59:48,  3.41s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.094696044921875, 'learning_rate': 2.6847457627118643e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:47:31<2:59:48,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:47:35<3:00:28,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.10080254822969437, 'learning_rate': 2.683898305084746e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:47:35<3:00:28,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:47:38<3:00:21,  3.42s/it]                                                       {'loss': 0.0391, 'grad_norm': 4.0938005447387695, 'learning_rate': 2.6830508474576272e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:47:38<3:00:21,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:47:42<3:00:55,  3.43s/it]                                                       {'loss': 0.153, 'grad_norm': 11.754676818847656, 'learning_rate': 2.6822033898305087e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:47:42<3:00:55,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:47:45<2:59:23,  3.40s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5359842777252197, 'learning_rate': 2.6813559322033898e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:47:45<2:59:23,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:47:48<2:58:29,  3.39s/it]                                                       {'loss': 0.001, 'grad_norm': 0.1793534755706787, 'learning_rate': 2.6805084745762716e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:47:48<2:58:29,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:47:52<2:59:36,  3.41s/it]                                                       {'loss': 0.0687, 'grad_norm': 8.442753791809082, 'learning_rate': 2.6796610169491527e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:47:52<2:59:36,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:47:55<2:59:07,  3.40s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5941662192344666, 'learning_rate': 2.6788135593220342e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:47:55<2:59:07,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:47:59<2:59:38,  3.41s/it]                                                       {'loss': 0.0338, 'grad_norm': 3.5406787395477295, 'learning_rate': 2.6779661016949153e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:47:59<2:59:38,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:48:02<3:01:05,  3.44s/it]                                                       {'loss': 0.0229, 'grad_norm': 2.887507200241089, 'learning_rate': 2.677118644067797e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:48:02<3:01:05,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:48:06<3:07:15,  3.56s/it]                                                       {'loss': 0.0184, 'grad_norm': 1.1741013526916504, 'learning_rate': 2.676271186440678e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:48:06<3:07:15,  3.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:48:10<3:11:18,  3.64s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.2345800399780273, 'learning_rate': 2.675423728813559e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:48:10<3:11:18,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:48:13<3:06:27,  3.54s/it]                                                       {'loss': 0.1353, 'grad_norm': 5.876528263092041, 'learning_rate': 2.674576271186441e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:48:13<3:06:27,  3.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:48:17<3:03:48,  3.50s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.637656331062317, 'learning_rate': 2.673728813559322e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:48:17<3:03:48,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:48:20<3:10:07,  3.62s/it]                                                       {'loss': 0.1198, 'grad_norm': 5.670208930969238, 'learning_rate': 2.6728813559322035e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:48:20<3:10:07,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:48:24<3:11:15,  3.64s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2774638235569, 'learning_rate': 2.6720338983050846e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:48:24<3:11:15,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:48:28<3:14:18,  3.70s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.5481416583061218, 'learning_rate': 2.6711864406779664e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:48:28<3:14:18,  3.70s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:48:32<3:11:31,  3.65s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6654796004295349, 'learning_rate': 2.6703389830508475e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:48:32<3:11:31,  3.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:48:35<3:10:03,  3.62s/it]                                                       {'loss': 0.0276, 'grad_norm': 3.595313549041748, 'learning_rate': 2.669491525423729e-05, 'epoch': 0.47}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:48:35<3:10:03,  3.62s/it][2025-10-20 18:18:22,066] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:48:41<3:43:47,  4.26s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09360364824533463, 'learning_rate': 2.66864406779661e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:48:41<3:43:47,  4.26s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:48:44<3:31:36,  4.03s/it]                                                       {'loss': 0.2028, 'grad_norm': 6.911875247955322, 'learning_rate': 2.667796610169492e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:48:44<3:31:36,  4.03s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:48:48<3:21:39,  3.84s/it]                                                       {'loss': 0.0969, 'grad_norm': 6.821982383728027, 'learning_rate': 2.6669491525423727e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:48:48<3:21:39,  3.84s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:48:51<3:19:58,  3.81s/it]                                                       {'loss': 0.0438, 'grad_norm': 6.099765300750732, 'learning_rate': 2.6661016949152545e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:48:51<3:19:58,  3.81s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:48:55<3:12:19,  3.67s/it]                                                       {'loss': 0.0734, 'grad_norm': 5.820690631866455, 'learning_rate': 2.6652542372881357e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:48:55<3:12:19,  3.67s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:48:58<3:07:35,  3.58s/it]                                                       {'loss': 0.0565, 'grad_norm': 5.718685150146484, 'learning_rate': 2.664406779661017e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:48:58<3:07:35,  3.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:49:01<3:02:58,  3.49s/it]                                                       {'loss': 0.1878, 'grad_norm': 7.707203388214111, 'learning_rate': 2.6635593220338983e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:49:01<3:02:58,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:49:05<3:00:21,  3.44s/it]                                                       {'loss': 0.0292, 'grad_norm': 2.745685338973999, 'learning_rate': 2.66271186440678e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:49:05<3:00:21,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:49:08<3:00:25,  3.45s/it]                                                       {'loss': 0.0509, 'grad_norm': 5.218877792358398, 'learning_rate': 2.6618644067796612e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:49:08<3:00:25,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:49:12<3:01:23,  3.47s/it]                                                       {'loss': 0.028, 'grad_norm': 3.0207724571228027, 'learning_rate': 2.6610169491525427e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:49:12<3:01:23,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:49:15<3:01:45,  3.47s/it]                                                       {'loss': 0.0736, 'grad_norm': 7.032421588897705, 'learning_rate': 2.6601694915254238e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:49:15<3:01:45,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:49:19<3:00:37,  3.45s/it]                                                       {'loss': 0.1718, 'grad_norm': 7.096205711364746, 'learning_rate': 2.6593220338983056e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:49:19<3:00:37,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:49:22<3:00:50,  3.46s/it]                                                       {'loss': 0.0696, 'grad_norm': 6.073184967041016, 'learning_rate': 2.6584745762711867e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:49:22<3:00:50,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:49:25<2:58:38,  3.42s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.3956928253173828, 'learning_rate': 2.6576271186440675e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:49:25<2:58:38,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:49:29<2:58:18,  3.41s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.9674360752105713, 'learning_rate': 2.6567796610169493e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:49:29<2:58:18,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:49:32<2:58:43,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.01848512515425682, 'learning_rate': 2.6559322033898304e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:49:32<2:58:43,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:49:36<3:01:32,  3.48s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3437495827674866, 'learning_rate': 2.655084745762712e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:49:36<3:01:32,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:49:39<3:02:03,  3.49s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.08016883581876755, 'learning_rate': 2.654237288135593e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:49:39<3:02:03,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:49:43<3:04:25,  3.53s/it]                                                       {'loss': 0.0389, 'grad_norm': 3.4553823471069336, 'learning_rate': 2.653389830508475e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:49:43<3:04:25,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:49:46<3:00:47,  3.47s/it]                                                       {'loss': 0.0163, 'grad_norm': 2.246338129043579, 'learning_rate': 2.652542372881356e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:49:46<3:00:47,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:49:50<2:59:15,  3.44s/it]                                                       {'loss': 0.0205, 'grad_norm': 3.0912716388702393, 'learning_rate': 2.6516949152542374e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:49:50<2:59:15,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:49:53<2:59:14,  3.44s/it]                                                       {'loss': 0.0209, 'grad_norm': 3.095777750015259, 'learning_rate': 2.6508474576271186e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:49:53<2:59:14,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:49:57<2:59:15,  3.44s/it]                                                       {'loss': 0.0558, 'grad_norm': 6.424288749694824, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:49:57<2:59:15,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:50:00<2:59:40,  3.45s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.1601215600967407, 'learning_rate': 2.6491525423728815e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:50:00<2:59:40,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:50:03<2:57:50,  3.41s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04236571118235588, 'learning_rate': 2.648305084745763e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:50:03<2:57:50,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:50:07<2:59:00,  3.44s/it]                                                       {'loss': 0.0208, 'grad_norm': 3.7003633975982666, 'learning_rate': 2.647457627118644e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:50:07<2:59:00,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:50:10<2:59:41,  3.45s/it]                                                       {'loss': 0.0388, 'grad_norm': 4.121493816375732, 'learning_rate': 2.6466101694915256e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:50:10<2:59:41,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:50:14<2:58:56,  3.44s/it]                                                       {'loss': 0.0298, 'grad_norm': 2.72525954246521, 'learning_rate': 2.6457627118644067e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:50:14<2:58:56,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:50:17<2:58:55,  3.44s/it]                                                       {'loss': 0.1205, 'grad_norm': 3.8456807136535645, 'learning_rate': 2.6449152542372885e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:50:17<2:58:55,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:50:21<3:05:33,  3.57s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.1316589117050171, 'learning_rate': 2.6440677966101696e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:50:21<3:05:33,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:50:25<3:03:03,  3.52s/it]                                                       {'loss': 0.007, 'grad_norm': 0.738680362701416, 'learning_rate': 2.643220338983051e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:50:25<3:03:03,  3.52s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:50:28<3:01:39,  3.50s/it]                                                       {'loss': 0.0213, 'grad_norm': 3.975799322128296, 'learning_rate': 2.6423728813559322e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:50:28<3:01:39,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:50:31<2:59:39,  3.46s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.9440627098083496, 'learning_rate': 2.641525423728814e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:50:31<2:59:39,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:50:35<2:59:41,  3.46s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9798659086227417, 'learning_rate': 2.640677966101695e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:50:35<2:59:41,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:50:39<3:14:04,  3.74s/it]                                                       {'loss': 0.0223, 'grad_norm': 2.2405736446380615, 'learning_rate': 2.6398305084745763e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:50:39<3:14:04,  3.74s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:50:43<3:08:05,  3.62s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.4212471544742584, 'learning_rate': 2.6389830508474578e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:50:43<3:08:05,  3.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:50:46<3:05:01,  3.57s/it]                                                       {'loss': 0.044, 'grad_norm': 2.4258108139038086, 'learning_rate': 2.638135593220339e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:50:46<3:05:01,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:50:49<3:03:20,  3.53s/it]                                                       {'loss': 0.1012, 'grad_norm': 5.740932464599609, 'learning_rate': 2.6372881355932204e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:50:49<3:03:20,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:50:53<3:01:02,  3.49s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.47119811177253723, 'learning_rate': 2.6364406779661015e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:50:53<3:01:02,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:50:56<3:00:00,  3.47s/it]                                                       {'loss': 0.018, 'grad_norm': 2.651252031326294, 'learning_rate': 2.6355932203389833e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:50:56<3:00:00,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:51:00<3:01:20,  3.50s/it]                                                       {'loss': 0.1112, 'grad_norm': 6.300496578216553, 'learning_rate': 2.6347457627118644e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:51:00<3:01:20,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:51:03<2:59:27,  3.46s/it]                                                       {'loss': 0.4072, 'grad_norm': 8.480057716369629, 'learning_rate': 2.633898305084746e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:51:03<2:59:27,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:51:07<3:00:31,  3.49s/it]                                                       {'loss': 0.1035, 'grad_norm': 7.716986656188965, 'learning_rate': 2.633050847457627e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:51:07<3:00:31,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:51:10<2:58:06,  3.44s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.0610466003417969, 'learning_rate': 2.6322033898305088e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:51:10<2:58:06,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:51:13<2:56:38,  3.41s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.6736974716186523, 'learning_rate': 2.63135593220339e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:51:13<2:56:38,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [2:51:17<3:00:59,  3.50s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.2491142749786377, 'learning_rate': 2.6305084745762714e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [2:51:17<3:00:59,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [2:51:21<2:59:23,  3.47s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.5834155678749084, 'learning_rate': 2.6296610169491525e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [2:51:21<2:59:23,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [2:51:24<2:57:36,  3.44s/it]                                                       {'loss': 0.1971, 'grad_norm': 7.821877956390381, 'learning_rate': 2.6288135593220344e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [2:51:24<2:57:36,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [2:51:27<2:55:10,  3.39s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3068203926086426, 'learning_rate': 2.627966101694915e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [2:51:27<2:55:10,  3.39s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [2:51:31<2:54:42,  3.38s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.6532440185546875, 'learning_rate': 2.627118644067797e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [2:51:31<2:54:42,  3.38s/it][2025-10-20 18:21:17,515] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [2:51:37<3:35:55,  4.18s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.21288906037807465, 'learning_rate': 2.626271186440678e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [2:51:37<3:35:55,  4.18s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [2:51:40<3:25:17,  3.98s/it]                                                       {'loss': 0.3015, 'grad_norm': 8.37031364440918, 'learning_rate': 2.6254237288135595e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [2:51:40<3:25:17,  3.98s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [2:51:43<3:14:55,  3.78s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.511444091796875, 'learning_rate': 2.6245762711864407e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [2:51:43<3:14:55,  3.78s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [2:51:47<3:07:33,  3.63s/it]                                                       {'loss': 0.008, 'grad_norm': 0.9510785937309265, 'learning_rate': 2.6237288135593225e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [2:51:47<3:07:33,  3.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [2:51:50<3:02:43,  3.54s/it]                                                       {'loss': 0.0253, 'grad_norm': 3.0347840785980225, 'learning_rate': 2.6228813559322036e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [2:51:50<3:02:43,  3.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [2:51:53<2:59:31,  3.48s/it]                                                       {'loss': 0.0155, 'grad_norm': 1.5983097553253174, 'learning_rate': 2.6220338983050847e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [2:51:53<2:59:31,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [2:51:57<2:57:16,  3.44s/it]                                                       {'loss': 0.0282, 'grad_norm': 3.013584613800049, 'learning_rate': 2.6211864406779662e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [2:51:57<2:57:16,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [2:52:00<2:55:42,  3.41s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.21558678150177, 'learning_rate': 2.6203389830508473e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [2:52:00<2:55:42,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [2:52:03<2:54:52,  3.39s/it]                                                       {'loss': 0.2102, 'grad_norm': 7.774469375610352, 'learning_rate': 2.619491525423729e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [2:52:03<2:54:52,  3.39s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [2:52:07<2:55:07,  3.40s/it]                                                       {'loss': 0.1246, 'grad_norm': 4.6369781494140625, 'learning_rate': 2.61864406779661e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [2:52:07<2:55:07,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [2:52:10<2:54:54,  3.40s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1361345499753952, 'learning_rate': 2.6177966101694917e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [2:52:10<2:54:54,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [2:52:14<2:54:21,  3.39s/it]                                                       {'loss': 0.1187, 'grad_norm': 6.919375419616699, 'learning_rate': 2.616949152542373e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [2:52:14<2:54:21,  3.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [2:52:17<2:54:51,  3.40s/it]                                                       {'loss': 0.0783, 'grad_norm': 2.498234272003174, 'learning_rate': 2.6161016949152543e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [2:52:17<2:54:51,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [2:52:20<2:54:43,  3.40s/it]                                                       {'loss': 0.0627, 'grad_norm': 3.021164655685425, 'learning_rate': 2.6152542372881355e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [2:52:20<2:54:43,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [2:52:24<2:55:29,  3.41s/it]                                                       {'loss': 0.3754, 'grad_norm': 9.26315689086914, 'learning_rate': 2.6144067796610173e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [2:52:24<2:55:29,  3.41s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [2:52:28<3:06:24,  3.63s/it]                                                       {'loss': 0.0142, 'grad_norm': 1.5626193284988403, 'learning_rate': 2.6135593220338984e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [2:52:28<3:06:24,  3.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [2:52:31<3:02:23,  3.55s/it]                                                       {'loss': 0.1644, 'grad_norm': 6.0373759269714355, 'learning_rate': 2.61271186440678e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [2:52:31<3:02:23,  3.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [2:52:35<3:01:46,  3.54s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9704079627990723, 'learning_rate': 2.611864406779661e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [2:52:35<3:01:46,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [2:52:38<3:01:26,  3.53s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.387940913438797, 'learning_rate': 2.6110169491525428e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [2:52:38<3:01:26,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [2:52:42<2:59:27,  3.50s/it]                                                       {'loss': 0.0666, 'grad_norm': 5.564178943634033, 'learning_rate': 2.610169491525424e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [2:52:42<2:59:27,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [2:52:45<2:57:53,  3.47s/it]                                                       {'loss': 0.0385, 'grad_norm': 3.537602424621582, 'learning_rate': 2.6093220338983054e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [2:52:45<2:57:53,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [2:52:49<2:56:58,  3.45s/it]                                                       {'loss': 0.0797, 'grad_norm': 7.601317405700684, 'learning_rate': 2.6084745762711865e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [2:52:49<2:56:58,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [2:52:54<3:26:44,  4.03s/it]                                                       {'loss': 0.0879, 'grad_norm': 3.7177271842956543, 'learning_rate': 2.6076271186440683e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [2:52:54<3:26:44,  4.03s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [2:52:58<3:24:04,  3.98s/it]                                                       {'loss': 0.0808, 'grad_norm': 4.195218086242676, 'learning_rate': 2.606779661016949e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [2:52:58<3:24:04,  3.98s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [2:53:01<3:15:00,  3.80s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.9343651533126831, 'learning_rate': 2.605932203389831e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [2:53:01<3:15:00,  3.80s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [2:53:05<3:07:13,  3.65s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4346044659614563, 'learning_rate': 2.605084745762712e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [2:53:05<3:07:13,  3.65s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [2:53:08<3:03:50,  3.59s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.6687108278274536, 'learning_rate': 2.6042372881355932e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [2:53:08<3:03:50,  3.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [2:53:12<3:03:06,  3.58s/it]                                                       {'loss': 0.0789, 'grad_norm': 4.802884101867676, 'learning_rate': 2.6033898305084746e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [2:53:12<3:03:06,  3.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [2:53:15<3:07:09,  3.66s/it]                                                       {'loss': 0.0637, 'grad_norm': 6.17422342300415, 'learning_rate': 2.6025423728813558e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [2:53:15<3:07:09,  3.66s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [2:53:19<3:03:54,  3.59s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.082960844039917, 'learning_rate': 2.6016949152542376e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [2:53:19<3:03:54,  3.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [2:53:22<3:00:53,  3.54s/it]                                                       {'loss': 0.0182, 'grad_norm': 1.9696146249771118, 'learning_rate': 2.6008474576271187e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [2:53:22<3:00:53,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [2:53:26<2:58:54,  3.50s/it]                                                       {'loss': 0.0967, 'grad_norm': 6.3577094078063965, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [2:53:26<2:58:54,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [2:53:29<3:00:25,  3.53s/it]                                                       {'loss': 0.2029, 'grad_norm': 7.912010669708252, 'learning_rate': 2.5991525423728813e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [2:53:29<3:00:25,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [2:53:33<3:00:39,  3.54s/it]                                                       {'loss': 0.0254, 'grad_norm': 3.579099416732788, 'learning_rate': 2.598305084745763e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [2:53:33<3:00:39,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [2:53:36<2:58:20,  3.49s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.1830040067434311, 'learning_rate': 2.597457627118644e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [2:53:36<2:58:20,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [2:53:40<2:58:09,  3.49s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.5077944993972778, 'learning_rate': 2.5966101694915257e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [2:53:40<2:58:09,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [2:53:43<3:02:42,  3.58s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.6866445541381836, 'learning_rate': 2.595762711864407e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [2:53:43<3:02:42,  3.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [2:53:47<2:59:30,  3.52s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19739565253257751, 'learning_rate': 2.5949152542372883e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [2:53:47<2:59:30,  3.52s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [2:53:50<2:58:18,  3.50s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.498239517211914, 'learning_rate': 2.5940677966101694e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [2:53:50<2:58:18,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [2:53:54<2:56:52,  3.47s/it]                                                       {'loss': 0.2303, 'grad_norm': 7.123091220855713, 'learning_rate': 2.5932203389830512e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [2:53:54<2:56:52,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [2:53:57<2:55:55,  3.45s/it]                                                       {'loss': 0.0514, 'grad_norm': 3.505669116973877, 'learning_rate': 2.5923728813559324e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [2:53:57<2:55:55,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [2:54:01<3:01:17,  3.56s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0867389366030693, 'learning_rate': 2.591525423728814e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [2:54:01<3:01:17,  3.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [2:54:04<2:59:54,  3.53s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.18781185150146484, 'learning_rate': 2.590677966101695e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [2:54:04<2:59:54,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [2:54:08<2:58:36,  3.51s/it]                                                       {'loss': 0.0381, 'grad_norm': 5.804018497467041, 'learning_rate': 2.5898305084745768e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [2:54:08<2:58:36,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [2:54:11<3:00:04,  3.54s/it]                                                       {'loss': 0.1302, 'grad_norm': 6.3235273361206055, 'learning_rate': 2.588983050847458e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [2:54:11<3:00:04,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [2:54:15<2:55:58,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.01984703727066517, 'learning_rate': 2.5881355932203394e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [2:54:15<2:55:58,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [2:54:18<2:57:04,  3.48s/it]                                                       {'loss': 0.0238, 'grad_norm': 1.6547794342041016, 'learning_rate': 2.5872881355932205e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [2:54:18<2:57:04,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [2:54:22<2:57:27,  3.49s/it]                                                       {'loss': 0.003, 'grad_norm': 0.367148220539093, 'learning_rate': 2.5864406779661016e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [2:54:22<2:57:27,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [2:54:25<2:54:49,  3.44s/it]                                                       {'loss': 0.0463, 'grad_norm': 5.045054912567139, 'learning_rate': 2.585593220338983e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [2:54:25<2:54:49,  3.44s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [2:54:28<2:54:39,  3.44s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.8226153254508972, 'learning_rate': 2.5847457627118642e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [2:54:28<2:54:39,  3.44s/it][2025-10-20 18:24:15,451] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [2:54:34<3:31:58,  4.17s/it]                                                       {'loss': 0.0234, 'grad_norm': 2.214482545852661, 'learning_rate': 2.583898305084746e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [2:54:34<3:31:58,  4.17s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [2:54:38<3:20:37,  3.95s/it]                                                       {'loss': 0.1824, 'grad_norm': 6.909554958343506, 'learning_rate': 2.583050847457627e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [2:54:38<3:20:37,  3.95s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [2:54:41<3:11:27,  3.77s/it]                                                       {'loss': 0.0975, 'grad_norm': 7.682040214538574, 'learning_rate': 2.5822033898305086e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [2:54:41<3:11:27,  3.77s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [2:54:44<3:04:58,  3.64s/it]                                                       {'loss': 0.0782, 'grad_norm': 6.056154251098633, 'learning_rate': 2.5813559322033898e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [2:54:44<3:04:58,  3.64s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [2:54:48<2:59:49,  3.54s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.2880903482437134, 'learning_rate': 2.5805084745762716e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [2:54:48<2:59:49,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [2:54:51<2:56:48,  3.48s/it]                                                       {'loss': 0.0739, 'grad_norm': 5.565136909484863, 'learning_rate': 2.5796610169491527e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [2:54:51<2:56:48,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [2:54:54<2:54:58,  3.45s/it]                                                       {'loss': 0.0328, 'grad_norm': 3.2755050659179688, 'learning_rate': 2.578813559322034e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [2:54:54<2:54:58,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [2:54:58<2:53:31,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03733456879854202, 'learning_rate': 2.5779661016949153e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [2:54:58<2:53:31,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [2:55:01<2:55:20,  3.46s/it]                                                       {'loss': 0.0433, 'grad_norm': 6.041304111480713, 'learning_rate': 2.5771186440677967e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [2:55:01<2:55:20,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [2:55:05<2:58:15,  3.52s/it]                                                       {'loss': 0.0525, 'grad_norm': 4.887724876403809, 'learning_rate': 2.576271186440678e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [2:55:05<2:58:15,  3.52s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [2:55:08<2:56:39,  3.49s/it]                                                       {'loss': 0.2951, 'grad_norm': 9.156414985656738, 'learning_rate': 2.5754237288135597e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [2:55:08<2:56:39,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [2:55:12<2:55:02,  3.46s/it]                                                       {'loss': 0.0538, 'grad_norm': 4.115550994873047, 'learning_rate': 2.5745762711864408e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [2:55:12<2:55:02,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [2:55:15<2:57:00,  3.50s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.2949559688568115, 'learning_rate': 2.5737288135593223e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [2:55:15<2:57:00,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [2:55:19<2:55:16,  3.46s/it]                                                       {'loss': 0.0907, 'grad_norm': 5.685512542724609, 'learning_rate': 2.5728813559322034e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [2:55:19<2:55:16,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [2:55:22<2:55:37,  3.47s/it]                                                       {'loss': 0.0322, 'grad_norm': 3.454871416091919, 'learning_rate': 2.5720338983050852e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [2:55:22<2:55:37,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [2:55:26<2:55:12,  3.46s/it]                                                       {'loss': 0.1281, 'grad_norm': 7.628946304321289, 'learning_rate': 2.5711864406779663e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [2:55:26<2:55:12,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [2:55:29<2:53:22,  3.43s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.4109705984592438, 'learning_rate': 2.5703389830508475e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [2:55:29<2:53:22,  3.43s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [2:55:32<2:50:59,  3.38s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.6570888757705688, 'learning_rate': 2.569491525423729e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [2:55:32<2:50:59,  3.38s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [2:55:36<2:53:54,  3.44s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1601606160402298, 'learning_rate': 2.56864406779661e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [2:55:36<2:53:54,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [2:55:39<2:51:24,  3.39s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07885805517435074, 'learning_rate': 2.5677966101694915e-05, 'epoch': 0.49}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [2:55:39<2:51:24,  3.39s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [2:55:43<2:52:04,  3.41s/it]                                                       {'loss': 0.1212, 'grad_norm': 10.289948463439941, 'learning_rate': 2.5669491525423727e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [2:55:43<2:52:04,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [2:55:46<2:51:47,  3.40s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.0350812673568726, 'learning_rate': 2.5661016949152545e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [2:55:46<2:51:47,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [2:55:50<2:54:06,  3.45s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.5729495286941528, 'learning_rate': 2.5652542372881356e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [2:55:50<2:54:06,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [2:55:53<2:53:00,  3.43s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.480857789516449, 'learning_rate': 2.564406779661017e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [2:55:53<2:53:00,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [2:55:57<2:56:21,  3.50s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.6073534488677979, 'learning_rate': 2.5635593220338982e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [2:55:57<2:56:21,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [2:56:00<2:57:13,  3.52s/it]                                                       {'loss': 0.0193, 'grad_norm': 2.5218396186828613, 'learning_rate': 2.56271186440678e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [2:56:00<2:57:13,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [2:56:04<3:02:03,  3.61s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.43589872121810913, 'learning_rate': 2.561864406779661e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [2:56:04<3:02:03,  3.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [2:56:07<2:58:03,  3.54s/it]                                                       {'loss': 0.0553, 'grad_norm': 4.245317459106445, 'learning_rate': 2.5610169491525426e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [2:56:07<2:58:03,  3.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [2:56:11<2:56:15,  3.50s/it]                                                       {'loss': 0.2241, 'grad_norm': 9.343167304992676, 'learning_rate': 2.5601694915254237e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [2:56:11<2:56:15,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [2:56:15<3:02:18,  3.62s/it]                                                       {'loss': 0.0537, 'grad_norm': 4.669818878173828, 'learning_rate': 2.5593220338983055e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [2:56:15<3:02:18,  3.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [2:56:18<2:58:39,  3.55s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1384091079235077, 'learning_rate': 2.5584745762711863e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [2:56:18<2:58:39,  3.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [2:56:22<2:58:54,  3.56s/it]                                                       {'loss': 0.049, 'grad_norm': 4.243120193481445, 'learning_rate': 2.557627118644068e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [2:56:22<2:58:54,  3.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [2:56:25<2:57:03,  3.52s/it]                                                       {'loss': 0.0217, 'grad_norm': 2.791043281555176, 'learning_rate': 2.5567796610169493e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [2:56:25<2:57:03,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [2:56:28<2:53:19,  3.45s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2084205150604248, 'learning_rate': 2.5559322033898307e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [2:56:28<2:53:19,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [2:56:32<2:52:47,  3.44s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.9715238213539124, 'learning_rate': 2.555084745762712e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [2:56:32<2:52:47,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [2:56:36<2:57:29,  3.53s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.25636011362075806, 'learning_rate': 2.5542372881355937e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [2:56:36<2:57:29,  3.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [2:56:39<2:54:47,  3.48s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.6064445972442627, 'learning_rate': 2.5533898305084748e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [2:56:39<2:54:47,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [2:56:43<2:59:24,  3.57s/it]                                                       {'loss': 0.0573, 'grad_norm': 4.476166248321533, 'learning_rate': 2.552542372881356e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [2:56:43<2:59:24,  3.57s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [2:56:46<2:55:39,  3.50s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.0886915773153305, 'learning_rate': 2.5516949152542374e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [2:56:46<2:55:39,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [2:56:50<3:05:36,  3.70s/it]                                                       {'loss': 0.0711, 'grad_norm': 5.897334575653076, 'learning_rate': 2.5508474576271185e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [2:56:50<3:05:36,  3.70s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [2:56:54<2:59:48,  3.59s/it]                                                       {'loss': 0.0721, 'grad_norm': 3.6181766986846924, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [2:56:54<2:59:48,  3.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [2:56:57<2:56:33,  3.52s/it]                                                       {'loss': 0.251, 'grad_norm': 10.869999885559082, 'learning_rate': 2.549152542372881e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [2:56:57<2:56:33,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [2:57:00<2:53:35,  3.46s/it]                                                       {'loss': 0.1786, 'grad_norm': 7.964078903198242, 'learning_rate': 2.548305084745763e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [2:57:00<2:53:35,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [2:57:04<2:51:48,  3.43s/it]                                                       {'loss': 0.6847, 'grad_norm': 21.912363052368164, 'learning_rate': 2.547457627118644e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [2:57:04<2:51:48,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [2:57:07<2:51:39,  3.43s/it]                                                       {'loss': 0.2918, 'grad_norm': 8.590110778808594, 'learning_rate': 2.5466101694915255e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [2:57:07<2:51:39,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [2:57:11<2:54:38,  3.49s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.725131869316101, 'learning_rate': 2.5457627118644066e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [2:57:11<2:54:38,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [2:57:14<2:53:58,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07473629713058472, 'learning_rate': 2.5449152542372884e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [2:57:14<2:53:58,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [2:57:18<2:54:39,  3.49s/it]                                                       {'loss': 0.2462, 'grad_norm': 10.963536262512207, 'learning_rate': 2.5440677966101696e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [2:57:18<2:54:39,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [2:57:21<2:59:54,  3.60s/it]                                                       {'loss': 0.0397, 'grad_norm': 4.491308212280273, 'learning_rate': 2.543220338983051e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [2:57:22<2:59:54,  3.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [2:57:25<2:58:06,  3.56s/it]                                                       {'loss': 0.019, 'grad_norm': 2.1144521236419678, 'learning_rate': 2.5423728813559322e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [2:57:25<2:58:06,  3.56s/it][2025-10-20 18:27:11,969] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [2:57:31<3:35:15,  4.31s/it]                                                       {'loss': 0.0296, 'grad_norm': 3.359149694442749, 'learning_rate': 2.541525423728814e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [2:57:31<3:35:15,  4.31s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [2:57:34<3:20:29,  4.01s/it]                                                       {'loss': 0.0889, 'grad_norm': 4.748610973358154, 'learning_rate': 2.540677966101695e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [2:57:34<3:20:29,  4.01s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [2:57:38<3:19:01,  3.98s/it]                                                       {'loss': 0.011, 'grad_norm': 1.276581883430481, 'learning_rate': 2.5398305084745766e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [2:57:38<3:19:01,  3.98s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [2:57:42<3:09:44,  3.80s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.8117617964744568, 'learning_rate': 2.5389830508474577e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [2:57:42<3:09:44,  3.80s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [2:57:45<3:06:29,  3.74s/it]                                                       {'loss': 0.0256, 'grad_norm': 2.6396491527557373, 'learning_rate': 2.538135593220339e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [2:57:45<3:06:29,  3.74s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [2:57:49<3:03:06,  3.67s/it]                                                       {'loss': 0.0154, 'grad_norm': 1.1643344163894653, 'learning_rate': 2.5372881355932203e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [2:57:49<3:03:06,  3.67s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [2:57:52<3:04:26,  3.70s/it]                                                       {'loss': 0.0151, 'grad_norm': 1.2863465547561646, 'learning_rate': 2.536440677966102e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [2:57:53<3:04:26,  3.70s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [2:57:56<2:58:59,  3.59s/it]                                                       {'loss': 0.1109, 'grad_norm': 9.064407348632812, 'learning_rate': 2.5355932203389832e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [2:57:56<2:58:59,  3.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [2:57:59<2:56:50,  3.55s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5377936363220215, 'learning_rate': 2.5347457627118644e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [2:57:59<2:56:50,  3.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [2:58:03<2:53:50,  3.49s/it]                                                       {'loss': 0.2089, 'grad_norm': 8.36304759979248, 'learning_rate': 2.5338983050847458e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [2:58:03<2:53:50,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [2:58:06<2:50:43,  3.43s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.2302898168563843, 'learning_rate': 2.533050847457627e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [2:58:06<2:50:43,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [2:58:09<2:49:38,  3.41s/it]                                                       {'loss': 0.3475, 'grad_norm': 6.956459045410156, 'learning_rate': 2.5322033898305088e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [2:58:09<2:49:38,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [2:58:13<2:50:19,  3.42s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.12621618807315826, 'learning_rate': 2.53135593220339e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [2:58:13<2:50:19,  3.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [2:58:16<2:50:35,  3.43s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.9758465886116028, 'learning_rate': 2.5305084745762714e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [2:58:16<2:50:35,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [2:58:19<2:48:49,  3.39s/it]                                                       {'loss': 0.128, 'grad_norm': 6.479125499725342, 'learning_rate': 2.5296610169491525e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [2:58:19<2:48:49,  3.39s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [2:58:23<2:50:41,  3.43s/it]                                                       {'loss': 0.0569, 'grad_norm': 4.307177543640137, 'learning_rate': 2.528813559322034e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [2:58:23<2:50:41,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [2:58:26<2:50:49,  3.44s/it]                                                       {'loss': 0.0833, 'grad_norm': 8.630088806152344, 'learning_rate': 2.527966101694915e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [2:58:26<2:50:49,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [2:58:30<2:52:00,  3.46s/it]                                                       {'loss': 0.0348, 'grad_norm': 4.863928318023682, 'learning_rate': 2.527118644067797e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [2:58:30<2:52:00,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [2:58:33<2:52:09,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06916093826293945, 'learning_rate': 2.526271186440678e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [2:58:33<2:52:09,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [2:58:37<2:50:06,  3.43s/it]                                                       {'loss': 0.1459, 'grad_norm': 6.444118976593018, 'learning_rate': 2.5254237288135595e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [2:58:37<2:50:06,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [2:58:40<2:49:14,  3.41s/it]                                                       {'loss': 0.0432, 'grad_norm': 3.5867412090301514, 'learning_rate': 2.5245762711864406e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [2:58:40<2:49:14,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [2:58:44<2:52:17,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013784556649625301, 'learning_rate': 2.5237288135593224e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [2:58:44<2:52:17,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [2:58:48<2:56:48,  3.56s/it]                                                       {'loss': 0.0776, 'grad_norm': 7.41560173034668, 'learning_rate': 2.5228813559322035e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [2:58:48<2:56:48,  3.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [2:58:51<2:55:11,  3.53s/it]                                                       {'loss': 0.2919, 'grad_norm': 8.488723754882812, 'learning_rate': 2.522033898305085e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [2:58:51<2:55:11,  3.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [2:58:54<2:52:20,  3.48s/it]                                                       {'loss': 0.1851, 'grad_norm': 7.502920150756836, 'learning_rate': 2.521186440677966e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [2:58:54<2:52:20,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [2:58:58<2:53:36,  3.50s/it]                                                       {'loss': 0.0518, 'grad_norm': 3.9740707874298096, 'learning_rate': 2.520338983050848e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [2:58:58<2:53:36,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [2:59:01<2:52:02,  3.47s/it]                                                       {'loss': 0.094, 'grad_norm': 4.4473490715026855, 'learning_rate': 2.5194915254237287e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [2:59:01<2:52:02,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [2:59:05<2:54:03,  3.51s/it]                                                       {'loss': 0.0171, 'grad_norm': 1.7727997303009033, 'learning_rate': 2.5186440677966105e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [2:59:05<2:54:03,  3.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [2:59:08<2:51:41,  3.47s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2236144095659256, 'learning_rate': 2.5177966101694917e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [2:59:08<2:51:41,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [2:59:12<2:51:01,  3.45s/it]                                                       {'loss': 0.0228, 'grad_norm': 1.9633406400680542, 'learning_rate': 2.5169491525423728e-05, 'epoch': 0.51}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [2:59:12<2:51:01,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [2:59:15<2:51:18,  3.46s/it]                                                       {'loss': 0.0336, 'grad_norm': 1.8764451742172241, 'learning_rate': 2.5161016949152543e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [2:59:15<2:51:18,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [2:59:19<2:51:56,  3.48s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.8414912223815918, 'learning_rate': 2.5152542372881354e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [2:59:19<2:51:56,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [2:59:22<2:50:39,  3.45s/it]                                                       {'loss': 0.3615, 'grad_norm': 9.273284912109375, 'learning_rate': 2.5144067796610172e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [2:59:22<2:50:39,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [2:59:26<2:51:00,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11019661277532578, 'learning_rate': 2.5135593220338983e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [2:59:26<2:51:00,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [2:59:29<2:54:50,  3.54s/it]                                                       {'loss': 0.0663, 'grad_norm': 5.225468635559082, 'learning_rate': 2.5127118644067798e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [2:59:29<2:54:50,  3.54s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [2:59:33<2:52:24,  3.49s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07454977184534073, 'learning_rate': 2.511864406779661e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [2:59:33<2:52:24,  3.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [2:59:36<2:50:49,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02324623242020607, 'learning_rate': 2.5110169491525427e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [2:59:36<2:50:49,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [2:59:39<2:48:57,  3.42s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1980721354484558, 'learning_rate': 2.5101694915254235e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [2:59:39<2:48:57,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [2:59:43<2:48:37,  3.42s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.1165249347686768, 'learning_rate': 2.5093220338983053e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [2:59:43<2:48:37,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [2:59:46<2:48:21,  3.41s/it]                                                       {'loss': 0.007, 'grad_norm': 0.9628358483314514, 'learning_rate': 2.5084745762711865e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [2:59:46<2:48:21,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [2:59:50<2:48:14,  3.41s/it]                                                       {'loss': 0.0172, 'grad_norm': 1.0639606714248657, 'learning_rate': 2.507627118644068e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [2:59:50<2:48:14,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [2:59:53<2:47:40,  3.40s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05188412964344025, 'learning_rate': 2.506779661016949e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [2:59:53<2:47:40,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [2:59:56<2:48:38,  3.42s/it]                                                       {'loss': 0.0744, 'grad_norm': 7.599069595336914, 'learning_rate': 2.505932203389831e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [2:59:56<2:48:38,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [3:00:00<2:49:02,  3.43s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.9885492920875549, 'learning_rate': 2.505084745762712e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [3:00:00<2:49:02,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [3:00:03<2:48:43,  3.43s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13477163016796112, 'learning_rate': 2.5042372881355935e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [3:00:03<2:48:43,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [3:00:07<2:51:25,  3.48s/it]                                                       {'loss': 0.1337, 'grad_norm': 7.768255710601807, 'learning_rate': 2.5033898305084746e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [3:00:07<2:51:25,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [3:00:10<2:49:36,  3.45s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.23297259211540222, 'learning_rate': 2.5025423728813564e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [3:00:10<2:49:36,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [3:00:14<2:52:37,  3.51s/it]                                                       {'loss': 0.0908, 'grad_norm': 3.9705662727355957, 'learning_rate': 2.5016949152542375e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [3:00:14<2:52:37,  3.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [3:00:18<2:56:43,  3.59s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.3445358276367188, 'learning_rate': 2.500847457627119e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [3:00:18<2:56:43,  3.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [3:00:21<2:55:25,  3.57s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03079853765666485, 'learning_rate': 2.5e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [3:00:21<2:55:25,  3.57s/it][2025-10-20 18:30:08,250] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3050
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 6e78aad2-36de-4a84-b8bd-45ca78542a56)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 18:30:18,311] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 6e78aad2-36de-4a84-b8bd-45ca78542a56)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 18:30:18,312] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: d8f23389-a574-4557-b4c9-342fac481897)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 18:30:29,484] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: d8f23389-a574-4557-b4c9-342fac481897)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 18:30:29,486] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [3:00:50<9:00:45, 11.00s/it]                                                       {'loss': 0.4134, 'grad_norm': 11.4994478225708, 'learning_rate': 2.4991525423728816e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [3:00:50<9:00:45, 11.00s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [3:00:53<7:14:12,  8.84s/it]                                                       {'loss': 0.0683, 'grad_norm': 4.77079439163208, 'learning_rate': 2.4983050847457627e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [3:00:53<7:14:12,  8.84s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [3:00:57<5:53:04,  7.19s/it]                                                       {'loss': 0.015, 'grad_norm': 2.365605115890503, 'learning_rate': 2.4974576271186442e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [3:00:57<5:53:04,  7.19s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [3:01:00<4:56:39,  6.04s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.17105154693126678, 'learning_rate': 2.4966101694915257e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [3:01:00<4:56:39,  6.04s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [3:01:04<4:17:59,  5.26s/it]                                                       {'loss': 0.0791, 'grad_norm': 5.7623395919799805, 'learning_rate': 2.495762711864407e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [3:01:04<4:17:59,  5.26s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [3:01:07<3:52:36,  4.74s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.0492314100265503, 'learning_rate': 2.4949152542372882e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [3:01:07<3:52:36,  4.74s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [3:01:10<3:32:46,  4.34s/it]                                                       {'loss': 0.001, 'grad_norm': 0.14374877512454987, 'learning_rate': 2.4940677966101697e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [3:01:10<3:32:46,  4.34s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [3:01:14<3:18:32,  4.05s/it]                                                       {'loss': 0.0324, 'grad_norm': 4.277841091156006, 'learning_rate': 2.4932203389830512e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [3:01:14<3:18:32,  4.05s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [3:01:18<3:18:31,  4.05s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.4772966206073761, 'learning_rate': 2.4923728813559323e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [3:01:18<3:18:31,  4.05s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [3:01:21<3:11:45,  3.91s/it]                                                       {'loss': 0.0445, 'grad_norm': 3.985761880874634, 'learning_rate': 2.4915254237288138e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [3:01:21<3:11:45,  3.91s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [3:01:25<3:04:22,  3.76s/it]                                                       {'loss': 0.0426, 'grad_norm': 4.299961090087891, 'learning_rate': 2.490677966101695e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [3:01:25<3:04:22,  3.76s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [3:01:28<2:58:23,  3.64s/it]                                                       {'loss': 0.0099, 'grad_norm': 0.7907870411872864, 'learning_rate': 2.4898305084745764e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [3:01:28<2:58:23,  3.64s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [3:01:32<2:53:49,  3.55s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.455504894256592, 'learning_rate': 2.4889830508474575e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [3:01:32<2:53:49,  3.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [3:01:35<2:58:16,  3.64s/it]                                                       {'loss': 0.0192, 'grad_norm': 3.5187835693359375, 'learning_rate': 2.488135593220339e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [3:01:35<2:58:16,  3.64s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [3:01:39<2:55:13,  3.58s/it]                                                       {'loss': 0.1622, 'grad_norm': 8.55039119720459, 'learning_rate': 2.4872881355932204e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [3:01:39<2:55:13,  3.58s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [3:01:42<2:52:11,  3.52s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5733188986778259, 'learning_rate': 2.486440677966102e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [3:01:42<2:52:11,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [3:01:46<2:49:09,  3.46s/it]                                                       {'loss': 0.0133, 'grad_norm': 2.409115791320801, 'learning_rate': 2.485593220338983e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [3:01:46<2:49:09,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [3:01:49<2:49:06,  3.46s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.8236004114151001, 'learning_rate': 2.4847457627118645e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [3:01:49<2:49:06,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [3:01:52<2:48:03,  3.44s/it]                                                       {'loss': 0.1113, 'grad_norm': 7.879509449005127, 'learning_rate': 2.483898305084746e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [3:01:52<2:48:03,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [3:01:56<2:46:30,  3.41s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11520031094551086, 'learning_rate': 2.483050847457627e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [3:01:56<2:46:30,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [3:01:59<2:45:09,  3.38s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.766022801399231, 'learning_rate': 2.4822033898305086e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [3:01:59<2:45:09,  3.38s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [3:02:02<2:44:12,  3.36s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.355278491973877, 'learning_rate': 2.48135593220339e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [3:02:02<2:44:12,  3.36s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [3:02:06<2:51:01,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.026480287313461304, 'learning_rate': 2.4805084745762715e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [3:02:06<2:51:01,  3.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [3:02:10<2:51:50,  3.52s/it]                                                       {'loss': 0.3694, 'grad_norm': 10.79096794128418, 'learning_rate': 2.4796610169491526e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [3:02:10<2:51:50,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [3:02:13<2:49:43,  3.48s/it]                                                       {'loss': 0.1726, 'grad_norm': 6.3689141273498535, 'learning_rate': 2.478813559322034e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [3:02:13<2:49:43,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [3:02:17<2:53:37,  3.56s/it]                                                       {'loss': 0.1379, 'grad_norm': 5.485593795776367, 'learning_rate': 2.4779661016949156e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [3:02:17<2:53:37,  3.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [3:02:20<2:50:17,  3.50s/it]                                                       {'loss': 0.0107, 'grad_norm': 2.1469082832336426, 'learning_rate': 2.4771186440677967e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [3:02:20<2:50:17,  3.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [3:02:24<2:47:51,  3.45s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.20873817801475525, 'learning_rate': 2.476271186440678e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [3:02:24<2:47:51,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [3:02:27<2:46:09,  3.41s/it]                                                       {'loss': 0.005, 'grad_norm': 1.1142317056655884, 'learning_rate': 2.4754237288135596e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [3:02:27<2:46:09,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [3:02:30<2:45:47,  3.41s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.480381727218628, 'learning_rate': 2.4745762711864408e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [3:02:30<2:45:47,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [3:02:34<2:46:14,  3.42s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.4886804819107056, 'learning_rate': 2.4737288135593222e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [3:02:34<2:46:14,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [3:02:37<2:46:13,  3.42s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.6329470872879028, 'learning_rate': 2.4728813559322034e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [3:02:37<2:46:13,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [3:02:41<2:47:13,  3.44s/it]                                                       {'loss': 0.0118, 'grad_norm': 0.9321615099906921, 'learning_rate': 2.4720338983050848e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [3:02:41<2:47:13,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [3:02:44<2:46:24,  3.42s/it]                                                       {'loss': 0.0866, 'grad_norm': 6.34553337097168, 'learning_rate': 2.4711864406779663e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [3:02:44<2:46:24,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [3:02:47<2:45:29,  3.41s/it]                                                       {'loss': 0.0635, 'grad_norm': 3.086158037185669, 'learning_rate': 2.4703389830508474e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [3:02:47<2:45:29,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [3:02:51<2:45:14,  3.40s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5198701024055481, 'learning_rate': 2.469491525423729e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [3:02:51<2:45:14,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [3:02:54<2:45:14,  3.40s/it]                                                       {'loss': 0.0233, 'grad_norm': 1.6965278387069702, 'learning_rate': 2.4686440677966103e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [3:02:54<2:45:14,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [3:02:58<2:46:01,  3.42s/it]                                                       {'loss': 0.1676, 'grad_norm': 10.500812530517578, 'learning_rate': 2.4677966101694915e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [3:02:58<2:46:01,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [3:03:01<2:45:26,  3.41s/it]                                                       {'loss': 0.0148, 'grad_norm': 1.9897743463516235, 'learning_rate': 2.466949152542373e-05, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [3:03:01<2:45:26,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [3:03:05<2:47:44,  3.46s/it]                                                       {'loss': 0.0352, 'grad_norm': 4.017725467681885, 'learning_rate': 2.4661016949152544e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [3:03:05<2:47:44,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [3:03:08<2:46:20,  3.43s/it]                                                       {'loss': 0.2887, 'grad_norm': 10.074970245361328, 'learning_rate': 2.4652542372881355e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [3:03:08<2:46:20,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [3:03:11<2:46:33,  3.44s/it]                                                       {'loss': 0.2464, 'grad_norm': 8.829951286315918, 'learning_rate': 2.464406779661017e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [3:03:12<2:46:33,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [3:03:15<2:45:01,  3.41s/it]                                                       {'loss': 0.0678, 'grad_norm': 6.808850288391113, 'learning_rate': 2.4635593220338985e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [3:03:15<2:45:01,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [3:03:19<2:52:15,  3.56s/it]                                                       {'loss': 0.008, 'grad_norm': 0.9984102845191956, 'learning_rate': 2.46271186440678e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [3:03:19<2:52:15,  3.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [3:03:22<2:50:19,  3.52s/it]                                                       {'loss': 0.0956, 'grad_norm': 9.298235893249512, 'learning_rate': 2.461864406779661e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [3:03:22<2:50:19,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [3:03:26<2:47:47,  3.47s/it]                                                       {'loss': 0.0538, 'grad_norm': 5.630800724029541, 'learning_rate': 2.4610169491525425e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [3:03:26<2:47:47,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [3:03:29<2:46:54,  3.45s/it]                                                       {'loss': 0.1419, 'grad_norm': 8.725388526916504, 'learning_rate': 2.460169491525424e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [3:03:29<2:46:54,  3.45s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [3:03:32<2:46:27,  3.44s/it]                                                       {'loss': 0.0159, 'grad_norm': 1.7743016481399536, 'learning_rate': 2.459322033898305e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [3:03:32<2:46:27,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [3:03:36<2:47:58,  3.47s/it]                                                       {'loss': 0.0375, 'grad_norm': 2.464792490005493, 'learning_rate': 2.4584745762711866e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [3:03:36<2:47:58,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [3:03:39<2:46:59,  3.46s/it]                                                       {'loss': 0.0283, 'grad_norm': 4.706053733825684, 'learning_rate': 2.457627118644068e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [3:03:39<2:46:59,  3.46s/it][2025-10-20 18:33:26,299] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [3:03:45<3:21:21,  4.17s/it]                                                       {'loss': 0.0696, 'grad_norm': 3.3771564960479736, 'learning_rate': 2.4567796610169495e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [3:03:45<3:21:21,  4.17s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [3:03:49<3:13:36,  4.01s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.010270307771861553, 'learning_rate': 2.4559322033898303e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [3:03:49<3:13:36,  4.01s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [3:03:52<3:05:53,  3.85s/it]                                                       {'loss': 0.183, 'grad_norm': 9.200944900512695, 'learning_rate': 2.4550847457627118e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [3:03:52<3:05:53,  3.85s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [3:03:56<2:58:37,  3.70s/it]                                                       {'loss': 0.1527, 'grad_norm': 4.856031894683838, 'learning_rate': 2.4542372881355933e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [3:03:56<2:58:37,  3.70s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [3:03:59<2:55:03,  3.63s/it]                                                       {'loss': 0.0587, 'grad_norm': 4.716246128082275, 'learning_rate': 2.4533898305084747e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [3:03:59<2:55:03,  3.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [3:04:03<2:59:21,  3.72s/it]                                                       {'loss': 0.0398, 'grad_norm': 3.620014190673828, 'learning_rate': 2.452542372881356e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [3:04:03<2:59:21,  3.72s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [3:04:06<2:54:13,  3.61s/it]                                                       {'loss': 0.012, 'grad_norm': 2.3288936614990234, 'learning_rate': 2.4516949152542373e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [3:04:06<2:54:13,  3.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [3:04:10<2:50:57,  3.55s/it]                                                       {'loss': 0.0633, 'grad_norm': 6.624823570251465, 'learning_rate': 2.4508474576271188e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [3:04:10<2:50:57,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [3:04:13<2:48:04,  3.49s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.0706284046173096, 'learning_rate': 2.45e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [3:04:13<2:48:04,  3.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [3:04:17<2:47:41,  3.48s/it]                                                       {'loss': 0.0169, 'grad_norm': 3.4826419353485107, 'learning_rate': 2.4491525423728814e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [3:04:17<2:47:41,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [3:04:20<2:46:39,  3.46s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.482724666595459, 'learning_rate': 2.448305084745763e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [3:04:20<2:46:39,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [3:04:24<2:48:10,  3.49s/it]                                                       {'loss': 0.021, 'grad_norm': 2.7895679473876953, 'learning_rate': 2.4474576271186443e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [3:04:24<2:48:10,  3.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [3:04:27<2:45:19,  3.44s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.54965740442276, 'learning_rate': 2.4466101694915255e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [3:04:27<2:45:19,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [3:04:30<2:44:22,  3.42s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.5831159353256226, 'learning_rate': 2.445762711864407e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [3:04:30<2:44:22,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [3:04:34<2:45:21,  3.44s/it]                                                       {'loss': 0.1528, 'grad_norm': 8.165831565856934, 'learning_rate': 2.4449152542372884e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [3:04:34<2:45:21,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [3:04:38<2:50:43,  3.55s/it]                                                       {'loss': 0.0696, 'grad_norm': 5.29226541519165, 'learning_rate': 2.4440677966101695e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [3:04:38<2:50:43,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [3:04:41<2:47:24,  3.48s/it]                                                       {'loss': 0.1002, 'grad_norm': 7.128151893615723, 'learning_rate': 2.443220338983051e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [3:04:41<2:47:24,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [3:04:45<2:51:44,  3.58s/it]                                                       {'loss': 0.0193, 'grad_norm': 3.623687744140625, 'learning_rate': 2.4423728813559324e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [3:04:45<2:51:44,  3.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [3:04:48<2:54:57,  3.64s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6581506133079529, 'learning_rate': 2.441525423728814e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [3:04:48<2:54:57,  3.64s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [3:04:52<2:50:40,  3.56s/it]                                                       {'loss': 0.004, 'grad_norm': 0.5374606251716614, 'learning_rate': 2.440677966101695e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [3:04:52<2:50:40,  3.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [3:04:55<2:48:44,  3.52s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6378817558288574, 'learning_rate': 2.4398305084745765e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [3:04:55<2:48:44,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [3:04:59<2:49:10,  3.53s/it]                                                       {'loss': 0.0278, 'grad_norm': 3.5970420837402344, 'learning_rate': 2.438983050847458e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [3:04:59<2:49:10,  3.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [3:05:02<2:49:22,  3.53s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11647152900695801, 'learning_rate': 2.438135593220339e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [3:05:02<2:49:22,  3.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [3:05:06<2:50:01,  3.55s/it]                                                       {'loss': 0.0177, 'grad_norm': 3.614030122756958, 'learning_rate': 2.4372881355932202e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [3:05:06<2:50:01,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [3:05:09<2:46:44,  3.48s/it]                                                       {'loss': 0.0652, 'grad_norm': 7.702972412109375, 'learning_rate': 2.4364406779661017e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [3:05:09<2:46:44,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [3:05:13<2:44:02,  3.42s/it]                                                       {'loss': 0.1747, 'grad_norm': 6.012762069702148, 'learning_rate': 2.4355932203389832e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [3:05:13<2:44:02,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [3:05:16<2:43:44,  3.42s/it]                                                       {'loss': 0.0605, 'grad_norm': 6.055260181427002, 'learning_rate': 2.4347457627118643e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [3:05:16<2:43:44,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [3:05:19<2:44:04,  3.43s/it]                                                       {'loss': 0.0195, 'grad_norm': 2.104048490524292, 'learning_rate': 2.4338983050847458e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [3:05:19<2:44:04,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [3:05:23<2:50:24,  3.56s/it]                                                       {'loss': 0.0082, 'grad_norm': 2.0588696002960205, 'learning_rate': 2.4330508474576272e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [3:05:23<2:50:24,  3.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [3:05:27<2:47:25,  3.50s/it]                                                       {'loss': 0.0496, 'grad_norm': 5.251170635223389, 'learning_rate': 2.4322033898305087e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [3:05:27<2:47:25,  3.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [3:05:30<2:45:49,  3.47s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5269795060157776, 'learning_rate': 2.43135593220339e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [3:05:30<2:45:49,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [3:05:33<2:42:58,  3.41s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3251091539859772, 'learning_rate': 2.4305084745762713e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [3:05:33<2:42:58,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [3:05:37<2:41:45,  3.39s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4581056535243988, 'learning_rate': 2.4296610169491528e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [3:05:37<2:41:45,  3.39s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [3:05:40<2:47:15,  3.50s/it]                                                       {'loss': 0.1912, 'grad_norm': 9.967921257019043, 'learning_rate': 2.428813559322034e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [3:05:40<2:47:15,  3.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [3:05:44<2:47:33,  3.51s/it]                                                       {'loss': 0.0576, 'grad_norm': 4.9247260093688965, 'learning_rate': 2.4279661016949154e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [3:05:44<2:47:33,  3.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [3:05:47<2:47:43,  3.51s/it]                                                       {'loss': 0.1896, 'grad_norm': 5.664013862609863, 'learning_rate': 2.4271186440677968e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [3:05:47<2:47:43,  3.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [3:05:51<2:45:24,  3.47s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4478071630001068, 'learning_rate': 2.4262711864406783e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [3:05:51<2:45:24,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [3:05:54<2:47:13,  3.51s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.4013209342956543, 'learning_rate': 2.4254237288135594e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [3:05:54<2:47:13,  3.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [3:05:58<2:44:45,  3.46s/it]                                                       {'loss': 0.0882, 'grad_norm': 6.741422176361084, 'learning_rate': 2.424576271186441e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [3:05:58<2:44:45,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [3:06:01<2:42:25,  3.41s/it]                                                       {'loss': 0.0343, 'grad_norm': 2.415487051010132, 'learning_rate': 2.4237288135593224e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [3:06:01<2:42:25,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [3:06:04<2:42:10,  3.40s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.0763236284255981, 'learning_rate': 2.4228813559322035e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [3:06:04<2:42:10,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [3:06:08<2:41:50,  3.40s/it]                                                       {'loss': 0.011, 'grad_norm': 1.2291051149368286, 'learning_rate': 2.422033898305085e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [3:06:08<2:41:50,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [3:06:11<2:41:34,  3.39s/it]                                                       {'loss': 0.1886, 'grad_norm': 9.591412544250488, 'learning_rate': 2.4211864406779664e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [3:06:11<2:41:34,  3.39s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [3:06:15<2:40:55,  3.38s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.017860379070043564, 'learning_rate': 2.4203389830508476e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [3:06:15<2:40:55,  3.38s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [3:06:18<2:41:37,  3.40s/it]                                                       {'loss': 0.0182, 'grad_norm': 2.5889065265655518, 'learning_rate': 2.4194915254237287e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [3:06:18<2:41:37,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [3:06:21<2:41:02,  3.39s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.517559289932251, 'learning_rate': 2.41864406779661e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [3:06:21<2:41:02,  3.39s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [3:06:25<2:40:34,  3.38s/it]                                                       {'loss': 0.1514, 'grad_norm': 6.9181623458862305, 'learning_rate': 2.4177966101694916e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [3:06:25<2:40:34,  3.38s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [3:06:28<2:40:41,  3.38s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.13874715566635132, 'learning_rate': 2.416949152542373e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [3:06:28<2:40:41,  3.38s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [3:06:32<2:42:52,  3.43s/it]                                                       {'loss': 0.0517, 'grad_norm': 4.582619667053223, 'learning_rate': 2.4161016949152542e-05, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [3:06:32<2:42:52,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [3:06:35<2:41:23,  3.40s/it]                                                       {'loss': 0.2041, 'grad_norm': 6.476958751678467, 'learning_rate': 2.4152542372881357e-05, 'epoch': 0.53}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [3:06:35<2:41:23,  3.40s/it][2025-10-20 18:36:21,934] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [3:06:41<3:14:51,  4.10s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3684879243373871, 'learning_rate': 2.414406779661017e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [3:06:41<3:14:51,  4.10s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [3:06:44<3:04:43,  3.89s/it]                                                       {'loss': 0.0623, 'grad_norm': 6.090116024017334, 'learning_rate': 2.4135593220338983e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [3:06:44<3:04:43,  3.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [3:06:47<2:56:16,  3.72s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6449984908103943, 'learning_rate': 2.4127118644067797e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [3:06:47<2:56:16,  3.72s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [3:06:51<2:51:16,  3.61s/it]                                                       {'loss': 0.002, 'grad_norm': 0.36365142464637756, 'learning_rate': 2.4118644067796612e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [3:06:51<2:51:16,  3.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [3:06:54<2:47:11,  3.53s/it]                                                       {'loss': 0.1304, 'grad_norm': 6.168497562408447, 'learning_rate': 2.4110169491525423e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [3:06:54<2:47:11,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [3:06:57<2:45:10,  3.48s/it]                                                       {'loss': 0.0583, 'grad_norm': 5.09925651550293, 'learning_rate': 2.4101694915254238e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [3:06:57<2:45:10,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [3:07:01<2:45:45,  3.50s/it]                                                       {'loss': 0.0559, 'grad_norm': 2.537580728530884, 'learning_rate': 2.4093220338983053e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [3:07:01<2:45:45,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [3:07:04<2:44:30,  3.47s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.9116055369377136, 'learning_rate': 2.4084745762711867e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [3:07:04<2:44:30,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [3:07:08<2:43:37,  3.46s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.13641992211341858, 'learning_rate': 2.407627118644068e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [3:07:08<2:43:37,  3.46s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [3:07:12<2:47:33,  3.54s/it]                                                       {'loss': 0.0195, 'grad_norm': 3.3763647079467773, 'learning_rate': 2.4067796610169493e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [3:07:12<2:47:33,  3.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [3:07:15<2:47:30,  3.54s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07914625853300095, 'learning_rate': 2.4059322033898308e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [3:07:15<2:47:30,  3.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [3:07:19<2:45:45,  3.50s/it]                                                       {'loss': 0.1054, 'grad_norm': 9.114198684692383, 'learning_rate': 2.405084745762712e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [3:07:19<2:45:45,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [3:07:22<2:44:26,  3.48s/it]                                                       {'loss': 0.0346, 'grad_norm': 4.951172351837158, 'learning_rate': 2.4042372881355934e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [3:07:22<2:44:26,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [3:07:26<2:48:40,  3.57s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5242205262184143, 'learning_rate': 2.403389830508475e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [3:07:26<2:48:40,  3.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [3:07:29<2:45:58,  3.51s/it]                                                       {'loss': 0.0847, 'grad_norm': 4.894824504852295, 'learning_rate': 2.402542372881356e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [3:07:29<2:45:58,  3.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [3:07:33<2:47:08,  3.54s/it]                                                       {'loss': 0.0245, 'grad_norm': 3.763552665710449, 'learning_rate': 2.401694915254237e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [3:07:33<2:47:08,  3.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [3:07:36<2:44:15,  3.48s/it]                                                       {'loss': 0.2009, 'grad_norm': 7.2764506340026855, 'learning_rate': 2.4008474576271186e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [3:07:36<2:44:15,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [3:07:40<2:47:24,  3.55s/it]                                                       {'loss': 0.0926, 'grad_norm': 6.467696189880371, 'learning_rate': 2.4e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [3:07:40<2:47:24,  3.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [3:07:43<2:44:25,  3.48s/it]                                                       {'loss': 0.061, 'grad_norm': 4.8969645500183105, 'learning_rate': 2.3991525423728815e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [3:07:43<2:44:25,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [3:07:47<2:44:50,  3.49s/it]                                                       {'loss': 0.0145, 'grad_norm': 1.552030086517334, 'learning_rate': 2.3983050847457627e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [3:07:47<2:44:50,  3.49s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [3:07:50<2:48:47,  3.58s/it]                                                       {'loss': 0.093, 'grad_norm': 8.677571296691895, 'learning_rate': 2.397457627118644e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [3:07:50<2:48:47,  3.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [3:07:54<2:52:54,  3.67s/it]                                                       {'loss': 0.002, 'grad_norm': 0.1786845475435257, 'learning_rate': 2.3966101694915256e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [3:07:54<2:52:54,  3.67s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [3:07:58<2:54:13,  3.70s/it]                                                       {'loss': 0.0443, 'grad_norm': 3.1286094188690186, 'learning_rate': 2.3957627118644067e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [3:07:58<2:54:13,  3.70s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [3:08:01<2:50:45,  3.63s/it]                                                       {'loss': 0.2518, 'grad_norm': 6.2548723220825195, 'learning_rate': 2.3949152542372882e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [3:08:01<2:50:45,  3.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [3:08:05<2:49:20,  3.60s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.5696567296981812, 'learning_rate': 2.3940677966101697e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [3:08:05<2:49:20,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [3:08:09<2:49:28,  3.60s/it]                                                       {'loss': 0.005, 'grad_norm': 0.8626620173454285, 'learning_rate': 2.393220338983051e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [3:08:09<2:49:28,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [3:08:12<2:47:10,  3.55s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07669015228748322, 'learning_rate': 2.3923728813559323e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [3:08:12<2:47:10,  3.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [3:08:16<2:49:25,  3.60s/it]                                                       {'loss': 0.0336, 'grad_norm': 3.3153772354125977, 'learning_rate': 2.3915254237288137e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [3:08:16<2:49:25,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [3:08:19<2:46:32,  3.54s/it]                                                       {'loss': 0.0183, 'grad_norm': 2.2227911949157715, 'learning_rate': 2.3906779661016952e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [3:08:19<2:46:32,  3.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [3:08:23<2:45:10,  3.51s/it]                                                       {'loss': 0.0297, 'grad_norm': 3.8967947959899902, 'learning_rate': 2.3898305084745763e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [3:08:23<2:45:10,  3.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [3:08:26<2:44:19,  3.50s/it]                                                       {'loss': 0.0949, 'grad_norm': 6.841564655303955, 'learning_rate': 2.3889830508474578e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [3:08:26<2:44:19,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [3:08:29<2:42:21,  3.46s/it]                                                       {'loss': 0.1429, 'grad_norm': 8.825873374938965, 'learning_rate': 2.3881355932203392e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [3:08:29<2:42:21,  3.46s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [3:08:33<2:41:25,  3.44s/it]                                                       {'loss': 0.1294, 'grad_norm': 7.324151515960693, 'learning_rate': 2.3872881355932207e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [3:08:33<2:41:25,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [3:08:37<2:45:08,  3.52s/it]                                                       {'loss': 0.0231, 'grad_norm': 1.4149972200393677, 'learning_rate': 2.386440677966102e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [3:08:37<2:45:08,  3.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [3:08:40<2:42:28,  3.46s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2147730141878128, 'learning_rate': 2.3855932203389833e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [3:08:40<2:42:28,  3.46s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [3:08:43<2:44:04,  3.50s/it]                                                       {'loss': 0.0194, 'grad_norm': 3.04938006401062, 'learning_rate': 2.3847457627118644e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [3:08:43<2:44:04,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [3:08:47<2:42:41,  3.47s/it]                                                       {'loss': 0.0185, 'grad_norm': 2.5693349838256836, 'learning_rate': 2.383898305084746e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [3:08:47<2:42:41,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [3:08:50<2:42:27,  3.47s/it]                                                       {'loss': 0.1463, 'grad_norm': 7.675739288330078, 'learning_rate': 2.383050847457627e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [3:08:50<2:42:27,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [3:08:54<2:42:29,  3.47s/it]                                                       {'loss': 0.0417, 'grad_norm': 6.677620887756348, 'learning_rate': 2.3822033898305085e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [3:08:54<2:42:29,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [3:08:58<2:50:19,  3.64s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.9521805047988892, 'learning_rate': 2.38135593220339e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [3:08:58<2:50:19,  3.64s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [3:09:01<2:48:14,  3.59s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.9838826656341553, 'learning_rate': 2.380508474576271e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [3:09:01<2:48:14,  3.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [3:09:05<2:44:18,  3.51s/it]                                                       {'loss': 0.0843, 'grad_norm': 6.3719329833984375, 'learning_rate': 2.3796610169491526e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [3:09:05<2:44:18,  3.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [3:09:08<2:42:18,  3.47s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.027465322986245155, 'learning_rate': 2.378813559322034e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [3:09:08<2:42:18,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [3:09:11<2:41:09,  3.45s/it]                                                       {'loss': 0.0989, 'grad_norm': 6.443478107452393, 'learning_rate': 2.3779661016949155e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [3:09:11<2:41:09,  3.45s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [3:09:15<2:39:25,  3.41s/it]                                                       {'loss': 0.0208, 'grad_norm': 3.372607707977295, 'learning_rate': 2.3771186440677966e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [3:09:15<2:39:25,  3.41s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [3:09:18<2:37:58,  3.38s/it]                                                       {'loss': 0.1584, 'grad_norm': 6.451199531555176, 'learning_rate': 2.376271186440678e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [3:09:18<2:37:58,  3.38s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [3:09:21<2:38:20,  3.39s/it]                                                       {'loss': 0.0595, 'grad_norm': 9.8040189743042, 'learning_rate': 2.3754237288135596e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [3:09:21<2:38:20,  3.39s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [3:09:25<2:37:38,  3.38s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.8837162256240845, 'learning_rate': 2.3745762711864407e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [3:09:25<2:37:38,  3.38s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [3:09:28<2:38:41,  3.40s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.1372907161712646, 'learning_rate': 2.373728813559322e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [3:09:28<2:38:41,  3.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [3:09:32<2:38:52,  3.40s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5545406937599182, 'learning_rate': 2.3728813559322036e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [3:09:32<2:38:52,  3.40s/it][2025-10-20 18:39:18,669] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [3:09:37<3:12:37,  4.13s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.8365591764450073, 'learning_rate': 2.372033898305085e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [3:09:37<3:12:37,  4.13s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [3:09:41<3:01:31,  3.89s/it]                                                       {'loss': 0.0424, 'grad_norm': 4.781258583068848, 'learning_rate': 2.3711864406779662e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [3:09:41<3:01:31,  3.89s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [3:09:44<2:53:57,  3.73s/it]                                                       {'loss': 0.0746, 'grad_norm': 6.881582736968994, 'learning_rate': 2.3703389830508477e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [3:09:44<2:53:57,  3.73s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [3:09:48<2:48:06,  3.61s/it]                                                       {'loss': 0.0662, 'grad_norm': 4.855103492736816, 'learning_rate': 2.369491525423729e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [3:09:48<2:48:06,  3.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [3:09:51<2:45:30,  3.55s/it]                                                       {'loss': 0.036, 'grad_norm': 2.8056697845458984, 'learning_rate': 2.3686440677966103e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [3:09:51<2:45:30,  3.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [3:09:55<2:52:43,  3.71s/it]                                                       {'loss': 0.0279, 'grad_norm': 3.076237440109253, 'learning_rate': 2.3677966101694914e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [3:09:55<2:52:43,  3.71s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [3:09:58<2:48:05,  3.61s/it]                                                       {'loss': 0.005, 'grad_norm': 0.679583728313446, 'learning_rate': 2.366949152542373e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [3:09:58<2:48:05,  3.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [3:10:02<2:47:25,  3.60s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.314275860786438, 'learning_rate': 2.3661016949152544e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [3:10:02<2:47:25,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [3:10:05<2:45:51,  3.57s/it]                                                       {'loss': 0.0373, 'grad_norm': 4.570826530456543, 'learning_rate': 2.3652542372881355e-05, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [3:10:05<2:45:51,  3.57s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [3:10:09<2:44:02,  3.53s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09970447421073914, 'learning_rate': 2.364406779661017e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [3:10:09<2:44:02,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [3:10:12<2:42:39,  3.50s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9743207097053528, 'learning_rate': 2.3635593220338984e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [3:10:12<2:42:39,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [3:10:16<2:40:21,  3.45s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.28274041414260864, 'learning_rate': 2.36271186440678e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [3:10:16<2:40:21,  3.45s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [3:10:19<2:43:11,  3.51s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4328882098197937, 'learning_rate': 2.361864406779661e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [3:10:19<2:43:11,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [3:10:23<2:41:47,  3.48s/it]                                                       {'loss': 0.0449, 'grad_norm': 1.0474849939346313, 'learning_rate': 2.3610169491525425e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [3:10:23<2:41:47,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [3:10:27<2:46:48,  3.59s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.7405291199684143, 'learning_rate': 2.360169491525424e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [3:10:27<2:46:48,  3.59s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [3:10:30<2:43:26,  3.52s/it]                                                       {'loss': 0.0686, 'grad_norm': 9.592020988464355, 'learning_rate': 2.359322033898305e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [3:10:30<2:43:26,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [3:10:33<2:43:05,  3.52s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.9607078433036804, 'learning_rate': 2.3584745762711865e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [3:10:33<2:43:05,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [3:10:37<2:41:42,  3.49s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0400191992521286, 'learning_rate': 2.357627118644068e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [3:10:37<2:41:42,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [3:10:40<2:40:15,  3.46s/it]                                                       {'loss': 0.0114, 'grad_norm': 1.3817980289459229, 'learning_rate': 2.356779661016949e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [3:10:40<2:40:15,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [3:10:44<2:37:56,  3.41s/it]                                                       {'loss': 0.1481, 'grad_norm': 8.973639488220215, 'learning_rate': 2.3559322033898306e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [3:10:44<2:37:56,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [3:10:47<2:36:41,  3.38s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.7346333861351013, 'learning_rate': 2.355084745762712e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [3:10:47<2:36:41,  3.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [3:10:50<2:36:21,  3.38s/it]                                                       {'loss': 0.0162, 'grad_norm': 1.8312032222747803, 'learning_rate': 2.3542372881355935e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [3:10:50<2:36:21,  3.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [3:10:54<2:36:28,  3.38s/it]                                                       {'loss': 0.0652, 'grad_norm': 6.111084461212158, 'learning_rate': 2.3533898305084747e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [3:10:54<2:36:28,  3.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [3:10:57<2:39:11,  3.44s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.01337460521608591, 'learning_rate': 2.352542372881356e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [3:10:57<2:39:11,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [3:11:01<2:37:14,  3.40s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.05056564509868622, 'learning_rate': 2.3516949152542376e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [3:11:01<2:37:14,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [3:11:04<2:37:45,  3.41s/it]                                                       {'loss': 0.1008, 'grad_norm': 11.11180591583252, 'learning_rate': 2.3508474576271187e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [3:11:04<2:37:45,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [3:11:07<2:37:17,  3.40s/it]                                                       {'loss': 0.003, 'grad_norm': 0.256924569606781, 'learning_rate': 2.35e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [3:11:07<2:37:17,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [3:11:11<2:37:45,  3.41s/it]                                                       {'loss': 0.1844, 'grad_norm': 8.56352710723877, 'learning_rate': 2.3491525423728813e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [3:11:11<2:37:45,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [3:11:14<2:37:02,  3.40s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.7753287553787231, 'learning_rate': 2.3483050847457628e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [3:11:14<2:37:02,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [3:11:18<2:37:55,  3.42s/it]                                                       {'loss': 0.0925, 'grad_norm': 9.022920608520508, 'learning_rate': 2.347457627118644e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [3:11:18<2:37:55,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [3:11:21<2:36:52,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025270193815231323, 'learning_rate': 2.3466101694915254e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [3:11:21<2:36:52,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [3:11:24<2:38:03,  3.43s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.033008575439453, 'learning_rate': 2.345762711864407e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [3:11:24<2:38:03,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [3:11:28<2:37:17,  3.41s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.39143890142440796, 'learning_rate': 2.3449152542372883e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [3:11:28<2:37:17,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [3:11:31<2:36:31,  3.40s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.4473240375518799, 'learning_rate': 2.3440677966101695e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [3:11:31<2:36:31,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [3:11:35<2:36:04,  3.39s/it]                                                       {'loss': 0.4791, 'grad_norm': 8.611571311950684, 'learning_rate': 2.343220338983051e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [3:11:35<2:36:04,  3.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [3:11:38<2:38:39,  3.44s/it]                                                       {'loss': 0.132, 'grad_norm': 5.738773345947266, 'learning_rate': 2.3423728813559324e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [3:11:38<2:38:39,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [3:11:41<2:37:12,  3.41s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.47129595279693604, 'learning_rate': 2.3415254237288135e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [3:11:41<2:37:12,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [3:11:45<2:41:46,  3.51s/it]                                                       {'loss': 0.0252, 'grad_norm': 1.722520112991333, 'learning_rate': 2.340677966101695e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [3:11:45<2:41:46,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [3:11:49<2:42:24,  3.53s/it]                                                       {'loss': 0.0656, 'grad_norm': 7.748401165008545, 'learning_rate': 2.3398305084745765e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [3:11:49<2:42:24,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [3:11:52<2:40:40,  3.49s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.39136508107185364, 'learning_rate': 2.338983050847458e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [3:11:52<2:40:40,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [3:11:56<2:39:35,  3.47s/it]                                                       {'loss': 0.1352, 'grad_norm': 9.836703300476074, 'learning_rate': 2.338135593220339e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [3:11:56<2:39:35,  3.47s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [3:11:59<2:41:00,  3.50s/it]                                                       {'loss': 0.0252, 'grad_norm': 4.311038494110107, 'learning_rate': 2.3372881355932205e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [3:11:59<2:41:00,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [3:12:03<2:40:00,  3.48s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5631648898124695, 'learning_rate': 2.336440677966102e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [3:12:03<2:40:00,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [3:12:07<2:53:25,  3.78s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.10345014184713364, 'learning_rate': 2.335593220338983e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [3:12:07<2:53:25,  3.78s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [3:12:11<2:50:37,  3.72s/it]                                                       {'loss': 0.0126, 'grad_norm': 0.909081757068634, 'learning_rate': 2.3347457627118646e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [3:12:11<2:50:37,  3.72s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [3:12:14<2:47:15,  3.64s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.5275523066520691, 'learning_rate': 2.333898305084746e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [3:12:14<2:47:15,  3.64s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [3:12:17<2:42:42,  3.55s/it]                                                       {'loss': 0.0273, 'grad_norm': 3.140570878982544, 'learning_rate': 2.3330508474576275e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [3:12:17<2:42:42,  3.55s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [3:12:21<2:41:33,  3.52s/it]                                                       {'loss': 0.1426, 'grad_norm': 7.6962456703186035, 'learning_rate': 2.3322033898305083e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [3:12:21<2:41:33,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [3:12:24<2:39:43,  3.48s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07181177288293839, 'learning_rate': 2.3313559322033898e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [3:12:24<2:39:43,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [3:12:28<2:37:52,  3.44s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.9468705058097839, 'learning_rate': 2.3305084745762712e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [3:12:28<2:37:52,  3.44s/it][2025-10-20 18:42:14,657] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [3:12:34<3:10:52,  4.17s/it]                                                       {'loss': 0.0202, 'grad_norm': 1.4538066387176514, 'learning_rate': 2.3296610169491527e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [3:12:34<3:10:52,  4.17s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [3:12:37<2:59:35,  3.92s/it]                                                       {'loss': 0.015, 'grad_norm': 3.0384788513183594, 'learning_rate': 2.328813559322034e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [3:12:37<2:59:35,  3.92s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [3:12:40<2:52:43,  3.77s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.4808549880981445, 'learning_rate': 2.3279661016949153e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [3:12:40<2:52:43,  3.77s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [3:12:44<2:49:48,  3.71s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.7655802965164185, 'learning_rate': 2.3271186440677968e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [3:12:44<2:49:48,  3.71s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [3:12:47<2:45:32,  3.62s/it]                                                       {'loss': 0.0447, 'grad_norm': 4.809080600738525, 'learning_rate': 2.326271186440678e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [3:12:47<2:45:32,  3.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [3:12:51<2:42:05,  3.54s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.04147038981318474, 'learning_rate': 2.3254237288135594e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [3:12:51<2:42:05,  3.54s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [3:12:55<2:47:55,  3.67s/it]                                                       {'loss': 0.0618, 'grad_norm': 4.0715460777282715, 'learning_rate': 2.324576271186441e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [3:12:55<2:47:55,  3.67s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [3:12:58<2:44:40,  3.60s/it]                                                       {'loss': 0.1062, 'grad_norm': 8.933119773864746, 'learning_rate': 2.3237288135593223e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [3:12:58<2:44:40,  3.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [3:13:02<2:43:50,  3.59s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.19411681592464447, 'learning_rate': 2.3228813559322034e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [3:13:02<2:43:50,  3.59s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [3:13:05<2:46:34,  3.65s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.7560532689094543, 'learning_rate': 2.322033898305085e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [3:13:05<2:46:34,  3.65s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [3:13:09<2:43:37,  3.58s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05112934485077858, 'learning_rate': 2.3211864406779664e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [3:13:09<2:43:37,  3.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [3:13:12<2:41:27,  3.54s/it]                                                       {'loss': 0.0592, 'grad_norm': 2.6156179904937744, 'learning_rate': 2.3203389830508475e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [3:13:12<2:41:27,  3.54s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [3:13:16<2:39:02,  3.49s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.3229644298553467, 'learning_rate': 2.319491525423729e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [3:13:16<2:39:02,  3.49s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [3:13:19<2:37:41,  3.46s/it]                                                       {'loss': 0.0216, 'grad_norm': 3.4817705154418945, 'learning_rate': 2.3186440677966104e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [3:13:19<2:37:41,  3.46s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [3:13:22<2:36:35,  3.44s/it]                                                       {'loss': 0.1155, 'grad_norm': 7.07638692855835, 'learning_rate': 2.317796610169492e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [3:13:22<2:36:35,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [3:13:26<2:35:42,  3.42s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.38169872760772705, 'learning_rate': 2.316949152542373e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [3:13:26<2:35:42,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [3:13:29<2:35:12,  3.41s/it]                                                       {'loss': 0.0207, 'grad_norm': 1.633779525756836, 'learning_rate': 2.3161016949152545e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [3:13:29<2:35:12,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [3:13:33<2:35:04,  3.41s/it]                                                       {'loss': 0.3302, 'grad_norm': 12.978738784790039, 'learning_rate': 2.315254237288136e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [3:13:33<2:35:04,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [3:13:36<2:34:34,  3.40s/it]                                                       {'loss': 0.1222, 'grad_norm': 7.026741027832031, 'learning_rate': 2.314406779661017e-05, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [3:13:36<2:34:34,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [3:13:39<2:37:03,  3.45s/it]                                                       {'loss': 0.108, 'grad_norm': 7.169541358947754, 'learning_rate': 2.3135593220338982e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [3:13:40<2:37:03,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [3:13:43<2:36:42,  3.45s/it]                                                       {'loss': 0.0419, 'grad_norm': 4.2465901374816895, 'learning_rate': 2.3127118644067797e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [3:13:43<2:36:42,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [3:13:46<2:36:12,  3.44s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5160298943519592, 'learning_rate': 2.311864406779661e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [3:13:46<2:36:12,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [3:13:50<2:40:38,  3.53s/it]                                                       {'loss': 0.0567, 'grad_norm': 3.8982155323028564, 'learning_rate': 2.3110169491525423e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [3:13:50<2:40:38,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [3:13:54<2:38:48,  3.50s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.461225152015686, 'learning_rate': 2.3101694915254237e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [3:13:54<2:38:48,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [3:13:57<2:42:47,  3.58s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3450464904308319, 'learning_rate': 2.3093220338983052e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [3:13:57<2:42:47,  3.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [3:14:01<2:40:40,  3.54s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.069463349878788, 'learning_rate': 2.3084745762711867e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [3:14:01<2:40:40,  3.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [3:14:04<2:37:35,  3.47s/it]                                                       {'loss': 0.0533, 'grad_norm': 3.9931681156158447, 'learning_rate': 2.3076271186440678e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [3:14:04<2:37:35,  3.47s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [3:14:07<2:36:05,  3.44s/it]                                                       {'loss': 0.1126, 'grad_norm': 3.4496049880981445, 'learning_rate': 2.3067796610169493e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [3:14:07<2:36:05,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [3:14:11<2:43:08,  3.60s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.6472891569137573, 'learning_rate': 2.3059322033898307e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [3:14:11<2:43:08,  3.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [3:14:15<2:40:07,  3.53s/it]                                                       {'loss': 0.0534, 'grad_norm': 5.4570746421813965, 'learning_rate': 2.305084745762712e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [3:14:15<2:40:07,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [3:14:18<2:38:48,  3.50s/it]                                                       {'loss': 0.0888, 'grad_norm': 6.281309127807617, 'learning_rate': 2.3042372881355933e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [3:14:18<2:38:48,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [3:14:22<2:39:59,  3.53s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.885319471359253, 'learning_rate': 2.3033898305084748e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [3:14:22<2:39:59,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [3:14:25<2:38:58,  3.51s/it]                                                       {'loss': 0.1684, 'grad_norm': 6.974011421203613, 'learning_rate': 2.302542372881356e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [3:14:25<2:38:58,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [3:14:29<2:37:45,  3.48s/it]                                                       {'loss': 0.0566, 'grad_norm': 5.264792442321777, 'learning_rate': 2.3016949152542374e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [3:14:29<2:37:45,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [3:14:32<2:35:52,  3.44s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.13562169671058655, 'learning_rate': 2.300847457627119e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [3:14:32<2:35:52,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [3:14:36<2:40:11,  3.54s/it]                                                       {'loss': 0.015, 'grad_norm': 1.9132505655288696, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [3:14:36<2:40:11,  3.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [3:14:39<2:39:20,  3.52s/it]                                                       {'loss': 0.0576, 'grad_norm': 4.084568500518799, 'learning_rate': 2.2991525423728815e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [3:14:39<2:39:20,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [3:14:43<2:37:22,  3.48s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.972053050994873, 'learning_rate': 2.298305084745763e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [3:14:43<2:37:22,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [3:14:46<2:35:10,  3.43s/it]                                                       {'loss': 0.0204, 'grad_norm': 2.5156233310699463, 'learning_rate': 2.297457627118644e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [3:14:46<2:35:10,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [3:14:49<2:34:38,  3.42s/it]                                                       {'loss': 0.2429, 'grad_norm': 7.271609783172607, 'learning_rate': 2.2966101694915255e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [3:14:49<2:34:38,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [3:14:53<2:37:22,  3.49s/it]                                                       {'loss': 0.0163, 'grad_norm': 2.156578779220581, 'learning_rate': 2.2957627118644067e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [3:14:53<2:37:22,  3.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [3:14:56<2:37:05,  3.48s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.5922917723655701, 'learning_rate': 2.294915254237288e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [3:14:56<2:37:05,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [3:15:00<2:36:02,  3.46s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.7879183292388916, 'learning_rate': 2.2940677966101696e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [3:15:00<2:36:02,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [3:15:03<2:35:14,  3.44s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.1439521312713623, 'learning_rate': 2.2932203389830507e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [3:15:03<2:35:14,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [3:15:07<2:35:35,  3.45s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5098556876182556, 'learning_rate': 2.2923728813559322e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [3:15:07<2:35:35,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [3:15:10<2:34:24,  3.43s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.5705332159996033, 'learning_rate': 2.2915254237288137e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [3:15:10<2:34:24,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [3:15:13<2:32:38,  3.39s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06773319840431213, 'learning_rate': 2.290677966101695e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [3:15:13<2:32:38,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [3:15:17<2:33:57,  3.42s/it]                                                       {'loss': 0.0594, 'grad_norm': 6.034124374389648, 'learning_rate': 2.2898305084745763e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [3:15:17<2:33:57,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [3:15:20<2:33:06,  3.40s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04786582663655281, 'learning_rate': 2.2889830508474577e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [3:15:20<2:33:06,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [3:15:24<2:33:32,  3.41s/it]                                                       {'loss': 0.0458, 'grad_norm': 4.207699298858643, 'learning_rate': 2.2881355932203392e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [3:15:24<2:33:32,  3.41s/it][2025-10-20 18:45:10,730] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [3:15:29<3:04:55,  4.11s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.780859112739563, 'learning_rate': 2.2872881355932203e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [3:15:29<3:04:55,  4.11s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [3:15:33<2:54:06,  3.87s/it]                                                       {'loss': 0.0472, 'grad_norm': 3.258124828338623, 'learning_rate': 2.2864406779661018e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [3:15:33<2:54:06,  3.87s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [3:15:36<2:47:10,  3.72s/it]                                                       {'loss': 0.0419, 'grad_norm': 4.384952068328857, 'learning_rate': 2.2855932203389833e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [3:15:36<2:47:10,  3.72s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [3:15:39<2:41:33,  3.60s/it]                                                       {'loss': 0.0181, 'grad_norm': 2.4669225215911865, 'learning_rate': 2.2847457627118647e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [3:15:39<2:41:33,  3.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [3:15:43<2:38:03,  3.52s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.43641698360443115, 'learning_rate': 2.283898305084746e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [3:15:43<2:38:03,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [3:15:46<2:36:05,  3.48s/it]                                                       {'loss': 0.1942, 'grad_norm': 10.293916702270508, 'learning_rate': 2.2830508474576273e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [3:15:46<2:36:05,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [3:15:49<2:33:36,  3.42s/it]                                                       {'loss': 0.2743, 'grad_norm': 7.193727970123291, 'learning_rate': 2.2822033898305088e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [3:15:49<2:33:36,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [3:15:53<2:31:47,  3.38s/it]                                                       {'loss': 0.008, 'grad_norm': 1.3053940534591675, 'learning_rate': 2.28135593220339e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [3:15:53<2:31:47,  3.38s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [3:15:56<2:32:37,  3.40s/it]                                                       {'loss': 0.0264, 'grad_norm': 4.1983323097229, 'learning_rate': 2.2805084745762714e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [3:15:56<2:32:37,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [3:16:00<2:32:50,  3.41s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5824532508850098, 'learning_rate': 2.2796610169491525e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [3:16:00<2:32:50,  3.41s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [3:16:03<2:32:57,  3.41s/it]                                                       {'loss': 0.1563, 'grad_norm': 6.463088035583496, 'learning_rate': 2.278813559322034e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [3:16:03<2:32:57,  3.41s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [3:16:07<2:33:47,  3.43s/it]                                                       {'loss': 0.0372, 'grad_norm': 2.992814779281616, 'learning_rate': 2.277966101694915e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [3:16:07<2:33:47,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [3:16:10<2:31:56,  3.39s/it]                                                       {'loss': 0.0848, 'grad_norm': 8.464670181274414, 'learning_rate': 2.2771186440677966e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [3:16:10<2:31:56,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [3:16:14<2:37:47,  3.52s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.44920387864112854, 'learning_rate': 2.276271186440678e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [3:16:14<2:37:47,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [3:16:17<2:37:12,  3.51s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.3365278244018555, 'learning_rate': 2.2754237288135595e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [3:16:17<2:37:12,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [3:16:20<2:33:53,  3.44s/it]                                                       {'loss': 0.0288, 'grad_norm': 3.4289917945861816, 'learning_rate': 2.2745762711864406e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [3:16:20<2:33:53,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [3:16:24<2:31:22,  3.39s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.23479141294956207, 'learning_rate': 2.273728813559322e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [3:16:24<2:31:22,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [3:16:27<2:31:36,  3.39s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.3711417615413666, 'learning_rate': 2.2728813559322036e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [3:16:27<2:31:36,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [3:16:31<2:33:09,  3.43s/it]                                                       {'loss': 0.0374, 'grad_norm': 5.599287033081055, 'learning_rate': 2.2720338983050847e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [3:16:31<2:33:09,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [3:16:34<2:33:29,  3.44s/it]                                                       {'loss': 0.3583, 'grad_norm': 12.748587608337402, 'learning_rate': 2.271186440677966e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [3:16:34<2:33:29,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [3:16:37<2:33:05,  3.43s/it]                                                       {'loss': 0.2863, 'grad_norm': 10.062997817993164, 'learning_rate': 2.2703389830508476e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [3:16:37<2:33:05,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [3:16:41<2:33:10,  3.43s/it]                                                       {'loss': 0.0231, 'grad_norm': 4.525711536407471, 'learning_rate': 2.269491525423729e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [3:16:41<2:33:10,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [3:16:44<2:33:39,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.027204908430576324, 'learning_rate': 2.2686440677966102e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [3:16:44<2:33:39,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [3:16:48<2:33:31,  3.44s/it]                                                       {'loss': 0.071, 'grad_norm': 8.156265258789062, 'learning_rate': 2.2677966101694917e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [3:16:48<2:33:31,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [3:16:51<2:33:31,  3.44s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.5344939827919006, 'learning_rate': 2.266949152542373e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [3:16:51<2:33:31,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [3:16:55<2:35:03,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2606736421585083, 'learning_rate': 2.2661016949152543e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [3:16:55<2:35:03,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [3:16:59<2:45:43,  3.72s/it]                                                       {'loss': 0.0731, 'grad_norm': 6.211626052856445, 'learning_rate': 2.2652542372881358e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [3:16:59<2:45:43,  3.72s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [3:17:02<2:40:13,  3.60s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.97406268119812, 'learning_rate': 2.2644067796610172e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [3:17:02<2:40:13,  3.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [3:17:06<2:38:32,  3.56s/it]                                                       {'loss': 0.0108, 'grad_norm': 1.520025372505188, 'learning_rate': 2.2635593220338987e-05, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [3:17:06<2:38:32,  3.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [3:17:09<2:37:22,  3.54s/it]                                                       {'loss': 0.0086, 'grad_norm': 0.8419826626777649, 'learning_rate': 2.2627118644067798e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [3:17:09<2:37:22,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [3:17:13<2:35:17,  3.49s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5818428993225098, 'learning_rate': 2.261864406779661e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [3:17:13<2:35:17,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [3:17:16<2:32:36,  3.43s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.44809964299201965, 'learning_rate': 2.2610169491525424e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [3:17:16<2:32:36,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [3:17:19<2:31:49,  3.42s/it]                                                       {'loss': 0.0521, 'grad_norm': 1.4939697980880737, 'learning_rate': 2.260169491525424e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [3:17:19<2:31:49,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [3:17:23<2:34:30,  3.48s/it]                                                       {'loss': 0.0614, 'grad_norm': 3.3196678161621094, 'learning_rate': 2.259322033898305e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [3:17:23<2:34:30,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [3:17:27<2:39:37,  3.59s/it]                                                       {'loss': 0.0878, 'grad_norm': 3.4729838371276855, 'learning_rate': 2.2584745762711865e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [3:17:27<2:39:37,  3.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [3:17:31<2:43:41,  3.69s/it]                                                       {'loss': 0.0187, 'grad_norm': 2.1534245014190674, 'learning_rate': 2.257627118644068e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [3:17:31<2:43:41,  3.69s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [3:17:34<2:40:21,  3.61s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.027566909790039, 'learning_rate': 2.256779661016949e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [3:17:34<2:40:21,  3.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [3:17:38<2:36:39,  3.53s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.1970808506011963, 'learning_rate': 2.2559322033898305e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [3:17:38<2:36:39,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [3:17:41<2:34:23,  3.48s/it]                                                       {'loss': 0.0238, 'grad_norm': 3.117565870285034, 'learning_rate': 2.255084745762712e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [3:17:41<2:34:23,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [3:17:44<2:33:29,  3.46s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.8887100219726562, 'learning_rate': 2.2542372881355935e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [3:17:44<2:33:29,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [3:17:48<2:31:32,  3.42s/it]                                                       {'loss': 0.0343, 'grad_norm': 4.194856643676758, 'learning_rate': 2.2533898305084746e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [3:17:48<2:31:32,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [3:17:51<2:30:20,  3.39s/it]                                                       {'loss': 0.0318, 'grad_norm': 5.179609298706055, 'learning_rate': 2.252542372881356e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [3:17:51<2:30:20,  3.39s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [3:17:54<2:30:29,  3.40s/it]                                                       {'loss': 0.1007, 'grad_norm': 5.324659824371338, 'learning_rate': 2.2516949152542375e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [3:17:54<2:30:29,  3.40s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [3:17:58<2:30:46,  3.41s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0745716392993927, 'learning_rate': 2.2508474576271187e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [3:17:58<2:30:46,  3.41s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [3:18:01<2:31:05,  3.41s/it]                                                       {'loss': 0.007, 'grad_norm': 1.5607272386550903, 'learning_rate': 2.25e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [3:18:01<2:31:05,  3.41s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [3:18:05<2:36:57,  3.55s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.8338706493377686, 'learning_rate': 2.2491525423728816e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [3:18:05<2:36:57,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [3:18:09<2:41:26,  3.65s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.36753085255622864, 'learning_rate': 2.2483050847457627e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [3:18:09<2:41:26,  3.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [3:18:12<2:36:47,  3.55s/it]                                                       {'loss': 0.0697, 'grad_norm': 4.742770195007324, 'learning_rate': 2.2474576271186442e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [3:18:12<2:36:47,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [3:18:16<2:33:44,  3.48s/it]                                                       {'loss': 0.2138, 'grad_norm': 9.512024879455566, 'learning_rate': 2.2466101694915257e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [3:18:16<2:33:44,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [3:18:19<2:33:08,  3.47s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02154436521232128, 'learning_rate': 2.245762711864407e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [3:18:19<2:33:08,  3.47s/it][2025-10-20 18:48:06,124] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [3:18:25<3:04:33,  4.18s/it]                                                       {'loss': 0.0233, 'grad_norm': 3.0181570053100586, 'learning_rate': 2.2449152542372883e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [3:18:25<3:04:33,  4.18s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [3:18:28<2:55:40,  3.98s/it]                                                       {'loss': 0.0239, 'grad_norm': 2.445431709289551, 'learning_rate': 2.2440677966101694e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [3:18:28<2:55:40,  3.98s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [3:18:32<2:49:19,  3.84s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.36293262243270874, 'learning_rate': 2.243220338983051e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [3:18:32<2:49:19,  3.84s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [3:18:36<2:46:16,  3.77s/it]                                                       {'loss': 0.0351, 'grad_norm': 2.997558116912842, 'learning_rate': 2.2423728813559323e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [3:18:36<2:46:16,  3.77s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [3:18:39<2:40:45,  3.65s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4546384811401367, 'learning_rate': 2.2415254237288135e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [3:18:39<2:40:45,  3.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [3:18:42<2:38:20,  3.59s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.7940527200698853, 'learning_rate': 2.240677966101695e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [3:18:42<2:38:20,  3.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [3:18:46<2:40:34,  3.65s/it]                                                       {'loss': 0.1687, 'grad_norm': 6.345504283905029, 'learning_rate': 2.2398305084745764e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [3:18:46<2:40:34,  3.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [3:18:50<2:37:58,  3.59s/it]                                                       {'loss': 0.0341, 'grad_norm': 5.088735103607178, 'learning_rate': 2.2389830508474575e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [3:18:50<2:37:58,  3.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [3:18:53<2:36:15,  3.55s/it]                                                       {'loss': 0.1861, 'grad_norm': 7.6324782371521, 'learning_rate': 2.238135593220339e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [3:18:53<2:36:15,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [3:18:57<2:34:20,  3.51s/it]                                                       {'loss': 0.0206, 'grad_norm': 3.1091301441192627, 'learning_rate': 2.2372881355932205e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [3:18:57<2:34:20,  3.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [3:19:00<2:31:52,  3.45s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.7519788146018982, 'learning_rate': 2.236440677966102e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [3:19:00<2:31:52,  3.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [3:19:03<2:30:15,  3.42s/it]                                                       {'loss': 0.1005, 'grad_norm': 4.968323230743408, 'learning_rate': 2.235593220338983e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [3:19:03<2:30:15,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [3:19:07<2:32:11,  3.46s/it]                                                       {'loss': 0.0654, 'grad_norm': 5.65760612487793, 'learning_rate': 2.2347457627118645e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [3:19:07<2:32:11,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [3:19:10<2:31:16,  3.44s/it]                                                       {'loss': 0.2085, 'grad_norm': 6.659321308135986, 'learning_rate': 2.233898305084746e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [3:19:10<2:31:16,  3.44s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [3:19:14<2:30:47,  3.43s/it]                                                       {'loss': 0.3342, 'grad_norm': 10.077722549438477, 'learning_rate': 2.233050847457627e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [3:19:14<2:30:47,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [3:19:17<2:30:31,  3.43s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07684755325317383, 'learning_rate': 2.2322033898305086e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [3:19:17<2:30:31,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [3:19:20<2:30:07,  3.42s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.43078166246414185, 'learning_rate': 2.23135593220339e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [3:19:20<2:30:07,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [3:19:24<2:29:30,  3.41s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5369560718536377, 'learning_rate': 2.2305084745762715e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [3:19:24<2:29:30,  3.41s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [3:19:27<2:27:55,  3.37s/it]                                                       {'loss': 0.0774, 'grad_norm': 7.699289321899414, 'learning_rate': 2.2296610169491526e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [3:19:27<2:27:55,  3.37s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [3:19:31<2:30:03,  3.42s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.3242992162704468, 'learning_rate': 2.228813559322034e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [3:19:31<2:30:03,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [3:19:35<2:44:35,  3.76s/it]                                                       {'loss': 0.2647, 'grad_norm': 9.018285751342773, 'learning_rate': 2.2279661016949156e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [3:19:35<2:44:35,  3.76s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [3:19:39<2:40:48,  3.67s/it]                                                       {'loss': 0.1082, 'grad_norm': 4.466954231262207, 'learning_rate': 2.2271186440677967e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [3:19:39<2:40:48,  3.67s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [3:19:42<2:39:07,  3.63s/it]                                                       {'loss': 0.0524, 'grad_norm': 3.2956864833831787, 'learning_rate': 2.226271186440678e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [3:19:42<2:39:07,  3.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [3:19:45<2:35:09,  3.55s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.1658422946929932, 'learning_rate': 2.2254237288135593e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [3:19:45<2:35:09,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [3:19:49<2:34:54,  3.54s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.0611847639083862, 'learning_rate': 2.2245762711864408e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [3:19:49<2:34:54,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [3:19:52<2:32:32,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.7648105025291443, 'learning_rate': 2.223728813559322e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [3:19:52<2:32:32,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [3:19:56<2:33:04,  3.50s/it]                                                       {'loss': 0.11, 'grad_norm': 8.57620906829834, 'learning_rate': 2.2228813559322034e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [3:19:56<2:33:04,  3.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [3:20:00<2:43:34,  3.74s/it]                                                       {'loss': 0.0435, 'grad_norm': 4.068145751953125, 'learning_rate': 2.222033898305085e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [3:20:00<2:43:34,  3.74s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [3:20:03<2:37:20,  3.60s/it]                                                       {'loss': 0.0809, 'grad_norm': 6.444686412811279, 'learning_rate': 2.2211864406779663e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [3:20:03<2:37:20,  3.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [3:20:07<2:33:34,  3.52s/it]                                                       {'loss': 0.1145, 'grad_norm': 4.925271034240723, 'learning_rate': 2.2203389830508474e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [3:20:07<2:33:34,  3.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [3:20:10<2:32:10,  3.49s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.7697947025299072, 'learning_rate': 2.219491525423729e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [3:20:10<2:32:10,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [3:20:14<2:40:19,  3.67s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.7000789046287537, 'learning_rate': 2.2186440677966104e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [3:20:14<2:40:19,  3.67s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [3:20:18<2:36:33,  3.59s/it]                                                       {'loss': 0.094, 'grad_norm': 7.6201701164245605, 'learning_rate': 2.2177966101694915e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [3:20:18<2:36:33,  3.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [3:20:21<2:33:51,  3.53s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3155113756656647, 'learning_rate': 2.216949152542373e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [3:20:21<2:33:51,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [3:20:25<2:34:41,  3.55s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7723792195320129, 'learning_rate': 2.2161016949152544e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [3:20:25<2:34:41,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [3:20:28<2:31:20,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.18126770853996277, 'learning_rate': 2.215254237288136e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [3:20:28<2:31:20,  3.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [3:20:32<2:31:43,  3.48s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03026340715587139, 'learning_rate': 2.214406779661017e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [3:20:32<2:31:43,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [3:20:35<2:29:47,  3.44s/it]                                                       {'loss': 0.2399, 'grad_norm': 6.36268424987793, 'learning_rate': 2.2135593220338985e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [3:20:35<2:29:47,  3.44s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [3:20:38<2:28:40,  3.42s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.47829949855804443, 'learning_rate': 2.21271186440678e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [3:20:38<2:28:40,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [3:20:42<2:28:13,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.018672935664653778, 'learning_rate': 2.211864406779661e-05, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [3:20:42<2:28:13,  3.41s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [3:20:45<2:33:40,  3.53s/it]                                                       {'loss': 0.1455, 'grad_norm': 8.615501403808594, 'learning_rate': 2.2110169491525426e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [3:20:45<2:33:40,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [3:20:49<2:33:28,  3.53s/it]                                                       {'loss': 0.1442, 'grad_norm': 6.599302291870117, 'learning_rate': 2.210169491525424e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [3:20:49<2:33:28,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [3:20:52<2:31:56,  3.50s/it]                                                       {'loss': 0.1215, 'grad_norm': 7.123061656951904, 'learning_rate': 2.209322033898305e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [3:20:52<2:31:56,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [3:20:56<2:29:57,  3.45s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5123782753944397, 'learning_rate': 2.2084745762711863e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [3:20:56<2:29:57,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [3:21:00<2:40:33,  3.70s/it]                                                       {'loss': 0.0415, 'grad_norm': 0.6069666147232056, 'learning_rate': 2.2076271186440678e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [3:21:00<2:40:33,  3.70s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [3:21:03<2:36:41,  3.61s/it]                                                       {'loss': 0.0732, 'grad_norm': 6.689510345458984, 'learning_rate': 2.2067796610169492e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [3:21:03<2:36:41,  3.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [3:21:07<2:33:56,  3.55s/it]                                                       {'loss': 0.24, 'grad_norm': 8.019367218017578, 'learning_rate': 2.2059322033898307e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [3:21:07<2:33:56,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [3:21:10<2:32:11,  3.51s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.5003185272216797, 'learning_rate': 2.2050847457627118e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [3:21:10<2:32:11,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [3:21:14<2:31:11,  3.49s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.21521739661693573, 'learning_rate': 2.2042372881355933e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [3:21:14<2:31:11,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [3:21:18<2:36:36,  3.61s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.9457055330276489, 'learning_rate': 2.2033898305084748e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [3:21:18<2:36:36,  3.61s/it][2025-10-20 18:51:04,558] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [3:21:23<3:04:29,  4.26s/it]                                                       {'loss': 0.2149, 'grad_norm': 7.179755687713623, 'learning_rate': 2.202542372881356e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [3:21:23<3:04:29,  4.26s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [3:21:27<2:54:34,  4.03s/it]                                                       {'loss': 0.0311, 'grad_norm': 4.7160797119140625, 'learning_rate': 2.2016949152542373e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [3:21:27<2:54:34,  4.03s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [3:21:30<2:45:10,  3.82s/it]                                                       {'loss': 0.1156, 'grad_norm': 7.836416244506836, 'learning_rate': 2.2008474576271188e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [3:21:30<2:45:10,  3.82s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [3:21:34<2:42:20,  3.75s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.7307709455490112, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [3:21:34<2:42:20,  3.75s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [3:21:37<2:37:14,  3.64s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10293272137641907, 'learning_rate': 2.1991525423728814e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [3:21:37<2:37:14,  3.64s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [3:21:40<2:33:06,  3.54s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.21202711760997772, 'learning_rate': 2.198305084745763e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [3:21:40<2:33:06,  3.54s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [3:21:44<2:31:46,  3.51s/it]                                                       {'loss': 0.2069, 'grad_norm': 6.8173418045043945, 'learning_rate': 2.1974576271186443e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [3:21:44<2:31:46,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [3:21:48<2:42:46,  3.77s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5603724122047424, 'learning_rate': 2.1966101694915255e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [3:21:48<2:42:46,  3.77s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [3:21:52<2:38:54,  3.68s/it]                                                       {'loss': 0.2196, 'grad_norm': 8.9711332321167, 'learning_rate': 2.195762711864407e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [3:21:52<2:38:54,  3.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [3:21:55<2:35:43,  3.61s/it]                                                       {'loss': 0.0571, 'grad_norm': 8.051602363586426, 'learning_rate': 2.1949152542372884e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [3:21:55<2:35:43,  3.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [3:21:59<2:34:46,  3.59s/it]                                                       {'loss': 0.1057, 'grad_norm': 4.905045986175537, 'learning_rate': 2.1940677966101695e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [3:21:59<2:34:46,  3.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [3:22:02<2:33:17,  3.55s/it]                                                       {'loss': 0.0943, 'grad_norm': 3.8801231384277344, 'learning_rate': 2.193220338983051e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [3:22:02<2:33:17,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [3:22:06<2:30:42,  3.50s/it]                                                       {'loss': 0.0421, 'grad_norm': 6.278265476226807, 'learning_rate': 2.1923728813559325e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [3:22:06<2:30:42,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [3:22:09<2:28:59,  3.46s/it]                                                       {'loss': 0.0414, 'grad_norm': 5.588323593139648, 'learning_rate': 2.1915254237288136e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [3:22:09<2:28:59,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [3:22:12<2:30:36,  3.50s/it]                                                       {'loss': 0.1006, 'grad_norm': 6.336513519287109, 'learning_rate': 2.190677966101695e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [3:22:12<2:30:36,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [3:22:16<2:30:02,  3.48s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.3666999340057373, 'learning_rate': 2.1898305084745762e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [3:22:16<2:30:02,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [3:22:20<2:31:50,  3.53s/it]                                                       {'loss': 0.0249, 'grad_norm': 2.6531028747558594, 'learning_rate': 2.1889830508474577e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [3:22:20<2:31:50,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [3:22:23<2:30:27,  3.50s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.150338813662529, 'learning_rate': 2.188135593220339e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [3:22:23<2:30:27,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [3:22:26<2:29:55,  3.49s/it]                                                       {'loss': 0.0222, 'grad_norm': 2.9147183895111084, 'learning_rate': 2.1872881355932203e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [3:22:26<2:29:55,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [3:22:30<2:28:38,  3.46s/it]                                                       {'loss': 0.0768, 'grad_norm': 7.162501335144043, 'learning_rate': 2.1864406779661017e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [3:22:30<2:28:38,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [3:22:33<2:29:50,  3.49s/it]                                                       {'loss': 0.0378, 'grad_norm': 4.222177982330322, 'learning_rate': 2.1855932203389832e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [3:22:33<2:29:50,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [3:22:37<2:29:18,  3.48s/it]                                                       {'loss': 0.0905, 'grad_norm': 6.585786819458008, 'learning_rate': 2.1847457627118643e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [3:22:37<2:29:18,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [3:22:41<2:36:23,  3.64s/it]                                                       {'loss': 0.1913, 'grad_norm': 7.546853542327881, 'learning_rate': 2.1838983050847458e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [3:22:41<2:36:23,  3.64s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [3:22:44<2:35:20,  3.62s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.5659427642822266, 'learning_rate': 2.1830508474576273e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [3:22:44<2:35:20,  3.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [3:22:48<2:32:58,  3.56s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.40464192628860474, 'learning_rate': 2.1822033898305087e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [3:22:48<2:32:58,  3.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [3:22:51<2:31:32,  3.53s/it]                                                       {'loss': 0.0346, 'grad_norm': 2.6709437370300293, 'learning_rate': 2.18135593220339e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [3:22:51<2:31:32,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [3:22:55<2:30:49,  3.52s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.6945736408233643, 'learning_rate': 2.1805084745762713e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [3:22:55<2:30:49,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [3:22:58<2:29:04,  3.48s/it]                                                       {'loss': 0.0893, 'grad_norm': 6.760656356811523, 'learning_rate': 2.1796610169491528e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [3:22:58<2:29:04,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [3:23:02<2:28:10,  3.46s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.293246030807495, 'learning_rate': 2.178813559322034e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [3:23:02<2:28:10,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [3:23:05<2:26:41,  3.42s/it]                                                       {'loss': 0.2288, 'grad_norm': 7.574666500091553, 'learning_rate': 2.1779661016949154e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [3:23:05<2:26:41,  3.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [3:23:09<2:30:57,  3.53s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.16119384765625, 'learning_rate': 2.177118644067797e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [3:23:09<2:30:57,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [3:23:12<2:30:32,  3.52s/it]                                                       {'loss': 0.0678, 'grad_norm': 3.538400888442993, 'learning_rate': 2.1762711864406783e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [3:23:12<2:30:32,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [3:23:16<2:30:08,  3.51s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.0981953963637352, 'learning_rate': 2.1754237288135594e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [3:23:16<2:30:08,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [3:23:19<2:28:48,  3.48s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.4971656799316406, 'learning_rate': 2.174576271186441e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [3:23:19<2:28:48,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [3:23:23<2:27:44,  3.46s/it]                                                       {'loss': 0.0142, 'grad_norm': 1.6165746450424194, 'learning_rate': 2.173728813559322e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [3:23:23<2:27:44,  3.46s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [3:23:26<2:27:25,  3.45s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.12095839530229568, 'learning_rate': 2.1728813559322035e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [3:23:26<2:27:25,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [3:23:30<2:33:20,  3.59s/it]                                                       {'loss': 0.0264, 'grad_norm': 2.5390701293945312, 'learning_rate': 2.1720338983050846e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [3:23:30<2:33:20,  3.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [3:23:33<2:30:38,  3.53s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.12459997832775116, 'learning_rate': 2.171186440677966e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [3:23:33<2:30:38,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [3:23:37<2:36:41,  3.67s/it]                                                       {'loss': 0.0326, 'grad_norm': 3.20965576171875, 'learning_rate': 2.1703389830508476e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [3:23:37<2:36:41,  3.67s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [3:23:41<2:33:07,  3.59s/it]                                                       {'loss': 0.0844, 'grad_norm': 5.944214820861816, 'learning_rate': 2.1694915254237287e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [3:23:41<2:33:07,  3.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [3:23:44<2:32:22,  3.57s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.59968900680542, 'learning_rate': 2.1686440677966102e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [3:23:44<2:32:22,  3.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [3:23:48<2:29:58,  3.52s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.23239807784557343, 'learning_rate': 2.1677966101694916e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [3:23:48<2:29:58,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [3:23:51<2:28:56,  3.49s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.2500547170639038, 'learning_rate': 2.166949152542373e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [3:23:51<2:28:56,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [3:23:54<2:27:02,  3.45s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.6920042037963867, 'learning_rate': 2.1661016949152542e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [3:23:54<2:27:02,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [3:23:58<2:25:58,  3.43s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.0187278985977173, 'learning_rate': 2.1652542372881357e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [3:23:58<2:25:58,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [3:24:02<2:30:34,  3.54s/it]                                                       {'loss': 0.0668, 'grad_norm': 4.557477951049805, 'learning_rate': 2.1644067796610172e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [3:24:02<2:30:34,  3.54s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [3:24:05<2:28:20,  3.49s/it]                                                       {'loss': 0.0471, 'grad_norm': 3.1362645626068115, 'learning_rate': 2.1635593220338983e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [3:24:05<2:28:20,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [3:24:08<2:26:41,  3.45s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.072259545326233, 'learning_rate': 2.1627118644067798e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [3:24:08<2:26:41,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [3:24:12<2:25:37,  3.43s/it]                                                       {'loss': 0.0138, 'grad_norm': 1.2957258224487305, 'learning_rate': 2.1618644067796612e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [3:24:12<2:25:37,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [3:24:15<2:30:58,  3.55s/it]                                                       {'loss': 0.008, 'grad_norm': 1.4289472103118896, 'learning_rate': 2.1610169491525427e-05, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [3:24:15<2:30:58,  3.55s/it][2025-10-20 18:54:02,483] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [3:24:21<2:58:33,  4.20s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.1433083564043045, 'learning_rate': 2.1601694915254238e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [3:24:21<2:58:33,  4.20s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [3:24:25<2:53:38,  4.09s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.7087370157241821, 'learning_rate': 2.1593220338983053e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [3:24:25<2:53:38,  4.09s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [3:24:28<2:45:27,  3.90s/it]                                                       {'loss': 0.1482, 'grad_norm': 7.284879684448242, 'learning_rate': 2.1584745762711868e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [3:24:28<2:45:27,  3.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [3:24:32<2:39:09,  3.75s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.6692227125167847, 'learning_rate': 2.157627118644068e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [3:24:32<2:39:09,  3.75s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [3:24:36<2:41:22,  3.80s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06159903109073639, 'learning_rate': 2.1567796610169494e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [3:24:36<2:41:22,  3.80s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [3:24:39<2:36:36,  3.69s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06073484197258949, 'learning_rate': 2.1559322033898305e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [3:24:39<2:36:36,  3.69s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [3:24:43<2:32:46,  3.60s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.2434142380952835, 'learning_rate': 2.155084745762712e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [3:24:43<2:32:46,  3.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [3:24:46<2:29:20,  3.53s/it]                                                       {'loss': 0.0048, 'grad_norm': 1.6272221803665161, 'learning_rate': 2.154237288135593e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [3:24:46<2:29:20,  3.53s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [3:24:49<2:27:45,  3.49s/it]                                                       {'loss': 0.0405, 'grad_norm': 3.9743447303771973, 'learning_rate': 2.1533898305084746e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [3:24:49<2:27:45,  3.49s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [3:24:53<2:25:45,  3.44s/it]                                                       {'loss': 0.0739, 'grad_norm': 6.437922477722168, 'learning_rate': 2.152542372881356e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [3:24:53<2:25:45,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [3:24:56<2:25:18,  3.43s/it]                                                       {'loss': 0.2613, 'grad_norm': 8.054298400878906, 'learning_rate': 2.1516949152542375e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [3:24:56<2:25:18,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [3:25:00<2:25:18,  3.43s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.47118082642555237, 'learning_rate': 2.1508474576271186e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [3:25:00<2:25:18,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [3:25:03<2:26:08,  3.46s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.15811391174793243, 'learning_rate': 2.15e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [3:25:03<2:26:08,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [3:25:07<2:26:04,  3.46s/it]                                                       {'loss': 0.0377, 'grad_norm': 4.022618770599365, 'learning_rate': 2.1491525423728816e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [3:25:07<2:26:04,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [3:25:10<2:25:31,  3.44s/it]                                                       {'loss': 0.007, 'grad_norm': 1.0659334659576416, 'learning_rate': 2.1483050847457627e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [3:25:10<2:25:31,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [3:25:13<2:24:26,  3.42s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3603673577308655, 'learning_rate': 2.147457627118644e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [3:25:13<2:24:26,  3.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [3:25:17<2:22:52,  3.38s/it]                                                       {'loss': 0.0459, 'grad_norm': 5.830173492431641, 'learning_rate': 2.1466101694915256e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [3:25:17<2:22:52,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [3:25:20<2:23:45,  3.41s/it]                                                       {'loss': 0.021, 'grad_norm': 3.711679458618164, 'learning_rate': 2.145762711864407e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [3:25:20<2:23:45,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [3:25:24<2:28:32,  3.52s/it]                                                       {'loss': 0.0678, 'grad_norm': 4.687084197998047, 'learning_rate': 2.1449152542372882e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [3:25:24<2:28:32,  3.52s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [3:25:27<2:28:13,  3.52s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.20356717705726624, 'learning_rate': 2.1440677966101697e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [3:25:27<2:28:13,  3.52s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [3:25:31<2:25:55,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.18638275563716888, 'learning_rate': 2.143220338983051e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [3:25:31<2:25:55,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [3:25:34<2:24:09,  3.42s/it]                                                       {'loss': 0.018, 'grad_norm': 2.935917377471924, 'learning_rate': 2.1423728813559323e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [3:25:34<2:24:09,  3.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [3:25:38<2:25:11,  3.45s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.40551984310150146, 'learning_rate': 2.1415254237288137e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [3:25:38<2:25:11,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [3:25:41<2:25:17,  3.45s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.689903974533081, 'learning_rate': 2.1406779661016952e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [3:25:41<2:25:17,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [3:25:44<2:24:10,  3.43s/it]                                                       {'loss': 0.0656, 'grad_norm': 6.481743812561035, 'learning_rate': 2.1398305084745763e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [3:25:44<2:24:10,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [3:25:48<2:24:05,  3.43s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.1607496738433838, 'learning_rate': 2.1389830508474575e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [3:25:48<2:24:05,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [3:25:51<2:26:07,  3.48s/it]                                                       {'loss': 0.2162, 'grad_norm': 10.47401237487793, 'learning_rate': 2.138135593220339e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [3:25:51<2:26:07,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [3:25:55<2:24:48,  3.45s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5720970630645752, 'learning_rate': 2.1372881355932204e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [3:25:55<2:24:48,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [3:25:58<2:25:46,  3.47s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.14843657612800598, 'learning_rate': 2.136440677966102e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [3:25:58<2:25:46,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [3:26:02<2:29:43,  3.56s/it]                                                       {'loss': 0.2469, 'grad_norm': 8.457418441772461, 'learning_rate': 2.135593220338983e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [3:26:02<2:29:43,  3.56s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [3:26:05<2:27:32,  3.51s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.3725565969944, 'learning_rate': 2.1347457627118645e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [3:26:05<2:27:32,  3.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [3:26:09<2:25:37,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.007259415928274393, 'learning_rate': 2.133898305084746e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [3:26:09<2:25:37,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [3:26:12<2:25:19,  3.46s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.5286893844604492, 'learning_rate': 2.133050847457627e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [3:26:12<2:25:19,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [3:26:16<2:23:52,  3.43s/it]                                                       {'loss': 0.063, 'grad_norm': 5.971456527709961, 'learning_rate': 2.1322033898305085e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [3:26:16<2:23:52,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [3:26:19<2:24:46,  3.45s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.4821083545684814, 'learning_rate': 2.13135593220339e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [3:26:19<2:24:46,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [3:26:23<2:23:47,  3.43s/it]                                                       {'loss': 0.0665, 'grad_norm': 6.341219425201416, 'learning_rate': 2.130508474576271e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [3:26:23<2:23:47,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [3:26:26<2:24:07,  3.44s/it]                                                       {'loss': 0.0605, 'grad_norm': 6.519824028015137, 'learning_rate': 2.1296610169491526e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [3:26:26<2:24:07,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [3:26:30<2:24:58,  3.46s/it]                                                       {'loss': 0.006, 'grad_norm': 0.7692508101463318, 'learning_rate': 2.128813559322034e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [3:26:30<2:24:58,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [3:26:33<2:22:54,  3.41s/it]                                                       {'loss': 0.1804, 'grad_norm': 8.338608741760254, 'learning_rate': 2.1279661016949155e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [3:26:33<2:22:54,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [3:26:36<2:21:46,  3.39s/it]                                                       {'loss': 0.1621, 'grad_norm': 5.520716667175293, 'learning_rate': 2.1271186440677967e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [3:26:36<2:21:46,  3.39s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [3:26:39<2:21:03,  3.37s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1198199987411499, 'learning_rate': 2.126271186440678e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [3:26:39<2:21:03,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [3:26:43<2:23:14,  3.43s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.1486988663673401, 'learning_rate': 2.1254237288135596e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [3:26:43<2:23:14,  3.43s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [3:26:46<2:22:26,  3.41s/it]                                                       {'loss': 0.0281, 'grad_norm': 2.9876322746276855, 'learning_rate': 2.1245762711864407e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [3:26:46<2:22:26,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [3:26:50<2:22:25,  3.41s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.8715745210647583, 'learning_rate': 2.1237288135593222e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [3:26:50<2:22:25,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [3:26:53<2:22:04,  3.40s/it]                                                       {'loss': 0.07, 'grad_norm': 6.00390100479126, 'learning_rate': 2.1228813559322037e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [3:26:53<2:22:04,  3.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [3:26:57<2:21:40,  3.39s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.39030933380126953, 'learning_rate': 2.122033898305085e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [3:26:57<2:21:40,  3.39s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [3:27:00<2:20:29,  3.37s/it]                                                       {'loss': 0.006, 'grad_norm': 0.7611667513847351, 'learning_rate': 2.121186440677966e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [3:27:00<2:20:29,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [3:27:04<2:25:42,  3.49s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05389821529388428, 'learning_rate': 2.1203389830508474e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [3:27:04<2:25:42,  3.49s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [3:27:07<2:26:06,  3.51s/it]                                                       {'loss': 0.0795, 'grad_norm': 6.445923328399658, 'learning_rate': 2.119491525423729e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [3:27:07<2:26:06,  3.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [3:27:11<2:25:12,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5841639041900635, 'learning_rate': 2.1186440677966103e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [3:27:11<2:25:12,  3.48s/it][2025-10-20 18:56:57,633] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [3:27:16<2:53:22,  4.16s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.9881510734558105, 'learning_rate': 2.1177966101694914e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [3:27:16<2:53:22,  4.16s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [3:27:20<2:42:31,  3.90s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.562865138053894, 'learning_rate': 2.116949152542373e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [3:27:20<2:42:31,  3.90s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [3:27:23<2:36:43,  3.77s/it]                                                       {'loss': 0.0232, 'grad_norm': 3.3066558837890625, 'learning_rate': 2.1161016949152544e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [3:27:23<2:36:43,  3.77s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [3:27:26<2:31:28,  3.64s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.43255019187927246, 'learning_rate': 2.1152542372881355e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [3:27:26<2:31:28,  3.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [3:27:30<2:29:21,  3.59s/it]                                                       {'loss': 0.0424, 'grad_norm': 4.087996006011963, 'learning_rate': 2.114406779661017e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [3:27:30<2:29:21,  3.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [3:27:33<2:28:25,  3.57s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3621990978717804, 'learning_rate': 2.1135593220338984e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [3:27:33<2:28:25,  3.57s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [3:27:37<2:27:51,  3.56s/it]                                                       {'loss': 0.1394, 'grad_norm': 7.224573135375977, 'learning_rate': 2.11271186440678e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [3:27:37<2:27:51,  3.56s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [3:27:40<2:25:23,  3.50s/it]                                                       {'loss': 0.0452, 'grad_norm': 2.687415599822998, 'learning_rate': 2.111864406779661e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [3:27:40<2:25:23,  3.50s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [3:27:44<2:23:03,  3.45s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.30075696110725403, 'learning_rate': 2.1110169491525425e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [3:27:44<2:23:03,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [3:27:47<2:23:42,  3.46s/it]                                                       {'loss': 0.0588, 'grad_norm': 6.379197597503662, 'learning_rate': 2.110169491525424e-05, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [3:27:47<2:23:42,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [3:27:51<2:26:00,  3.52s/it]                                                       {'loss': 0.018, 'grad_norm': 1.9005526304244995, 'learning_rate': 2.109322033898305e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [3:27:51<2:26:00,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [3:27:54<2:25:08,  3.50s/it]                                                       {'loss': 0.0964, 'grad_norm': 8.167553901672363, 'learning_rate': 2.1084745762711866e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [3:27:54<2:25:08,  3.50s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [3:27:58<2:25:33,  3.51s/it]                                                       {'loss': 0.085, 'grad_norm': 4.013824462890625, 'learning_rate': 2.107627118644068e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [3:27:58<2:25:33,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [3:28:01<2:25:43,  3.52s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.626405119895935, 'learning_rate': 2.1067796610169495e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [3:28:01<2:25:43,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [3:28:05<2:23:19,  3.46s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.382278323173523, 'learning_rate': 2.1059322033898306e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [3:28:05<2:23:19,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [3:28:08<2:22:21,  3.44s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.4298245310783386, 'learning_rate': 2.105084745762712e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [3:28:08<2:22:21,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [3:28:12<2:22:24,  3.44s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.16906598210334778, 'learning_rate': 2.1042372881355936e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [3:28:12<2:22:24,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [3:28:15<2:20:46,  3.40s/it]                                                       {'loss': 0.5093, 'grad_norm': 8.791230201721191, 'learning_rate': 2.1033898305084747e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [3:28:15<2:20:46,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [3:28:18<2:23:44,  3.48s/it]                                                       {'loss': 0.1538, 'grad_norm': 6.100146293640137, 'learning_rate': 2.1025423728813558e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [3:28:18<2:23:44,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [3:28:22<2:24:09,  3.49s/it]                                                       {'loss': 0.2195, 'grad_norm': 7.985659122467041, 'learning_rate': 2.1016949152542373e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [3:28:22<2:24:09,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [3:28:26<2:25:37,  3.52s/it]                                                       {'loss': 0.1526, 'grad_norm': 6.625824451446533, 'learning_rate': 2.1008474576271188e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [3:28:26<2:25:37,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [3:28:30<2:33:47,  3.72s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4342857599258423, 'learning_rate': 2.1e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [3:28:30<2:33:47,  3.72s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [3:28:33<2:29:27,  3.62s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.12159395962953568, 'learning_rate': 2.0991525423728814e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [3:28:33<2:29:27,  3.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [3:28:37<2:26:26,  3.55s/it]                                                       {'loss': 0.0265, 'grad_norm': 1.7391941547393799, 'learning_rate': 2.0983050847457628e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [3:28:37<2:26:26,  3.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [3:28:40<2:24:22,  3.50s/it]                                                       {'loss': 0.2012, 'grad_norm': 8.95445728302002, 'learning_rate': 2.0974576271186443e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [3:28:40<2:24:22,  3.50s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [3:28:43<2:23:57,  3.49s/it]                                                       {'loss': 0.0768, 'grad_norm': 7.074276447296143, 'learning_rate': 2.0966101694915254e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [3:28:43<2:23:57,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [3:28:47<2:22:20,  3.45s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.092289686203003, 'learning_rate': 2.095762711864407e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [3:28:47<2:22:20,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [3:28:50<2:21:02,  3.42s/it]                                                       {'loss': 0.0766, 'grad_norm': 4.547561168670654, 'learning_rate': 2.0949152542372883e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [3:28:50<2:21:02,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [3:28:54<2:22:24,  3.46s/it]                                                       {'loss': 0.0628, 'grad_norm': 3.7455332279205322, 'learning_rate': 2.0940677966101695e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [3:28:54<2:22:24,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [3:28:57<2:20:55,  3.42s/it]                                                       {'loss': 0.1934, 'grad_norm': 9.056302070617676, 'learning_rate': 2.093220338983051e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [3:28:57<2:20:55,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [3:29:00<2:20:16,  3.41s/it]                                                       {'loss': 0.0173, 'grad_norm': 3.0012502670288086, 'learning_rate': 2.0923728813559324e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [3:29:00<2:20:16,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [3:29:04<2:19:02,  3.38s/it]                                                       {'loss': 0.0321, 'grad_norm': 2.22621750831604, 'learning_rate': 2.091525423728814e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [3:29:04<2:19:02,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [3:29:07<2:18:59,  3.38s/it]                                                       {'loss': 0.0468, 'grad_norm': 5.958043098449707, 'learning_rate': 2.090677966101695e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [3:29:07<2:18:59,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [3:29:11<2:20:00,  3.41s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.42123642563819885, 'learning_rate': 2.0898305084745765e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [3:29:11<2:20:00,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [3:29:14<2:20:17,  3.41s/it]                                                       {'loss': 0.0511, 'grad_norm': 3.7896652221679688, 'learning_rate': 2.088983050847458e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [3:29:14<2:20:17,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [3:29:18<2:21:35,  3.45s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.0237561464309692, 'learning_rate': 2.088135593220339e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [3:29:18<2:21:35,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [3:29:21<2:20:58,  3.43s/it]                                                       {'loss': 0.1487, 'grad_norm': 6.240754127502441, 'learning_rate': 2.0872881355932205e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [3:29:21<2:20:58,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [3:29:24<2:20:53,  3.43s/it]                                                       {'loss': 0.441, 'grad_norm': 8.895469665527344, 'learning_rate': 2.086440677966102e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [3:29:24<2:20:53,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [3:29:28<2:20:07,  3.42s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.7224153876304626, 'learning_rate': 2.085593220338983e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [3:29:28<2:20:07,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [3:29:31<2:19:48,  3.41s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05850693956017494, 'learning_rate': 2.0847457627118643e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [3:29:31<2:19:48,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [3:29:34<2:18:39,  3.38s/it]                                                       {'loss': 0.2129, 'grad_norm': 6.306983470916748, 'learning_rate': 2.0838983050847457e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [3:29:34<2:18:39,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [3:29:38<2:19:14,  3.40s/it]                                                       {'loss': 0.1679, 'grad_norm': 7.7522358894348145, 'learning_rate': 2.0830508474576272e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [3:29:38<2:19:14,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [3:29:41<2:19:55,  3.42s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4087987542152405, 'learning_rate': 2.0822033898305087e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [3:29:41<2:19:55,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [3:29:45<2:19:36,  3.41s/it]                                                       {'loss': 0.2606, 'grad_norm': 8.40421199798584, 'learning_rate': 2.0813559322033898e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [3:29:45<2:19:36,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [3:29:48<2:18:52,  3.39s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6985387802124023, 'learning_rate': 2.0805084745762713e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [3:29:48<2:18:52,  3.39s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [3:29:52<2:24:26,  3.53s/it]                                                       {'loss': 0.1433, 'grad_norm': 7.761482238769531, 'learning_rate': 2.0796610169491527e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [3:29:52<2:24:26,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [3:29:55<2:24:04,  3.52s/it]                                                       {'loss': 0.1492, 'grad_norm': 7.429873943328857, 'learning_rate': 2.078813559322034e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [3:29:55<2:24:04,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [3:29:59<2:22:10,  3.48s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3396722972393036, 'learning_rate': 2.0779661016949153e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [3:29:59<2:22:10,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [3:30:02<2:20:07,  3.43s/it]                                                       {'loss': 0.0357, 'grad_norm': 3.9942166805267334, 'learning_rate': 2.0771186440677968e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [3:30:02<2:20:07,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [3:30:05<2:18:55,  3.40s/it]                                                       {'loss': 0.1359, 'grad_norm': 5.433059215545654, 'learning_rate': 2.076271186440678e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [3:30:05<2:18:55,  3.40s/it][2025-10-20 18:59:52,469] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3550
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: b33fe1fa-43f7-4dff-a342-1cfb31388b6c)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 19:00:02,514] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: b33fe1fa-43f7-4dff-a342-1cfb31388b6c)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 19:00:02,515] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [3:30:23<5:16:51,  7.76s/it]                                                       {'loss': 0.0506, 'grad_norm': 3.713174819946289, 'learning_rate': 2.0754237288135594e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [3:30:23<5:16:51,  7.76s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [3:30:27<4:27:55,  6.57s/it]                                                       {'loss': 0.0504, 'grad_norm': 3.3390610218048096, 'learning_rate': 2.074576271186441e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [3:30:27<4:27:55,  6.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [3:30:31<3:51:11,  5.67s/it]                                                       {'loss': 0.0257, 'grad_norm': 3.879957914352417, 'learning_rate': 2.0737288135593223e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [3:30:31<3:51:11,  5.67s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [3:30:34<3:23:09,  4.98s/it]                                                       {'loss': 0.0241, 'grad_norm': 1.8549576997756958, 'learning_rate': 2.0728813559322035e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [3:30:34<3:23:09,  4.98s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [3:30:38<3:04:12,  4.52s/it]                                                       {'loss': 0.0747, 'grad_norm': 6.214704513549805, 'learning_rate': 2.072033898305085e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [3:30:38<3:04:12,  4.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [3:30:41<2:50:05,  4.18s/it]                                                       {'loss': 0.1686, 'grad_norm': 6.646347522735596, 'learning_rate': 2.0711864406779664e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [3:30:41<2:50:05,  4.18s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [3:30:44<2:41:27,  3.97s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3084954619407654, 'learning_rate': 2.0703389830508475e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [3:30:44<2:41:27,  3.97s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [3:30:48<2:34:43,  3.80s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0010813756380230188, 'learning_rate': 2.069491525423729e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [3:30:48<2:34:43,  3.80s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [3:30:51<2:30:11,  3.69s/it]                                                       {'loss': 0.1359, 'grad_norm': 5.692544460296631, 'learning_rate': 2.06864406779661e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [3:30:51<2:30:11,  3.69s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [3:30:55<2:25:54,  3.59s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04587091505527496, 'learning_rate': 2.0677966101694916e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [3:30:55<2:25:54,  3.59s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [3:30:58<2:22:58,  3.52s/it]                                                       {'loss': 0.0261, 'grad_norm': 4.234203815460205, 'learning_rate': 2.0669491525423727e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [3:30:58<2:22:58,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [3:31:01<2:21:04,  3.47s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.194265365600586, 'learning_rate': 2.0661016949152542e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [3:31:01<2:21:04,  3.47s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [3:31:05<2:21:16,  3.48s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3252585828304291, 'learning_rate': 2.0652542372881356e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [3:31:05<2:21:16,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [3:31:09<2:25:15,  3.58s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5210720896720886, 'learning_rate': 2.064406779661017e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [3:31:09<2:25:15,  3.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [3:31:12<2:22:56,  3.52s/it]                                                       {'loss': 0.0265, 'grad_norm': 2.295999050140381, 'learning_rate': 2.0635593220338982e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [3:31:12<2:22:56,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [3:31:16<2:24:00,  3.55s/it]                                                       {'loss': 0.0469, 'grad_norm': 5.338778972625732, 'learning_rate': 2.0627118644067797e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [3:31:16<2:24:00,  3.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [3:31:19<2:21:21,  3.49s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09973728656768799, 'learning_rate': 2.0618644067796612e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [3:31:19<2:21:21,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [3:31:22<2:21:02,  3.48s/it]                                                       {'loss': 0.1761, 'grad_norm': 4.8213934898376465, 'learning_rate': 2.0610169491525423e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [3:31:22<2:21:02,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [3:31:26<2:19:36,  3.45s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.14811843633651733, 'learning_rate': 2.0601694915254238e-05, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [3:31:26<2:19:36,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [3:31:29<2:18:43,  3.43s/it]                                                       {'loss': 0.017, 'grad_norm': 1.7297275066375732, 'learning_rate': 2.0593220338983052e-05, 'epoch': 0.59}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [3:31:29<2:18:43,  3.43s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [3:31:33<2:19:39,  3.45s/it]                                                       {'loss': 0.0599, 'grad_norm': 2.7587127685546875, 'learning_rate': 2.0584745762711867e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [3:31:33<2:19:39,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [3:31:36<2:20:35,  3.47s/it]                                                       {'loss': 0.0508, 'grad_norm': 3.739062786102295, 'learning_rate': 2.057627118644068e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [3:31:36<2:20:35,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [3:31:40<2:19:00,  3.44s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.39416593313217163, 'learning_rate': 2.0567796610169493e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [3:31:40<2:19:00,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [3:31:44<2:25:02,  3.59s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.027683556079864502, 'learning_rate': 2.0559322033898308e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [3:31:44<2:25:02,  3.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [3:31:48<2:32:19,  3.77s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.217925027012825, 'learning_rate': 2.055084745762712e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [3:31:48<2:32:19,  3.77s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [3:31:51<2:27:17,  3.65s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.2980507612228394, 'learning_rate': 2.0542372881355934e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [3:31:51<2:27:17,  3.65s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [3:31:55<2:27:08,  3.64s/it]                                                       {'loss': 0.0639, 'grad_norm': 5.836559295654297, 'learning_rate': 2.053389830508475e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [3:31:55<2:27:08,  3.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [3:31:58<2:23:32,  3.56s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.19517982006072998, 'learning_rate': 2.0525423728813563e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [3:31:58<2:23:32,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [3:32:01<2:20:37,  3.49s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.11652818322181702, 'learning_rate': 2.0516949152542374e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [3:32:01<2:20:37,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [3:32:05<2:19:27,  3.46s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.317948818206787, 'learning_rate': 2.0508474576271186e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [3:32:05<2:19:27,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [3:32:09<2:24:26,  3.58s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.16588900983333588, 'learning_rate': 2.05e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [3:32:09<2:24:26,  3.58s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [3:32:12<2:23:24,  3.56s/it]                                                       {'loss': 0.2241, 'grad_norm': 6.492974758148193, 'learning_rate': 2.0491525423728815e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [3:32:12<2:23:24,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [3:32:16<2:25:47,  3.62s/it]                                                       {'loss': 0.0538, 'grad_norm': 5.006444454193115, 'learning_rate': 2.0483050847457626e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [3:32:16<2:25:47,  3.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [3:32:19<2:23:12,  3.56s/it]                                                       {'loss': 0.0194, 'grad_norm': 1.4652206897735596, 'learning_rate': 2.047457627118644e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [3:32:19<2:23:12,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [3:32:23<2:20:36,  3.49s/it]                                                       {'loss': 0.0617, 'grad_norm': 4.533804893493652, 'learning_rate': 2.0466101694915256e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [3:32:23<2:20:36,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [3:32:26<2:18:50,  3.45s/it]                                                       {'loss': 0.0864, 'grad_norm': 6.060894966125488, 'learning_rate': 2.0457627118644067e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [3:32:26<2:18:50,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [3:32:29<2:17:52,  3.43s/it]                                                       {'loss': 0.0954, 'grad_norm': 6.142655372619629, 'learning_rate': 2.044915254237288e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [3:32:29<2:17:52,  3.43s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [3:32:33<2:17:54,  3.43s/it]                                                       {'loss': 0.1635, 'grad_norm': 7.164435863494873, 'learning_rate': 2.0440677966101696e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [3:32:33<2:17:54,  3.43s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [3:32:36<2:18:08,  3.44s/it]                                                       {'loss': 0.1848, 'grad_norm': 4.585223197937012, 'learning_rate': 2.043220338983051e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [3:32:36<2:18:08,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [3:32:40<2:16:59,  3.41s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.8489521145820618, 'learning_rate': 2.0423728813559322e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [3:32:40<2:16:59,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [3:32:43<2:15:58,  3.39s/it]                                                       {'loss': 0.2139, 'grad_norm': 8.02950668334961, 'learning_rate': 2.0415254237288137e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [3:32:43<2:15:58,  3.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [3:32:46<2:16:08,  3.39s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.41657546162605286, 'learning_rate': 2.040677966101695e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [3:32:46<2:16:08,  3.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [3:32:50<2:15:55,  3.39s/it]                                                       {'loss': 0.2099, 'grad_norm': 7.120246887207031, 'learning_rate': 2.0398305084745763e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [3:32:50<2:15:55,  3.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [3:32:54<2:22:28,  3.55s/it]                                                       {'loss': 0.1258, 'grad_norm': 5.96563720703125, 'learning_rate': 2.0389830508474577e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [3:32:54<2:22:28,  3.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [3:32:57<2:21:11,  3.52s/it]                                                       {'loss': 0.1785, 'grad_norm': 5.382302761077881, 'learning_rate': 2.0381355932203392e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [3:32:57<2:21:11,  3.52s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [3:33:01<2:19:17,  3.48s/it]                                                       {'loss': 0.0219, 'grad_norm': 2.5412819385528564, 'learning_rate': 2.0372881355932207e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [3:33:01<2:19:17,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [3:33:04<2:18:47,  3.47s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.0521364212036133, 'learning_rate': 2.0364406779661018e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [3:33:04<2:18:47,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [3:33:07<2:17:42,  3.44s/it]                                                       {'loss': 0.1479, 'grad_norm': 7.62840461730957, 'learning_rate': 2.0355932203389833e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [3:33:07<2:17:42,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [3:33:11<2:16:04,  3.40s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.8732564449310303, 'learning_rate': 2.0347457627118647e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [3:33:11<2:16:04,  3.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [3:33:14<2:15:01,  3.38s/it]                                                       {'loss': 0.0419, 'grad_norm': 4.206117630004883, 'learning_rate': 2.033898305084746e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [3:33:14<2:15:01,  3.38s/it][2025-10-20 19:03:00,967] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [3:33:20<2:47:13,  4.18s/it]                                                       {'loss': 0.0531, 'grad_norm': 5.836818695068359, 'learning_rate': 2.033050847457627e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [3:33:20<2:47:13,  4.18s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [3:33:23<2:38:28,  3.97s/it]                                                       {'loss': 0.0759, 'grad_norm': 5.590303421020508, 'learning_rate': 2.0322033898305085e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [3:33:23<2:38:28,  3.97s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [3:33:27<2:34:14,  3.86s/it]                                                       {'loss': 0.054, 'grad_norm': 6.260404586791992, 'learning_rate': 2.03135593220339e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [3:33:27<2:34:14,  3.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [3:33:30<2:28:08,  3.71s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.41793593764305115, 'learning_rate': 2.030508474576271e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [3:33:30<2:28:08,  3.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [3:33:34<2:23:59,  3.61s/it]                                                       {'loss': 0.001, 'grad_norm': 0.20792055130004883, 'learning_rate': 2.0296610169491525e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [3:33:34<2:23:59,  3.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [3:33:37<2:21:35,  3.55s/it]                                                       {'loss': 0.0913, 'grad_norm': 2.6079206466674805, 'learning_rate': 2.028813559322034e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [3:33:37<2:21:35,  3.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [3:33:41<2:19:57,  3.51s/it]                                                       {'loss': 0.1072, 'grad_norm': 8.946481704711914, 'learning_rate': 2.0279661016949155e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [3:33:41<2:19:57,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [3:33:44<2:20:03,  3.51s/it]                                                       {'loss': 0.1099, 'grad_norm': 8.377659797668457, 'learning_rate': 2.0271186440677966e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [3:33:44<2:20:03,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [3:33:48<2:28:46,  3.73s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.6422669887542725, 'learning_rate': 2.026271186440678e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [3:33:48<2:28:46,  3.73s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [3:33:53<2:36:17,  3.92s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.9230433702468872, 'learning_rate': 2.0254237288135595e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [3:33:53<2:36:17,  3.92s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [3:33:56<2:29:34,  3.76s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5092948079109192, 'learning_rate': 2.0245762711864407e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [3:33:56<2:29:34,  3.76s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [3:34:00<2:26:47,  3.69s/it]                                                       {'loss': 0.0213, 'grad_norm': 2.164353132247925, 'learning_rate': 2.023728813559322e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [3:34:00<2:26:47,  3.69s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [3:34:03<2:22:41,  3.59s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2424677461385727, 'learning_rate': 2.0228813559322036e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [3:34:03<2:22:41,  3.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [3:34:07<2:24:47,  3.64s/it]                                                       {'loss': 0.0317, 'grad_norm': 2.5765950679779053, 'learning_rate': 2.0220338983050847e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [3:34:07<2:24:47,  3.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [3:34:10<2:21:32,  3.56s/it]                                                       {'loss': 0.3404, 'grad_norm': 10.827510833740234, 'learning_rate': 2.0211864406779662e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [3:34:10<2:21:32,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [3:34:14<2:19:36,  3.51s/it]                                                       {'loss': 0.1836, 'grad_norm': 8.35632610321045, 'learning_rate': 2.0203389830508477e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [3:34:14<2:19:36,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [3:34:17<2:17:59,  3.47s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.8395880460739136, 'learning_rate': 2.019491525423729e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [3:34:17<2:17:59,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [3:34:20<2:17:24,  3.46s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.1188738346099854, 'learning_rate': 2.0186440677966103e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [3:34:20<2:17:24,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [3:34:24<2:17:54,  3.48s/it]                                                       {'loss': 0.0943, 'grad_norm': 5.601134300231934, 'learning_rate': 2.0177966101694917e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [3:34:24<2:17:54,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [3:34:27<2:16:48,  3.45s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.5035144090652466, 'learning_rate': 2.0169491525423732e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [3:34:27<2:16:48,  3.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [3:34:31<2:18:27,  3.49s/it]                                                       {'loss': 0.1181, 'grad_norm': 7.883790969848633, 'learning_rate': 2.0161016949152543e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [3:34:31<2:18:27,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [3:34:34<2:16:30,  3.44s/it]                                                       {'loss': 0.1646, 'grad_norm': 6.196234703063965, 'learning_rate': 2.0152542372881354e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [3:34:34<2:16:30,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [3:34:38<2:15:33,  3.42s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.28905901312828064, 'learning_rate': 2.014406779661017e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [3:34:38<2:15:33,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [3:34:41<2:14:49,  3.40s/it]                                                       {'loss': 0.1207, 'grad_norm': 5.8773722648620605, 'learning_rate': 2.0135593220338984e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [3:34:41<2:14:49,  3.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [3:34:44<2:14:19,  3.39s/it]                                                       {'loss': 0.2078, 'grad_norm': 9.603178977966309, 'learning_rate': 2.0127118644067795e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [3:34:44<2:14:19,  3.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [3:34:48<2:14:25,  3.40s/it]                                                       {'loss': 0.0512, 'grad_norm': 6.325443744659424, 'learning_rate': 2.011864406779661e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [3:34:48<2:14:25,  3.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [3:34:51<2:14:52,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.020535532385110855, 'learning_rate': 2.0110169491525424e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [3:34:51<2:14:52,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [3:34:54<2:13:26,  3.38s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.9303956031799316, 'learning_rate': 2.010169491525424e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [3:34:54<2:13:26,  3.38s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [3:34:58<2:18:06,  3.49s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.8105056881904602, 'learning_rate': 2.009322033898305e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [3:34:58<2:18:06,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [3:35:02<2:16:41,  3.46s/it]                                                       {'loss': 0.1973, 'grad_norm': 8.575366973876953, 'learning_rate': 2.0084745762711865e-05, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [3:35:02<2:16:41,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [3:35:05<2:16:00,  3.44s/it]                                                       {'loss': 0.0351, 'grad_norm': 3.612135410308838, 'learning_rate': 2.007627118644068e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [3:35:05<2:16:00,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [3:35:08<2:15:38,  3.44s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5654737949371338, 'learning_rate': 2.006779661016949e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [3:35:08<2:15:38,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [3:35:13<2:25:53,  3.70s/it]                                                       {'loss': 0.2677, 'grad_norm': 8.501192092895508, 'learning_rate': 2.0059322033898306e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [3:35:13<2:25:53,  3.70s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [3:35:16<2:21:55,  3.60s/it]                                                       {'loss': 0.096, 'grad_norm': 6.822571277618408, 'learning_rate': 2.005084745762712e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [3:35:16<2:21:55,  3.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [3:35:19<2:18:47,  3.52s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.20581792294979095, 'learning_rate': 2.0042372881355935e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [3:35:19<2:18:47,  3.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [3:35:23<2:17:48,  3.50s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.0422968864440918, 'learning_rate': 2.0033898305084746e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [3:35:23<2:17:48,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [3:35:27<2:19:28,  3.54s/it]                                                       {'loss': 0.1039, 'grad_norm': 4.915335178375244, 'learning_rate': 2.002542372881356e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [3:35:27<2:19:28,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [3:35:30<2:18:46,  3.53s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09550831466913223, 'learning_rate': 2.0016949152542376e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [3:35:30<2:18:46,  3.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [3:35:33<2:16:56,  3.48s/it]                                                       {'loss': 0.096, 'grad_norm': 8.789206504821777, 'learning_rate': 2.0008474576271187e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [3:35:33<2:16:56,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [3:35:37<2:17:35,  3.50s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6077159643173218, 'learning_rate': 2e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [3:35:37<2:17:35,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [3:35:40<2:16:36,  3.47s/it]                                                       {'loss': 0.0303, 'grad_norm': 3.3392090797424316, 'learning_rate': 1.9991525423728816e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [3:35:40<2:16:36,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [3:35:44<2:16:11,  3.47s/it]                                                       {'loss': 0.0817, 'grad_norm': 3.548473358154297, 'learning_rate': 1.998305084745763e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [3:35:44<2:16:11,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [3:35:48<2:20:58,  3.59s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08256576955318451, 'learning_rate': 1.997457627118644e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [3:35:48<2:20:58,  3.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [3:35:51<2:17:33,  3.50s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11074274033308029, 'learning_rate': 1.9966101694915254e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [3:35:51<2:17:33,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [3:35:54<2:17:32,  3.50s/it]                                                       {'loss': 0.1809, 'grad_norm': 12.426636695861816, 'learning_rate': 1.9957627118644068e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [3:35:55<2:17:32,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [3:35:58<2:16:29,  3.48s/it]                                                       {'loss': 0.1622, 'grad_norm': 6.803976535797119, 'learning_rate': 1.9949152542372883e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [3:35:58<2:16:29,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [3:36:01<2:15:20,  3.45s/it]                                                       {'loss': 0.0846, 'grad_norm': 5.009449005126953, 'learning_rate': 1.9940677966101694e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [3:36:01<2:15:20,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [3:36:05<2:14:27,  3.43s/it]                                                       {'loss': 0.0316, 'grad_norm': 4.629330635070801, 'learning_rate': 1.993220338983051e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [3:36:05<2:14:27,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [3:36:08<2:14:54,  3.44s/it]                                                       {'loss': 0.0223, 'grad_norm': 1.9832741022109985, 'learning_rate': 1.9923728813559324e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [3:36:08<2:14:54,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [3:36:12<2:14:00,  3.42s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.11200017482042313, 'learning_rate': 1.9915254237288135e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [3:36:12<2:14:00,  3.42s/it][2025-10-20 19:05:58,521] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [3:36:17<2:40:57,  4.11s/it]                                                       {'loss': 0.005, 'grad_norm': 0.9521711468696594, 'learning_rate': 1.990677966101695e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [3:36:17<2:40:57,  4.11s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [3:36:21<2:35:19,  3.97s/it]                                                       {'loss': 0.0554, 'grad_norm': 5.414251327514648, 'learning_rate': 1.9898305084745764e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [3:36:21<2:35:19,  3.97s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [3:36:24<2:28:12,  3.79s/it]                                                       {'loss': 0.0866, 'grad_norm': 6.15300178527832, 'learning_rate': 1.988983050847458e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [3:36:24<2:28:12,  3.79s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [3:36:28<2:22:24,  3.64s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.026221323758363724, 'learning_rate': 1.988135593220339e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [3:36:28<2:22:24,  3.64s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [3:36:31<2:19:59,  3.58s/it]                                                       {'loss': 0.2078, 'grad_norm': 8.580013275146484, 'learning_rate': 1.9872881355932205e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [3:36:31<2:19:59,  3.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [3:36:34<2:17:09,  3.51s/it]                                                       {'loss': 0.2495, 'grad_norm': 8.242696762084961, 'learning_rate': 1.986440677966102e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [3:36:34<2:17:09,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [3:36:38<2:15:04,  3.46s/it]                                                       {'loss': 0.038, 'grad_norm': 3.63655686378479, 'learning_rate': 1.985593220338983e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [3:36:38<2:15:04,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [3:36:41<2:15:35,  3.47s/it]                                                       {'loss': 0.0265, 'grad_norm': 2.910975694656372, 'learning_rate': 1.9847457627118645e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [3:36:41<2:15:35,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [3:36:45<2:18:34,  3.55s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5854549407958984, 'learning_rate': 1.983898305084746e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [3:36:45<2:18:34,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [3:36:48<2:16:48,  3.51s/it]                                                       {'loss': 0.0321, 'grad_norm': 4.863700866699219, 'learning_rate': 1.9830508474576275e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [3:36:48<2:16:48,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [3:36:52<2:15:22,  3.47s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.4578170776367188, 'learning_rate': 1.9822033898305086e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [3:36:52<2:15:22,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [3:36:55<2:13:26,  3.42s/it]                                                       {'loss': 0.0211, 'grad_norm': 1.9881945848464966, 'learning_rate': 1.98135593220339e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [3:36:55<2:13:26,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [3:36:58<2:13:50,  3.44s/it]                                                       {'loss': 0.1051, 'grad_norm': 5.759850025177002, 'learning_rate': 1.9805084745762712e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [3:36:58<2:13:50,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [3:37:02<2:13:04,  3.42s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.5412321090698242, 'learning_rate': 1.9796610169491527e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [3:37:02<2:13:04,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [3:37:06<2:20:05,  3.60s/it]                                                       {'loss': 0.0118, 'grad_norm': 1.8678094148635864, 'learning_rate': 1.9788135593220338e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [3:37:06<2:20:05,  3.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [3:37:10<2:24:37,  3.72s/it]                                                       {'loss': 0.1107, 'grad_norm': 4.34708833694458, 'learning_rate': 1.9779661016949153e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [3:37:10<2:24:37,  3.72s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [3:37:13<2:21:02,  3.63s/it]                                                       {'loss': 0.0388, 'grad_norm': 4.285689353942871, 'learning_rate': 1.9771186440677967e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [3:37:13<2:21:02,  3.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [3:37:17<2:18:32,  3.56s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.08942607790231705, 'learning_rate': 1.976271186440678e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [3:37:17<2:18:32,  3.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [3:37:20<2:17:23,  3.54s/it]                                                       {'loss': 0.0759, 'grad_norm': 5.65524435043335, 'learning_rate': 1.9754237288135593e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [3:37:20<2:17:23,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [3:37:24<2:20:48,  3.63s/it]                                                       {'loss': 0.061, 'grad_norm': 5.694689750671387, 'learning_rate': 1.9745762711864408e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [3:37:24<2:20:48,  3.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [3:37:27<2:16:39,  3.52s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.0852572917938232, 'learning_rate': 1.9737288135593223e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [3:37:27<2:16:39,  3.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [3:37:31<2:15:20,  3.49s/it]                                                       {'loss': 0.025, 'grad_norm': 2.0929200649261475, 'learning_rate': 1.9728813559322034e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [3:37:31<2:15:20,  3.49s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [3:37:34<2:13:16,  3.44s/it]                                                       {'loss': 0.233, 'grad_norm': 9.838547706604004, 'learning_rate': 1.972033898305085e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [3:37:34<2:13:16,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [3:37:38<2:17:44,  3.55s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.8988794088363647, 'learning_rate': 1.9711864406779663e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [3:37:38<2:17:44,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [3:37:41<2:18:08,  3.56s/it]                                                       {'loss': 0.0487, 'grad_norm': 4.2373762130737305, 'learning_rate': 1.9703389830508475e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [3:37:41<2:18:08,  3.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [3:37:45<2:17:20,  3.55s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.4610963463783264, 'learning_rate': 1.969491525423729e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [3:37:45<2:17:20,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [3:37:48<2:15:58,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02480543591082096, 'learning_rate': 1.9686440677966104e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [3:37:48<2:15:58,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [3:37:52<2:13:50,  3.46s/it]                                                       {'loss': 0.0631, 'grad_norm': 3.3529446125030518, 'learning_rate': 1.9677966101694915e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [3:37:52<2:13:50,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [3:37:55<2:12:45,  3.43s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.10932625830173492, 'learning_rate': 1.966949152542373e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [3:37:55<2:12:45,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [3:37:59<2:13:42,  3.46s/it]                                                       {'loss': 0.027, 'grad_norm': 3.413496732711792, 'learning_rate': 1.9661016949152545e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [3:37:59<2:13:42,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [3:38:02<2:15:07,  3.50s/it]                                                       {'loss': 0.0349, 'grad_norm': 2.644787311553955, 'learning_rate': 1.965254237288136e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [3:38:02<2:15:07,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [3:38:06<2:14:16,  3.48s/it]                                                       {'loss': 0.0512, 'grad_norm': 4.231410503387451, 'learning_rate': 1.964406779661017e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [3:38:06<2:14:16,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [3:38:09<2:18:53,  3.60s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8766919374465942, 'learning_rate': 1.9635593220338985e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [3:38:09<2:18:53,  3.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [3:38:13<2:16:24,  3.53s/it]                                                       {'loss': 0.1255, 'grad_norm': 7.555019378662109, 'learning_rate': 1.9627118644067796e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [3:38:13<2:16:24,  3.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [3:38:17<2:18:51,  3.60s/it]                                                       {'loss': 0.0241, 'grad_norm': 2.173473358154297, 'learning_rate': 1.961864406779661e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [3:38:17<2:18:51,  3.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [3:38:20<2:20:19,  3.64s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.01321773324161768, 'learning_rate': 1.9610169491525422e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [3:38:20<2:20:19,  3.64s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [3:38:24<2:22:18,  3.69s/it]                                                       {'loss': 0.0997, 'grad_norm': 7.181975364685059, 'learning_rate': 1.9601694915254237e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [3:38:24<2:22:18,  3.69s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [3:38:28<2:18:33,  3.60s/it]                                                       {'loss': 0.016, 'grad_norm': 2.274001121520996, 'learning_rate': 1.9593220338983052e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [3:38:28<2:18:33,  3.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [3:38:31<2:16:13,  3.54s/it]                                                       {'loss': 0.0433, 'grad_norm': 5.050014972686768, 'learning_rate': 1.9584745762711863e-05, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [3:38:31<2:16:13,  3.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [3:38:35<2:16:23,  3.54s/it]                                                       {'loss': 0.0424, 'grad_norm': 3.2745776176452637, 'learning_rate': 1.9576271186440678e-05, 'epoch': 0.61}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [3:38:35<2:16:23,  3.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [3:38:38<2:13:45,  3.48s/it]                                                       {'loss': 0.0547, 'grad_norm': 2.0344135761260986, 'learning_rate': 1.9567796610169492e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [3:38:38<2:13:45,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [3:38:41<2:14:26,  3.50s/it]                                                       {'loss': 0.024, 'grad_norm': 5.256043434143066, 'learning_rate': 1.9559322033898307e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [3:38:41<2:14:26,  3.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [3:38:45<2:14:09,  3.49s/it]                                                       {'loss': 0.0314, 'grad_norm': 3.830895185470581, 'learning_rate': 1.955084745762712e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [3:38:45<2:14:09,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [3:38:49<2:16:21,  3.55s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.1761887073516846, 'learning_rate': 1.9542372881355933e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [3:38:49<2:16:21,  3.55s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [3:38:52<2:15:23,  3.52s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.28944095969200134, 'learning_rate': 1.9533898305084748e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [3:38:52<2:15:23,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [3:38:55<2:14:20,  3.50s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1467835158109665, 'learning_rate': 1.952542372881356e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [3:38:55<2:14:20,  3.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [3:38:59<2:14:16,  3.50s/it]                                                       {'loss': 0.0856, 'grad_norm': 7.460562229156494, 'learning_rate': 1.9516949152542374e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [3:38:59<2:14:16,  3.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [3:39:03<2:22:37,  3.72s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11692171543836594, 'learning_rate': 1.950847457627119e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [3:39:03<2:22:37,  3.72s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [3:39:07<2:22:36,  3.72s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.881549060344696, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [3:39:07<2:22:36,  3.72s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [3:39:11<2:22:40,  3.72s/it]                                                       {'loss': 0.1614, 'grad_norm': 10.707756042480469, 'learning_rate': 1.9491525423728814e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [3:39:11<2:22:40,  3.72s/it][2025-10-20 19:08:57,613] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [3:39:16<2:46:28,  4.34s/it]                                                       {'loss': 0.1087, 'grad_norm': 5.120942115783691, 'learning_rate': 1.948305084745763e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [3:39:16<2:46:28,  4.34s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [3:39:20<2:34:36,  4.04s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.5836553573608398, 'learning_rate': 1.9474576271186444e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [3:39:20<2:34:36,  4.04s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [3:39:23<2:26:41,  3.83s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.449702262878418, 'learning_rate': 1.9466101694915255e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [3:39:23<2:26:41,  3.83s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [3:39:27<2:21:54,  3.71s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5471659302711487, 'learning_rate': 1.945762711864407e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [3:39:27<2:21:54,  3.71s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [3:39:30<2:18:51,  3.63s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.910111427307129, 'learning_rate': 1.944915254237288e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [3:39:30<2:18:51,  3.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [3:39:34<2:21:31,  3.70s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.7327123880386353, 'learning_rate': 1.9440677966101696e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [3:39:34<2:21:31,  3.70s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [3:39:37<2:17:40,  3.60s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.14318415522575378, 'learning_rate': 1.9432203389830507e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [3:39:37<2:17:40,  3.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [3:39:41<2:15:01,  3.53s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.6525831818580627, 'learning_rate': 1.942372881355932e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [3:39:41<2:15:01,  3.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [3:39:44<2:12:25,  3.47s/it]                                                       {'loss': 0.0453, 'grad_norm': 5.950055122375488, 'learning_rate': 1.9415254237288136e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [3:39:44<2:12:25,  3.47s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [3:39:47<2:11:43,  3.45s/it]                                                       {'loss': 0.1381, 'grad_norm': 5.375676155090332, 'learning_rate': 1.940677966101695e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [3:39:47<2:11:43,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [3:39:51<2:10:26,  3.42s/it]                                                       {'loss': 0.1699, 'grad_norm': 8.12994384765625, 'learning_rate': 1.9398305084745762e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [3:39:51<2:10:26,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [3:39:54<2:09:48,  3.40s/it]                                                       {'loss': 0.008, 'grad_norm': 1.3398220539093018, 'learning_rate': 1.9389830508474577e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [3:39:54<2:09:48,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [3:39:57<2:10:05,  3.41s/it]                                                       {'loss': 0.0533, 'grad_norm': 5.279557228088379, 'learning_rate': 1.938135593220339e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [3:39:57<2:10:05,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [3:40:01<2:11:17,  3.45s/it]                                                       {'loss': 0.1392, 'grad_norm': 3.889643669128418, 'learning_rate': 1.9372881355932203e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [3:40:01<2:11:17,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [3:40:04<2:11:52,  3.46s/it]                                                       {'loss': 0.0464, 'grad_norm': 6.39263391494751, 'learning_rate': 1.9364406779661017e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [3:40:04<2:11:52,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [3:40:08<2:10:16,  3.42s/it]                                                       {'loss': 0.0328, 'grad_norm': 4.244789123535156, 'learning_rate': 1.9355932203389832e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [3:40:08<2:10:16,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [3:40:11<2:10:01,  3.42s/it]                                                       {'loss': 0.0482, 'grad_norm': 3.8845343589782715, 'learning_rate': 1.9347457627118647e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [3:40:11<2:10:01,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [3:40:15<2:09:59,  3.42s/it]                                                       {'loss': 0.0368, 'grad_norm': 2.1746199131011963, 'learning_rate': 1.9338983050847458e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [3:40:15<2:09:59,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [3:40:18<2:12:12,  3.48s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.7621168494224548, 'learning_rate': 1.9330508474576273e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [3:40:18<2:12:12,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [3:40:22<2:11:22,  3.46s/it]                                                       {'loss': 0.134, 'grad_norm': 5.848634719848633, 'learning_rate': 1.9322033898305087e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [3:40:22<2:11:22,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [3:40:25<2:10:41,  3.44s/it]                                                       {'loss': 0.1308, 'grad_norm': 7.972604751586914, 'learning_rate': 1.93135593220339e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [3:40:25<2:10:41,  3.44s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [3:40:29<2:14:55,  3.55s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.18462565541267395, 'learning_rate': 1.9305084745762713e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [3:40:29<2:14:55,  3.55s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [3:40:32<2:12:13,  3.48s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11393756419420242, 'learning_rate': 1.9296610169491528e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [3:40:32<2:12:13,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [3:40:36<2:17:08,  3.62s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.0544118881225586, 'learning_rate': 1.9288135593220343e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [3:40:36<2:17:08,  3.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [3:40:40<2:15:10,  3.57s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.10261522978544235, 'learning_rate': 1.9279661016949154e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [3:40:40<2:15:10,  3.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [3:40:43<2:17:45,  3.63s/it]                                                       {'loss': 0.1986, 'grad_norm': 6.369897842407227, 'learning_rate': 1.9271186440677965e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [3:40:43<2:17:45,  3.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [3:40:47<2:15:40,  3.58s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012235189788043499, 'learning_rate': 1.926271186440678e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [3:40:47<2:15:40,  3.58s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [3:40:50<2:12:47,  3.51s/it]                                                       {'loss': 0.0426, 'grad_norm': 5.229813098907471, 'learning_rate': 1.9254237288135595e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [3:40:50<2:12:47,  3.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [3:40:54<2:11:44,  3.48s/it]                                                       {'loss': 0.1507, 'grad_norm': 8.795388221740723, 'learning_rate': 1.9245762711864406e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [3:40:54<2:11:44,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [3:40:57<2:16:01,  3.60s/it]                                                       {'loss': 0.0634, 'grad_norm': 4.336998462677002, 'learning_rate': 1.923728813559322e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [3:40:57<2:16:01,  3.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [3:41:01<2:13:37,  3.53s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.0987890362739563, 'learning_rate': 1.9228813559322035e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [3:41:01<2:13:37,  3.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [3:41:04<2:13:09,  3.52s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.3206156492233276, 'learning_rate': 1.9220338983050847e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [3:41:04<2:13:09,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [3:41:08<2:17:09,  3.63s/it]                                                       {'loss': 0.0, 'grad_norm': 0.004682502709329128, 'learning_rate': 1.921186440677966e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [3:41:08<2:17:09,  3.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [3:41:12<2:18:37,  3.67s/it]                                                       {'loss': 0.0234, 'grad_norm': 3.3036718368530273, 'learning_rate': 1.9203389830508476e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [3:41:12<2:18:37,  3.67s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [3:41:15<2:16:12,  3.61s/it]                                                       {'loss': 0.1372, 'grad_norm': 4.414590835571289, 'learning_rate': 1.919491525423729e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [3:41:15<2:16:12,  3.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [3:41:19<2:13:40,  3.54s/it]                                                       {'loss': 0.0407, 'grad_norm': 1.9259902238845825, 'learning_rate': 1.9186440677966102e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [3:41:19<2:13:40,  3.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [3:41:22<2:12:21,  3.51s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.3049143552780151, 'learning_rate': 1.9177966101694917e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [3:41:22<2:12:21,  3.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [3:41:26<2:11:39,  3.49s/it]                                                       {'loss': 0.0627, 'grad_norm': 3.680173397064209, 'learning_rate': 1.916949152542373e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [3:41:26<2:11:39,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [3:41:29<2:10:28,  3.46s/it]                                                       {'loss': 0.1443, 'grad_norm': 8.62003231048584, 'learning_rate': 1.9161016949152543e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [3:41:29<2:10:28,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [3:41:32<2:08:07,  3.40s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.09195858240127563, 'learning_rate': 1.9152542372881357e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [3:41:32<2:08:07,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [3:41:36<2:08:11,  3.40s/it]                                                       {'loss': 0.1554, 'grad_norm': 6.152866840362549, 'learning_rate': 1.9144067796610172e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [3:41:36<2:08:11,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [3:41:39<2:07:53,  3.40s/it]                                                       {'loss': 0.1871, 'grad_norm': 9.575587272644043, 'learning_rate': 1.9135593220338983e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [3:41:39<2:07:53,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [3:41:43<2:07:28,  3.39s/it]                                                       {'loss': 0.0348, 'grad_norm': 3.3979227542877197, 'learning_rate': 1.9127118644067798e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [3:41:43<2:07:28,  3.39s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [3:41:46<2:07:13,  3.38s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4099910259246826, 'learning_rate': 1.9118644067796613e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [3:41:46<2:07:13,  3.38s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [3:41:49<2:07:36,  3.40s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.3631933927536011, 'learning_rate': 1.9110169491525427e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [3:41:49<2:07:36,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [3:41:53<2:12:08,  3.52s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2445553094148636, 'learning_rate': 1.910169491525424e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [3:41:53<2:12:08,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [3:41:56<2:10:34,  3.48s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.671537399291992, 'learning_rate': 1.909322033898305e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [3:41:56<2:10:34,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [3:42:00<2:09:04,  3.44s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.980948805809021, 'learning_rate': 1.9084745762711864e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [3:42:00<2:09:04,  3.44s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [3:42:03<2:07:03,  3.39s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.3403602838516235, 'learning_rate': 1.907627118644068e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [3:42:03<2:07:03,  3.39s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [3:42:07<2:07:13,  3.39s/it]                                                       {'loss': 0.0454, 'grad_norm': 5.873773097991943, 'learning_rate': 1.906779661016949e-05, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [3:42:07<2:07:13,  3.39s/it][2025-10-20 19:11:53,507] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [3:42:12<2:31:44,  4.05s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.4571425914764404, 'learning_rate': 1.9059322033898305e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [3:42:12<2:31:44,  4.05s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [3:42:15<2:24:13,  3.85s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.7364293336868286, 'learning_rate': 1.905084745762712e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [3:42:15<2:24:13,  3.85s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [3:42:19<2:17:57,  3.68s/it]                                                       {'loss': 0.002, 'grad_norm': 0.201760932803154, 'learning_rate': 1.904237288135593e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [3:42:19<2:17:57,  3.68s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [3:42:22<2:14:09,  3.58s/it]                                                       {'loss': 0.0348, 'grad_norm': 4.570827484130859, 'learning_rate': 1.9033898305084746e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [3:42:22<2:14:09,  3.58s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [3:42:26<2:13:22,  3.56s/it]                                                       {'loss': 0.0295, 'grad_norm': 4.535378932952881, 'learning_rate': 1.902542372881356e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [3:42:26<2:13:22,  3.56s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [3:42:29<2:10:56,  3.50s/it]                                                       {'loss': 0.0157, 'grad_norm': 2.2281782627105713, 'learning_rate': 1.9016949152542375e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [3:42:29<2:10:56,  3.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [3:42:33<2:12:22,  3.54s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.7927093505859375, 'learning_rate': 1.9008474576271186e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [3:42:33<2:12:22,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [3:42:36<2:11:31,  3.52s/it]                                                       {'loss': 0.005, 'grad_norm': 0.592862069606781, 'learning_rate': 1.9e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [3:42:36<2:11:31,  3.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [3:42:40<2:10:46,  3.50s/it]                                                       {'loss': 0.035, 'grad_norm': 2.538470506668091, 'learning_rate': 1.8991525423728816e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [3:42:40<2:10:46,  3.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [3:42:43<2:08:52,  3.45s/it]                                                       {'loss': 0.3315, 'grad_norm': 9.785923957824707, 'learning_rate': 1.8983050847457627e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [3:42:43<2:08:52,  3.45s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [3:42:46<2:08:09,  3.43s/it]                                                       {'loss': 0.0519, 'grad_norm': 3.3834922313690186, 'learning_rate': 1.897457627118644e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [3:42:46<2:08:09,  3.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [3:42:50<2:09:28,  3.47s/it]                                                       {'loss': 0.0272, 'grad_norm': 1.9646633863449097, 'learning_rate': 1.8966101694915256e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [3:42:50<2:09:28,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [3:42:53<2:08:40,  3.45s/it]                                                       {'loss': 0.0278, 'grad_norm': 4.026398658752441, 'learning_rate': 1.895762711864407e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [3:42:53<2:08:40,  3.45s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [3:42:57<2:07:58,  3.43s/it]                                                       {'loss': 0.0282, 'grad_norm': 3.5408074855804443, 'learning_rate': 1.8949152542372882e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [3:42:57<2:07:58,  3.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [3:43:00<2:08:04,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.051347970962524414, 'learning_rate': 1.8940677966101697e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [3:43:00<2:08:04,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [3:43:04<2:09:51,  3.49s/it]                                                       {'loss': 0.0875, 'grad_norm': 6.215095520019531, 'learning_rate': 1.893220338983051e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [3:43:04<2:09:51,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [3:43:07<2:09:09,  3.47s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6758440136909485, 'learning_rate': 1.8923728813559323e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [3:43:07<2:09:09,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [3:43:11<2:08:58,  3.47s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5771690607070923, 'learning_rate': 1.8915254237288134e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [3:43:11<2:08:58,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [3:43:14<2:07:57,  3.44s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.14285197854042053, 'learning_rate': 1.890677966101695e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [3:43:14<2:07:57,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [3:43:18<2:09:38,  3.49s/it]                                                       {'loss': 0.1299, 'grad_norm': 8.759137153625488, 'learning_rate': 1.8898305084745764e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [3:43:18<2:09:38,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [3:43:21<2:10:18,  3.51s/it]                                                       {'loss': 0.0528, 'grad_norm': 6.019023895263672, 'learning_rate': 1.8889830508474575e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [3:43:21<2:10:18,  3.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [3:43:25<2:12:44,  3.57s/it]                                                       {'loss': 0.0481, 'grad_norm': 3.3834245204925537, 'learning_rate': 1.888135593220339e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [3:43:25<2:12:44,  3.57s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [3:43:28<2:11:28,  3.54s/it]                                                       {'loss': 0.0284, 'grad_norm': 1.06977379322052, 'learning_rate': 1.8872881355932204e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [3:43:28<2:11:28,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [3:43:33<2:19:36,  3.76s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.8622002601623535, 'learning_rate': 1.886440677966102e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [3:43:33<2:19:36,  3.76s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [3:43:36<2:16:11,  3.67s/it]                                                       {'loss': 0.0803, 'grad_norm': 8.463994979858398, 'learning_rate': 1.885593220338983e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [3:43:36<2:16:11,  3.67s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [3:43:40<2:14:03,  3.62s/it]                                                       {'loss': 0.0188, 'grad_norm': 2.4540436267852783, 'learning_rate': 1.8847457627118645e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [3:43:40<2:14:03,  3.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [3:43:43<2:11:02,  3.54s/it]                                                       {'loss': 0.0174, 'grad_norm': 1.1555826663970947, 'learning_rate': 1.883898305084746e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [3:43:43<2:11:02,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [3:43:46<2:09:04,  3.49s/it]                                                       {'loss': 0.0892, 'grad_norm': 4.750288486480713, 'learning_rate': 1.883050847457627e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [3:43:46<2:09:04,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [3:43:50<2:08:40,  3.48s/it]                                                       {'loss': 0.0451, 'grad_norm': 2.98691987991333, 'learning_rate': 1.8822033898305085e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [3:43:50<2:08:40,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [3:43:53<2:07:06,  3.44s/it]                                                       {'loss': 0.073, 'grad_norm': 5.336390018463135, 'learning_rate': 1.88135593220339e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [3:43:53<2:07:06,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [3:43:57<2:07:48,  3.46s/it]                                                       {'loss': 0.0316, 'grad_norm': 2.4120829105377197, 'learning_rate': 1.8805084745762715e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [3:43:57<2:07:48,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [3:44:00<2:07:00,  3.44s/it]                                                       {'loss': 0.0458, 'grad_norm': 5.354343414306641, 'learning_rate': 1.8796610169491526e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [3:44:00<2:07:00,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [3:44:03<2:07:17,  3.44s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.16676542162895203, 'learning_rate': 1.878813559322034e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [3:44:03<2:07:17,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [3:44:07<2:05:41,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02378542721271515, 'learning_rate': 1.8779661016949155e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [3:44:07<2:05:41,  3.40s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [3:44:11<2:10:42,  3.54s/it]                                                       {'loss': 0.0439, 'grad_norm': 5.002233028411865, 'learning_rate': 1.8771186440677967e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [3:44:11<2:10:42,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [3:44:14<2:10:57,  3.55s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.7274338603019714, 'learning_rate': 1.876271186440678e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [3:44:14<2:10:57,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [3:44:18<2:14:43,  3.65s/it]                                                       {'loss': 0.1128, 'grad_norm': 7.230935573577881, 'learning_rate': 1.8754237288135596e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [3:44:18<2:14:43,  3.65s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [3:44:22<2:12:54,  3.61s/it]                                                       {'loss': 0.1257, 'grad_norm': 5.975367546081543, 'learning_rate': 1.8745762711864407e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [3:44:22<2:12:54,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [3:44:25<2:12:58,  3.61s/it]                                                       {'loss': 0.0198, 'grad_norm': 1.9908571243286133, 'learning_rate': 1.873728813559322e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [3:44:25<2:12:58,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [3:44:29<2:13:38,  3.63s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012820888310670853, 'learning_rate': 1.8728813559322033e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [3:44:29<2:13:38,  3.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [3:44:33<2:19:40,  3.79s/it]                                                       {'loss': 0.2547, 'grad_norm': 9.270915031433105, 'learning_rate': 1.8720338983050848e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [3:44:33<2:19:40,  3.79s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [3:44:37<2:20:28,  3.82s/it]                                                       {'loss': 0.1221, 'grad_norm': 5.309841156005859, 'learning_rate': 1.8711864406779663e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [3:44:37<2:20:28,  3.82s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [3:44:40<2:15:22,  3.68s/it]                                                       {'loss': 0.1613, 'grad_norm': 6.729533672332764, 'learning_rate': 1.8703389830508474e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [3:44:40<2:15:22,  3.68s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [3:44:44<2:12:01,  3.59s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.127331018447876, 'learning_rate': 1.869491525423729e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [3:44:44<2:12:01,  3.59s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [3:44:47<2:09:08,  3.51s/it]                                                       {'loss': 0.0806, 'grad_norm': 5.0607709884643555, 'learning_rate': 1.8686440677966103e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [3:44:47<2:09:08,  3.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [3:44:51<2:12:30,  3.61s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04349362477660179, 'learning_rate': 1.8677966101694915e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [3:44:51<2:12:30,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [3:44:54<2:10:02,  3.54s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.30424317717552185, 'learning_rate': 1.866949152542373e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [3:44:54<2:10:02,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [3:44:58<2:09:11,  3.52s/it]                                                       {'loss': 0.019, 'grad_norm': 5.354051113128662, 'learning_rate': 1.8661016949152544e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [3:44:58<2:09:11,  3.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [3:45:01<2:07:36,  3.48s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.050637152045965195, 'learning_rate': 1.865254237288136e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [3:45:01<2:07:36,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [3:45:04<2:05:52,  3.43s/it]                                                       {'loss': 0.1348, 'grad_norm': 7.864624977111816, 'learning_rate': 1.864406779661017e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [3:45:04<2:05:52,  3.43s/it][2025-10-20 19:14:51,339] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [3:45:10<2:30:39,  4.11s/it]                                                       {'loss': 0.0416, 'grad_norm': 3.385158061981201, 'learning_rate': 1.8635593220338985e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [3:45:10<2:30:39,  4.11s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [3:45:13<2:22:20,  3.89s/it]                                                       {'loss': 0.0898, 'grad_norm': 4.969460487365723, 'learning_rate': 1.86271186440678e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [3:45:13<2:22:20,  3.89s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [3:45:17<2:17:14,  3.75s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.4040646255016327, 'learning_rate': 1.861864406779661e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [3:45:17<2:17:14,  3.75s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [3:45:20<2:12:48,  3.63s/it]                                                       {'loss': 0.035, 'grad_norm': 2.146101713180542, 'learning_rate': 1.8610169491525425e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [3:45:20<2:12:48,  3.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [3:45:24<2:09:55,  3.55s/it]                                                       {'loss': 0.0137, 'grad_norm': 2.2766692638397217, 'learning_rate': 1.860169491525424e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [3:45:24<2:09:55,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [3:45:27<2:09:15,  3.53s/it]                                                       {'loss': 0.1028, 'grad_norm': 3.471630334854126, 'learning_rate': 1.859322033898305e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [3:45:27<2:09:15,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [3:45:31<2:09:10,  3.53s/it]                                                       {'loss': 0.1577, 'grad_norm': 6.418421745300293, 'learning_rate': 1.8584745762711866e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [3:45:31<2:09:10,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [3:45:34<2:07:28,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.007471855264157057, 'learning_rate': 1.857627118644068e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [3:45:34<2:07:28,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [3:45:38<2:13:44,  3.66s/it]                                                       {'loss': 0.1611, 'grad_norm': 10.885705947875977, 'learning_rate': 1.8567796610169492e-05, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [3:45:38<2:13:44,  3.66s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [3:45:41<2:09:50,  3.56s/it]                                                       {'loss': 0.1097, 'grad_norm': 7.188040256500244, 'learning_rate': 1.8559322033898307e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [3:45:41<2:09:50,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [3:45:45<2:08:19,  3.52s/it]                                                       {'loss': 0.152, 'grad_norm': 8.125287055969238, 'learning_rate': 1.8550847457627118e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [3:45:45<2:08:19,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [3:45:48<2:08:54,  3.54s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.027435053139925003, 'learning_rate': 1.8542372881355932e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [3:45:48<2:08:54,  3.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [3:45:52<2:11:32,  3.61s/it]                                                       {'loss': 0.0581, 'grad_norm': 5.1471076011657715, 'learning_rate': 1.8533898305084747e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [3:45:52<2:11:32,  3.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [3:45:56<2:09:42,  3.56s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.5331840515136719, 'learning_rate': 1.852542372881356e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [3:45:56<2:09:42,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [3:45:59<2:07:52,  3.51s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.4889487028121948, 'learning_rate': 1.8516949152542373e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [3:45:59<2:07:52,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [3:46:02<2:05:29,  3.45s/it]                                                       {'loss': 0.0492, 'grad_norm': 3.5864696502685547, 'learning_rate': 1.8508474576271188e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [3:46:02<2:05:29,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [3:46:06<2:05:39,  3.45s/it]                                                       {'loss': 0.1137, 'grad_norm': 7.581883907318115, 'learning_rate': 1.85e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [3:46:06<2:05:39,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [3:46:09<2:04:58,  3.44s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.4469068050384521, 'learning_rate': 1.8491525423728814e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [3:46:09<2:04:58,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [3:46:13<2:04:54,  3.44s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.5938727855682373, 'learning_rate': 1.848305084745763e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [3:46:13<2:04:54,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [3:46:16<2:04:09,  3.42s/it]                                                       {'loss': 0.005, 'grad_norm': 1.0773937702178955, 'learning_rate': 1.8474576271186443e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [3:46:16<2:04:09,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [3:46:19<2:03:26,  3.40s/it]                                                       {'loss': 0.0377, 'grad_norm': 1.038295030593872, 'learning_rate': 1.8466101694915254e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [3:46:19<2:03:26,  3.40s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [3:46:23<2:04:14,  3.42s/it]                                                       {'loss': 0.1433, 'grad_norm': 4.222542762756348, 'learning_rate': 1.845762711864407e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [3:46:23<2:04:14,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [3:46:27<2:08:02,  3.53s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.49246400594711304, 'learning_rate': 1.8449152542372884e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [3:46:27<2:08:02,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [3:46:30<2:07:08,  3.51s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11839576065540314, 'learning_rate': 1.8440677966101695e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [3:46:30<2:07:08,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [3:46:33<2:05:28,  3.46s/it]                                                       {'loss': 0.0757, 'grad_norm': 4.276423454284668, 'learning_rate': 1.843220338983051e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [3:46:33<2:05:28,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [3:46:37<2:04:29,  3.44s/it]                                                       {'loss': 0.0952, 'grad_norm': 5.455991268157959, 'learning_rate': 1.8423728813559324e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [3:46:37<2:04:29,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [3:46:40<2:04:36,  3.44s/it]                                                       {'loss': 0.1303, 'grad_norm': 7.400207996368408, 'learning_rate': 1.841525423728814e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [3:46:40<2:04:36,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [3:46:44<2:04:29,  3.44s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.6633695363998413, 'learning_rate': 1.840677966101695e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [3:46:44<2:04:29,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [3:46:47<2:04:06,  3.43s/it]                                                       {'loss': 0.0699, 'grad_norm': 4.3221025466918945, 'learning_rate': 1.8398305084745765e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [3:46:47<2:04:06,  3.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [3:46:51<2:04:37,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08588878065347672, 'learning_rate': 1.8389830508474576e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [3:46:51<2:04:37,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [3:46:54<2:04:54,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.0360410213470459, 'learning_rate': 1.838135593220339e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [3:46:54<2:04:54,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [3:46:57<2:04:38,  3.45s/it]                                                       {'loss': 0.0664, 'grad_norm': 6.883878231048584, 'learning_rate': 1.8372881355932202e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [3:46:57<2:04:38,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [3:47:01<2:08:34,  3.56s/it]                                                       {'loss': 0.006, 'grad_norm': 0.5148981213569641, 'learning_rate': 1.8364406779661017e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [3:47:01<2:08:34,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [3:47:05<2:05:47,  3.48s/it]                                                       {'loss': 0.0937, 'grad_norm': 6.997257232666016, 'learning_rate': 1.835593220338983e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [3:47:05<2:05:47,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [3:47:08<2:09:24,  3.59s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4386882781982422, 'learning_rate': 1.8347457627118643e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [3:47:08<2:09:24,  3.59s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [3:47:12<2:07:08,  3.53s/it]                                                       {'loss': 0.023, 'grad_norm': 2.6639113426208496, 'learning_rate': 1.8338983050847458e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [3:47:12<2:07:08,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [3:47:15<2:05:26,  3.48s/it]                                                       {'loss': 0.0387, 'grad_norm': 4.0359344482421875, 'learning_rate': 1.8330508474576272e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [3:47:15<2:05:26,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [3:47:19<2:04:28,  3.45s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.499409556388855, 'learning_rate': 1.8322033898305087e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [3:47:19<2:04:28,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [3:47:22<2:07:40,  3.55s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.18127283453941345, 'learning_rate': 1.8313559322033898e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [3:47:22<2:07:40,  3.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [3:47:26<2:06:00,  3.50s/it]                                                       {'loss': 0.0813, 'grad_norm': 4.451902866363525, 'learning_rate': 1.8305084745762713e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [3:47:26<2:06:00,  3.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [3:47:30<2:11:07,  3.64s/it]                                                       {'loss': 0.0756, 'grad_norm': 6.272806644439697, 'learning_rate': 1.8296610169491528e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [3:47:30<2:11:07,  3.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [3:47:33<2:10:21,  3.62s/it]                                                       {'loss': 0.2066, 'grad_norm': 10.867570877075195, 'learning_rate': 1.828813559322034e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [3:47:33<2:10:21,  3.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [3:47:37<2:07:00,  3.53s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.591411590576172, 'learning_rate': 1.8279661016949153e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [3:47:37<2:07:00,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [3:47:40<2:07:35,  3.55s/it]                                                       {'loss': 0.2057, 'grad_norm': 9.43906021118164, 'learning_rate': 1.8271186440677968e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [3:47:40<2:07:35,  3.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [3:47:44<2:08:01,  3.56s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.631805419921875, 'learning_rate': 1.8262711864406783e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [3:47:44<2:08:01,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [3:47:48<2:11:43,  3.67s/it]                                                       {'loss': 0.2776, 'grad_norm': 9.40918254852295, 'learning_rate': 1.8254237288135594e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [3:47:48<2:11:43,  3.67s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [3:47:51<2:09:13,  3.60s/it]                                                       {'loss': 0.0706, 'grad_norm': 4.824034214019775, 'learning_rate': 1.824576271186441e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [3:47:51<2:09:13,  3.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [3:47:54<2:06:17,  3.52s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2246706783771515, 'learning_rate': 1.8237288135593223e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [3:47:54<2:06:17,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [3:47:58<2:04:14,  3.47s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.19595198333263397, 'learning_rate': 1.8228813559322035e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [3:47:58<2:04:14,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [3:48:01<2:05:18,  3.50s/it]                                                       {'loss': 0.1822, 'grad_norm': 6.407376289367676, 'learning_rate': 1.8220338983050846e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [3:48:01<2:05:18,  3.50s/it][2025-10-20 19:17:48,329] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3850
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 189aa2ae-2607-4482-8b41-ef18091c532d)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 19:17:58,473] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 189aa2ae-2607-4482-8b41-ef18091c532d)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 19:17:58,474] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [3:48:18<4:29:17,  7.52s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.0223805904388428, 'learning_rate': 1.821186440677966e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [3:48:18<4:29:17,  7.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [3:48:22<3:44:50,  6.28s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.8130885362625122, 'learning_rate': 1.8203389830508475e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [3:48:22<3:44:50,  6.28s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [3:48:25<3:14:11,  5.43s/it]                                                       {'loss': 0.037, 'grad_norm': 4.927319049835205, 'learning_rate': 1.8194915254237287e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [3:48:25<3:14:11,  5.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [3:48:29<2:55:12,  4.90s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08518662303686142, 'learning_rate': 1.81864406779661e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [3:48:29<2:55:12,  4.90s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [3:48:32<2:41:33,  4.52s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.20968741178512573, 'learning_rate': 1.8177966101694916e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [3:48:32<2:41:33,  4.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [3:48:36<2:29:44,  4.19s/it]                                                       {'loss': 0.2757, 'grad_norm': 6.990198612213135, 'learning_rate': 1.816949152542373e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [3:48:36<2:29:44,  4.19s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [3:48:39<2:20:39,  3.94s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09567064791917801, 'learning_rate': 1.8161016949152542e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [3:48:39<2:20:39,  3.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [3:48:42<2:14:16,  3.76s/it]                                                       {'loss': 0.044, 'grad_norm': 2.576601028442383, 'learning_rate': 1.8152542372881357e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [3:48:42<2:14:16,  3.76s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [3:48:46<2:10:40,  3.66s/it]                                                       {'loss': 0.0502, 'grad_norm': 2.3808276653289795, 'learning_rate': 1.814406779661017e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [3:48:46<2:10:40,  3.66s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [3:48:49<2:07:06,  3.56s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03828464075922966, 'learning_rate': 1.8135593220338983e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [3:48:49<2:07:06,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [3:48:53<2:05:57,  3.53s/it]                                                       {'loss': 0.2147, 'grad_norm': 7.865861892700195, 'learning_rate': 1.8127118644067797e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [3:48:53<2:05:57,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [3:48:56<2:05:00,  3.51s/it]                                                       {'loss': 0.1867, 'grad_norm': 5.7150349617004395, 'learning_rate': 1.8118644067796612e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [3:48:56<2:05:00,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [3:49:00<2:05:09,  3.51s/it]                                                       {'loss': 0.1042, 'grad_norm': 6.836668491363525, 'learning_rate': 1.8110169491525427e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [3:49:00<2:05:09,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [3:49:03<2:05:04,  3.51s/it]                                                       {'loss': 0.1399, 'grad_norm': 9.420110702514648, 'learning_rate': 1.8101694915254238e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [3:49:03<2:05:04,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [3:49:07<2:03:08,  3.46s/it]                                                       {'loss': 0.0666, 'grad_norm': 6.153069972991943, 'learning_rate': 1.8093220338983053e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [3:49:07<2:03:08,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [3:49:10<2:03:45,  3.48s/it]                                                       {'loss': 0.1118, 'grad_norm': 5.9791154861450195, 'learning_rate': 1.8084745762711867e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [3:49:10<2:03:45,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [3:49:15<2:21:00,  3.97s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.7820446491241455, 'learning_rate': 1.807627118644068e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [3:49:15<2:21:00,  3.97s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [3:49:19<2:15:14,  3.81s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13444657623767853, 'learning_rate': 1.8067796610169493e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [3:49:19<2:15:14,  3.81s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [3:49:22<2:10:37,  3.68s/it]                                                       {'loss': 0.0246, 'grad_norm': 2.5235092639923096, 'learning_rate': 1.8059322033898308e-05, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [3:49:22<2:10:37,  3.68s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [3:49:25<2:07:42,  3.60s/it]                                                       {'loss': 0.0785, 'grad_norm': 5.982941150665283, 'learning_rate': 1.805084745762712e-05, 'epoch': 0.65}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [3:49:25<2:07:42,  3.60s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [3:49:29<2:04:56,  3.52s/it]                                                       {'loss': 0.006, 'grad_norm': 1.885095238685608, 'learning_rate': 1.804237288135593e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [3:49:29<2:04:56,  3.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [3:49:32<2:03:06,  3.47s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.8015772104263306, 'learning_rate': 1.8033898305084745e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [3:49:32<2:03:06,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [3:49:36<2:02:38,  3.46s/it]                                                       {'loss': 0.0393, 'grad_norm': 3.3695080280303955, 'learning_rate': 1.802542372881356e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [3:49:36<2:02:38,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [3:49:39<2:01:04,  3.42s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.40107622742652893, 'learning_rate': 1.8016949152542374e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [3:49:39<2:01:04,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [3:49:42<2:00:31,  3.40s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.5163117051124573, 'learning_rate': 1.8008474576271186e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [3:49:42<2:00:31,  3.40s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [3:49:46<2:00:32,  3.41s/it]                                                       {'loss': 0.0138, 'grad_norm': 2.16933536529541, 'learning_rate': 1.8e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [3:49:46<2:00:32,  3.41s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [3:49:49<2:00:19,  3.40s/it]                                                       {'loss': 0.1116, 'grad_norm': 6.309021949768066, 'learning_rate': 1.7991525423728815e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [3:49:49<2:00:19,  3.40s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [3:49:53<2:05:07,  3.54s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.8031487464904785, 'learning_rate': 1.7983050847457626e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [3:49:53<2:05:07,  3.54s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [3:49:56<2:03:22,  3.49s/it]                                                       {'loss': 0.0361, 'grad_norm': 3.1667702198028564, 'learning_rate': 1.797457627118644e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [3:49:56<2:03:22,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [3:50:00<2:01:52,  3.45s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1908784657716751, 'learning_rate': 1.7966101694915256e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [3:50:00<2:01:52,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [3:50:03<2:03:15,  3.49s/it]                                                       {'loss': 0.2386, 'grad_norm': 6.942313194274902, 'learning_rate': 1.7957627118644067e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [3:50:03<2:03:15,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [3:50:06<2:01:06,  3.43s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.18495383858680725, 'learning_rate': 1.7949152542372882e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [3:50:06<2:01:06,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [3:50:10<2:03:14,  3.49s/it]                                                       {'loss': 0.0513, 'grad_norm': 4.359672546386719, 'learning_rate': 1.7940677966101696e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [3:50:10<2:03:14,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [3:50:13<2:01:51,  3.46s/it]                                                       {'loss': 0.0343, 'grad_norm': 3.078263759613037, 'learning_rate': 1.793220338983051e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [3:50:13<2:01:51,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [3:50:17<2:02:07,  3.46s/it]                                                       {'loss': 0.0454, 'grad_norm': 3.0575883388519287, 'learning_rate': 1.7923728813559322e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [3:50:17<2:02:07,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [3:50:20<2:00:52,  3.43s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07365084439516068, 'learning_rate': 1.7915254237288137e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [3:50:20<2:00:52,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [3:50:24<2:03:02,  3.49s/it]                                                       {'loss': 0.2424, 'grad_norm': 11.609370231628418, 'learning_rate': 1.7906779661016952e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [3:50:24<2:03:02,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [3:50:28<2:09:52,  3.69s/it]                                                       {'loss': 0.1985, 'grad_norm': 9.379705429077148, 'learning_rate': 1.7898305084745763e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [3:50:28<2:09:52,  3.69s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [3:50:31<2:05:57,  3.58s/it]                                                       {'loss': 0.0748, 'grad_norm': 5.733450889587402, 'learning_rate': 1.7889830508474578e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [3:50:31<2:05:57,  3.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [3:50:35<2:04:08,  3.53s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.2747983932495117, 'learning_rate': 1.7881355932203392e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [3:50:35<2:04:08,  3.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [3:50:38<2:03:12,  3.51s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.1933529376983643, 'learning_rate': 1.7872881355932207e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [3:50:38<2:03:12,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [3:50:42<2:01:59,  3.47s/it]                                                       {'loss': 0.0638, 'grad_norm': 4.6826887130737305, 'learning_rate': 1.7864406779661015e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [3:50:42<2:01:59,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [3:50:46<2:05:49,  3.58s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.3263943195343018, 'learning_rate': 1.785593220338983e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [3:50:46<2:05:49,  3.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [3:50:49<2:04:10,  3.54s/it]                                                       {'loss': 0.001, 'grad_norm': 0.13611675798892975, 'learning_rate': 1.7847457627118644e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [3:50:49<2:04:10,  3.54s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [3:50:52<2:01:59,  3.48s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3561444580554962, 'learning_rate': 1.783898305084746e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [3:50:52<2:01:59,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [3:50:56<2:01:58,  3.48s/it]                                                       {'loss': 0.0165, 'grad_norm': 3.0910098552703857, 'learning_rate': 1.783050847457627e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [3:50:56<2:01:58,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [3:50:59<2:00:15,  3.43s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5707886219024658, 'learning_rate': 1.7822033898305085e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [3:50:59<2:00:15,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [3:51:02<1:59:34,  3.41s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5618667006492615, 'learning_rate': 1.78135593220339e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [3:51:02<1:59:34,  3.41s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [3:51:06<1:58:41,  3.39s/it]                                                       {'loss': 0.1977, 'grad_norm': 7.208263397216797, 'learning_rate': 1.780508474576271e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [3:51:06<1:58:41,  3.39s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [3:51:09<1:59:09,  3.40s/it]                                                       {'loss': 0.0407, 'grad_norm': 3.4086716175079346, 'learning_rate': 1.7796610169491526e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [3:51:09<1:59:09,  3.40s/it][2025-10-20 19:20:56,236] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3900
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 130bbeed-3abc-4ab4-8e21-e01ec33a606c)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
[2025-10-20 19:21:06,296] WARNING [huggingface_hub.utils._http:321] '(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 130bbeed-3abc-4ab4-8e21-e01ec33a606c)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[2025-10-20 19:21:06,297] WARNING [huggingface_hub.utils._http:330] Retrying in 1s [Retry 1/5].
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [3:51:26<4:19:35,  7.42s/it]                                                       {'loss': 0.3352, 'grad_norm': 9.718631744384766, 'learning_rate': 1.778813559322034e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [3:51:26<4:19:35,  7.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [3:51:29<3:37:36,  6.22s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.268247127532959, 'learning_rate': 1.7779661016949155e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [3:51:29<3:37:36,  6.22s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [3:51:33<3:07:51,  5.38s/it]                                                       {'loss': 0.1924, 'grad_norm': 7.705860614776611, 'learning_rate': 1.7771186440677966e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [3:51:33<3:07:51,  5.38s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [3:51:36<2:46:36,  4.77s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.10702924430370331, 'learning_rate': 1.776271186440678e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [3:51:36<2:46:36,  4.77s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [3:51:40<2:31:14,  4.33s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4192458689212799, 'learning_rate': 1.7754237288135596e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [3:51:40<2:31:14,  4.33s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [3:51:43<2:22:20,  4.08s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.1226847171783447, 'learning_rate': 1.7745762711864407e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [3:51:43<2:22:20,  4.08s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [3:51:46<2:15:47,  3.89s/it]                                                       {'loss': 0.1811, 'grad_norm': 7.126881122589111, 'learning_rate': 1.773728813559322e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [3:51:46<2:15:47,  3.89s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [3:51:50<2:09:25,  3.71s/it]                                                       {'loss': 0.0679, 'grad_norm': 5.035725116729736, 'learning_rate': 1.7728813559322036e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [3:51:50<2:09:25,  3.71s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [3:51:53<2:05:53,  3.61s/it]                                                       {'loss': 0.0704, 'grad_norm': 5.2474751472473145, 'learning_rate': 1.772033898305085e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [3:51:53<2:05:53,  3.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [3:51:56<2:02:33,  3.52s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.284494400024414, 'learning_rate': 1.7711864406779662e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [3:51:56<2:02:33,  3.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [3:52:00<2:01:10,  3.48s/it]                                                       {'loss': 0.0747, 'grad_norm': 3.6969399452209473, 'learning_rate': 1.7703389830508477e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [3:52:00<2:01:10,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [3:52:03<2:00:54,  3.47s/it]                                                       {'loss': 0.0753, 'grad_norm': 6.538148403167725, 'learning_rate': 1.769491525423729e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [3:52:03<2:00:54,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [3:52:07<2:00:13,  3.46s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.4601383209228516, 'learning_rate': 1.7686440677966103e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [3:52:07<2:00:13,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [3:52:10<1:58:06,  3.40s/it]                                                       {'loss': 0.0256, 'grad_norm': 2.55739688873291, 'learning_rate': 1.7677966101694914e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [3:52:10<1:58:06,  3.40s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [3:52:14<2:02:47,  3.53s/it]                                                       {'loss': 0.0893, 'grad_norm': 6.326590061187744, 'learning_rate': 1.766949152542373e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [3:52:14<2:02:47,  3.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [3:52:17<2:01:22,  3.49s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.36913052201271057, 'learning_rate': 1.7661016949152543e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [3:52:17<2:01:22,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [3:52:21<2:00:15,  3.46s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.22352753579616547, 'learning_rate': 1.7652542372881355e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [3:52:21<2:00:15,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [3:52:24<1:59:56,  3.46s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.6627067923545837, 'learning_rate': 1.764406779661017e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [3:52:24<1:59:56,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [3:52:27<1:59:09,  3.44s/it]                                                       {'loss': 0.1776, 'grad_norm': 7.277831077575684, 'learning_rate': 1.7635593220338984e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [3:52:27<1:59:09,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [3:52:31<1:58:51,  3.43s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.03313147649168968, 'learning_rate': 1.76271186440678e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [3:52:31<1:58:51,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [3:52:34<1:58:20,  3.42s/it]                                                       {'loss': 0.0389, 'grad_norm': 0.9446609616279602, 'learning_rate': 1.761864406779661e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [3:52:34<1:58:20,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [3:52:38<1:58:35,  3.42s/it]                                                       {'loss': 0.0458, 'grad_norm': 1.8354237079620361, 'learning_rate': 1.7610169491525425e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [3:52:38<1:58:35,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [3:52:41<1:59:25,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.26913467049598694, 'learning_rate': 1.760169491525424e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [3:52:41<1:59:25,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [3:52:45<1:58:15,  3.42s/it]                                                       {'loss': 0.0243, 'grad_norm': 1.625900149345398, 'learning_rate': 1.759322033898305e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [3:52:45<1:58:15,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [3:52:48<2:01:50,  3.52s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.0952199175953865, 'learning_rate': 1.7584745762711865e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [3:52:48<2:01:50,  3.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [3:52:52<2:03:56,  3.59s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.019777709618210793, 'learning_rate': 1.757627118644068e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [3:52:52<2:03:56,  3.59s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [3:52:55<2:01:53,  3.53s/it]                                                       {'loss': 0.0583, 'grad_norm': 4.117048263549805, 'learning_rate': 1.7567796610169495e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [3:52:55<2:01:53,  3.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [3:52:59<2:00:23,  3.49s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.6311192512512207, 'learning_rate': 1.7559322033898306e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [3:52:59<2:00:23,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [3:53:02<2:02:13,  3.54s/it]                                                       {'loss': 0.0732, 'grad_norm': 4.573038101196289, 'learning_rate': 1.755084745762712e-05, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [3:53:02<2:02:13,  3.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [3:53:06<1:59:45,  3.47s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.4872053265571594, 'learning_rate': 1.7542372881355935e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [3:53:06<1:59:45,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [3:53:09<1:58:38,  3.44s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.11109282076358795, 'learning_rate': 1.7533898305084747e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [3:53:09<1:58:38,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [3:53:13<2:02:54,  3.57s/it]                                                       {'loss': 0.0728, 'grad_norm': 5.488162040710449, 'learning_rate': 1.752542372881356e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [3:53:13<2:02:54,  3.57s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [3:53:16<2:01:16,  3.52s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.558226466178894, 'learning_rate': 1.7516949152542373e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [3:53:16<2:01:16,  3.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [3:53:20<1:59:56,  3.48s/it]                                                       {'loss': 0.1674, 'grad_norm': 9.571686744689941, 'learning_rate': 1.7508474576271187e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [3:53:20<1:59:56,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [3:53:23<1:58:35,  3.45s/it]                                                       {'loss': 0.0608, 'grad_norm': 5.793236255645752, 'learning_rate': 1.75e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [3:53:23<1:58:35,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [3:53:27<1:57:48,  3.42s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.5943567752838135, 'learning_rate': 1.7491525423728813e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [3:53:27<1:57:48,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [3:53:30<2:00:31,  3.51s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.21463267505168915, 'learning_rate': 1.7483050847457628e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [3:53:30<2:00:31,  3.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [3:53:34<1:59:02,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015086384490132332, 'learning_rate': 1.7474576271186442e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [3:53:34<1:59:02,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [3:53:37<1:58:28,  3.45s/it]                                                       {'loss': 0.0869, 'grad_norm': 5.833174705505371, 'learning_rate': 1.7466101694915254e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [3:53:37<1:58:28,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [3:53:40<1:57:41,  3.43s/it]                                                       {'loss': 0.0837, 'grad_norm': 4.851307392120361, 'learning_rate': 1.745762711864407e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [3:53:40<1:57:41,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [3:53:44<1:57:30,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1621716171503067, 'learning_rate': 1.7449152542372883e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [3:53:44<1:57:30,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [3:53:47<1:57:02,  3.41s/it]                                                       {'loss': 0.2604, 'grad_norm': 8.009828567504883, 'learning_rate': 1.7440677966101694e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [3:53:47<1:57:02,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [3:53:51<1:57:31,  3.43s/it]                                                       {'loss': 0.0, 'grad_norm': 0.003042935160920024, 'learning_rate': 1.743220338983051e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [3:53:51<1:57:31,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [3:53:54<1:56:47,  3.41s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.6402252912521362, 'learning_rate': 1.7423728813559324e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [3:53:54<1:56:47,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [3:53:57<1:56:12,  3.39s/it]                                                       {'loss': 0.1494, 'grad_norm': 8.473760604858398, 'learning_rate': 1.7415254237288135e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [3:53:57<1:56:12,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [3:54:01<1:56:14,  3.40s/it]                                                       {'loss': 0.0995, 'grad_norm': 5.095926284790039, 'learning_rate': 1.740677966101695e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [3:54:01<1:56:14,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [3:54:04<1:55:44,  3.38s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.0410834550857544, 'learning_rate': 1.7398305084745764e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [3:54:04<1:55:44,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [3:54:07<1:54:48,  3.36s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.22414909303188324, 'learning_rate': 1.738983050847458e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [3:54:07<1:54:48,  3.36s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [3:54:11<1:56:12,  3.40s/it]                                                       {'loss': 0.1166, 'grad_norm': 5.825613498687744, 'learning_rate': 1.738135593220339e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [3:54:11<1:56:12,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [3:54:14<1:56:03,  3.40s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.9673765897750854, 'learning_rate': 1.7372881355932205e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [3:54:14<1:56:03,  3.40s/it][2025-10-20 19:24:01,348] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [3:54:20<2:19:33,  4.09s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.13648441433906555, 'learning_rate': 1.736440677966102e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [3:54:20<2:19:33,  4.09s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [3:54:23<2:12:38,  3.89s/it]                                                       {'loss': 0.0564, 'grad_norm': 4.607654571533203, 'learning_rate': 1.735593220338983e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [3:54:23<2:12:38,  3.89s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [3:54:27<2:08:10,  3.76s/it]                                                       {'loss': 0.049, 'grad_norm': 4.142539978027344, 'learning_rate': 1.7347457627118646e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [3:54:27<2:08:10,  3.76s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [3:54:30<2:04:52,  3.66s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3274684548377991, 'learning_rate': 1.7338983050847457e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [3:54:30<2:04:52,  3.66s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [3:54:34<2:01:49,  3.57s/it]                                                       {'loss': 0.0566, 'grad_norm': 4.211432456970215, 'learning_rate': 1.733050847457627e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [3:54:34<2:01:49,  3.57s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [3:54:37<2:02:33,  3.60s/it]                                                       {'loss': 0.052, 'grad_norm': 4.884368896484375, 'learning_rate': 1.7322033898305083e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [3:54:37<2:02:33,  3.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [3:54:41<2:02:22,  3.59s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4824472963809967, 'learning_rate': 1.7313559322033898e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [3:54:41<2:02:22,  3.59s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [3:54:44<2:00:36,  3.54s/it]                                                       {'loss': 0.047, 'grad_norm': 3.0617005825042725, 'learning_rate': 1.7305084745762712e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [3:54:44<2:00:36,  3.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [3:54:48<1:58:51,  3.49s/it]                                                       {'loss': 0.0464, 'grad_norm': 5.6846089363098145, 'learning_rate': 1.7296610169491527e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [3:54:48<1:58:51,  3.49s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [3:54:51<1:58:01,  3.47s/it]                                                       {'loss': 0.004, 'grad_norm': 0.7465298771858215, 'learning_rate': 1.7288135593220338e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [3:54:51<1:58:01,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [3:54:55<1:56:39,  3.43s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.24637730419635773, 'learning_rate': 1.7279661016949153e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [3:54:55<1:56:39,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [3:54:58<1:56:18,  3.42s/it]                                                       {'loss': 0.0607, 'grad_norm': 6.730098247528076, 'learning_rate': 1.7271186440677968e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [3:54:58<1:56:18,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [3:55:01<1:55:22,  3.40s/it]                                                       {'loss': 0.1131, 'grad_norm': 7.056371688842773, 'learning_rate': 1.726271186440678e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [3:55:01<1:55:22,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [3:55:05<1:56:53,  3.44s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.1663464307785034, 'learning_rate': 1.7254237288135594e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [3:55:05<1:56:53,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [3:55:08<1:56:34,  3.44s/it]                                                       {'loss': 0.0805, 'grad_norm': 6.4695963859558105, 'learning_rate': 1.7245762711864408e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [3:55:08<1:56:34,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [3:55:12<1:55:50,  3.42s/it]                                                       {'loss': 0.003, 'grad_norm': 0.4824928343296051, 'learning_rate': 1.7237288135593223e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [3:55:12<1:55:50,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [3:55:15<1:54:57,  3.39s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03712085261940956, 'learning_rate': 1.7228813559322034e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [3:55:15<1:54:57,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [3:55:19<1:57:55,  3.48s/it]                                                       {'loss': 0.1536, 'grad_norm': 6.874968528747559, 'learning_rate': 1.722033898305085e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [3:55:19<1:57:55,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [3:55:22<1:56:58,  3.46s/it]                                                       {'loss': 0.437, 'grad_norm': 8.692416191101074, 'learning_rate': 1.7211864406779664e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [3:55:22<1:56:58,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [3:55:26<1:58:01,  3.49s/it]                                                       {'loss': 0.4971, 'grad_norm': 7.39925479888916, 'learning_rate': 1.7203389830508475e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [3:55:26<1:58:01,  3.49s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [3:55:29<1:57:45,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.01851501874625683, 'learning_rate': 1.719491525423729e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [3:55:29<1:57:45,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [3:55:32<1:56:08,  3.44s/it]                                                       {'loss': 0.1189, 'grad_norm': 7.741156101226807, 'learning_rate': 1.7186440677966104e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [3:55:32<1:56:08,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [3:55:36<1:57:10,  3.47s/it]                                                       {'loss': 0.0185, 'grad_norm': 1.4213093519210815, 'learning_rate': 1.717796610169492e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [3:55:36<1:57:10,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [3:55:39<1:55:07,  3.41s/it]                                                       {'loss': 0.0462, 'grad_norm': 4.076089382171631, 'learning_rate': 1.716949152542373e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [3:55:39<1:55:07,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [3:55:43<1:55:26,  3.42s/it]                                                       {'loss': 0.0243, 'grad_norm': 3.4838199615478516, 'learning_rate': 1.716101694915254e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [3:55:43<1:55:26,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [3:55:46<1:54:37,  3.40s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.23656819760799408, 'learning_rate': 1.7152542372881356e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [3:55:46<1:54:37,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [3:55:49<1:54:46,  3.40s/it]                                                       {'loss': 0.002, 'grad_norm': 0.3507961928844452, 'learning_rate': 1.714406779661017e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [3:55:49<1:54:46,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [3:55:53<1:53:57,  3.38s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.05161302909255028, 'learning_rate': 1.7135593220338982e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [3:55:53<1:53:57,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [3:55:56<1:53:44,  3.38s/it]                                                       {'loss': 0.067, 'grad_norm': 3.600724935531616, 'learning_rate': 1.7127118644067797e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [3:55:56<1:53:44,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [3:55:59<1:53:28,  3.37s/it]                                                       {'loss': 0.1277, 'grad_norm': 6.7286376953125, 'learning_rate': 1.711864406779661e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [3:55:59<1:53:28,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [3:56:03<1:53:17,  3.37s/it]                                                       {'loss': 0.0207, 'grad_norm': 2.0018577575683594, 'learning_rate': 1.7110169491525423e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [3:56:03<1:53:17,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [3:56:06<1:53:00,  3.36s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.4764091670513153, 'learning_rate': 1.7101694915254237e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [3:56:06<1:53:00,  3.36s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [3:56:10<1:53:51,  3.39s/it]                                                       {'loss': 0.0391, 'grad_norm': 4.751662254333496, 'learning_rate': 1.7093220338983052e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [3:56:10<1:53:51,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [3:56:13<1:53:36,  3.38s/it]                                                       {'loss': 0.0447, 'grad_norm': 2.2762362957000732, 'learning_rate': 1.7084745762711867e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [3:56:13<1:53:36,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [3:56:16<1:54:30,  3.41s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3497501611709595, 'learning_rate': 1.7076271186440678e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [3:56:16<1:54:30,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [3:56:20<1:55:09,  3.43s/it]                                                       {'loss': 0.0402, 'grad_norm': 1.8980522155761719, 'learning_rate': 1.7067796610169493e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [3:56:20<1:55:09,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [3:56:23<1:55:55,  3.46s/it]                                                       {'loss': 0.0247, 'grad_norm': 2.201807975769043, 'learning_rate': 1.7059322033898307e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [3:56:23<1:55:55,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [3:56:27<1:55:01,  3.43s/it]                                                       {'loss': 0.1039, 'grad_norm': 3.8904120922088623, 'learning_rate': 1.705084745762712e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [3:56:27<1:55:01,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [3:56:30<1:55:15,  3.44s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.34860479831695557, 'learning_rate': 1.7042372881355933e-05, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [3:56:30<1:55:15,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [3:56:34<1:54:40,  3.42s/it]                                                       {'loss': 0.0397, 'grad_norm': 2.6575679779052734, 'learning_rate': 1.7033898305084748e-05, 'epoch': 0.67}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [3:56:34<1:54:40,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [3:56:37<1:53:42,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.09054149687290192, 'learning_rate': 1.7025423728813563e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [3:56:37<1:53:42,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [3:56:40<1:54:18,  3.42s/it]                                                       {'loss': 0.1202, 'grad_norm': 7.958965301513672, 'learning_rate': 1.7016949152542374e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [3:56:40<1:54:18,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [3:56:44<1:54:22,  3.42s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.7648770809173584, 'learning_rate': 1.700847457627119e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [3:56:44<1:54:22,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [3:56:48<2:03:30,  3.69s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2157425731420517, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [3:56:48<2:03:30,  3.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [3:56:52<2:01:50,  3.65s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.5587725639343262, 'learning_rate': 1.6991525423728815e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [3:56:52<2:01:50,  3.65s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [3:56:55<1:58:20,  3.54s/it]                                                       {'loss': 0.0649, 'grad_norm': 2.939016103744507, 'learning_rate': 1.6983050847457626e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [3:56:55<1:58:20,  3.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [3:56:58<1:56:31,  3.49s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.20785804092884064, 'learning_rate': 1.697457627118644e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [3:56:58<1:56:31,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [3:57:02<1:55:05,  3.45s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.8179813027381897, 'learning_rate': 1.6966101694915255e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [3:57:02<1:55:05,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [3:57:05<1:55:03,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.10185273736715317, 'learning_rate': 1.6957627118644066e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [3:57:05<1:55:03,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [3:57:09<1:54:59,  3.45s/it]                                                       {'loss': 0.1073, 'grad_norm': 7.692793846130371, 'learning_rate': 1.694915254237288e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [3:57:09<1:54:59,  3.45s/it][2025-10-20 19:26:55,686] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [3:57:14<2:16:59,  4.11s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.9919309616088867, 'learning_rate': 1.6940677966101696e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [3:57:14<2:16:59,  4.11s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [3:57:18<2:10:16,  3.91s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.3148630857467651, 'learning_rate': 1.693220338983051e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [3:57:18<2:10:16,  3.91s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [3:57:21<2:04:57,  3.75s/it]                                                       {'loss': 0.053, 'grad_norm': 4.209898471832275, 'learning_rate': 1.6923728813559322e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [3:57:21<2:04:57,  3.75s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [3:57:25<2:02:06,  3.67s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.5285452604293823, 'learning_rate': 1.6915254237288136e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [3:57:25<2:02:06,  3.67s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [3:57:28<1:59:00,  3.58s/it]                                                       {'loss': 0.047, 'grad_norm': 2.340928077697754, 'learning_rate': 1.690677966101695e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [3:57:28<1:59:00,  3.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [3:57:31<1:56:36,  3.51s/it]                                                       {'loss': 0.0312, 'grad_norm': 3.235152244567871, 'learning_rate': 1.6898305084745762e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [3:57:31<1:56:36,  3.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [3:57:35<1:55:18,  3.47s/it]                                                       {'loss': 0.0303, 'grad_norm': 2.0536787509918213, 'learning_rate': 1.6889830508474577e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [3:57:35<1:55:18,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [3:57:38<1:53:21,  3.41s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.3098140954971313, 'learning_rate': 1.6881355932203392e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [3:57:38<1:53:21,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [3:57:41<1:52:54,  3.40s/it]                                                       {'loss': 0.0737, 'grad_norm': 6.176196098327637, 'learning_rate': 1.6872881355932203e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [3:57:41<1:52:54,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [3:57:45<1:53:01,  3.41s/it]                                                       {'loss': 0.0335, 'grad_norm': 6.263166427612305, 'learning_rate': 1.6864406779661018e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [3:57:45<1:53:01,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [3:57:48<1:53:06,  3.41s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.5217010974884033, 'learning_rate': 1.6855932203389832e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [3:57:48<1:53:06,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [3:57:52<1:52:45,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.07478896528482437, 'learning_rate': 1.6847457627118647e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [3:57:52<1:52:45,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [3:57:55<1:52:07,  3.39s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.059802114963531494, 'learning_rate': 1.683898305084746e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [3:57:55<1:52:07,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [3:57:58<1:51:38,  3.37s/it]                                                       {'loss': 0.1575, 'grad_norm': 8.092089653015137, 'learning_rate': 1.6830508474576273e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [3:57:58<1:51:38,  3.37s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [3:58:02<1:52:00,  3.39s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8529484272003174, 'learning_rate': 1.6822033898305088e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [3:58:02<1:52:00,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [3:58:05<1:53:04,  3.42s/it]                                                       {'loss': 0.0545, 'grad_norm': 4.606152534484863, 'learning_rate': 1.68135593220339e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [3:58:05<1:53:04,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [3:58:09<1:51:58,  3.39s/it]                                                       {'loss': 0.0255, 'grad_norm': 2.7937188148498535, 'learning_rate': 1.680508474576271e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [3:58:09<1:51:58,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [3:58:12<1:51:16,  3.37s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05835198611021042, 'learning_rate': 1.6796610169491525e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [3:58:12<1:51:16,  3.37s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [3:58:15<1:51:14,  3.37s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.76997971534729, 'learning_rate': 1.678813559322034e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [3:58:15<1:51:14,  3.37s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [3:58:19<1:51:39,  3.38s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.8135195970535278, 'learning_rate': 1.677966101694915e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [3:58:19<1:51:39,  3.38s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [3:58:22<1:51:01,  3.37s/it]                                                       {'loss': 0.0246, 'grad_norm': 4.638792991638184, 'learning_rate': 1.6771186440677966e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [3:58:22<1:51:01,  3.37s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [3:58:26<2:02:15,  3.71s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.7303200364112854, 'learning_rate': 1.676271186440678e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [3:58:27<2:02:15,  3.71s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [3:58:30<1:59:45,  3.63s/it]                                                       {'loss': 0.1013, 'grad_norm': 5.558717727661133, 'learning_rate': 1.6754237288135595e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [3:58:30<1:59:45,  3.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [3:58:34<2:05:12,  3.80s/it]                                                       {'loss': 0.0186, 'grad_norm': 1.3001840114593506, 'learning_rate': 1.6745762711864406e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [3:58:34<2:05:12,  3.80s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [3:58:38<2:01:33,  3.69s/it]                                                       {'loss': 0.3574, 'grad_norm': 9.508347511291504, 'learning_rate': 1.673728813559322e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [3:58:38<2:01:33,  3.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [3:58:41<1:58:20,  3.60s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.1425012350082397, 'learning_rate': 1.6728813559322036e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [3:58:41<1:58:20,  3.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [3:58:45<2:03:16,  3.75s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.42712366580963135, 'learning_rate': 1.6720338983050847e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [3:58:45<2:03:16,  3.75s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [3:58:48<1:59:47,  3.64s/it]                                                       {'loss': 0.0444, 'grad_norm': 4.827584266662598, 'learning_rate': 1.671186440677966e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [3:58:48<1:59:47,  3.64s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [3:58:52<1:57:14,  3.57s/it]                                                       {'loss': 0.1828, 'grad_norm': 6.979625701904297, 'learning_rate': 1.6703389830508476e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [3:58:52<1:57:14,  3.57s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [3:58:55<1:56:00,  3.53s/it]                                                       {'loss': 0.1299, 'grad_norm': 6.556480407714844, 'learning_rate': 1.669491525423729e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [3:58:55<1:56:00,  3.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [3:58:59<1:54:19,  3.48s/it]                                                       {'loss': 0.0399, 'grad_norm': 1.561859130859375, 'learning_rate': 1.6686440677966102e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [3:58:59<1:54:19,  3.48s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [3:59:02<1:53:54,  3.47s/it]                                                       {'loss': 0.0226, 'grad_norm': 1.9287042617797852, 'learning_rate': 1.6677966101694917e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [3:59:02<1:53:54,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [3:59:06<1:53:07,  3.45s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.2614109516143799, 'learning_rate': 1.666949152542373e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [3:59:06<1:53:07,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [3:59:09<1:52:03,  3.42s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.2466003894805908, 'learning_rate': 1.6661016949152543e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [3:59:09<1:52:03,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [3:59:12<1:52:08,  3.42s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.4323803186416626, 'learning_rate': 1.6652542372881357e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [3:59:12<1:52:08,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [3:59:16<1:51:04,  3.39s/it]                                                       {'loss': 0.0227, 'grad_norm': 3.0634469985961914, 'learning_rate': 1.6644067796610172e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [3:59:16<1:51:04,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [3:59:19<1:50:37,  3.38s/it]                                                       {'loss': 0.0736, 'grad_norm': 3.5197529792785645, 'learning_rate': 1.6635593220338983e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [3:59:19<1:50:37,  3.38s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [3:59:23<1:52:36,  3.44s/it]                                                       {'loss': 0.0588, 'grad_norm': 5.488361835479736, 'learning_rate': 1.6627118644067795e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [3:59:23<1:52:36,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [3:59:26<1:53:27,  3.47s/it]                                                       {'loss': 0.0308, 'grad_norm': 3.576505184173584, 'learning_rate': 1.661864406779661e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [3:59:26<1:53:27,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [3:59:30<1:54:04,  3.49s/it]                                                       {'loss': 0.0077, 'grad_norm': 0.7964949011802673, 'learning_rate': 1.6610169491525424e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [3:59:30<1:54:04,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [3:59:33<1:57:24,  3.60s/it]                                                       {'loss': 0.0909, 'grad_norm': 6.21274471282959, 'learning_rate': 1.660169491525424e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [3:59:33<1:57:24,  3.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [3:59:37<1:55:36,  3.54s/it]                                                       {'loss': 0.0255, 'grad_norm': 2.9912526607513428, 'learning_rate': 1.659322033898305e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [3:59:37<1:55:36,  3.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [3:59:41<2:00:27,  3.69s/it]                                                       {'loss': 0.0415, 'grad_norm': 4.036415100097656, 'learning_rate': 1.6584745762711865e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [3:59:41<2:00:27,  3.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [3:59:44<1:57:10,  3.59s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.5314334630966187, 'learning_rate': 1.657627118644068e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [3:59:44<1:57:10,  3.59s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [3:59:48<1:54:53,  3.53s/it]                                                       {'loss': 0.0294, 'grad_norm': 3.0211844444274902, 'learning_rate': 1.656779661016949e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [3:59:48<1:54:53,  3.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [3:59:51<1:52:42,  3.46s/it]                                                       {'loss': 0.035, 'grad_norm': 5.893887519836426, 'learning_rate': 1.6559322033898305e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [3:59:51<1:52:42,  3.46s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [3:59:55<1:53:42,  3.49s/it]                                                       {'loss': 0.2515, 'grad_norm': 8.275887489318848, 'learning_rate': 1.655084745762712e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [3:59:55<1:53:42,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [3:59:58<1:52:51,  3.47s/it]                                                       {'loss': 0.064, 'grad_norm': 5.2403645515441895, 'learning_rate': 1.6542372881355935e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [3:59:58<1:52:51,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [4:00:01<1:52:27,  3.46s/it]                                                       {'loss': 0.2071, 'grad_norm': 8.508503913879395, 'learning_rate': 1.6533898305084746e-05, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [4:00:01<1:52:27,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [4:00:05<1:52:35,  3.46s/it]                                                       {'loss': 0.187, 'grad_norm': 7.028857231140137, 'learning_rate': 1.652542372881356e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [4:00:05<1:52:35,  3.46s/it][2025-10-20 19:29:51,879] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [4:00:10<2:13:23,  4.11s/it]                                                       {'loss': 0.1337, 'grad_norm': 7.374517917633057, 'learning_rate': 1.6516949152542375e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [4:00:10<2:13:23,  4.11s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [4:00:14<2:06:28,  3.90s/it]                                                       {'loss': 0.0298, 'grad_norm': 3.54008412361145, 'learning_rate': 1.6508474576271187e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [4:00:14<2:06:28,  3.90s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [4:00:18<2:05:03,  3.85s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.9058114886283875, 'learning_rate': 1.65e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [4:00:18<2:05:03,  3.85s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [4:00:21<2:01:33,  3.75s/it]                                                       {'loss': 0.0942, 'grad_norm': 5.860804557800293, 'learning_rate': 1.6491525423728816e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [4:00:21<2:01:33,  3.75s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [4:00:25<1:59:14,  3.68s/it]                                                       {'loss': 0.0272, 'grad_norm': 1.6264402866363525, 'learning_rate': 1.648305084745763e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [4:00:25<1:59:14,  3.68s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [4:00:28<2:00:05,  3.71s/it]                                                       {'loss': 0.1541, 'grad_norm': 6.477587699890137, 'learning_rate': 1.6474576271186442e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [4:00:28<2:00:05,  3.71s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [4:00:32<1:56:06,  3.59s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2887243330478668, 'learning_rate': 1.6466101694915257e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [4:00:32<1:56:06,  3.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [4:00:35<1:53:57,  3.52s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.4897097051143646, 'learning_rate': 1.6457627118644068e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [4:00:35<1:53:57,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [4:00:38<1:52:15,  3.47s/it]                                                       {'loss': 0.0049, 'grad_norm': 2.8208060264587402, 'learning_rate': 1.6449152542372883e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [4:00:38<1:52:15,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [4:00:42<1:50:57,  3.43s/it]                                                       {'loss': 0.1451, 'grad_norm': 9.149190902709961, 'learning_rate': 1.6440677966101694e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [4:00:42<1:50:57,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [4:00:45<1:51:11,  3.44s/it]                                                       {'loss': 0.2736, 'grad_norm': 11.77686595916748, 'learning_rate': 1.643220338983051e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [4:00:45<1:51:11,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [4:00:49<1:50:03,  3.41s/it]                                                       {'loss': 0.0364, 'grad_norm': 4.938630104064941, 'learning_rate': 1.6423728813559323e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [4:00:49<1:50:03,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [4:00:53<1:56:07,  3.60s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.5898771286010742, 'learning_rate': 1.6415254237288134e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [4:00:53<1:56:07,  3.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [4:00:56<1:53:41,  3.52s/it]                                                       {'loss': 0.0489, 'grad_norm': 5.093662738800049, 'learning_rate': 1.640677966101695e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [4:00:56<1:53:41,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [4:01:00<1:58:06,  3.66s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.9256510138511658, 'learning_rate': 1.6398305084745764e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [4:01:00<1:58:06,  3.66s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [4:01:03<1:54:44,  3.56s/it]                                                       {'loss': 0.0233, 'grad_norm': 2.898859977722168, 'learning_rate': 1.638983050847458e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [4:01:03<1:54:44,  3.56s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [4:01:07<1:53:00,  3.51s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.5340729355812073, 'learning_rate': 1.638135593220339e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [4:01:07<1:53:00,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [4:01:10<1:51:42,  3.47s/it]                                                       {'loss': 0.0279, 'grad_norm': 2.981320858001709, 'learning_rate': 1.6372881355932204e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [4:01:10<1:51:42,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [4:01:13<1:50:36,  3.44s/it]                                                       {'loss': 0.0425, 'grad_norm': 5.2936930656433105, 'learning_rate': 1.636440677966102e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [4:01:13<1:50:36,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [4:01:17<1:49:33,  3.41s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.20985010266304016, 'learning_rate': 1.635593220338983e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [4:01:17<1:49:33,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [4:01:20<1:49:33,  3.41s/it]                                                       {'loss': 0.1171, 'grad_norm': 7.611793041229248, 'learning_rate': 1.6347457627118645e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [4:01:20<1:49:33,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [4:01:24<1:51:01,  3.46s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.20710642635822296, 'learning_rate': 1.633898305084746e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [4:01:24<1:51:01,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [4:01:27<1:53:12,  3.52s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.874314546585083, 'learning_rate': 1.633050847457627e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [4:01:27<1:53:12,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [4:01:31<1:51:54,  3.49s/it]                                                       {'loss': 0.1629, 'grad_norm': 7.235014915466309, 'learning_rate': 1.6322033898305086e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [4:01:31<1:51:54,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [4:01:34<1:50:11,  3.43s/it]                                                       {'loss': 0.0411, 'grad_norm': 3.7693583965301514, 'learning_rate': 1.63135593220339e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [4:01:34<1:50:11,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [4:01:38<1:53:16,  3.53s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2815629541873932, 'learning_rate': 1.6305084745762715e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [4:01:38<1:53:16,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [4:01:41<1:52:30,  3.51s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.49652358889579773, 'learning_rate': 1.6296610169491526e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [4:01:41<1:52:30,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [4:01:45<1:52:33,  3.51s/it]                                                       {'loss': 0.0584, 'grad_norm': 6.134615898132324, 'learning_rate': 1.628813559322034e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [4:01:45<1:52:33,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [4:01:48<1:51:35,  3.49s/it]                                                       {'loss': 0.1236, 'grad_norm': 6.278656959533691, 'learning_rate': 1.6279661016949152e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [4:01:48<1:51:35,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [4:01:52<1:50:31,  3.45s/it]                                                       {'loss': 0.0464, 'grad_norm': 4.983492851257324, 'learning_rate': 1.6271186440677967e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [4:01:52<1:50:31,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [4:01:55<1:52:57,  3.53s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.18295621871948242, 'learning_rate': 1.6262711864406778e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [4:01:55<1:52:57,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [4:01:59<1:52:10,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.018044449388980865, 'learning_rate': 1.6254237288135593e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [4:01:59<1:52:10,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [4:02:02<1:50:30,  3.46s/it]                                                       {'loss': 0.0404, 'grad_norm': 3.5839734077453613, 'learning_rate': 1.6245762711864408e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [4:02:02<1:50:30,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [4:02:06<1:54:17,  3.58s/it]                                                       {'loss': 0.0174, 'grad_norm': 3.2956080436706543, 'learning_rate': 1.623728813559322e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [4:02:06<1:54:17,  3.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [4:02:09<1:52:34,  3.53s/it]                                                       {'loss': 0.0565, 'grad_norm': 4.067745208740234, 'learning_rate': 1.6228813559322034e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [4:02:09<1:52:34,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [4:02:13<1:50:47,  3.47s/it]                                                       {'loss': 0.0646, 'grad_norm': 6.440835952758789, 'learning_rate': 1.6220338983050848e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [4:02:13<1:50:47,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [4:02:16<1:51:16,  3.49s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.018792008981108665, 'learning_rate': 1.6211864406779663e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [4:02:16<1:51:16,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [4:02:20<1:53:41,  3.57s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.9452672004699707, 'learning_rate': 1.6203389830508474e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [4:02:20<1:53:41,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [4:02:23<1:52:05,  3.52s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.135416030883789, 'learning_rate': 1.619491525423729e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [4:02:23<1:52:05,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [4:02:27<1:50:48,  3.48s/it]                                                       {'loss': 0.046, 'grad_norm': 2.2848033905029297, 'learning_rate': 1.6186440677966104e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [4:02:27<1:50:48,  3.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [4:02:30<1:49:36,  3.45s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.0983547791838646, 'learning_rate': 1.6177966101694915e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [4:02:30<1:49:36,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [4:02:34<1:48:14,  3.40s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.6273802518844604, 'learning_rate': 1.616949152542373e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [4:02:34<1:48:14,  3.40s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [4:02:37<1:47:41,  3.39s/it]                                                       {'loss': 0.1369, 'grad_norm': 7.3267598152160645, 'learning_rate': 1.6161016949152544e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [4:02:37<1:47:41,  3.39s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [4:02:40<1:47:49,  3.39s/it]                                                       {'loss': 0.028, 'grad_norm': 5.1833343505859375, 'learning_rate': 1.615254237288136e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [4:02:40<1:47:49,  3.39s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [4:02:44<1:48:59,  3.43s/it]                                                       {'loss': 0.0397, 'grad_norm': 5.227100849151611, 'learning_rate': 1.614406779661017e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [4:02:44<1:48:59,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [4:02:47<1:48:37,  3.42s/it]                                                       {'loss': 0.0443, 'grad_norm': 1.9828691482543945, 'learning_rate': 1.6135593220338985e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [4:02:47<1:48:37,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [4:02:51<1:48:40,  3.43s/it]                                                       {'loss': 0.1707, 'grad_norm': 6.159720420837402, 'learning_rate': 1.61271186440678e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [4:02:51<1:48:40,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [4:02:54<1:49:35,  3.46s/it]                                                       {'loss': 0.0279, 'grad_norm': 5.01961612701416, 'learning_rate': 1.611864406779661e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [4:02:54<1:49:35,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [4:02:58<1:48:55,  3.44s/it]                                                       {'loss': 0.0197, 'grad_norm': 2.1221871376037598, 'learning_rate': 1.6110169491525425e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [4:02:58<1:48:55,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [4:03:02<1:53:51,  3.60s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3438606858253479, 'learning_rate': 1.6101694915254237e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [4:03:02<1:53:51,  3.60s/it][2025-10-20 19:32:48,531] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [4:03:07<2:12:49,  4.20s/it]                                                       {'loss': 0.1382, 'grad_norm': 6.18927001953125, 'learning_rate': 1.609322033898305e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [4:03:07<2:12:49,  4.20s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [4:03:11<2:06:09,  3.99s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.2610580921173096, 'learning_rate': 1.6084745762711863e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [4:03:11<2:06:09,  3.99s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [4:03:14<2:04:19,  3.93s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.899932861328125, 'learning_rate': 1.6076271186440677e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [4:03:14<2:04:19,  3.93s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [4:03:18<2:05:19,  3.97s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.3509818315505981, 'learning_rate': 1.6067796610169492e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [4:03:18<2:05:19,  3.97s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [4:03:22<2:00:14,  3.81s/it]                                                       {'loss': 0.1177, 'grad_norm': 7.74806022644043, 'learning_rate': 1.6059322033898307e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [4:03:22<2:00:14,  3.81s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [4:03:26<2:01:03,  3.84s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.6261285543441772, 'learning_rate': 1.6050847457627118e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [4:03:26<2:01:03,  3.84s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [4:03:29<1:56:43,  3.70s/it]                                                       {'loss': 0.0318, 'grad_norm': 3.674912929534912, 'learning_rate': 1.6042372881355933e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [4:03:29<1:56:43,  3.70s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [4:03:33<1:52:52,  3.58s/it]                                                       {'loss': 0.0703, 'grad_norm': 6.59844446182251, 'learning_rate': 1.6033898305084747e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [4:03:33<1:52:52,  3.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [4:03:36<1:56:19,  3.69s/it]                                                       {'loss': 0.0589, 'grad_norm': 5.099799633026123, 'learning_rate': 1.602542372881356e-05, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [4:03:36<1:56:19,  3.69s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [4:03:40<1:53:45,  3.61s/it]                                                       {'loss': 0.002, 'grad_norm': 0.24725736677646637, 'learning_rate': 1.6016949152542373e-05, 'epoch': 0.69}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [4:03:40<1:53:45,  3.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [4:03:43<1:51:58,  3.56s/it]                                                       {'loss': 0.0227, 'grad_norm': 3.638467311859131, 'learning_rate': 1.6008474576271188e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [4:03:43<1:51:58,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [4:03:47<1:50:17,  3.51s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.3502644300460815, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [4:03:47<1:50:17,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [4:03:51<1:54:25,  3.64s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.028008097782731056, 'learning_rate': 1.5991525423728814e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [4:03:51<1:54:25,  3.64s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [4:03:54<1:52:06,  3.57s/it]                                                       {'loss': 0.0898, 'grad_norm': 5.752642631530762, 'learning_rate': 1.598305084745763e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [4:03:54<1:52:06,  3.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [4:03:57<1:50:09,  3.51s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.28832271695137024, 'learning_rate': 1.5974576271186443e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [4:03:57<1:50:09,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [4:04:01<1:48:48,  3.47s/it]                                                       {'loss': 0.0622, 'grad_norm': 5.422163486480713, 'learning_rate': 1.5966101694915255e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [4:04:01<1:48:48,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [4:04:05<1:51:48,  3.56s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.540280818939209, 'learning_rate': 1.595762711864407e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [4:04:05<1:51:48,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [4:04:08<1:49:22,  3.49s/it]                                                       {'loss': 0.0888, 'grad_norm': 5.339328289031982, 'learning_rate': 1.5949152542372884e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [4:04:08<1:49:22,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [4:04:11<1:49:15,  3.48s/it]                                                       {'loss': 0.0271, 'grad_norm': 0.9942044615745544, 'learning_rate': 1.59406779661017e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [4:04:11<1:49:15,  3.48s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [4:04:15<1:49:37,  3.50s/it]                                                       {'loss': 0.002, 'grad_norm': 0.2560384273529053, 'learning_rate': 1.5932203389830507e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [4:04:15<1:49:37,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [4:04:19<1:51:10,  3.55s/it]                                                       {'loss': 0.2559, 'grad_norm': 11.540240287780762, 'learning_rate': 1.592372881355932e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [4:04:19<1:51:10,  3.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [4:04:22<1:50:17,  3.52s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05416668951511383, 'learning_rate': 1.5915254237288136e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [4:04:22<1:50:17,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [4:04:25<1:49:24,  3.50s/it]                                                       {'loss': 0.0507, 'grad_norm': 6.6282639503479, 'learning_rate': 1.590677966101695e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [4:04:25<1:49:24,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [4:04:29<1:47:38,  3.44s/it]                                                       {'loss': 0.0279, 'grad_norm': 3.892554521560669, 'learning_rate': 1.5898305084745762e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [4:04:29<1:47:38,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [4:04:32<1:46:57,  3.42s/it]                                                       {'loss': 0.0283, 'grad_norm': 3.2207396030426025, 'learning_rate': 1.5889830508474576e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [4:04:32<1:46:57,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [4:04:36<1:46:22,  3.41s/it]                                                       {'loss': 0.0869, 'grad_norm': 7.124795913696289, 'learning_rate': 1.588135593220339e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [4:04:36<1:46:22,  3.41s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [4:04:39<1:45:56,  3.39s/it]                                                       {'loss': 0.1463, 'grad_norm': 7.461985111236572, 'learning_rate': 1.5872881355932202e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [4:04:39<1:45:56,  3.39s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [4:04:42<1:47:25,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.030044199898838997, 'learning_rate': 1.5864406779661017e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [4:04:42<1:47:25,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [4:04:46<1:46:09,  3.40s/it]                                                       {'loss': 0.2712, 'grad_norm': 8.455408096313477, 'learning_rate': 1.5855932203389832e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [4:04:46<1:46:09,  3.40s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [4:04:49<1:46:13,  3.41s/it]                                                       {'loss': 0.07, 'grad_norm': 5.224180698394775, 'learning_rate': 1.5847457627118646e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [4:04:49<1:46:13,  3.41s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [4:04:53<1:46:51,  3.43s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0040941983461380005, 'learning_rate': 1.5838983050847458e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [4:04:53<1:46:51,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [4:04:56<1:45:40,  3.39s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.4862749576568604, 'learning_rate': 1.5830508474576272e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [4:04:56<1:45:40,  3.39s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [4:05:00<1:52:35,  3.62s/it]                                                       {'loss': 0.016, 'grad_norm': 2.22306752204895, 'learning_rate': 1.5822033898305087e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [4:05:00<1:52:35,  3.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [4:05:03<1:49:58,  3.54s/it]                                                       {'loss': 0.2586, 'grad_norm': 9.708090782165527, 'learning_rate': 1.58135593220339e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [4:05:03<1:49:58,  3.54s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [4:05:07<1:47:45,  3.47s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.2917474508285522, 'learning_rate': 1.5805084745762713e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [4:05:07<1:47:45,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [4:05:11<1:51:23,  3.59s/it]                                                       {'loss': 0.0314, 'grad_norm': 4.774802207946777, 'learning_rate': 1.5796610169491528e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [4:05:11<1:51:23,  3.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [4:05:15<1:55:25,  3.72s/it]                                                       {'loss': 0.0358, 'grad_norm': 3.3929359912872314, 'learning_rate': 1.578813559322034e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [4:05:15<1:55:25,  3.72s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [4:05:18<1:53:02,  3.64s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.5893195867538452, 'learning_rate': 1.5779661016949154e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [4:05:18<1:53:02,  3.64s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [4:05:21<1:50:20,  3.56s/it]                                                       {'loss': 0.0682, 'grad_norm': 7.551265239715576, 'learning_rate': 1.577118644067797e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [4:05:21<1:50:20,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [4:05:25<1:49:49,  3.54s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1660136878490448, 'learning_rate': 1.5762711864406783e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [4:05:25<1:49:49,  3.54s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [4:05:28<1:48:45,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03599157556891441, 'learning_rate': 1.575423728813559e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [4:05:28<1:48:45,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [4:05:32<1:46:58,  3.45s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.3063547611236572, 'learning_rate': 1.5745762711864406e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [4:05:32<1:46:58,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [4:05:35<1:47:32,  3.47s/it]                                                       {'loss': 0.211, 'grad_norm': 10.043086051940918, 'learning_rate': 1.573728813559322e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [4:05:35<1:47:32,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [4:05:39<1:47:53,  3.49s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.13530871272087097, 'learning_rate': 1.5728813559322035e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [4:05:39<1:47:53,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [4:05:42<1:46:39,  3.45s/it]                                                       {'loss': 0.0836, 'grad_norm': 4.050441265106201, 'learning_rate': 1.5720338983050846e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [4:05:42<1:46:39,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [4:05:46<1:48:24,  3.51s/it]                                                       {'loss': 0.0134, 'grad_norm': 1.570755124092102, 'learning_rate': 1.571186440677966e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [4:05:46<1:48:24,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [4:05:49<1:47:04,  3.47s/it]                                                       {'loss': 0.007, 'grad_norm': 0.8990830183029175, 'learning_rate': 1.5703389830508476e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [4:05:49<1:47:04,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [4:05:52<1:45:38,  3.42s/it]                                                       {'loss': 0.1962, 'grad_norm': 6.474470615386963, 'learning_rate': 1.5694915254237287e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [4:05:52<1:45:38,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [4:05:56<1:44:57,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.0134658208116889, 'learning_rate': 1.56864406779661e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [4:05:56<1:44:57,  3.40s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [4:05:59<1:44:28,  3.39s/it]                                                       {'loss': 0.1266, 'grad_norm': 6.518488883972168, 'learning_rate': 1.5677966101694916e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [4:05:59<1:44:28,  3.39s/it][2025-10-20 19:35:46,181] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [4:06:05<2:05:58,  4.09s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.3598097860813141, 'learning_rate': 1.566949152542373e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [4:06:05<2:05:58,  4.09s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [4:06:08<1:59:14,  3.87s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0620901957154274, 'learning_rate': 1.5661016949152542e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [4:06:08<1:59:14,  3.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [4:06:12<1:54:21,  3.71s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.9749292135238647, 'learning_rate': 1.5652542372881357e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [4:06:12<1:54:21,  3.71s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [4:06:16<1:56:32,  3.79s/it]                                                       {'loss': 0.0494, 'grad_norm': 5.976505279541016, 'learning_rate': 1.564406779661017e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [4:06:16<1:56:32,  3.79s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [4:06:19<1:52:49,  3.67s/it]                                                       {'loss': 0.006, 'grad_norm': 0.8106584548950195, 'learning_rate': 1.5635593220338983e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [4:06:19<1:52:49,  3.67s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [4:06:22<1:50:43,  3.60s/it]                                                       {'loss': 0.054, 'grad_norm': 6.468634605407715, 'learning_rate': 1.5627118644067798e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [4:06:22<1:50:43,  3.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [4:06:26<1:49:54,  3.58s/it]                                                       {'loss': 0.0722, 'grad_norm': 7.339282035827637, 'learning_rate': 1.5618644067796612e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [4:06:26<1:49:54,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [4:06:30<1:51:45,  3.64s/it]                                                       {'loss': 0.0865, 'grad_norm': 8.190747261047363, 'learning_rate': 1.5610169491525427e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [4:06:30<1:51:45,  3.64s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [4:06:33<1:50:43,  3.61s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.13166111707687378, 'learning_rate': 1.5601694915254238e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [4:06:33<1:50:43,  3.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [4:06:37<1:48:17,  3.53s/it]                                                       {'loss': 0.0537, 'grad_norm': 5.725677967071533, 'learning_rate': 1.5593220338983053e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [4:06:37<1:48:17,  3.53s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [4:06:40<1:46:59,  3.49s/it]                                                       {'loss': 0.02, 'grad_norm': 2.5225610733032227, 'learning_rate': 1.5584745762711867e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [4:06:40<1:46:59,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [4:06:43<1:46:21,  3.47s/it]                                                       {'loss': 0.1371, 'grad_norm': 6.02643346786499, 'learning_rate': 1.557627118644068e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [4:06:43<1:46:21,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [4:06:47<1:45:16,  3.44s/it]                                                       {'loss': 0.0388, 'grad_norm': 3.1612868309020996, 'learning_rate': 1.556779661016949e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [4:06:47<1:45:16,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [4:06:50<1:44:44,  3.42s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2072683870792389, 'learning_rate': 1.5559322033898305e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [4:06:50<1:44:44,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [4:06:54<1:44:40,  3.42s/it]                                                       {'loss': 0.0398, 'grad_norm': 4.229512691497803, 'learning_rate': 1.555084745762712e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [4:06:54<1:44:40,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [4:06:57<1:44:42,  3.43s/it]                                                       {'loss': 0.0971, 'grad_norm': 5.345089435577393, 'learning_rate': 1.554237288135593e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [4:06:57<1:44:42,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [4:07:01<1:45:03,  3.44s/it]                                                       {'loss': 0.0187, 'grad_norm': 2.0151424407958984, 'learning_rate': 1.5533898305084745e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [4:07:01<1:45:03,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [4:07:04<1:45:18,  3.45s/it]                                                       {'loss': 0.0729, 'grad_norm': 5.11531925201416, 'learning_rate': 1.552542372881356e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [4:07:04<1:45:18,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [4:07:08<1:51:07,  3.64s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.7473008036613464, 'learning_rate': 1.5516949152542375e-05, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [4:07:08<1:51:07,  3.64s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [4:07:11<1:48:55,  3.57s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07084234803915024, 'learning_rate': 1.5508474576271186e-05, 'epoch': 0.69}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [4:07:11<1:48:55,  3.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [4:07:15<1:52:24,  3.69s/it]                                                       {'loss': 0.3248, 'grad_norm': 8.658140182495117, 'learning_rate': 1.55e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [4:07:15<1:52:24,  3.69s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [4:07:19<1:51:15,  3.65s/it]                                                       {'loss': 0.1867, 'grad_norm': 6.183355808258057, 'learning_rate': 1.5491525423728815e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [4:07:19<1:51:15,  3.65s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [4:07:23<1:50:31,  3.63s/it]                                                       {'loss': 0.0218, 'grad_norm': 2.406841993331909, 'learning_rate': 1.5483050847457627e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [4:07:23<1:50:31,  3.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [4:07:26<1:48:27,  3.56s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08491784334182739, 'learning_rate': 1.547457627118644e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [4:07:26<1:48:27,  3.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [4:07:30<1:48:02,  3.55s/it]                                                       {'loss': 0.0177, 'grad_norm': 1.4510905742645264, 'learning_rate': 1.5466101694915256e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [4:07:30<1:48:02,  3.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [4:07:33<1:46:27,  3.50s/it]                                                       {'loss': 0.0596, 'grad_norm': 4.0550947189331055, 'learning_rate': 1.545762711864407e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [4:07:33<1:46:27,  3.50s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [4:07:36<1:45:16,  3.46s/it]                                                       {'loss': 0.0367, 'grad_norm': 5.596679210662842, 'learning_rate': 1.5449152542372882e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [4:07:36<1:45:16,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [4:07:40<1:44:42,  3.45s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.512923002243042, 'learning_rate': 1.5440677966101697e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [4:07:40<1:44:42,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [4:07:43<1:44:20,  3.44s/it]                                                       {'loss': 0.0868, 'grad_norm': 6.697360992431641, 'learning_rate': 1.543220338983051e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [4:07:43<1:44:20,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [4:07:46<1:43:00,  3.40s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.771020233631134, 'learning_rate': 1.5423728813559323e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [4:07:46<1:43:00,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [4:07:50<1:42:26,  3.38s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1654733568429947, 'learning_rate': 1.5415254237288137e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [4:07:50<1:42:26,  3.38s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [4:07:53<1:41:04,  3.34s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07043161243200302, 'learning_rate': 1.5406779661016952e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [4:07:53<1:41:04,  3.34s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [4:07:56<1:41:35,  3.35s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.509386420249939, 'learning_rate': 1.5398305084745763e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [4:07:56<1:41:35,  3.35s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [4:08:00<1:41:57,  3.37s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.010444882325828075, 'learning_rate': 1.5389830508474574e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [4:08:00<1:41:57,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [4:08:03<1:41:57,  3.37s/it]                                                       {'loss': 0.3506, 'grad_norm': 5.953919887542725, 'learning_rate': 1.538135593220339e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [4:08:03<1:41:57,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [4:08:06<1:41:39,  3.36s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.0170950889587402, 'learning_rate': 1.5372881355932204e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [4:08:07<1:41:39,  3.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [4:08:10<1:41:37,  3.36s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.6167071461677551, 'learning_rate': 1.536440677966102e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [4:08:10<1:41:37,  3.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [4:08:13<1:43:57,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03423362597823143, 'learning_rate': 1.535593220338983e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [4:08:13<1:43:57,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [4:08:17<1:45:09,  3.48s/it]                                                       {'loss': 0.0171, 'grad_norm': 2.3494679927825928, 'learning_rate': 1.5347457627118644e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [4:08:17<1:45:09,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [4:08:20<1:44:30,  3.46s/it]                                                       {'loss': 0.1488, 'grad_norm': 8.342957496643066, 'learning_rate': 1.533898305084746e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [4:08:20<1:44:30,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [4:08:24<1:44:11,  3.46s/it]                                                       {'loss': 0.0463, 'grad_norm': 5.332748889923096, 'learning_rate': 1.533050847457627e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [4:08:24<1:44:11,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [4:08:27<1:44:18,  3.46s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1265871822834015, 'learning_rate': 1.5322033898305085e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [4:08:27<1:44:18,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [4:08:31<1:44:42,  3.48s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.8150904178619385, 'learning_rate': 1.53135593220339e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [4:08:31<1:44:42,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [4:08:34<1:44:20,  3.47s/it]                                                       {'loss': 0.1166, 'grad_norm': 8.46503734588623, 'learning_rate': 1.5305084745762714e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [4:08:34<1:44:20,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [4:08:38<1:44:33,  3.48s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2780536413192749, 'learning_rate': 1.5296610169491526e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [4:08:38<1:44:33,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [4:08:41<1:44:14,  3.47s/it]                                                       {'loss': 0.0572, 'grad_norm': 2.124319076538086, 'learning_rate': 1.528813559322034e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [4:08:41<1:44:14,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [4:08:45<1:43:15,  3.44s/it]                                                       {'loss': 0.0297, 'grad_norm': 3.3610644340515137, 'learning_rate': 1.5279661016949155e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [4:08:45<1:43:15,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [4:08:48<1:42:09,  3.40s/it]                                                       {'loss': 0.1062, 'grad_norm': 6.429266929626465, 'learning_rate': 1.5271186440677966e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [4:08:48<1:42:09,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [4:08:51<1:41:48,  3.39s/it]                                                       {'loss': 0.0567, 'grad_norm': 6.321726322174072, 'learning_rate': 1.526271186440678e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [4:08:51<1:41:48,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [4:08:55<1:41:48,  3.39s/it]                                                       {'loss': 0.048, 'grad_norm': 6.910629749298096, 'learning_rate': 1.5254237288135596e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [4:08:55<1:41:48,  3.39s/it][2025-10-20 19:38:41,739] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [4:09:01<2:04:30,  4.15s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.26201683282852173, 'learning_rate': 1.5245762711864409e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [4:09:01<2:04:30,  4.15s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [4:09:04<1:57:49,  3.93s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.6740317344665527, 'learning_rate': 1.5237288135593222e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [4:09:04<1:57:49,  3.93s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [4:09:07<1:52:48,  3.77s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6980702877044678, 'learning_rate': 1.5228813559322033e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [4:09:07<1:52:48,  3.77s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [4:09:11<1:49:31,  3.66s/it]                                                       {'loss': 0.0378, 'grad_norm': 2.519314765930176, 'learning_rate': 1.5220338983050848e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [4:09:11<1:49:31,  3.66s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [4:09:14<1:47:00,  3.58s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.0093306303024292, 'learning_rate': 1.521186440677966e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [4:09:14<1:47:00,  3.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [4:09:18<1:44:48,  3.51s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.0597578287124634, 'learning_rate': 1.5203389830508474e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [4:09:18<1:44:48,  3.51s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [4:09:21<1:43:10,  3.45s/it]                                                       {'loss': 0.0475, 'grad_norm': 5.867677211761475, 'learning_rate': 1.5194915254237288e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [4:09:21<1:43:10,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [4:09:24<1:42:37,  3.44s/it]                                                       {'loss': 0.1497, 'grad_norm': 7.097448825836182, 'learning_rate': 1.5186440677966101e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [4:09:24<1:42:37,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [4:09:28<1:42:03,  3.42s/it]                                                       {'loss': 0.0243, 'grad_norm': 4.011760711669922, 'learning_rate': 1.5177966101694916e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [4:09:28<1:42:03,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [4:09:31<1:40:46,  3.38s/it]                                                       {'loss': 0.0489, 'grad_norm': 6.591861724853516, 'learning_rate': 1.5169491525423729e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [4:09:31<1:40:46,  3.38s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [4:09:34<1:41:02,  3.39s/it]                                                       {'loss': 0.0864, 'grad_norm': 6.525166034698486, 'learning_rate': 1.5161016949152544e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [4:09:34<1:41:02,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [4:09:38<1:41:14,  3.40s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.1671825498342514, 'learning_rate': 1.5152542372881357e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [4:09:38<1:41:14,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [4:09:41<1:41:26,  3.41s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2827121317386627, 'learning_rate': 1.514406779661017e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [4:09:41<1:41:26,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [4:09:45<1:40:35,  3.38s/it]                                                       {'loss': 0.0368, 'grad_norm': 2.1985690593719482, 'learning_rate': 1.5135593220338984e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [4:09:45<1:40:35,  3.38s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [4:09:48<1:42:12,  3.44s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.4228573739528656, 'learning_rate': 1.5127118644067797e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [4:09:48<1:42:12,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [4:09:51<1:41:14,  3.40s/it]                                                       {'loss': 0.2534, 'grad_norm': 7.384270191192627, 'learning_rate': 1.5118644067796612e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [4:09:51<1:41:14,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [4:09:55<1:42:24,  3.45s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.7118942737579346, 'learning_rate': 1.5110169491525425e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [4:09:55<1:42:24,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [4:09:58<1:41:42,  3.42s/it]                                                       {'loss': 0.0949, 'grad_norm': 7.016565322875977, 'learning_rate': 1.5101694915254238e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [4:09:58<1:41:42,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [4:10:02<1:41:31,  3.42s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.30496490001678467, 'learning_rate': 1.5093220338983053e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [4:10:02<1:41:31,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [4:10:05<1:40:23,  3.38s/it]                                                       {'loss': 0.0798, 'grad_norm': 5.3006696701049805, 'learning_rate': 1.5084745762711865e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [4:10:05<1:40:23,  3.38s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [4:10:08<1:40:01,  3.37s/it]                                                       {'loss': 0.1143, 'grad_norm': 7.216039180755615, 'learning_rate': 1.507627118644068e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [4:10:08<1:40:01,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [4:10:12<1:44:28,  3.53s/it]                                                       {'loss': 0.0416, 'grad_norm': 3.852532386779785, 'learning_rate': 1.5067796610169493e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [4:10:12<1:44:28,  3.53s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [4:10:16<1:44:54,  3.54s/it]                                                       {'loss': 0.0604, 'grad_norm': 6.203356742858887, 'learning_rate': 1.5059322033898308e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [4:10:16<1:44:54,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [4:10:20<1:46:32,  3.60s/it]                                                       {'loss': 0.1463, 'grad_norm': 7.237300395965576, 'learning_rate': 1.5050847457627117e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [4:10:20<1:46:32,  3.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [4:10:24<1:50:19,  3.73s/it]                                                       {'loss': 0.1414, 'grad_norm': 7.075083255767822, 'learning_rate': 1.5042372881355932e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [4:10:24<1:50:19,  3.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [4:10:28<1:57:06,  3.96s/it]                                                       {'loss': 0.0192, 'grad_norm': 3.32635760307312, 'learning_rate': 1.5033898305084745e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [4:10:28<1:57:06,  3.96s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [4:10:32<1:51:54,  3.79s/it]                                                       {'loss': 0.0228, 'grad_norm': 2.842313051223755, 'learning_rate': 1.502542372881356e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [4:10:32<1:51:54,  3.79s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [4:10:35<1:50:00,  3.72s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1497063934803009, 'learning_rate': 1.5016949152542373e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [4:10:35<1:50:00,  3.72s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [4:10:38<1:46:49,  3.62s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.060399055480957, 'learning_rate': 1.5008474576271186e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [4:10:39<1:46:49,  3.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [4:10:42<1:48:23,  3.67s/it]                                                       {'loss': 0.0525, 'grad_norm': 4.231259346008301, 'learning_rate': 1.5e-05, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [4:10:42<1:48:23,  3.67s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [4:10:46<1:48:58,  3.70s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.7435208559036255, 'learning_rate': 1.4991525423728813e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [4:10:46<1:48:58,  3.70s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [4:10:49<1:46:20,  3.61s/it]                                                       {'loss': 0.0191, 'grad_norm': 2.3860256671905518, 'learning_rate': 1.4983050847457628e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [4:10:49<1:46:20,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [4:10:53<1:43:55,  3.53s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3969099223613739, 'learning_rate': 1.4974576271186441e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [4:10:53<1:43:55,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [4:10:56<1:42:31,  3.48s/it]                                                       {'loss': 0.0211, 'grad_norm': 2.270723581314087, 'learning_rate': 1.4966101694915256e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [4:10:56<1:42:31,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [4:10:59<1:41:04,  3.44s/it]                                                       {'loss': 0.0413, 'grad_norm': 3.77718186378479, 'learning_rate': 1.4957627118644069e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [4:11:00<1:41:04,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [4:11:03<1:40:15,  3.41s/it]                                                       {'loss': 0.0591, 'grad_norm': 6.364845275878906, 'learning_rate': 1.4949152542372882e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [4:11:03<1:40:15,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [4:11:07<1:44:25,  3.55s/it]                                                       {'loss': 0.0388, 'grad_norm': 5.032357692718506, 'learning_rate': 1.4940677966101696e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [4:11:07<1:44:25,  3.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [4:11:10<1:42:33,  3.49s/it]                                                       {'loss': 0.102, 'grad_norm': 6.746896266937256, 'learning_rate': 1.493220338983051e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [4:11:10<1:42:33,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [4:11:13<1:41:15,  3.45s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9800543785095215, 'learning_rate': 1.4923728813559324e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [4:11:13<1:41:15,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [4:11:17<1:39:59,  3.41s/it]                                                       {'loss': 0.0469, 'grad_norm': 2.2129099369049072, 'learning_rate': 1.4915254237288137e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [4:11:17<1:39:59,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [4:11:20<1:39:56,  3.41s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3261961042881012, 'learning_rate': 1.490677966101695e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [4:11:20<1:39:56,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [4:11:24<1:40:18,  3.42s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5564411878585815, 'learning_rate': 1.4898305084745765e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [4:11:24<1:40:18,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [4:11:28<1:44:28,  3.57s/it]                                                       {'loss': 0.0789, 'grad_norm': 5.05473518371582, 'learning_rate': 1.4889830508474578e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [4:11:28<1:44:28,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [4:11:32<1:49:43,  3.75s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5166320204734802, 'learning_rate': 1.4881355932203392e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [4:11:32<1:49:43,  3.75s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [4:11:35<1:47:01,  3.66s/it]                                                       {'loss': 0.0535, 'grad_norm': 6.060188293457031, 'learning_rate': 1.4872881355932204e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [4:11:35<1:47:01,  3.66s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [4:11:39<1:47:50,  3.69s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.1952272355556488, 'learning_rate': 1.4864406779661017e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [4:11:39<1:47:50,  3.69s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [4:11:42<1:45:27,  3.61s/it]                                                       {'loss': 0.06, 'grad_norm': 6.045526027679443, 'learning_rate': 1.485593220338983e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [4:11:42<1:45:27,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [4:11:46<1:44:17,  3.57s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.716446042060852, 'learning_rate': 1.4847457627118644e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [4:11:46<1:44:17,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [4:11:49<1:42:04,  3.50s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.08294154703617096, 'learning_rate': 1.4838983050847457e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [4:11:49<1:42:04,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [4:11:53<1:42:15,  3.51s/it]                                                       {'loss': 0.1111, 'grad_norm': 8.762709617614746, 'learning_rate': 1.4830508474576272e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [4:11:53<1:42:15,  3.51s/it][2025-10-20 19:41:39,653] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [4:11:58<2:00:34,  4.14s/it]                                                       {'loss': 0.035, 'grad_norm': 1.993166208267212, 'learning_rate': 1.4822033898305085e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [4:11:58<2:00:34,  4.14s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [4:12:02<1:54:42,  3.94s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05073406174778938, 'learning_rate': 1.4813559322033898e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [4:12:02<1:54:42,  3.94s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [4:12:06<1:53:23,  3.89s/it]                                                       {'loss': 0.0496, 'grad_norm': 5.582108497619629, 'learning_rate': 1.4805084745762712e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [4:12:06<1:53:23,  3.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [4:12:09<1:48:51,  3.74s/it]                                                       {'loss': 0.1252, 'grad_norm': 5.653207302093506, 'learning_rate': 1.4796610169491525e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [4:12:09<1:48:51,  3.74s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [4:12:12<1:45:08,  3.61s/it]                                                       {'loss': 0.0629, 'grad_norm': 3.624570369720459, 'learning_rate': 1.478813559322034e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [4:12:12<1:45:08,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [4:12:16<1:42:50,  3.54s/it]                                                       {'loss': 0.0942, 'grad_norm': 5.846832275390625, 'learning_rate': 1.4779661016949153e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [4:12:16<1:42:50,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [4:12:19<1:41:36,  3.50s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3036084473133087, 'learning_rate': 1.4771186440677968e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [4:12:19<1:41:36,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [4:12:22<1:40:22,  3.46s/it]                                                       {'loss': 0.0324, 'grad_norm': 2.7169785499572754, 'learning_rate': 1.476271186440678e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [4:12:22<1:40:22,  3.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [4:12:26<1:38:44,  3.40s/it]                                                       {'loss': 0.0532, 'grad_norm': 4.358768463134766, 'learning_rate': 1.4754237288135594e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [4:12:26<1:38:44,  3.40s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [4:12:29<1:38:01,  3.38s/it]                                                       {'loss': 0.019, 'grad_norm': 2.0605688095092773, 'learning_rate': 1.4745762711864408e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [4:12:29<1:38:01,  3.38s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [4:12:32<1:39:11,  3.42s/it]                                                       {'loss': 0.151, 'grad_norm': 5.662719249725342, 'learning_rate': 1.4737288135593221e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [4:12:32<1:39:11,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [4:12:36<1:38:19,  3.39s/it]                                                       {'loss': 0.0206, 'grad_norm': 2.437211751937866, 'learning_rate': 1.4728813559322036e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [4:12:36<1:38:19,  3.39s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [4:12:40<1:42:21,  3.54s/it]                                                       {'loss': 0.1152, 'grad_norm': 6.995995998382568, 'learning_rate': 1.4720338983050849e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [4:12:40<1:42:21,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [4:12:43<1:41:42,  3.52s/it]                                                       {'loss': 0.0237, 'grad_norm': 2.6157824993133545, 'learning_rate': 1.4711864406779664e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [4:12:43<1:41:42,  3.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [4:12:47<1:40:34,  3.48s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5223246812820435, 'learning_rate': 1.4703389830508477e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [4:12:47<1:40:34,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [4:12:50<1:38:45,  3.42s/it]                                                       {'loss': 0.092, 'grad_norm': 6.882347106933594, 'learning_rate': 1.4694915254237288e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [4:12:50<1:38:45,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [4:12:53<1:39:07,  3.43s/it]                                                       {'loss': 0.0648, 'grad_norm': 4.866730213165283, 'learning_rate': 1.4686440677966101e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [4:12:53<1:39:07,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [4:12:57<1:38:41,  3.42s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.2518804967403412, 'learning_rate': 1.4677966101694916e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [4:12:57<1:38:41,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [4:13:00<1:38:59,  3.43s/it]                                                       {'loss': 0.083, 'grad_norm': 5.735875606536865, 'learning_rate': 1.4669491525423729e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [4:13:00<1:38:59,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [4:13:04<1:41:00,  3.50s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1013321727514267, 'learning_rate': 1.4661016949152542e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [4:13:04<1:41:00,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [4:13:08<1:43:33,  3.59s/it]                                                       {'loss': 0.0249, 'grad_norm': 2.748788595199585, 'learning_rate': 1.4652542372881356e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [4:13:08<1:43:33,  3.59s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [4:13:11<1:41:33,  3.53s/it]                                                       {'loss': 0.0369, 'grad_norm': 4.323750972747803, 'learning_rate': 1.464406779661017e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [4:13:11<1:41:33,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [4:13:15<1:42:34,  3.56s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.046592019498348236, 'learning_rate': 1.4635593220338984e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [4:13:15<1:42:34,  3.56s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [4:13:18<1:40:22,  3.49s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.32614758610725403, 'learning_rate': 1.4627118644067797e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [4:13:18<1:40:22,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [4:13:22<1:41:22,  3.53s/it]                                                       {'loss': 0.1394, 'grad_norm': 6.133371829986572, 'learning_rate': 1.4618644067796612e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [4:13:22<1:41:22,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [4:13:25<1:40:56,  3.51s/it]                                                       {'loss': 0.0215, 'grad_norm': 2.5010085105895996, 'learning_rate': 1.4610169491525425e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [4:13:25<1:40:56,  3.51s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [4:13:29<1:45:39,  3.68s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.8317219018936157, 'learning_rate': 1.4601694915254238e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [4:13:29<1:45:39,  3.68s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [4:13:33<1:46:56,  3.73s/it]                                                       {'loss': 0.1141, 'grad_norm': 8.997664451599121, 'learning_rate': 1.4593220338983052e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [4:13:33<1:46:56,  3.73s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [4:13:37<1:45:31,  3.68s/it]                                                       {'loss': 0.0256, 'grad_norm': 3.499966621398926, 'learning_rate': 1.4584745762711865e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [4:13:37<1:45:31,  3.68s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [4:13:40<1:43:38,  3.62s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.061479389667510986, 'learning_rate': 1.457627118644068e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [4:13:40<1:43:38,  3.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [4:13:43<1:41:04,  3.53s/it]                                                       {'loss': 0.1731, 'grad_norm': 10.124042510986328, 'learning_rate': 1.4567796610169493e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [4:13:43<1:41:04,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [4:13:47<1:39:32,  3.48s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.99125075340271, 'learning_rate': 1.4559322033898306e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [4:13:47<1:39:32,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [4:13:50<1:38:59,  3.46s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.7247031331062317, 'learning_rate': 1.455084745762712e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [4:13:50<1:38:59,  3.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [4:13:54<1:43:01,  3.60s/it]                                                       {'loss': 0.1486, 'grad_norm': 7.4225873947143555, 'learning_rate': 1.4542372881355933e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [4:13:54<1:43:01,  3.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [4:13:57<1:40:43,  3.52s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.4093868732452393, 'learning_rate': 1.4533898305084748e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [4:13:57<1:40:43,  3.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [4:14:01<1:41:18,  3.55s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.2061928510665894, 'learning_rate': 1.4525423728813561e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [4:14:01<1:41:18,  3.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [4:14:04<1:40:04,  3.51s/it]                                                       {'loss': 0.024, 'grad_norm': 3.761834144592285, 'learning_rate': 1.4516949152542372e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [4:14:04<1:40:04,  3.51s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [4:14:08<1:38:55,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11955712735652924, 'learning_rate': 1.4508474576271185e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [4:14:08<1:38:55,  3.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [4:14:11<1:37:45,  3.43s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3134966194629669, 'learning_rate': 1.45e-05, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [4:14:11<1:37:45,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [4:14:14<1:36:41,  3.39s/it]                                                       {'loss': 0.0295, 'grad_norm': 2.8734548091888428, 'learning_rate': 1.4491525423728813e-05, 'epoch': 0.71}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [4:14:14<1:36:41,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [4:14:18<1:37:00,  3.41s/it]                                                       {'loss': 0.0284, 'grad_norm': 2.000847339630127, 'learning_rate': 1.4483050847457628e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [4:14:18<1:37:00,  3.41s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [4:14:21<1:36:46,  3.40s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.22690953314304352, 'learning_rate': 1.447457627118644e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [4:14:21<1:36:46,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [4:14:25<1:36:41,  3.40s/it]                                                       {'loss': 0.0931, 'grad_norm': 7.152310371398926, 'learning_rate': 1.4466101694915254e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [4:14:25<1:36:41,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [4:14:28<1:36:16,  3.39s/it]                                                       {'loss': 0.0214, 'grad_norm': 3.701260566711426, 'learning_rate': 1.4457627118644068e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [4:14:28<1:36:16,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [4:14:31<1:36:11,  3.39s/it]                                                       {'loss': 0.0379, 'grad_norm': 3.8405375480651855, 'learning_rate': 1.4449152542372881e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [4:14:31<1:36:11,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [4:14:35<1:39:11,  3.49s/it]                                                       {'loss': 0.4077, 'grad_norm': 10.106149673461914, 'learning_rate': 1.4440677966101696e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [4:14:35<1:39:11,  3.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [4:14:38<1:38:24,  3.47s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2091754525899887, 'learning_rate': 1.4432203389830509e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [4:14:38<1:38:24,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [4:14:42<1:42:39,  3.62s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.20346279442310333, 'learning_rate': 1.4423728813559324e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [4:14:42<1:42:39,  3.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [4:14:46<1:40:23,  3.54s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.5474406480789185, 'learning_rate': 1.4415254237288137e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [4:14:46<1:40:23,  3.54s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [4:14:49<1:39:10,  3.50s/it]                                                       {'loss': 0.0353, 'grad_norm': 1.9766892194747925, 'learning_rate': 1.440677966101695e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [4:14:49<1:39:10,  3.50s/it][2025-10-20 19:44:36,225] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [4:14:55<1:58:38,  4.19s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.9097433686256409, 'learning_rate': 1.4398305084745764e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [4:14:55<1:58:38,  4.19s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [4:14:58<1:51:47,  3.95s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1563718020915985, 'learning_rate': 1.4389830508474577e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [4:14:58<1:51:47,  3.95s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [4:15:02<1:46:38,  3.77s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.2203350067138672, 'learning_rate': 1.4381355932203392e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [4:15:02<1:46:38,  3.77s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [4:15:06<1:46:54,  3.78s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.16642911732196808, 'learning_rate': 1.4372881355932205e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [4:15:06<1:46:54,  3.78s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [4:15:09<1:43:42,  3.67s/it]                                                       {'loss': 0.0822, 'grad_norm': 7.051961898803711, 'learning_rate': 1.4364406779661018e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [4:15:09<1:43:42,  3.67s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [4:15:13<1:45:15,  3.73s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.4984443783760071, 'learning_rate': 1.4355932203389833e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [4:15:13<1:45:15,  3.73s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [4:15:16<1:41:48,  3.61s/it]                                                       {'loss': 0.0308, 'grad_norm': 3.1253933906555176, 'learning_rate': 1.4347457627118644e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [4:15:16<1:41:48,  3.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [4:15:20<1:40:39,  3.57s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.9977308511734009, 'learning_rate': 1.4338983050847457e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [4:15:20<1:40:39,  3.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [4:15:23<1:38:15,  3.49s/it]                                                       {'loss': 0.1114, 'grad_norm': 4.477165222167969, 'learning_rate': 1.4330508474576272e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [4:15:23<1:38:15,  3.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [4:15:26<1:37:09,  3.45s/it]                                                       {'loss': 0.0178, 'grad_norm': 2.933119773864746, 'learning_rate': 1.4322033898305085e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [4:15:26<1:37:09,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [4:15:30<1:36:56,  3.44s/it]                                                       {'loss': 0.435, 'grad_norm': 10.86645221710205, 'learning_rate': 1.4313559322033898e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [4:15:30<1:36:56,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [4:15:33<1:38:57,  3.52s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.6026588678359985, 'learning_rate': 1.4305084745762712e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [4:15:33<1:38:57,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [4:15:37<1:37:28,  3.47s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.46798649430274963, 'learning_rate': 1.4296610169491525e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [4:15:37<1:37:28,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [4:15:40<1:36:16,  3.43s/it]                                                       {'loss': 0.0565, 'grad_norm': 6.20493221282959, 'learning_rate': 1.428813559322034e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [4:15:40<1:36:16,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [4:15:44<1:41:06,  3.60s/it]                                                       {'loss': 0.068, 'grad_norm': 5.140514373779297, 'learning_rate': 1.4279661016949153e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [4:15:44<1:41:06,  3.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [4:15:48<1:41:12,  3.61s/it]                                                       {'loss': 0.0761, 'grad_norm': 5.405725955963135, 'learning_rate': 1.4271186440677966e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [4:15:48<1:41:12,  3.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [4:15:51<1:39:56,  3.56s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.15393535792827606, 'learning_rate': 1.426271186440678e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [4:15:51<1:39:56,  3.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [4:15:55<1:38:42,  3.52s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.9212110042572021, 'learning_rate': 1.4254237288135593e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [4:15:55<1:38:42,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [4:15:58<1:37:51,  3.49s/it]                                                       {'loss': 0.0614, 'grad_norm': 5.49320650100708, 'learning_rate': 1.4245762711864408e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [4:15:58<1:37:51,  3.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [4:16:01<1:36:59,  3.46s/it]                                                       {'loss': 0.1926, 'grad_norm': 8.20528507232666, 'learning_rate': 1.4237288135593221e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [4:16:01<1:36:59,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [4:16:05<1:38:22,  3.52s/it]                                                       {'loss': 0.1723, 'grad_norm': 8.281461715698242, 'learning_rate': 1.4228813559322036e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [4:16:05<1:38:22,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [4:16:09<1:37:51,  3.50s/it]                                                       {'loss': 0.1005, 'grad_norm': 4.769839763641357, 'learning_rate': 1.4220338983050849e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [4:16:09<1:37:51,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [4:16:12<1:36:46,  3.46s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.19398273527622223, 'learning_rate': 1.4211864406779662e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [4:16:12<1:36:46,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [4:16:15<1:36:04,  3.44s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.6759228706359863, 'learning_rate': 1.4203389830508476e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [4:16:15<1:36:04,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [4:16:19<1:37:12,  3.48s/it]                                                       {'loss': 0.0622, 'grad_norm': 5.777848720550537, 'learning_rate': 1.419491525423729e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [4:16:19<1:37:12,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [4:16:23<1:39:30,  3.57s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2961568832397461, 'learning_rate': 1.4186440677966104e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [4:16:23<1:39:30,  3.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [4:16:26<1:38:47,  3.54s/it]                                                       {'loss': 0.0838, 'grad_norm': 4.739221096038818, 'learning_rate': 1.4177966101694917e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [4:16:26<1:38:47,  3.54s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [4:16:29<1:36:54,  3.48s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.655728816986084, 'learning_rate': 1.4169491525423728e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [4:16:29<1:36:54,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [4:16:33<1:36:14,  3.46s/it]                                                       {'loss': 0.1303, 'grad_norm': 3.8129734992980957, 'learning_rate': 1.4161016949152541e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [4:16:33<1:36:14,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [4:16:36<1:35:17,  3.42s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.7008181810379028, 'learning_rate': 1.4152542372881356e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [4:16:36<1:35:17,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [4:16:40<1:38:16,  3.53s/it]                                                       {'loss': 0.0396, 'grad_norm': 4.004666328430176, 'learning_rate': 1.4144067796610169e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [4:16:40<1:38:16,  3.53s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [4:16:43<1:36:48,  3.48s/it]                                                       {'loss': 0.0649, 'grad_norm': 5.584224700927734, 'learning_rate': 1.4135593220338984e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [4:16:43<1:36:48,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [4:16:47<1:37:45,  3.52s/it]                                                       {'loss': 0.0176, 'grad_norm': 2.5696892738342285, 'learning_rate': 1.4127118644067797e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [4:16:47<1:37:45,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [4:16:50<1:36:39,  3.48s/it]                                                       {'loss': 0.01, 'grad_norm': 0.9855514168739319, 'learning_rate': 1.411864406779661e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [4:16:50<1:36:39,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [4:16:54<1:36:09,  3.47s/it]                                                       {'loss': 0.0182, 'grad_norm': 2.215468406677246, 'learning_rate': 1.4110169491525424e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [4:16:54<1:36:09,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [4:16:57<1:35:42,  3.45s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.6787634491920471, 'learning_rate': 1.4101694915254237e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [4:16:57<1:35:42,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [4:17:01<1:34:34,  3.41s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.5651438236236572, 'learning_rate': 1.4093220338983052e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [4:17:01<1:34:34,  3.41s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [4:17:04<1:33:42,  3.38s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.023616552352905273, 'learning_rate': 1.4084745762711865e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [4:17:04<1:33:42,  3.38s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [4:17:07<1:33:21,  3.37s/it]                                                       {'loss': 0.122, 'grad_norm': 8.793889999389648, 'learning_rate': 1.407627118644068e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [4:17:07<1:33:21,  3.37s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [4:17:11<1:33:03,  3.36s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.35771557688713074, 'learning_rate': 1.4067796610169493e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [4:17:11<1:33:03,  3.36s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [4:17:14<1:33:59,  3.40s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3089157044887543, 'learning_rate': 1.4059322033898306e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [4:17:14<1:33:59,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [4:17:17<1:34:07,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013631438836455345, 'learning_rate': 1.405084745762712e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [4:17:17<1:34:07,  3.41s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [4:17:21<1:34:39,  3.43s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.4851073622703552, 'learning_rate': 1.4042372881355933e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [4:17:21<1:34:39,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [4:17:24<1:34:49,  3.44s/it]                                                       {'loss': 0.0881, 'grad_norm': 5.344670295715332, 'learning_rate': 1.4033898305084748e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [4:17:24<1:34:49,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [4:17:28<1:35:12,  3.45s/it]                                                       {'loss': 0.1481, 'grad_norm': 8.211919784545898, 'learning_rate': 1.4025423728813561e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [4:17:28<1:35:12,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [4:17:31<1:34:34,  3.43s/it]                                                       {'loss': 0.0727, 'grad_norm': 9.305122375488281, 'learning_rate': 1.4016949152542374e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [4:17:31<1:34:34,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [4:17:35<1:34:05,  3.42s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.35112568736076355, 'learning_rate': 1.4008474576271189e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [4:17:35<1:34:05,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [4:17:38<1:37:07,  3.53s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.6660680174827576, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [4:17:38<1:37:07,  3.53s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [4:17:42<1:35:40,  3.48s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.1280381679534912, 'learning_rate': 1.3991525423728813e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [4:17:42<1:35:40,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [4:17:45<1:35:45,  3.48s/it]                                                       {'loss': 0.0481, 'grad_norm': 4.2722554206848145, 'learning_rate': 1.3983050847457627e-05, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [4:17:45<1:35:45,  3.48s/it][2025-10-20 19:47:32,271] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [4:17:51<1:54:19,  4.16s/it]                                                       {'loss': 0.1121, 'grad_norm': 8.080765724182129, 'learning_rate': 1.397457627118644e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [4:17:51<1:54:19,  4.16s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [4:17:54<1:48:29,  3.95s/it]                                                       {'loss': 0.0587, 'grad_norm': 4.587039470672607, 'learning_rate': 1.3966101694915253e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [4:17:54<1:48:29,  3.95s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [4:17:58<1:43:41,  3.78s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.42516857385635376, 'learning_rate': 1.3957627118644068e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [4:17:58<1:43:41,  3.78s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [4:18:01<1:40:26,  3.66s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.5104906558990479, 'learning_rate': 1.3949152542372881e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [4:18:01<1:40:26,  3.66s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [4:18:05<1:38:10,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05027192458510399, 'learning_rate': 1.3940677966101696e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [4:18:05<1:38:10,  3.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [4:18:09<1:40:31,  3.67s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.11504311114549637, 'learning_rate': 1.3932203389830509e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [4:18:09<1:40:31,  3.67s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [4:18:12<1:42:09,  3.73s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.10657932609319687, 'learning_rate': 1.3923728813559322e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [4:18:12<1:42:09,  3.73s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [4:18:16<1:39:34,  3.64s/it]                                                       {'loss': 0.3789, 'grad_norm': 6.595892429351807, 'learning_rate': 1.3915254237288136e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [4:18:16<1:39:34,  3.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [4:18:19<1:37:00,  3.55s/it]                                                       {'loss': 0.0572, 'grad_norm': 4.72890567779541, 'learning_rate': 1.390677966101695e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [4:18:19<1:37:00,  3.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [4:18:23<1:37:02,  3.55s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.0209414958953857, 'learning_rate': 1.3898305084745764e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [4:18:23<1:37:02,  3.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [4:18:26<1:35:22,  3.49s/it]                                                       {'loss': 0.047, 'grad_norm': 5.496649742126465, 'learning_rate': 1.3889830508474577e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [4:18:26<1:35:22,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [4:18:29<1:34:36,  3.47s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.11436139047145844, 'learning_rate': 1.3881355932203392e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [4:18:29<1:34:36,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [4:18:33<1:35:20,  3.49s/it]                                                       {'loss': 0.043, 'grad_norm': 3.8019204139709473, 'learning_rate': 1.3872881355932205e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [4:18:33<1:35:20,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [4:18:37<1:35:12,  3.49s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.08330781757831573, 'learning_rate': 1.3864406779661018e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [4:18:37<1:35:12,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [4:18:40<1:34:38,  3.47s/it]                                                       {'loss': 0.0381, 'grad_norm': 4.22317361831665, 'learning_rate': 1.3855932203389832e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [4:18:40<1:34:38,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [4:18:43<1:34:13,  3.46s/it]                                                       {'loss': 0.0273, 'grad_norm': 2.8823201656341553, 'learning_rate': 1.3847457627118645e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [4:18:43<1:34:13,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [4:18:47<1:33:43,  3.44s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.088706374168396, 'learning_rate': 1.383898305084746e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [4:18:47<1:33:43,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [4:18:50<1:33:10,  3.43s/it]                                                       {'loss': 0.0289, 'grad_norm': 3.5850749015808105, 'learning_rate': 1.3830508474576273e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [4:18:50<1:33:10,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [4:18:54<1:32:59,  3.42s/it]                                                       {'loss': 0.2227, 'grad_norm': 6.667115211486816, 'learning_rate': 1.3822033898305086e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [4:18:54<1:32:59,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [4:18:57<1:33:11,  3.43s/it]                                                       {'loss': 0.2249, 'grad_norm': 9.651002883911133, 'learning_rate': 1.3813559322033897e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [4:18:57<1:33:11,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [4:19:00<1:33:08,  3.43s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5410048961639404, 'learning_rate': 1.3805084745762712e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [4:19:00<1:33:08,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [4:19:04<1:33:11,  3.43s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.6332799792289734, 'learning_rate': 1.3796610169491525e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [4:19:04<1:33:11,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [4:19:07<1:34:21,  3.48s/it]                                                       {'loss': 0.034, 'grad_norm': 4.115814208984375, 'learning_rate': 1.378813559322034e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [4:19:07<1:34:21,  3.48s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [4:19:11<1:34:06,  3.47s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.3985034227371216, 'learning_rate': 1.3779661016949153e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [4:19:11<1:34:06,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [4:19:14<1:33:25,  3.45s/it]                                                       {'loss': 0.0488, 'grad_norm': 6.266487121582031, 'learning_rate': 1.3771186440677965e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [4:19:14<1:33:25,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [4:19:18<1:34:12,  3.48s/it]                                                       {'loss': 0.0311, 'grad_norm': 2.796180248260498, 'learning_rate': 1.376271186440678e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [4:19:18<1:34:12,  3.48s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [4:19:21<1:34:09,  3.48s/it]                                                       {'loss': 0.0514, 'grad_norm': 4.113502502441406, 'learning_rate': 1.3754237288135593e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [4:19:21<1:34:09,  3.48s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [4:19:25<1:33:49,  3.47s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.7242932319641113, 'learning_rate': 1.3745762711864408e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [4:19:25<1:33:49,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [4:19:28<1:33:38,  3.47s/it]                                                       {'loss': 0.057, 'grad_norm': 3.4134433269500732, 'learning_rate': 1.373728813559322e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [4:19:28<1:33:38,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [4:19:32<1:32:15,  3.42s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.3549809157848358, 'learning_rate': 1.3728813559322034e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [4:19:32<1:32:15,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [4:19:35<1:32:17,  3.42s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.0967179536819458, 'learning_rate': 1.3720338983050848e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [4:19:35<1:32:17,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [4:19:38<1:31:33,  3.40s/it]                                                       {'loss': 0.179, 'grad_norm': 8.00137710571289, 'learning_rate': 1.3711864406779661e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [4:19:38<1:31:33,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [4:19:42<1:32:18,  3.43s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09393975883722305, 'learning_rate': 1.3703389830508476e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [4:19:42<1:32:18,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [4:19:45<1:31:51,  3.41s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.40709617733955383, 'learning_rate': 1.3694915254237289e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [4:19:45<1:31:51,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [4:19:49<1:31:46,  3.41s/it]                                                       {'loss': 0.0, 'grad_norm': 0.009849355556070805, 'learning_rate': 1.3686440677966104e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [4:19:49<1:31:46,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [4:19:53<1:37:25,  3.62s/it]                                                       {'loss': 0.0559, 'grad_norm': 6.49932336807251, 'learning_rate': 1.3677966101694917e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [4:19:53<1:37:25,  3.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [4:19:56<1:35:39,  3.56s/it]                                                       {'loss': 0.037, 'grad_norm': 4.2334370613098145, 'learning_rate': 1.366949152542373e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [4:19:56<1:35:39,  3.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [4:20:00<1:35:05,  3.54s/it]                                                       {'loss': 0.0348, 'grad_norm': 5.053628921508789, 'learning_rate': 1.3661016949152544e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [4:20:00<1:35:05,  3.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [4:20:04<1:37:43,  3.64s/it]                                                       {'loss': 0.005, 'grad_norm': 0.450032502412796, 'learning_rate': 1.3652542372881357e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [4:20:04<1:37:43,  3.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [4:20:07<1:37:06,  3.62s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02757752127945423, 'learning_rate': 1.3644067796610169e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [4:20:07<1:37:06,  3.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [4:20:11<1:36:35,  3.60s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.007119267247617245, 'learning_rate': 1.3635593220338982e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [4:20:11<1:36:35,  3.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [4:20:14<1:35:55,  3.58s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.13963741064071655, 'learning_rate': 1.3627118644067796e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [4:20:14<1:35:55,  3.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [4:20:18<1:33:53,  3.51s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.36049899458885193, 'learning_rate': 1.361864406779661e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [4:20:18<1:33:53,  3.51s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [4:20:21<1:32:32,  3.46s/it]                                                       {'loss': 0.1516, 'grad_norm': 9.53913688659668, 'learning_rate': 1.3610169491525424e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [4:20:21<1:32:32,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [4:20:24<1:31:30,  3.42s/it]                                                       {'loss': 0.2431, 'grad_norm': 10.119468688964844, 'learning_rate': 1.3601694915254237e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [4:20:24<1:31:30,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [4:20:27<1:30:35,  3.39s/it]                                                       {'loss': 0.06, 'grad_norm': 5.428369045257568, 'learning_rate': 1.3593220338983052e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [4:20:28<1:30:35,  3.39s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [4:20:31<1:34:31,  3.54s/it]                                                       {'loss': 0.002, 'grad_norm': 0.1993345022201538, 'learning_rate': 1.3584745762711865e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [4:20:31<1:34:31,  3.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [4:20:35<1:32:39,  3.47s/it]                                                       {'loss': 0.1509, 'grad_norm': 6.068246364593506, 'learning_rate': 1.3576271186440678e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [4:20:35<1:32:39,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [4:20:38<1:32:16,  3.46s/it]                                                       {'loss': 0.1953, 'grad_norm': 8.545580863952637, 'learning_rate': 1.3567796610169492e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [4:20:38<1:32:16,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [4:20:42<1:31:40,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.037828318774700165, 'learning_rate': 1.3559322033898305e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [4:20:42<1:31:40,  3.44s/it][2025-10-20 19:50:28,515] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [4:20:47<1:49:31,  4.11s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07715064287185669, 'learning_rate': 1.355084745762712e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [4:20:47<1:49:31,  4.11s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [4:20:51<1:43:51,  3.90s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.387864589691162, 'learning_rate': 1.3542372881355933e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [4:20:51<1:43:51,  3.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [4:20:54<1:40:08,  3.76s/it]                                                       {'loss': 0.0255, 'grad_norm': 2.141238212585449, 'learning_rate': 1.3533898305084748e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [4:20:54<1:40:08,  3.76s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [4:20:58<1:37:58,  3.68s/it]                                                       {'loss': 0.0498, 'grad_norm': 3.8563671112060547, 'learning_rate': 1.352542372881356e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [4:20:58<1:37:58,  3.68s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [4:21:01<1:36:45,  3.64s/it]                                                       {'loss': 0.0185, 'grad_norm': 1.4212802648544312, 'learning_rate': 1.3516949152542374e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [4:21:01<1:36:45,  3.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [4:21:04<1:34:11,  3.55s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.92226243019104, 'learning_rate': 1.3508474576271188e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [4:21:04<1:34:11,  3.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [4:21:08<1:32:54,  3.50s/it]                                                       {'loss': 0.0342, 'grad_norm': 3.7295191287994385, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [4:21:08<1:32:54,  3.50s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [4:21:11<1:31:16,  3.44s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.009921998716890812, 'learning_rate': 1.3491525423728816e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [4:21:11<1:31:16,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [4:21:14<1:30:33,  3.42s/it]                                                       {'loss': 0.0651, 'grad_norm': 6.062708377838135, 'learning_rate': 1.3483050847457629e-05, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [4:21:14<1:30:33,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [4:21:18<1:29:30,  3.38s/it]                                                       {'loss': 0.1081, 'grad_norm': 7.838561534881592, 'learning_rate': 1.3474576271186442e-05, 'epoch': 0.73}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [4:21:18<1:29:30,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [4:21:21<1:29:24,  3.38s/it]                                                       {'loss': 0.0292, 'grad_norm': 5.0567216873168945, 'learning_rate': 1.3466101694915253e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [4:21:21<1:29:24,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [4:21:24<1:28:41,  3.35s/it]                                                       {'loss': 0.0542, 'grad_norm': 2.196505546569824, 'learning_rate': 1.3457627118644068e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [4:21:24<1:28:41,  3.35s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [4:21:28<1:29:04,  3.37s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.3555002212524414, 'learning_rate': 1.344915254237288e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [4:21:28<1:29:04,  3.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [4:21:31<1:30:00,  3.40s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.5748049020767212, 'learning_rate': 1.3440677966101695e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [4:21:31<1:30:00,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [4:21:35<1:30:08,  3.41s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.008596464991569519, 'learning_rate': 1.3432203389830508e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [4:21:35<1:30:08,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [4:21:38<1:30:18,  3.42s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.29112306237220764, 'learning_rate': 1.3423728813559321e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [4:21:38<1:30:18,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [4:21:42<1:32:43,  3.51s/it]                                                       {'loss': 0.2812, 'grad_norm': 11.69689655303955, 'learning_rate': 1.3415254237288136e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [4:21:42<1:32:43,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [4:21:45<1:31:27,  3.47s/it]                                                       {'loss': 0.0636, 'grad_norm': 8.29780101776123, 'learning_rate': 1.3406779661016949e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [4:21:45<1:31:27,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [4:21:49<1:30:21,  3.43s/it]                                                       {'loss': 0.005, 'grad_norm': 0.6938934922218323, 'learning_rate': 1.3398305084745764e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [4:21:49<1:30:21,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [4:21:52<1:29:45,  3.41s/it]                                                       {'loss': 0.0, 'grad_norm': 0.009314799681305885, 'learning_rate': 1.3389830508474577e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [4:21:52<1:29:45,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [4:21:55<1:28:59,  3.38s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1508375108242035, 'learning_rate': 1.338135593220339e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [4:21:55<1:28:59,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [4:21:59<1:29:35,  3.41s/it]                                                       {'loss': 0.0135, 'grad_norm': 3.10029673576355, 'learning_rate': 1.3372881355932204e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [4:21:59<1:29:35,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [4:22:02<1:29:04,  3.39s/it]                                                       {'loss': 0.0913, 'grad_norm': 7.0071120262146, 'learning_rate': 1.3364406779661017e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [4:22:02<1:29:04,  3.39s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [4:22:06<1:33:11,  3.55s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03593265637755394, 'learning_rate': 1.3355932203389832e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [4:22:06<1:33:11,  3.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [4:22:09<1:31:50,  3.50s/it]                                                       {'loss': 0.2744, 'grad_norm': 6.417571544647217, 'learning_rate': 1.3347457627118645e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [4:22:09<1:31:50,  3.50s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [4:22:13<1:30:13,  3.44s/it]                                                       {'loss': 0.0663, 'grad_norm': 8.142653465270996, 'learning_rate': 1.333898305084746e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [4:22:13<1:30:13,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [4:22:16<1:30:47,  3.46s/it]                                                       {'loss': 0.0, 'grad_norm': 0.003241785103455186, 'learning_rate': 1.3330508474576273e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [4:22:16<1:30:47,  3.46s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [4:22:20<1:29:47,  3.43s/it]                                                       {'loss': 0.0208, 'grad_norm': 1.4148684740066528, 'learning_rate': 1.3322033898305086e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [4:22:20<1:29:47,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [4:22:23<1:29:28,  3.42s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.6528841257095337, 'learning_rate': 1.33135593220339e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [4:22:23<1:29:28,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [4:22:26<1:28:40,  3.39s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08627989143133163, 'learning_rate': 1.3305084745762713e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [4:22:26<1:28:40,  3.39s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [4:22:30<1:30:09,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.13993780314922333, 'learning_rate': 1.3296610169491528e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [4:22:30<1:30:09,  3.45s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [4:22:33<1:29:24,  3.42s/it]                                                       {'loss': 0.0275, 'grad_norm': 3.456162929534912, 'learning_rate': 1.3288135593220338e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [4:22:33<1:29:24,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [4:22:37<1:29:00,  3.41s/it]                                                       {'loss': 0.0328, 'grad_norm': 4.973323822021484, 'learning_rate': 1.3279661016949152e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [4:22:37<1:29:00,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [4:22:40<1:29:04,  3.41s/it]                                                       {'loss': 0.003, 'grad_norm': 0.24693280458450317, 'learning_rate': 1.3271186440677965e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [4:22:40<1:29:04,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [4:22:44<1:30:23,  3.47s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5147112011909485, 'learning_rate': 1.326271186440678e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [4:22:44<1:30:23,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [4:22:47<1:29:57,  3.45s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.34098196029663086, 'learning_rate': 1.3254237288135593e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [4:22:47<1:29:57,  3.45s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [4:22:51<1:31:09,  3.50s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.5280616283416748, 'learning_rate': 1.3245762711864408e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [4:22:51<1:31:09,  3.50s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [4:22:54<1:29:51,  3.45s/it]                                                       {'loss': 0.0377, 'grad_norm': 3.279367208480835, 'learning_rate': 1.323728813559322e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [4:22:54<1:29:51,  3.45s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [4:22:58<1:32:36,  3.56s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6822776794433594, 'learning_rate': 1.3228813559322033e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [4:22:58<1:32:36,  3.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [4:23:01<1:31:11,  3.51s/it]                                                       {'loss': 0.1358, 'grad_norm': 6.843533039093018, 'learning_rate': 1.3220338983050848e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [4:23:01<1:31:11,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [4:23:05<1:31:36,  3.53s/it]                                                       {'loss': 0.0933, 'grad_norm': 6.550765514373779, 'learning_rate': 1.3211864406779661e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [4:23:05<1:31:36,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [4:23:08<1:31:12,  3.51s/it]                                                       {'loss': 0.0978, 'grad_norm': 7.923783302307129, 'learning_rate': 1.3203389830508476e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [4:23:08<1:31:12,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [4:23:12<1:31:27,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.13022197782993317, 'learning_rate': 1.3194915254237289e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [4:23:12<1:31:27,  3.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [4:23:15<1:30:11,  3.48s/it]                                                       {'loss': 0.0272, 'grad_norm': 3.07558536529541, 'learning_rate': 1.3186440677966102e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [4:23:15<1:30:11,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [4:23:19<1:29:15,  3.44s/it]                                                       {'loss': 0.0316, 'grad_norm': 3.6987760066986084, 'learning_rate': 1.3177966101694916e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [4:23:19<1:29:15,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [4:23:22<1:31:46,  3.54s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.2760002613067627, 'learning_rate': 1.316949152542373e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [4:23:22<1:31:46,  3.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [4:23:26<1:30:24,  3.49s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4249227046966553, 'learning_rate': 1.3161016949152544e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [4:23:26<1:30:24,  3.49s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [4:23:29<1:29:17,  3.45s/it]                                                       {'loss': 0.0517, 'grad_norm': 1.928183674812317, 'learning_rate': 1.3152542372881357e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [4:23:29<1:29:17,  3.45s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [4:23:32<1:28:52,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.3533245623111725, 'learning_rate': 1.3144067796610172e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [4:23:32<1:28:52,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [4:23:36<1:29:34,  3.47s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.048648357391357, 'learning_rate': 1.3135593220338985e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [4:23:36<1:29:34,  3.47s/it][2025-10-20 19:53:22,966] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [4:23:43<1:53:56,  4.41s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02273777686059475, 'learning_rate': 1.3127118644067798e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [4:23:43<1:53:56,  4.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [4:23:46<1:46:40,  4.13s/it]                                                       {'loss': 0.1439, 'grad_norm': 7.5994038581848145, 'learning_rate': 1.3118644067796612e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [4:23:46<1:46:40,  4.13s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [4:23:50<1:44:25,  4.05s/it]                                                       {'loss': 0.0316, 'grad_norm': 4.061877250671387, 'learning_rate': 1.3110169491525424e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [4:23:50<1:44:25,  4.05s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [4:23:53<1:39:13,  3.85s/it]                                                       {'loss': 0.0186, 'grad_norm': 2.506502151489258, 'learning_rate': 1.3101694915254237e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [4:23:53<1:39:13,  3.85s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [4:23:57<1:35:14,  3.70s/it]                                                       {'loss': 0.0318, 'grad_norm': 3.815162420272827, 'learning_rate': 1.309322033898305e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [4:23:57<1:35:14,  3.70s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [4:24:00<1:33:11,  3.62s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.17091751098632812, 'learning_rate': 1.3084745762711864e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [4:24:00<1:33:11,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [4:24:04<1:31:37,  3.56s/it]                                                       {'loss': 0.028, 'grad_norm': 1.776821494102478, 'learning_rate': 1.3076271186440677e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [4:24:04<1:31:37,  3.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [4:24:07<1:29:58,  3.50s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.9372198581695557, 'learning_rate': 1.3067796610169492e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [4:24:07<1:29:58,  3.50s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [4:24:11<1:32:49,  3.61s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.6722200512886047, 'learning_rate': 1.3059322033898305e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [4:24:11<1:32:49,  3.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [4:24:14<1:30:33,  3.53s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5233710408210754, 'learning_rate': 1.305084745762712e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [4:24:14<1:30:33,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [4:24:18<1:33:12,  3.63s/it]                                                       {'loss': 0.0455, 'grad_norm': 3.8751742839813232, 'learning_rate': 1.3042372881355933e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [4:24:18<1:33:12,  3.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [4:24:21<1:31:25,  3.57s/it]                                                       {'loss': 0.0251, 'grad_norm': 3.6516411304473877, 'learning_rate': 1.3033898305084746e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [4:24:21<1:31:25,  3.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [4:24:25<1:32:38,  3.62s/it]                                                       {'loss': 0.1177, 'grad_norm': 7.905500888824463, 'learning_rate': 1.302542372881356e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [4:24:25<1:32:38,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [4:24:29<1:31:20,  3.57s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3856017589569092, 'learning_rate': 1.3016949152542373e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [4:24:29<1:31:20,  3.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [4:24:32<1:30:12,  3.53s/it]                                                       {'loss': 0.0802, 'grad_norm': 9.913455963134766, 'learning_rate': 1.3008474576271188e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [4:24:32<1:30:12,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [4:24:35<1:29:50,  3.51s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.8389725089073181, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [4:24:35<1:29:50,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [4:24:39<1:32:11,  3.61s/it]                                                       {'loss': 0.0465, 'grad_norm': 4.9062347412109375, 'learning_rate': 1.2991525423728816e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [4:24:39<1:32:11,  3.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [4:24:43<1:30:07,  3.53s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.16316021978855133, 'learning_rate': 1.2983050847457629e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [4:24:43<1:30:07,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [4:24:46<1:28:31,  3.47s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0573740191757679, 'learning_rate': 1.2974576271186442e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [4:24:46<1:28:31,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [4:24:49<1:27:33,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.05684749782085419, 'learning_rate': 1.2966101694915256e-05, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [4:24:49<1:27:33,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [4:24:53<1:27:32,  3.44s/it]                                                       {'loss': 0.1599, 'grad_norm': 8.563948631286621, 'learning_rate': 1.295762711864407e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [4:24:53<1:27:32,  3.44s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [4:24:56<1:27:24,  3.43s/it]                                                       {'loss': 0.0103, 'grad_norm': 1.443411946296692, 'learning_rate': 1.2949152542372884e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [4:24:56<1:27:24,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [4:25:00<1:27:40,  3.44s/it]                                                       {'loss': 0.056, 'grad_norm': 5.087680339813232, 'learning_rate': 1.2940677966101697e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [4:25:00<1:27:40,  3.44s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [4:25:03<1:27:35,  3.44s/it]                                                       {'loss': 0.1563, 'grad_norm': 9.372614860534668, 'learning_rate': 1.2932203389830508e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [4:25:03<1:27:35,  3.44s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [4:25:06<1:26:48,  3.42s/it]                                                       {'loss': 0.3066, 'grad_norm': 9.301494598388672, 'learning_rate': 1.2923728813559321e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [4:25:06<1:26:48,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [4:25:10<1:30:29,  3.56s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3851560652256012, 'learning_rate': 1.2915254237288136e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [4:25:10<1:30:29,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [4:25:14<1:29:32,  3.53s/it]                                                       {'loss': 0.194, 'grad_norm': 10.51942253112793, 'learning_rate': 1.2906779661016949e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [4:25:14<1:29:32,  3.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [4:25:17<1:29:57,  3.55s/it]                                                       {'loss': 0.0189, 'grad_norm': 3.6934406757354736, 'learning_rate': 1.2898305084745763e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [4:25:17<1:29:57,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [4:25:22<1:35:41,  3.78s/it]                                                       {'loss': 0.0988, 'grad_norm': 8.045354843139648, 'learning_rate': 1.2889830508474576e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [4:25:22<1:35:41,  3.78s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [4:25:25<1:32:20,  3.64s/it]                                                       {'loss': 0.0323, 'grad_norm': 4.517707347869873, 'learning_rate': 1.288135593220339e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [4:25:25<1:32:20,  3.64s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [4:25:28<1:29:45,  3.55s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.220794916152954, 'learning_rate': 1.2872881355932204e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [4:25:28<1:29:45,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [4:25:32<1:29:52,  3.55s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.664868712425232, 'learning_rate': 1.2864406779661017e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [4:25:32<1:29:52,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [4:25:35<1:28:14,  3.49s/it]                                                       {'loss': 0.2667, 'grad_norm': 6.2771406173706055, 'learning_rate': 1.2855932203389832e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [4:25:35<1:28:14,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [4:25:39<1:27:53,  3.48s/it]                                                       {'loss': 0.0089, 'grad_norm': 2.148442029953003, 'learning_rate': 1.2847457627118645e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [4:25:39<1:27:53,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [4:25:43<1:29:59,  3.56s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.019029341638088226, 'learning_rate': 1.2838983050847458e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [4:25:43<1:29:59,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [4:25:46<1:27:59,  3.49s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5943018794059753, 'learning_rate': 1.2830508474576272e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [4:25:46<1:27:59,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [4:25:49<1:27:47,  3.48s/it]                                                       {'loss': 0.2879, 'grad_norm': 9.123602867126465, 'learning_rate': 1.2822033898305085e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [4:25:49<1:27:47,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [4:25:53<1:26:47,  3.44s/it]                                                       {'loss': 0.0235, 'grad_norm': 2.3249833583831787, 'learning_rate': 1.28135593220339e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [4:25:53<1:26:47,  3.44s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [4:25:56<1:29:41,  3.56s/it]                                                       {'loss': 0.0368, 'grad_norm': 2.4609885215759277, 'learning_rate': 1.2805084745762713e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [4:25:56<1:29:41,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [4:26:00<1:28:08,  3.50s/it]                                                       {'loss': 0.1668, 'grad_norm': 10.556495666503906, 'learning_rate': 1.2796610169491528e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [4:26:00<1:28:08,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [4:26:04<1:30:14,  3.59s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.017486507073044777, 'learning_rate': 1.278813559322034e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [4:26:04<1:30:14,  3.59s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [4:26:07<1:28:40,  3.53s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.7046055793762207, 'learning_rate': 1.2779661016949154e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [4:26:07<1:28:40,  3.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [4:26:10<1:27:20,  3.48s/it]                                                       {'loss': 0.0269, 'grad_norm': 4.168436527252197, 'learning_rate': 1.2771186440677968e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [4:26:10<1:27:20,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [4:26:14<1:27:21,  3.48s/it]                                                       {'loss': 0.0627, 'grad_norm': 4.628635883331299, 'learning_rate': 1.276271186440678e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [4:26:14<1:27:21,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [4:26:17<1:25:46,  3.42s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10704921185970306, 'learning_rate': 1.2754237288135593e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [4:26:17<1:25:46,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [4:26:21<1:25:54,  3.43s/it]                                                       {'loss': 0.0732, 'grad_norm': 5.402013778686523, 'learning_rate': 1.2745762711864406e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [4:26:21<1:25:54,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [4:26:24<1:25:17,  3.40s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.16551591455936432, 'learning_rate': 1.273728813559322e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [4:26:24<1:25:17,  3.40s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [4:26:27<1:24:27,  3.37s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.4996025562286377, 'learning_rate': 1.2728813559322033e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [4:26:27<1:24:27,  3.37s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [4:26:31<1:24:32,  3.38s/it]                                                       {'loss': 0.042, 'grad_norm': 5.250772953033447, 'learning_rate': 1.2720338983050848e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [4:26:31<1:24:32,  3.38s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [4:26:34<1:24:34,  3.38s/it]                                                       {'loss': 0.1175, 'grad_norm': 7.480401039123535, 'learning_rate': 1.2711864406779661e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [4:26:34<1:24:34,  3.38s/it][2025-10-20 19:56:21,016] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [4:26:40<1:41:17,  4.05s/it]                                                       {'loss': 0.0236, 'grad_norm': 2.1414692401885986, 'learning_rate': 1.2703389830508476e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [4:26:40<1:41:17,  4.05s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [4:26:43<1:38:56,  3.96s/it]                                                       {'loss': 0.1607, 'grad_norm': 8.560341835021973, 'learning_rate': 1.2694915254237289e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [4:26:43<1:38:56,  3.96s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [4:26:47<1:35:17,  3.82s/it]                                                       {'loss': 0.1264, 'grad_norm': 7.297731876373291, 'learning_rate': 1.2686440677966101e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [4:26:47<1:35:17,  3.82s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [4:26:50<1:31:36,  3.67s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.18281815946102142, 'learning_rate': 1.2677966101694916e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [4:26:50<1:31:36,  3.67s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [4:26:54<1:29:26,  3.59s/it]                                                       {'loss': 0.0108, 'grad_norm': 1.9650020599365234, 'learning_rate': 1.2669491525423729e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [4:26:54<1:29:26,  3.59s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [4:26:57<1:28:13,  3.54s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.29223522543907166, 'learning_rate': 1.2661016949152544e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [4:26:57<1:28:13,  3.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [4:27:00<1:27:09,  3.50s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.21880218386650085, 'learning_rate': 1.2652542372881357e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [4:27:00<1:27:09,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [4:27:04<1:27:38,  3.52s/it]                                                       {'loss': 0.062, 'grad_norm': 6.039745807647705, 'learning_rate': 1.264406779661017e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [4:27:04<1:27:38,  3.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [4:27:08<1:27:32,  3.52s/it]                                                       {'loss': 0.2176, 'grad_norm': 7.229284763336182, 'learning_rate': 1.2635593220338984e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [4:27:08<1:27:32,  3.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [4:27:11<1:26:38,  3.49s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2592049241065979, 'learning_rate': 1.2627118644067797e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [4:27:11<1:26:38,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [4:27:14<1:26:23,  3.48s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.1432851552963257, 'learning_rate': 1.2618644067796612e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [4:27:14<1:26:23,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [4:27:18<1:25:43,  3.46s/it]                                                       {'loss': 0.045, 'grad_norm': 5.554618835449219, 'learning_rate': 1.2610169491525425e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [4:27:18<1:25:43,  3.46s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [4:27:22<1:30:18,  3.64s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.1554574966430664, 'learning_rate': 1.260169491525424e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [4:27:22<1:30:18,  3.64s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [4:27:25<1:27:47,  3.54s/it]                                                       {'loss': 0.0667, 'grad_norm': 6.093691825866699, 'learning_rate': 1.2593220338983053e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [4:27:25<1:27:47,  3.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [4:27:29<1:30:15,  3.65s/it]                                                       {'loss': 0.012, 'grad_norm': 2.726487874984741, 'learning_rate': 1.2584745762711864e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [4:27:29<1:30:15,  3.65s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [4:27:32<1:27:46,  3.55s/it]                                                       {'loss': 0.1262, 'grad_norm': 10.514147758483887, 'learning_rate': 1.2576271186440677e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [4:27:32<1:27:46,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [4:27:36<1:26:18,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011095673777163029, 'learning_rate': 1.2567796610169492e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [4:27:36<1:26:18,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [4:27:39<1:26:27,  3.50s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.5500272512435913, 'learning_rate': 1.2559322033898305e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [4:27:39<1:26:27,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [4:27:43<1:26:54,  3.52s/it]                                                       {'loss': 0.1226, 'grad_norm': 5.99459981918335, 'learning_rate': 1.2550847457627118e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [4:27:43<1:26:54,  3.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [4:27:47<1:30:19,  3.66s/it]                                                       {'loss': 0.053, 'grad_norm': 6.932815074920654, 'learning_rate': 1.2542372881355932e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [4:27:47<1:30:19,  3.66s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [4:27:50<1:27:49,  3.56s/it]                                                       {'loss': 0.4066, 'grad_norm': 11.372902870178223, 'learning_rate': 1.2533898305084745e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [4:27:50<1:27:49,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [4:27:54<1:31:40,  3.72s/it]                                                       {'loss': 0.0293, 'grad_norm': 3.7654733657836914, 'learning_rate': 1.252542372881356e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [4:27:54<1:31:40,  3.72s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [4:27:58<1:29:17,  3.63s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.683440625667572, 'learning_rate': 1.2516949152542373e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [4:27:58<1:29:17,  3.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [4:28:02<1:36:35,  3.93s/it]                                                       {'loss': 0.0759, 'grad_norm': 3.8545050621032715, 'learning_rate': 1.2508474576271188e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [4:28:02<1:36:35,  3.93s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [4:28:06<1:32:56,  3.78s/it]                                                       {'loss': 0.062, 'grad_norm': 4.079282283782959, 'learning_rate': 1.25e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [4:28:06<1:32:56,  3.78s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [4:28:09<1:32:39,  3.77s/it]                                                       {'loss': 0.0147, 'grad_norm': 2.4747464656829834, 'learning_rate': 1.2491525423728814e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [4:28:10<1:32:39,  3.77s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [4:28:14<1:39:15,  4.04s/it]                                                       {'loss': 0.1673, 'grad_norm': 8.228841781616211, 'learning_rate': 1.2483050847457628e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [4:28:14<1:39:15,  4.04s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [4:28:18<1:35:13,  3.88s/it]                                                       {'loss': 0.2785, 'grad_norm': 7.559571266174316, 'learning_rate': 1.2474576271186441e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [4:28:18<1:35:13,  3.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [4:28:21<1:31:42,  3.74s/it]                                                       {'loss': 0.1631, 'grad_norm': 6.948462963104248, 'learning_rate': 1.2466101694915256e-05, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [4:28:21<1:31:42,  3.74s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [4:28:24<1:28:50,  3.63s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.93464732170105, 'learning_rate': 1.2457627118644069e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [4:28:24<1:28:50,  3.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [4:28:28<1:27:42,  3.58s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6379947066307068, 'learning_rate': 1.2449152542372882e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [4:28:28<1:27:42,  3.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [4:28:31<1:26:36,  3.54s/it]                                                       {'loss': 0.0675, 'grad_norm': 5.890624523162842, 'learning_rate': 1.2440677966101695e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [4:28:31<1:26:36,  3.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [4:28:35<1:25:12,  3.48s/it]                                                       {'loss': 0.0576, 'grad_norm': 6.9432830810546875, 'learning_rate': 1.243220338983051e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [4:28:35<1:25:12,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [4:28:38<1:27:11,  3.57s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.0261157788336277, 'learning_rate': 1.2423728813559323e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [4:28:38<1:27:11,  3.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [4:28:42<1:27:14,  3.57s/it]                                                       {'loss': 0.0417, 'grad_norm': 8.376677513122559, 'learning_rate': 1.2415254237288135e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [4:28:42<1:27:14,  3.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [4:28:46<1:29:17,  3.66s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.8339228630065918, 'learning_rate': 1.240677966101695e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [4:28:46<1:29:17,  3.66s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [4:28:49<1:27:43,  3.60s/it]                                                       {'loss': 0.1082, 'grad_norm': 7.881098747253418, 'learning_rate': 1.2398305084745763e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [4:28:49<1:27:43,  3.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [4:28:53<1:26:05,  3.53s/it]                                                       {'loss': 0.013, 'grad_norm': 2.5204784870147705, 'learning_rate': 1.2389830508474578e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [4:28:53<1:26:05,  3.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [4:28:56<1:25:28,  3.51s/it]                                                       {'loss': 0.041, 'grad_norm': 3.1983578205108643, 'learning_rate': 1.238135593220339e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [4:28:56<1:25:28,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [4:29:00<1:25:23,  3.51s/it]                                                       {'loss': 0.0256, 'grad_norm': 3.6283187866210938, 'learning_rate': 1.2372881355932204e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [4:29:00<1:25:23,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [4:29:04<1:30:12,  3.71s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.7980444431304932, 'learning_rate': 1.2364406779661017e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [4:29:04<1:30:12,  3.71s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [4:29:07<1:27:19,  3.59s/it]                                                       {'loss': 0.1131, 'grad_norm': 6.469142913818359, 'learning_rate': 1.2355932203389831e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [4:29:07<1:27:19,  3.59s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [4:29:11<1:26:31,  3.56s/it]                                                       {'loss': 0.0747, 'grad_norm': 9.186640739440918, 'learning_rate': 1.2347457627118644e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [4:29:11<1:26:31,  3.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [4:29:14<1:25:06,  3.51s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.694951057434082, 'learning_rate': 1.2338983050847457e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [4:29:14<1:25:06,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [4:29:17<1:24:00,  3.46s/it]                                                       {'loss': 0.0339, 'grad_norm': 1.9132543802261353, 'learning_rate': 1.2330508474576272e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [4:29:17<1:24:00,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [4:29:21<1:25:10,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.017315123230218887, 'learning_rate': 1.2322033898305085e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [4:29:21<1:25:10,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [4:29:25<1:24:30,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0943702906370163, 'learning_rate': 1.23135593220339e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [4:29:25<1:24:30,  3.49s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [4:29:28<1:24:20,  3.48s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.13927653431892395, 'learning_rate': 1.2305084745762713e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [4:29:28<1:24:20,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [4:29:31<1:23:06,  3.44s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2712653577327728, 'learning_rate': 1.2296610169491526e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [4:29:31<1:23:06,  3.44s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [4:29:35<1:23:12,  3.44s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.0036587715148926, 'learning_rate': 1.228813559322034e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [4:29:35<1:23:12,  3.44s/it][2025-10-20 19:59:21,776] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [4:29:41<1:39:41,  4.13s/it]                                                       {'loss': 0.1125, 'grad_norm': 6.5369439125061035, 'learning_rate': 1.2279661016949152e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [4:29:41<1:39:41,  4.13s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [4:29:44<1:33:43,  3.88s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.4687600135803223, 'learning_rate': 1.2271186440677966e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [4:29:44<1:33:43,  3.88s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [4:29:47<1:30:11,  3.74s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.059218499809503555, 'learning_rate': 1.226271186440678e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [4:29:47<1:30:11,  3.74s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [4:29:51<1:30:36,  3.76s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.15703152120113373, 'learning_rate': 1.2254237288135594e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [4:29:51<1:30:36,  3.76s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [4:29:54<1:28:07,  3.66s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07292799651622772, 'learning_rate': 1.2245762711864407e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [4:29:54<1:28:07,  3.66s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [4:29:58<1:26:04,  3.58s/it]                                                       {'loss': 0.0678, 'grad_norm': 5.92598295211792, 'learning_rate': 1.2237288135593222e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [4:29:58<1:26:04,  3.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [4:30:02<1:31:28,  3.80s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.5827307105064392, 'learning_rate': 1.2228813559322035e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [4:30:02<1:31:28,  3.80s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [4:30:06<1:29:10,  3.71s/it]                                                       {'loss': 0.3148, 'grad_norm': 6.556060791015625, 'learning_rate': 1.2220338983050848e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [4:30:06<1:29:10,  3.71s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [4:30:09<1:26:46,  3.61s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.20731177926063538, 'learning_rate': 1.2211864406779662e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [4:30:09<1:26:46,  3.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [4:30:12<1:25:14,  3.55s/it]                                                       {'loss': 0.0559, 'grad_norm': 4.085941314697266, 'learning_rate': 1.2203389830508475e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [4:30:12<1:25:14,  3.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [4:30:16<1:23:54,  3.50s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.7993674874305725, 'learning_rate': 1.219491525423729e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [4:30:16<1:23:54,  3.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [4:30:19<1:22:48,  3.46s/it]                                                       {'loss': 0.089, 'grad_norm': 7.612909317016602, 'learning_rate': 1.2186440677966101e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [4:30:19<1:22:48,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [4:30:23<1:22:37,  3.45s/it]                                                       {'loss': 0.018, 'grad_norm': 3.458258867263794, 'learning_rate': 1.2177966101694916e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [4:30:23<1:22:37,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [4:30:26<1:22:47,  3.46s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.4964398741722107, 'learning_rate': 1.2169491525423729e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [4:30:26<1:22:47,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [4:30:29<1:21:57,  3.43s/it]                                                       {'loss': 0.0521, 'grad_norm': 2.708752393722534, 'learning_rate': 1.2161016949152544e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [4:30:29<1:21:57,  3.43s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [4:30:33<1:21:45,  3.42s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2758635878562927, 'learning_rate': 1.2152542372881356e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [4:30:33<1:21:45,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [4:30:36<1:22:26,  3.45s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.634979248046875, 'learning_rate': 1.214406779661017e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [4:30:36<1:22:26,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [4:30:40<1:22:13,  3.45s/it]                                                       {'loss': 0.1014, 'grad_norm': 6.887716293334961, 'learning_rate': 1.2135593220338984e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [4:30:40<1:22:13,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [4:30:43<1:21:20,  3.41s/it]                                                       {'loss': 0.1084, 'grad_norm': 8.497990608215332, 'learning_rate': 1.2127118644067797e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [4:30:43<1:21:20,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [4:30:47<1:20:54,  3.39s/it]                                                       {'loss': 0.0156, 'grad_norm': 2.980947256088257, 'learning_rate': 1.2118644067796612e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [4:30:47<1:20:54,  3.39s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [4:30:50<1:20:23,  3.38s/it]                                                       {'loss': 0.0171, 'grad_norm': 3.9170899391174316, 'learning_rate': 1.2110169491525425e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [4:30:50<1:20:23,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [4:30:53<1:20:31,  3.38s/it]                                                       {'loss': 0.1256, 'grad_norm': 6.489391803741455, 'learning_rate': 1.2101694915254238e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [4:30:53<1:20:31,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [4:30:57<1:19:55,  3.36s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.8226366639137268, 'learning_rate': 1.209322033898305e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [4:30:57<1:19:55,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [4:31:00<1:19:39,  3.35s/it]                                                       {'loss': 0.3046, 'grad_norm': 6.684737682342529, 'learning_rate': 1.2084745762711865e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [4:31:00<1:19:39,  3.35s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [4:31:03<1:20:11,  3.38s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.8163751363754272, 'learning_rate': 1.2076271186440678e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [4:31:03<1:20:11,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [4:31:07<1:20:18,  3.38s/it]                                                       {'loss': 0.0859, 'grad_norm': 5.325079441070557, 'learning_rate': 1.2067796610169491e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [4:31:07<1:20:18,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [4:31:10<1:20:34,  3.40s/it]                                                       {'loss': 0.007, 'grad_norm': 1.5273879766464233, 'learning_rate': 1.2059322033898306e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [4:31:10<1:20:34,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [4:31:14<1:20:57,  3.42s/it]                                                       {'loss': 0.1534, 'grad_norm': 7.886687278747559, 'learning_rate': 1.2050847457627119e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [4:31:14<1:20:57,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [4:31:17<1:21:00,  3.42s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.45097365975379944, 'learning_rate': 1.2042372881355934e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [4:31:17<1:21:00,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [4:31:20<1:20:49,  3.42s/it]                                                       {'loss': 0.0211, 'grad_norm': 1.250906229019165, 'learning_rate': 1.2033898305084747e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [4:31:20<1:20:49,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [4:31:24<1:20:05,  3.39s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5499696135520935, 'learning_rate': 1.202542372881356e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [4:31:24<1:20:05,  3.39s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [4:31:27<1:19:28,  3.36s/it]                                                       {'loss': 0.0887, 'grad_norm': 8.806501388549805, 'learning_rate': 1.2016949152542374e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [4:31:27<1:19:28,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [4:31:30<1:19:51,  3.38s/it]                                                       {'loss': 0.0487, 'grad_norm': 3.470258951187134, 'learning_rate': 1.2008474576271186e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [4:31:31<1:19:51,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [4:31:34<1:23:48,  3.55s/it]                                                       {'loss': 0.0516, 'grad_norm': 3.7436201572418213, 'learning_rate': 1.2e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [4:31:34<1:23:48,  3.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [4:31:38<1:22:48,  3.51s/it]                                                       {'loss': 0.2051, 'grad_norm': 8.808335304260254, 'learning_rate': 1.1991525423728813e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [4:31:38<1:22:48,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [4:31:41<1:21:29,  3.46s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.9081728458404541, 'learning_rate': 1.1983050847457628e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [4:31:41<1:21:29,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [4:31:45<1:22:25,  3.50s/it]                                                       {'loss': 0.0535, 'grad_norm': 7.002688884735107, 'learning_rate': 1.1974576271186441e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [4:31:45<1:22:25,  3.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [4:31:48<1:21:05,  3.45s/it]                                                       {'loss': 0.0881, 'grad_norm': 6.419117450714111, 'learning_rate': 1.1966101694915256e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [4:31:48<1:21:05,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [4:31:51<1:20:28,  3.42s/it]                                                       {'loss': 0.2573, 'grad_norm': 6.8002028465271, 'learning_rate': 1.1957627118644069e-05, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [4:31:51<1:20:28,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [4:31:55<1:21:33,  3.47s/it]                                                       {'loss': 0.077, 'grad_norm': 6.785196304321289, 'learning_rate': 1.1949152542372882e-05, 'epoch': 0.77}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [4:31:55<1:21:33,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [4:31:59<1:21:51,  3.49s/it]                                                       {'loss': 0.0342, 'grad_norm': 3.7182319164276123, 'learning_rate': 1.1940677966101696e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [4:31:59<1:21:51,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [4:32:02<1:22:05,  3.50s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3072208762168884, 'learning_rate': 1.193220338983051e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [4:32:02<1:22:05,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [4:32:06<1:23:47,  3.57s/it]                                                       {'loss': 0.0424, 'grad_norm': 4.62951135635376, 'learning_rate': 1.1923728813559322e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [4:32:06<1:23:47,  3.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [4:32:09<1:22:20,  3.51s/it]                                                       {'loss': 0.0163, 'grad_norm': 2.0548713207244873, 'learning_rate': 1.1915254237288135e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [4:32:09<1:22:20,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [4:32:13<1:21:36,  3.48s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.5569002032279968, 'learning_rate': 1.190677966101695e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [4:32:13<1:21:36,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [4:32:16<1:20:37,  3.45s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.23509620130062103, 'learning_rate': 1.1898305084745763e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [4:32:16<1:20:37,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [4:32:20<1:25:25,  3.65s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.680732786655426, 'learning_rate': 1.1889830508474578e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [4:32:20<1:25:25,  3.65s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [4:32:24<1:23:42,  3.58s/it]                                                       {'loss': 0.0504, 'grad_norm': 3.54803466796875, 'learning_rate': 1.188135593220339e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [4:32:24<1:23:42,  3.58s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [4:32:27<1:22:16,  3.52s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.4083973169326782, 'learning_rate': 1.1872881355932203e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [4:32:27<1:22:16,  3.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [4:32:30<1:21:19,  3.49s/it]                                                       {'loss': 0.0771, 'grad_norm': 4.116847038269043, 'learning_rate': 1.1864406779661018e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [4:32:30<1:21:19,  3.49s/it][2025-10-20 20:02:17,339] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [4:32:36<1:36:34,  4.14s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.4915699064731598, 'learning_rate': 1.1855932203389831e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [4:32:36<1:36:34,  4.14s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [4:32:39<1:31:51,  3.94s/it]                                                       {'loss': 0.088, 'grad_norm': 7.647000312805176, 'learning_rate': 1.1847457627118646e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [4:32:40<1:31:51,  3.94s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [4:32:43<1:28:14,  3.79s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.2021796703338623, 'learning_rate': 1.1838983050847457e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [4:32:43<1:28:14,  3.79s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [4:32:46<1:25:21,  3.67s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.338256597518921, 'learning_rate': 1.1830508474576272e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [4:32:46<1:25:21,  3.67s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [4:32:50<1:23:37,  3.60s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5834712386131287, 'learning_rate': 1.1822033898305085e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [4:32:50<1:23:37,  3.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [4:32:53<1:21:57,  3.53s/it]                                                       {'loss': 0.0563, 'grad_norm': 4.465208053588867, 'learning_rate': 1.18135593220339e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [4:32:53<1:21:57,  3.53s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [4:32:56<1:20:39,  3.47s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.988531768321991, 'learning_rate': 1.1805084745762712e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [4:32:56<1:20:39,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [4:33:00<1:19:48,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05432566627860069, 'learning_rate': 1.1796610169491525e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [4:33:00<1:19:48,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [4:33:04<1:28:07,  3.80s/it]                                                       {'loss': 0.0587, 'grad_norm': 5.921630382537842, 'learning_rate': 1.178813559322034e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [4:33:04<1:28:07,  3.80s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [4:33:08<1:26:54,  3.75s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.14758779108524323, 'learning_rate': 1.1779661016949153e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [4:33:08<1:26:54,  3.75s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [4:33:12<1:30:11,  3.90s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.27517271041870117, 'learning_rate': 1.1771186440677968e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [4:33:12<1:30:11,  3.90s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [4:33:16<1:26:25,  3.74s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5581364631652832, 'learning_rate': 1.176271186440678e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [4:33:16<1:26:25,  3.74s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [4:33:20<1:27:35,  3.79s/it]                                                       {'loss': 0.1765, 'grad_norm': 6.772707462310791, 'learning_rate': 1.1754237288135594e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [4:33:20<1:27:35,  3.79s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [4:33:23<1:24:14,  3.65s/it]                                                       {'loss': 0.0422, 'grad_norm': 4.196444034576416, 'learning_rate': 1.1745762711864407e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [4:33:23<1:24:14,  3.65s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [4:33:26<1:22:18,  3.57s/it]                                                       {'loss': 0.0274, 'grad_norm': 2.8470847606658936, 'learning_rate': 1.173728813559322e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [4:33:26<1:22:18,  3.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [4:33:30<1:20:42,  3.50s/it]                                                       {'loss': 0.005, 'grad_norm': 0.3948366343975067, 'learning_rate': 1.1728813559322034e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [4:33:30<1:20:42,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [4:33:33<1:20:01,  3.47s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.9647572040557861, 'learning_rate': 1.1720338983050847e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [4:33:33<1:20:01,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [4:33:36<1:19:12,  3.44s/it]                                                       {'loss': 0.0203, 'grad_norm': 3.1749298572540283, 'learning_rate': 1.1711864406779662e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [4:33:36<1:19:12,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [4:33:40<1:20:03,  3.48s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.008984699845314026, 'learning_rate': 1.1703389830508475e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [4:33:40<1:20:03,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [4:33:43<1:19:46,  3.47s/it]                                                       {'loss': 0.0271, 'grad_norm': 2.791459560394287, 'learning_rate': 1.169491525423729e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [4:33:43<1:19:46,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [4:33:47<1:19:07,  3.44s/it]                                                       {'loss': 0.2653, 'grad_norm': 7.266474723815918, 'learning_rate': 1.1686440677966103e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [4:33:47<1:19:07,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [4:33:50<1:19:29,  3.46s/it]                                                       {'loss': 0.0696, 'grad_norm': 7.681567192077637, 'learning_rate': 1.1677966101694916e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [4:33:50<1:19:29,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [4:33:54<1:20:42,  3.52s/it]                                                       {'loss': 0.0119, 'grad_norm': 2.5665066242218018, 'learning_rate': 1.166949152542373e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [4:33:54<1:20:42,  3.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [4:33:57<1:19:53,  3.48s/it]                                                       {'loss': 0.0935, 'grad_norm': 5.698399543762207, 'learning_rate': 1.1661016949152542e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [4:33:57<1:19:53,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [4:34:01<1:19:11,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05124996230006218, 'learning_rate': 1.1652542372881356e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [4:34:01<1:19:11,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [4:34:04<1:18:24,  3.42s/it]                                                       {'loss': 0.0417, 'grad_norm': 4.59561014175415, 'learning_rate': 1.164406779661017e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [4:34:04<1:18:24,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [4:34:07<1:17:53,  3.40s/it]                                                       {'loss': 0.0918, 'grad_norm': 5.6680827140808105, 'learning_rate': 1.1635593220338984e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [4:34:07<1:17:53,  3.40s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [4:34:11<1:18:12,  3.42s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.7047367691993713, 'learning_rate': 1.1627118644067797e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [4:34:11<1:18:12,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [4:34:14<1:18:26,  3.43s/it]                                                       {'loss': 0.0168, 'grad_norm': 2.067195415496826, 'learning_rate': 1.1618644067796612e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [4:34:14<1:18:26,  3.43s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [4:34:18<1:21:16,  3.56s/it]                                                       {'loss': 0.0349, 'grad_norm': 4.339962959289551, 'learning_rate': 1.1610169491525424e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [4:34:18<1:21:16,  3.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [4:34:22<1:20:35,  3.53s/it]                                                       {'loss': 0.1711, 'grad_norm': 6.0726094245910645, 'learning_rate': 1.1601694915254237e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [4:34:22<1:20:35,  3.53s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [4:34:25<1:19:13,  3.48s/it]                                                       {'loss': 0.1136, 'grad_norm': 9.182233810424805, 'learning_rate': 1.1593220338983052e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [4:34:25<1:19:13,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [4:34:28<1:18:10,  3.43s/it]                                                       {'loss': 0.049, 'grad_norm': 4.608847618103027, 'learning_rate': 1.1584745762711865e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [4:34:28<1:18:10,  3.43s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [4:34:32<1:18:07,  3.43s/it]                                                       {'loss': 0.0598, 'grad_norm': 5.433821201324463, 'learning_rate': 1.157627118644068e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [4:34:32<1:18:07,  3.43s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [4:34:35<1:17:50,  3.42s/it]                                                       {'loss': 0.1374, 'grad_norm': 6.776272296905518, 'learning_rate': 1.1567796610169491e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [4:34:35<1:17:50,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [4:34:39<1:17:25,  3.41s/it]                                                       {'loss': 0.0293, 'grad_norm': 1.8993369340896606, 'learning_rate': 1.1559322033898306e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [4:34:39<1:17:25,  3.41s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [4:34:42<1:17:43,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.5779983997344971, 'learning_rate': 1.1550847457627119e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [4:34:42<1:17:43,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [4:34:46<1:21:48,  3.60s/it]                                                       {'loss': 0.001, 'grad_norm': 0.20373204350471497, 'learning_rate': 1.1542372881355933e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [4:34:46<1:21:48,  3.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [4:34:49<1:19:52,  3.52s/it]                                                       {'loss': 0.0575, 'grad_norm': 4.134922504425049, 'learning_rate': 1.1533898305084746e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [4:34:49<1:19:52,  3.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [4:34:53<1:18:36,  3.47s/it]                                                       {'loss': 0.009, 'grad_norm': 1.4820356369018555, 'learning_rate': 1.152542372881356e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [4:34:53<1:18:36,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [4:34:56<1:19:17,  3.50s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11994943022727966, 'learning_rate': 1.1516949152542374e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [4:34:56<1:19:17,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [4:35:00<1:17:52,  3.44s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.5438260436058044, 'learning_rate': 1.1508474576271187e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [4:35:00<1:17:52,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [4:35:03<1:20:33,  3.56s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.01897742971777916, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [4:35:03<1:20:33,  3.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [4:35:07<1:19:23,  3.51s/it]                                                       {'loss': 0.0652, 'grad_norm': 4.326870441436768, 'learning_rate': 1.1491525423728815e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [4:35:07<1:19:23,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [4:35:10<1:18:12,  3.46s/it]                                                       {'loss': 0.0541, 'grad_norm': 6.88320255279541, 'learning_rate': 1.1483050847457628e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [4:35:10<1:18:12,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [4:35:14<1:17:13,  3.42s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.6682953834533691, 'learning_rate': 1.147457627118644e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [4:35:14<1:17:13,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [4:35:17<1:17:04,  3.42s/it]                                                       {'loss': 0.0243, 'grad_norm': 3.258026123046875, 'learning_rate': 1.1466101694915254e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [4:35:17<1:17:04,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [4:35:20<1:17:52,  3.46s/it]                                                       {'loss': 0.0274, 'grad_norm': 2.6623661518096924, 'learning_rate': 1.1457627118644068e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [4:35:20<1:17:52,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [4:35:24<1:18:15,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09869164228439331, 'learning_rate': 1.1449152542372881e-05, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [4:35:24<1:18:15,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [4:35:27<1:17:50,  3.46s/it]                                                       {'loss': 0.1204, 'grad_norm': 8.009273529052734, 'learning_rate': 1.1440677966101696e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [4:35:27<1:17:50,  3.46s/it][2025-10-20 20:05:14,422] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [4:35:33<1:33:08,  4.14s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.028100168332457542, 'learning_rate': 1.1432203389830509e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [4:35:33<1:33:08,  4.14s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [4:35:37<1:30:05,  4.01s/it]                                                       {'loss': 0.0191, 'grad_norm': 2.1571969985961914, 'learning_rate': 1.1423728813559324e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [4:35:37<1:30:05,  4.01s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [4:35:40<1:25:35,  3.81s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.7532422542572021, 'learning_rate': 1.1415254237288137e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [4:35:40<1:25:35,  3.81s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [4:35:44<1:23:12,  3.71s/it]                                                       {'loss': 0.038, 'grad_norm': 2.452974319458008, 'learning_rate': 1.140677966101695e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [4:35:44<1:23:12,  3.71s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [4:35:47<1:20:36,  3.60s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.033708095550537, 'learning_rate': 1.1398305084745763e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [4:35:47<1:20:36,  3.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [4:35:51<1:20:33,  3.60s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.671155571937561, 'learning_rate': 1.1389830508474576e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [4:35:51<1:20:33,  3.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [4:35:54<1:18:29,  3.51s/it]                                                       {'loss': 0.067, 'grad_norm': 6.302401542663574, 'learning_rate': 1.138135593220339e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [4:35:54<1:18:29,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [4:35:57<1:17:39,  3.47s/it]                                                       {'loss': 0.1847, 'grad_norm': 10.864653587341309, 'learning_rate': 1.1372881355932203e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [4:35:57<1:17:39,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [4:36:01<1:16:53,  3.44s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.0648486614227295, 'learning_rate': 1.1364406779661018e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [4:36:01<1:16:53,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [4:36:04<1:16:51,  3.44s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.4284372627735138, 'learning_rate': 1.135593220338983e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [4:36:04<1:16:51,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [4:36:08<1:16:31,  3.43s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5188947916030884, 'learning_rate': 1.1347457627118646e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [4:36:08<1:16:31,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [4:36:11<1:16:42,  3.44s/it]                                                       {'loss': 0.007, 'grad_norm': 1.1142491102218628, 'learning_rate': 1.1338983050847458e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [4:36:11<1:16:42,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [4:36:14<1:16:23,  3.43s/it]                                                       {'loss': 0.0179, 'grad_norm': 1.620792031288147, 'learning_rate': 1.1330508474576271e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [4:36:14<1:16:23,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [4:36:18<1:15:57,  3.41s/it]                                                       {'loss': 0.007, 'grad_norm': 1.4509241580963135, 'learning_rate': 1.1322033898305086e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [4:36:18<1:15:57,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [4:36:21<1:15:32,  3.39s/it]                                                       {'loss': 0.0992, 'grad_norm': 4.972024917602539, 'learning_rate': 1.1313559322033899e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [4:36:21<1:15:32,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [4:36:24<1:15:01,  3.37s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.09184804558753967, 'learning_rate': 1.1305084745762712e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [4:36:24<1:15:01,  3.37s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [4:36:28<1:16:38,  3.45s/it]                                                       {'loss': 0.0818, 'grad_norm': 7.4130144119262695, 'learning_rate': 1.1296610169491525e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [4:36:28<1:16:38,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [4:36:31<1:16:08,  3.43s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.026845689862966537, 'learning_rate': 1.128813559322034e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [4:36:31<1:16:08,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [4:36:35<1:15:19,  3.40s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.055266525596380234, 'learning_rate': 1.1279661016949153e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [4:36:35<1:15:19,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [4:36:38<1:15:09,  3.39s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.7347922921180725, 'learning_rate': 1.1271186440677967e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [4:36:38<1:15:09,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [4:36:42<1:15:40,  3.42s/it]                                                       {'loss': 0.0479, 'grad_norm': 5.2047648429870605, 'learning_rate': 1.126271186440678e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [4:36:42<1:15:40,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [4:36:45<1:16:45,  3.47s/it]                                                       {'loss': 0.174, 'grad_norm': 9.743947982788086, 'learning_rate': 1.1254237288135593e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [4:36:45<1:16:45,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [4:36:49<1:16:36,  3.46s/it]                                                       {'loss': 0.007, 'grad_norm': 1.3978984355926514, 'learning_rate': 1.1245762711864408e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [4:36:49<1:16:36,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [4:36:52<1:15:45,  3.43s/it]                                                       {'loss': 0.0968, 'grad_norm': 5.672553539276123, 'learning_rate': 1.1237288135593221e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [4:36:52<1:15:45,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [4:36:55<1:15:06,  3.40s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11529407650232315, 'learning_rate': 1.1228813559322036e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [4:36:55<1:15:06,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [4:36:59<1:14:53,  3.39s/it]                                                       {'loss': 0.0233, 'grad_norm': 4.310171604156494, 'learning_rate': 1.1220338983050847e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [4:36:59<1:14:53,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [4:37:02<1:14:30,  3.38s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.12623587250709534, 'learning_rate': 1.1211864406779662e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [4:37:02<1:14:30,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [4:37:05<1:14:37,  3.39s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.566887617111206, 'learning_rate': 1.1203389830508475e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [4:37:05<1:14:37,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [4:37:09<1:14:56,  3.40s/it]                                                       {'loss': 0.0127, 'grad_norm': 1.8368582725524902, 'learning_rate': 1.1194915254237288e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [4:37:09<1:14:56,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [4:37:12<1:14:43,  3.40s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.8775739073753357, 'learning_rate': 1.1186440677966102e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [4:37:12<1:14:43,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [4:37:16<1:14:21,  3.38s/it]                                                       {'loss': 0.0796, 'grad_norm': 5.363938331604004, 'learning_rate': 1.1177966101694915e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [4:37:16<1:14:21,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [4:37:19<1:14:41,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.025563161820173264, 'learning_rate': 1.116949152542373e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [4:37:19<1:14:41,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [4:37:23<1:14:58,  3.42s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.6690300703048706, 'learning_rate': 1.1161016949152543e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [4:37:23<1:14:58,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [4:37:26<1:16:15,  3.48s/it]                                                       {'loss': 0.004, 'grad_norm': 0.756798505783081, 'learning_rate': 1.1152542372881358e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [4:37:26<1:16:15,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [4:37:30<1:16:15,  3.48s/it]                                                       {'loss': 0.0484, 'grad_norm': 3.2479407787323, 'learning_rate': 1.114406779661017e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [4:37:30<1:16:15,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [4:37:33<1:15:32,  3.45s/it]                                                       {'loss': 0.1095, 'grad_norm': 6.014923572540283, 'learning_rate': 1.1135593220338984e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [4:37:33<1:15:32,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [4:37:36<1:14:46,  3.42s/it]                                                       {'loss': 0.0817, 'grad_norm': 3.941455364227295, 'learning_rate': 1.1127118644067797e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [4:37:36<1:14:46,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [4:37:40<1:14:41,  3.42s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.220778226852417, 'learning_rate': 1.111864406779661e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [4:37:40<1:14:41,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [4:37:44<1:16:49,  3.52s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5514757633209229, 'learning_rate': 1.1110169491525424e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [4:37:44<1:16:49,  3.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [4:37:47<1:16:09,  3.49s/it]                                                       {'loss': 0.1041, 'grad_norm': 7.682368278503418, 'learning_rate': 1.1101694915254237e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [4:37:47<1:16:09,  3.49s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [4:37:50<1:15:29,  3.46s/it]                                                       {'loss': 0.2644, 'grad_norm': 8.543549537658691, 'learning_rate': 1.1093220338983052e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [4:37:50<1:15:29,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [4:37:54<1:14:29,  3.42s/it]                                                       {'loss': 0.0551, 'grad_norm': 1.4936577081680298, 'learning_rate': 1.1084745762711865e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [4:37:54<1:14:29,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [4:37:57<1:14:59,  3.44s/it]                                                       {'loss': 0.0328, 'grad_norm': 5.143878936767578, 'learning_rate': 1.107627118644068e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [4:37:57<1:14:59,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [4:38:01<1:16:25,  3.51s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.24164347350597382, 'learning_rate': 1.1067796610169492e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [4:38:01<1:16:25,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [4:38:05<1:17:35,  3.57s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.6747997999191284, 'learning_rate': 1.1059322033898305e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [4:38:05<1:17:35,  3.57s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [4:38:08<1:16:25,  3.52s/it]                                                       {'loss': 0.0201, 'grad_norm': 1.9246172904968262, 'learning_rate': 1.105084745762712e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [4:38:08<1:16:25,  3.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [4:38:11<1:15:28,  3.48s/it]                                                       {'loss': 0.1135, 'grad_norm': 5.914172649383545, 'learning_rate': 1.1042372881355931e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [4:38:11<1:15:28,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [4:38:15<1:14:31,  3.43s/it]                                                       {'loss': 0.0397, 'grad_norm': 4.898327827453613, 'learning_rate': 1.1033898305084746e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [4:38:15<1:14:31,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [4:38:18<1:14:16,  3.43s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2553442716598511, 'learning_rate': 1.1025423728813559e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [4:38:18<1:14:16,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [4:38:21<1:14:08,  3.42s/it]                                                       {'loss': 0.0313, 'grad_norm': 5.513000965118408, 'learning_rate': 1.1016949152542374e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [4:38:21<1:14:08,  3.42s/it][2025-10-20 20:08:08,454] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [4:38:27<1:28:59,  4.11s/it]                                                       {'loss': 0.0998, 'grad_norm': 6.930583953857422, 'learning_rate': 1.1008474576271187e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [4:38:27<1:28:59,  4.11s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [4:38:31<1:25:22,  3.95s/it]                                                       {'loss': 0.0593, 'grad_norm': 4.424797058105469, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [4:38:31<1:25:22,  3.95s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [4:38:34<1:22:00,  3.79s/it]                                                       {'loss': 0.0158, 'grad_norm': 1.8478124141693115, 'learning_rate': 1.0991525423728814e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [4:38:34<1:22:00,  3.79s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [4:38:38<1:19:23,  3.68s/it]                                                       {'loss': 0.1881, 'grad_norm': 7.028219223022461, 'learning_rate': 1.0983050847457627e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [4:38:38<1:19:23,  3.68s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [4:38:41<1:18:08,  3.62s/it]                                                       {'loss': 0.0878, 'grad_norm': 6.664696216583252, 'learning_rate': 1.0974576271186442e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [4:38:41<1:18:08,  3.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [4:38:45<1:16:55,  3.57s/it]                                                       {'loss': 0.1819, 'grad_norm': 8.455534934997559, 'learning_rate': 1.0966101694915255e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [4:38:45<1:16:55,  3.57s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [4:38:48<1:15:40,  3.51s/it]                                                       {'loss': 0.0234, 'grad_norm': 2.3960065841674805, 'learning_rate': 1.0957627118644068e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [4:38:48<1:15:40,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [4:38:51<1:14:37,  3.47s/it]                                                       {'loss': 0.0291, 'grad_norm': 4.364168643951416, 'learning_rate': 1.0949152542372881e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [4:38:51<1:14:37,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [4:38:55<1:13:40,  3.42s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0727737620472908, 'learning_rate': 1.0940677966101696e-05, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [4:38:55<1:13:40,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [4:38:58<1:13:23,  3.41s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.6439247727394104, 'learning_rate': 1.0932203389830509e-05, 'epoch': 0.79}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [4:38:58<1:13:23,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [4:39:01<1:12:53,  3.39s/it]                                                       {'loss': 0.07, 'grad_norm': 3.17413592338562, 'learning_rate': 1.0923728813559322e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [4:39:01<1:12:53,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [4:39:05<1:14:55,  3.49s/it]                                                       {'loss': 0.0667, 'grad_norm': 3.2791242599487305, 'learning_rate': 1.0915254237288136e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [4:39:05<1:14:55,  3.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [4:39:08<1:13:58,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.029063034802675247, 'learning_rate': 1.090677966101695e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [4:39:08<1:13:58,  3.45s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [4:39:12<1:16:27,  3.57s/it]                                                       {'loss': 0.4021, 'grad_norm': 7.630409240722656, 'learning_rate': 1.0898305084745764e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [4:39:12<1:16:27,  3.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [4:39:16<1:14:32,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.10006596148014069, 'learning_rate': 1.0889830508474577e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [4:39:16<1:14:32,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [4:39:19<1:13:40,  3.44s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.5665619373321533, 'learning_rate': 1.0881355932203392e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [4:39:19<1:13:40,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [4:39:22<1:13:21,  3.43s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.6156233549118042, 'learning_rate': 1.0872881355932205e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [4:39:22<1:13:21,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [4:39:26<1:14:47,  3.50s/it]                                                       {'loss': 0.0383, 'grad_norm': 6.197731971740723, 'learning_rate': 1.0864406779661018e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [4:39:26<1:14:47,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [4:39:29<1:14:35,  3.49s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.22604870796203613, 'learning_rate': 1.085593220338983e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [4:39:29<1:14:35,  3.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [4:39:33<1:13:48,  3.46s/it]                                                       {'loss': 0.047, 'grad_norm': 5.9829840660095215, 'learning_rate': 1.0847457627118644e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [4:39:33<1:13:48,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [4:39:36<1:12:32,  3.40s/it]                                                       {'loss': 0.046, 'grad_norm': 5.437859058380127, 'learning_rate': 1.0838983050847458e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [4:39:36<1:12:32,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [4:39:39<1:12:01,  3.38s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.10492531210184097, 'learning_rate': 1.0830508474576271e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [4:39:39<1:12:01,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [4:39:43<1:12:05,  3.39s/it]                                                       {'loss': 0.0318, 'grad_norm': 5.762531280517578, 'learning_rate': 1.0822033898305086e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [4:39:43<1:12:05,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [4:39:46<1:12:01,  3.39s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.1307989358901978, 'learning_rate': 1.0813559322033899e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [4:39:46<1:12:01,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [4:39:50<1:12:33,  3.41s/it]                                                       {'loss': 0.037, 'grad_norm': 4.518895626068115, 'learning_rate': 1.0805084745762714e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [4:39:50<1:12:33,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [4:39:53<1:14:55,  3.53s/it]                                                       {'loss': 0.1161, 'grad_norm': 7.681549549102783, 'learning_rate': 1.0796610169491526e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [4:39:53<1:14:55,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [4:39:57<1:17:10,  3.64s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.16104969382286072, 'learning_rate': 1.078813559322034e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [4:39:57<1:17:10,  3.64s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [4:40:01<1:15:42,  3.57s/it]                                                       {'loss': 0.0239, 'grad_norm': 3.531987190246582, 'learning_rate': 1.0779661016949152e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [4:40:01<1:15:42,  3.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [4:40:04<1:14:36,  3.52s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4953128397464752, 'learning_rate': 1.0771186440677965e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [4:40:04<1:14:36,  3.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [4:40:08<1:14:23,  3.51s/it]                                                       {'loss': 0.0434, 'grad_norm': 2.6597187519073486, 'learning_rate': 1.076271186440678e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [4:40:08<1:14:23,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [4:40:11<1:13:43,  3.49s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.44942954182624817, 'learning_rate': 1.0754237288135593e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [4:40:11<1:13:43,  3.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [4:40:14<1:12:45,  3.44s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0040603443048894405, 'learning_rate': 1.0745762711864408e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [4:40:14<1:12:45,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [4:40:18<1:14:55,  3.55s/it]                                                       {'loss': 0.1526, 'grad_norm': 6.28207540512085, 'learning_rate': 1.073728813559322e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [4:40:18<1:14:55,  3.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [4:40:22<1:14:50,  3.55s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.0168859958648682, 'learning_rate': 1.0728813559322035e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [4:40:22<1:14:50,  3.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [4:40:25<1:13:41,  3.50s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.243767499923706, 'learning_rate': 1.0720338983050848e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [4:40:25<1:13:41,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [4:40:29<1:13:05,  3.47s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.22042019665241241, 'learning_rate': 1.0711864406779661e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [4:40:29<1:13:05,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [4:40:32<1:12:33,  3.45s/it]                                                       {'loss': 0.0149, 'grad_norm': 2.3166122436523438, 'learning_rate': 1.0703389830508476e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [4:40:32<1:12:33,  3.45s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [4:40:36<1:14:42,  3.55s/it]                                                       {'loss': 0.0683, 'grad_norm': 2.397962808609009, 'learning_rate': 1.0694915254237287e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [4:40:36<1:14:42,  3.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [4:40:39<1:13:51,  3.51s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.7947033643722534, 'learning_rate': 1.0686440677966102e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [4:40:39<1:13:51,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [4:40:43<1:13:40,  3.51s/it]                                                       {'loss': 0.109, 'grad_norm': 3.5174362659454346, 'learning_rate': 1.0677966101694915e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [4:40:43<1:13:40,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [4:40:46<1:12:32,  3.46s/it]                                                       {'loss': 0.3565, 'grad_norm': 13.4339017868042, 'learning_rate': 1.066949152542373e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [4:40:46<1:12:32,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [4:40:49<1:12:42,  3.47s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.9702624082565308, 'learning_rate': 1.0661016949152543e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [4:40:49<1:12:42,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [4:40:53<1:12:00,  3.44s/it]                                                       {'loss': 0.0836, 'grad_norm': 5.643726825714111, 'learning_rate': 1.0652542372881356e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [4:40:53<1:12:00,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [4:40:56<1:11:17,  3.41s/it]                                                       {'loss': 0.0265, 'grad_norm': 3.109992027282715, 'learning_rate': 1.064406779661017e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [4:40:56<1:11:17,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [4:41:00<1:10:48,  3.39s/it]                                                       {'loss': 0.0509, 'grad_norm': 3.5582072734832764, 'learning_rate': 1.0635593220338983e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [4:41:00<1:10:48,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [4:41:03<1:12:19,  3.46s/it]                                                       {'loss': 0.0876, 'grad_norm': 4.768489360809326, 'learning_rate': 1.0627118644067798e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [4:41:03<1:12:19,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [4:41:07<1:13:30,  3.52s/it]                                                       {'loss': 0.017, 'grad_norm': 3.041950225830078, 'learning_rate': 1.0618644067796611e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [4:41:07<1:13:30,  3.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [4:41:10<1:12:25,  3.47s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.11955777555704117, 'learning_rate': 1.0610169491525426e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [4:41:10<1:12:25,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [4:41:14<1:11:46,  3.44s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.8131710290908813, 'learning_rate': 1.0601694915254237e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [4:41:14<1:11:46,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [4:41:17<1:11:14,  3.42s/it]                                                       {'loss': 0.0228, 'grad_norm': 2.9714503288269043, 'learning_rate': 1.0593220338983052e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [4:41:17<1:11:14,  3.42s/it][2025-10-20 20:11:03,917] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [4:41:23<1:25:31,  4.11s/it]                                                       {'loss': 0.028, 'grad_norm': 3.5281665325164795, 'learning_rate': 1.0584745762711865e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [4:41:23<1:25:31,  4.11s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [4:41:26<1:21:26,  3.92s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.6837098598480225, 'learning_rate': 1.0576271186440678e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [4:41:26<1:21:26,  3.92s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [4:41:29<1:17:54,  3.75s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.11897516250610352, 'learning_rate': 1.0567796610169492e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [4:41:29<1:17:54,  3.75s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [4:41:33<1:14:59,  3.61s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.8412490487098694, 'learning_rate': 1.0559322033898305e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [4:41:33<1:14:59,  3.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [4:41:36<1:13:12,  3.53s/it]                                                       {'loss': 0.0183, 'grad_norm': 2.7779667377471924, 'learning_rate': 1.055084745762712e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [4:41:36<1:13:12,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [4:41:39<1:11:51,  3.47s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.9425427913665771, 'learning_rate': 1.0542372881355933e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [4:41:39<1:11:51,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [4:41:43<1:10:39,  3.41s/it]                                                       {'loss': 0.0516, 'grad_norm': 6.779332637786865, 'learning_rate': 1.0533898305084747e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [4:41:43<1:10:39,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [4:41:46<1:10:33,  3.41s/it]                                                       {'loss': 0.045, 'grad_norm': 4.466848850250244, 'learning_rate': 1.052542372881356e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [4:41:46<1:10:33,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [4:41:49<1:10:15,  3.40s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.266891747713089, 'learning_rate': 1.0516949152542373e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [4:41:49<1:10:15,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [4:41:53<1:09:53,  3.38s/it]                                                       {'loss': 0.0735, 'grad_norm': 6.898177146911621, 'learning_rate': 1.0508474576271186e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [4:41:53<1:09:53,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [4:41:56<1:09:52,  3.38s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.3990114629268646, 'learning_rate': 1.05e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [4:41:56<1:09:52,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [4:42:00<1:09:45,  3.38s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.16465310752391815, 'learning_rate': 1.0491525423728814e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [4:42:00<1:09:45,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [4:42:03<1:09:34,  3.37s/it]                                                       {'loss': 0.2076, 'grad_norm': 8.434446334838867, 'learning_rate': 1.0483050847457627e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [4:42:03<1:09:34,  3.37s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [4:42:07<1:12:00,  3.50s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0667412132024765, 'learning_rate': 1.0474576271186442e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [4:42:07<1:12:00,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [4:42:10<1:11:25,  3.47s/it]                                                       {'loss': 0.0253, 'grad_norm': 4.485720157623291, 'learning_rate': 1.0466101694915255e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [4:42:10<1:11:25,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [4:42:14<1:10:55,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12889859080314636, 'learning_rate': 1.045762711864407e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [4:42:14<1:10:55,  3.45s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [4:42:17<1:10:15,  3.42s/it]                                                       {'loss': 0.11, 'grad_norm': 7.329582691192627, 'learning_rate': 1.0449152542372882e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [4:42:17<1:10:15,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [4:42:20<1:09:33,  3.39s/it]                                                       {'loss': 0.0133, 'grad_norm': 2.221709966659546, 'learning_rate': 1.0440677966101695e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [4:42:20<1:09:33,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [4:42:24<1:09:43,  3.40s/it]                                                       {'loss': 0.1716, 'grad_norm': 11.461949348449707, 'learning_rate': 1.043220338983051e-05, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [4:42:24<1:09:43,  3.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [4:42:27<1:09:44,  3.40s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.1764758676290512, 'learning_rate': 1.0423728813559321e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [4:42:27<1:09:44,  3.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [4:42:31<1:10:22,  3.44s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.2014427185058594, 'learning_rate': 1.0415254237288136e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [4:42:31<1:10:22,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [4:42:34<1:09:28,  3.39s/it]                                                       {'loss': 0.0836, 'grad_norm': 5.419503688812256, 'learning_rate': 1.0406779661016949e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [4:42:34<1:09:28,  3.39s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [4:42:37<1:10:35,  3.45s/it]                                                       {'loss': 0.0284, 'grad_norm': 4.471427917480469, 'learning_rate': 1.0398305084745764e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [4:42:37<1:10:35,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [4:42:41<1:11:00,  3.48s/it]                                                       {'loss': 0.09, 'grad_norm': 3.804213047027588, 'learning_rate': 1.0389830508474577e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [4:42:41<1:11:00,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [4:42:44<1:11:05,  3.48s/it]                                                       {'loss': 0.2953, 'grad_norm': 9.264534950256348, 'learning_rate': 1.038135593220339e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [4:42:44<1:11:05,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [4:42:48<1:10:41,  3.47s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5102762579917908, 'learning_rate': 1.0372881355932204e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [4:42:48<1:10:41,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [4:42:51<1:09:56,  3.43s/it]                                                       {'loss': 0.0663, 'grad_norm': 4.105052947998047, 'learning_rate': 1.0364406779661017e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [4:42:51<1:09:56,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [4:42:55<1:11:07,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0665295422077179, 'learning_rate': 1.0355932203389832e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [4:42:55<1:11:07,  3.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [4:42:59<1:14:39,  3.67s/it]                                                       {'loss': 0.1865, 'grad_norm': 10.429854393005371, 'learning_rate': 1.0347457627118645e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [4:42:59<1:14:39,  3.67s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [4:43:02<1:12:39,  3.57s/it]                                                       {'loss': 0.0196, 'grad_norm': 3.8860230445861816, 'learning_rate': 1.0338983050847458e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [4:43:02<1:12:39,  3.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [4:43:06<1:12:53,  3.59s/it]                                                       {'loss': 0.0687, 'grad_norm': 5.163542747497559, 'learning_rate': 1.0330508474576271e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [4:43:06<1:12:53,  3.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [4:43:09<1:11:11,  3.51s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.34164559841156, 'learning_rate': 1.0322033898305086e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [4:43:09<1:11:11,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [4:43:13<1:10:12,  3.46s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.023386571556329727, 'learning_rate': 1.0313559322033899e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [4:43:13<1:10:12,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [4:43:16<1:12:38,  3.58s/it]                                                       {'loss': 0.1449, 'grad_norm': 8.032068252563477, 'learning_rate': 1.0305084745762712e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [4:43:16<1:12:38,  3.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [4:43:20<1:11:02,  3.51s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06250760704278946, 'learning_rate': 1.0296610169491526e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [4:43:20<1:11:02,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [4:43:23<1:09:58,  3.46s/it]                                                       {'loss': 0.0343, 'grad_norm': 4.7469258308410645, 'learning_rate': 1.028813559322034e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [4:43:23<1:09:58,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [4:43:27<1:11:38,  3.54s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06556262075901031, 'learning_rate': 1.0279661016949154e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [4:43:27<1:11:38,  3.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [4:43:31<1:13:09,  3.62s/it]                                                       {'loss': 0.0181, 'grad_norm': 1.9996309280395508, 'learning_rate': 1.0271186440677967e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [4:43:31<1:13:09,  3.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [4:43:34<1:11:45,  3.56s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4080192446708679, 'learning_rate': 1.0262711864406781e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [4:43:34<1:11:45,  3.56s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [4:43:37<1:10:44,  3.51s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06059568375349045, 'learning_rate': 1.0254237288135593e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [4:43:37<1:10:44,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [4:43:41<1:09:34,  3.45s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.3338374197483063, 'learning_rate': 1.0245762711864407e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [4:43:41<1:09:34,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [4:43:44<1:10:48,  3.52s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.484754204750061, 'learning_rate': 1.023728813559322e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [4:43:44<1:10:48,  3.52s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [4:43:48<1:09:59,  3.48s/it]                                                       {'loss': 0.0642, 'grad_norm': 6.426487445831299, 'learning_rate': 1.0228813559322033e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [4:43:48<1:09:59,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [4:43:51<1:09:23,  3.45s/it]                                                       {'loss': 0.0696, 'grad_norm': 5.354823589324951, 'learning_rate': 1.0220338983050848e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [4:43:51<1:09:23,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [4:43:55<1:08:57,  3.43s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.953341007232666, 'learning_rate': 1.0211864406779661e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [4:43:55<1:08:57,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [4:43:58<1:09:06,  3.44s/it]                                                       {'loss': 0.1743, 'grad_norm': 8.72634506225586, 'learning_rate': 1.0203389830508476e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [4:43:58<1:09:06,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [4:44:02<1:09:01,  3.44s/it]                                                       {'loss': 0.0156, 'grad_norm': 3.177095413208008, 'learning_rate': 1.0194915254237289e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [4:44:02<1:09:01,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [4:44:05<1:07:48,  3.38s/it]                                                       {'loss': 0.0748, 'grad_norm': 6.579974174499512, 'learning_rate': 1.0186440677966103e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [4:44:05<1:07:48,  3.38s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [4:44:09<1:10:08,  3.50s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.12435593456029892, 'learning_rate': 1.0177966101694916e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [4:44:09<1:10:08,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [4:44:12<1:09:18,  3.47s/it]                                                       {'loss': 0.1277, 'grad_norm': 5.155653476715088, 'learning_rate': 1.016949152542373e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [4:44:12<1:09:18,  3.47s/it][2025-10-20 20:13:58,942] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [4:44:18<1:22:16,  4.12s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.34527587890625, 'learning_rate': 1.0161016949152542e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [4:44:18<1:22:16,  4.12s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [4:44:22<1:22:01,  4.11s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.1790508031845093, 'learning_rate': 1.0152542372881355e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [4:44:22<1:22:01,  4.11s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [4:44:25<1:18:42,  3.95s/it]                                                       {'loss': 0.0334, 'grad_norm': 4.500468730926514, 'learning_rate': 1.014406779661017e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [4:44:25<1:18:42,  3.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [4:44:29<1:15:43,  3.80s/it]                                                       {'loss': 0.0705, 'grad_norm': 3.0249788761138916, 'learning_rate': 1.0135593220338983e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [4:44:29<1:15:43,  3.80s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [4:44:32<1:15:01,  3.77s/it]                                                       {'loss': 0.1242, 'grad_norm': 6.6548919677734375, 'learning_rate': 1.0127118644067798e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [4:44:32<1:15:01,  3.77s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [4:44:36<1:12:26,  3.64s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.16154758632183075, 'learning_rate': 1.011864406779661e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [4:44:36<1:12:26,  3.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [4:44:39<1:11:06,  3.58s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.18604250252246857, 'learning_rate': 1.0110169491525424e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [4:44:39<1:11:06,  3.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [4:44:43<1:09:44,  3.51s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.15684200823307037, 'learning_rate': 1.0101694915254238e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [4:44:43<1:09:44,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [4:44:46<1:08:52,  3.47s/it]                                                       {'loss': 0.014, 'grad_norm': 2.175828456878662, 'learning_rate': 1.0093220338983051e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [4:44:46<1:08:52,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [4:44:49<1:08:08,  3.44s/it]                                                       {'loss': 0.1453, 'grad_norm': 5.481298923492432, 'learning_rate': 1.0084745762711866e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [4:44:49<1:08:08,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [4:44:53<1:07:49,  3.42s/it]                                                       {'loss': 0.0205, 'grad_norm': 1.9837090969085693, 'learning_rate': 1.0076271186440677e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [4:44:53<1:07:49,  3.42s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [4:44:56<1:08:26,  3.46s/it]                                                       {'loss': 0.009, 'grad_norm': 1.1408673524856567, 'learning_rate': 1.0067796610169492e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [4:44:56<1:08:26,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [4:45:00<1:07:51,  3.43s/it]                                                       {'loss': 0.0229, 'grad_norm': 3.2978227138519287, 'learning_rate': 1.0059322033898305e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [4:45:00<1:07:51,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [4:45:04<1:11:47,  3.63s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.45273149013519287, 'learning_rate': 1.005084745762712e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [4:45:04<1:11:47,  3.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [4:45:07<1:09:59,  3.54s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.5505892038345337, 'learning_rate': 1.0042372881355933e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [4:45:07<1:09:59,  3.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [4:45:10<1:08:40,  3.48s/it]                                                       {'loss': 0.2134, 'grad_norm': 8.303722381591797, 'learning_rate': 1.0033898305084746e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [4:45:10<1:08:40,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [4:45:14<1:07:50,  3.44s/it]                                                       {'loss': 0.0565, 'grad_norm': 5.22531270980835, 'learning_rate': 1.002542372881356e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [4:45:14<1:07:50,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [4:45:18<1:10:22,  3.57s/it]                                                       {'loss': 0.0209, 'grad_norm': 2.0031864643096924, 'learning_rate': 1.0016949152542373e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [4:45:18<1:10:22,  3.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [4:45:21<1:09:30,  3.53s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.859023094177246, 'learning_rate': 1.0008474576271188e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [4:45:21<1:09:30,  3.53s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [4:45:24<1:08:45,  3.50s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.5042493343353271, 'learning_rate': 1e-05, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [4:45:24<1:08:45,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [4:45:28<1:07:45,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1246974915266037, 'learning_rate': 9.991525423728815e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [4:45:28<1:07:45,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [4:45:31<1:08:29,  3.49s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.2214595079421997, 'learning_rate': 9.983050847457627e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [4:45:31<1:08:29,  3.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [4:45:35<1:07:41,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1128271073102951, 'learning_rate': 9.974576271186441e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [4:45:35<1:07:41,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [4:45:38<1:07:10,  3.43s/it]                                                       {'loss': 0.1971, 'grad_norm': 9.256052017211914, 'learning_rate': 9.966101694915254e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [4:45:38<1:07:10,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [4:45:42<1:08:58,  3.52s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.8645449280738831, 'learning_rate': 9.957627118644067e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [4:45:42<1:08:58,  3.52s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [4:45:45<1:09:17,  3.54s/it]                                                       {'loss': 0.1582, 'grad_norm': 8.863532066345215, 'learning_rate': 9.949152542372882e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [4:45:45<1:09:17,  3.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [4:45:49<1:08:19,  3.49s/it]                                                       {'loss': 0.3757, 'grad_norm': 11.81352424621582, 'learning_rate': 9.940677966101695e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [4:45:49<1:08:19,  3.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [4:45:52<1:07:49,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.19270694255828857, 'learning_rate': 9.93220338983051e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [4:45:52<1:07:49,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [4:45:56<1:07:39,  3.47s/it]                                                       {'loss': 0.1564, 'grad_norm': 6.962696552276611, 'learning_rate': 9.923728813559323e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [4:45:56<1:07:39,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [4:46:00<1:15:21,  3.86s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.17204532027244568, 'learning_rate': 9.915254237288137e-06, 'epoch': 0.81}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [4:46:00<1:15:21,  3.86s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [4:46:04<1:13:49,  3.79s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.038059115409851, 'learning_rate': 9.90677966101695e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [4:46:04<1:13:49,  3.79s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [4:46:07<1:11:19,  3.66s/it]                                                       {'loss': 0.0378, 'grad_norm': 1.3211148977279663, 'learning_rate': 9.898305084745763e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [4:46:07<1:11:19,  3.66s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [4:46:11<1:12:50,  3.74s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.19082011282444, 'learning_rate': 9.889830508474576e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [4:46:11<1:12:50,  3.74s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [4:46:15<1:10:32,  3.63s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2064000517129898, 'learning_rate': 9.88135593220339e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [4:46:15<1:10:32,  3.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [4:46:19<1:13:46,  3.80s/it]                                                       {'loss': 0.0367, 'grad_norm': 3.2447569370269775, 'learning_rate': 9.872881355932204e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [4:46:19<1:13:46,  3.80s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [4:46:22<1:11:39,  3.69s/it]                                                       {'loss': 0.0481, 'grad_norm': 3.6913695335388184, 'learning_rate': 9.864406779661017e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [4:46:22<1:11:39,  3.69s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [4:46:26<1:09:57,  3.61s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07568220049142838, 'learning_rate': 9.855932203389832e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [4:46:26<1:09:57,  3.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [4:46:30<1:11:20,  3.68s/it]                                                       {'loss': 0.1029, 'grad_norm': 5.42294979095459, 'learning_rate': 9.847457627118645e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [4:46:30<1:11:20,  3.68s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [4:46:34<1:16:04,  3.93s/it]                                                       {'loss': 0.0281, 'grad_norm': 2.596189260482788, 'learning_rate': 9.838983050847458e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [4:46:34<1:16:04,  3.93s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [4:46:38<1:12:48,  3.77s/it]                                                       {'loss': 0.1675, 'grad_norm': 5.8716349601745605, 'learning_rate': 9.830508474576272e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [4:46:38<1:12:48,  3.77s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [4:46:41<1:10:50,  3.67s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.1420480012893677, 'learning_rate': 9.822033898305085e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [4:46:41<1:10:50,  3.67s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [4:46:44<1:09:37,  3.61s/it]                                                       {'loss': 0.0362, 'grad_norm': 5.56043815612793, 'learning_rate': 9.813559322033898e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [4:46:44<1:09:37,  3.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [4:46:48<1:10:22,  3.65s/it]                                                       {'loss': 0.1525, 'grad_norm': 8.517413139343262, 'learning_rate': 9.805084745762711e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [4:46:48<1:10:22,  3.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [4:46:52<1:09:39,  3.62s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.3825141489505768, 'learning_rate': 9.796610169491526e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [4:46:52<1:09:39,  3.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [4:46:55<1:08:11,  3.54s/it]                                                       {'loss': 0.1498, 'grad_norm': 9.112078666687012, 'learning_rate': 9.788135593220339e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [4:46:55<1:08:11,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [4:46:58<1:06:35,  3.46s/it]                                                       {'loss': 0.0425, 'grad_norm': 0.4333353638648987, 'learning_rate': 9.779661016949154e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [4:46:58<1:06:35,  3.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [4:47:02<1:06:20,  3.45s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.6148309707641602, 'learning_rate': 9.771186440677967e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [4:47:02<1:06:20,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [4:47:05<1:05:50,  3.43s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.022133708000183, 'learning_rate': 9.76271186440678e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [4:47:05<1:05:50,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [4:47:09<1:06:33,  3.47s/it]                                                       {'loss': 0.0198, 'grad_norm': 3.038796901702881, 'learning_rate': 9.754237288135594e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [4:47:09<1:06:33,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [4:47:12<1:06:43,  3.48s/it]                                                       {'loss': 0.0183, 'grad_norm': 1.6734116077423096, 'learning_rate': 9.745762711864407e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [4:47:12<1:06:43,  3.48s/it][2025-10-20 20:16:59,221] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [4:47:18<1:20:26,  4.20s/it]                                                       {'loss': 0.0974, 'grad_norm': 6.665445804595947, 'learning_rate': 9.737288135593222e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [4:47:18<1:20:26,  4.20s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [4:47:21<1:15:33,  3.95s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.16036616265773773, 'learning_rate': 9.728813559322035e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [4:47:21<1:15:33,  3.95s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [4:47:25<1:11:46,  3.75s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.09938632696866989, 'learning_rate': 9.720338983050848e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [4:47:25<1:11:46,  3.75s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [4:47:28<1:09:37,  3.65s/it]                                                       {'loss': 0.3172, 'grad_norm': 8.612174987792969, 'learning_rate': 9.71186440677966e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [4:47:28<1:09:37,  3.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [4:47:32<1:10:03,  3.67s/it]                                                       {'loss': 0.0552, 'grad_norm': 4.694701671600342, 'learning_rate': 9.703389830508475e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [4:47:32<1:10:03,  3.67s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [4:47:35<1:07:45,  3.55s/it]                                                       {'loss': 0.1009, 'grad_norm': 6.312811851501465, 'learning_rate': 9.694915254237288e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [4:47:35<1:07:45,  3.55s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [4:47:39<1:06:38,  3.50s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.8801880478858948, 'learning_rate': 9.686440677966101e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [4:47:39<1:06:38,  3.50s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [4:47:42<1:06:41,  3.50s/it]                                                       {'loss': 0.2525, 'grad_norm': 9.538851737976074, 'learning_rate': 9.677966101694916e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [4:47:42<1:06:41,  3.50s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [4:47:46<1:08:35,  3.61s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.9781015515327454, 'learning_rate': 9.669491525423729e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [4:47:46<1:08:35,  3.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [4:47:49<1:06:47,  3.51s/it]                                                       {'loss': 0.0124, 'grad_norm': 1.8347734212875366, 'learning_rate': 9.661016949152544e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [4:47:49<1:06:47,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [4:47:53<1:06:01,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09078697115182877, 'learning_rate': 9.652542372881357e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [4:47:53<1:06:01,  3.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [4:47:56<1:06:38,  3.51s/it]                                                       {'loss': 0.0609, 'grad_norm': 5.0493927001953125, 'learning_rate': 9.644067796610171e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [4:47:56<1:06:38,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [4:48:00<1:06:09,  3.49s/it]                                                       {'loss': 0.0852, 'grad_norm': 7.803936958312988, 'learning_rate': 9.635593220338983e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [4:48:00<1:06:09,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [4:48:03<1:07:46,  3.58s/it]                                                       {'loss': 0.1435, 'grad_norm': 6.515529632568359, 'learning_rate': 9.627118644067797e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [4:48:03<1:07:46,  3.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [4:48:07<1:07:53,  3.59s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5796087384223938, 'learning_rate': 9.61864406779661e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [4:48:07<1:07:53,  3.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [4:48:10<1:06:51,  3.54s/it]                                                       {'loss': 0.015, 'grad_norm': 2.306241512298584, 'learning_rate': 9.610169491525423e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [4:48:10<1:06:51,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [4:48:14<1:05:54,  3.49s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1267041712999344, 'learning_rate': 9.601694915254238e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [4:48:14<1:05:54,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [4:48:17<1:05:33,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.12115228176116943, 'learning_rate': 9.593220338983051e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [4:48:17<1:05:33,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [4:48:21<1:04:51,  3.44s/it]                                                       {'loss': 0.0546, 'grad_norm': 5.933540344238281, 'learning_rate': 9.584745762711866e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [4:48:21<1:04:51,  3.44s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [4:48:24<1:04:22,  3.42s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.6509913802146912, 'learning_rate': 9.576271186440679e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [4:48:24<1:04:22,  3.42s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [4:48:28<1:07:03,  3.56s/it]                                                       {'loss': 0.033, 'grad_norm': 4.247742176055908, 'learning_rate': 9.567796610169492e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [4:48:28<1:07:03,  3.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [4:48:31<1:06:49,  3.55s/it]                                                       {'loss': 0.0673, 'grad_norm': 3.3293309211730957, 'learning_rate': 9.559322033898306e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [4:48:31<1:06:49,  3.55s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [4:48:35<1:06:19,  3.53s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.6528981924057007, 'learning_rate': 9.55084745762712e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [4:48:35<1:06:19,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [4:48:38<1:06:23,  3.54s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.6750433444976807, 'learning_rate': 9.542372881355932e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [4:48:38<1:06:23,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [4:48:42<1:05:21,  3.49s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09003596007823944, 'learning_rate': 9.533898305084745e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [4:48:42<1:05:21,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [4:48:46<1:07:25,  3.60s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07028882950544357, 'learning_rate': 9.52542372881356e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [4:48:46<1:07:25,  3.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [4:48:49<1:06:55,  3.58s/it]                                                       {'loss': 0.2434, 'grad_norm': 7.471368789672852, 'learning_rate': 9.516949152542373e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [4:48:49<1:06:55,  3.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [4:48:53<1:06:09,  3.54s/it]                                                       {'loss': 0.153, 'grad_norm': 7.870560646057129, 'learning_rate': 9.508474576271188e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [4:48:53<1:06:09,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [4:48:56<1:05:53,  3.53s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.6532952785491943, 'learning_rate': 9.5e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [4:48:56<1:05:53,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [4:49:00<1:05:50,  3.53s/it]                                                       {'loss': 0.0166, 'grad_norm': 2.33188533782959, 'learning_rate': 9.491525423728814e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [4:49:00<1:05:50,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [4:49:03<1:04:42,  3.47s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3425596356391907, 'learning_rate': 9.483050847457628e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [4:49:03<1:04:42,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [4:49:06<1:03:48,  3.42s/it]                                                       {'loss': 0.0803, 'grad_norm': 5.447841644287109, 'learning_rate': 9.474576271186441e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [4:49:06<1:03:48,  3.42s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [4:49:10<1:03:10,  3.39s/it]                                                       {'loss': 0.0804, 'grad_norm': 5.096923351287842, 'learning_rate': 9.466101694915256e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [4:49:10<1:03:10,  3.39s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [4:49:13<1:02:54,  3.38s/it]                                                       {'loss': 0.2763, 'grad_norm': 6.688482761383057, 'learning_rate': 9.457627118644067e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [4:49:13<1:02:54,  3.38s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [4:49:16<1:03:21,  3.41s/it]                                                       {'loss': 0.2451, 'grad_norm': 10.158438682556152, 'learning_rate': 9.449152542372882e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [4:49:16<1:03:21,  3.41s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [4:49:20<1:02:56,  3.39s/it]                                                       {'loss': 0.0225, 'grad_norm': 3.5316970348358154, 'learning_rate': 9.440677966101695e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [4:49:20<1:02:56,  3.39s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [4:49:23<1:03:12,  3.41s/it]                                                       {'loss': 0.004, 'grad_norm': 0.5294697880744934, 'learning_rate': 9.43220338983051e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [4:49:23<1:03:12,  3.41s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [4:49:27<1:02:39,  3.38s/it]                                                       {'loss': 0.0347, 'grad_norm': 3.720776319503784, 'learning_rate': 9.423728813559322e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [4:49:27<1:02:39,  3.38s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [4:49:30<1:02:20,  3.37s/it]                                                       {'loss': 0.0481, 'grad_norm': 4.1452836990356445, 'learning_rate': 9.415254237288135e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [4:49:30<1:02:20,  3.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [4:49:33<1:01:57,  3.35s/it]                                                       {'loss': 0.1143, 'grad_norm': 8.22285270690918, 'learning_rate': 9.40677966101695e-06, 'epoch': 0.81}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [4:49:33<1:01:57,  3.35s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [4:49:37<1:01:47,  3.34s/it]                                                       {'loss': 0.1975, 'grad_norm': 6.648589611053467, 'learning_rate': 9.398305084745763e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [4:49:37<1:01:47,  3.34s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [4:49:40<1:01:43,  3.34s/it]                                                       {'loss': 0.1061, 'grad_norm': 6.012190341949463, 'learning_rate': 9.389830508474578e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [4:49:40<1:01:43,  3.34s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [4:49:43<1:02:15,  3.37s/it]                                                       {'loss': 0.0673, 'grad_norm': 5.39844274520874, 'learning_rate': 9.38135593220339e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [4:49:43<1:02:15,  3.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [4:49:47<1:02:14,  3.38s/it]                                                       {'loss': 0.0381, 'grad_norm': 8.321714401245117, 'learning_rate': 9.372881355932204e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [4:49:47<1:02:14,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [4:49:50<1:02:30,  3.39s/it]                                                       {'loss': 0.0688, 'grad_norm': 5.550989151000977, 'learning_rate': 9.364406779661017e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [4:49:50<1:02:30,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [4:49:54<1:02:05,  3.37s/it]                                                       {'loss': 0.0417, 'grad_norm': 3.1825599670410156, 'learning_rate': 9.355932203389831e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [4:49:54<1:02:05,  3.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [4:49:57<1:02:09,  3.38s/it]                                                       {'loss': 0.1116, 'grad_norm': 4.513582229614258, 'learning_rate': 9.347457627118644e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [4:49:57<1:02:09,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [4:50:00<1:02:39,  3.41s/it]                                                       {'loss': 0.1658, 'grad_norm': 4.571586608886719, 'learning_rate': 9.338983050847457e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [4:50:00<1:02:39,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [4:50:04<1:03:03,  3.44s/it]                                                       {'loss': 0.0186, 'grad_norm': 1.8805067539215088, 'learning_rate': 9.330508474576272e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [4:50:04<1:03:03,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [4:50:08<1:05:11,  3.56s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.9606980085372925, 'learning_rate': 9.322033898305085e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [4:50:08<1:05:11,  3.56s/it][2025-10-20 20:19:54,702] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [4:50:13<1:16:55,  4.20s/it]                                                       {'loss': 0.0365, 'grad_norm': 2.3065834045410156, 'learning_rate': 9.3135593220339e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [4:50:13<1:16:55,  4.20s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [4:50:17<1:12:16,  3.95s/it]                                                       {'loss': 0.0549, 'grad_norm': 3.241248607635498, 'learning_rate': 9.305084745762713e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [4:50:17<1:12:16,  3.95s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [4:50:20<1:09:30,  3.80s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.8362351059913635, 'learning_rate': 9.296610169491526e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [4:50:20<1:09:30,  3.80s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [4:50:24<1:07:01,  3.67s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.4679104685783386, 'learning_rate': 9.28813559322034e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [4:50:24<1:07:01,  3.67s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [4:50:27<1:06:12,  3.63s/it]                                                       {'loss': 0.0095, 'grad_norm': 0.548865020275116, 'learning_rate': 9.279661016949153e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [4:50:27<1:06:12,  3.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [4:50:31<1:05:36,  3.60s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.8773950338363647, 'learning_rate': 9.271186440677966e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [4:50:31<1:05:36,  3.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [4:50:34<1:04:25,  3.54s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3369549512863159, 'learning_rate': 9.26271186440678e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [4:50:34<1:04:25,  3.54s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [4:50:37<1:03:32,  3.49s/it]                                                       {'loss': 0.0396, 'grad_norm': 4.442972183227539, 'learning_rate': 9.254237288135594e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [4:50:37<1:03:32,  3.49s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [4:50:41<1:02:34,  3.44s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.7905799150466919, 'learning_rate': 9.245762711864407e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [4:50:41<1:02:34,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [4:50:44<1:02:34,  3.44s/it]                                                       {'loss': 0.1223, 'grad_norm': 5.117806911468506, 'learning_rate': 9.237288135593222e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [4:50:44<1:02:34,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [4:50:48<1:01:45,  3.40s/it]                                                       {'loss': 0.0517, 'grad_norm': 7.5701189041137695, 'learning_rate': 9.228813559322035e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [4:50:48<1:01:45,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [4:50:51<1:01:25,  3.39s/it]                                                       {'loss': 0.0872, 'grad_norm': 2.9511947631835938, 'learning_rate': 9.220338983050847e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [4:50:51<1:01:25,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [4:50:54<1:01:20,  3.39s/it]                                                       {'loss': 0.0094, 'grad_norm': 2.441236972808838, 'learning_rate': 9.211864406779662e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [4:50:54<1:01:20,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [4:50:58<1:01:12,  3.38s/it]                                                       {'loss': 0.0281, 'grad_norm': 2.7307310104370117, 'learning_rate': 9.203389830508475e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [4:50:58<1:01:12,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [4:51:01<1:01:57,  3.43s/it]                                                       {'loss': 0.0446, 'grad_norm': 5.564704418182373, 'learning_rate': 9.194915254237288e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [4:51:01<1:01:57,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [4:51:05<1:01:53,  3.43s/it]                                                       {'loss': 0.0345, 'grad_norm': 3.796377182006836, 'learning_rate': 9.186440677966101e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [4:51:05<1:01:53,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [4:51:08<1:01:48,  3.42s/it]                                                       {'loss': 0.0143, 'grad_norm': 1.1848210096359253, 'learning_rate': 9.177966101694916e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [4:51:08<1:01:48,  3.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [4:51:12<1:02:39,  3.47s/it]                                                       {'loss': 0.0276, 'grad_norm': 1.0860666036605835, 'learning_rate': 9.169491525423729e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [4:51:12<1:02:39,  3.47s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [4:51:15<1:02:19,  3.46s/it]                                                       {'loss': 0.1075, 'grad_norm': 5.708869457244873, 'learning_rate': 9.161016949152543e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [4:51:15<1:02:19,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [4:51:18<1:02:24,  3.47s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.38698580861091614, 'learning_rate': 9.152542372881356e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [4:51:19<1:02:24,  3.47s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [4:51:22<1:02:12,  3.46s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.037370204925537, 'learning_rate': 9.14406779661017e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [4:51:22<1:02:12,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [4:51:26<1:04:45,  3.60s/it]                                                       {'loss': 0.0128, 'grad_norm': 1.3740017414093018, 'learning_rate': 9.135593220338984e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [4:51:26<1:04:45,  3.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [4:51:29<1:04:00,  3.57s/it]                                                       {'loss': 0.0687, 'grad_norm': 3.5047287940979004, 'learning_rate': 9.127118644067797e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [4:51:29<1:04:00,  3.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [4:51:33<1:02:38,  3.49s/it]                                                       {'loss': 0.0348, 'grad_norm': 1.6454476118087769, 'learning_rate': 9.118644067796612e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [4:51:33<1:02:38,  3.49s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [4:51:36<1:04:11,  3.58s/it]                                                       {'loss': 0.1143, 'grad_norm': 7.402762413024902, 'learning_rate': 9.110169491525423e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [4:51:36<1:04:11,  3.58s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [4:51:40<1:03:03,  3.52s/it]                                                       {'loss': 0.0179, 'grad_norm': 2.6379549503326416, 'learning_rate': 9.101694915254238e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [4:51:40<1:03:03,  3.52s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [4:51:43<1:01:59,  3.47s/it]                                                       {'loss': 0.0241, 'grad_norm': 3.1669270992279053, 'learning_rate': 9.09322033898305e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [4:51:43<1:01:59,  3.47s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [4:51:47<1:01:23,  3.44s/it]                                                       {'loss': 0.1885, 'grad_norm': 12.099370002746582, 'learning_rate': 9.084745762711865e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [4:51:47<1:01:23,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [4:51:50<1:01:55,  3.47s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.6542273759841919, 'learning_rate': 9.076271186440678e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [4:51:50<1:01:55,  3.47s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [4:51:53<1:01:03,  3.42s/it]                                                       {'loss': 0.008, 'grad_norm': 1.3170342445373535, 'learning_rate': 9.067796610169491e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [4:51:53<1:01:03,  3.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [4:51:57<1:02:02,  3.48s/it]                                                       {'loss': 0.0167, 'grad_norm': 3.296445608139038, 'learning_rate': 9.059322033898306e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [4:51:57<1:02:02,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [4:52:00<1:01:29,  3.45s/it]                                                       {'loss': 0.1198, 'grad_norm': 7.744754314422607, 'learning_rate': 9.050847457627119e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [4:52:00<1:01:29,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [4:52:04<1:00:33,  3.41s/it]                                                       {'loss': 0.2581, 'grad_norm': 8.267160415649414, 'learning_rate': 9.042372881355934e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [4:52:04<1:00:33,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [4:52:07<1:00:18,  3.39s/it]                                                       {'loss': 0.018, 'grad_norm': 2.062899351119995, 'learning_rate': 9.033898305084747e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [4:52:07<1:00:18,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [4:52:11<1:00:21,  3.40s/it]                                                       {'loss': 0.0156, 'grad_norm': 2.3236916065216064, 'learning_rate': 9.02542372881356e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [4:52:11<1:00:21,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [4:52:15<1:05:49,  3.71s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.0984859466552734, 'learning_rate': 9.016949152542373e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [4:52:15<1:05:49,  3.71s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [4:52:19<1:09:19,  3.91s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.7866032719612122, 'learning_rate': 9.008474576271187e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [4:52:19<1:09:19,  3.91s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [4:52:23<1:07:18,  3.80s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.994332194328308, 'learning_rate': 9e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [4:52:23<1:07:18,  3.80s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [4:52:26<1:05:13,  3.69s/it]                                                       {'loss': 0.0132, 'grad_norm': 1.80918550491333, 'learning_rate': 8.991525423728813e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [4:52:26<1:05:13,  3.69s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [4:52:30<1:04:19,  3.64s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.0346442461013794, 'learning_rate': 8.983050847457628e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [4:52:30<1:04:19,  3.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [4:52:33<1:02:52,  3.56s/it]                                                       {'loss': 0.0308, 'grad_norm': 3.8269762992858887, 'learning_rate': 8.974576271186441e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [4:52:33<1:02:52,  3.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [4:52:37<1:02:22,  3.54s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5013282299041748, 'learning_rate': 8.966101694915256e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [4:52:37<1:02:22,  3.54s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [4:52:40<1:02:07,  3.53s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.28246983885765076, 'learning_rate': 8.957627118644069e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [4:52:40<1:02:07,  3.53s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [4:52:44<1:01:36,  3.50s/it]                                                       {'loss': 0.0422, 'grad_norm': 4.586119174957275, 'learning_rate': 8.949152542372881e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [4:52:44<1:01:36,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [4:52:47<1:02:33,  3.56s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.24994106590747833, 'learning_rate': 8.940677966101696e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [4:52:47<1:02:33,  3.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [4:52:51<1:02:29,  3.56s/it]                                                       {'loss': 0.1115, 'grad_norm': 6.485231876373291, 'learning_rate': 8.932203389830507e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [4:52:51<1:02:29,  3.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [4:52:54<1:01:44,  3.52s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.86557537317276, 'learning_rate': 8.923728813559322e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [4:52:54<1:01:44,  3.52s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [4:52:59<1:06:32,  3.79s/it]                                                       {'loss': 0.1752, 'grad_norm': 8.585552215576172, 'learning_rate': 8.915254237288135e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [4:52:59<1:06:32,  3.79s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [4:53:02<1:04:04,  3.66s/it]                                                       {'loss': 0.0252, 'grad_norm': 3.9541728496551514, 'learning_rate': 8.90677966101695e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [4:53:02<1:04:04,  3.66s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [4:53:05<1:02:25,  3.57s/it]                                                       {'loss': 0.2345, 'grad_norm': 7.1708455085754395, 'learning_rate': 8.898305084745763e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [4:53:05<1:02:25,  3.57s/it][2025-10-20 20:22:52,427] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [4:53:12<1:16:37,  4.38s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.13314977288246155, 'learning_rate': 8.889830508474577e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [4:53:12<1:16:37,  4.38s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [4:53:16<1:13:52,  4.23s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.2722454071044922, 'learning_rate': 8.88135593220339e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [4:53:16<1:13:52,  4.23s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [4:53:19<1:09:04,  3.96s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0009072102257050574, 'learning_rate': 8.872881355932203e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [4:53:19<1:09:04,  3.96s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [4:53:23<1:08:22,  3.92s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03372233733534813, 'learning_rate': 8.864406779661018e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [4:53:23<1:08:22,  3.92s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [4:53:26<1:06:03,  3.79s/it]                                                       {'loss': 0.0513, 'grad_norm': 6.211050033569336, 'learning_rate': 8.855932203389831e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [4:53:26<1:06:03,  3.79s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [4:53:30<1:04:02,  3.68s/it]                                                       {'loss': 0.0106, 'grad_norm': 2.154221773147583, 'learning_rate': 8.847457627118646e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [4:53:30<1:04:02,  3.68s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [4:53:33<1:04:10,  3.69s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04443174973130226, 'learning_rate': 8.838983050847457e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [4:53:33<1:04:10,  3.69s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [4:53:37<1:02:56,  3.62s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11387351900339127, 'learning_rate': 8.830508474576272e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [4:53:37<1:02:56,  3.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [4:53:41<1:03:12,  3.64s/it]                                                       {'loss': 0.0224, 'grad_norm': 3.1447319984436035, 'learning_rate': 8.822033898305085e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [4:53:41<1:03:12,  3.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [4:53:44<1:02:18,  3.59s/it]                                                       {'loss': 0.0236, 'grad_norm': 3.5072007179260254, 'learning_rate': 8.8135593220339e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [4:53:44<1:02:18,  3.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [4:53:48<1:03:03,  3.64s/it]                                                       {'loss': 0.1287, 'grad_norm': 7.362041473388672, 'learning_rate': 8.805084745762712e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [4:53:48<1:03:03,  3.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [4:53:52<1:04:51,  3.75s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.7203511595726013, 'learning_rate': 8.796610169491525e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [4:53:52<1:04:51,  3.75s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [4:53:55<1:02:26,  3.61s/it]                                                       {'loss': 0.148, 'grad_norm': 6.601109027862549, 'learning_rate': 8.78813559322034e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [4:53:55<1:02:26,  3.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [4:53:58<1:00:48,  3.52s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2918878197669983, 'learning_rate': 8.779661016949153e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [4:53:58<1:00:48,  3.52s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [4:54:02<1:00:26,  3.50s/it]                                                       {'loss': 0.0903, 'grad_norm': 9.362544059753418, 'learning_rate': 8.771186440677968e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [4:54:02<1:00:26,  3.50s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [4:54:05<1:00:06,  3.49s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.1067250967025757, 'learning_rate': 8.76271186440678e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [4:54:05<1:00:06,  3.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [4:54:09<1:00:13,  3.50s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.5285700559616089, 'learning_rate': 8.754237288135594e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [4:54:09<1:00:13,  3.50s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [4:54:12<59:24,  3.45s/it]                                                       {'loss': 0.0433, 'grad_norm': 3.755117177963257, 'learning_rate': 8.745762711864407e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [4:54:12<59:24,  3.45s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [4:54:15<58:45,  3.42s/it]                                                     {'loss': 0.0929, 'grad_norm': 6.637301445007324, 'learning_rate': 8.737288135593221e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [4:54:15<58:45,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [4:54:19<58:33,  3.41s/it]                                                     {'loss': 0.0755, 'grad_norm': 7.82726526260376, 'learning_rate': 8.728813559322034e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [4:54:19<58:33,  3.41s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [4:54:22<58:06,  3.39s/it]                                                     {'loss': 0.0489, 'grad_norm': 3.200469493865967, 'learning_rate': 8.720338983050847e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [4:54:22<58:06,  3.39s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [4:54:26<57:44,  3.37s/it]                                                     {'loss': 0.0862, 'grad_norm': 8.318806648254395, 'learning_rate': 8.711864406779662e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [4:54:26<57:44,  3.37s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [4:54:29<58:01,  3.39s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.20596544444561005, 'learning_rate': 8.703389830508475e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [4:54:29<58:01,  3.39s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [4:54:33<59:45,  3.49s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.5535271167755127, 'learning_rate': 8.69491525423729e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [4:54:33<59:45,  3.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [4:54:36<59:30,  3.48s/it]                                                     {'loss': 0.1353, 'grad_norm': 6.352437973022461, 'learning_rate': 8.686440677966103e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [4:54:36<59:30,  3.48s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [4:54:40<58:50,  3.45s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.07187860459089279, 'learning_rate': 8.677966101694915e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [4:54:40<58:50,  3.45s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [4:54:43<58:18,  3.42s/it]                                                     {'loss': 0.0031, 'grad_norm': 0.3917994499206543, 'learning_rate': 8.669491525423728e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [4:54:43<58:18,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [4:54:46<58:08,  3.41s/it]                                                     {'loss': 0.0, 'grad_norm': 0.0018576192669570446, 'learning_rate': 8.661016949152541e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [4:54:46<58:08,  3.41s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [4:54:50<58:33,  3.44s/it]                                                     {'loss': 0.0718, 'grad_norm': 3.962183952331543, 'learning_rate': 8.652542372881356e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [4:54:50<58:33,  3.44s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [4:54:54<1:00:31,  3.56s/it]                                                       {'loss': 0.1143, 'grad_norm': 5.056632041931152, 'learning_rate': 8.644067796610169e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [4:54:54<1:00:31,  3.56s/it]Traceback (most recent call last):
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
    main()
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 104, in main
    trainer.train(resume_from_checkpoint=resume_checkpoint_dir)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 510, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 708, in training_step
    loss = self.gc(queries, targets, no_sync_except_last=_distributed)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 71, in __call__
    return self.cache_step(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 294, in cache_step
    self.forward_backward(model, x, model_cache, rnd_states, no_sync_except_last=no_sync_except_last)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 239, in forward_backward
    y = self.model_call(model, x)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 141, in model_call
    return model(**model_input)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 335, in forward
    tgt_reps = self.encode_input(tgt, self.tgt_chosen_layer) if tgt else None # (bsz_per_device, dim)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 110, in encode_input
    hidden_states = self.encoder(**input, return_dict=True, output_hidden_states=True)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/peft/peft_model.py", line 881, in forward
    return self.get_base_model()(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/vlm_backbone/qwen2_vl/modeling_qwen2_vl.py", line 1777, in forward
    logits = self.lm_head(hidden_states)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.56 GiB of which 781.00 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 20.06 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
[rank0]:     main()
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 104, in main
[rank0]:     trainer.train(resume_from_checkpoint=resume_checkpoint_dir)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 510, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 708, in training_step
[rank0]:     loss = self.gc(queries, targets, no_sync_except_last=_distributed)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 71, in __call__
[rank0]:     return self.cache_step(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 294, in cache_step
[rank0]:     self.forward_backward(model, x, model_cache, rnd_states, no_sync_except_last=no_sync_except_last)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 239, in forward_backward
[rank0]:     y = self.model_call(model, x)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 141, in model_call
[rank0]:     return model(**model_input)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 335, in forward
[rank0]:     tgt_reps = self.encode_input(tgt, self.tgt_chosen_layer) if tgt else None # (bsz_per_device, dim)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 110, in encode_input
[rank0]:     hidden_states = self.encoder(**input, return_dict=True, output_hidden_states=True)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/peft/peft_model.py", line 881, in forward
[rank0]:     return self.get_base_model()(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/vlm_backbone/qwen2_vl/modeling_qwen2_vl.py", line 1777, in forward
[rank0]:     logits = self.lm_head(hidden_states)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.56 GiB of which 781.00 MiB is free. Including non-PyTorch memory, this process has 22.79 GiB memory in use. Of the allocated memory 20.06 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mTailTokenPF-Qwen/Qwen2-VL-2B-Instruct[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/public/exps/train/TailTokenPF-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251020_152926-1mbu38js/logs[0m
W1020 20:24:48.562000 131350605657920 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 262194 closing signal SIGTERM
E1020 20:24:49.077000 131350605657920 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 262193) of binary: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python3.10
Traceback (most recent call last):
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-20_20:24:48
  host      : node40.enst.fr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 262193)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Job finished at: lun. 20 oct. 2025 20:24:49 CEST
