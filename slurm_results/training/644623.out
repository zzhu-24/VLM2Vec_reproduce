==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/train.log
W1021 01:23:52.988000 135673244415808 torch/distributed/run.py:779] 
W1021 01:23:52.988000 135673244415808 torch/distributed/run.py:779] *****************************************
W1021 01:23:52.988000 135673244415808 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1021 01:23:52.988000 135673244415808 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-21 01:24:02,836] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.00it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.71it/s]
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251021_012403-eqkax5ns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/eqkax5ns
[2025-10-21 01:24:04,348] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.19it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.03it/s]
[2025-10-21 01:24:04,967] INFO [src.utils:19] Enabling TailTokenWrapper (learnable tail token).
[2025-10-21 01:24:04,972] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x TailIsolatedBlock(
        (block): Qwen2VLDecoderLayer(
          (self_attn): Qwen2VLFlashAttention2(
            (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
            (k_proj): Linear(in_features=1536, out_features=256, bias=True)
            (v_proj): Linear(in_features=1536, out_features=256, bias=True)
            (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
            (rotary_emb): Qwen2VLRotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
            (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
            (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
          (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        )
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-10-21 01:24:13,945] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-21 01:24:15,143] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-21 01:24:15,144] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-21 01:24:19,330] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-21 01:24:19,331] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-21 01:24:20,153] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-21 01:24:20,154] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-21 01:24:20,154] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-21 01:24:20,156] INFO [src.utils:19] ==================================================
[2025-10-21 01:24:20,157] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-21 01:24:20,158] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-21 01:24:20,159] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-21 01:24:20,159] INFO [src.utils:19] ==================================================
[2025-10-21 01:24:22,056] INFO [src.trainer:342] ***** Running training *****
[2025-10-21 01:24:22,056] INFO [src.trainer:342] ***** Running training *****
[2025-10-21 01:24:22,056] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-21 01:24:22,057] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-21 01:24:22,057] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-21 01:24:22,057] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-21 01:24:22,057] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-21 01:24:22,057] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-21 01:24:22,057] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-21 01:24:22,057] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-21 01:24:22,058] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-21 01:24:22,058] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-21 01:24:22,059] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-21 01:24:22,059] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-21 01:24:22,068] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-21 01:24:22,071] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W1021 01:24:25.708213334 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1021 01:24:25.748767284 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/6000 [00:04<8:01:54,  4.82s/it]                                                  {'loss': 20.6106, 'grad_norm': 872.3709716796875, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<8:01:54,  4.82s/it]  0%|          | 2/6000 [00:08<6:32:35,  3.93s/it]                                                  {'loss': 17.9095, 'grad_norm': 1095.5198974609375, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:08<6:32:35,  3.93s/it]  0%|          | 3/6000 [00:11<6:09:17,  3.69s/it]                                                  {'loss': 15.7898, 'grad_norm': 1047.822509765625, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:11<6:09:17,  3.69s/it]  0%|          | 4/6000 [00:15<6:01:01,  3.61s/it]                                                  {'loss': 16.5714, 'grad_norm': 2110.636962890625, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:15<6:01:01,  3.61s/it]  0%|          | 5/6000 [00:18<5:52:49,  3.53s/it]                                                  {'loss': 16.4115, 'grad_norm': 1310.578369140625, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:18<5:52:49,  3.53s/it]  0%|          | 6/6000 [00:21<5:47:27,  3.48s/it]                                                  {'loss': 17.5416, 'grad_norm': 1216.6484375, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:21<5:47:27,  3.48s/it]  0%|          | 7/6000 [00:25<5:43:14,  3.44s/it]                                                  {'loss': 16.2706, 'grad_norm': 1327.23828125, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:25<5:43:14,  3.44s/it]  0%|          | 8/6000 [00:28<5:38:18,  3.39s/it]                                                  {'loss': 16.6604, 'grad_norm': 1381.1148681640625, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:28<5:38:18,  3.39s/it]  0%|          | 9/6000 [00:31<5:39:51,  3.40s/it]                                                  {'loss': 13.0962, 'grad_norm': 1352.6859130859375, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:31<5:39:51,  3.40s/it]  0%|          | 10/6000 [00:35<5:36:59,  3.38s/it]                                                   {'loss': 14.507, 'grad_norm': 1909.83154296875, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:35<5:36:59,  3.38s/it]  0%|          | 11/6000 [00:38<5:46:24,  3.47s/it]                                                   {'loss': 14.9604, 'grad_norm': 1223.052978515625, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:38<5:46:24,  3.47s/it]  0%|          | 12/6000 [00:42<5:49:12,  3.50s/it]                                                   {'loss': 12.6686, 'grad_norm': 1897.3367919921875, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:42<5:49:12,  3.50s/it]  0%|          | 13/6000 [00:45<5:45:32,  3.46s/it]                                                   {'loss': 11.5498, 'grad_norm': 2354.294921875, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:45<5:45:32,  3.46s/it]  0%|          | 14/6000 [00:49<5:47:04,  3.48s/it]                                                   {'loss': 9.6389, 'grad_norm': 3440.90771484375, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:49<5:47:04,  3.48s/it]  0%|          | 15/6000 [00:52<5:44:19,  3.45s/it]                                                   {'loss': 5.558, 'grad_norm': 1066.4088134765625, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:52<5:44:19,  3.45s/it]  0%|          | 16/6000 [00:56<5:40:33,  3.41s/it]                                                   {'loss': 4.9003, 'grad_norm': 1161.2562255859375, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:56<5:40:33,  3.41s/it]  0%|          | 17/6000 [00:59<5:39:54,  3.41s/it]                                                   {'loss': 6.0881, 'grad_norm': 697.5374755859375, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:59<5:39:54,  3.41s/it]  0%|          | 18/6000 [01:02<5:40:13,  3.41s/it]                                                   {'loss': 5.0596, 'grad_norm': 1815.5001220703125, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [01:02<5:40:13,  3.41s/it]  0%|          | 19/6000 [01:06<5:36:19,  3.37s/it]                                                   {'loss': 4.6089, 'grad_norm': 955.8987426757812, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [01:06<5:36:19,  3.37s/it]  0%|          | 20/6000 [01:09<5:37:09,  3.38s/it]                                                   {'loss': 4.708, 'grad_norm': 651.417236328125, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [01:09<5:37:09,  3.38s/it]  0%|          | 21/6000 [01:13<5:40:45,  3.42s/it]                                                   {'loss': 4.4279, 'grad_norm': 485.89361572265625, 'learning_rate': 1.05e-05, 'epoch': 0.0}
  0%|          | 21/6000 [01:13<5:40:45,  3.42s/it]  0%|          | 22/6000 [01:16<5:41:56,  3.43s/it]                                                   {'loss': 4.2354, 'grad_norm': 452.9237365722656, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}
  0%|          | 22/6000 [01:16<5:41:56,  3.43s/it]  0%|          | 23/6000 [01:19<5:40:00,  3.41s/it]                                                   {'loss': 4.0893, 'grad_norm': 345.4326171875, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.0}
  0%|          | 23/6000 [01:19<5:40:00,  3.41s/it]  0%|          | 24/6000 [01:23<5:43:58,  3.45s/it]                                                   {'loss': 4.0774, 'grad_norm': 363.0848693847656, 'learning_rate': 1.2e-05, 'epoch': 0.0}
  0%|          | 24/6000 [01:23<5:43:58,  3.45s/it]  0%|          | 25/6000 [01:26<5:43:01,  3.44s/it]                                                   {'loss': 4.1594, 'grad_norm': 271.8493957519531, 'learning_rate': 1.25e-05, 'epoch': 0.0}
  0%|          | 25/6000 [01:26<5:43:01,  3.44s/it]  0%|          | 26/6000 [01:30<5:42:24,  3.44s/it]                                                   {'loss': 3.5624, 'grad_norm': 218.78469848632812, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}
  0%|          | 26/6000 [01:30<5:42:24,  3.44s/it]  0%|          | 27/6000 [01:33<5:41:33,  3.43s/it]                                                   {'loss': 3.3517, 'grad_norm': 320.0047912597656, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.0}
  0%|          | 27/6000 [01:33<5:41:33,  3.43s/it]  0%|          | 28/6000 [01:38<6:09:28,  3.71s/it]                                                   {'loss': 3.3136, 'grad_norm': 254.33795166015625, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}
  0%|          | 28/6000 [01:38<6:09:28,  3.71s/it]  0%|          | 29/6000 [01:41<5:59:20,  3.61s/it]                                                   {'loss': 3.2239, 'grad_norm': 158.8186798095703, 'learning_rate': 1.45e-05, 'epoch': 0.0}
  0%|          | 29/6000 [01:41<5:59:20,  3.61s/it]  0%|          | 30/6000 [01:44<5:52:55,  3.55s/it]                                                   {'loss': 3.6264, 'grad_norm': 211.05555725097656, 'learning_rate': 1.5e-05, 'epoch': 0.01}
  0%|          | 30/6000 [01:44<5:52:55,  3.55s/it]  1%|          | 31/6000 [01:48<5:47:22,  3.49s/it]                                                   {'loss': 3.0912, 'grad_norm': 130.6297607421875, 'learning_rate': 1.55e-05, 'epoch': 0.01}
  1%|          | 31/6000 [01:48<5:47:22,  3.49s/it]  1%|          | 32/6000 [01:51<5:45:15,  3.47s/it]                                                   {'loss': 3.3364, 'grad_norm': 83.98812866210938, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}
  1%|          | 32/6000 [01:51<5:45:15,  3.47s/it]  1%|          | 33/6000 [01:55<5:45:31,  3.47s/it]                                                   {'loss': 2.9878, 'grad_norm': 133.6818084716797, 'learning_rate': 1.65e-05, 'epoch': 0.01}
  1%|          | 33/6000 [01:55<5:45:31,  3.47s/it]  1%|          | 34/6000 [01:58<5:42:29,  3.44s/it]                                                   {'loss': 3.1736, 'grad_norm': 74.75069427490234, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}
  1%|          | 34/6000 [01:58<5:42:29,  3.44s/it]  1%|          | 35/6000 [02:01<5:42:00,  3.44s/it]                                                   {'loss': 3.1915, 'grad_norm': 115.13343811035156, 'learning_rate': 1.75e-05, 'epoch': 0.01}
  1%|          | 35/6000 [02:01<5:42:00,  3.44s/it]  1%|          | 36/6000 [02:05<5:39:33,  3.42s/it]                                                   {'loss': 2.9656, 'grad_norm': 89.35506439208984, 'learning_rate': 1.8e-05, 'epoch': 0.01}
  1%|          | 36/6000 [02:05<5:39:33,  3.42s/it]  1%|          | 37/6000 [02:08<5:39:44,  3.42s/it]                                                   {'loss': 2.9336, 'grad_norm': 107.55658721923828, 'learning_rate': 1.85e-05, 'epoch': 0.01}
  1%|          | 37/6000 [02:08<5:39:44,  3.42s/it]  1%|          | 38/6000 [02:12<5:37:03,  3.39s/it]                                                   {'loss': 3.0532, 'grad_norm': 49.671966552734375, 'learning_rate': 1.9e-05, 'epoch': 0.01}
  1%|          | 38/6000 [02:12<5:37:03,  3.39s/it]  1%|          | 39/6000 [02:15<5:37:23,  3.40s/it]                                                   {'loss': 2.9857, 'grad_norm': 69.92037963867188, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}
  1%|          | 39/6000 [02:15<5:37:23,  3.40s/it]  1%|          | 40/6000 [02:18<5:37:53,  3.40s/it]                                                   {'loss': 3.231, 'grad_norm': 66.25906372070312, 'learning_rate': 2e-05, 'epoch': 0.01}
  1%|          | 40/6000 [02:18<5:37:53,  3.40s/it]  1%|          | 41/6000 [02:22<5:38:49,  3.41s/it]                                                   {'loss': 2.8526, 'grad_norm': 56.462005615234375, 'learning_rate': 2.05e-05, 'epoch': 0.01}
  1%|          | 41/6000 [02:22<5:38:49,  3.41s/it]  1%|          | 42/6000 [02:25<5:37:22,  3.40s/it]                                                   {'loss': 2.8318, 'grad_norm': 42.203853607177734, 'learning_rate': 2.1e-05, 'epoch': 0.01}
  1%|          | 42/6000 [02:25<5:37:22,  3.40s/it]  1%|          | 43/6000 [02:30<6:08:32,  3.71s/it]                                                   {'loss': 3.1557, 'grad_norm': 324.2672119140625, 'learning_rate': 2.15e-05, 'epoch': 0.01}
  1%|          | 43/6000 [02:30<6:08:32,  3.71s/it]  1%|          | 44/6000 [02:33<6:12:57,  3.76s/it]                                                   {'loss': 2.5638, 'grad_norm': 48.48851776123047, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.01}
  1%|          | 44/6000 [02:33<6:12:57,  3.76s/it]  1%|          | 45/6000 [02:37<6:03:14,  3.66s/it]                                                   {'loss': 2.6468, 'grad_norm': 60.65298843383789, 'learning_rate': 2.25e-05, 'epoch': 0.01}
  1%|          | 45/6000 [02:37<6:03:14,  3.66s/it]  1%|          | 46/6000 [02:40<5:56:44,  3.59s/it]                                                   {'loss': 2.474, 'grad_norm': 112.57621765136719, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01}
  1%|          | 46/6000 [02:40<5:56:44,  3.59s/it]  1%|          | 47/6000 [02:44<5:50:49,  3.54s/it]                                                   {'loss': 2.4519, 'grad_norm': 61.331085205078125, 'learning_rate': 2.35e-05, 'epoch': 0.01}
  1%|          | 47/6000 [02:44<5:50:49,  3.54s/it]  1%|          | 48/6000 [02:47<5:47:29,  3.50s/it]                                                   {'loss': 2.2988, 'grad_norm': 84.69309997558594, 'learning_rate': 2.4e-05, 'epoch': 0.01}
  1%|          | 48/6000 [02:47<5:47:29,  3.50s/it]  1%|          | 49/6000 [02:51<5:43:11,  3.46s/it]                                                   {'loss': 1.9679, 'grad_norm': 58.31829071044922, 'learning_rate': 2.45e-05, 'epoch': 0.01}
  1%|          | 49/6000 [02:51<5:43:11,  3.46s/it]  1%|          | 50/6000 [02:54<5:44:55,  3.48s/it]                                                   {'loss': 1.8018, 'grad_norm': 36.3787956237793, 'learning_rate': 2.5e-05, 'epoch': 0.01}
  1%|          | 50/6000 [02:54<5:44:55,  3.48s/it][2025-10-21 01:27:16,771] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  1%|          | 51/6000 [03:00<6:44:23,  4.08s/it]                                                   {'loss': 1.7776, 'grad_norm': 72.5295639038086, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.01}
  1%|          | 51/6000 [03:00<6:44:23,  4.08s/it]  1%|          | 52/6000 [03:03<6:23:38,  3.87s/it]                                                   {'loss': 1.2355, 'grad_norm': 35.33207321166992, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}
  1%|          | 52/6000 [03:03<6:23:38,  3.87s/it]  1%|          | 53/6000 [03:06<6:10:35,  3.74s/it]                                                   {'loss': 2.2641, 'grad_norm': 51.838382720947266, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.01}
  1%|          | 53/6000 [03:06<6:10:35,  3.74s/it]  1%|          | 54/6000 [03:10<5:58:47,  3.62s/it]                                                   {'loss': 1.5407, 'grad_norm': 23.438661575317383, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}
  1%|          | 54/6000 [03:10<5:58:47,  3.62s/it]  1%|          | 55/6000 [03:13<5:51:57,  3.55s/it]                                                   {'loss': 1.6843, 'grad_norm': 36.28197479248047, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.01}
  1%|          | 55/6000 [03:13<5:51:57,  3.55s/it]  1%|          | 56/6000 [03:16<5:46:07,  3.49s/it]                                                   {'loss': 1.2001, 'grad_norm': 48.85111999511719, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}
  1%|          | 56/6000 [03:16<5:46:07,  3.49s/it]  1%|          | 57/6000 [03:20<5:42:52,  3.46s/it]                                                   {'loss': 1.2912, 'grad_norm': 36.60158920288086, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.01}
  1%|          | 57/6000 [03:20<5:42:52,  3.46s/it]  1%|          | 58/6000 [03:23<5:40:29,  3.44s/it]                                                   {'loss': 0.9877, 'grad_norm': 42.34379959106445, 'learning_rate': 2.9e-05, 'epoch': 0.01}
  1%|          | 58/6000 [03:23<5:40:29,  3.44s/it]  1%|          | 59/6000 [03:26<5:35:50,  3.39s/it]                                                   {'loss': 1.096, 'grad_norm': 33.759212493896484, 'learning_rate': 2.95e-05, 'epoch': 0.01}
  1%|          | 59/6000 [03:26<5:35:50,  3.39s/it]  1%|          | 60/6000 [03:30<5:36:03,  3.39s/it]                                                   {'loss': 0.6562, 'grad_norm': 24.46564483642578, 'learning_rate': 3e-05, 'epoch': 0.01}
  1%|          | 60/6000 [03:30<5:36:03,  3.39s/it]  1%|          | 61/6000 [03:33<5:33:58,  3.37s/it]                                                   {'loss': 0.4953, 'grad_norm': 27.707996368408203, 'learning_rate': 3.05e-05, 'epoch': 0.01}
  1%|          | 61/6000 [03:33<5:33:58,  3.37s/it]  1%|          | 62/6000 [03:37<5:34:48,  3.38s/it]                                                   {'loss': 0.4895, 'grad_norm': 24.20620346069336, 'learning_rate': 3.1e-05, 'epoch': 0.01}
  1%|          | 62/6000 [03:37<5:34:48,  3.38s/it]  1%|          | 63/6000 [03:40<5:34:49,  3.38s/it]                                                   {'loss': 0.2022, 'grad_norm': 10.550751686096191, 'learning_rate': 3.15e-05, 'epoch': 0.01}
  1%|          | 63/6000 [03:40<5:34:49,  3.38s/it]  1%|          | 64/6000 [03:43<5:33:49,  3.37s/it]                                                   {'loss': 0.2426, 'grad_norm': 13.899986267089844, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.01}
  1%|          | 64/6000 [03:43<5:33:49,  3.37s/it]  1%|          | 65/6000 [03:47<5:34:54,  3.39s/it]                                                   {'loss': 0.3102, 'grad_norm': 16.52703285217285, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.01}
  1%|          | 65/6000 [03:47<5:34:54,  3.39s/it]  1%|          | 66/6000 [03:51<5:48:10,  3.52s/it]                                                   {'loss': 0.3037, 'grad_norm': 13.286208152770996, 'learning_rate': 3.3e-05, 'epoch': 0.01}
  1%|          | 66/6000 [03:51<5:48:10,  3.52s/it]  1%|          | 67/6000 [03:54<5:45:36,  3.50s/it]                                                   {'loss': 0.3995, 'grad_norm': 20.74390411376953, 'learning_rate': 3.35e-05, 'epoch': 0.01}
  1%|          | 67/6000 [03:54<5:45:36,  3.50s/it]  1%|          | 68/6000 [03:57<5:41:48,  3.46s/it]                                                   {'loss': 0.961, 'grad_norm': 746.3091430664062, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.01}
  1%|          | 68/6000 [03:57<5:41:48,  3.46s/it]  1%|          | 69/6000 [04:01<5:39:09,  3.43s/it]                                                   {'loss': 0.5179, 'grad_norm': 40.801551818847656, 'learning_rate': 3.45e-05, 'epoch': 0.01}
  1%|          | 69/6000 [04:01<5:39:09,  3.43s/it]  1%|          | 70/6000 [04:05<5:48:25,  3.53s/it]                                                   {'loss': 0.178, 'grad_norm': 11.06032943725586, 'learning_rate': 3.5e-05, 'epoch': 0.01}
  1%|          | 70/6000 [04:05<5:48:25,  3.53s/it]  1%|          | 71/6000 [04:08<5:44:23,  3.49s/it]                                                   {'loss': 0.1215, 'grad_norm': 9.818398475646973, 'learning_rate': 3.55e-05, 'epoch': 0.01}
  1%|          | 71/6000 [04:08<5:44:23,  3.49s/it]  1%|          | 72/6000 [04:12<5:53:04,  3.57s/it]                                                   {'loss': 0.3019, 'grad_norm': 14.880002975463867, 'learning_rate': 3.6e-05, 'epoch': 0.01}
  1%|          | 72/6000 [04:12<5:53:04,  3.57s/it]  1%|          | 73/6000 [04:15<5:48:55,  3.53s/it]                                                   {'loss': 0.3293, 'grad_norm': 19.708232879638672, 'learning_rate': 3.65e-05, 'epoch': 0.01}
  1%|          | 73/6000 [04:15<5:48:55,  3.53s/it]  1%|          | 74/6000 [04:18<5:42:49,  3.47s/it]                                                   {'loss': 0.2717, 'grad_norm': 9.868402481079102, 'learning_rate': 3.7e-05, 'epoch': 0.01}
  1%|          | 74/6000 [04:18<5:42:49,  3.47s/it]  1%|â–         | 75/6000 [04:22<5:39:11,  3.43s/it]                                                   {'loss': 0.3329, 'grad_norm': 20.66899871826172, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.01}
  1%|â–         | 75/6000 [04:22<5:39:11,  3.43s/it]  1%|â–         | 76/6000 [04:25<5:46:55,  3.51s/it]                                                   {'loss': 0.1355, 'grad_norm': 7.60074520111084, 'learning_rate': 3.8e-05, 'epoch': 0.01}
  1%|â–         | 76/6000 [04:25<5:46:55,  3.51s/it]  1%|â–         | 77/6000 [04:29<5:45:02,  3.50s/it]                                                   {'loss': 0.2824, 'grad_norm': 57.301513671875, 'learning_rate': 3.85e-05, 'epoch': 0.01}
  1%|â–         | 77/6000 [04:29<5:45:02,  3.50s/it]  1%|â–         | 78/6000 [04:33<5:53:21,  3.58s/it]                                                   {'loss': 0.0438, 'grad_norm': 5.385558128356934, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 78/6000 [04:33<5:53:21,  3.58s/it]  1%|â–         | 79/6000 [04:36<5:47:22,  3.52s/it]                                                   {'loss': 0.2611, 'grad_norm': 23.212047576904297, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.01}
  1%|â–         | 79/6000 [04:36<5:47:22,  3.52s/it]  1%|â–         | 80/6000 [04:40<5:44:13,  3.49s/it]                                                   {'loss': 0.1955, 'grad_norm': 73.79951477050781, 'learning_rate': 4e-05, 'epoch': 0.01}
  1%|â–         | 80/6000 [04:40<5:44:13,  3.49s/it]  1%|â–         | 81/6000 [04:43<5:40:37,  3.45s/it]                                                   {'loss': 0.0452, 'grad_norm': 2.820802688598633, 'learning_rate': 4.05e-05, 'epoch': 0.01}
  1%|â–         | 81/6000 [04:43<5:40:37,  3.45s/it]  1%|â–         | 82/6000 [04:46<5:41:40,  3.46s/it]                                                   {'loss': 0.2055, 'grad_norm': 10.380772590637207, 'learning_rate': 4.1e-05, 'epoch': 0.01}
  1%|â–         | 82/6000 [04:46<5:41:40,  3.46s/it]  1%|â–         | 83/6000 [04:50<5:41:49,  3.47s/it]                                                   {'loss': 0.3974, 'grad_norm': 15.353171348571777, 'learning_rate': 4.15e-05, 'epoch': 0.01}
  1%|â–         | 83/6000 [04:50<5:41:49,  3.47s/it]  1%|â–         | 84/6000 [04:53<5:42:13,  3.47s/it]                                                   {'loss': 0.1738, 'grad_norm': 13.998580932617188, 'learning_rate': 4.2e-05, 'epoch': 0.01}
  1%|â–         | 84/6000 [04:53<5:42:13,  3.47s/it]  1%|â–         | 85/6000 [04:57<5:51:53,  3.57s/it]                                                   {'loss': 0.1189, 'grad_norm': 8.405045509338379, 'learning_rate': 4.25e-05, 'epoch': 0.01}
  1%|â–         | 85/6000 [04:57<5:51:53,  3.57s/it]  1%|â–         | 86/6000 [05:01<5:46:57,  3.52s/it]                                                   {'loss': 0.2683, 'grad_norm': 12.223896980285645, 'learning_rate': 4.3e-05, 'epoch': 0.01}
  1%|â–         | 86/6000 [05:01<5:46:57,  3.52s/it]  1%|â–         | 87/6000 [05:04<5:40:18,  3.45s/it]                                                   {'loss': 0.0076, 'grad_norm': 0.9714768528938293, 'learning_rate': 4.35e-05, 'epoch': 0.01}
  1%|â–         | 87/6000 [05:04<5:40:18,  3.45s/it]  1%|â–         | 88/6000 [05:07<5:36:14,  3.41s/it]                                                   {'loss': 0.2724, 'grad_norm': 17.035816192626953, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 88/6000 [05:07<5:36:14,  3.41s/it]  1%|â–         | 89/6000 [05:10<5:33:39,  3.39s/it]                                                   {'loss': 0.1087, 'grad_norm': 12.542256355285645, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}
  1%|â–         | 89/6000 [05:10<5:33:39,  3.39s/it]  2%|â–         | 90/6000 [05:14<5:36:58,  3.42s/it]                                                   {'loss': 0.0343, 'grad_norm': 4.192655563354492, 'learning_rate': 4.5e-05, 'epoch': 0.01}
  2%|â–         | 90/6000 [05:14<5:36:58,  3.42s/it]  2%|â–         | 91/6000 [05:17<5:33:56,  3.39s/it]                                                   {'loss': 0.3869, 'grad_norm': 18.48587417602539, 'learning_rate': 4.55e-05, 'epoch': 0.02}
  2%|â–         | 91/6000 [05:17<5:33:56,  3.39s/it]  2%|â–         | 92/6000 [05:21<5:44:48,  3.50s/it]                                                   {'loss': 0.1931, 'grad_norm': 10.671961784362793, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.02}
  2%|â–         | 92/6000 [05:21<5:44:48,  3.50s/it]  2%|â–         | 93/6000 [05:25<5:46:53,  3.52s/it]                                                   {'loss': 0.1034, 'grad_norm': 7.000412940979004, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.02}
  2%|â–         | 93/6000 [05:25<5:46:53,  3.52s/it]  2%|â–         | 94/6000 [05:28<5:42:20,  3.48s/it]                                                   {'loss': 0.0902, 'grad_norm': 7.926488876342773, 'learning_rate': 4.7e-05, 'epoch': 0.02}
  2%|â–         | 94/6000 [05:28<5:42:20,  3.48s/it]  2%|â–         | 95/6000 [05:31<5:39:25,  3.45s/it]                                                   {'loss': 0.0151, 'grad_norm': 3.291347026824951, 'learning_rate': 4.75e-05, 'epoch': 0.02}
  2%|â–         | 95/6000 [05:31<5:39:25,  3.45s/it]  2%|â–         | 96/6000 [05:35<5:38:10,  3.44s/it]                                                   {'loss': 0.2023, 'grad_norm': 9.007400512695312, 'learning_rate': 4.8e-05, 'epoch': 0.02}
  2%|â–         | 96/6000 [05:35<5:38:10,  3.44s/it]  2%|â–         | 97/6000 [05:38<5:36:38,  3.42s/it]                                                   {'loss': 0.3841, 'grad_norm': 12.021346092224121, 'learning_rate': 4.85e-05, 'epoch': 0.02}
  2%|â–         | 97/6000 [05:38<5:36:38,  3.42s/it]  2%|â–         | 98/6000 [05:42<5:36:25,  3.42s/it]                                                   {'loss': 0.2563, 'grad_norm': 12.991199493408203, 'learning_rate': 4.9e-05, 'epoch': 0.02}
  2%|â–         | 98/6000 [05:42<5:36:25,  3.42s/it]  2%|â–         | 99/6000 [05:45<5:34:44,  3.40s/it]                                                   {'loss': 0.162, 'grad_norm': 12.73320484161377, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}
  2%|â–         | 99/6000 [05:45<5:34:44,  3.40s/it]  2%|â–         | 100/6000 [05:48<5:31:53,  3.38s/it]                                                    {'loss': 0.5044, 'grad_norm': 12.58362865447998, 'learning_rate': 5e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [05:48<5:31:53,  3.38s/it][2025-10-21 01:30:11,021] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  2%|â–         | 101/6000 [05:55<7:05:27,  4.33s/it]                                                    {'loss': 0.4835, 'grad_norm': 164.05416870117188, 'learning_rate': 4.9991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 101/6000 [05:55<7:05:27,  4.33s/it]  2%|â–         | 102/6000 [05:58<6:37:15,  4.04s/it]                                                    {'loss': 0.0108, 'grad_norm': 1.0769681930541992, 'learning_rate': 4.998305084745763e-05, 'epoch': 0.02}
  2%|â–         | 102/6000 [05:58<6:37:15,  4.04s/it]  2%|â–         | 103/6000 [06:02<6:19:43,  3.86s/it]                                                    {'loss': 0.0474, 'grad_norm': 2.08835768699646, 'learning_rate': 4.997457627118644e-05, 'epoch': 0.02}
  2%|â–         | 103/6000 [06:02<6:19:43,  3.86s/it]  2%|â–         | 104/6000 [06:05<6:12:55,  3.80s/it]                                                    {'loss': 0.0774, 'grad_norm': 6.923866271972656, 'learning_rate': 4.9966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 104/6000 [06:05<6:12:55,  3.80s/it]  2%|â–         | 105/6000 [06:09<6:03:33,  3.70s/it]                                                    {'loss': 0.2295, 'grad_norm': 9.633031845092773, 'learning_rate': 4.9957627118644066e-05, 'epoch': 0.02}
  2%|â–         | 105/6000 [06:09<6:03:33,  3.70s/it]  2%|â–         | 106/6000 [06:12<6:00:37,  3.67s/it]                                                    {'loss': 0.0169, 'grad_norm': 8.755483627319336, 'learning_rate': 4.9949152542372884e-05, 'epoch': 0.02}
  2%|â–         | 106/6000 [06:12<6:00:37,  3.67s/it]  2%|â–         | 107/6000 [06:16<5:52:43,  3.59s/it]                                                    {'loss': 0.199, 'grad_norm': 58.44057083129883, 'learning_rate': 4.9940677966101695e-05, 'epoch': 0.02}
  2%|â–         | 107/6000 [06:16<5:52:43,  3.59s/it]  2%|â–         | 108/6000 [06:19<5:51:04,  3.58s/it]                                                    {'loss': 0.0595, 'grad_norm': 6.33941650390625, 'learning_rate': 4.993220338983051e-05, 'epoch': 0.02}
  2%|â–         | 108/6000 [06:19<5:51:04,  3.58s/it]  2%|â–         | 109/6000 [06:23<5:57:53,  3.65s/it]                                                    {'loss': 0.1025, 'grad_norm': 6.702392101287842, 'learning_rate': 4.9923728813559324e-05, 'epoch': 0.02}
  2%|â–         | 109/6000 [06:23<5:57:53,  3.65s/it]  2%|â–         | 110/6000 [06:27<5:52:36,  3.59s/it]                                                    {'loss': 0.0865, 'grad_norm': 3.928361177444458, 'learning_rate': 4.991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 110/6000 [06:27<5:52:36,  3.59s/it]  2%|â–         | 111/6000 [06:30<5:50:50,  3.57s/it]                                                    {'loss': 0.2151, 'grad_norm': 11.374777793884277, 'learning_rate': 4.990677966101695e-05, 'epoch': 0.02}
  2%|â–         | 111/6000 [06:30<5:50:50,  3.57s/it]  2%|â–         | 112/6000 [06:34<6:02:26,  3.69s/it]                                                    {'loss': 0.168, 'grad_norm': 8.82790756225586, 'learning_rate': 4.9898305084745765e-05, 'epoch': 0.02}
  2%|â–         | 112/6000 [06:34<6:02:26,  3.69s/it]  2%|â–         | 113/6000 [06:38<5:55:46,  3.63s/it]                                                    {'loss': 0.0429, 'grad_norm': 3.9960379600524902, 'learning_rate': 4.9889830508474576e-05, 'epoch': 0.02}
  2%|â–         | 113/6000 [06:38<5:55:46,  3.63s/it]  2%|â–         | 114/6000 [06:41<5:50:28,  3.57s/it]                                                    {'loss': 0.1732, 'grad_norm': 13.118108749389648, 'learning_rate': 4.9881355932203394e-05, 'epoch': 0.02}
  2%|â–         | 114/6000 [06:41<5:50:28,  3.57s/it]  2%|â–         | 115/6000 [06:44<5:45:18,  3.52s/it]                                                    {'loss': 0.0668, 'grad_norm': 5.739691734313965, 'learning_rate': 4.9872881355932206e-05, 'epoch': 0.02}
  2%|â–         | 115/6000 [06:44<5:45:18,  3.52s/it]  2%|â–         | 116/6000 [06:48<5:40:46,  3.47s/it]                                                    {'loss': 0.2056, 'grad_norm': 19.51430892944336, 'learning_rate': 4.9864406779661024e-05, 'epoch': 0.02}
  2%|â–         | 116/6000 [06:48<5:40:46,  3.47s/it]  2%|â–         | 117/6000 [06:51<5:40:22,  3.47s/it]                                                    {'loss': 0.0901, 'grad_norm': 3.6642568111419678, 'learning_rate': 4.9855932203389835e-05, 'epoch': 0.02}
  2%|â–         | 117/6000 [06:51<5:40:22,  3.47s/it]  2%|â–         | 118/6000 [06:55<5:56:36,  3.64s/it]                                                    {'loss': 0.2316, 'grad_norm': 9.050724029541016, 'learning_rate': 4.9847457627118646e-05, 'epoch': 0.02}
  2%|â–         | 118/6000 [06:55<5:56:36,  3.64s/it]  2%|â–         | 119/6000 [06:59<5:48:02,  3.55s/it]                                                    {'loss': 0.1194, 'grad_norm': 8.815711975097656, 'learning_rate': 4.983898305084746e-05, 'epoch': 0.02}
  2%|â–         | 119/6000 [06:59<5:48:02,  3.55s/it]  2%|â–         | 120/6000 [07:02<5:45:19,  3.52s/it]                                                    {'loss': 0.1234, 'grad_norm': 6.266046524047852, 'learning_rate': 4.9830508474576276e-05, 'epoch': 0.02}
  2%|â–         | 120/6000 [07:02<5:45:19,  3.52s/it]  2%|â–         | 121/6000 [07:05<5:42:33,  3.50s/it]                                                    {'loss': 0.0594, 'grad_norm': 7.447242736816406, 'learning_rate': 4.982203389830509e-05, 'epoch': 0.02}
  2%|â–         | 121/6000 [07:05<5:42:33,  3.50s/it]  2%|â–         | 122/6000 [07:09<5:43:22,  3.50s/it]                                                    {'loss': 0.1043, 'grad_norm': 5.439912796020508, 'learning_rate': 4.98135593220339e-05, 'epoch': 0.02}
  2%|â–         | 122/6000 [07:09<5:43:22,  3.50s/it]  2%|â–         | 123/6000 [07:12<5:38:32,  3.46s/it]                                                    {'loss': 0.0118, 'grad_norm': 1.225221872329712, 'learning_rate': 4.9805084745762716e-05, 'epoch': 0.02}
  2%|â–         | 123/6000 [07:12<5:38:32,  3.46s/it]  2%|â–         | 124/6000 [07:16<5:34:57,  3.42s/it]                                                    {'loss': 0.2514, 'grad_norm': 8.08950424194336, 'learning_rate': 4.979661016949153e-05, 'epoch': 0.02}
  2%|â–         | 124/6000 [07:16<5:34:57,  3.42s/it]  2%|â–         | 125/6000 [07:19<5:41:29,  3.49s/it]                                                    {'loss': 0.0685, 'grad_norm': 5.314083576202393, 'learning_rate': 4.978813559322034e-05, 'epoch': 0.02}
  2%|â–         | 125/6000 [07:19<5:41:29,  3.49s/it]  2%|â–         | 126/6000 [07:23<5:40:31,  3.48s/it]                                                    {'loss': 0.143, 'grad_norm': 10.18880558013916, 'learning_rate': 4.977966101694915e-05, 'epoch': 0.02}
  2%|â–         | 126/6000 [07:23<5:40:31,  3.48s/it]  2%|â–         | 127/6000 [07:26<5:44:12,  3.52s/it]                                                    {'loss': 0.259, 'grad_norm': 8.932756423950195, 'learning_rate': 4.977118644067797e-05, 'epoch': 0.02}
  2%|â–         | 127/6000 [07:26<5:44:12,  3.52s/it]  2%|â–         | 128/6000 [07:30<5:39:59,  3.47s/it]                                                    {'loss': 0.0683, 'grad_norm': 6.767570972442627, 'learning_rate': 4.976271186440678e-05, 'epoch': 0.02}
  2%|â–         | 128/6000 [07:30<5:39:59,  3.47s/it]  2%|â–         | 129/6000 [07:33<5:37:59,  3.45s/it]                                                    {'loss': 0.2324, 'grad_norm': 8.42968463897705, 'learning_rate': 4.97542372881356e-05, 'epoch': 0.02}
  2%|â–         | 129/6000 [07:33<5:37:59,  3.45s/it]  2%|â–         | 130/6000 [07:37<5:34:42,  3.42s/it]                                                    {'loss': 0.072, 'grad_norm': 4.859616279602051, 'learning_rate': 4.974576271186441e-05, 'epoch': 0.02}
  2%|â–         | 130/6000 [07:37<5:34:42,  3.42s/it]  2%|â–         | 131/6000 [07:40<5:35:20,  3.43s/it]                                                    {'loss': 0.139, 'grad_norm': 7.570178508758545, 'learning_rate': 4.973728813559323e-05, 'epoch': 0.02}
  2%|â–         | 131/6000 [07:40<5:35:20,  3.43s/it]  2%|â–         | 132/6000 [07:43<5:33:00,  3.41s/it]                                                    {'loss': 0.0531, 'grad_norm': 3.7144246101379395, 'learning_rate': 4.972881355932204e-05, 'epoch': 0.02}
  2%|â–         | 132/6000 [07:43<5:33:00,  3.41s/it]  2%|â–         | 133/6000 [07:47<5:32:40,  3.40s/it]                                                    {'loss': 0.2755, 'grad_norm': 10.856618881225586, 'learning_rate': 4.972033898305085e-05, 'epoch': 0.02}
  2%|â–         | 133/6000 [07:47<5:32:40,  3.40s/it]  2%|â–         | 134/6000 [07:50<5:37:44,  3.45s/it]                                                    {'loss': 0.1683, 'grad_norm': 4.904426574707031, 'learning_rate': 4.971186440677966e-05, 'epoch': 0.02}
  2%|â–         | 134/6000 [07:50<5:37:44,  3.45s/it]  2%|â–         | 135/6000 [07:54<5:36:33,  3.44s/it]                                                    {'loss': 0.2029, 'grad_norm': 6.067047119140625, 'learning_rate': 4.970338983050848e-05, 'epoch': 0.02}
  2%|â–         | 135/6000 [07:54<5:36:33,  3.44s/it]  2%|â–         | 136/6000 [07:57<5:33:54,  3.42s/it]                                                    {'loss': 0.1034, 'grad_norm': 4.812397480010986, 'learning_rate': 4.969491525423729e-05, 'epoch': 0.02}
  2%|â–         | 136/6000 [07:57<5:33:54,  3.42s/it]  2%|â–         | 137/6000 [08:01<5:49:18,  3.57s/it]                                                    {'loss': 0.0714, 'grad_norm': 5.167621612548828, 'learning_rate': 4.968644067796611e-05, 'epoch': 0.02}
  2%|â–         | 137/6000 [08:01<5:49:18,  3.57s/it]  2%|â–         | 138/6000 [08:04<5:42:44,  3.51s/it]                                                    {'loss': 0.1124, 'grad_norm': 8.148942947387695, 'learning_rate': 4.967796610169492e-05, 'epoch': 0.02}
  2%|â–         | 138/6000 [08:04<5:42:44,  3.51s/it]  2%|â–         | 139/6000 [08:08<5:44:29,  3.53s/it]                                                    {'loss': 0.1715, 'grad_norm': 6.639649391174316, 'learning_rate': 4.966949152542373e-05, 'epoch': 0.02}
  2%|â–         | 139/6000 [08:08<5:44:29,  3.53s/it]  2%|â–         | 140/6000 [08:12<5:54:31,  3.63s/it]                                                    {'loss': 0.102, 'grad_norm': 7.333745002746582, 'learning_rate': 4.966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 140/6000 [08:12<5:54:31,  3.63s/it]  2%|â–         | 141/6000 [08:15<5:49:03,  3.57s/it]                                                    {'loss': 0.1975, 'grad_norm': 7.483778476715088, 'learning_rate': 4.965254237288136e-05, 'epoch': 0.02}
  2%|â–         | 141/6000 [08:15<5:49:03,  3.57s/it]  2%|â–         | 142/6000 [08:19<5:43:03,  3.51s/it]                                                    {'loss': 0.112, 'grad_norm': 5.592278003692627, 'learning_rate': 4.964406779661017e-05, 'epoch': 0.02}
  2%|â–         | 142/6000 [08:19<5:43:03,  3.51s/it]  2%|â–         | 143/6000 [08:22<5:38:21,  3.47s/it]                                                    {'loss': 0.0527, 'grad_norm': 4.414031982421875, 'learning_rate': 4.963559322033898e-05, 'epoch': 0.02}
  2%|â–         | 143/6000 [08:22<5:38:21,  3.47s/it]  2%|â–         | 144/6000 [08:25<5:36:42,  3.45s/it]                                                    {'loss': 0.0198, 'grad_norm': 1.4502958059310913, 'learning_rate': 4.96271186440678e-05, 'epoch': 0.02}
  2%|â–         | 144/6000 [08:25<5:36:42,  3.45s/it]  2%|â–         | 145/6000 [08:29<5:38:00,  3.46s/it]                                                    {'loss': 0.0108, 'grad_norm': 1.1801117658615112, 'learning_rate': 4.961864406779661e-05, 'epoch': 0.02}
  2%|â–         | 145/6000 [08:29<5:38:00,  3.46s/it]  2%|â–         | 146/6000 [08:32<5:39:10,  3.48s/it]                                                    {'loss': 0.1219, 'grad_norm': 9.047207832336426, 'learning_rate': 4.961016949152543e-05, 'epoch': 0.02}
  2%|â–         | 146/6000 [08:32<5:39:10,  3.48s/it]  2%|â–         | 147/6000 [08:36<5:34:34,  3.43s/it]                                                    {'loss': 0.3189, 'grad_norm': 10.338327407836914, 'learning_rate': 4.9601694915254234e-05, 'epoch': 0.02}
  2%|â–         | 147/6000 [08:36<5:34:34,  3.43s/it]  2%|â–         | 148/6000 [08:39<5:34:00,  3.42s/it]                                                    {'loss': 0.0711, 'grad_norm': 5.056412696838379, 'learning_rate': 4.959322033898305e-05, 'epoch': 0.02}
  2%|â–         | 148/6000 [08:39<5:34:00,  3.42s/it]  2%|â–         | 149/6000 [08:42<5:30:48,  3.39s/it]                                                    {'loss': 0.0643, 'grad_norm': 6.028191566467285, 'learning_rate': 4.9584745762711864e-05, 'epoch': 0.02}
  2%|â–         | 149/6000 [08:42<5:30:48,  3.39s/it]  2%|â–Ž         | 150/6000 [08:46<5:30:32,  3.39s/it]                                                    {'loss': 0.0151, 'grad_norm': 1.607060194015503, 'learning_rate': 4.957627118644068e-05, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [08:46<5:30:32,  3.39s/it][2025-10-21 01:33:08,576] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 151/6000 [08:51<6:34:55,  4.05s/it]                                                    {'loss': 0.0923, 'grad_norm': 4.05007266998291, 'learning_rate': 4.956779661016949e-05, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [08:51<6:34:55,  4.05s/it]  3%|â–Ž         | 152/6000 [08:55<6:18:47,  3.89s/it]                                                    {'loss': 0.0525, 'grad_norm': 5.316904544830322, 'learning_rate': 4.955932203389831e-05, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [08:55<6:18:47,  3.89s/it]  3%|â–Ž         | 153/6000 [08:58<6:04:14,  3.74s/it]                                                    {'loss': 0.0455, 'grad_norm': 2.553342819213867, 'learning_rate': 4.955084745762712e-05, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [08:58<6:04:14,  3.74s/it]  3%|â–Ž         | 154/6000 [09:02<5:57:39,  3.67s/it]                                                    {'loss': 0.0295, 'grad_norm': 3.8478586673736572, 'learning_rate': 4.9542372881355934e-05, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [09:02<5:57:39,  3.67s/it]  3%|â–Ž         | 155/6000 [09:05<5:50:41,  3.60s/it]                                                    {'loss': 0.0488, 'grad_norm': 1.7355207204818726, 'learning_rate': 4.9533898305084745e-05, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [09:05<5:50:41,  3.60s/it]  3%|â–Ž         | 156/6000 [09:09<5:47:16,  3.57s/it]                                                    {'loss': 0.0259, 'grad_norm': 3.0517618656158447, 'learning_rate': 4.952542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [09:09<5:47:16,  3.57s/it]  3%|â–Ž         | 157/6000 [09:13<5:57:31,  3.67s/it]                                                    {'loss': 0.0691, 'grad_norm': 4.566730976104736, 'learning_rate': 4.9516949152542374e-05, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [09:13<5:57:31,  3.67s/it]  3%|â–Ž         | 158/6000 [09:16<5:47:57,  3.57s/it]                                                    {'loss': 0.0094, 'grad_norm': 1.1843481063842773, 'learning_rate': 4.950847457627119e-05, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [09:16<5:47:57,  3.57s/it]  3%|â–Ž         | 159/6000 [09:19<5:42:13,  3.52s/it]                                                    {'loss': 0.1728, 'grad_norm': 6.347014904022217, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [09:19<5:42:13,  3.52s/it]  3%|â–Ž         | 160/6000 [09:24<6:01:42,  3.72s/it]                                                    {'loss': 0.0998, 'grad_norm': 4.643429756164551, 'learning_rate': 4.9491525423728815e-05, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [09:24<6:01:42,  3.72s/it]  3%|â–Ž         | 161/6000 [09:27<5:56:03,  3.66s/it]                                                    {'loss': 0.1681, 'grad_norm': 8.050593376159668, 'learning_rate': 4.9483050847457626e-05, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [09:27<5:56:03,  3.66s/it]  3%|â–Ž         | 162/6000 [09:30<5:47:12,  3.57s/it]                                                    {'loss': 0.0087, 'grad_norm': 0.7855186462402344, 'learning_rate': 4.9474576271186444e-05, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [09:30<5:47:12,  3.57s/it]  3%|â–Ž         | 163/6000 [09:34<5:53:53,  3.64s/it]                                                    {'loss': 0.1015, 'grad_norm': 7.3752641677856445, 'learning_rate': 4.9466101694915256e-05, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [09:34<5:53:53,  3.64s/it]  3%|â–Ž         | 164/6000 [09:38<5:45:58,  3.56s/it]                                                    {'loss': 0.2571, 'grad_norm': 10.14073371887207, 'learning_rate': 4.945762711864407e-05, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [09:38<5:45:58,  3.56s/it]  3%|â–Ž         | 165/6000 [09:41<5:45:55,  3.56s/it]                                                    {'loss': 0.0188, 'grad_norm': 1.398686408996582, 'learning_rate': 4.9449152542372885e-05, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [09:41<5:45:55,  3.56s/it]  3%|â–Ž         | 166/6000 [09:45<5:39:12,  3.49s/it]                                                    {'loss': 0.0932, 'grad_norm': 3.4979729652404785, 'learning_rate': 4.9440677966101696e-05, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [09:45<5:39:12,  3.49s/it]  3%|â–Ž         | 167/6000 [09:48<5:37:18,  3.47s/it]                                                    {'loss': 0.0362, 'grad_norm': 3.173142194747925, 'learning_rate': 4.9432203389830514e-05, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [09:48<5:37:18,  3.47s/it]  3%|â–Ž         | 168/6000 [09:51<5:35:57,  3.46s/it]                                                    {'loss': 0.1447, 'grad_norm': 5.274627685546875, 'learning_rate': 4.9423728813559326e-05, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [09:51<5:35:57,  3.46s/it]  3%|â–Ž         | 169/6000 [09:55<5:47:15,  3.57s/it]                                                    {'loss': 0.2166, 'grad_norm': 8.50540542602539, 'learning_rate': 4.941525423728814e-05, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [09:55<5:47:15,  3.57s/it]  3%|â–Ž         | 170/6000 [09:59<5:41:15,  3.51s/it]                                                    {'loss': 0.1123, 'grad_norm': 3.7063159942626953, 'learning_rate': 4.940677966101695e-05, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [09:59<5:41:15,  3.51s/it]  3%|â–Ž         | 171/6000 [10:02<5:37:31,  3.47s/it]                                                    {'loss': 0.0781, 'grad_norm': 3.91465425491333, 'learning_rate': 4.9398305084745766e-05, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [10:02<5:37:31,  3.47s/it]  3%|â–Ž         | 172/6000 [10:06<5:39:13,  3.49s/it]                                                    {'loss': 0.2092, 'grad_norm': 7.793280124664307, 'learning_rate': 4.938983050847458e-05, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [10:06<5:39:13,  3.49s/it]  3%|â–Ž         | 173/6000 [10:09<5:39:22,  3.49s/it]                                                    {'loss': 0.0681, 'grad_norm': 5.689415454864502, 'learning_rate': 4.9381355932203396e-05, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [10:09<5:39:22,  3.49s/it]  3%|â–Ž         | 174/6000 [10:13<5:58:32,  3.69s/it]                                                    {'loss': 0.0043, 'grad_norm': 0.2071557492017746, 'learning_rate': 4.937288135593221e-05, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [10:13<5:58:32,  3.69s/it]  3%|â–Ž         | 175/6000 [10:17<5:49:13,  3.60s/it]                                                    {'loss': 0.1828, 'grad_norm': 7.206740379333496, 'learning_rate': 4.936440677966102e-05, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [10:17<5:49:13,  3.60s/it]  3%|â–Ž         | 176/6000 [10:20<5:53:38,  3.64s/it]                                                    {'loss': 0.0482, 'grad_norm': 3.9785311222076416, 'learning_rate': 4.935593220338983e-05, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [10:20<5:53:38,  3.64s/it]  3%|â–Ž         | 177/6000 [10:24<5:44:42,  3.55s/it]                                                    {'loss': 0.022, 'grad_norm': 1.353003740310669, 'learning_rate': 4.934745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [10:24<5:44:42,  3.55s/it]  3%|â–Ž         | 178/6000 [10:27<5:41:05,  3.52s/it]                                                    {'loss': 0.0695, 'grad_norm': 4.659437656402588, 'learning_rate': 4.933898305084746e-05, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [10:27<5:41:05,  3.52s/it]  3%|â–Ž         | 179/6000 [10:30<5:37:07,  3.47s/it]                                                    {'loss': 0.0555, 'grad_norm': 2.750821828842163, 'learning_rate': 4.933050847457628e-05, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [10:30<5:37:07,  3.47s/it]  3%|â–Ž         | 180/6000 [10:34<5:37:03,  3.47s/it]                                                    {'loss': 0.3117, 'grad_norm': 8.232194900512695, 'learning_rate': 4.932203389830509e-05, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [10:34<5:37:03,  3.47s/it]  3%|â–Ž         | 181/6000 [10:37<5:35:23,  3.46s/it]                                                    {'loss': 0.3402, 'grad_norm': 7.957277297973633, 'learning_rate': 4.9313559322033906e-05, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [10:37<5:35:23,  3.46s/it]  3%|â–Ž         | 182/6000 [10:41<5:32:05,  3.42s/it]                                                    {'loss': 0.0358, 'grad_norm': 2.3977246284484863, 'learning_rate': 4.930508474576271e-05, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [10:41<5:32:05,  3.42s/it]  3%|â–Ž         | 183/6000 [10:44<5:31:22,  3.42s/it]                                                    {'loss': 0.111, 'grad_norm': 3.0915491580963135, 'learning_rate': 4.929661016949153e-05, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [10:44<5:31:22,  3.42s/it]  3%|â–Ž         | 184/6000 [10:48<5:32:38,  3.43s/it]                                                    {'loss': 0.1958, 'grad_norm': 6.967250823974609, 'learning_rate': 4.928813559322034e-05, 'epoch': 0.03}
  3%|â–Ž         | 184/6000 [10:48<5:32:38,  3.43s/it]  3%|â–Ž         | 185/6000 [10:51<5:32:14,  3.43s/it]                                                    {'loss': 0.2204, 'grad_norm': 5.536468982696533, 'learning_rate': 4.927966101694915e-05, 'epoch': 0.03}
  3%|â–Ž         | 185/6000 [10:51<5:32:14,  3.43s/it]  3%|â–Ž         | 186/6000 [10:54<5:32:20,  3.43s/it]                                                    {'loss': 0.1186, 'grad_norm': 7.686173915863037, 'learning_rate': 4.927118644067797e-05, 'epoch': 0.03}
  3%|â–Ž         | 186/6000 [10:54<5:32:20,  3.43s/it]  3%|â–Ž         | 187/6000 [10:58<5:31:11,  3.42s/it]                                                    {'loss': 0.0437, 'grad_norm': 3.6133038997650146, 'learning_rate': 4.926271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 187/6000 [10:58<5:31:11,  3.42s/it]  3%|â–Ž         | 188/6000 [11:01<5:29:49,  3.40s/it]                                                    {'loss': 0.0547, 'grad_norm': 3.003807306289673, 'learning_rate': 4.92542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 188/6000 [11:01<5:29:49,  3.40s/it]  3%|â–Ž         | 189/6000 [11:05<5:29:38,  3.40s/it]                                                    {'loss': 0.2023, 'grad_norm': 7.705862998962402, 'learning_rate': 4.924576271186441e-05, 'epoch': 0.03}
  3%|â–Ž         | 189/6000 [11:05<5:29:38,  3.40s/it]  3%|â–Ž         | 190/6000 [11:08<5:27:23,  3.38s/it]                                                    {'loss': 0.0999, 'grad_norm': 10.519733428955078, 'learning_rate': 4.923728813559322e-05, 'epoch': 0.03}
  3%|â–Ž         | 190/6000 [11:08<5:27:23,  3.38s/it]  3%|â–Ž         | 191/6000 [11:11<5:29:02,  3.40s/it]                                                    {'loss': 0.0518, 'grad_norm': 3.4518074989318848, 'learning_rate': 4.922881355932203e-05, 'epoch': 0.03}
  3%|â–Ž         | 191/6000 [11:11<5:29:02,  3.40s/it]  3%|â–Ž         | 192/6000 [11:15<5:48:17,  3.60s/it]                                                    {'loss': 0.1102, 'grad_norm': 11.870038986206055, 'learning_rate': 4.922033898305085e-05, 'epoch': 0.03}
  3%|â–Ž         | 192/6000 [11:15<5:48:17,  3.60s/it]  3%|â–Ž         | 193/6000 [11:19<5:51:52,  3.64s/it]                                                    {'loss': 0.1963, 'grad_norm': 4.866642951965332, 'learning_rate': 4.921186440677966e-05, 'epoch': 0.03}
  3%|â–Ž         | 193/6000 [11:19<5:51:52,  3.64s/it]  3%|â–Ž         | 194/6000 [11:22<5:43:58,  3.55s/it]                                                    {'loss': 0.0996, 'grad_norm': 4.54231595993042, 'learning_rate': 4.920338983050848e-05, 'epoch': 0.03}
  3%|â–Ž         | 194/6000 [11:22<5:43:58,  3.55s/it]  3%|â–Ž         | 195/6000 [11:26<5:40:19,  3.52s/it]                                                    {'loss': 0.0139, 'grad_norm': 1.0889862775802612, 'learning_rate': 4.919491525423729e-05, 'epoch': 0.03}
  3%|â–Ž         | 195/6000 [11:26<5:40:19,  3.52s/it]  3%|â–Ž         | 196/6000 [11:29<5:38:06,  3.50s/it]                                                    {'loss': 0.0219, 'grad_norm': 2.0031826496124268, 'learning_rate': 4.91864406779661e-05, 'epoch': 0.03}
  3%|â–Ž         | 196/6000 [11:29<5:38:06,  3.50s/it]  3%|â–Ž         | 197/6000 [11:33<5:40:37,  3.52s/it]                                                    {'loss': 0.0281, 'grad_norm': 1.5563873052597046, 'learning_rate': 4.9177966101694914e-05, 'epoch': 0.03}
  3%|â–Ž         | 197/6000 [11:33<5:40:37,  3.52s/it]  3%|â–Ž         | 198/6000 [11:36<5:40:46,  3.52s/it]                                                    {'loss': 0.0193, 'grad_norm': 1.399695634841919, 'learning_rate': 4.916949152542373e-05, 'epoch': 0.03}
  3%|â–Ž         | 198/6000 [11:36<5:40:46,  3.52s/it]  3%|â–Ž         | 199/6000 [11:40<5:36:16,  3.48s/it]                                                    {'loss': 0.1062, 'grad_norm': 3.400364398956299, 'learning_rate': 4.916101694915254e-05, 'epoch': 0.03}
  3%|â–Ž         | 199/6000 [11:40<5:36:16,  3.48s/it]  3%|â–Ž         | 200/6000 [11:44<5:46:42,  3.59s/it]                                                    {'loss': 0.1439, 'grad_norm': 6.233985424041748, 'learning_rate': 4.915254237288136e-05, 'epoch': 0.03}
  3%|â–Ž         | 200/6000 [11:44<5:46:42,  3.59s/it][2025-10-21 01:36:06,432] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 201/6000 [11:49<6:48:47,  4.23s/it]                                                    {'loss': 0.235, 'grad_norm': 6.7979302406311035, 'learning_rate': 4.914406779661017e-05, 'epoch': 0.03}
  3%|â–Ž         | 201/6000 [11:49<6:48:47,  4.23s/it]  3%|â–Ž         | 202/6000 [11:53<6:23:22,  3.97s/it]                                                    {'loss': 0.1976, 'grad_norm': 5.493851661682129, 'learning_rate': 4.913559322033899e-05, 'epoch': 0.03}
  3%|â–Ž         | 202/6000 [11:53<6:23:22,  3.97s/it]  3%|â–Ž         | 203/6000 [11:56<6:09:21,  3.82s/it]                                                    {'loss': 0.0773, 'grad_norm': 2.7180469036102295, 'learning_rate': 4.91271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 203/6000 [11:56<6:09:21,  3.82s/it]  3%|â–Ž         | 204/6000 [12:00<5:59:43,  3.72s/it]                                                    {'loss': 0.0623, 'grad_norm': 2.900587797164917, 'learning_rate': 4.9118644067796607e-05, 'epoch': 0.03}
  3%|â–Ž         | 204/6000 [12:00<5:59:43,  3.72s/it]  3%|â–Ž         | 205/6000 [12:03<5:48:08,  3.60s/it]                                                    {'loss': 0.1547, 'grad_norm': 5.383495330810547, 'learning_rate': 4.9110169491525425e-05, 'epoch': 0.03}
  3%|â–Ž         | 205/6000 [12:03<5:48:08,  3.60s/it]  3%|â–Ž         | 206/6000 [12:06<5:41:17,  3.53s/it]                                                    {'loss': 0.0085, 'grad_norm': 1.3192174434661865, 'learning_rate': 4.9101694915254236e-05, 'epoch': 0.03}
  3%|â–Ž         | 206/6000 [12:06<5:41:17,  3.53s/it]  3%|â–Ž         | 207/6000 [12:10<5:38:36,  3.51s/it]                                                    {'loss': 0.0268, 'grad_norm': 1.945902705192566, 'learning_rate': 4.9093220338983054e-05, 'epoch': 0.03}
  3%|â–Ž         | 207/6000 [12:10<5:38:36,  3.51s/it]  3%|â–Ž         | 208/6000 [12:13<5:32:44,  3.45s/it]                                                    {'loss': 0.1941, 'grad_norm': 177.1073455810547, 'learning_rate': 4.9084745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 208/6000 [12:13<5:32:44,  3.45s/it]  3%|â–Ž         | 209/6000 [12:17<5:30:04,  3.42s/it]                                                    {'loss': 0.0244, 'grad_norm': 14.591046333312988, 'learning_rate': 4.907627118644068e-05, 'epoch': 0.03}
  3%|â–Ž         | 209/6000 [12:17<5:30:04,  3.42s/it]  4%|â–Ž         | 210/6000 [12:20<5:40:49,  3.53s/it]                                                    {'loss': 0.0216, 'grad_norm': 1.9267780780792236, 'learning_rate': 4.9067796610169495e-05, 'epoch': 0.04}
  4%|â–Ž         | 210/6000 [12:20<5:40:49,  3.53s/it]  4%|â–Ž         | 211/6000 [12:24<5:42:40,  3.55s/it]                                                    {'loss': 0.0477, 'grad_norm': 2.9921441078186035, 'learning_rate': 4.9059322033898306e-05, 'epoch': 0.04}
  4%|â–Ž         | 211/6000 [12:24<5:42:40,  3.55s/it]  4%|â–Ž         | 212/6000 [12:28<5:49:38,  3.62s/it]                                                    {'loss': 0.1676, 'grad_norm': 4.799740314483643, 'learning_rate': 4.905084745762712e-05, 'epoch': 0.04}
  4%|â–Ž         | 212/6000 [12:28<5:49:38,  3.62s/it]  4%|â–Ž         | 213/6000 [12:31<5:45:14,  3.58s/it]                                                    {'loss': 0.111, 'grad_norm': 5.207877159118652, 'learning_rate': 4.9042372881355935e-05, 'epoch': 0.04}
  4%|â–Ž         | 213/6000 [12:31<5:45:14,  3.58s/it]  4%|â–Ž         | 214/6000 [12:35<5:38:19,  3.51s/it]                                                    {'loss': 0.0605, 'grad_norm': 4.476914882659912, 'learning_rate': 4.9033898305084746e-05, 'epoch': 0.04}
  4%|â–Ž         | 214/6000 [12:35<5:38:19,  3.51s/it]  4%|â–Ž         | 215/6000 [12:38<5:34:59,  3.47s/it]                                                    {'loss': 0.0668, 'grad_norm': 4.15475606918335, 'learning_rate': 4.9025423728813565e-05, 'epoch': 0.04}
  4%|â–Ž         | 215/6000 [12:38<5:34:59,  3.47s/it]  4%|â–Ž         | 216/6000 [12:41<5:34:40,  3.47s/it]                                                    {'loss': 0.0038, 'grad_norm': 0.22492264211177826, 'learning_rate': 4.9016949152542376e-05, 'epoch': 0.04}
  4%|â–Ž         | 216/6000 [12:41<5:34:40,  3.47s/it]  4%|â–Ž         | 217/6000 [12:45<5:37:10,  3.50s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.30916911363601685, 'learning_rate': 4.9008474576271194e-05, 'epoch': 0.04}
  4%|â–Ž         | 217/6000 [12:45<5:37:10,  3.50s/it]  4%|â–Ž         | 218/6000 [12:48<5:34:53,  3.48s/it]                                                    {'loss': 0.0911, 'grad_norm': 2.956049919128418, 'learning_rate': 4.9e-05, 'epoch': 0.04}
  4%|â–Ž         | 218/6000 [12:48<5:34:53,  3.48s/it]  4%|â–Ž         | 219/6000 [12:52<5:30:33,  3.43s/it]                                                    {'loss': 0.1158, 'grad_norm': 4.389596939086914, 'learning_rate': 4.8991525423728816e-05, 'epoch': 0.04}
  4%|â–Ž         | 219/6000 [12:52<5:30:33,  3.43s/it]  4%|â–Ž         | 220/6000 [12:55<5:31:08,  3.44s/it]                                                    {'loss': 0.3907, 'grad_norm': 6.912596225738525, 'learning_rate': 4.898305084745763e-05, 'epoch': 0.04}
  4%|â–Ž         | 220/6000 [12:55<5:31:08,  3.44s/it]  4%|â–Ž         | 221/6000 [12:59<5:29:29,  3.42s/it]                                                    {'loss': 0.0328, 'grad_norm': 1.7881324291229248, 'learning_rate': 4.8974576271186446e-05, 'epoch': 0.04}
  4%|â–Ž         | 221/6000 [12:59<5:29:29,  3.42s/it]  4%|â–Ž         | 222/6000 [13:02<5:32:57,  3.46s/it]                                                    {'loss': 0.099, 'grad_norm': 4.69214391708374, 'learning_rate': 4.896610169491526e-05, 'epoch': 0.04}
  4%|â–Ž         | 222/6000 [13:02<5:32:57,  3.46s/it]  4%|â–Ž         | 223/6000 [13:06<5:32:25,  3.45s/it]                                                    {'loss': 0.0717, 'grad_norm': 4.0090837478637695, 'learning_rate': 4.8957627118644075e-05, 'epoch': 0.04}
  4%|â–Ž         | 223/6000 [13:06<5:32:25,  3.45s/it]  4%|â–Ž         | 224/6000 [13:09<5:29:48,  3.43s/it]                                                    {'loss': 0.0631, 'grad_norm': 3.3309502601623535, 'learning_rate': 4.8949152542372886e-05, 'epoch': 0.04}
  4%|â–Ž         | 224/6000 [13:09<5:29:48,  3.43s/it]  4%|â–         | 225/6000 [13:12<5:30:39,  3.44s/it]                                                    {'loss': 0.179, 'grad_norm': 5.710811614990234, 'learning_rate': 4.89406779661017e-05, 'epoch': 0.04}
  4%|â–         | 225/6000 [13:12<5:30:39,  3.44s/it]  4%|â–         | 226/6000 [13:16<5:45:13,  3.59s/it]                                                    {'loss': 0.0525, 'grad_norm': 2.9902751445770264, 'learning_rate': 4.893220338983051e-05, 'epoch': 0.04}
  4%|â–         | 226/6000 [13:16<5:45:13,  3.59s/it]  4%|â–         | 227/6000 [13:20<5:38:32,  3.52s/it]                                                    {'loss': 0.0891, 'grad_norm': 6.8036603927612305, 'learning_rate': 4.892372881355932e-05, 'epoch': 0.04}
  4%|â–         | 227/6000 [13:20<5:38:32,  3.52s/it]  4%|â–         | 228/6000 [13:23<5:37:37,  3.51s/it]                                                    {'loss': 0.0079, 'grad_norm': 0.36170297861099243, 'learning_rate': 4.891525423728814e-05, 'epoch': 0.04}
  4%|â–         | 228/6000 [13:23<5:37:37,  3.51s/it]  4%|â–         | 229/6000 [13:26<5:32:41,  3.46s/it]                                                    {'loss': 0.0511, 'grad_norm': 2.5559985637664795, 'learning_rate': 4.890677966101695e-05, 'epoch': 0.04}
  4%|â–         | 229/6000 [13:26<5:32:41,  3.46s/it]  4%|â–         | 230/6000 [13:30<5:33:12,  3.46s/it]                                                    {'loss': 0.0281, 'grad_norm': 2.410576820373535, 'learning_rate': 4.889830508474577e-05, 'epoch': 0.04}
  4%|â–         | 230/6000 [13:30<5:33:12,  3.46s/it]  4%|â–         | 231/6000 [13:33<5:29:06,  3.42s/it]                                                    {'loss': 0.0422, 'grad_norm': 2.6434431076049805, 'learning_rate': 4.888983050847458e-05, 'epoch': 0.04}
  4%|â–         | 231/6000 [13:33<5:29:06,  3.42s/it]  4%|â–         | 232/6000 [13:37<5:27:51,  3.41s/it]                                                    {'loss': 0.3359, 'grad_norm': 9.168572425842285, 'learning_rate': 4.888135593220339e-05, 'epoch': 0.04}
  4%|â–         | 232/6000 [13:37<5:27:51,  3.41s/it]  4%|â–         | 233/6000 [13:40<5:39:05,  3.53s/it]                                                    {'loss': 0.0963, 'grad_norm': 5.082717418670654, 'learning_rate': 4.88728813559322e-05, 'epoch': 0.04}
  4%|â–         | 233/6000 [13:40<5:39:05,  3.53s/it]  4%|â–         | 234/6000 [13:44<5:44:52,  3.59s/it]                                                    {'loss': 0.0667, 'grad_norm': 4.1397833824157715, 'learning_rate': 4.886440677966102e-05, 'epoch': 0.04}
  4%|â–         | 234/6000 [13:44<5:44:52,  3.59s/it]  4%|â–         | 235/6000 [13:48<5:37:44,  3.52s/it]                                                    {'loss': 0.2145, 'grad_norm': 7.506964206695557, 'learning_rate': 4.885593220338983e-05, 'epoch': 0.04}
  4%|â–         | 235/6000 [13:48<5:37:44,  3.52s/it]  4%|â–         | 236/6000 [13:51<5:37:26,  3.51s/it]                                                    {'loss': 0.1415, 'grad_norm': 2.9262020587921143, 'learning_rate': 4.884745762711865e-05, 'epoch': 0.04}
  4%|â–         | 236/6000 [13:51<5:37:26,  3.51s/it]  4%|â–         | 237/6000 [13:54<5:35:07,  3.49s/it]                                                    {'loss': 0.2744, 'grad_norm': 5.486428260803223, 'learning_rate': 4.883898305084746e-05, 'epoch': 0.04}
  4%|â–         | 237/6000 [13:54<5:35:07,  3.49s/it]  4%|â–         | 238/6000 [13:58<5:45:13,  3.59s/it]                                                    {'loss': 0.31, 'grad_norm': 6.736509799957275, 'learning_rate': 4.883050847457628e-05, 'epoch': 0.04}
  4%|â–         | 238/6000 [13:58<5:45:13,  3.59s/it]  4%|â–         | 239/6000 [14:02<5:42:54,  3.57s/it]                                                    {'loss': 0.0518, 'grad_norm': 3.45721697807312, 'learning_rate': 4.882203389830508e-05, 'epoch': 0.04}
  4%|â–         | 239/6000 [14:02<5:42:54,  3.57s/it]  4%|â–         | 240/6000 [14:05<5:38:27,  3.53s/it]                                                    {'loss': 0.1021, 'grad_norm': 5.820042133331299, 'learning_rate': 4.88135593220339e-05, 'epoch': 0.04}
  4%|â–         | 240/6000 [14:05<5:38:27,  3.53s/it]  4%|â–         | 241/6000 [14:09<5:39:16,  3.53s/it]                                                    {'loss': 0.1149, 'grad_norm': 4.563860893249512, 'learning_rate': 4.880508474576271e-05, 'epoch': 0.04}
  4%|â–         | 241/6000 [14:09<5:39:16,  3.53s/it]  4%|â–         | 242/6000 [14:12<5:35:28,  3.50s/it]                                                    {'loss': 0.0959, 'grad_norm': 8.502384185791016, 'learning_rate': 4.879661016949153e-05, 'epoch': 0.04}
  4%|â–         | 242/6000 [14:12<5:35:28,  3.50s/it]  4%|â–         | 243/6000 [14:16<5:42:04,  3.57s/it]                                                    {'loss': 0.1621, 'grad_norm': 4.846240997314453, 'learning_rate': 4.878813559322034e-05, 'epoch': 0.04}
  4%|â–         | 243/6000 [14:16<5:42:04,  3.57s/it]  4%|â–         | 244/6000 [14:19<5:40:24,  3.55s/it]                                                    {'loss': 0.042, 'grad_norm': 2.065070390701294, 'learning_rate': 4.877966101694916e-05, 'epoch': 0.04}
  4%|â–         | 244/6000 [14:19<5:40:24,  3.55s/it]  4%|â–         | 245/6000 [14:23<5:38:02,  3.52s/it]                                                    {'loss': 0.0597, 'grad_norm': 3.7230257987976074, 'learning_rate': 4.877118644067797e-05, 'epoch': 0.04}
  4%|â–         | 245/6000 [14:23<5:38:02,  3.52s/it]  4%|â–         | 246/6000 [14:26<5:37:36,  3.52s/it]                                                    {'loss': 0.0482, 'grad_norm': 4.4806413650512695, 'learning_rate': 4.876271186440678e-05, 'epoch': 0.04}
  4%|â–         | 246/6000 [14:26<5:37:36,  3.52s/it]  4%|â–         | 247/6000 [14:30<5:31:51,  3.46s/it]                                                    {'loss': 0.0348, 'grad_norm': 2.1405582427978516, 'learning_rate': 4.8754237288135593e-05, 'epoch': 0.04}
  4%|â–         | 247/6000 [14:30<5:31:51,  3.46s/it]  4%|â–         | 248/6000 [14:33<5:33:14,  3.48s/it]                                                    {'loss': 0.0604, 'grad_norm': 4.228540897369385, 'learning_rate': 4.8745762711864405e-05, 'epoch': 0.04}
  4%|â–         | 248/6000 [14:33<5:33:14,  3.48s/it]  4%|â–         | 249/6000 [14:37<5:27:20,  3.42s/it]                                                    {'loss': 0.0118, 'grad_norm': 1.4051212072372437, 'learning_rate': 4.873728813559322e-05, 'epoch': 0.04}
  4%|â–         | 249/6000 [14:37<5:27:20,  3.42s/it]  4%|â–         | 250/6000 [14:40<5:24:54,  3.39s/it]                                                    {'loss': 0.0379, 'grad_norm': 1.2708545923233032, 'learning_rate': 4.8728813559322034e-05, 'epoch': 0.04}
  4%|â–         | 250/6000 [14:40<5:24:54,  3.39s/it][2025-10-21 01:39:02,626] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  4%|â–         | 251/6000 [14:45<6:23:22,  4.00s/it]                                                    {'loss': 0.0562, 'grad_norm': 3.44684100151062, 'learning_rate': 4.872033898305085e-05, 'epoch': 0.04}
  4%|â–         | 251/6000 [14:45<6:23:22,  4.00s/it]  4%|â–         | 252/6000 [14:49<6:13:08,  3.90s/it]                                                    {'loss': 0.0904, 'grad_norm': 5.642423152923584, 'learning_rate': 4.8711864406779663e-05, 'epoch': 0.04}
  4%|â–         | 252/6000 [14:49<6:13:08,  3.90s/it]  4%|â–         | 253/6000 [14:52<5:59:44,  3.76s/it]                                                    {'loss': 0.0572, 'grad_norm': 3.53159236907959, 'learning_rate': 4.8703389830508475e-05, 'epoch': 0.04}
  4%|â–         | 253/6000 [14:52<5:59:44,  3.76s/it]  4%|â–         | 254/6000 [14:56<5:51:11,  3.67s/it]                                                    {'loss': 0.1375, 'grad_norm': 4.589917182922363, 'learning_rate': 4.8694915254237286e-05, 'epoch': 0.04}
  4%|â–         | 254/6000 [14:56<5:51:11,  3.67s/it]  4%|â–         | 255/6000 [14:59<5:43:50,  3.59s/it]                                                    {'loss': 0.0207, 'grad_norm': 1.9428188800811768, 'learning_rate': 4.8686440677966104e-05, 'epoch': 0.04}
  4%|â–         | 255/6000 [14:59<5:43:50,  3.59s/it]  4%|â–         | 256/6000 [15:03<5:50:23,  3.66s/it]                                                    {'loss': 0.0667, 'grad_norm': 4.577427387237549, 'learning_rate': 4.8677966101694915e-05, 'epoch': 0.04}
  4%|â–         | 256/6000 [15:03<5:50:23,  3.66s/it]  4%|â–         | 257/6000 [15:07<5:43:50,  3.59s/it]                                                    {'loss': 0.0216, 'grad_norm': 2.3595130443573, 'learning_rate': 4.8669491525423733e-05, 'epoch': 0.04}
  4%|â–         | 257/6000 [15:07<5:43:50,  3.59s/it]  4%|â–         | 258/6000 [15:10<5:38:31,  3.54s/it]                                                    {'loss': 0.0381, 'grad_norm': 2.176785707473755, 'learning_rate': 4.8661016949152545e-05, 'epoch': 0.04}
  4%|â–         | 258/6000 [15:10<5:38:31,  3.54s/it]  4%|â–         | 259/6000 [15:13<5:33:32,  3.49s/it]                                                    {'loss': 0.0164, 'grad_norm': 1.1936566829681396, 'learning_rate': 4.865254237288136e-05, 'epoch': 0.04}
  4%|â–         | 259/6000 [15:13<5:33:32,  3.49s/it]  4%|â–         | 260/6000 [15:17<5:30:32,  3.46s/it]                                                    {'loss': 0.0027, 'grad_norm': 0.26033684611320496, 'learning_rate': 4.8644067796610174e-05, 'epoch': 0.04}
  4%|â–         | 260/6000 [15:17<5:30:32,  3.46s/it]  4%|â–         | 261/6000 [15:20<5:32:32,  3.48s/it]                                                    {'loss': 0.0685, 'grad_norm': 2.5711562633514404, 'learning_rate': 4.8635593220338985e-05, 'epoch': 0.04}
  4%|â–         | 261/6000 [15:20<5:32:32,  3.48s/it]  4%|â–         | 262/6000 [15:24<5:30:03,  3.45s/it]                                                    {'loss': 0.0058, 'grad_norm': 1.0869587659835815, 'learning_rate': 4.86271186440678e-05, 'epoch': 0.04}
  4%|â–         | 262/6000 [15:24<5:30:03,  3.45s/it]  4%|â–         | 263/6000 [15:27<5:40:37,  3.56s/it]                                                    {'loss': 0.0398, 'grad_norm': 3.1887753009796143, 'learning_rate': 4.8618644067796615e-05, 'epoch': 0.04}
  4%|â–         | 263/6000 [15:27<5:40:37,  3.56s/it]  4%|â–         | 264/6000 [15:31<5:33:31,  3.49s/it]                                                    {'loss': 0.0885, 'grad_norm': 4.210982799530029, 'learning_rate': 4.8610169491525426e-05, 'epoch': 0.04}
  4%|â–         | 264/6000 [15:31<5:33:31,  3.49s/it]  4%|â–         | 265/6000 [15:34<5:35:17,  3.51s/it]                                                    {'loss': 0.0182, 'grad_norm': 1.7589491605758667, 'learning_rate': 4.8601694915254244e-05, 'epoch': 0.04}
  4%|â–         | 265/6000 [15:34<5:35:17,  3.51s/it]  4%|â–         | 266/6000 [15:38<5:34:58,  3.51s/it]                                                    {'loss': 0.0065, 'grad_norm': 0.34712010622024536, 'learning_rate': 4.8593220338983055e-05, 'epoch': 0.04}
  4%|â–         | 266/6000 [15:38<5:34:58,  3.51s/it]  4%|â–         | 267/6000 [15:41<5:29:00,  3.44s/it]                                                    {'loss': 0.0255, 'grad_norm': 1.3588995933532715, 'learning_rate': 4.858474576271187e-05, 'epoch': 0.04}
  4%|â–         | 267/6000 [15:41<5:29:00,  3.44s/it]  4%|â–         | 268/6000 [15:45<5:28:46,  3.44s/it]                                                    {'loss': 0.0752, 'grad_norm': 3.3581902980804443, 'learning_rate': 4.857627118644068e-05, 'epoch': 0.04}
  4%|â–         | 268/6000 [15:45<5:28:46,  3.44s/it]  4%|â–         | 269/6000 [15:48<5:31:35,  3.47s/it]                                                    {'loss': 0.0155, 'grad_norm': 0.7881268262863159, 'learning_rate': 4.856779661016949e-05, 'epoch': 0.04}
  4%|â–         | 269/6000 [15:48<5:31:35,  3.47s/it]  4%|â–         | 270/6000 [15:51<5:29:53,  3.45s/it]                                                    {'loss': 0.0152, 'grad_norm': 0.9482983946800232, 'learning_rate': 4.855932203389831e-05, 'epoch': 0.04}
  4%|â–         | 270/6000 [15:51<5:29:53,  3.45s/it]  5%|â–         | 271/6000 [15:55<5:29:42,  3.45s/it]                                                    {'loss': 0.0222, 'grad_norm': 1.9777547121047974, 'learning_rate': 4.855084745762712e-05, 'epoch': 0.05}
  5%|â–         | 271/6000 [15:55<5:29:42,  3.45s/it]  5%|â–         | 272/6000 [15:58<5:27:45,  3.43s/it]                                                    {'loss': 0.0981, 'grad_norm': 5.465663909912109, 'learning_rate': 4.8542372881355937e-05, 'epoch': 0.05}
  5%|â–         | 272/6000 [15:58<5:27:45,  3.43s/it]  5%|â–         | 273/6000 [16:02<5:27:57,  3.44s/it]                                                    {'loss': 0.0715, 'grad_norm': 4.0057244300842285, 'learning_rate': 4.853389830508475e-05, 'epoch': 0.05}
  5%|â–         | 273/6000 [16:02<5:27:57,  3.44s/it]  5%|â–         | 274/6000 [16:06<5:38:29,  3.55s/it]                                                    {'loss': 0.0347, 'grad_norm': 1.3317980766296387, 'learning_rate': 4.8525423728813566e-05, 'epoch': 0.05}
  5%|â–         | 274/6000 [16:06<5:38:29,  3.55s/it]  5%|â–         | 275/6000 [16:09<5:35:24,  3.52s/it]                                                    {'loss': 0.1746, 'grad_norm': 7.772393703460693, 'learning_rate': 4.851694915254237e-05, 'epoch': 0.05}
  5%|â–         | 275/6000 [16:09<5:35:24,  3.52s/it]  5%|â–         | 276/6000 [16:12<5:34:47,  3.51s/it]                                                    {'loss': 0.0821, 'grad_norm': 3.537130832672119, 'learning_rate': 4.850847457627119e-05, 'epoch': 0.05}
  5%|â–         | 276/6000 [16:12<5:34:47,  3.51s/it]  5%|â–         | 277/6000 [16:16<5:29:53,  3.46s/it]                                                    {'loss': 0.0907, 'grad_norm': 3.483560562133789, 'learning_rate': 4.85e-05, 'epoch': 0.05}
  5%|â–         | 277/6000 [16:16<5:29:53,  3.46s/it]  5%|â–         | 278/6000 [16:19<5:29:56,  3.46s/it]                                                    {'loss': 0.0129, 'grad_norm': 1.0519980192184448, 'learning_rate': 4.849152542372882e-05, 'epoch': 0.05}
  5%|â–         | 278/6000 [16:19<5:29:56,  3.46s/it]  5%|â–         | 279/6000 [16:23<5:29:12,  3.45s/it]                                                    {'loss': 0.2537, 'grad_norm': 5.000642776489258, 'learning_rate': 4.848305084745763e-05, 'epoch': 0.05}
  5%|â–         | 279/6000 [16:23<5:29:12,  3.45s/it]  5%|â–         | 280/6000 [16:26<5:30:30,  3.47s/it]                                                    {'loss': 0.06, 'grad_norm': 2.8955602645874023, 'learning_rate': 4.847457627118645e-05, 'epoch': 0.05}
  5%|â–         | 280/6000 [16:26<5:30:30,  3.47s/it]  5%|â–         | 281/6000 [16:30<5:30:11,  3.46s/it]                                                    {'loss': 0.3482, 'grad_norm': 6.386208534240723, 'learning_rate': 4.846610169491526e-05, 'epoch': 0.05}
  5%|â–         | 281/6000 [16:30<5:30:11,  3.46s/it]  5%|â–         | 282/6000 [16:34<5:42:54,  3.60s/it]                                                    {'loss': 0.1142, 'grad_norm': 3.950483560562134, 'learning_rate': 4.845762711864407e-05, 'epoch': 0.05}
  5%|â–         | 282/6000 [16:34<5:42:54,  3.60s/it]  5%|â–         | 283/6000 [16:37<5:47:13,  3.64s/it]                                                    {'loss': 0.0065, 'grad_norm': 0.4883742928504944, 'learning_rate': 4.844915254237288e-05, 'epoch': 0.05}
  5%|â–         | 283/6000 [16:37<5:47:13,  3.64s/it]  5%|â–         | 284/6000 [16:41<6:00:16,  3.78s/it]                                                    {'loss': 0.096, 'grad_norm': 4.972742557525635, 'learning_rate': 4.84406779661017e-05, 'epoch': 0.05}
  5%|â–         | 284/6000 [16:41<6:00:16,  3.78s/it]  5%|â–         | 285/6000 [16:45<5:53:20,  3.71s/it]                                                    {'loss': 0.1029, 'grad_norm': 3.855297088623047, 'learning_rate': 4.843220338983051e-05, 'epoch': 0.05}
  5%|â–         | 285/6000 [16:45<5:53:20,  3.71s/it]  5%|â–         | 286/6000 [16:48<5:43:56,  3.61s/it]                                                    {'loss': 0.1789, 'grad_norm': 6.388302326202393, 'learning_rate': 4.842372881355933e-05, 'epoch': 0.05}
  5%|â–         | 286/6000 [16:48<5:43:56,  3.61s/it]  5%|â–         | 287/6000 [16:52<5:39:45,  3.57s/it]                                                    {'loss': 0.0653, 'grad_norm': 4.340030670166016, 'learning_rate': 4.841525423728814e-05, 'epoch': 0.05}
  5%|â–         | 287/6000 [16:52<5:39:45,  3.57s/it]  5%|â–         | 288/6000 [16:55<5:34:08,  3.51s/it]                                                    {'loss': 0.0195, 'grad_norm': 1.8097113370895386, 'learning_rate': 4.840677966101695e-05, 'epoch': 0.05}
  5%|â–         | 288/6000 [16:55<5:34:08,  3.51s/it]  5%|â–         | 289/6000 [16:59<5:36:46,  3.54s/it]                                                    {'loss': 0.1652, 'grad_norm': 6.4298553466796875, 'learning_rate': 4.839830508474576e-05, 'epoch': 0.05}
  5%|â–         | 289/6000 [16:59<5:36:46,  3.54s/it]  5%|â–         | 290/6000 [17:02<5:33:18,  3.50s/it]                                                    {'loss': 0.0352, 'grad_norm': 2.0151069164276123, 'learning_rate': 4.8389830508474574e-05, 'epoch': 0.05}
  5%|â–         | 290/6000 [17:02<5:33:18,  3.50s/it]  5%|â–         | 291/6000 [17:06<5:30:08,  3.47s/it]                                                    {'loss': 0.222, 'grad_norm': 6.95337438583374, 'learning_rate': 4.838135593220339e-05, 'epoch': 0.05}
  5%|â–         | 291/6000 [17:06<5:30:08,  3.47s/it]  5%|â–         | 292/6000 [17:09<5:27:03,  3.44s/it]                                                    {'loss': 0.2368, 'grad_norm': 6.6994476318359375, 'learning_rate': 4.83728813559322e-05, 'epoch': 0.05}
  5%|â–         | 292/6000 [17:09<5:27:03,  3.44s/it]  5%|â–         | 293/6000 [17:12<5:24:55,  3.42s/it]                                                    {'loss': 0.0977, 'grad_norm': 4.294913291931152, 'learning_rate': 4.836440677966102e-05, 'epoch': 0.05}
  5%|â–         | 293/6000 [17:12<5:24:55,  3.42s/it]  5%|â–         | 294/6000 [17:16<5:26:04,  3.43s/it]                                                    {'loss': 0.5061, 'grad_norm': 8.942914962768555, 'learning_rate': 4.835593220338983e-05, 'epoch': 0.05}
  5%|â–         | 294/6000 [17:16<5:26:04,  3.43s/it]  5%|â–         | 295/6000 [17:19<5:26:42,  3.44s/it]                                                    {'loss': 0.0949, 'grad_norm': 3.252516031265259, 'learning_rate': 4.834745762711865e-05, 'epoch': 0.05}
  5%|â–         | 295/6000 [17:19<5:26:42,  3.44s/it]  5%|â–         | 296/6000 [17:23<5:32:46,  3.50s/it]                                                    {'loss': 0.0868, 'grad_norm': 5.126960754394531, 'learning_rate': 4.833898305084746e-05, 'epoch': 0.05}
  5%|â–         | 296/6000 [17:23<5:32:46,  3.50s/it]  5%|â–         | 297/6000 [17:26<5:30:06,  3.47s/it]                                                    {'loss': 0.0471, 'grad_norm': 2.4604432582855225, 'learning_rate': 4.833050847457627e-05, 'epoch': 0.05}
  5%|â–         | 297/6000 [17:26<5:30:06,  3.47s/it]  5%|â–         | 298/6000 [17:30<5:33:53,  3.51s/it]                                                    {'loss': 0.0947, 'grad_norm': 3.4990038871765137, 'learning_rate': 4.8322033898305084e-05, 'epoch': 0.05}
  5%|â–         | 298/6000 [17:30<5:33:53,  3.51s/it]  5%|â–         | 299/6000 [17:34<5:58:38,  3.77s/it]                                                    {'loss': 0.0545, 'grad_norm': 1.3921623229980469, 'learning_rate': 4.83135593220339e-05, 'epoch': 0.05}
  5%|â–         | 299/6000 [17:34<5:58:38,  3.77s/it]  5%|â–Œ         | 300/6000 [17:38<5:52:15,  3.71s/it]                                                    {'loss': 0.016, 'grad_norm': 1.738348126411438, 'learning_rate': 4.8305084745762714e-05, 'epoch': 0.05}
  5%|â–Œ         | 300/6000 [17:38<5:52:15,  3.71s/it][2025-10-21 01:42:00,628] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  5%|â–Œ         | 301/6000 [17:44<6:55:48,  4.38s/it]                                                    {'loss': 0.0683, 'grad_norm': 3.5208656787872314, 'learning_rate': 4.829661016949153e-05, 'epoch': 0.05}
  5%|â–Œ         | 301/6000 [17:44<6:55:48,  4.38s/it]  5%|â–Œ         | 302/6000 [17:47<6:31:49,  4.13s/it]                                                    {'loss': 0.0577, 'grad_norm': 3.6264607906341553, 'learning_rate': 4.828813559322034e-05, 'epoch': 0.05}
  5%|â–Œ         | 302/6000 [17:47<6:31:49,  4.13s/it]  5%|â–Œ         | 303/6000 [17:51<6:12:31,  3.92s/it]                                                    {'loss': 0.0212, 'grad_norm': 1.6195704936981201, 'learning_rate': 4.8279661016949154e-05, 'epoch': 0.05}
  5%|â–Œ         | 303/6000 [17:51<6:12:31,  3.92s/it]  5%|â–Œ         | 304/6000 [17:54<6:00:33,  3.80s/it]                                                    {'loss': 0.0673, 'grad_norm': 3.456136703491211, 'learning_rate': 4.8271186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 304/6000 [17:54<6:00:33,  3.80s/it]  5%|â–Œ         | 305/6000 [17:58<5:48:09,  3.67s/it]                                                    {'loss': 0.199, 'grad_norm': 6.461255073547363, 'learning_rate': 4.8262711864406784e-05, 'epoch': 0.05}
  5%|â–Œ         | 305/6000 [17:58<5:48:09,  3.67s/it]  5%|â–Œ         | 306/6000 [18:01<5:40:42,  3.59s/it]                                                    {'loss': 0.0464, 'grad_norm': 3.578329086303711, 'learning_rate': 4.8254237288135595e-05, 'epoch': 0.05}
  5%|â–Œ         | 306/6000 [18:01<5:40:42,  3.59s/it]  5%|â–Œ         | 307/6000 [18:04<5:34:12,  3.52s/it]                                                    {'loss': 0.0332, 'grad_norm': 1.9167594909667969, 'learning_rate': 4.824576271186441e-05, 'epoch': 0.05}
  5%|â–Œ         | 307/6000 [18:04<5:34:12,  3.52s/it]  5%|â–Œ         | 308/6000 [18:08<5:30:07,  3.48s/it]                                                    {'loss': 0.0601, 'grad_norm': 2.3309948444366455, 'learning_rate': 4.8237288135593224e-05, 'epoch': 0.05}
  5%|â–Œ         | 308/6000 [18:08<5:30:07,  3.48s/it]  5%|â–Œ         | 309/6000 [18:11<5:31:52,  3.50s/it]                                                    {'loss': 0.1953, 'grad_norm': 6.678578853607178, 'learning_rate': 4.8228813559322036e-05, 'epoch': 0.05}
  5%|â–Œ         | 309/6000 [18:11<5:31:52,  3.50s/it]  5%|â–Œ         | 310/6000 [18:15<5:27:32,  3.45s/it]                                                    {'loss': 0.0193, 'grad_norm': 1.1978756189346313, 'learning_rate': 4.822033898305085e-05, 'epoch': 0.05}
  5%|â–Œ         | 310/6000 [18:15<5:27:32,  3.45s/it]  5%|â–Œ         | 311/6000 [18:18<5:25:07,  3.43s/it]                                                    {'loss': 0.1581, 'grad_norm': 4.979165554046631, 'learning_rate': 4.821186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 311/6000 [18:18<5:25:07,  3.43s/it]  5%|â–Œ         | 312/6000 [18:22<5:25:15,  3.43s/it]                                                    {'loss': 0.238, 'grad_norm': 6.113238334655762, 'learning_rate': 4.8203389830508476e-05, 'epoch': 0.05}
  5%|â–Œ         | 312/6000 [18:22<5:25:15,  3.43s/it]  5%|â–Œ         | 313/6000 [18:25<5:27:02,  3.45s/it]                                                    {'loss': 0.0742, 'grad_norm': 3.296907424926758, 'learning_rate': 4.819491525423729e-05, 'epoch': 0.05}
  5%|â–Œ         | 313/6000 [18:25<5:27:02,  3.45s/it]  5%|â–Œ         | 314/6000 [18:28<5:24:06,  3.42s/it]                                                    {'loss': 0.1077, 'grad_norm': 3.804893732070923, 'learning_rate': 4.8186440677966105e-05, 'epoch': 0.05}
  5%|â–Œ         | 314/6000 [18:28<5:24:06,  3.42s/it]  5%|â–Œ         | 315/6000 [18:32<5:22:14,  3.40s/it]                                                    {'loss': 0.0656, 'grad_norm': 1.8414517641067505, 'learning_rate': 4.817796610169492e-05, 'epoch': 0.05}
  5%|â–Œ         | 315/6000 [18:32<5:22:14,  3.40s/it]  5%|â–Œ         | 316/6000 [18:35<5:19:35,  3.37s/it]                                                    {'loss': 0.0112, 'grad_norm': 0.5710228681564331, 'learning_rate': 4.8169491525423735e-05, 'epoch': 0.05}
  5%|â–Œ         | 316/6000 [18:35<5:19:35,  3.37s/it]  5%|â–Œ         | 317/6000 [18:39<5:24:20,  3.42s/it]                                                    {'loss': 0.0384, 'grad_norm': 2.253844738006592, 'learning_rate': 4.8161016949152546e-05, 'epoch': 0.05}
  5%|â–Œ         | 317/6000 [18:39<5:24:20,  3.42s/it]  5%|â–Œ         | 318/6000 [18:42<5:32:35,  3.51s/it]                                                    {'loss': 0.0355, 'grad_norm': 2.2443394660949707, 'learning_rate': 4.815254237288136e-05, 'epoch': 0.05}
  5%|â–Œ         | 318/6000 [18:42<5:32:35,  3.51s/it]  5%|â–Œ         | 319/6000 [18:46<5:28:19,  3.47s/it]                                                    {'loss': 0.3807, 'grad_norm': 7.233731269836426, 'learning_rate': 4.814406779661017e-05, 'epoch': 0.05}
  5%|â–Œ         | 319/6000 [18:46<5:28:19,  3.47s/it]  5%|â–Œ         | 320/6000 [18:49<5:28:38,  3.47s/it]                                                    {'loss': 0.1108, 'grad_norm': 4.956745624542236, 'learning_rate': 4.813559322033899e-05, 'epoch': 0.05}
  5%|â–Œ         | 320/6000 [18:49<5:28:38,  3.47s/it]  5%|â–Œ         | 321/6000 [18:53<5:41:02,  3.60s/it]                                                    {'loss': 0.0097, 'grad_norm': 0.8072184324264526, 'learning_rate': 4.81271186440678e-05, 'epoch': 0.05}
  5%|â–Œ         | 321/6000 [18:53<5:41:02,  3.60s/it]  5%|â–Œ         | 322/6000 [18:57<5:37:58,  3.57s/it]                                                    {'loss': 0.0501, 'grad_norm': 2.436741590499878, 'learning_rate': 4.8118644067796616e-05, 'epoch': 0.05}
  5%|â–Œ         | 322/6000 [18:57<5:37:58,  3.57s/it]  5%|â–Œ         | 323/6000 [19:01<5:52:07,  3.72s/it]                                                    {'loss': 0.0767, 'grad_norm': 4.6605119705200195, 'learning_rate': 4.811016949152543e-05, 'epoch': 0.05}
  5%|â–Œ         | 323/6000 [19:01<5:52:07,  3.72s/it]  5%|â–Œ         | 324/6000 [19:04<5:46:08,  3.66s/it]                                                    {'loss': 0.0522, 'grad_norm': 4.215632438659668, 'learning_rate': 4.810169491525424e-05, 'epoch': 0.05}
  5%|â–Œ         | 324/6000 [19:04<5:46:08,  3.66s/it]  5%|â–Œ         | 325/6000 [19:08<5:40:21,  3.60s/it]                                                    {'loss': 0.0468, 'grad_norm': 2.1225037574768066, 'learning_rate': 4.809322033898305e-05, 'epoch': 0.05}
  5%|â–Œ         | 325/6000 [19:08<5:40:21,  3.60s/it]  5%|â–Œ         | 326/6000 [19:11<5:34:49,  3.54s/it]                                                    {'loss': 0.0757, 'grad_norm': 3.1582818031311035, 'learning_rate': 4.808474576271187e-05, 'epoch': 0.05}
  5%|â–Œ         | 326/6000 [19:11<5:34:49,  3.54s/it]  5%|â–Œ         | 327/6000 [19:14<5:28:58,  3.48s/it]                                                    {'loss': 0.0516, 'grad_norm': 2.449950933456421, 'learning_rate': 4.807627118644068e-05, 'epoch': 0.05}
  5%|â–Œ         | 327/6000 [19:14<5:28:58,  3.48s/it]  5%|â–Œ         | 328/6000 [19:18<5:31:17,  3.50s/it]                                                    {'loss': 0.0224, 'grad_norm': 1.951785922050476, 'learning_rate': 4.80677966101695e-05, 'epoch': 0.05}
  5%|â–Œ         | 328/6000 [19:18<5:31:17,  3.50s/it]  5%|â–Œ         | 329/6000 [19:21<5:27:35,  3.47s/it]                                                    {'loss': 0.0635, 'grad_norm': 3.553483247756958, 'learning_rate': 4.805932203389831e-05, 'epoch': 0.05}
  5%|â–Œ         | 329/6000 [19:21<5:27:35,  3.47s/it]  6%|â–Œ         | 330/6000 [19:25<5:25:26,  3.44s/it]                                                    {'loss': 0.0613, 'grad_norm': 3.00763201713562, 'learning_rate': 4.805084745762712e-05, 'epoch': 0.06}
  6%|â–Œ         | 330/6000 [19:25<5:25:26,  3.44s/it]  6%|â–Œ         | 331/6000 [19:28<5:24:11,  3.43s/it]                                                    {'loss': 0.2009, 'grad_norm': 6.135210990905762, 'learning_rate': 4.804237288135594e-05, 'epoch': 0.06}
  6%|â–Œ         | 331/6000 [19:28<5:24:11,  3.43s/it]  6%|â–Œ         | 332/6000 [19:31<5:20:40,  3.39s/it]                                                    {'loss': 0.0569, 'grad_norm': 2.1230692863464355, 'learning_rate': 4.803389830508474e-05, 'epoch': 0.06}
  6%|â–Œ         | 332/6000 [19:31<5:20:40,  3.39s/it]  6%|â–Œ         | 333/6000 [19:35<5:20:19,  3.39s/it]                                                    {'loss': 0.0053, 'grad_norm': 0.345706969499588, 'learning_rate': 4.802542372881356e-05, 'epoch': 0.06}
  6%|â–Œ         | 333/6000 [19:35<5:20:19,  3.39s/it]  6%|â–Œ         | 334/6000 [19:38<5:20:46,  3.40s/it]                                                    {'loss': 0.0295, 'grad_norm': 0.5565246939659119, 'learning_rate': 4.801694915254237e-05, 'epoch': 0.06}
  6%|â–Œ         | 334/6000 [19:38<5:20:46,  3.40s/it]  6%|â–Œ         | 335/6000 [19:42<5:23:29,  3.43s/it]                                                    {'loss': 0.0196, 'grad_norm': 0.8253167271614075, 'learning_rate': 4.800847457627119e-05, 'epoch': 0.06}
  6%|â–Œ         | 335/6000 [19:42<5:23:29,  3.43s/it]  6%|â–Œ         | 336/6000 [19:45<5:19:44,  3.39s/it]                                                    {'loss': 0.0576, 'grad_norm': 2.383298873901367, 'learning_rate': 4.8e-05, 'epoch': 0.06}
  6%|â–Œ         | 336/6000 [19:45<5:19:44,  3.39s/it]  6%|â–Œ         | 337/6000 [19:48<5:22:40,  3.42s/it]                                                    {'loss': 0.0414, 'grad_norm': 2.1211986541748047, 'learning_rate': 4.799152542372882e-05, 'epoch': 0.06}
  6%|â–Œ         | 337/6000 [19:48<5:22:40,  3.42s/it]  6%|â–Œ         | 338/6000 [19:52<5:19:42,  3.39s/it]                                                    {'loss': 0.1418, 'grad_norm': 4.9135026931762695, 'learning_rate': 4.798305084745763e-05, 'epoch': 0.06}
  6%|â–Œ         | 338/6000 [19:52<5:19:42,  3.39s/it]  6%|â–Œ         | 339/6000 [19:55<5:19:12,  3.38s/it]                                                    {'loss': 0.0149, 'grad_norm': 1.246448040008545, 'learning_rate': 4.797457627118644e-05, 'epoch': 0.06}
  6%|â–Œ         | 339/6000 [19:55<5:19:12,  3.38s/it]  6%|â–Œ         | 340/6000 [19:59<5:26:57,  3.47s/it]                                                    {'loss': 0.1547, 'grad_norm': 6.193991661071777, 'learning_rate': 4.796610169491525e-05, 'epoch': 0.06}
  6%|â–Œ         | 340/6000 [19:59<5:26:57,  3.47s/it]  6%|â–Œ         | 341/6000 [20:02<5:22:48,  3.42s/it]                                                    {'loss': 0.025, 'grad_norm': 1.5419363975524902, 'learning_rate': 4.795762711864407e-05, 'epoch': 0.06}
  6%|â–Œ         | 341/6000 [20:02<5:22:48,  3.42s/it]  6%|â–Œ         | 342/6000 [20:05<5:20:45,  3.40s/it]                                                    {'loss': 0.1677, 'grad_norm': 4.894885063171387, 'learning_rate': 4.794915254237288e-05, 'epoch': 0.06}
  6%|â–Œ         | 342/6000 [20:05<5:20:45,  3.40s/it]  6%|â–Œ         | 343/6000 [20:10<5:39:34,  3.60s/it]                                                    {'loss': 0.1289, 'grad_norm': 6.005011558532715, 'learning_rate': 4.79406779661017e-05, 'epoch': 0.06}
  6%|â–Œ         | 343/6000 [20:10<5:39:34,  3.60s/it]  6%|â–Œ         | 344/6000 [20:13<5:33:17,  3.54s/it]                                                    {'loss': 0.0838, 'grad_norm': 3.2708611488342285, 'learning_rate': 4.793220338983051e-05, 'epoch': 0.06}
  6%|â–Œ         | 344/6000 [20:13<5:33:17,  3.54s/it]  6%|â–Œ         | 345/6000 [20:16<5:29:42,  3.50s/it]                                                    {'loss': 0.0936, 'grad_norm': 4.865618705749512, 'learning_rate': 4.792372881355933e-05, 'epoch': 0.06}
  6%|â–Œ         | 345/6000 [20:16<5:29:42,  3.50s/it]  6%|â–Œ         | 346/6000 [20:20<5:28:39,  3.49s/it]                                                    {'loss': 0.0441, 'grad_norm': 1.241629958152771, 'learning_rate': 4.7915254237288134e-05, 'epoch': 0.06}
  6%|â–Œ         | 346/6000 [20:20<5:28:39,  3.49s/it]  6%|â–Œ         | 347/6000 [20:23<5:26:52,  3.47s/it]                                                    {'loss': 0.0194, 'grad_norm': 1.712563157081604, 'learning_rate': 4.790677966101695e-05, 'epoch': 0.06}
  6%|â–Œ         | 347/6000 [20:23<5:26:52,  3.47s/it]  6%|â–Œ         | 348/6000 [20:27<5:28:07,  3.48s/it]                                                    {'loss': 0.2692, 'grad_norm': 6.509364128112793, 'learning_rate': 4.7898305084745764e-05, 'epoch': 0.06}
  6%|â–Œ         | 348/6000 [20:27<5:28:07,  3.48s/it]  6%|â–Œ         | 349/6000 [20:30<5:26:58,  3.47s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.2954956293106079, 'learning_rate': 4.788983050847458e-05, 'epoch': 0.06}
  6%|â–Œ         | 349/6000 [20:30<5:26:58,  3.47s/it]  6%|â–Œ         | 350/6000 [20:34<5:26:20,  3.47s/it]                                                    {'loss': 0.1728, 'grad_norm': 7.194067001342773, 'learning_rate': 4.788135593220339e-05, 'epoch': 0.06}
  6%|â–Œ         | 350/6000 [20:34<5:26:20,  3.47s/it][2025-10-21 01:44:56,400] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  6%|â–Œ         | 351/6000 [20:40<6:34:03,  4.19s/it]                                                    {'loss': 0.1708, 'grad_norm': 6.143642902374268, 'learning_rate': 4.7872881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 351/6000 [20:40<6:34:03,  4.19s/it]  6%|â–Œ         | 352/6000 [20:43<6:10:40,  3.94s/it]                                                    {'loss': 0.0721, 'grad_norm': 4.4905571937561035, 'learning_rate': 4.786440677966102e-05, 'epoch': 0.06}
  6%|â–Œ         | 352/6000 [20:43<6:10:40,  3.94s/it]  6%|â–Œ         | 353/6000 [20:46<5:52:25,  3.74s/it]                                                    {'loss': 0.0632, 'grad_norm': 2.7089195251464844, 'learning_rate': 4.7855932203389834e-05, 'epoch': 0.06}
  6%|â–Œ         | 353/6000 [20:46<5:52:25,  3.74s/it]  6%|â–Œ         | 354/6000 [20:50<5:41:08,  3.63s/it]                                                    {'loss': 0.0436, 'grad_norm': 2.5153396129608154, 'learning_rate': 4.7847457627118645e-05, 'epoch': 0.06}
  6%|â–Œ         | 354/6000 [20:50<5:41:08,  3.63s/it]  6%|â–Œ         | 355/6000 [20:53<5:31:59,  3.53s/it]                                                    {'loss': 0.0144, 'grad_norm': 1.75715172290802, 'learning_rate': 4.7838983050847456e-05, 'epoch': 0.06}
  6%|â–Œ         | 355/6000 [20:53<5:31:59,  3.53s/it]  6%|â–Œ         | 356/6000 [20:56<5:33:16,  3.54s/it]                                                    {'loss': 0.0207, 'grad_norm': 1.4715980291366577, 'learning_rate': 4.7830508474576274e-05, 'epoch': 0.06}
  6%|â–Œ         | 356/6000 [20:56<5:33:16,  3.54s/it]  6%|â–Œ         | 357/6000 [21:00<5:28:49,  3.50s/it]                                                    {'loss': 0.0872, 'grad_norm': 3.7320525646209717, 'learning_rate': 4.7822033898305086e-05, 'epoch': 0.06}
  6%|â–Œ         | 357/6000 [21:00<5:28:49,  3.50s/it]  6%|â–Œ         | 358/6000 [21:03<5:23:34,  3.44s/it]                                                    {'loss': 0.0406, 'grad_norm': 3.257847547531128, 'learning_rate': 4.7813559322033904e-05, 'epoch': 0.06}
  6%|â–Œ         | 358/6000 [21:03<5:23:34,  3.44s/it]  6%|â–Œ         | 359/6000 [21:07<5:23:16,  3.44s/it]                                                    {'loss': 0.0648, 'grad_norm': 3.8893485069274902, 'learning_rate': 4.7805084745762715e-05, 'epoch': 0.06}
  6%|â–Œ         | 359/6000 [21:07<5:23:16,  3.44s/it]  6%|â–Œ         | 360/6000 [21:10<5:21:04,  3.42s/it]                                                    {'loss': 0.2748, 'grad_norm': 6.358197212219238, 'learning_rate': 4.7796610169491526e-05, 'epoch': 0.06}
  6%|â–Œ         | 360/6000 [21:10<5:21:04,  3.42s/it]  6%|â–Œ         | 361/6000 [21:13<5:18:43,  3.39s/it]                                                    {'loss': 0.1827, 'grad_norm': 6.606469631195068, 'learning_rate': 4.778813559322034e-05, 'epoch': 0.06}
  6%|â–Œ         | 361/6000 [21:13<5:18:43,  3.39s/it]  6%|â–Œ         | 362/6000 [21:17<5:18:17,  3.39s/it]                                                    {'loss': 0.2026, 'grad_norm': 5.139797687530518, 'learning_rate': 4.7779661016949156e-05, 'epoch': 0.06}
  6%|â–Œ         | 362/6000 [21:17<5:18:17,  3.39s/it]  6%|â–Œ         | 363/6000 [21:20<5:18:45,  3.39s/it]                                                    {'loss': 0.0159, 'grad_norm': 1.0431461334228516, 'learning_rate': 4.777118644067797e-05, 'epoch': 0.06}
  6%|â–Œ         | 363/6000 [21:20<5:18:45,  3.39s/it]  6%|â–Œ         | 364/6000 [21:24<5:23:34,  3.44s/it]                                                    {'loss': 0.0702, 'grad_norm': 4.285028457641602, 'learning_rate': 4.7762711864406785e-05, 'epoch': 0.06}
  6%|â–Œ         | 364/6000 [21:24<5:23:34,  3.44s/it]  6%|â–Œ         | 365/6000 [21:27<5:24:01,  3.45s/it]                                                    {'loss': 0.0404, 'grad_norm': 3.495213270187378, 'learning_rate': 4.7754237288135596e-05, 'epoch': 0.06}
  6%|â–Œ         | 365/6000 [21:27<5:24:01,  3.45s/it]  6%|â–Œ         | 366/6000 [21:30<5:22:48,  3.44s/it]                                                    {'loss': 0.0295, 'grad_norm': 1.2657898664474487, 'learning_rate': 4.7745762711864414e-05, 'epoch': 0.06}
  6%|â–Œ         | 366/6000 [21:30<5:22:48,  3.44s/it]  6%|â–Œ         | 367/6000 [21:34<5:22:21,  3.43s/it]                                                    {'loss': 0.0408, 'grad_norm': 2.2265641689300537, 'learning_rate': 4.773728813559322e-05, 'epoch': 0.06}
  6%|â–Œ         | 367/6000 [21:34<5:22:21,  3.43s/it]  6%|â–Œ         | 368/6000 [21:38<5:34:45,  3.57s/it]                                                    {'loss': 0.1148, 'grad_norm': 4.223822593688965, 'learning_rate': 4.772881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 368/6000 [21:38<5:34:45,  3.57s/it]  6%|â–Œ         | 369/6000 [21:41<5:27:53,  3.49s/it]                                                    {'loss': 0.059, 'grad_norm': 2.2546913623809814, 'learning_rate': 4.772033898305085e-05, 'epoch': 0.06}
  6%|â–Œ         | 369/6000 [21:41<5:27:53,  3.49s/it]  6%|â–Œ         | 370/6000 [21:44<5:25:58,  3.47s/it]                                                    {'loss': 0.0059, 'grad_norm': 0.40240317583084106, 'learning_rate': 4.7711864406779666e-05, 'epoch': 0.06}
  6%|â–Œ         | 370/6000 [21:45<5:25:58,  3.47s/it]  6%|â–Œ         | 371/6000 [21:48<5:23:30,  3.45s/it]                                                    {'loss': 0.0188, 'grad_norm': 1.005654215812683, 'learning_rate': 4.770338983050848e-05, 'epoch': 0.06}
  6%|â–Œ         | 371/6000 [21:48<5:23:30,  3.45s/it]  6%|â–Œ         | 372/6000 [21:51<5:21:35,  3.43s/it]                                                    {'loss': 0.0103, 'grad_norm': 0.6626128554344177, 'learning_rate': 4.769491525423729e-05, 'epoch': 0.06}
  6%|â–Œ         | 372/6000 [21:51<5:21:35,  3.43s/it]  6%|â–Œ         | 373/6000 [21:55<5:20:19,  3.42s/it]                                                    {'loss': 0.0011, 'grad_norm': 0.10968755930662155, 'learning_rate': 4.768644067796611e-05, 'epoch': 0.06}
  6%|â–Œ         | 373/6000 [21:55<5:20:19,  3.42s/it]  6%|â–Œ         | 374/6000 [21:58<5:21:20,  3.43s/it]                                                    {'loss': 0.349, 'grad_norm': 7.973103046417236, 'learning_rate': 4.767796610169492e-05, 'epoch': 0.06}
  6%|â–Œ         | 374/6000 [21:58<5:21:20,  3.43s/it]  6%|â–‹         | 375/6000 [22:02<5:20:31,  3.42s/it]                                                    {'loss': 0.0338, 'grad_norm': 1.6593917608261108, 'learning_rate': 4.766949152542373e-05, 'epoch': 0.06}
  6%|â–‹         | 375/6000 [22:02<5:20:31,  3.42s/it]  6%|â–‹         | 376/6000 [22:05<5:17:56,  3.39s/it]                                                    {'loss': 0.0795, 'grad_norm': 5.614055633544922, 'learning_rate': 4.766101694915254e-05, 'epoch': 0.06}
  6%|â–‹         | 376/6000 [22:05<5:17:56,  3.39s/it]  6%|â–‹         | 377/6000 [22:08<5:17:38,  3.39s/it]                                                    {'loss': 0.0389, 'grad_norm': 3.6479694843292236, 'learning_rate': 4.765254237288136e-05, 'epoch': 0.06}
  6%|â–‹         | 377/6000 [22:08<5:17:38,  3.39s/it]  6%|â–‹         | 378/6000 [22:12<5:24:03,  3.46s/it]                                                    {'loss': 0.0833, 'grad_norm': 2.08082914352417, 'learning_rate': 4.764406779661017e-05, 'epoch': 0.06}
  6%|â–‹         | 378/6000 [22:12<5:24:03,  3.46s/it]  6%|â–‹         | 379/6000 [22:15<5:22:34,  3.44s/it]                                                    {'loss': 0.0039, 'grad_norm': 0.43204164505004883, 'learning_rate': 4.763559322033899e-05, 'epoch': 0.06}
  6%|â–‹         | 379/6000 [22:15<5:22:34,  3.44s/it]  6%|â–‹         | 380/6000 [22:19<5:32:42,  3.55s/it]                                                    {'loss': 0.084, 'grad_norm': 3.2253735065460205, 'learning_rate': 4.76271186440678e-05, 'epoch': 0.06}
  6%|â–‹         | 380/6000 [22:19<5:32:42,  3.55s/it]  6%|â–‹         | 381/6000 [22:23<5:30:22,  3.53s/it]                                                    {'loss': 0.0128, 'grad_norm': 0.543906033039093, 'learning_rate': 4.761864406779661e-05, 'epoch': 0.06}
  6%|â–‹         | 381/6000 [22:23<5:30:22,  3.53s/it]  6%|â–‹         | 382/6000 [22:26<5:26:43,  3.49s/it]                                                    {'loss': 0.0392, 'grad_norm': 3.2280187606811523, 'learning_rate': 4.761016949152542e-05, 'epoch': 0.06}
  6%|â–‹         | 382/6000 [22:26<5:26:43,  3.49s/it]  6%|â–‹         | 383/6000 [22:29<5:24:57,  3.47s/it]                                                    {'loss': 0.0837, 'grad_norm': 3.797111749649048, 'learning_rate': 4.760169491525424e-05, 'epoch': 0.06}
  6%|â–‹         | 383/6000 [22:29<5:24:57,  3.47s/it]  6%|â–‹         | 384/6000 [22:33<5:24:37,  3.47s/it]                                                    {'loss': 0.0478, 'grad_norm': 2.865593433380127, 'learning_rate': 4.759322033898305e-05, 'epoch': 0.06}
  6%|â–‹         | 384/6000 [22:33<5:24:37,  3.47s/it]  6%|â–‹         | 385/6000 [22:37<5:34:49,  3.58s/it]                                                    {'loss': 0.0107, 'grad_norm': 0.8054761290550232, 'learning_rate': 4.758474576271187e-05, 'epoch': 0.06}
  6%|â–‹         | 385/6000 [22:37<5:34:49,  3.58s/it]  6%|â–‹         | 386/6000 [22:40<5:32:25,  3.55s/it]                                                    {'loss': 0.0247, 'grad_norm': 2.6528522968292236, 'learning_rate': 4.757627118644068e-05, 'epoch': 0.06}
  6%|â–‹         | 386/6000 [22:40<5:32:25,  3.55s/it]  6%|â–‹         | 387/6000 [22:44<5:41:45,  3.65s/it]                                                    {'loss': 0.0375, 'grad_norm': 2.9646241664886475, 'learning_rate': 4.75677966101695e-05, 'epoch': 0.06}
  6%|â–‹         | 387/6000 [22:44<5:41:45,  3.65s/it]  6%|â–‹         | 388/6000 [22:48<5:39:46,  3.63s/it]                                                    {'loss': 0.022, 'grad_norm': 1.2884283065795898, 'learning_rate': 4.755932203389831e-05, 'epoch': 0.06}
  6%|â–‹         | 388/6000 [22:48<5:39:46,  3.63s/it]  6%|â–‹         | 389/6000 [22:51<5:32:22,  3.55s/it]                                                    {'loss': 0.0238, 'grad_norm': 1.967777967453003, 'learning_rate': 4.755084745762712e-05, 'epoch': 0.06}
  6%|â–‹         | 389/6000 [22:51<5:32:22,  3.55s/it]  6%|â–‹         | 390/6000 [22:54<5:28:47,  3.52s/it]                                                    {'loss': 0.0043, 'grad_norm': 0.3415626883506775, 'learning_rate': 4.754237288135593e-05, 'epoch': 0.07}
  6%|â–‹         | 390/6000 [22:54<5:28:47,  3.52s/it]  7%|â–‹         | 391/6000 [22:58<5:24:08,  3.47s/it]                                                    {'loss': 0.44, 'grad_norm': 9.35896110534668, 'learning_rate': 4.7533898305084744e-05, 'epoch': 0.07}
  7%|â–‹         | 391/6000 [22:58<5:24:08,  3.47s/it]  7%|â–‹         | 392/6000 [23:01<5:25:07,  3.48s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.11022945493459702, 'learning_rate': 4.752542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 392/6000 [23:01<5:25:07,  3.48s/it]  7%|â–‹         | 393/6000 [23:05<5:25:51,  3.49s/it]                                                    {'loss': 0.0199, 'grad_norm': 1.6879204511642456, 'learning_rate': 4.751694915254237e-05, 'epoch': 0.07}
  7%|â–‹         | 393/6000 [23:05<5:25:51,  3.49s/it]  7%|â–‹         | 394/6000 [23:08<5:26:26,  3.49s/it]                                                    {'loss': 0.1108, 'grad_norm': 4.296774864196777, 'learning_rate': 4.750847457627119e-05, 'epoch': 0.07}
  7%|â–‹         | 394/6000 [23:08<5:26:26,  3.49s/it]  7%|â–‹         | 395/6000 [23:12<5:22:53,  3.46s/it]                                                    {'loss': 0.0546, 'grad_norm': 3.184915781021118, 'learning_rate': 4.75e-05, 'epoch': 0.07}
  7%|â–‹         | 395/6000 [23:12<5:22:53,  3.46s/it]  7%|â–‹         | 396/6000 [23:15<5:22:54,  3.46s/it]                                                    {'loss': 0.025, 'grad_norm': 1.0653972625732422, 'learning_rate': 4.7491525423728814e-05, 'epoch': 0.07}
  7%|â–‹         | 396/6000 [23:15<5:22:54,  3.46s/it]  7%|â–‹         | 397/6000 [23:19<5:33:52,  3.58s/it]                                                    {'loss': 0.075, 'grad_norm': 1.6180287599563599, 'learning_rate': 4.7483050847457625e-05, 'epoch': 0.07}
  7%|â–‹         | 397/6000 [23:19<5:33:52,  3.58s/it]  7%|â–‹         | 398/6000 [23:22<5:26:37,  3.50s/it]                                                    {'loss': 0.0945, 'grad_norm': 2.4712321758270264, 'learning_rate': 4.747457627118644e-05, 'epoch': 0.07}
  7%|â–‹         | 398/6000 [23:22<5:26:37,  3.50s/it]  7%|â–‹         | 399/6000 [23:26<5:24:12,  3.47s/it]                                                    {'loss': 0.1823, 'grad_norm': 4.67950963973999, 'learning_rate': 4.7466101694915255e-05, 'epoch': 0.07}
  7%|â–‹         | 399/6000 [23:26<5:24:12,  3.47s/it]  7%|â–‹         | 400/6000 [23:29<5:22:59,  3.46s/it]                                                    {'loss': 0.0075, 'grad_norm': 0.5962217450141907, 'learning_rate': 4.745762711864407e-05, 'epoch': 0.07}
  7%|â–‹         | 400/6000 [23:29<5:22:59,  3.46s/it][2025-10-21 01:47:51,881] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  7%|â–‹         | 401/6000 [23:35<6:18:21,  4.05s/it]                                                    {'loss': 0.0383, 'grad_norm': 1.590985655784607, 'learning_rate': 4.7449152542372884e-05, 'epoch': 0.07}
  7%|â–‹         | 401/6000 [23:35<6:18:21,  4.05s/it]  7%|â–‹         | 402/6000 [23:38<5:58:44,  3.84s/it]                                                    {'loss': 0.0837, 'grad_norm': 3.1022422313690186, 'learning_rate': 4.74406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 402/6000 [23:38<5:58:44,  3.84s/it]  7%|â–‹         | 403/6000 [23:41<5:45:59,  3.71s/it]                                                    {'loss': 0.0911, 'grad_norm': 4.207784652709961, 'learning_rate': 4.7432203389830506e-05, 'epoch': 0.07}
  7%|â–‹         | 403/6000 [23:41<5:45:59,  3.71s/it]  7%|â–‹         | 404/6000 [23:45<5:40:51,  3.65s/it]                                                    {'loss': 0.2827, 'grad_norm': 5.682455539703369, 'learning_rate': 4.7423728813559325e-05, 'epoch': 0.07}
  7%|â–‹         | 404/6000 [23:45<5:40:51,  3.65s/it]  7%|â–‹         | 405/6000 [23:48<5:33:45,  3.58s/it]                                                    {'loss': 0.0357, 'grad_norm': 2.1608774662017822, 'learning_rate': 4.7415254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 405/6000 [23:48<5:33:45,  3.58s/it]  7%|â–‹         | 406/6000 [23:52<5:28:07,  3.52s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.053127747029066086, 'learning_rate': 4.7406779661016954e-05, 'epoch': 0.07}
  7%|â–‹         | 406/6000 [23:52<5:28:07,  3.52s/it]  7%|â–‹         | 407/6000 [23:55<5:24:14,  3.48s/it]                                                    {'loss': 0.0255, 'grad_norm': 1.2666012048721313, 'learning_rate': 4.7398305084745765e-05, 'epoch': 0.07}
  7%|â–‹         | 407/6000 [23:55<5:24:14,  3.48s/it]  7%|â–‹         | 408/6000 [23:59<5:41:17,  3.66s/it]                                                    {'loss': 0.0812, 'grad_norm': 4.313955783843994, 'learning_rate': 4.738983050847458e-05, 'epoch': 0.07}
  7%|â–‹         | 408/6000 [23:59<5:41:17,  3.66s/it]  7%|â–‹         | 409/6000 [24:03<5:36:22,  3.61s/it]                                                    {'loss': 0.0583, 'grad_norm': 2.9391539096832275, 'learning_rate': 4.7381355932203395e-05, 'epoch': 0.07}
  7%|â–‹         | 409/6000 [24:03<5:36:22,  3.61s/it]  7%|â–‹         | 410/6000 [24:06<5:29:33,  3.54s/it]                                                    {'loss': 0.1425, 'grad_norm': 5.274325847625732, 'learning_rate': 4.7372881355932206e-05, 'epoch': 0.07}
  7%|â–‹         | 410/6000 [24:06<5:29:33,  3.54s/it]  7%|â–‹         | 411/6000 [24:10<5:48:04,  3.74s/it]                                                    {'loss': 0.0088, 'grad_norm': 0.3486383855342865, 'learning_rate': 4.736440677966102e-05, 'epoch': 0.07}
  7%|â–‹         | 411/6000 [24:10<5:48:04,  3.74s/it]  7%|â–‹         | 412/6000 [24:14<5:41:34,  3.67s/it]                                                    {'loss': 0.125, 'grad_norm': 3.693032741546631, 'learning_rate': 4.735593220338983e-05, 'epoch': 0.07}
  7%|â–‹         | 412/6000 [24:14<5:41:34,  3.67s/it]  7%|â–‹         | 413/6000 [24:17<5:38:44,  3.64s/it]                                                    {'loss': 0.3099, 'grad_norm': 6.865203857421875, 'learning_rate': 4.7347457627118646e-05, 'epoch': 0.07}
  7%|â–‹         | 413/6000 [24:17<5:38:44,  3.64s/it]  7%|â–‹         | 414/6000 [24:21<5:30:22,  3.55s/it]                                                    {'loss': 0.0501, 'grad_norm': 2.7789690494537354, 'learning_rate': 4.733898305084746e-05, 'epoch': 0.07}
  7%|â–‹         | 414/6000 [24:21<5:30:22,  3.55s/it]  7%|â–‹         | 415/6000 [24:24<5:31:58,  3.57s/it]                                                    {'loss': 0.0595, 'grad_norm': 2.877187728881836, 'learning_rate': 4.7330508474576276e-05, 'epoch': 0.07}
  7%|â–‹         | 415/6000 [24:24<5:31:58,  3.57s/it]  7%|â–‹         | 416/6000 [24:28<5:28:52,  3.53s/it]                                                    {'loss': 0.0262, 'grad_norm': 2.383692741394043, 'learning_rate': 4.732203389830509e-05, 'epoch': 0.07}
  7%|â–‹         | 416/6000 [24:28<5:28:52,  3.53s/it]  7%|â–‹         | 417/6000 [24:31<5:26:00,  3.50s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.08460187911987305, 'learning_rate': 4.73135593220339e-05, 'epoch': 0.07}
  7%|â–‹         | 417/6000 [24:31<5:26:00,  3.50s/it]  7%|â–‹         | 418/6000 [24:34<5:23:03,  3.47s/it]                                                    {'loss': 0.073, 'grad_norm': 3.192193031311035, 'learning_rate': 4.730508474576271e-05, 'epoch': 0.07}
  7%|â–‹         | 418/6000 [24:34<5:23:03,  3.47s/it]  7%|â–‹         | 419/6000 [24:38<5:35:01,  3.60s/it]                                                    {'loss': 0.0172, 'grad_norm': 0.6292647123336792, 'learning_rate': 4.729661016949153e-05, 'epoch': 0.07}
  7%|â–‹         | 419/6000 [24:38<5:35:01,  3.60s/it]  7%|â–‹         | 420/6000 [24:42<5:32:12,  3.57s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.38322389125823975, 'learning_rate': 4.728813559322034e-05, 'epoch': 0.07}
  7%|â–‹         | 420/6000 [24:42<5:32:12,  3.57s/it]  7%|â–‹         | 421/6000 [24:45<5:27:32,  3.52s/it]                                                    {'loss': 0.1746, 'grad_norm': 6.484123229980469, 'learning_rate': 4.727966101694916e-05, 'epoch': 0.07}
  7%|â–‹         | 421/6000 [24:45<5:27:32,  3.52s/it]  7%|â–‹         | 422/6000 [24:49<5:23:19,  3.48s/it]                                                    {'loss': 0.0827, 'grad_norm': 3.9895970821380615, 'learning_rate': 4.727118644067797e-05, 'epoch': 0.07}
  7%|â–‹         | 422/6000 [24:49<5:23:19,  3.48s/it]  7%|â–‹         | 423/6000 [24:52<5:20:41,  3.45s/it]                                                    {'loss': 0.0991, 'grad_norm': 4.6159987449646, 'learning_rate': 4.7262711864406786e-05, 'epoch': 0.07}
  7%|â–‹         | 423/6000 [24:52<5:20:41,  3.45s/it]  7%|â–‹         | 424/6000 [24:55<5:20:10,  3.45s/it]                                                    {'loss': 0.0021, 'grad_norm': 0.12599590420722961, 'learning_rate': 4.72542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 424/6000 [24:55<5:20:10,  3.45s/it]  7%|â–‹         | 425/6000 [24:59<5:17:37,  3.42s/it]                                                    {'loss': 0.0305, 'grad_norm': 1.3639757633209229, 'learning_rate': 4.724576271186441e-05, 'epoch': 0.07}
  7%|â–‹         | 425/6000 [24:59<5:17:37,  3.42s/it]  7%|â–‹         | 426/6000 [25:02<5:17:42,  3.42s/it]                                                    {'loss': 0.0221, 'grad_norm': 1.8537168502807617, 'learning_rate': 4.723728813559322e-05, 'epoch': 0.07}
  7%|â–‹         | 426/6000 [25:02<5:17:42,  3.42s/it]  7%|â–‹         | 427/6000 [25:06<5:17:35,  3.42s/it]                                                    {'loss': 0.1628, 'grad_norm': 4.568852424621582, 'learning_rate': 4.722881355932204e-05, 'epoch': 0.07}
  7%|â–‹         | 427/6000 [25:06<5:17:35,  3.42s/it]  7%|â–‹         | 428/6000 [25:09<5:17:03,  3.41s/it]                                                    {'loss': 0.006, 'grad_norm': 0.40536320209503174, 'learning_rate': 4.722033898305085e-05, 'epoch': 0.07}
  7%|â–‹         | 428/6000 [25:09<5:17:03,  3.41s/it]  7%|â–‹         | 429/6000 [25:12<5:15:50,  3.40s/it]                                                    {'loss': 0.0525, 'grad_norm': 3.1466431617736816, 'learning_rate': 4.721186440677967e-05, 'epoch': 0.07}
  7%|â–‹         | 429/6000 [25:12<5:15:50,  3.40s/it]  7%|â–‹         | 430/6000 [25:16<5:16:41,  3.41s/it]                                                    {'loss': 0.0882, 'grad_norm': 4.132057189941406, 'learning_rate': 4.720338983050848e-05, 'epoch': 0.07}
  7%|â–‹         | 430/6000 [25:16<5:16:41,  3.41s/it]  7%|â–‹         | 431/6000 [25:19<5:17:11,  3.42s/it]                                                    {'loss': 0.1254, 'grad_norm': 6.648634433746338, 'learning_rate': 4.719491525423729e-05, 'epoch': 0.07}
  7%|â–‹         | 431/6000 [25:19<5:17:11,  3.42s/it]  7%|â–‹         | 432/6000 [25:23<5:18:38,  3.43s/it]                                                    {'loss': 0.0723, 'grad_norm': 2.105917453765869, 'learning_rate': 4.71864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 432/6000 [25:23<5:18:38,  3.43s/it]  7%|â–‹         | 433/6000 [25:26<5:17:19,  3.42s/it]                                                    {'loss': 0.008, 'grad_norm': 0.8099511861801147, 'learning_rate': 4.717796610169491e-05, 'epoch': 0.07}
  7%|â–‹         | 433/6000 [25:26<5:17:19,  3.42s/it]  7%|â–‹         | 434/6000 [25:30<5:15:09,  3.40s/it]                                                    {'loss': 0.0051, 'grad_norm': 0.4987412691116333, 'learning_rate': 4.716949152542373e-05, 'epoch': 0.07}
  7%|â–‹         | 434/6000 [25:30<5:15:09,  3.40s/it]  7%|â–‹         | 435/6000 [25:33<5:15:10,  3.40s/it]                                                    {'loss': 0.045, 'grad_norm': 3.945136547088623, 'learning_rate': 4.716101694915254e-05, 'epoch': 0.07}
  7%|â–‹         | 435/6000 [25:33<5:15:10,  3.40s/it]  7%|â–‹         | 436/6000 [25:36<5:17:33,  3.42s/it]                                                    {'loss': 0.0073, 'grad_norm': 0.49416518211364746, 'learning_rate': 4.715254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 436/6000 [25:36<5:17:33,  3.42s/it]  7%|â–‹         | 437/6000 [25:40<5:19:00,  3.44s/it]                                                    {'loss': 0.065, 'grad_norm': 2.9327802658081055, 'learning_rate': 4.714406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 437/6000 [25:40<5:19:00,  3.44s/it]  7%|â–‹         | 438/6000 [25:44<5:24:05,  3.50s/it]                                                    {'loss': 0.0239, 'grad_norm': 1.693234920501709, 'learning_rate': 4.713559322033898e-05, 'epoch': 0.07}
  7%|â–‹         | 438/6000 [25:44<5:24:05,  3.50s/it]  7%|â–‹         | 439/6000 [25:47<5:23:18,  3.49s/it]                                                    {'loss': 0.0232, 'grad_norm': 2.1592047214508057, 'learning_rate': 4.7127118644067794e-05, 'epoch': 0.07}
  7%|â–‹         | 439/6000 [25:47<5:23:18,  3.49s/it]  7%|â–‹         | 440/6000 [25:50<5:21:42,  3.47s/it]                                                    {'loss': 0.0084, 'grad_norm': 0.6425911784172058, 'learning_rate': 4.711864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 440/6000 [25:50<5:21:42,  3.47s/it]  7%|â–‹         | 441/6000 [25:54<5:26:01,  3.52s/it]                                                    {'loss': 0.0282, 'grad_norm': 3.0909857749938965, 'learning_rate': 4.7110169491525423e-05, 'epoch': 0.07}
  7%|â–‹         | 441/6000 [25:54<5:26:01,  3.52s/it]  7%|â–‹         | 442/6000 [25:58<5:30:56,  3.57s/it]                                                    {'loss': 0.0227, 'grad_norm': 2.262322425842285, 'learning_rate': 4.710169491525424e-05, 'epoch': 0.07}
  7%|â–‹         | 442/6000 [25:58<5:30:56,  3.57s/it]  7%|â–‹         | 443/6000 [26:01<5:26:19,  3.52s/it]                                                    {'loss': 0.0162, 'grad_norm': 1.5480746030807495, 'learning_rate': 4.709322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 443/6000 [26:01<5:26:19,  3.52s/it]  7%|â–‹         | 444/6000 [26:04<5:21:25,  3.47s/it]                                                    {'loss': 0.0108, 'grad_norm': 1.3395169973373413, 'learning_rate': 4.708474576271187e-05, 'epoch': 0.07}
  7%|â–‹         | 444/6000 [26:04<5:21:25,  3.47s/it]  7%|â–‹         | 445/6000 [26:08<5:21:21,  3.47s/it]                                                    {'loss': 0.1347, 'grad_norm': 5.448879718780518, 'learning_rate': 4.707627118644068e-05, 'epoch': 0.07}
  7%|â–‹         | 445/6000 [26:08<5:21:21,  3.47s/it]  7%|â–‹         | 446/6000 [26:11<5:19:29,  3.45s/it]                                                    {'loss': 0.0307, 'grad_norm': 2.9224884510040283, 'learning_rate': 4.7067796610169493e-05, 'epoch': 0.07}
  7%|â–‹         | 446/6000 [26:11<5:19:29,  3.45s/it]  7%|â–‹         | 447/6000 [26:15<5:18:31,  3.44s/it]                                                    {'loss': 0.1774, 'grad_norm': 4.404492378234863, 'learning_rate': 4.7059322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 447/6000 [26:15<5:18:31,  3.44s/it]  7%|â–‹         | 448/6000 [26:18<5:16:57,  3.43s/it]                                                    {'loss': 0.016, 'grad_norm': 1.6586521863937378, 'learning_rate': 4.705084745762712e-05, 'epoch': 0.07}
  7%|â–‹         | 448/6000 [26:18<5:16:57,  3.43s/it]  7%|â–‹         | 449/6000 [26:22<5:19:40,  3.46s/it]                                                    {'loss': 0.0504, 'grad_norm': 3.827359676361084, 'learning_rate': 4.7042372881355934e-05, 'epoch': 0.07}
  7%|â–‹         | 449/6000 [26:22<5:19:40,  3.46s/it]  8%|â–Š         | 450/6000 [26:25<5:18:59,  3.45s/it]                                                    {'loss': 0.0271, 'grad_norm': 2.704228639602661, 'learning_rate': 4.703389830508475e-05, 'epoch': 0.07}
  8%|â–Š         | 450/6000 [26:25<5:18:59,  3.45s/it][2025-10-21 01:50:47,889] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 451/6000 [26:31<6:17:48,  4.09s/it]                                                    {'loss': 0.0159, 'grad_norm': 1.873503565788269, 'learning_rate': 4.702542372881356e-05, 'epoch': 0.08}
  8%|â–Š         | 451/6000 [26:31<6:17:48,  4.09s/it]  8%|â–Š         | 452/6000 [26:34<6:08:05,  3.98s/it]                                                    {'loss': 0.1355, 'grad_norm': 2.1873674392700195, 'learning_rate': 4.7016949152542375e-05, 'epoch': 0.08}
  8%|â–Š         | 452/6000 [26:34<6:08:05,  3.98s/it]  8%|â–Š         | 453/6000 [26:38<5:51:48,  3.81s/it]                                                    {'loss': 0.1512, 'grad_norm': 4.78715705871582, 'learning_rate': 4.7008474576271186e-05, 'epoch': 0.08}
  8%|â–Š         | 453/6000 [26:38<5:51:48,  3.81s/it]  8%|â–Š         | 454/6000 [26:41<5:42:17,  3.70s/it]                                                    {'loss': 0.1488, 'grad_norm': 4.870976448059082, 'learning_rate': 4.7e-05, 'epoch': 0.08}
  8%|â–Š         | 454/6000 [26:41<5:42:17,  3.70s/it]  8%|â–Š         | 455/6000 [26:45<5:32:33,  3.60s/it]                                                    {'loss': 0.0205, 'grad_norm': 1.3471081256866455, 'learning_rate': 4.6991525423728815e-05, 'epoch': 0.08}
  8%|â–Š         | 455/6000 [26:45<5:32:33,  3.60s/it]  8%|â–Š         | 456/6000 [26:48<5:28:59,  3.56s/it]                                                    {'loss': 0.3931, 'grad_norm': 7.333314418792725, 'learning_rate': 4.6983050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 456/6000 [26:48<5:28:59,  3.56s/it]  8%|â–Š         | 457/6000 [26:52<5:26:29,  3.53s/it]                                                    {'loss': 0.0597, 'grad_norm': 3.22979474067688, 'learning_rate': 4.6974576271186445e-05, 'epoch': 0.08}
  8%|â–Š         | 457/6000 [26:52<5:26:29,  3.53s/it]  8%|â–Š         | 458/6000 [26:55<5:21:55,  3.49s/it]                                                    {'loss': 0.0993, 'grad_norm': 5.130035400390625, 'learning_rate': 4.6966101694915256e-05, 'epoch': 0.08}
  8%|â–Š         | 458/6000 [26:55<5:21:55,  3.49s/it]  8%|â–Š         | 459/6000 [26:58<5:19:03,  3.45s/it]                                                    {'loss': 0.1924, 'grad_norm': 4.057183265686035, 'learning_rate': 4.6957627118644074e-05, 'epoch': 0.08}
  8%|â–Š         | 459/6000 [26:58<5:19:03,  3.45s/it]  8%|â–Š         | 460/6000 [27:02<5:16:08,  3.42s/it]                                                    {'loss': 0.0521, 'grad_norm': 2.7415852546691895, 'learning_rate': 4.694915254237288e-05, 'epoch': 0.08}
  8%|â–Š         | 460/6000 [27:02<5:16:08,  3.42s/it]  8%|â–Š         | 461/6000 [27:05<5:14:34,  3.41s/it]                                                    {'loss': 0.038, 'grad_norm': 1.3189620971679688, 'learning_rate': 4.6940677966101697e-05, 'epoch': 0.08}
  8%|â–Š         | 461/6000 [27:05<5:14:34,  3.41s/it]  8%|â–Š         | 462/6000 [27:08<5:12:08,  3.38s/it]                                                    {'loss': 0.0546, 'grad_norm': 1.4966720342636108, 'learning_rate': 4.693220338983051e-05, 'epoch': 0.08}
  8%|â–Š         | 462/6000 [27:08<5:12:08,  3.38s/it]  8%|â–Š         | 463/6000 [27:12<5:12:03,  3.38s/it]                                                    {'loss': 0.1338, 'grad_norm': 4.924350261688232, 'learning_rate': 4.6923728813559326e-05, 'epoch': 0.08}
  8%|â–Š         | 463/6000 [27:12<5:12:03,  3.38s/it]  8%|â–Š         | 464/6000 [27:15<5:10:55,  3.37s/it]                                                    {'loss': 0.1461, 'grad_norm': 6.148525714874268, 'learning_rate': 4.691525423728814e-05, 'epoch': 0.08}
  8%|â–Š         | 464/6000 [27:15<5:10:55,  3.37s/it]  8%|â–Š         | 465/6000 [27:19<5:14:40,  3.41s/it]                                                    {'loss': 0.249, 'grad_norm': 7.436496734619141, 'learning_rate': 4.6906779661016955e-05, 'epoch': 0.08}
  8%|â–Š         | 465/6000 [27:19<5:14:40,  3.41s/it]  8%|â–Š         | 466/6000 [27:22<5:14:22,  3.41s/it]                                                    {'loss': 0.0244, 'grad_norm': 0.9928707480430603, 'learning_rate': 4.6898305084745767e-05, 'epoch': 0.08}
  8%|â–Š         | 466/6000 [27:22<5:14:22,  3.41s/it]  8%|â–Š         | 467/6000 [27:25<5:15:37,  3.42s/it]                                                    {'loss': 0.1217, 'grad_norm': 4.7293009757995605, 'learning_rate': 4.688983050847458e-05, 'epoch': 0.08}
  8%|â–Š         | 467/6000 [27:25<5:15:37,  3.42s/it]  8%|â–Š         | 468/6000 [27:29<5:17:27,  3.44s/it]                                                    {'loss': 0.0506, 'grad_norm': 1.4787676334381104, 'learning_rate': 4.688135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 468/6000 [27:29<5:17:27,  3.44s/it]  8%|â–Š         | 469/6000 [27:32<5:14:29,  3.41s/it]                                                    {'loss': 0.3008, 'grad_norm': 5.6880621910095215, 'learning_rate': 4.687288135593221e-05, 'epoch': 0.08}
  8%|â–Š         | 469/6000 [27:32<5:14:29,  3.41s/it]  8%|â–Š         | 470/6000 [27:36<5:13:34,  3.40s/it]                                                    {'loss': 0.0062, 'grad_norm': 0.4156878590583801, 'learning_rate': 4.686440677966102e-05, 'epoch': 0.08}
  8%|â–Š         | 470/6000 [27:36<5:13:34,  3.40s/it]  8%|â–Š         | 471/6000 [27:39<5:12:19,  3.39s/it]                                                    {'loss': 0.1255, 'grad_norm': 7.007257461547852, 'learning_rate': 4.6855932203389837e-05, 'epoch': 0.08}
  8%|â–Š         | 471/6000 [27:39<5:12:19,  3.39s/it]  8%|â–Š         | 472/6000 [27:42<5:11:41,  3.38s/it]                                                    {'loss': 0.2327, 'grad_norm': 4.377240180969238, 'learning_rate': 4.684745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 472/6000 [27:42<5:11:41,  3.38s/it]  8%|â–Š         | 473/6000 [27:46<5:12:14,  3.39s/it]                                                    {'loss': 0.2328, 'grad_norm': 6.038877964019775, 'learning_rate': 4.6838983050847466e-05, 'epoch': 0.08}
  8%|â–Š         | 473/6000 [27:46<5:12:14,  3.39s/it]  8%|â–Š         | 474/6000 [27:49<5:11:41,  3.38s/it]                                                    {'loss': 0.0268, 'grad_norm': 1.2891302108764648, 'learning_rate': 4.683050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 474/6000 [27:49<5:11:41,  3.38s/it]  8%|â–Š         | 475/6000 [27:53<5:12:19,  3.39s/it]                                                    {'loss': 0.0856, 'grad_norm': 1.7019141912460327, 'learning_rate': 4.682203389830508e-05, 'epoch': 0.08}
  8%|â–Š         | 475/6000 [27:53<5:12:19,  3.39s/it]  8%|â–Š         | 476/6000 [27:56<5:11:33,  3.38s/it]                                                    {'loss': 0.0329, 'grad_norm': 2.0363516807556152, 'learning_rate': 4.68135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 476/6000 [27:56<5:11:33,  3.38s/it]  8%|â–Š         | 477/6000 [27:59<5:12:07,  3.39s/it]                                                    {'loss': 0.0544, 'grad_norm': 3.6610124111175537, 'learning_rate': 4.680508474576271e-05, 'epoch': 0.08}
  8%|â–Š         | 477/6000 [27:59<5:12:07,  3.39s/it]  8%|â–Š         | 478/6000 [28:03<5:13:15,  3.40s/it]                                                    {'loss': 0.0134, 'grad_norm': 1.6738258600234985, 'learning_rate': 4.679661016949153e-05, 'epoch': 0.08}
  8%|â–Š         | 478/6000 [28:03<5:13:15,  3.40s/it]  8%|â–Š         | 479/6000 [28:06<5:12:31,  3.40s/it]                                                    {'loss': 0.0497, 'grad_norm': 2.3801608085632324, 'learning_rate': 4.678813559322034e-05, 'epoch': 0.08}
  8%|â–Š         | 479/6000 [28:06<5:12:31,  3.40s/it]  8%|â–Š         | 480/6000 [28:10<5:10:39,  3.38s/it]                                                    {'loss': 0.0201, 'grad_norm': 1.0871740579605103, 'learning_rate': 4.677966101694916e-05, 'epoch': 0.08}
  8%|â–Š         | 480/6000 [28:10<5:10:39,  3.38s/it]  8%|â–Š         | 481/6000 [28:13<5:15:38,  3.43s/it]                                                    {'loss': 0.016, 'grad_norm': 1.3053081035614014, 'learning_rate': 4.677118644067797e-05, 'epoch': 0.08}
  8%|â–Š         | 481/6000 [28:13<5:15:38,  3.43s/it]  8%|â–Š         | 482/6000 [28:16<5:14:05,  3.42s/it]                                                    {'loss': 0.0177, 'grad_norm': 1.1421922445297241, 'learning_rate': 4.676271186440678e-05, 'epoch': 0.08}
  8%|â–Š         | 482/6000 [28:16<5:14:05,  3.42s/it]  8%|â–Š         | 483/6000 [28:20<5:14:20,  3.42s/it]                                                    {'loss': 0.0536, 'grad_norm': 1.8692004680633545, 'learning_rate': 4.675423728813559e-05, 'epoch': 0.08}
  8%|â–Š         | 483/6000 [28:20<5:14:20,  3.42s/it]  8%|â–Š         | 484/6000 [28:24<5:19:33,  3.48s/it]                                                    {'loss': 0.0069, 'grad_norm': 0.7619299292564392, 'learning_rate': 4.674576271186441e-05, 'epoch': 0.08}
  8%|â–Š         | 484/6000 [28:24<5:19:33,  3.48s/it]  8%|â–Š         | 485/6000 [28:27<5:32:11,  3.61s/it]                                                    {'loss': 0.0189, 'grad_norm': 1.3102319240570068, 'learning_rate': 4.673728813559322e-05, 'epoch': 0.08}
  8%|â–Š         | 485/6000 [28:27<5:32:11,  3.61s/it]  8%|â–Š         | 486/6000 [28:31<5:23:56,  3.52s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.4274131655693054, 'learning_rate': 4.672881355932204e-05, 'epoch': 0.08}
  8%|â–Š         | 486/6000 [28:31<5:23:56,  3.52s/it]  8%|â–Š         | 487/6000 [28:34<5:24:23,  3.53s/it]                                                    {'loss': 0.2902, 'grad_norm': 5.802417755126953, 'learning_rate': 4.672033898305085e-05, 'epoch': 0.08}
  8%|â–Š         | 487/6000 [28:34<5:24:23,  3.53s/it]  8%|â–Š         | 488/6000 [28:38<5:25:53,  3.55s/it]                                                    {'loss': 0.3846, 'grad_norm': 7.009028434753418, 'learning_rate': 4.671186440677966e-05, 'epoch': 0.08}
  8%|â–Š         | 488/6000 [28:38<5:25:53,  3.55s/it]  8%|â–Š         | 489/6000 [28:41<5:25:18,  3.54s/it]                                                    {'loss': 0.0715, 'grad_norm': 2.7859973907470703, 'learning_rate': 4.6703389830508474e-05, 'epoch': 0.08}
  8%|â–Š         | 489/6000 [28:41<5:25:18,  3.54s/it]  8%|â–Š         | 490/6000 [28:45<5:22:00,  3.51s/it]                                                    {'loss': 0.156, 'grad_norm': 4.766231060028076, 'learning_rate': 4.669491525423729e-05, 'epoch': 0.08}
  8%|â–Š         | 490/6000 [28:45<5:22:00,  3.51s/it]  8%|â–Š         | 491/6000 [28:48<5:23:35,  3.52s/it]                                                    {'loss': 0.1242, 'grad_norm': 4.276452541351318, 'learning_rate': 4.66864406779661e-05, 'epoch': 0.08}
  8%|â–Š         | 491/6000 [28:48<5:23:35,  3.52s/it]  8%|â–Š         | 492/6000 [28:52<5:19:15,  3.48s/it]                                                    {'loss': 0.0159, 'grad_norm': 0.8823248147964478, 'learning_rate': 4.667796610169492e-05, 'epoch': 0.08}
  8%|â–Š         | 492/6000 [28:52<5:19:15,  3.48s/it]  8%|â–Š         | 493/6000 [28:55<5:19:12,  3.48s/it]                                                    {'loss': 0.1572, 'grad_norm': 4.9103569984436035, 'learning_rate': 4.666949152542373e-05, 'epoch': 0.08}
  8%|â–Š         | 493/6000 [28:55<5:19:12,  3.48s/it]  8%|â–Š         | 494/6000 [28:59<5:16:51,  3.45s/it]                                                    {'loss': 0.0576, 'grad_norm': 3.44193959236145, 'learning_rate': 4.666101694915255e-05, 'epoch': 0.08}
  8%|â–Š         | 494/6000 [28:59<5:16:51,  3.45s/it]  8%|â–Š         | 495/6000 [29:02<5:18:42,  3.47s/it]                                                    {'loss': 0.079, 'grad_norm': 3.4815685749053955, 'learning_rate': 4.6652542372881355e-05, 'epoch': 0.08}
  8%|â–Š         | 495/6000 [29:02<5:18:42,  3.47s/it]  8%|â–Š         | 496/6000 [29:06<5:15:51,  3.44s/it]                                                    {'loss': 0.0708, 'grad_norm': 3.581875801086426, 'learning_rate': 4.6644067796610166e-05, 'epoch': 0.08}
  8%|â–Š         | 496/6000 [29:06<5:15:51,  3.44s/it]  8%|â–Š         | 497/6000 [29:09<5:17:59,  3.47s/it]                                                    {'loss': 0.0074, 'grad_norm': 0.6175896525382996, 'learning_rate': 4.6635593220338984e-05, 'epoch': 0.08}
  8%|â–Š         | 497/6000 [29:09<5:17:59,  3.47s/it]  8%|â–Š         | 498/6000 [29:13<5:17:20,  3.46s/it]                                                    {'loss': 0.0846, 'grad_norm': 2.7767555713653564, 'learning_rate': 4.6627118644067795e-05, 'epoch': 0.08}
  8%|â–Š         | 498/6000 [29:13<5:17:20,  3.46s/it]  8%|â–Š         | 499/6000 [29:16<5:15:46,  3.44s/it]                                                    {'loss': 0.0654, 'grad_norm': 1.7306476831436157, 'learning_rate': 4.6618644067796614e-05, 'epoch': 0.08}
  8%|â–Š         | 499/6000 [29:16<5:15:46,  3.44s/it]  8%|â–Š         | 500/6000 [29:19<5:16:06,  3.45s/it]                                                    {'loss': 0.1072, 'grad_norm': 3.0622196197509766, 'learning_rate': 4.6610169491525425e-05, 'epoch': 0.08}
  8%|â–Š         | 500/6000 [29:19<5:16:06,  3.45s/it][2025-10-21 01:53:42,121] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 501/6000 [29:25<6:12:51,  4.07s/it]                                                    {'loss': 0.0941, 'grad_norm': 4.306609630584717, 'learning_rate': 4.660169491525424e-05, 'epoch': 0.08}
  8%|â–Š         | 501/6000 [29:25<6:12:51,  4.07s/it]  8%|â–Š         | 502/6000 [29:28<5:59:37,  3.92s/it]                                                    {'loss': 0.0209, 'grad_norm': 1.2481273412704468, 'learning_rate': 4.6593220338983054e-05, 'epoch': 0.08}
  8%|â–Š         | 502/6000 [29:28<5:59:37,  3.92s/it]  8%|â–Š         | 503/6000 [29:32<5:44:30,  3.76s/it]                                                    {'loss': 0.0281, 'grad_norm': 1.5277645587921143, 'learning_rate': 4.6584745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 503/6000 [29:32<5:44:30,  3.76s/it]  8%|â–Š         | 504/6000 [29:35<5:32:05,  3.63s/it]                                                    {'loss': 0.0324, 'grad_norm': 1.2461085319519043, 'learning_rate': 4.657627118644068e-05, 'epoch': 0.08}
  8%|â–Š         | 504/6000 [29:35<5:32:05,  3.63s/it]  8%|â–Š         | 505/6000 [29:39<5:26:41,  3.57s/it]                                                    {'loss': 0.0354, 'grad_norm': 2.7826054096221924, 'learning_rate': 4.6567796610169495e-05, 'epoch': 0.08}
  8%|â–Š         | 505/6000 [29:39<5:26:41,  3.57s/it]  8%|â–Š         | 506/6000 [29:42<5:32:50,  3.63s/it]                                                    {'loss': 0.0965, 'grad_norm': 4.725661277770996, 'learning_rate': 4.6559322033898306e-05, 'epoch': 0.08}
  8%|â–Š         | 506/6000 [29:42<5:32:50,  3.63s/it]  8%|â–Š         | 507/6000 [29:46<5:27:17,  3.57s/it]                                                    {'loss': 0.1121, 'grad_norm': 4.741854190826416, 'learning_rate': 4.6550847457627124e-05, 'epoch': 0.08}
  8%|â–Š         | 507/6000 [29:46<5:27:17,  3.57s/it]  8%|â–Š         | 508/6000 [29:49<5:20:28,  3.50s/it]                                                    {'loss': 0.0226, 'grad_norm': 1.649393081665039, 'learning_rate': 4.6542372881355935e-05, 'epoch': 0.08}
  8%|â–Š         | 508/6000 [29:49<5:20:28,  3.50s/it]  8%|â–Š         | 509/6000 [29:52<5:14:59,  3.44s/it]                                                    {'loss': 0.0592, 'grad_norm': 2.2978150844573975, 'learning_rate': 4.653389830508475e-05, 'epoch': 0.08}
  8%|â–Š         | 509/6000 [29:52<5:14:59,  3.44s/it]  8%|â–Š         | 510/6000 [29:56<5:14:52,  3.44s/it]                                                    {'loss': 0.0791, 'grad_norm': 3.5185911655426025, 'learning_rate': 4.652542372881356e-05, 'epoch': 0.09}
  8%|â–Š         | 510/6000 [29:56<5:14:52,  3.44s/it]  9%|â–Š         | 511/6000 [29:59<5:15:23,  3.45s/it]                                                    {'loss': 0.0726, 'grad_norm': 1.5019532442092896, 'learning_rate': 4.6516949152542376e-05, 'epoch': 0.09}
  9%|â–Š         | 511/6000 [29:59<5:15:23,  3.45s/it]  9%|â–Š         | 512/6000 [30:03<5:14:25,  3.44s/it]                                                    {'loss': 0.0594, 'grad_norm': 3.2548792362213135, 'learning_rate': 4.650847457627119e-05, 'epoch': 0.09}
  9%|â–Š         | 512/6000 [30:03<5:14:25,  3.44s/it]  9%|â–Š         | 513/6000 [30:06<5:19:43,  3.50s/it]                                                    {'loss': 0.0052, 'grad_norm': 0.4074352979660034, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.09}
  9%|â–Š         | 513/6000 [30:06<5:19:43,  3.50s/it]  9%|â–Š         | 514/6000 [30:10<5:18:21,  3.48s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.18315821886062622, 'learning_rate': 4.649152542372882e-05, 'epoch': 0.09}
  9%|â–Š         | 514/6000 [30:10<5:18:21,  3.48s/it]  9%|â–Š         | 515/6000 [30:13<5:15:54,  3.46s/it]                                                    {'loss': 0.0882, 'grad_norm': 2.8497676849365234, 'learning_rate': 4.6483050847457635e-05, 'epoch': 0.09}
  9%|â–Š         | 515/6000 [30:13<5:15:54,  3.46s/it]  9%|â–Š         | 516/6000 [30:17<5:21:14,  3.51s/it]                                                    {'loss': 0.0656, 'grad_norm': 5.538510322570801, 'learning_rate': 4.6474576271186446e-05, 'epoch': 0.09}
  9%|â–Š         | 516/6000 [30:17<5:21:14,  3.51s/it]  9%|â–Š         | 517/6000 [30:20<5:19:41,  3.50s/it]                                                    {'loss': 0.0011, 'grad_norm': 0.07873347401618958, 'learning_rate': 4.646610169491525e-05, 'epoch': 0.09}
  9%|â–Š         | 517/6000 [30:20<5:19:41,  3.50s/it]  9%|â–Š         | 518/6000 [30:24<5:16:23,  3.46s/it]                                                    {'loss': 0.2957, 'grad_norm': 6.426178932189941, 'learning_rate': 4.645762711864407e-05, 'epoch': 0.09}
  9%|â–Š         | 518/6000 [30:24<5:16:23,  3.46s/it]  9%|â–Š         | 519/6000 [30:27<5:20:02,  3.50s/it]                                                    {'loss': 0.0243, 'grad_norm': 2.1575701236724854, 'learning_rate': 4.644915254237288e-05, 'epoch': 0.09}
  9%|â–Š         | 519/6000 [30:27<5:20:02,  3.50s/it]  9%|â–Š         | 520/6000 [30:31<5:25:23,  3.56s/it]                                                    {'loss': 0.1994, 'grad_norm': 4.875452041625977, 'learning_rate': 4.64406779661017e-05, 'epoch': 0.09}
  9%|â–Š         | 520/6000 [30:31<5:25:23,  3.56s/it]  9%|â–Š         | 521/6000 [30:34<5:21:25,  3.52s/it]                                                    {'loss': 0.1164, 'grad_norm': 5.385178089141846, 'learning_rate': 4.643220338983051e-05, 'epoch': 0.09}
  9%|â–Š         | 521/6000 [30:34<5:21:25,  3.52s/it]  9%|â–Š         | 522/6000 [30:38<5:17:47,  3.48s/it]                                                    {'loss': 0.0038, 'grad_norm': 0.30097249150276184, 'learning_rate': 4.642372881355933e-05, 'epoch': 0.09}
  9%|â–Š         | 522/6000 [30:38<5:17:47,  3.48s/it]  9%|â–Š         | 523/6000 [30:41<5:18:26,  3.49s/it]                                                    {'loss': 0.0087, 'grad_norm': 0.6547417640686035, 'learning_rate': 4.641525423728814e-05, 'epoch': 0.09}
  9%|â–Š         | 523/6000 [30:41<5:18:26,  3.49s/it]  9%|â–Š         | 524/6000 [30:45<5:16:10,  3.46s/it]                                                    {'loss': 0.1716, 'grad_norm': 6.304707050323486, 'learning_rate': 4.640677966101695e-05, 'epoch': 0.09}
  9%|â–Š         | 524/6000 [30:45<5:16:10,  3.46s/it]  9%|â–‰         | 525/6000 [30:48<5:14:30,  3.45s/it]                                                    {'loss': 0.0871, 'grad_norm': 3.7048511505126953, 'learning_rate': 4.639830508474576e-05, 'epoch': 0.09}
  9%|â–‰         | 525/6000 [30:48<5:14:30,  3.45s/it]  9%|â–‰         | 526/6000 [30:52<5:13:53,  3.44s/it]                                                    {'loss': 0.0463, 'grad_norm': 2.5299036502838135, 'learning_rate': 4.638983050847458e-05, 'epoch': 0.09}
  9%|â–‰         | 526/6000 [30:52<5:13:53,  3.44s/it]  9%|â–‰         | 527/6000 [30:55<5:15:26,  3.46s/it]                                                    {'loss': 0.0371, 'grad_norm': 2.9653756618499756, 'learning_rate': 4.638135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 527/6000 [30:55<5:15:26,  3.46s/it]  9%|â–‰         | 528/6000 [30:59<5:18:23,  3.49s/it]                                                    {'loss': 0.0762, 'grad_norm': 3.452540636062622, 'learning_rate': 4.637288135593221e-05, 'epoch': 0.09}
  9%|â–‰         | 528/6000 [30:59<5:18:23,  3.49s/it]  9%|â–‰         | 529/6000 [31:02<5:16:26,  3.47s/it]                                                    {'loss': 0.0036, 'grad_norm': 0.41466060280799866, 'learning_rate': 4.636440677966102e-05, 'epoch': 0.09}
  9%|â–‰         | 529/6000 [31:02<5:16:26,  3.47s/it]  9%|â–‰         | 530/6000 [31:06<5:16:41,  3.47s/it]                                                    {'loss': 0.0217, 'grad_norm': 1.7117072343826294, 'learning_rate': 4.635593220338984e-05, 'epoch': 0.09}
  9%|â–‰         | 530/6000 [31:06<5:16:41,  3.47s/it]  9%|â–‰         | 531/6000 [31:09<5:14:48,  3.45s/it]                                                    {'loss': 0.1103, 'grad_norm': 5.008113384246826, 'learning_rate': 4.634745762711864e-05, 'epoch': 0.09}
  9%|â–‰         | 531/6000 [31:09<5:14:48,  3.45s/it]  9%|â–‰         | 532/6000 [31:12<5:16:38,  3.47s/it]                                                    {'loss': 0.07, 'grad_norm': 4.731034278869629, 'learning_rate': 4.633898305084746e-05, 'epoch': 0.09}
  9%|â–‰         | 532/6000 [31:13<5:16:38,  3.47s/it]  9%|â–‰         | 533/6000 [31:16<5:11:30,  3.42s/it]                                                    {'loss': 0.0472, 'grad_norm': 3.1504905223846436, 'learning_rate': 4.633050847457627e-05, 'epoch': 0.09}
  9%|â–‰         | 533/6000 [31:16<5:11:30,  3.42s/it]  9%|â–‰         | 534/6000 [31:19<5:15:38,  3.46s/it]                                                    {'loss': 0.0116, 'grad_norm': 0.9923304319381714, 'learning_rate': 4.632203389830509e-05, 'epoch': 0.09}
  9%|â–‰         | 534/6000 [31:19<5:15:38,  3.46s/it]  9%|â–‰         | 535/6000 [31:23<5:16:48,  3.48s/it]                                                    {'loss': 0.001, 'grad_norm': 0.08772506564855576, 'learning_rate': 4.63135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 535/6000 [31:23<5:16:48,  3.48s/it]  9%|â–‰         | 536/6000 [31:26<5:16:18,  3.47s/it]                                                    {'loss': 0.245, 'grad_norm': 6.227721214294434, 'learning_rate': 4.630508474576272e-05, 'epoch': 0.09}
  9%|â–‰         | 536/6000 [31:26<5:16:18,  3.47s/it]  9%|â–‰         | 537/6000 [31:30<5:15:12,  3.46s/it]                                                    {'loss': 0.0206, 'grad_norm': 1.4537460803985596, 'learning_rate': 4.629661016949153e-05, 'epoch': 0.09}
  9%|â–‰         | 537/6000 [31:30<5:15:12,  3.46s/it]  9%|â–‰         | 538/6000 [31:33<5:13:13,  3.44s/it]                                                    {'loss': 0.0183, 'grad_norm': 1.4930566549301147, 'learning_rate': 4.628813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 538/6000 [31:33<5:13:13,  3.44s/it]  9%|â–‰         | 539/6000 [31:37<5:10:53,  3.42s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.03547808527946472, 'learning_rate': 4.627966101694915e-05, 'epoch': 0.09}
  9%|â–‰         | 539/6000 [31:37<5:10:53,  3.42s/it]  9%|â–‰         | 540/6000 [31:40<5:09:21,  3.40s/it]                                                    {'loss': 0.0576, 'grad_norm': 3.45841121673584, 'learning_rate': 4.6271186440677964e-05, 'epoch': 0.09}
  9%|â–‰         | 540/6000 [31:40<5:09:21,  3.40s/it]  9%|â–‰         | 541/6000 [31:43<5:12:31,  3.43s/it]                                                    {'loss': 0.0422, 'grad_norm': 3.2147819995880127, 'learning_rate': 4.626271186440678e-05, 'epoch': 0.09}
  9%|â–‰         | 541/6000 [31:43<5:12:31,  3.43s/it]  9%|â–‰         | 542/6000 [31:47<5:11:55,  3.43s/it]                                                    {'loss': 0.0191, 'grad_norm': 1.8540149927139282, 'learning_rate': 4.6254237288135594e-05, 'epoch': 0.09}
  9%|â–‰         | 542/6000 [31:47<5:11:55,  3.43s/it]  9%|â–‰         | 543/6000 [31:50<5:11:36,  3.43s/it]                                                    {'loss': 0.1208, 'grad_norm': 5.450295448303223, 'learning_rate': 4.624576271186441e-05, 'epoch': 0.09}
  9%|â–‰         | 543/6000 [31:50<5:11:36,  3.43s/it]  9%|â–‰         | 544/6000 [31:54<5:10:41,  3.42s/it]                                                    {'loss': 0.109, 'grad_norm': 5.684929370880127, 'learning_rate': 4.623728813559322e-05, 'epoch': 0.09}
  9%|â–‰         | 544/6000 [31:54<5:10:41,  3.42s/it]  9%|â–‰         | 545/6000 [31:57<5:12:03,  3.43s/it]                                                    {'loss': 0.116, 'grad_norm': 5.842057704925537, 'learning_rate': 4.6228813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 545/6000 [31:57<5:12:03,  3.43s/it]  9%|â–‰         | 546/6000 [32:01<5:13:35,  3.45s/it]                                                    {'loss': 0.0512, 'grad_norm': 2.776611566543579, 'learning_rate': 4.6220338983050846e-05, 'epoch': 0.09}
  9%|â–‰         | 546/6000 [32:01<5:13:35,  3.45s/it]  9%|â–‰         | 547/6000 [32:04<5:16:42,  3.48s/it]                                                    {'loss': 0.0234, 'grad_norm': 2.2203872203826904, 'learning_rate': 4.6211864406779664e-05, 'epoch': 0.09}
  9%|â–‰         | 547/6000 [32:04<5:16:42,  3.48s/it]  9%|â–‰         | 548/6000 [32:08<5:19:15,  3.51s/it]                                                    {'loss': 0.0092, 'grad_norm': 0.593610405921936, 'learning_rate': 4.6203389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 548/6000 [32:08<5:19:15,  3.51s/it]  9%|â–‰         | 549/6000 [32:11<5:15:28,  3.47s/it]                                                    {'loss': 0.0573, 'grad_norm': 3.096975088119507, 'learning_rate': 4.619491525423729e-05, 'epoch': 0.09}
  9%|â–‰         | 549/6000 [32:11<5:15:28,  3.47s/it]  9%|â–‰         | 550/6000 [32:15<5:13:52,  3.46s/it]                                                    {'loss': 0.2213, 'grad_norm': 5.146905899047852, 'learning_rate': 4.6186440677966104e-05, 'epoch': 0.09}
  9%|â–‰         | 550/6000 [32:15<5:13:52,  3.46s/it][2025-10-21 01:56:37,278] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  9%|â–‰         | 551/6000 [32:21<6:37:45,  4.38s/it]                                                    {'loss': 0.0332, 'grad_norm': 2.5956969261169434, 'learning_rate': 4.617796610169492e-05, 'epoch': 0.09}
  9%|â–‰         | 551/6000 [32:21<6:37:45,  4.38s/it]  9%|â–‰         | 552/6000 [32:25<6:13:47,  4.12s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.04774709418416023, 'learning_rate': 4.6169491525423734e-05, 'epoch': 0.09}
  9%|â–‰         | 552/6000 [32:25<6:13:47,  4.12s/it]  9%|â–‰         | 553/6000 [32:28<5:58:31,  3.95s/it]                                                    {'loss': 0.1368, 'grad_norm': 4.565439224243164, 'learning_rate': 4.6161016949152545e-05, 'epoch': 0.09}
  9%|â–‰         | 553/6000 [32:28<5:58:31,  3.95s/it]  9%|â–‰         | 554/6000 [32:31<5:42:13,  3.77s/it]                                                    {'loss': 0.2398, 'grad_norm': 5.767665863037109, 'learning_rate': 4.6152542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 554/6000 [32:31<5:42:13,  3.77s/it]  9%|â–‰         | 555/6000 [32:35<5:31:21,  3.65s/it]                                                    {'loss': 0.0516, 'grad_norm': 2.7338144779205322, 'learning_rate': 4.6144067796610174e-05, 'epoch': 0.09}
  9%|â–‰         | 555/6000 [32:35<5:31:21,  3.65s/it]  9%|â–‰         | 556/6000 [32:38<5:23:35,  3.57s/it]                                                    {'loss': 0.0331, 'grad_norm': 1.2913979291915894, 'learning_rate': 4.6135593220338986e-05, 'epoch': 0.09}
  9%|â–‰         | 556/6000 [32:38<5:23:35,  3.57s/it]  9%|â–‰         | 557/6000 [32:42<5:19:17,  3.52s/it]                                                    {'loss': 0.0699, 'grad_norm': 2.8816752433776855, 'learning_rate': 4.6127118644067804e-05, 'epoch': 0.09}
  9%|â–‰         | 557/6000 [32:42<5:19:17,  3.52s/it]  9%|â–‰         | 558/6000 [32:45<5:17:52,  3.50s/it]                                                    {'loss': 0.1164, 'grad_norm': 6.080080986022949, 'learning_rate': 4.6118644067796615e-05, 'epoch': 0.09}
  9%|â–‰         | 558/6000 [32:45<5:17:52,  3.50s/it]  9%|â–‰         | 559/6000 [32:49<5:20:03,  3.53s/it]                                                    {'loss': 0.0196, 'grad_norm': 1.184882640838623, 'learning_rate': 4.6110169491525426e-05, 'epoch': 0.09}
  9%|â–‰         | 559/6000 [32:49<5:20:03,  3.53s/it]  9%|â–‰         | 560/6000 [32:52<5:18:15,  3.51s/it]                                                    {'loss': 0.2161, 'grad_norm': 6.4651713371276855, 'learning_rate': 4.610169491525424e-05, 'epoch': 0.09}
  9%|â–‰         | 560/6000 [32:52<5:18:15,  3.51s/it]  9%|â–‰         | 561/6000 [32:56<5:30:27,  3.65s/it]                                                    {'loss': 0.0411, 'grad_norm': 2.5995914936065674, 'learning_rate': 4.609322033898305e-05, 'epoch': 0.09}
  9%|â–‰         | 561/6000 [32:56<5:30:27,  3.65s/it]  9%|â–‰         | 562/6000 [32:59<5:23:20,  3.57s/it]                                                    {'loss': 0.2954, 'grad_norm': 5.967742443084717, 'learning_rate': 4.608474576271187e-05, 'epoch': 0.09}
  9%|â–‰         | 562/6000 [33:00<5:23:20,  3.57s/it]  9%|â–‰         | 563/6000 [33:03<5:19:36,  3.53s/it]                                                    {'loss': 0.0149, 'grad_norm': 1.0441755056381226, 'learning_rate': 4.607627118644068e-05, 'epoch': 0.09}
  9%|â–‰         | 563/6000 [33:03<5:19:36,  3.53s/it]  9%|â–‰         | 564/6000 [33:06<5:16:27,  3.49s/it]                                                    {'loss': 0.0042, 'grad_norm': 0.21991094946861267, 'learning_rate': 4.6067796610169496e-05, 'epoch': 0.09}
  9%|â–‰         | 564/6000 [33:06<5:16:27,  3.49s/it]  9%|â–‰         | 565/6000 [33:10<5:20:17,  3.54s/it]                                                    {'loss': 0.0221, 'grad_norm': 1.165740728378296, 'learning_rate': 4.605932203389831e-05, 'epoch': 0.09}
  9%|â–‰         | 565/6000 [33:10<5:20:17,  3.54s/it]  9%|â–‰         | 566/6000 [33:13<5:15:55,  3.49s/it]                                                    {'loss': 0.0298, 'grad_norm': 2.365983247756958, 'learning_rate': 4.605084745762712e-05, 'epoch': 0.09}
  9%|â–‰         | 566/6000 [33:13<5:15:55,  3.49s/it]  9%|â–‰         | 567/6000 [33:17<5:26:20,  3.60s/it]                                                    {'loss': 0.0309, 'grad_norm': 1.4925917387008667, 'learning_rate': 4.604237288135593e-05, 'epoch': 0.09}
  9%|â–‰         | 567/6000 [33:17<5:26:20,  3.60s/it]  9%|â–‰         | 568/6000 [33:21<5:22:52,  3.57s/it]                                                    {'loss': 0.0528, 'grad_norm': 1.2838069200515747, 'learning_rate': 4.603389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 568/6000 [33:21<5:22:52,  3.57s/it]  9%|â–‰         | 569/6000 [33:24<5:21:12,  3.55s/it]                                                    {'loss': 0.0008, 'grad_norm': 0.03808972239494324, 'learning_rate': 4.602542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 569/6000 [33:24<5:21:12,  3.55s/it] 10%|â–‰         | 570/6000 [33:28<5:18:02,  3.51s/it]                                                    {'loss': 0.0747, 'grad_norm': 2.280022621154785, 'learning_rate': 4.601694915254238e-05, 'epoch': 0.1}
 10%|â–‰         | 570/6000 [33:28<5:18:02,  3.51s/it] 10%|â–‰         | 571/6000 [33:32<5:52:20,  3.89s/it]                                                    {'loss': 0.0238, 'grad_norm': 2.5707733631134033, 'learning_rate': 4.600847457627119e-05, 'epoch': 0.1}
 10%|â–‰         | 571/6000 [33:32<5:52:20,  3.89s/it] 10%|â–‰         | 572/6000 [33:36<5:45:25,  3.82s/it]                                                    {'loss': 0.2675, 'grad_norm': 4.674154281616211, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.1}
 10%|â–‰         | 572/6000 [33:36<5:45:25,  3.82s/it] 10%|â–‰         | 573/6000 [33:39<5:34:08,  3.69s/it]                                                    {'loss': 0.183, 'grad_norm': 4.83967924118042, 'learning_rate': 4.599152542372882e-05, 'epoch': 0.1}
 10%|â–‰         | 573/6000 [33:39<5:34:08,  3.69s/it] 10%|â–‰         | 574/6000 [33:43<5:28:47,  3.64s/it]                                                    {'loss': 0.3798, 'grad_norm': 7.933138370513916, 'learning_rate': 4.598305084745763e-05, 'epoch': 0.1}
 10%|â–‰         | 574/6000 [33:43<5:28:47,  3.64s/it] 10%|â–‰         | 575/6000 [33:46<5:22:51,  3.57s/it]                                                    {'loss': 0.0293, 'grad_norm': 2.3702926635742188, 'learning_rate': 4.597457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 575/6000 [33:46<5:22:51,  3.57s/it] 10%|â–‰         | 576/6000 [33:50<5:23:02,  3.57s/it]                                                    {'loss': 0.0916, 'grad_norm': 4.281789779663086, 'learning_rate': 4.596610169491526e-05, 'epoch': 0.1}
 10%|â–‰         | 576/6000 [33:50<5:23:02,  3.57s/it] 10%|â–‰         | 577/6000 [33:54<5:24:48,  3.59s/it]                                                    {'loss': 0.0617, 'grad_norm': 1.7977313995361328, 'learning_rate': 4.595762711864407e-05, 'epoch': 0.1}
 10%|â–‰         | 577/6000 [33:54<5:24:48,  3.59s/it] 10%|â–‰         | 578/6000 [33:58<5:38:38,  3.75s/it]                                                    {'loss': 0.2066, 'grad_norm': 5.068265438079834, 'learning_rate': 4.594915254237288e-05, 'epoch': 0.1}
 10%|â–‰         | 578/6000 [33:58<5:38:38,  3.75s/it] 10%|â–‰         | 579/6000 [34:02<5:43:16,  3.80s/it]                                                    {'loss': 0.0158, 'grad_norm': 0.8900983929634094, 'learning_rate': 4.59406779661017e-05, 'epoch': 0.1}
 10%|â–‰         | 579/6000 [34:02<5:43:16,  3.80s/it] 10%|â–‰         | 580/6000 [34:05<5:33:30,  3.69s/it]                                                    {'loss': 0.1406, 'grad_norm': 4.959125518798828, 'learning_rate': 4.593220338983051e-05, 'epoch': 0.1}
 10%|â–‰         | 580/6000 [34:05<5:33:30,  3.69s/it] 10%|â–‰         | 581/6000 [34:10<5:53:49,  3.92s/it]                                                    {'loss': 0.3514, 'grad_norm': 5.845571994781494, 'learning_rate': 4.592372881355932e-05, 'epoch': 0.1}
 10%|â–‰         | 581/6000 [34:10<5:53:49,  3.92s/it] 10%|â–‰         | 582/6000 [34:14<6:08:55,  4.09s/it]                                                    {'loss': 0.1447, 'grad_norm': 5.8112993240356445, 'learning_rate': 4.591525423728813e-05, 'epoch': 0.1}
 10%|â–‰         | 582/6000 [34:14<6:08:55,  4.09s/it] 10%|â–‰         | 583/6000 [34:18<5:53:01,  3.91s/it]                                                    {'loss': 0.0317, 'grad_norm': 2.312955379486084, 'learning_rate': 4.590677966101695e-05, 'epoch': 0.1}
 10%|â–‰         | 583/6000 [34:18<5:53:01,  3.91s/it] 10%|â–‰         | 584/6000 [34:21<5:41:40,  3.79s/it]                                                    {'loss': 0.4019, 'grad_norm': 6.253690719604492, 'learning_rate': 4.589830508474576e-05, 'epoch': 0.1}
 10%|â–‰         | 584/6000 [34:21<5:41:40,  3.79s/it] 10%|â–‰         | 585/6000 [34:25<5:49:18,  3.87s/it]                                                    {'loss': 0.0035, 'grad_norm': 0.263307124376297, 'learning_rate': 4.588983050847458e-05, 'epoch': 0.1}
 10%|â–‰         | 585/6000 [34:25<5:49:18,  3.87s/it] 10%|â–‰         | 586/6000 [34:28<5:36:54,  3.73s/it]                                                    {'loss': 0.0967, 'grad_norm': 4.991135120391846, 'learning_rate': 4.588135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 586/6000 [34:28<5:36:54,  3.73s/it] 10%|â–‰         | 587/6000 [34:32<5:26:23,  3.62s/it]                                                    {'loss': 0.0395, 'grad_norm': 1.2009292840957642, 'learning_rate': 4.587288135593221e-05, 'epoch': 0.1}
 10%|â–‰         | 587/6000 [34:32<5:26:23,  3.62s/it] 10%|â–‰         | 588/6000 [34:35<5:21:21,  3.56s/it]                                                    {'loss': 0.0118, 'grad_norm': 1.394008755683899, 'learning_rate': 4.5864406779661014e-05, 'epoch': 0.1}
 10%|â–‰         | 588/6000 [34:35<5:21:21,  3.56s/it] 10%|â–‰         | 589/6000 [34:39<5:18:59,  3.54s/it]                                                    {'loss': 0.0121, 'grad_norm': 0.6964139938354492, 'learning_rate': 4.585593220338983e-05, 'epoch': 0.1}
 10%|â–‰         | 589/6000 [34:39<5:18:59,  3.54s/it] 10%|â–‰         | 590/6000 [34:42<5:19:15,  3.54s/it]                                                    {'loss': 0.0603, 'grad_norm': 2.3536925315856934, 'learning_rate': 4.5847457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 590/6000 [34:42<5:19:15,  3.54s/it] 10%|â–‰         | 591/6000 [34:46<5:17:35,  3.52s/it]                                                    {'loss': 0.1385, 'grad_norm': 4.437182903289795, 'learning_rate': 4.583898305084746e-05, 'epoch': 0.1}
 10%|â–‰         | 591/6000 [34:46<5:17:35,  3.52s/it] 10%|â–‰         | 592/6000 [34:49<5:16:01,  3.51s/it]                                                    {'loss': 0.0793, 'grad_norm': 3.8874077796936035, 'learning_rate': 4.583050847457627e-05, 'epoch': 0.1}
 10%|â–‰         | 592/6000 [34:49<5:16:01,  3.51s/it] 10%|â–‰         | 593/6000 [34:53<5:16:00,  3.51s/it]                                                    {'loss': 0.0935, 'grad_norm': 6.679950714111328, 'learning_rate': 4.582203389830509e-05, 'epoch': 0.1}
 10%|â–‰         | 593/6000 [34:53<5:16:00,  3.51s/it] 10%|â–‰         | 594/6000 [34:56<5:16:21,  3.51s/it]                                                    {'loss': 0.0672, 'grad_norm': 4.456610202789307, 'learning_rate': 4.58135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 594/6000 [34:56<5:16:21,  3.51s/it] 10%|â–‰         | 595/6000 [35:00<5:22:14,  3.58s/it]                                                    {'loss': 0.0632, 'grad_norm': 2.522118091583252, 'learning_rate': 4.5805084745762714e-05, 'epoch': 0.1}
 10%|â–‰         | 595/6000 [35:00<5:22:14,  3.58s/it] 10%|â–‰         | 596/6000 [35:04<5:45:02,  3.83s/it]                                                    {'loss': 0.0914, 'grad_norm': 2.470399856567383, 'learning_rate': 4.5796610169491525e-05, 'epoch': 0.1}
 10%|â–‰         | 596/6000 [35:04<5:45:02,  3.83s/it] 10%|â–‰         | 597/6000 [35:08<5:32:22,  3.69s/it]                                                    {'loss': 0.0666, 'grad_norm': 3.049970865249634, 'learning_rate': 4.578813559322034e-05, 'epoch': 0.1}
 10%|â–‰         | 597/6000 [35:08<5:32:22,  3.69s/it] 10%|â–‰         | 598/6000 [35:11<5:24:16,  3.60s/it]                                                    {'loss': 0.0439, 'grad_norm': 3.4192333221435547, 'learning_rate': 4.5779661016949154e-05, 'epoch': 0.1}
 10%|â–‰         | 598/6000 [35:11<5:24:16,  3.60s/it] 10%|â–‰         | 599/6000 [35:15<5:17:20,  3.53s/it]                                                    {'loss': 0.0471, 'grad_norm': 2.331439256668091, 'learning_rate': 4.5771186440677966e-05, 'epoch': 0.1}
 10%|â–‰         | 599/6000 [35:15<5:17:20,  3.53s/it] 10%|â–ˆ         | 600/6000 [35:18<5:14:46,  3.50s/it]                                                    {'loss': 0.0707, 'grad_norm': 4.393772602081299, 'learning_rate': 4.5762711864406784e-05, 'epoch': 0.1}
 10%|â–ˆ         | 600/6000 [35:18<5:14:46,  3.50s/it][2025-10-21 01:59:40,712] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 10%|â–ˆ         | 601/6000 [35:24<6:10:20,  4.12s/it]                                                    {'loss': 0.16, 'grad_norm': 4.952543258666992, 'learning_rate': 4.5754237288135595e-05, 'epoch': 0.1}
 10%|â–ˆ         | 601/6000 [35:24<6:10:20,  4.12s/it] 10%|â–ˆ         | 602/6000 [35:27<5:52:53,  3.92s/it]                                                    {'loss': 0.0353, 'grad_norm': 2.3390438556671143, 'learning_rate': 4.5745762711864406e-05, 'epoch': 0.1}
 10%|â–ˆ         | 602/6000 [35:27<5:52:53,  3.92s/it] 10%|â–ˆ         | 603/6000 [35:30<5:39:33,  3.78s/it]                                                    {'loss': 0.2545, 'grad_norm': 6.834041118621826, 'learning_rate': 4.573728813559322e-05, 'epoch': 0.1}
 10%|â–ˆ         | 603/6000 [35:30<5:39:33,  3.78s/it] 10%|â–ˆ         | 604/6000 [35:34<5:46:38,  3.85s/it]                                                    {'loss': 0.1046, 'grad_norm': 4.161561489105225, 'learning_rate': 4.5728813559322036e-05, 'epoch': 0.1}
 10%|â–ˆ         | 604/6000 [35:34<5:46:38,  3.85s/it] 10%|â–ˆ         | 605/6000 [35:38<5:34:39,  3.72s/it]                                                    {'loss': 0.0832, 'grad_norm': 2.6460936069488525, 'learning_rate': 4.572033898305085e-05, 'epoch': 0.1}
 10%|â–ˆ         | 605/6000 [35:38<5:34:39,  3.72s/it] 10%|â–ˆ         | 606/6000 [35:41<5:29:29,  3.67s/it]                                                    {'loss': 0.0118, 'grad_norm': 0.8724308609962463, 'learning_rate': 4.5711864406779665e-05, 'epoch': 0.1}
 10%|â–ˆ         | 606/6000 [35:41<5:29:29,  3.67s/it] 10%|â–ˆ         | 607/6000 [35:45<5:21:51,  3.58s/it]                                                    {'loss': 0.0222, 'grad_norm': 1.4751336574554443, 'learning_rate': 4.5703389830508476e-05, 'epoch': 0.1}
 10%|â–ˆ         | 607/6000 [35:45<5:21:51,  3.58s/it] 10%|â–ˆ         | 608/6000 [35:48<5:19:54,  3.56s/it]                                                    {'loss': 0.1115, 'grad_norm': 4.819445610046387, 'learning_rate': 4.5694915254237294e-05, 'epoch': 0.1}
 10%|â–ˆ         | 608/6000 [35:48<5:19:54,  3.56s/it] 10%|â–ˆ         | 609/6000 [35:52<5:17:55,  3.54s/it]                                                    {'loss': 0.0939, 'grad_norm': 3.0388193130493164, 'learning_rate': 4.5686440677966106e-05, 'epoch': 0.1}
 10%|â–ˆ         | 609/6000 [35:52<5:17:55,  3.54s/it] 10%|â–ˆ         | 610/6000 [35:55<5:15:49,  3.52s/it]                                                    {'loss': 0.0488, 'grad_norm': 3.421931028366089, 'learning_rate': 4.567796610169492e-05, 'epoch': 0.1}
 10%|â–ˆ         | 610/6000 [35:55<5:15:49,  3.52s/it] 10%|â–ˆ         | 611/6000 [35:59<5:13:49,  3.49s/it]                                                    {'loss': 0.268, 'grad_norm': 6.766096115112305, 'learning_rate': 4.566949152542373e-05, 'epoch': 0.1}
 10%|â–ˆ         | 611/6000 [35:59<5:13:49,  3.49s/it] 10%|â–ˆ         | 612/6000 [36:02<5:16:45,  3.53s/it]                                                    {'loss': 0.0542, 'grad_norm': 2.2629282474517822, 'learning_rate': 4.5661016949152546e-05, 'epoch': 0.1}
 10%|â–ˆ         | 612/6000 [36:02<5:16:45,  3.53s/it] 10%|â–ˆ         | 613/6000 [36:06<5:17:08,  3.53s/it]                                                    {'loss': 0.0952, 'grad_norm': 3.266934871673584, 'learning_rate': 4.565254237288136e-05, 'epoch': 0.1}
 10%|â–ˆ         | 613/6000 [36:06<5:17:08,  3.53s/it] 10%|â–ˆ         | 614/6000 [36:09<5:13:36,  3.49s/it]                                                    {'loss': 0.009, 'grad_norm': 0.5139716863632202, 'learning_rate': 4.5644067796610176e-05, 'epoch': 0.1}
 10%|â–ˆ         | 614/6000 [36:09<5:13:36,  3.49s/it] 10%|â–ˆ         | 615/6000 [36:13<5:13:46,  3.50s/it]                                                    {'loss': 0.1446, 'grad_norm': 5.303433895111084, 'learning_rate': 4.563559322033899e-05, 'epoch': 0.1}
 10%|â–ˆ         | 615/6000 [36:13<5:13:46,  3.50s/it] 10%|â–ˆ         | 616/6000 [36:16<5:11:17,  3.47s/it]                                                    {'loss': 0.0848, 'grad_norm': 2.2978968620300293, 'learning_rate': 4.56271186440678e-05, 'epoch': 0.1}
 10%|â–ˆ         | 616/6000 [36:16<5:11:17,  3.47s/it] 10%|â–ˆ         | 617/6000 [36:20<5:09:56,  3.45s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.2904808819293976, 'learning_rate': 4.561864406779661e-05, 'epoch': 0.1}
 10%|â–ˆ         | 617/6000 [36:20<5:09:56,  3.45s/it] 10%|â–ˆ         | 618/6000 [36:23<5:07:52,  3.43s/it]                                                    {'loss': 0.0496, 'grad_norm': 1.7457492351531982, 'learning_rate': 4.561016949152543e-05, 'epoch': 0.1}
 10%|â–ˆ         | 618/6000 [36:23<5:07:52,  3.43s/it] 10%|â–ˆ         | 619/6000 [36:26<5:05:19,  3.40s/it]                                                    {'loss': 0.0515, 'grad_norm': 2.9003660678863525, 'learning_rate': 4.560169491525424e-05, 'epoch': 0.1}
 10%|â–ˆ         | 619/6000 [36:26<5:05:19,  3.40s/it] 10%|â–ˆ         | 620/6000 [36:30<5:05:15,  3.40s/it]                                                    {'loss': 0.0373, 'grad_norm': 2.053863763809204, 'learning_rate': 4.559322033898305e-05, 'epoch': 0.1}
 10%|â–ˆ         | 620/6000 [36:30<5:05:15,  3.40s/it] 10%|â–ˆ         | 621/6000 [36:33<5:04:02,  3.39s/it]                                                    {'loss': 0.0539, 'grad_norm': 2.701911449432373, 'learning_rate': 4.558474576271187e-05, 'epoch': 0.1}
 10%|â–ˆ         | 621/6000 [36:33<5:04:02,  3.39s/it] 10%|â–ˆ         | 622/6000 [36:36<5:03:00,  3.38s/it]                                                    {'loss': 0.2762, 'grad_norm': 6.928140640258789, 'learning_rate': 4.557627118644068e-05, 'epoch': 0.1}
 10%|â–ˆ         | 622/6000 [36:36<5:03:00,  3.38s/it] 10%|â–ˆ         | 623/6000 [36:40<5:03:12,  3.38s/it]                                                    {'loss': 0.1868, 'grad_norm': 4.741581439971924, 'learning_rate': 4.556779661016949e-05, 'epoch': 0.1}
 10%|â–ˆ         | 623/6000 [36:40<5:03:12,  3.38s/it] 10%|â–ˆ         | 624/6000 [36:43<5:02:57,  3.38s/it]                                                    {'loss': 0.1737, 'grad_norm': 5.301878929138184, 'learning_rate': 4.55593220338983e-05, 'epoch': 0.1}
 10%|â–ˆ         | 624/6000 [36:43<5:02:57,  3.38s/it] 10%|â–ˆ         | 625/6000 [36:47<5:10:51,  3.47s/it]                                                    {'loss': 0.012, 'grad_norm': 1.1845625638961792, 'learning_rate': 4.555084745762712e-05, 'epoch': 0.1}
 10%|â–ˆ         | 625/6000 [36:47<5:10:51,  3.47s/it] 10%|â–ˆ         | 626/6000 [36:50<5:08:38,  3.45s/it]                                                    {'loss': 0.0567, 'grad_norm': 2.181432008743286, 'learning_rate': 4.554237288135593e-05, 'epoch': 0.1}
 10%|â–ˆ         | 626/6000 [36:50<5:08:38,  3.45s/it] 10%|â–ˆ         | 627/6000 [36:55<5:30:17,  3.69s/it]                                                    {'loss': 0.0204, 'grad_norm': 0.9796188473701477, 'learning_rate': 4.553389830508475e-05, 'epoch': 0.1}
 10%|â–ˆ         | 627/6000 [36:55<5:30:17,  3.69s/it] 10%|â–ˆ         | 628/6000 [36:58<5:23:37,  3.61s/it]                                                    {'loss': 0.2109, 'grad_norm': 5.777804851531982, 'learning_rate': 4.552542372881356e-05, 'epoch': 0.1}
 10%|â–ˆ         | 628/6000 [36:58<5:23:37,  3.61s/it] 10%|â–ˆ         | 629/6000 [37:01<5:15:49,  3.53s/it]                                                    {'loss': 0.016, 'grad_norm': 1.0426925420761108, 'learning_rate': 4.551694915254238e-05, 'epoch': 0.1}
 10%|â–ˆ         | 629/6000 [37:01<5:15:49,  3.53s/it] 10%|â–ˆ         | 630/6000 [37:05<5:12:21,  3.49s/it]                                                    {'loss': 0.4702, 'grad_norm': 7.700038909912109, 'learning_rate': 4.550847457627119e-05, 'epoch': 0.1}
 10%|â–ˆ         | 630/6000 [37:05<5:12:21,  3.49s/it] 11%|â–ˆ         | 631/6000 [37:08<5:11:59,  3.49s/it]                                                    {'loss': 0.1096, 'grad_norm': 3.9063374996185303, 'learning_rate': 4.55e-05, 'epoch': 0.11}
 11%|â–ˆ         | 631/6000 [37:08<5:11:59,  3.49s/it] 11%|â–ˆ         | 632/6000 [37:12<5:12:43,  3.50s/it]                                                    {'loss': 0.0828, 'grad_norm': 3.1882805824279785, 'learning_rate': 4.549152542372881e-05, 'epoch': 0.11}
 11%|â–ˆ         | 632/6000 [37:12<5:12:43,  3.50s/it] 11%|â–ˆ         | 633/6000 [37:15<5:13:27,  3.50s/it]                                                    {'loss': 0.0525, 'grad_norm': 0.6463930606842041, 'learning_rate': 4.548305084745763e-05, 'epoch': 0.11}
 11%|â–ˆ         | 633/6000 [37:15<5:13:27,  3.50s/it] 11%|â–ˆ         | 634/6000 [37:19<5:20:46,  3.59s/it]                                                    {'loss': 0.0129, 'grad_norm': 1.0119136571884155, 'learning_rate': 4.547457627118644e-05, 'epoch': 0.11}
 11%|â–ˆ         | 634/6000 [37:19<5:20:46,  3.59s/it] 11%|â–ˆ         | 635/6000 [37:23<5:21:30,  3.60s/it]                                                    {'loss': 0.0381, 'grad_norm': 2.4219558238983154, 'learning_rate': 4.546610169491526e-05, 'epoch': 0.11}
 11%|â–ˆ         | 635/6000 [37:23<5:21:30,  3.60s/it] 11%|â–ˆ         | 636/6000 [37:26<5:17:42,  3.55s/it]                                                    {'loss': 0.0089, 'grad_norm': 0.805315375328064, 'learning_rate': 4.545762711864407e-05, 'epoch': 0.11}
 11%|â–ˆ         | 636/6000 [37:26<5:17:42,  3.55s/it] 11%|â–ˆ         | 637/6000 [37:30<5:16:04,  3.54s/it]                                                    {'loss': 0.0153, 'grad_norm': 1.1912634372711182, 'learning_rate': 4.544915254237288e-05, 'epoch': 0.11}
 11%|â–ˆ         | 637/6000 [37:30<5:16:04,  3.54s/it] 11%|â–ˆ         | 638/6000 [37:34<5:27:42,  3.67s/it]                                                    {'loss': 0.0651, 'grad_norm': 2.41567063331604, 'learning_rate': 4.5440677966101694e-05, 'epoch': 0.11}
 11%|â–ˆ         | 638/6000 [37:34<5:27:42,  3.67s/it] 11%|â–ˆ         | 639/6000 [37:37<5:23:12,  3.62s/it]                                                    {'loss': 0.0281, 'grad_norm': 1.334113597869873, 'learning_rate': 4.543220338983051e-05, 'epoch': 0.11}
 11%|â–ˆ         | 639/6000 [37:37<5:23:12,  3.62s/it] 11%|â–ˆ         | 640/6000 [37:41<5:29:58,  3.69s/it]                                                    {'loss': 0.031, 'grad_norm': 1.3992652893066406, 'learning_rate': 4.542372881355932e-05, 'epoch': 0.11}
 11%|â–ˆ         | 640/6000 [37:41<5:29:58,  3.69s/it] 11%|â–ˆ         | 641/6000 [37:45<5:36:26,  3.77s/it]                                                    {'loss': 0.0071, 'grad_norm': 0.3959248960018158, 'learning_rate': 4.5415254237288135e-05, 'epoch': 0.11}
 11%|â–ˆ         | 641/6000 [37:45<5:36:26,  3.77s/it] 11%|â–ˆ         | 642/6000 [37:48<5:25:16,  3.64s/it]                                                    {'loss': 0.0323, 'grad_norm': 2.08837890625, 'learning_rate': 4.540677966101695e-05, 'epoch': 0.11}
 11%|â–ˆ         | 642/6000 [37:48<5:25:16,  3.64s/it] 11%|â–ˆ         | 643/6000 [37:52<5:19:02,  3.57s/it]                                                    {'loss': 0.0402, 'grad_norm': 1.8348616361618042, 'learning_rate': 4.5398305084745764e-05, 'epoch': 0.11}
 11%|â–ˆ         | 643/6000 [37:52<5:19:02,  3.57s/it] 11%|â–ˆ         | 644/6000 [37:55<5:16:15,  3.54s/it]                                                    {'loss': 0.0311, 'grad_norm': 2.342529296875, 'learning_rate': 4.538983050847458e-05, 'epoch': 0.11}
 11%|â–ˆ         | 644/6000 [37:55<5:16:15,  3.54s/it] 11%|â–ˆ         | 645/6000 [37:58<5:11:56,  3.50s/it]                                                    {'loss': 0.0704, 'grad_norm': 1.971527099609375, 'learning_rate': 4.5381355932203387e-05, 'epoch': 0.11}
 11%|â–ˆ         | 645/6000 [37:58<5:11:56,  3.50s/it] 11%|â–ˆ         | 646/6000 [38:02<5:20:41,  3.59s/it]                                                    {'loss': 0.0547, 'grad_norm': 3.396054267883301, 'learning_rate': 4.5372881355932205e-05, 'epoch': 0.11}
 11%|â–ˆ         | 646/6000 [38:02<5:20:41,  3.59s/it] 11%|â–ˆ         | 647/6000 [38:06<5:15:08,  3.53s/it]                                                    {'loss': 0.0875, 'grad_norm': 2.2892165184020996, 'learning_rate': 4.5364406779661016e-05, 'epoch': 0.11}
 11%|â–ˆ         | 647/6000 [38:06<5:15:08,  3.53s/it] 11%|â–ˆ         | 648/6000 [38:09<5:23:04,  3.62s/it]                                                    {'loss': 0.1057, 'grad_norm': 3.2314908504486084, 'learning_rate': 4.5355932203389834e-05, 'epoch': 0.11}
 11%|â–ˆ         | 648/6000 [38:09<5:23:04,  3.62s/it] 11%|â–ˆ         | 649/6000 [38:13<5:17:04,  3.56s/it]                                                    {'loss': 0.0312, 'grad_norm': 2.383615493774414, 'learning_rate': 4.5347457627118645e-05, 'epoch': 0.11}
 11%|â–ˆ         | 649/6000 [38:13<5:17:04,  3.56s/it] 11%|â–ˆ         | 650/6000 [38:16<5:11:13,  3.49s/it]                                                    {'loss': 0.1675, 'grad_norm': 4.287788391113281, 'learning_rate': 4.533898305084746e-05, 'epoch': 0.11}
 11%|â–ˆ         | 650/6000 [38:16<5:11:13,  3.49s/it][2025-10-21 02:02:38,985] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 11%|â–ˆ         | 651/6000 [38:22<6:03:10,  4.07s/it]                                                    {'loss': 0.12, 'grad_norm': 3.754066228866577, 'learning_rate': 4.5330508474576275e-05, 'epoch': 0.11}
 11%|â–ˆ         | 651/6000 [38:22<6:03:10,  4.07s/it] 11%|â–ˆ         | 652/6000 [38:25<5:54:42,  3.98s/it]                                                    {'loss': 0.0559, 'grad_norm': 3.4389138221740723, 'learning_rate': 4.5322033898305086e-05, 'epoch': 0.11}
 11%|â–ˆ         | 652/6000 [38:25<5:54:42,  3.98s/it] 11%|â–ˆ         | 653/6000 [38:29<5:43:04,  3.85s/it]                                                    {'loss': 0.1624, 'grad_norm': 3.356919527053833, 'learning_rate': 4.53135593220339e-05, 'epoch': 0.11}
 11%|â–ˆ         | 653/6000 [38:29<5:43:04,  3.85s/it] 11%|â–ˆ         | 654/6000 [38:32<5:30:12,  3.71s/it]                                                    {'loss': 0.0101, 'grad_norm': 0.5952651500701904, 'learning_rate': 4.5305084745762715e-05, 'epoch': 0.11}
 11%|â–ˆ         | 654/6000 [38:32<5:30:12,  3.71s/it] 11%|â–ˆ         | 655/6000 [38:36<5:20:25,  3.60s/it]                                                    {'loss': 0.0368, 'grad_norm': 1.2301650047302246, 'learning_rate': 4.5296610169491527e-05, 'epoch': 0.11}
 11%|â–ˆ         | 655/6000 [38:36<5:20:25,  3.60s/it] 11%|â–ˆ         | 656/6000 [38:39<5:15:36,  3.54s/it]                                                    {'loss': 0.1312, 'grad_norm': 4.224391460418701, 'learning_rate': 4.5288135593220345e-05, 'epoch': 0.11}
 11%|â–ˆ         | 656/6000 [38:39<5:15:36,  3.54s/it] 11%|â–ˆ         | 657/6000 [38:43<5:16:48,  3.56s/it]                                                    {'loss': 0.0496, 'grad_norm': 1.3645707368850708, 'learning_rate': 4.5279661016949156e-05, 'epoch': 0.11}
 11%|â–ˆ         | 657/6000 [38:43<5:16:48,  3.56s/it] 11%|â–ˆ         | 658/6000 [38:47<5:24:09,  3.64s/it]                                                    {'loss': 0.0058, 'grad_norm': 0.3881966173648834, 'learning_rate': 4.5271186440677974e-05, 'epoch': 0.11}
 11%|â–ˆ         | 658/6000 [38:47<5:24:09,  3.64s/it] 11%|â–ˆ         | 659/6000 [38:50<5:15:22,  3.54s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.03342761471867561, 'learning_rate': 4.526271186440678e-05, 'epoch': 0.11}
 11%|â–ˆ         | 659/6000 [38:50<5:15:22,  3.54s/it] 11%|â–ˆ         | 660/6000 [38:53<5:11:39,  3.50s/it]                                                    {'loss': 0.0198, 'grad_norm': 1.4813495874404907, 'learning_rate': 4.5254237288135596e-05, 'epoch': 0.11}
 11%|â–ˆ         | 660/6000 [38:53<5:11:39,  3.50s/it] 11%|â–ˆ         | 661/6000 [38:57<5:06:20,  3.44s/it]                                                    {'loss': 0.0112, 'grad_norm': 1.1190866231918335, 'learning_rate': 4.524576271186441e-05, 'epoch': 0.11}
 11%|â–ˆ         | 661/6000 [38:57<5:06:20,  3.44s/it] 11%|â–ˆ         | 662/6000 [39:00<5:06:08,  3.44s/it]                                                    {'loss': 0.0416, 'grad_norm': 1.3879438638687134, 'learning_rate': 4.523728813559322e-05, 'epoch': 0.11}
 11%|â–ˆ         | 662/6000 [39:00<5:06:08,  3.44s/it] 11%|â–ˆ         | 663/6000 [39:03<5:03:52,  3.42s/it]                                                    {'loss': 0.1641, 'grad_norm': 5.1051530838012695, 'learning_rate': 4.522881355932204e-05, 'epoch': 0.11}
 11%|â–ˆ         | 663/6000 [39:03<5:03:52,  3.42s/it] 11%|â–ˆ         | 664/6000 [39:07<5:05:35,  3.44s/it]                                                    {'loss': 0.0572, 'grad_norm': 3.2200379371643066, 'learning_rate': 4.522033898305085e-05, 'epoch': 0.11}
 11%|â–ˆ         | 664/6000 [39:07<5:05:35,  3.44s/it] 11%|â–ˆ         | 665/6000 [39:10<5:07:51,  3.46s/it]                                                    {'loss': 0.0713, 'grad_norm': 2.0236339569091797, 'learning_rate': 4.5211864406779666e-05, 'epoch': 0.11}
 11%|â–ˆ         | 665/6000 [39:10<5:07:51,  3.46s/it] 11%|â–ˆ         | 666/6000 [39:14<5:08:26,  3.47s/it]                                                    {'loss': 0.113, 'grad_norm': 4.104304313659668, 'learning_rate': 4.520338983050848e-05, 'epoch': 0.11}
 11%|â–ˆ         | 666/6000 [39:14<5:08:26,  3.47s/it] 11%|â–ˆ         | 667/6000 [39:17<5:09:35,  3.48s/it]                                                    {'loss': 0.1076, 'grad_norm': 3.0459725856781006, 'learning_rate': 4.519491525423729e-05, 'epoch': 0.11}
 11%|â–ˆ         | 667/6000 [39:17<5:09:35,  3.48s/it] 11%|â–ˆ         | 668/6000 [39:21<5:07:29,  3.46s/it]                                                    {'loss': 0.0791, 'grad_norm': 5.14306640625, 'learning_rate': 4.51864406779661e-05, 'epoch': 0.11}
 11%|â–ˆ         | 668/6000 [39:21<5:07:29,  3.46s/it] 11%|â–ˆ         | 669/6000 [39:24<5:04:10,  3.42s/it]                                                    {'loss': 0.0035, 'grad_norm': 0.16733112931251526, 'learning_rate': 4.517796610169492e-05, 'epoch': 0.11}
 11%|â–ˆ         | 669/6000 [39:24<5:04:10,  3.42s/it] 11%|â–ˆ         | 670/6000 [39:28<5:07:17,  3.46s/it]                                                    {'loss': 0.0434, 'grad_norm': 2.545315742492676, 'learning_rate': 4.516949152542373e-05, 'epoch': 0.11}
 11%|â–ˆ         | 670/6000 [39:28<5:07:17,  3.46s/it] 11%|â–ˆ         | 671/6000 [39:31<5:05:28,  3.44s/it]                                                    {'loss': 0.0348, 'grad_norm': 1.7896367311477661, 'learning_rate': 4.516101694915255e-05, 'epoch': 0.11}
 11%|â–ˆ         | 671/6000 [39:31<5:05:28,  3.44s/it] 11%|â–ˆ         | 672/6000 [39:34<5:02:25,  3.41s/it]                                                    {'loss': 0.0691, 'grad_norm': 3.6515052318573, 'learning_rate': 4.515254237288136e-05, 'epoch': 0.11}
 11%|â–ˆ         | 672/6000 [39:34<5:02:25,  3.41s/it] 11%|â–ˆ         | 673/6000 [39:38<5:02:11,  3.40s/it]                                                    {'loss': 0.0484, 'grad_norm': 2.036039352416992, 'learning_rate': 4.514406779661017e-05, 'epoch': 0.11}
 11%|â–ˆ         | 673/6000 [39:38<5:02:11,  3.40s/it] 11%|â–ˆ         | 674/6000 [39:41<5:01:12,  3.39s/it]                                                    {'loss': 0.0698, 'grad_norm': 3.021392822265625, 'learning_rate': 4.513559322033898e-05, 'epoch': 0.11}
 11%|â–ˆ         | 674/6000 [39:41<5:01:12,  3.39s/it] 11%|â–ˆâ–        | 675/6000 [39:45<5:00:46,  3.39s/it]                                                    {'loss': 0.1863, 'grad_norm': 6.3833794593811035, 'learning_rate': 4.51271186440678e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 675/6000 [39:45<5:00:46,  3.39s/it] 11%|â–ˆâ–        | 676/6000 [39:48<5:02:04,  3.40s/it]                                                    {'loss': 0.1065, 'grad_norm': 5.923224449157715, 'learning_rate': 4.511864406779661e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 676/6000 [39:48<5:02:04,  3.40s/it] 11%|â–ˆâ–        | 677/6000 [39:51<5:00:35,  3.39s/it]                                                    {'loss': 0.1136, 'grad_norm': 4.602912902832031, 'learning_rate': 4.511016949152543e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 677/6000 [39:51<5:00:35,  3.39s/it] 11%|â–ˆâ–        | 678/6000 [39:55<5:02:03,  3.41s/it]                                                    {'loss': 0.0713, 'grad_norm': 3.6818182468414307, 'learning_rate': 4.510169491525424e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 678/6000 [39:55<5:02:03,  3.41s/it] 11%|â–ˆâ–        | 679/6000 [39:58<4:59:57,  3.38s/it]                                                    {'loss': 0.0232, 'grad_norm': 2.0081403255462646, 'learning_rate': 4.509322033898306e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 679/6000 [39:58<4:59:57,  3.38s/it] 11%|â–ˆâ–        | 680/6000 [40:02<5:01:08,  3.40s/it]                                                    {'loss': 0.0483, 'grad_norm': 2.3150572776794434, 'learning_rate': 4.508474576271187e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 680/6000 [40:02<5:01:08,  3.40s/it] 11%|â–ˆâ–        | 681/6000 [40:05<5:12:28,  3.52s/it]                                                    {'loss': 0.0328, 'grad_norm': 1.9343217611312866, 'learning_rate': 4.507627118644068e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 681/6000 [40:05<5:12:28,  3.52s/it] 11%|â–ˆâ–        | 682/6000 [40:09<5:11:59,  3.52s/it]                                                    {'loss': 0.0158, 'grad_norm': 1.7405260801315308, 'learning_rate': 4.506779661016949e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 682/6000 [40:09<5:11:59,  3.52s/it] 11%|â–ˆâ–        | 683/6000 [40:12<5:10:27,  3.50s/it]                                                    {'loss': 0.0627, 'grad_norm': 2.735327959060669, 'learning_rate': 4.5059322033898304e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 683/6000 [40:12<5:10:27,  3.50s/it] 11%|â–ˆâ–        | 684/6000 [40:16<5:07:14,  3.47s/it]                                                    {'loss': 0.1723, 'grad_norm': 5.698690414428711, 'learning_rate': 4.505084745762712e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 684/6000 [40:16<5:07:14,  3.47s/it] 11%|â–ˆâ–        | 685/6000 [40:19<5:05:57,  3.45s/it]                                                    {'loss': 0.1262, 'grad_norm': 5.525374412536621, 'learning_rate': 4.504237288135593e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 685/6000 [40:19<5:05:57,  3.45s/it] 11%|â–ˆâ–        | 686/6000 [40:23<5:20:33,  3.62s/it]                                                    {'loss': 0.1463, 'grad_norm': 4.210777282714844, 'learning_rate': 4.503389830508475e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 686/6000 [40:23<5:20:33,  3.62s/it] 11%|â–ˆâ–        | 687/6000 [40:26<5:12:53,  3.53s/it]                                                    {'loss': 0.001, 'grad_norm': 0.09719765931367874, 'learning_rate': 4.502542372881356e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 687/6000 [40:26<5:12:53,  3.53s/it] 11%|â–ˆâ–        | 688/6000 [40:30<5:09:13,  3.49s/it]                                                    {'loss': 0.0219, 'grad_norm': 1.4649229049682617, 'learning_rate': 4.5016949152542373e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 688/6000 [40:30<5:09:13,  3.49s/it] 11%|â–ˆâ–        | 689/6000 [40:33<5:11:51,  3.52s/it]                                                    {'loss': 0.1415, 'grad_norm': 5.715022563934326, 'learning_rate': 4.5008474576271185e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 689/6000 [40:33<5:11:51,  3.52s/it] 12%|â–ˆâ–        | 690/6000 [40:37<5:07:55,  3.48s/it]                                                    {'loss': 0.0699, 'grad_norm': 2.1268255710601807, 'learning_rate': 4.5e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 690/6000 [40:37<5:07:55,  3.48s/it] 12%|â–ˆâ–        | 691/6000 [40:40<5:07:23,  3.47s/it]                                                    {'loss': 0.0154, 'grad_norm': 0.8620181679725647, 'learning_rate': 4.4991525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 691/6000 [40:40<5:07:23,  3.47s/it] 12%|â–ˆâ–        | 692/6000 [40:44<5:06:54,  3.47s/it]                                                    {'loss': 0.2507, 'grad_norm': 6.22964334487915, 'learning_rate': 4.498305084745763e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 692/6000 [40:44<5:06:54,  3.47s/it] 12%|â–ˆâ–        | 693/6000 [40:47<5:02:38,  3.42s/it]                                                    {'loss': 0.0621, 'grad_norm': 2.6749346256256104, 'learning_rate': 4.4974576271186443e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 693/6000 [40:47<5:02:38,  3.42s/it] 12%|â–ˆâ–        | 694/6000 [40:50<5:01:08,  3.41s/it]                                                    {'loss': 0.0105, 'grad_norm': 1.4623408317565918, 'learning_rate': 4.4966101694915255e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 694/6000 [40:50<5:01:08,  3.41s/it] 12%|â–ˆâ–        | 695/6000 [40:54<5:01:37,  3.41s/it]                                                    {'loss': 0.0309, 'grad_norm': 1.3294438123703003, 'learning_rate': 4.4957627118644066e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 695/6000 [40:54<5:01:37,  3.41s/it] 12%|â–ˆâ–        | 696/6000 [40:58<5:10:25,  3.51s/it]                                                    {'loss': 0.1274, 'grad_norm': 6.077334880828857, 'learning_rate': 4.4949152542372884e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 696/6000 [40:58<5:10:25,  3.51s/it] 12%|â–ˆâ–        | 697/6000 [41:01<5:06:53,  3.47s/it]                                                    {'loss': 0.1616, 'grad_norm': 6.420944690704346, 'learning_rate': 4.4940677966101695e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 697/6000 [41:01<5:06:53,  3.47s/it] 12%|â–ˆâ–        | 698/6000 [41:04<5:04:34,  3.45s/it]                                                    {'loss': 0.0977, 'grad_norm': 4.427086353302002, 'learning_rate': 4.4932203389830513e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 698/6000 [41:04<5:04:34,  3.45s/it] 12%|â–ˆâ–        | 699/6000 [41:08<5:04:27,  3.45s/it]                                                    {'loss': 0.0227, 'grad_norm': 1.4925490617752075, 'learning_rate': 4.4923728813559325e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 699/6000 [41:08<5:04:27,  3.45s/it] 12%|â–ˆâ–        | 700/6000 [41:11<5:06:59,  3.48s/it]                                                    {'loss': 0.0088, 'grad_norm': 0.6137353181838989, 'learning_rate': 4.491525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 700/6000 [41:11<5:06:59,  3.48s/it][2025-10-21 02:05:34,084] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|â–ˆâ–        | 701/6000 [41:17<6:05:02,  4.13s/it]                                                    {'loss': 0.0242, 'grad_norm': 1.8463722467422485, 'learning_rate': 4.4906779661016954e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 701/6000 [41:17<6:05:02,  4.13s/it] 12%|â–ˆâ–        | 702/6000 [41:21<5:57:35,  4.05s/it]                                                    {'loss': 0.0586, 'grad_norm': 3.125166416168213, 'learning_rate': 4.4898305084745765e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 702/6000 [41:21<5:57:35,  4.05s/it] 12%|â–ˆâ–        | 703/6000 [41:24<5:43:40,  3.89s/it]                                                    {'loss': 0.0433, 'grad_norm': 2.6553330421447754, 'learning_rate': 4.488983050847458e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 703/6000 [41:24<5:43:40,  3.89s/it] 12%|â–ˆâ–        | 704/6000 [41:28<5:42:41,  3.88s/it]                                                    {'loss': 0.028, 'grad_norm': 1.8628499507904053, 'learning_rate': 4.488135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 704/6000 [41:28<5:42:41,  3.88s/it] 12%|â–ˆâ–        | 705/6000 [41:32<5:34:38,  3.79s/it]                                                    {'loss': 0.1481, 'grad_norm': 5.091868877410889, 'learning_rate': 4.4872881355932206e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 705/6000 [41:32<5:34:38,  3.79s/it] 12%|â–ˆâ–        | 706/6000 [41:35<5:23:45,  3.67s/it]                                                    {'loss': 0.109, 'grad_norm': 2.883307456970215, 'learning_rate': 4.486440677966102e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 706/6000 [41:35<5:23:45,  3.67s/it] 12%|â–ˆâ–        | 707/6000 [41:39<5:18:54,  3.61s/it]                                                    {'loss': 0.0162, 'grad_norm': 1.2768725156784058, 'learning_rate': 4.4855932203389835e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 707/6000 [41:39<5:18:54,  3.61s/it] 12%|â–ˆâ–        | 708/6000 [41:42<5:15:23,  3.58s/it]                                                    {'loss': 0.0153, 'grad_norm': 0.742978572845459, 'learning_rate': 4.484745762711865e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 708/6000 [41:42<5:15:23,  3.58s/it] 12%|â–ˆâ–        | 709/6000 [41:46<5:11:37,  3.53s/it]                                                    {'loss': 0.1038, 'grad_norm': 4.93100643157959, 'learning_rate': 4.483898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 709/6000 [41:46<5:11:37,  3.53s/it] 12%|â–ˆâ–        | 710/6000 [41:49<5:16:49,  3.59s/it]                                                    {'loss': 0.0283, 'grad_norm': 1.5701795816421509, 'learning_rate': 4.483050847457627e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 710/6000 [41:49<5:16:49,  3.59s/it] 12%|â–ˆâ–        | 711/6000 [41:53<5:12:10,  3.54s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.09359866380691528, 'learning_rate': 4.482203389830509e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 711/6000 [41:53<5:12:10,  3.54s/it] 12%|â–ˆâ–        | 712/6000 [41:56<5:10:56,  3.53s/it]                                                    {'loss': 0.0322, 'grad_norm': 2.3295958042144775, 'learning_rate': 4.48135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 712/6000 [41:56<5:10:56,  3.53s/it] 12%|â–ˆâ–        | 713/6000 [42:00<5:07:12,  3.49s/it]                                                    {'loss': 0.102, 'grad_norm': 3.402574062347412, 'learning_rate': 4.480508474576272e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 713/6000 [42:00<5:07:12,  3.49s/it] 12%|â–ˆâ–        | 714/6000 [42:03<5:05:17,  3.47s/it]                                                    {'loss': 0.0602, 'grad_norm': 3.890019416809082, 'learning_rate': 4.479661016949153e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 714/6000 [42:03<5:05:17,  3.47s/it] 12%|â–ˆâ–        | 715/6000 [42:06<5:03:58,  3.45s/it]                                                    {'loss': 0.0561, 'grad_norm': 5.4654412269592285, 'learning_rate': 4.4788135593220346e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 715/6000 [42:07<5:03:58,  3.45s/it] 12%|â–ˆâ–        | 716/6000 [42:10<5:02:41,  3.44s/it]                                                    {'loss': 0.1119, 'grad_norm': 4.944055080413818, 'learning_rate': 4.477966101694915e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 716/6000 [42:10<5:02:41,  3.44s/it] 12%|â–ˆâ–        | 717/6000 [42:14<5:10:40,  3.53s/it]                                                    {'loss': 0.1143, 'grad_norm': 3.99965500831604, 'learning_rate': 4.477118644067797e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 717/6000 [42:14<5:10:40,  3.53s/it] 12%|â–ˆâ–        | 718/6000 [42:17<5:05:56,  3.48s/it]                                                    {'loss': 0.0189, 'grad_norm': 1.473999261856079, 'learning_rate': 4.476271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 718/6000 [42:17<5:05:56,  3.48s/it] 12%|â–ˆâ–        | 719/6000 [42:20<5:05:59,  3.48s/it]                                                    {'loss': 0.0701, 'grad_norm': 3.827319622039795, 'learning_rate': 4.47542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 719/6000 [42:20<5:05:59,  3.48s/it] 12%|â–ˆâ–        | 720/6000 [42:24<5:03:53,  3.45s/it]                                                    {'loss': 0.0166, 'grad_norm': 1.5658810138702393, 'learning_rate': 4.474576271186441e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 720/6000 [42:24<5:03:53,  3.45s/it] 12%|â–ˆâ–        | 721/6000 [42:27<5:05:05,  3.47s/it]                                                    {'loss': 0.0295, 'grad_norm': 1.1723605394363403, 'learning_rate': 4.473728813559323e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 721/6000 [42:27<5:05:05,  3.47s/it] 12%|â–ˆâ–        | 722/6000 [42:31<5:04:45,  3.46s/it]                                                    {'loss': 0.0536, 'grad_norm': 2.1555545330047607, 'learning_rate': 4.472881355932204e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 722/6000 [42:31<5:04:45,  3.46s/it] 12%|â–ˆâ–        | 723/6000 [42:35<5:16:57,  3.60s/it]                                                    {'loss': 0.0745, 'grad_norm': 3.961684226989746, 'learning_rate': 4.472033898305085e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 723/6000 [42:35<5:16:57,  3.60s/it] 12%|â–ˆâ–        | 724/6000 [42:38<5:09:09,  3.52s/it]                                                    {'loss': 0.0496, 'grad_norm': 3.160604953765869, 'learning_rate': 4.471186440677966e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 724/6000 [42:38<5:09:09,  3.52s/it] 12%|â–ˆâ–        | 725/6000 [42:41<5:03:57,  3.46s/it]                                                    {'loss': 0.0625, 'grad_norm': 3.282998561859131, 'learning_rate': 4.470338983050847e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 725/6000 [42:41<5:03:57,  3.46s/it] 12%|â–ˆâ–        | 726/6000 [42:45<5:03:58,  3.46s/it]                                                    {'loss': 0.0116, 'grad_norm': 0.6376895904541016, 'learning_rate': 4.469491525423729e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 726/6000 [42:45<5:03:58,  3.46s/it] 12%|â–ˆâ–        | 727/6000 [42:48<5:02:20,  3.44s/it]                                                    {'loss': 0.0868, 'grad_norm': 3.606990098953247, 'learning_rate': 4.46864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 727/6000 [42:48<5:02:20,  3.44s/it] 12%|â–ˆâ–        | 728/6000 [42:52<5:00:12,  3.42s/it]                                                    {'loss': 0.0109, 'grad_norm': 0.598746120929718, 'learning_rate': 4.467796610169492e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 728/6000 [42:52<5:00:12,  3.42s/it] 12%|â–ˆâ–        | 729/6000 [42:55<4:59:46,  3.41s/it]                                                    {'loss': 0.0203, 'grad_norm': 1.5541952848434448, 'learning_rate': 4.466949152542373e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 729/6000 [42:55<4:59:46,  3.41s/it] 12%|â–ˆâ–        | 730/6000 [42:58<4:59:14,  3.41s/it]                                                    {'loss': 0.0764, 'grad_norm': 1.5024484395980835, 'learning_rate': 4.466101694915254e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 730/6000 [42:58<4:59:14,  3.41s/it] 12%|â–ˆâ–        | 731/6000 [43:02<4:57:56,  3.39s/it]                                                    {'loss': 0.0041, 'grad_norm': 0.26103219389915466, 'learning_rate': 4.4652542372881354e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 731/6000 [43:02<4:57:56,  3.39s/it] 12%|â–ˆâ–        | 732/6000 [43:05<5:02:43,  3.45s/it]                                                    {'loss': 0.0976, 'grad_norm': 4.446835517883301, 'learning_rate': 4.464406779661017e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 732/6000 [43:05<5:02:43,  3.45s/it] 12%|â–ˆâ–        | 733/6000 [43:09<5:06:20,  3.49s/it]                                                    {'loss': 0.0084, 'grad_norm': 0.7978308796882629, 'learning_rate': 4.463559322033898e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 733/6000 [43:09<5:06:20,  3.49s/it] 12%|â–ˆâ–        | 734/6000 [43:13<5:18:55,  3.63s/it]                                                    {'loss': 0.0082, 'grad_norm': 0.5334928035736084, 'learning_rate': 4.46271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 734/6000 [43:13<5:18:55,  3.63s/it] 12%|â–ˆâ–        | 735/6000 [43:16<5:12:23,  3.56s/it]                                                    {'loss': 0.0061, 'grad_norm': 0.5443928837776184, 'learning_rate': 4.461864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 735/6000 [43:16<5:12:23,  3.56s/it] 12%|â–ˆâ–        | 736/6000 [43:20<5:05:40,  3.48s/it]                                                    {'loss': 0.0508, 'grad_norm': 1.9080476760864258, 'learning_rate': 4.461016949152543e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 736/6000 [43:20<5:05:40,  3.48s/it] 12%|â–ˆâ–        | 737/6000 [43:23<5:02:59,  3.45s/it]                                                    {'loss': 0.0247, 'grad_norm': 1.3274035453796387, 'learning_rate': 4.460169491525424e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 737/6000 [43:23<5:02:59,  3.45s/it] 12%|â–ˆâ–        | 738/6000 [43:26<5:00:53,  3.43s/it]                                                    {'loss': 0.1958, 'grad_norm': 5.251368999481201, 'learning_rate': 4.459322033898305e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 738/6000 [43:26<5:00:53,  3.43s/it] 12%|â–ˆâ–        | 739/6000 [43:30<5:00:54,  3.43s/it]                                                    {'loss': 0.0189, 'grad_norm': 0.7383106350898743, 'learning_rate': 4.4584745762711864e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 739/6000 [43:30<5:00:54,  3.43s/it] 12%|â–ˆâ–        | 740/6000 [43:33<5:01:00,  3.43s/it]                                                    {'loss': 0.2882, 'grad_norm': 6.322702884674072, 'learning_rate': 4.457627118644068e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 740/6000 [43:33<5:01:00,  3.43s/it] 12%|â–ˆâ–        | 741/6000 [43:37<5:01:28,  3.44s/it]                                                    {'loss': 0.0673, 'grad_norm': 3.656999111175537, 'learning_rate': 4.4567796610169494e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 741/6000 [43:37<5:01:28,  3.44s/it] 12%|â–ˆâ–        | 742/6000 [43:40<4:58:43,  3.41s/it]                                                    {'loss': 0.0223, 'grad_norm': 2.1273109912872314, 'learning_rate': 4.455932203389831e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 742/6000 [43:40<4:58:43,  3.41s/it] 12%|â–ˆâ–        | 743/6000 [43:43<4:56:22,  3.38s/it]                                                    {'loss': 0.0924, 'grad_norm': 4.545633316040039, 'learning_rate': 4.455084745762712e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 743/6000 [43:43<4:56:22,  3.38s/it] 12%|â–ˆâ–        | 744/6000 [43:47<4:54:41,  3.36s/it]                                                    {'loss': 0.0149, 'grad_norm': 0.7239521145820618, 'learning_rate': 4.4542372881355934e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 744/6000 [43:47<4:54:41,  3.36s/it] 12%|â–ˆâ–        | 745/6000 [43:50<4:55:35,  3.38s/it]                                                    {'loss': 0.1315, 'grad_norm': 3.5594446659088135, 'learning_rate': 4.4533898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 745/6000 [43:50<4:55:35,  3.38s/it] 12%|â–ˆâ–        | 746/6000 [43:53<4:55:55,  3.38s/it]                                                    {'loss': 0.3016, 'grad_norm': 5.516190528869629, 'learning_rate': 4.452542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 746/6000 [43:53<4:55:55,  3.38s/it] 12%|â–ˆâ–        | 747/6000 [43:57<4:56:39,  3.39s/it]                                                    {'loss': 0.0606, 'grad_norm': 4.162776947021484, 'learning_rate': 4.4516949152542375e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 747/6000 [43:57<4:56:39,  3.39s/it] 12%|â–ˆâ–        | 748/6000 [44:00<5:00:32,  3.43s/it]                                                    {'loss': 0.0584, 'grad_norm': 5.075804233551025, 'learning_rate': 4.4508474576271186e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 748/6000 [44:00<5:00:32,  3.43s/it] 12%|â–ˆâ–        | 749/6000 [44:05<5:21:09,  3.67s/it]                                                    {'loss': 0.0894, 'grad_norm': 5.373124122619629, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 749/6000 [44:05<5:21:09,  3.67s/it] 12%|â–ˆâ–Ž        | 750/6000 [44:08<5:26:43,  3.73s/it]                                                    {'loss': 0.2215, 'grad_norm': 5.11644172668457, 'learning_rate': 4.4491525423728816e-05, 'epoch': 0.12}
 12%|â–ˆâ–Ž        | 750/6000 [44:09<5:26:43,  3.73s/it][2025-10-21 02:08:31,253] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 751/6000 [44:14<6:16:04,  4.30s/it]                                                    {'loss': 0.0348, 'grad_norm': 1.7444504499435425, 'learning_rate': 4.448305084745763e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 751/6000 [44:14<6:16:04,  4.30s/it] 13%|â–ˆâ–Ž        | 752/6000 [44:18<6:05:35,  4.18s/it]                                                    {'loss': 0.0285, 'grad_norm': 2.3212127685546875, 'learning_rate': 4.447457627118644e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 752/6000 [44:18<6:05:35,  4.18s/it] 13%|â–ˆâ–Ž        | 753/6000 [44:22<5:47:44,  3.98s/it]                                                    {'loss': 0.0089, 'grad_norm': 1.0561528205871582, 'learning_rate': 4.4466101694915256e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 753/6000 [44:22<5:47:44,  3.98s/it] 13%|â–ˆâ–Ž        | 754/6000 [44:25<5:32:17,  3.80s/it]                                                    {'loss': 0.0315, 'grad_norm': 1.5759543180465698, 'learning_rate': 4.445762711864407e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 754/6000 [44:25<5:32:17,  3.80s/it] 13%|â–ˆâ–Ž        | 755/6000 [44:28<5:19:44,  3.66s/it]                                                    {'loss': 0.003, 'grad_norm': 0.2871859073638916, 'learning_rate': 4.4449152542372886e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 755/6000 [44:28<5:19:44,  3.66s/it] 13%|â–ˆâ–Ž        | 756/6000 [44:32<5:10:10,  3.55s/it]                                                    {'loss': 0.013, 'grad_norm': 1.929470419883728, 'learning_rate': 4.44406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 756/6000 [44:32<5:10:10,  3.55s/it] 13%|â–ˆâ–Ž        | 757/6000 [44:35<5:12:01,  3.57s/it]                                                    {'loss': 0.0059, 'grad_norm': 0.7870259881019592, 'learning_rate': 4.4432203389830515e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 757/6000 [44:35<5:12:01,  3.57s/it] 13%|â–ˆâ–Ž        | 758/6000 [44:39<5:08:26,  3.53s/it]                                                    {'loss': 0.0231, 'grad_norm': 2.068708896636963, 'learning_rate': 4.4423728813559326e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 758/6000 [44:39<5:08:26,  3.53s/it] 13%|â–ˆâ–Ž        | 759/6000 [44:42<5:04:19,  3.48s/it]                                                    {'loss': 0.3162, 'grad_norm': 6.0324907302856445, 'learning_rate': 4.441525423728814e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 759/6000 [44:42<5:04:19,  3.48s/it] 13%|â–ˆâ–Ž        | 760/6000 [44:45<5:02:39,  3.47s/it]                                                    {'loss': 0.0344, 'grad_norm': 3.2735671997070312, 'learning_rate': 4.440677966101695e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 760/6000 [44:45<5:02:39,  3.47s/it] 13%|â–ˆâ–Ž        | 761/6000 [44:49<5:01:53,  3.46s/it]                                                    {'loss': 0.0542, 'grad_norm': 2.2018797397613525, 'learning_rate': 4.439830508474577e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 761/6000 [44:49<5:01:53,  3.46s/it] 13%|â–ˆâ–Ž        | 762/6000 [44:52<5:04:26,  3.49s/it]                                                    {'loss': 0.0981, 'grad_norm': 4.631716251373291, 'learning_rate': 4.438983050847458e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 762/6000 [44:52<5:04:26,  3.49s/it] 13%|â–ˆâ–Ž        | 763/6000 [44:56<5:00:52,  3.45s/it]                                                    {'loss': 0.1661, 'grad_norm': 4.16115140914917, 'learning_rate': 4.4381355932203396e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 763/6000 [44:56<5:00:52,  3.45s/it] 13%|â–ˆâ–Ž        | 764/6000 [44:59<4:59:15,  3.43s/it]                                                    {'loss': 0.1276, 'grad_norm': 5.172314167022705, 'learning_rate': 4.437288135593221e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 764/6000 [44:59<4:59:15,  3.43s/it] 13%|â–ˆâ–Ž        | 765/6000 [45:03<4:57:58,  3.42s/it]                                                    {'loss': 0.0685, 'grad_norm': 3.5912137031555176, 'learning_rate': 4.436440677966102e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 765/6000 [45:03<4:57:58,  3.42s/it] 13%|â–ˆâ–Ž        | 766/6000 [45:06<5:03:30,  3.48s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.20301851630210876, 'learning_rate': 4.435593220338983e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 766/6000 [45:06<5:03:30,  3.48s/it] 13%|â–ˆâ–Ž        | 767/6000 [45:10<5:11:33,  3.57s/it]                                                    {'loss': 0.0271, 'grad_norm': 2.1948249340057373, 'learning_rate': 4.434745762711864e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 767/6000 [45:10<5:11:33,  3.57s/it] 13%|â–ˆâ–Ž        | 768/6000 [45:13<5:07:23,  3.53s/it]                                                    {'loss': 0.0069, 'grad_norm': 0.5964539051055908, 'learning_rate': 4.433898305084746e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 768/6000 [45:13<5:07:23,  3.53s/it] 13%|â–ˆâ–Ž        | 769/6000 [45:17<5:10:03,  3.56s/it]                                                    {'loss': 0.0334, 'grad_norm': 0.8840256929397583, 'learning_rate': 4.433050847457627e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 769/6000 [45:17<5:10:03,  3.56s/it] 13%|â–ˆâ–Ž        | 770/6000 [45:20<5:04:51,  3.50s/it]                                                    {'loss': 0.1931, 'grad_norm': 5.916378974914551, 'learning_rate': 4.432203389830509e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 770/6000 [45:20<5:04:51,  3.50s/it] 13%|â–ˆâ–Ž        | 771/6000 [45:24<5:00:49,  3.45s/it]                                                    {'loss': 0.0041, 'grad_norm': 0.22781944274902344, 'learning_rate': 4.43135593220339e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 771/6000 [45:24<5:00:49,  3.45s/it] 13%|â–ˆâ–Ž        | 772/6000 [45:27<4:58:59,  3.43s/it]                                                    {'loss': 0.0285, 'grad_norm': 3.0424599647521973, 'learning_rate': 4.430508474576272e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 772/6000 [45:27<4:58:59,  3.43s/it] 13%|â–ˆâ–Ž        | 773/6000 [45:30<4:58:09,  3.42s/it]                                                    {'loss': 0.1585, 'grad_norm': 5.982339859008789, 'learning_rate': 4.429661016949152e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 773/6000 [45:30<4:58:09,  3.42s/it] 13%|â–ˆâ–Ž        | 774/6000 [45:34<4:56:55,  3.41s/it]                                                    {'loss': 0.007, 'grad_norm': 0.5014356374740601, 'learning_rate': 4.428813559322034e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 774/6000 [45:34<4:56:55,  3.41s/it] 13%|â–ˆâ–Ž        | 775/6000 [45:37<5:00:33,  3.45s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.3070707619190216, 'learning_rate': 4.427966101694915e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 775/6000 [45:37<5:00:33,  3.45s/it] 13%|â–ˆâ–Ž        | 776/6000 [45:41<5:01:27,  3.46s/it]                                                    {'loss': 0.0311, 'grad_norm': 2.2008912563323975, 'learning_rate': 4.427118644067797e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 776/6000 [45:41<5:01:27,  3.46s/it] 13%|â–ˆâ–Ž        | 777/6000 [45:45<5:06:12,  3.52s/it]                                                    {'loss': 0.0279, 'grad_norm': 2.472956895828247, 'learning_rate': 4.426271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 777/6000 [45:45<5:06:12,  3.52s/it] 13%|â–ˆâ–Ž        | 778/6000 [45:48<5:11:09,  3.58s/it]                                                    {'loss': 0.1534, 'grad_norm': 4.314201354980469, 'learning_rate': 4.42542372881356e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 778/6000 [45:48<5:11:09,  3.58s/it] 13%|â–ˆâ–Ž        | 779/6000 [45:52<5:06:25,  3.52s/it]                                                    {'loss': 0.1484, 'grad_norm': 5.712520122528076, 'learning_rate': 4.424576271186441e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 779/6000 [45:52<5:06:25,  3.52s/it] 13%|â–ˆâ–Ž        | 780/6000 [45:55<5:02:17,  3.47s/it]                                                    {'loss': 0.0123, 'grad_norm': 0.9355921745300293, 'learning_rate': 4.423728813559322e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 780/6000 [45:55<5:02:17,  3.47s/it] 13%|â–ˆâ–Ž        | 781/6000 [45:58<5:00:52,  3.46s/it]                                                    {'loss': 0.0376, 'grad_norm': 4.028653144836426, 'learning_rate': 4.422881355932203e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 781/6000 [45:58<5:00:52,  3.46s/it] 13%|â–ˆâ–Ž        | 782/6000 [46:02<4:58:53,  3.44s/it]                                                    {'loss': 0.0751, 'grad_norm': 5.913363456726074, 'learning_rate': 4.422033898305085e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 782/6000 [46:02<4:58:53,  3.44s/it] 13%|â–ˆâ–Ž        | 783/6000 [46:05<4:56:58,  3.42s/it]                                                    {'loss': 0.0463, 'grad_norm': 2.266050100326538, 'learning_rate': 4.421186440677966e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 783/6000 [46:05<4:56:58,  3.42s/it] 13%|â–ˆâ–Ž        | 784/6000 [46:08<4:54:39,  3.39s/it]                                                    {'loss': 0.1086, 'grad_norm': 3.8458616733551025, 'learning_rate': 4.420338983050848e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 784/6000 [46:08<4:54:39,  3.39s/it] 13%|â–ˆâ–Ž        | 785/6000 [46:12<4:52:13,  3.36s/it]                                                    {'loss': 0.2148, 'grad_norm': 8.17254638671875, 'learning_rate': 4.419491525423729e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 785/6000 [46:12<4:52:13,  3.36s/it] 13%|â–ˆâ–Ž        | 786/6000 [46:15<4:50:47,  3.35s/it]                                                    {'loss': 0.1596, 'grad_norm': 86.11351013183594, 'learning_rate': 4.41864406779661e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 786/6000 [46:15<4:50:47,  3.35s/it] 13%|â–ˆâ–Ž        | 787/6000 [46:18<4:51:29,  3.36s/it]                                                    {'loss': 0.0473, 'grad_norm': 3.9404120445251465, 'learning_rate': 4.4177966101694914e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 787/6000 [46:18<4:51:29,  3.36s/it] 13%|â–ˆâ–Ž        | 788/6000 [46:22<4:51:25,  3.35s/it]                                                    {'loss': 0.0264, 'grad_norm': 1.8328911066055298, 'learning_rate': 4.4169491525423726e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 788/6000 [46:22<4:51:25,  3.35s/it] 13%|â–ˆâ–Ž        | 789/6000 [46:25<4:55:52,  3.41s/it]                                                    {'loss': 0.0262, 'grad_norm': 2.8240389823913574, 'learning_rate': 4.4161016949152544e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 789/6000 [46:25<4:55:52,  3.41s/it] 13%|â–ˆâ–Ž        | 790/6000 [46:29<4:54:14,  3.39s/it]                                                    {'loss': 0.1412, 'grad_norm': 3.668286085128784, 'learning_rate': 4.4152542372881355e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 790/6000 [46:29<4:54:14,  3.39s/it] 13%|â–ˆâ–Ž        | 791/6000 [46:32<4:54:42,  3.39s/it]                                                    {'loss': 0.0268, 'grad_norm': 0.9559203386306763, 'learning_rate': 4.414406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 791/6000 [46:32<4:54:42,  3.39s/it] 13%|â–ˆâ–Ž        | 792/6000 [46:36<4:56:39,  3.42s/it]                                                    {'loss': 0.0484, 'grad_norm': 2.9992494583129883, 'learning_rate': 4.4135593220338984e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 792/6000 [46:36<4:56:39,  3.42s/it] 13%|â–ˆâ–Ž        | 793/6000 [46:39<4:55:50,  3.41s/it]                                                    {'loss': 0.0075, 'grad_norm': 0.622058093547821, 'learning_rate': 4.41271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 793/6000 [46:39<4:55:50,  3.41s/it] 13%|â–ˆâ–Ž        | 794/6000 [46:42<4:58:51,  3.44s/it]                                                    {'loss': 0.0443, 'grad_norm': 2.514446973800659, 'learning_rate': 4.4118644067796614e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 794/6000 [46:43<4:58:51,  3.44s/it] 13%|â–ˆâ–Ž        | 795/6000 [46:46<5:06:41,  3.54s/it]                                                    {'loss': 0.0343, 'grad_norm': 2.9120612144470215, 'learning_rate': 4.4110169491525425e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 795/6000 [46:46<5:06:41,  3.54s/it] 13%|â–ˆâ–Ž        | 796/6000 [46:50<5:00:52,  3.47s/it]                                                    {'loss': 0.1619, 'grad_norm': 4.909318447113037, 'learning_rate': 4.4101694915254236e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 796/6000 [46:50<5:00:52,  3.47s/it] 13%|â–ˆâ–Ž        | 797/6000 [46:53<4:59:40,  3.46s/it]                                                    {'loss': 0.0228, 'grad_norm': 1.0836480855941772, 'learning_rate': 4.4093220338983054e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 797/6000 [46:53<4:59:40,  3.46s/it] 13%|â–ˆâ–Ž        | 798/6000 [46:56<4:57:13,  3.43s/it]                                                    {'loss': 0.0015, 'grad_norm': 0.18275032937526703, 'learning_rate': 4.4084745762711866e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 798/6000 [46:56<4:57:13,  3.43s/it] 13%|â–ˆâ–Ž        | 799/6000 [47:00<4:57:27,  3.43s/it]                                                    {'loss': 0.1389, 'grad_norm': 4.799205303192139, 'learning_rate': 4.4076271186440684e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 799/6000 [47:00<4:57:27,  3.43s/it] 13%|â–ˆâ–Ž        | 800/6000 [47:03<4:58:20,  3.44s/it]                                                    {'loss': 0.0569, 'grad_norm': 3.981232166290283, 'learning_rate': 4.4067796610169495e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 800/6000 [47:03<4:58:20,  3.44s/it][2025-10-21 02:11:26,010] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 801/6000 [47:09<5:54:52,  4.10s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.2685920298099518, 'learning_rate': 4.4059322033898306e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 801/6000 [47:09<5:54:52,  4.10s/it] 13%|â–ˆâ–Ž        | 802/6000 [47:12<5:39:04,  3.91s/it]                                                    {'loss': 0.0568, 'grad_norm': 4.560020923614502, 'learning_rate': 4.405084745762712e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 802/6000 [47:12<5:39:04,  3.91s/it] 13%|â–ˆâ–Ž        | 803/6000 [47:16<5:24:30,  3.75s/it]                                                    {'loss': 0.2155, 'grad_norm': 3.5722780227661133, 'learning_rate': 4.4042372881355936e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 803/6000 [47:16<5:24:30,  3.75s/it] 13%|â–ˆâ–Ž        | 804/6000 [47:19<5:14:44,  3.63s/it]                                                    {'loss': 0.1554, 'grad_norm': 4.407870292663574, 'learning_rate': 4.403389830508475e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 804/6000 [47:19<5:14:44,  3.63s/it] 13%|â–ˆâ–Ž        | 805/6000 [47:23<5:08:43,  3.57s/it]                                                    {'loss': 0.0133, 'grad_norm': 0.9317015409469604, 'learning_rate': 4.4025423728813565e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 805/6000 [47:23<5:08:43,  3.57s/it] 13%|â–ˆâ–Ž        | 806/6000 [47:26<5:07:54,  3.56s/it]                                                    {'loss': 0.0029, 'grad_norm': 0.3177473545074463, 'learning_rate': 4.4016949152542376e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 806/6000 [47:26<5:07:54,  3.56s/it] 13%|â–ˆâ–Ž        | 807/6000 [47:29<5:01:54,  3.49s/it]                                                    {'loss': 0.006, 'grad_norm': 0.5110353231430054, 'learning_rate': 4.400847457627119e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 807/6000 [47:29<5:01:54,  3.49s/it] 13%|â–ˆâ–Ž        | 808/6000 [47:33<4:58:50,  3.45s/it]                                                    {'loss': 0.0117, 'grad_norm': 1.0925005674362183, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 808/6000 [47:33<4:58:50,  3.45s/it] 13%|â–ˆâ–Ž        | 809/6000 [47:36<4:55:19,  3.41s/it]                                                    {'loss': 0.0221, 'grad_norm': 2.1284711360931396, 'learning_rate': 4.399152542372881e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 809/6000 [47:36<4:55:19,  3.41s/it] 14%|â–ˆâ–Ž        | 810/6000 [47:40<4:58:21,  3.45s/it]                                                    {'loss': 0.3979, 'grad_norm': 6.56279182434082, 'learning_rate': 4.398305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 810/6000 [47:40<4:58:21,  3.45s/it] 14%|â–ˆâ–Ž        | 811/6000 [47:43<4:57:29,  3.44s/it]                                                    {'loss': 0.0113, 'grad_norm': 0.7858473658561707, 'learning_rate': 4.397457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 811/6000 [47:43<4:57:29,  3.44s/it] 14%|â–ˆâ–Ž        | 812/6000 [47:46<4:55:14,  3.41s/it]                                                    {'loss': 0.0331, 'grad_norm': 2.6593198776245117, 'learning_rate': 4.396610169491526e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 812/6000 [47:46<4:55:14,  3.41s/it] 14%|â–ˆâ–Ž        | 813/6000 [47:50<5:13:46,  3.63s/it]                                                    {'loss': 0.0513, 'grad_norm': 2.019197463989258, 'learning_rate': 4.395762711864407e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 813/6000 [47:50<5:13:46,  3.63s/it] 14%|â–ˆâ–Ž        | 814/6000 [47:54<5:06:50,  3.55s/it]                                                    {'loss': 0.0597, 'grad_norm': 2.347480535507202, 'learning_rate': 4.394915254237289e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 814/6000 [47:54<5:06:50,  3.55s/it] 14%|â–ˆâ–Ž        | 815/6000 [47:57<5:01:20,  3.49s/it]                                                    {'loss': 0.0101, 'grad_norm': 0.8346286416053772, 'learning_rate': 4.39406779661017e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 815/6000 [47:57<5:01:20,  3.49s/it] 14%|â–ˆâ–Ž        | 816/6000 [48:00<4:56:25,  3.43s/it]                                                    {'loss': 0.0788, 'grad_norm': 4.873923301696777, 'learning_rate': 4.393220338983051e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 816/6000 [48:01<4:56:25,  3.43s/it] 14%|â–ˆâ–Ž        | 817/6000 [48:05<5:17:09,  3.67s/it]                                                    {'loss': 0.1755, 'grad_norm': 4.552271842956543, 'learning_rate': 4.392372881355932e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 817/6000 [48:05<5:17:09,  3.67s/it] 14%|â–ˆâ–Ž        | 818/6000 [48:08<5:08:18,  3.57s/it]                                                    {'loss': 0.0136, 'grad_norm': 1.0237812995910645, 'learning_rate': 4.391525423728814e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 818/6000 [48:08<5:08:18,  3.57s/it] 14%|â–ˆâ–Ž        | 819/6000 [48:11<5:04:43,  3.53s/it]                                                    {'loss': 0.0355, 'grad_norm': 1.7166224718093872, 'learning_rate': 4.390677966101695e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 819/6000 [48:12<5:04:43,  3.53s/it] 14%|â–ˆâ–Ž        | 820/6000 [48:15<5:01:08,  3.49s/it]                                                    {'loss': 0.0242, 'grad_norm': 2.0566556453704834, 'learning_rate': 4.389830508474577e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 820/6000 [48:15<5:01:08,  3.49s/it] 14%|â–ˆâ–Ž        | 821/6000 [48:18<4:59:42,  3.47s/it]                                                    {'loss': 0.0166, 'grad_norm': 1.292907953262329, 'learning_rate': 4.388983050847458e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 821/6000 [48:18<4:59:42,  3.47s/it] 14%|â–ˆâ–Ž        | 822/6000 [48:22<4:56:49,  3.44s/it]                                                    {'loss': 0.0167, 'grad_norm': 1.8476985692977905, 'learning_rate': 4.388135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 822/6000 [48:22<4:56:49,  3.44s/it] 14%|â–ˆâ–Ž        | 823/6000 [48:25<4:56:16,  3.43s/it]                                                    {'loss': 0.2139, 'grad_norm': 7.469283103942871, 'learning_rate': 4.38728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 823/6000 [48:25<4:56:16,  3.43s/it] 14%|â–ˆâ–Ž        | 824/6000 [48:29<4:55:13,  3.42s/it]                                                    {'loss': 0.001, 'grad_norm': 0.09761469811201096, 'learning_rate': 4.386440677966102e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 824/6000 [48:29<4:55:13,  3.42s/it] 14%|â–ˆâ–        | 825/6000 [48:32<5:00:54,  3.49s/it]                                                    {'loss': 0.0619, 'grad_norm': 3.043076992034912, 'learning_rate': 4.385593220338983e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 825/6000 [48:32<5:00:54,  3.49s/it] 14%|â–ˆâ–        | 826/6000 [48:36<4:57:50,  3.45s/it]                                                    {'loss': 0.0018, 'grad_norm': 0.1511065512895584, 'learning_rate': 4.384745762711865e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 826/6000 [48:36<4:57:50,  3.45s/it] 14%|â–ˆâ–        | 827/6000 [48:39<4:55:17,  3.43s/it]                                                    {'loss': 0.0407, 'grad_norm': 2.900099039077759, 'learning_rate': 4.383898305084746e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 827/6000 [48:39<4:55:17,  3.43s/it] 14%|â–ˆâ–        | 828/6000 [48:42<4:55:32,  3.43s/it]                                                    {'loss': 0.2654, 'grad_norm': 5.576514720916748, 'learning_rate': 4.383050847457627e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 828/6000 [48:42<4:55:32,  3.43s/it] 14%|â–ˆâ–        | 829/6000 [48:46<4:55:46,  3.43s/it]                                                    {'loss': 0.0901, 'grad_norm': 1.9889737367630005, 'learning_rate': 4.382203389830509e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 829/6000 [48:46<4:55:46,  3.43s/it] 14%|â–ˆâ–        | 830/6000 [48:50<5:17:53,  3.69s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.19348618388175964, 'learning_rate': 4.38135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 830/6000 [48:50<5:17:53,  3.69s/it] 14%|â–ˆâ–        | 831/6000 [48:54<5:12:42,  3.63s/it]                                                    {'loss': 0.1225, 'grad_norm': 5.009262561798096, 'learning_rate': 4.380508474576271e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 831/6000 [48:54<5:12:42,  3.63s/it] 14%|â–ˆâ–        | 832/6000 [48:57<5:04:52,  3.54s/it]                                                    {'loss': 0.0897, 'grad_norm': 4.031797409057617, 'learning_rate': 4.3796610169491524e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 832/6000 [48:57<5:04:52,  3.54s/it] 14%|â–ˆâ–        | 833/6000 [49:00<4:59:12,  3.47s/it]                                                    {'loss': 0.0076, 'grad_norm': 0.8973953127861023, 'learning_rate': 4.378813559322034e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 833/6000 [49:00<4:59:12,  3.47s/it] 14%|â–ˆâ–        | 834/6000 [49:04<4:59:49,  3.48s/it]                                                    {'loss': 0.0702, 'grad_norm': 3.9586174488067627, 'learning_rate': 4.377966101694915e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 834/6000 [49:04<4:59:49,  3.48s/it] 14%|â–ˆâ–        | 835/6000 [49:08<5:10:25,  3.61s/it]                                                    {'loss': 0.0272, 'grad_norm': 1.582618236541748, 'learning_rate': 4.377118644067797e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 835/6000 [49:08<5:10:25,  3.61s/it] 14%|â–ˆâ–        | 836/6000 [49:11<5:02:09,  3.51s/it]                                                    {'loss': 0.0416, 'grad_norm': 2.6727664470672607, 'learning_rate': 4.376271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 836/6000 [49:11<5:02:09,  3.51s/it] 14%|â–ˆâ–        | 837/6000 [49:15<5:22:24,  3.75s/it]                                                    {'loss': 0.0185, 'grad_norm': 1.6317113637924194, 'learning_rate': 4.3754237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 837/6000 [49:15<5:22:24,  3.75s/it] 14%|â–ˆâ–        | 838/6000 [49:19<5:25:50,  3.79s/it]                                                    {'loss': 0.1441, 'grad_norm': 5.336349964141846, 'learning_rate': 4.3745762711864405e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 838/6000 [49:19<5:25:50,  3.79s/it] 14%|â–ˆâ–        | 839/6000 [49:22<5:16:13,  3.68s/it]                                                    {'loss': 0.0077, 'grad_norm': 0.6151542663574219, 'learning_rate': 4.373728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 839/6000 [49:22<5:16:13,  3.68s/it] 14%|â–ˆâ–        | 840/6000 [49:26<5:10:39,  3.61s/it]                                                    {'loss': 0.0007, 'grad_norm': 0.07613714039325714, 'learning_rate': 4.3728813559322035e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 840/6000 [49:26<5:10:39,  3.61s/it] 14%|â–ˆâ–        | 841/6000 [49:30<5:16:18,  3.68s/it]                                                    {'loss': 0.0736, 'grad_norm': 2.9487123489379883, 'learning_rate': 4.372033898305085e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 841/6000 [49:30<5:16:18,  3.68s/it] 14%|â–ˆâ–        | 842/6000 [49:33<5:08:37,  3.59s/it]                                                    {'loss': 0.133, 'grad_norm': 5.149959087371826, 'learning_rate': 4.3711864406779664e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 842/6000 [49:33<5:08:37,  3.59s/it] 14%|â–ˆâ–        | 843/6000 [49:36<5:02:02,  3.51s/it]                                                    {'loss': 0.0058, 'grad_norm': 0.38049420714378357, 'learning_rate': 4.370338983050848e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 843/6000 [49:36<5:02:02,  3.51s/it] 14%|â–ˆâ–        | 844/6000 [49:40<5:00:46,  3.50s/it]                                                    {'loss': 0.0198, 'grad_norm': 1.65656578540802, 'learning_rate': 4.3694915254237286e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 844/6000 [49:40<5:00:46,  3.50s/it] 14%|â–ˆâ–        | 845/6000 [49:43<4:56:36,  3.45s/it]                                                    {'loss': 0.0159, 'grad_norm': 0.8608573079109192, 'learning_rate': 4.3686440677966105e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 845/6000 [49:43<4:56:36,  3.45s/it] 14%|â–ˆâ–        | 846/6000 [49:47<5:00:48,  3.50s/it]                                                    {'loss': 0.021, 'grad_norm': 2.1524429321289062, 'learning_rate': 4.3677966101694916e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 846/6000 [49:47<5:00:48,  3.50s/it] 14%|â–ˆâ–        | 847/6000 [49:50<4:58:02,  3.47s/it]                                                    {'loss': 0.0744, 'grad_norm': 2.6050047874450684, 'learning_rate': 4.3669491525423734e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 847/6000 [49:50<4:58:02,  3.47s/it] 14%|â–ˆâ–        | 848/6000 [49:54<5:06:14,  3.57s/it]                                                    {'loss': 0.0916, 'grad_norm': 2.599137306213379, 'learning_rate': 4.3661016949152545e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 848/6000 [49:54<5:06:14,  3.57s/it] 14%|â–ˆâ–        | 849/6000 [49:58<5:04:07,  3.54s/it]                                                    {'loss': 0.021, 'grad_norm': 1.8334391117095947, 'learning_rate': 4.3652542372881356e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 849/6000 [49:58<5:04:07,  3.54s/it] 14%|â–ˆâ–        | 850/6000 [50:01<5:00:13,  3.50s/it]                                                    {'loss': 0.0717, 'grad_norm': 3.8005611896514893, 'learning_rate': 4.3644067796610175e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 850/6000 [50:01<5:00:13,  3.50s/it][2025-10-21 02:14:23,734] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 14%|â–ˆâ–        | 851/6000 [50:06<5:51:09,  4.09s/it]                                                    {'loss': 0.1786, 'grad_norm': 5.495809555053711, 'learning_rate': 4.3635593220338986e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 851/6000 [50:06<5:51:09,  4.09s/it] 14%|â–ˆâ–        | 852/6000 [50:10<5:32:53,  3.88s/it]                                                    {'loss': 0.133, 'grad_norm': 3.60845947265625, 'learning_rate': 4.36271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 852/6000 [50:10<5:32:53,  3.88s/it] 14%|â–ˆâ–        | 853/6000 [50:13<5:17:46,  3.70s/it]                                                    {'loss': 0.0123, 'grad_norm': 0.6743103861808777, 'learning_rate': 4.361864406779661e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 853/6000 [50:13<5:17:46,  3.70s/it] 14%|â–ˆâ–        | 854/6000 [50:17<5:10:57,  3.63s/it]                                                    {'loss': 0.0295, 'grad_norm': 2.982267379760742, 'learning_rate': 4.3610169491525426e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 854/6000 [50:17<5:10:57,  3.63s/it] 14%|â–ˆâ–        | 855/6000 [50:20<5:05:05,  3.56s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.15865282714366913, 'learning_rate': 4.360169491525424e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 855/6000 [50:20<5:05:05,  3.56s/it] 14%|â–ˆâ–        | 856/6000 [50:23<5:03:05,  3.54s/it]                                                    {'loss': 0.2115, 'grad_norm': 6.523932933807373, 'learning_rate': 4.3593220338983056e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 856/6000 [50:23<5:03:05,  3.54s/it] 14%|â–ˆâ–        | 857/6000 [50:27<4:59:12,  3.49s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.05959935113787651, 'learning_rate': 4.358474576271187e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 857/6000 [50:27<4:59:12,  3.49s/it] 14%|â–ˆâ–        | 858/6000 [50:30<4:56:43,  3.46s/it]                                                    {'loss': 0.0267, 'grad_norm': 1.7180067300796509, 'learning_rate': 4.357627118644068e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 858/6000 [50:30<4:56:43,  3.46s/it] 14%|â–ˆâ–        | 859/6000 [50:34<4:53:00,  3.42s/it]                                                    {'loss': 0.0182, 'grad_norm': 1.17970871925354, 'learning_rate': 4.356779661016949e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 859/6000 [50:34<4:53:00,  3.42s/it] 14%|â–ˆâ–        | 860/6000 [50:37<5:02:37,  3.53s/it]                                                    {'loss': 0.0454, 'grad_norm': 2.0831446647644043, 'learning_rate': 4.355932203389831e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 860/6000 [50:37<5:02:37,  3.53s/it] 14%|â–ˆâ–        | 861/6000 [50:41<4:57:53,  3.48s/it]                                                    {'loss': 0.0031, 'grad_norm': 0.35384541749954224, 'learning_rate': 4.355084745762712e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 861/6000 [50:41<4:57:53,  3.48s/it] 14%|â–ˆâ–        | 862/6000 [50:44<4:54:12,  3.44s/it]                                                    {'loss': 0.1827, 'grad_norm': 6.60410737991333, 'learning_rate': 4.354237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 862/6000 [50:44<4:54:12,  3.44s/it] 14%|â–ˆâ–        | 863/6000 [50:47<4:54:01,  3.43s/it]                                                    {'loss': 0.0393, 'grad_norm': 3.2813949584960938, 'learning_rate': 4.353389830508475e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 863/6000 [50:47<4:54:01,  3.43s/it] 14%|â–ˆâ–        | 864/6000 [50:51<4:52:41,  3.42s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.007798124570399523, 'learning_rate': 4.3525423728813566e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 864/6000 [50:51<4:52:41,  3.42s/it] 14%|â–ˆâ–        | 865/6000 [50:55<5:01:32,  3.52s/it]                                                    {'loss': 0.2949, 'grad_norm': 7.174514293670654, 'learning_rate': 4.351694915254238e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 865/6000 [50:55<5:01:32,  3.52s/it] 14%|â–ˆâ–        | 866/6000 [50:58<4:57:50,  3.48s/it]                                                    {'loss': 0.0401, 'grad_norm': 3.4646146297454834, 'learning_rate': 4.350847457627119e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 866/6000 [50:58<4:57:50,  3.48s/it] 14%|â–ˆâ–        | 867/6000 [51:01<4:57:36,  3.48s/it]                                                    {'loss': 0.2564, 'grad_norm': 6.395092487335205, 'learning_rate': 4.35e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 867/6000 [51:01<4:57:36,  3.48s/it] 14%|â–ˆâ–        | 868/6000 [51:05<4:53:11,  3.43s/it]                                                    {'loss': 0.2057, 'grad_norm': 6.105391025543213, 'learning_rate': 4.349152542372882e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 868/6000 [51:05<4:53:11,  3.43s/it] 14%|â–ˆâ–        | 869/6000 [51:08<4:51:00,  3.40s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.08747393637895584, 'learning_rate': 4.348305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 869/6000 [51:08<4:51:00,  3.40s/it] 14%|â–ˆâ–        | 870/6000 [51:12<4:51:17,  3.41s/it]                                                    {'loss': 0.091, 'grad_norm': 3.7724099159240723, 'learning_rate': 4.347457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 870/6000 [51:12<4:51:17,  3.41s/it] 15%|â–ˆâ–        | 871/6000 [51:15<4:52:14,  3.42s/it]                                                    {'loss': 0.051, 'grad_norm': 3.6794967651367188, 'learning_rate': 4.346610169491526e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 871/6000 [51:15<4:52:14,  3.42s/it] 15%|â–ˆâ–        | 872/6000 [51:18<4:53:15,  3.43s/it]                                                    {'loss': 0.1642, 'grad_norm': 4.848684310913086, 'learning_rate': 4.345762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 872/6000 [51:18<4:53:15,  3.43s/it] 15%|â–ˆâ–        | 873/6000 [51:22<4:55:12,  3.45s/it]                                                    {'loss': 0.0628, 'grad_norm': 3.3754236698150635, 'learning_rate': 4.344915254237288e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 873/6000 [51:22<4:55:12,  3.45s/it] 15%|â–ˆâ–        | 874/6000 [51:25<4:53:49,  3.44s/it]                                                    {'loss': 0.1362, 'grad_norm': 4.416473388671875, 'learning_rate': 4.344067796610169e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 874/6000 [51:25<4:53:49,  3.44s/it] 15%|â–ˆâ–        | 875/6000 [51:29<4:58:49,  3.50s/it]                                                    {'loss': 0.0951, 'grad_norm': 3.7879433631896973, 'learning_rate': 4.343220338983051e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 875/6000 [51:29<4:58:49,  3.50s/it] 15%|â–ˆâ–        | 876/6000 [51:32<4:55:34,  3.46s/it]                                                    {'loss': 0.0183, 'grad_norm': 1.4657710790634155, 'learning_rate': 4.342372881355932e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 876/6000 [51:32<4:55:34,  3.46s/it] 15%|â–ˆâ–        | 877/6000 [51:36<4:54:19,  3.45s/it]                                                    {'loss': 0.1076, 'grad_norm': 5.123659610748291, 'learning_rate': 4.341525423728814e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 877/6000 [51:36<4:54:19,  3.45s/it] 15%|â–ˆâ–        | 878/6000 [51:39<4:53:26,  3.44s/it]                                                    {'loss': 0.0529, 'grad_norm': 3.533970594406128, 'learning_rate': 4.340677966101695e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 878/6000 [51:39<4:53:26,  3.44s/it] 15%|â–ˆâ–        | 879/6000 [51:43<5:06:49,  3.59s/it]                                                    {'loss': 0.1085, 'grad_norm': 2.947446823120117, 'learning_rate': 4.339830508474576e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 879/6000 [51:43<5:06:49,  3.59s/it] 15%|â–ˆâ–        | 880/6000 [51:47<5:02:21,  3.54s/it]                                                    {'loss': 0.4327, 'grad_norm': 7.8166046142578125, 'learning_rate': 4.3389830508474574e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 880/6000 [51:47<5:02:21,  3.54s/it] 15%|â–ˆâ–        | 881/6000 [51:50<4:58:45,  3.50s/it]                                                    {'loss': 0.0048, 'grad_norm': 0.5903676152229309, 'learning_rate': 4.338135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 881/6000 [51:50<4:58:45,  3.50s/it] 15%|â–ˆâ–        | 882/6000 [51:54<4:59:52,  3.52s/it]                                                    {'loss': 0.0258, 'grad_norm': 1.9481204748153687, 'learning_rate': 4.3372881355932203e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 882/6000 [51:54<4:59:52,  3.52s/it] 15%|â–ˆâ–        | 883/6000 [51:57<4:56:06,  3.47s/it]                                                    {'loss': 0.0148, 'grad_norm': 0.6424799561500549, 'learning_rate': 4.336440677966102e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 883/6000 [51:57<4:56:06,  3.47s/it] 15%|â–ˆâ–        | 884/6000 [52:01<4:59:12,  3.51s/it]                                                    {'loss': 0.1786, 'grad_norm': 4.84124755859375, 'learning_rate': 4.335593220338983e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 884/6000 [52:01<4:59:12,  3.51s/it] 15%|â–ˆâ–        | 885/6000 [52:04<4:57:25,  3.49s/it]                                                    {'loss': 0.0115, 'grad_norm': 0.721276581287384, 'learning_rate': 4.334745762711865e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 885/6000 [52:04<4:57:25,  3.49s/it] 15%|â–ˆâ–        | 886/6000 [52:07<4:56:29,  3.48s/it]                                                    {'loss': 0.0837, 'grad_norm': 4.1310601234436035, 'learning_rate': 4.333898305084746e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 886/6000 [52:07<4:56:29,  3.48s/it] 15%|â–ˆâ–        | 887/6000 [52:11<4:55:23,  3.47s/it]                                                    {'loss': 0.0032, 'grad_norm': 0.32438915967941284, 'learning_rate': 4.3330508474576273e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 887/6000 [52:11<4:55:23,  3.47s/it] 15%|â–ˆâ–        | 888/6000 [52:14<4:56:10,  3.48s/it]                                                    {'loss': 0.0105, 'grad_norm': 0.9110831618309021, 'learning_rate': 4.3322033898305085e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 888/6000 [52:14<4:56:10,  3.48s/it] 15%|â–ˆâ–        | 889/6000 [52:18<4:53:18,  3.44s/it]                                                    {'loss': 0.0991, 'grad_norm': 4.95971155166626, 'learning_rate': 4.33135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 889/6000 [52:18<4:53:18,  3.44s/it] 15%|â–ˆâ–        | 890/6000 [52:21<4:53:34,  3.45s/it]                                                    {'loss': 0.0211, 'grad_norm': 1.3126153945922852, 'learning_rate': 4.3305084745762714e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 890/6000 [52:21<4:53:34,  3.45s/it] 15%|â–ˆâ–        | 891/6000 [52:24<4:49:07,  3.40s/it]                                                    {'loss': 0.022, 'grad_norm': 1.0390172004699707, 'learning_rate': 4.3296610169491525e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 891/6000 [52:24<4:49:07,  3.40s/it] 15%|â–ˆâ–        | 892/6000 [52:28<4:50:07,  3.41s/it]                                                    {'loss': 0.0832, 'grad_norm': 3.7724854946136475, 'learning_rate': 4.3288135593220343e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 892/6000 [52:28<4:50:07,  3.41s/it] 15%|â–ˆâ–        | 893/6000 [52:31<4:48:15,  3.39s/it]                                                    {'loss': 0.1622, 'grad_norm': 5.066280364990234, 'learning_rate': 4.3279661016949155e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 893/6000 [52:31<4:48:15,  3.39s/it] 15%|â–ˆâ–        | 894/6000 [52:35<4:50:41,  3.42s/it]                                                    {'loss': 0.0754, 'grad_norm': 3.919961452484131, 'learning_rate': 4.3271186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 894/6000 [52:35<4:50:41,  3.42s/it] 15%|â–ˆâ–        | 895/6000 [52:38<4:49:05,  3.40s/it]                                                    {'loss': 0.0433, 'grad_norm': 2.2696712017059326, 'learning_rate': 4.326271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 895/6000 [52:38<4:49:05,  3.40s/it] 15%|â–ˆâ–        | 896/6000 [52:41<4:48:11,  3.39s/it]                                                    {'loss': 0.0028, 'grad_norm': 0.27375665307044983, 'learning_rate': 4.3254237288135595e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 896/6000 [52:41<4:48:11,  3.39s/it] 15%|â–ˆâ–        | 897/6000 [52:45<4:48:59,  3.40s/it]                                                    {'loss': 0.025, 'grad_norm': 1.4022328853607178, 'learning_rate': 4.3245762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 897/6000 [52:45<4:48:59,  3.40s/it] 15%|â–ˆâ–        | 898/6000 [52:48<4:48:19,  3.39s/it]                                                    {'loss': 0.1005, 'grad_norm': 2.9215943813323975, 'learning_rate': 4.3237288135593225e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 898/6000 [52:48<4:48:19,  3.39s/it] 15%|â–ˆâ–        | 899/6000 [52:53<5:11:12,  3.66s/it]                                                    {'loss': 0.0028, 'grad_norm': 0.1712881326675415, 'learning_rate': 4.3228813559322036e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 899/6000 [52:53<5:11:12,  3.66s/it] 15%|â–ˆâ–Œ        | 900/6000 [52:56<5:05:15,  3.59s/it]                                                    {'loss': 0.0394, 'grad_norm': 2.4158775806427, 'learning_rate': 4.3220338983050854e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 900/6000 [52:56<5:05:15,  3.59s/it][2025-10-21 02:17:18,690] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|â–ˆâ–Œ        | 901/6000 [53:02<6:03:12,  4.27s/it]                                                    {'loss': 0.0422, 'grad_norm': 3.2752816677093506, 'learning_rate': 4.321186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 901/6000 [53:02<6:03:12,  4.27s/it] 15%|â–ˆâ–Œ        | 902/6000 [53:05<5:39:02,  3.99s/it]                                                    {'loss': 0.0097, 'grad_norm': 0.6023736000061035, 'learning_rate': 4.3203389830508477e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 902/6000 [53:05<5:39:02,  3.99s/it] 15%|â–ˆâ–Œ        | 903/6000 [53:08<5:22:39,  3.80s/it]                                                    {'loss': 0.0733, 'grad_norm': 2.1739823818206787, 'learning_rate': 4.319491525423729e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 903/6000 [53:08<5:22:39,  3.80s/it] 15%|â–ˆâ–Œ        | 904/6000 [53:12<5:13:19,  3.69s/it]                                                    {'loss': 0.2778, 'grad_norm': 4.522080898284912, 'learning_rate': 4.3186440677966106e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 904/6000 [53:12<5:13:19,  3.69s/it] 15%|â–ˆâ–Œ        | 905/6000 [53:16<5:21:33,  3.79s/it]                                                    {'loss': 0.1017, 'grad_norm': 4.69340705871582, 'learning_rate': 4.317796610169492e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 905/6000 [53:16<5:21:33,  3.79s/it] 15%|â–ˆâ–Œ        | 906/6000 [53:19<5:15:23,  3.71s/it]                                                    {'loss': 0.0129, 'grad_norm': 1.03827965259552, 'learning_rate': 4.3169491525423735e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 906/6000 [53:19<5:15:23,  3.71s/it] 15%|â–ˆâ–Œ        | 907/6000 [53:23<5:17:23,  3.74s/it]                                                    {'loss': 0.1215, 'grad_norm': 1.7458515167236328, 'learning_rate': 4.3161016949152547e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 907/6000 [53:23<5:17:23,  3.74s/it] 15%|â–ˆâ–Œ        | 908/6000 [53:27<5:17:54,  3.75s/it]                                                    {'loss': 0.2086, 'grad_norm': 4.5564093589782715, 'learning_rate': 4.315254237288136e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 908/6000 [53:27<5:17:54,  3.75s/it] 15%|â–ˆâ–Œ        | 909/6000 [53:30<5:07:38,  3.63s/it]                                                    {'loss': 0.0575, 'grad_norm': 3.153867721557617, 'learning_rate': 4.314406779661017e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 909/6000 [53:30<5:07:38,  3.63s/it] 15%|â–ˆâ–Œ        | 910/6000 [53:34<5:03:35,  3.58s/it]                                                    {'loss': 0.0492, 'grad_norm': 2.5304532051086426, 'learning_rate': 4.313559322033899e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 910/6000 [53:34<5:03:35,  3.58s/it] 15%|â–ˆâ–Œ        | 911/6000 [53:37<5:00:10,  3.54s/it]                                                    {'loss': 0.0822, 'grad_norm': 4.474761009216309, 'learning_rate': 4.31271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 911/6000 [53:37<5:00:10,  3.54s/it] 15%|â–ˆâ–Œ        | 912/6000 [53:41<4:57:30,  3.51s/it]                                                    {'loss': 0.0201, 'grad_norm': 1.3600170612335205, 'learning_rate': 4.311864406779661e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 912/6000 [53:41<4:57:30,  3.51s/it] 15%|â–ˆâ–Œ        | 913/6000 [53:44<4:53:07,  3.46s/it]                                                    {'loss': 0.0281, 'grad_norm': 0.8260718584060669, 'learning_rate': 4.311016949152543e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 913/6000 [53:44<4:53:07,  3.46s/it] 15%|â–ˆâ–Œ        | 914/6000 [53:48<5:01:16,  3.55s/it]                                                    {'loss': 0.0022, 'grad_norm': 0.20777590572834015, 'learning_rate': 4.310169491525424e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 914/6000 [53:48<5:01:16,  3.55s/it] 15%|â–ˆâ–Œ        | 915/6000 [53:52<5:21:37,  3.80s/it]                                                    {'loss': 0.0924, 'grad_norm': 2.633676528930664, 'learning_rate': 4.309322033898305e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 915/6000 [53:52<5:21:37,  3.80s/it] 15%|â–ˆâ–Œ        | 916/6000 [53:56<5:12:19,  3.69s/it]                                                    {'loss': 0.0289, 'grad_norm': 1.4740604162216187, 'learning_rate': 4.308474576271186e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 916/6000 [53:56<5:12:19,  3.69s/it] 15%|â–ˆâ–Œ        | 917/6000 [53:59<5:04:42,  3.60s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.11062995344400406, 'learning_rate': 4.307627118644068e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 917/6000 [53:59<5:04:42,  3.60s/it] 15%|â–ˆâ–Œ        | 918/6000 [54:03<5:03:46,  3.59s/it]                                                    {'loss': 0.0057, 'grad_norm': 0.39496278762817383, 'learning_rate': 4.306779661016949e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 918/6000 [54:03<5:03:46,  3.59s/it] 15%|â–ˆâ–Œ        | 919/6000 [54:06<4:59:55,  3.54s/it]                                                    {'loss': 0.087, 'grad_norm': 1.98995840549469, 'learning_rate': 4.305932203389831e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 919/6000 [54:06<4:59:55,  3.54s/it] 15%|â–ˆâ–Œ        | 920/6000 [54:09<4:56:11,  3.50s/it]                                                    {'loss': 0.0463, 'grad_norm': 2.255493402481079, 'learning_rate': 4.305084745762712e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 920/6000 [54:09<4:56:11,  3.50s/it] 15%|â–ˆâ–Œ        | 921/6000 [54:13<4:55:15,  3.49s/it]                                                    {'loss': 0.0891, 'grad_norm': 3.967318534851074, 'learning_rate': 4.304237288135594e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 921/6000 [54:13<4:55:15,  3.49s/it] 15%|â–ˆâ–Œ        | 922/6000 [54:17<4:58:38,  3.53s/it]                                                    {'loss': 0.0038, 'grad_norm': 0.17957425117492676, 'learning_rate': 4.303389830508475e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 922/6000 [54:17<4:58:38,  3.53s/it] 15%|â–ˆâ–Œ        | 923/6000 [54:20<4:56:20,  3.50s/it]                                                    {'loss': 0.126, 'grad_norm': 2.9205613136291504, 'learning_rate': 4.302542372881356e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 923/6000 [54:20<4:56:20,  3.50s/it] 15%|â–ˆâ–Œ        | 924/6000 [54:23<4:51:11,  3.44s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.08978684991598129, 'learning_rate': 4.301694915254237e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 924/6000 [54:23<4:51:11,  3.44s/it] 15%|â–ˆâ–Œ        | 925/6000 [54:27<4:49:10,  3.42s/it]                                                    {'loss': 0.0572, 'grad_norm': 2.0757386684417725, 'learning_rate': 4.300847457627119e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 925/6000 [54:27<4:49:10,  3.42s/it] 15%|â–ˆâ–Œ        | 926/6000 [54:30<4:51:07,  3.44s/it]                                                    {'loss': 0.1391, 'grad_norm': 4.603011608123779, 'learning_rate': 4.3e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 926/6000 [54:30<4:51:07,  3.44s/it] 15%|â–ˆâ–Œ        | 927/6000 [54:33<4:49:02,  3.42s/it]                                                    {'loss': 0.3425, 'grad_norm': 5.267069339752197, 'learning_rate': 4.299152542372882e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 927/6000 [54:33<4:49:02,  3.42s/it] 15%|â–ˆâ–Œ        | 928/6000 [54:37<4:47:45,  3.40s/it]                                                    {'loss': 0.1112, 'grad_norm': 3.5893735885620117, 'learning_rate': 4.298305084745763e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 928/6000 [54:37<4:47:45,  3.40s/it] 15%|â–ˆâ–Œ        | 929/6000 [54:40<4:47:46,  3.41s/it]                                                    {'loss': 0.046, 'grad_norm': 1.8199015855789185, 'learning_rate': 4.297457627118644e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 929/6000 [54:40<4:47:46,  3.41s/it] 16%|â–ˆâ–Œ        | 930/6000 [54:44<4:47:14,  3.40s/it]                                                    {'loss': 0.2599, 'grad_norm': 4.247374057769775, 'learning_rate': 4.2966101694915254e-05, 'epoch': 0.15}
 16%|â–ˆâ–Œ        | 930/6000 [54:44<4:47:14,  3.40s/it] 16%|â–ˆâ–Œ        | 931/6000 [54:47<4:48:43,  3.42s/it]                                                    {'loss': 0.0135, 'grad_norm': 0.9168841242790222, 'learning_rate': 4.2957627118644065e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 931/6000 [54:47<4:48:43,  3.42s/it] 16%|â–ˆâ–Œ        | 932/6000 [54:50<4:47:37,  3.41s/it]                                                    {'loss': 0.0086, 'grad_norm': 0.768440306186676, 'learning_rate': 4.294915254237288e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 932/6000 [54:50<4:47:37,  3.41s/it] 16%|â–ˆâ–Œ        | 933/6000 [54:54<4:46:42,  3.39s/it]                                                    {'loss': 0.0846, 'grad_norm': 4.65829610824585, 'learning_rate': 4.2940677966101694e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 933/6000 [54:54<4:46:42,  3.39s/it] 16%|â–ˆâ–Œ        | 934/6000 [54:58<4:58:08,  3.53s/it]                                                    {'loss': 0.0236, 'grad_norm': 0.992151141166687, 'learning_rate': 4.293220338983051e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 934/6000 [54:58<4:58:08,  3.53s/it] 16%|â–ˆâ–Œ        | 935/6000 [55:01<4:52:42,  3.47s/it]                                                    {'loss': 0.0211, 'grad_norm': 0.8895142078399658, 'learning_rate': 4.2923728813559324e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 935/6000 [55:01<4:52:42,  3.47s/it] 16%|â–ˆâ–Œ        | 936/6000 [55:04<4:50:01,  3.44s/it]                                                    {'loss': 0.0764, 'grad_norm': 3.4846813678741455, 'learning_rate': 4.291525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 936/6000 [55:04<4:50:01,  3.44s/it] 16%|â–ˆâ–Œ        | 937/6000 [55:08<4:51:32,  3.45s/it]                                                    {'loss': 0.1111, 'grad_norm': 4.459231376647949, 'learning_rate': 4.2906779661016946e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 937/6000 [55:08<4:51:32,  3.45s/it] 16%|â–ˆâ–Œ        | 938/6000 [55:11<4:49:35,  3.43s/it]                                                    {'loss': 0.0182, 'grad_norm': 1.3870197534561157, 'learning_rate': 4.2898305084745764e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 938/6000 [55:11<4:49:35,  3.43s/it] 16%|â–ˆâ–Œ        | 939/6000 [55:15<4:51:12,  3.45s/it]                                                    {'loss': 0.0086, 'grad_norm': 0.5118595361709595, 'learning_rate': 4.2889830508474575e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 939/6000 [55:15<4:51:12,  3.45s/it] 16%|â–ˆâ–Œ        | 940/6000 [55:18<4:50:08,  3.44s/it]                                                    {'loss': 0.001, 'grad_norm': 0.06425712257623672, 'learning_rate': 4.2881355932203394e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 940/6000 [55:18<4:50:08,  3.44s/it] 16%|â–ˆâ–Œ        | 941/6000 [55:22<5:05:58,  3.63s/it]                                                    {'loss': 0.0045, 'grad_norm': 0.2677896320819855, 'learning_rate': 4.2872881355932205e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 941/6000 [55:22<5:05:58,  3.63s/it] 16%|â–ˆâ–Œ        | 942/6000 [55:26<4:59:11,  3.55s/it]                                                    {'loss': 0.2074, 'grad_norm': 6.262295246124268, 'learning_rate': 4.286440677966102e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 942/6000 [55:26<4:59:11,  3.55s/it] 16%|â–ˆâ–Œ        | 943/6000 [55:29<4:55:55,  3.51s/it]                                                    {'loss': 0.0088, 'grad_norm': 0.5037116408348083, 'learning_rate': 4.2855932203389834e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 943/6000 [55:29<4:55:55,  3.51s/it] 16%|â–ˆâ–Œ        | 944/6000 [55:32<4:53:07,  3.48s/it]                                                    {'loss': 0.0407, 'grad_norm': 1.615136981010437, 'learning_rate': 4.2847457627118645e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 944/6000 [55:32<4:53:07,  3.48s/it] 16%|â–ˆâ–Œ        | 945/6000 [55:36<4:59:59,  3.56s/it]                                                    {'loss': 0.1872, 'grad_norm': 4.512534141540527, 'learning_rate': 4.283898305084746e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 945/6000 [55:36<4:59:59,  3.56s/it] 16%|â–ˆâ–Œ        | 946/6000 [55:40<4:57:42,  3.53s/it]                                                    {'loss': 0.0082, 'grad_norm': 0.7659524083137512, 'learning_rate': 4.2830508474576275e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 946/6000 [55:40<4:57:42,  3.53s/it] 16%|â–ˆâ–Œ        | 947/6000 [55:43<4:54:25,  3.50s/it]                                                    {'loss': 0.1057, 'grad_norm': 2.3620765209198, 'learning_rate': 4.2822033898305086e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 947/6000 [55:43<4:54:25,  3.50s/it] 16%|â–ˆâ–Œ        | 948/6000 [55:47<4:58:03,  3.54s/it]                                                    {'loss': 0.0612, 'grad_norm': 2.4086976051330566, 'learning_rate': 4.2813559322033904e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 948/6000 [55:47<4:58:03,  3.54s/it] 16%|â–ˆâ–Œ        | 949/6000 [55:51<5:05:05,  3.62s/it]                                                    {'loss': 0.0496, 'grad_norm': 3.083505392074585, 'learning_rate': 4.2805084745762715e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 949/6000 [55:51<5:05:05,  3.62s/it] 16%|â–ˆâ–Œ        | 950/6000 [55:54<5:01:18,  3.58s/it]                                                    {'loss': 0.1002, 'grad_norm': 4.744585037231445, 'learning_rate': 4.279661016949153e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 950/6000 [55:54<5:01:18,  3.58s/it][2025-10-21 02:20:16,754] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 16%|â–ˆâ–Œ        | 951/6000 [56:00<5:49:37,  4.15s/it]                                                    {'loss': 0.1126, 'grad_norm': 2.8429529666900635, 'learning_rate': 4.278813559322034e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 951/6000 [56:00<5:49:37,  4.15s/it] 16%|â–ˆâ–Œ        | 952/6000 [56:03<5:30:45,  3.93s/it]                                                    {'loss': 0.161, 'grad_norm': 4.048578262329102, 'learning_rate': 4.277966101694915e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 952/6000 [56:03<5:30:45,  3.93s/it] 16%|â–ˆâ–Œ        | 953/6000 [56:06<5:21:08,  3.82s/it]                                                    {'loss': 0.0013, 'grad_norm': 0.08262091875076294, 'learning_rate': 4.277118644067797e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 953/6000 [56:06<5:21:08,  3.82s/it] 16%|â–ˆâ–Œ        | 954/6000 [56:10<5:09:40,  3.68s/it]                                                    {'loss': 0.0135, 'grad_norm': 0.974124014377594, 'learning_rate': 4.276271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 954/6000 [56:10<5:09:40,  3.68s/it] 16%|â–ˆâ–Œ        | 955/6000 [56:13<5:04:17,  3.62s/it]                                                    {'loss': 0.1622, 'grad_norm': 5.048554420471191, 'learning_rate': 4.27542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 955/6000 [56:13<5:04:17,  3.62s/it] 16%|â–ˆâ–Œ        | 956/6000 [56:17<5:04:29,  3.62s/it]                                                    {'loss': 0.0821, 'grad_norm': 3.5194644927978516, 'learning_rate': 4.274576271186441e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 956/6000 [56:17<5:04:29,  3.62s/it] 16%|â–ˆâ–Œ        | 957/6000 [56:20<4:58:03,  3.55s/it]                                                    {'loss': 0.036, 'grad_norm': 1.5954041481018066, 'learning_rate': 4.2737288135593226e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 957/6000 [56:20<4:58:03,  3.55s/it] 16%|â–ˆâ–Œ        | 958/6000 [56:24<4:57:11,  3.54s/it]                                                    {'loss': 0.1452, 'grad_norm': 3.811800241470337, 'learning_rate': 4.272881355932204e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 958/6000 [56:24<4:57:11,  3.54s/it] 16%|â–ˆâ–Œ        | 959/6000 [56:27<4:50:22,  3.46s/it]                                                    {'loss': 0.028, 'grad_norm': 1.2436509132385254, 'learning_rate': 4.272033898305085e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 959/6000 [56:27<4:50:22,  3.46s/it] 16%|â–ˆâ–Œ        | 960/6000 [56:31<4:50:51,  3.46s/it]                                                    {'loss': 0.3172, 'grad_norm': 5.716176509857178, 'learning_rate': 4.271186440677966e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 960/6000 [56:31<4:50:51,  3.46s/it] 16%|â–ˆâ–Œ        | 961/6000 [56:34<4:52:13,  3.48s/it]                                                    {'loss': 0.0307, 'grad_norm': 1.3797309398651123, 'learning_rate': 4.270338983050848e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 961/6000 [56:34<4:52:13,  3.48s/it] 16%|â–ˆâ–Œ        | 962/6000 [56:38<5:00:50,  3.58s/it]                                                    {'loss': 0.0791, 'grad_norm': 3.3410024642944336, 'learning_rate': 4.269491525423729e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 962/6000 [56:38<5:00:50,  3.58s/it] 16%|â–ˆâ–Œ        | 963/6000 [56:41<4:55:51,  3.52s/it]                                                    {'loss': 0.1005, 'grad_norm': 3.459367513656616, 'learning_rate': 4.268644067796611e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 963/6000 [56:41<4:55:51,  3.52s/it] 16%|â–ˆâ–Œ        | 964/6000 [56:45<4:52:34,  3.49s/it]                                                    {'loss': 0.1367, 'grad_norm': 3.5811893939971924, 'learning_rate': 4.267796610169492e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 964/6000 [56:45<4:52:34,  3.49s/it] 16%|â–ˆâ–Œ        | 965/6000 [56:48<4:52:42,  3.49s/it]                                                    {'loss': 0.0938, 'grad_norm': 4.142542362213135, 'learning_rate': 4.266949152542373e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 965/6000 [56:48<4:52:42,  3.49s/it] 16%|â–ˆâ–Œ        | 966/6000 [56:52<4:53:50,  3.50s/it]                                                    {'loss': 0.0008, 'grad_norm': 0.0806511715054512, 'learning_rate': 4.266101694915254e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 966/6000 [56:52<4:53:50,  3.50s/it] 16%|â–ˆâ–Œ        | 967/6000 [56:55<4:53:33,  3.50s/it]                                                    {'loss': 0.0053, 'grad_norm': 0.3221132457256317, 'learning_rate': 4.265254237288136e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 967/6000 [56:55<4:53:33,  3.50s/it] 16%|â–ˆâ–Œ        | 968/6000 [56:59<4:59:48,  3.57s/it]                                                    {'loss': 0.0063, 'grad_norm': 0.5967938303947449, 'learning_rate': 4.264406779661017e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 968/6000 [56:59<4:59:48,  3.57s/it] 16%|â–ˆâ–Œ        | 969/6000 [57:02<4:55:16,  3.52s/it]                                                    {'loss': 0.0219, 'grad_norm': 2.063047170639038, 'learning_rate': 4.263559322033899e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 969/6000 [57:02<4:55:16,  3.52s/it] 16%|â–ˆâ–Œ        | 970/6000 [57:06<4:55:57,  3.53s/it]                                                    {'loss': 0.0216, 'grad_norm': 1.441577434539795, 'learning_rate': 4.26271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 970/6000 [57:06<4:55:57,  3.53s/it] 16%|â–ˆâ–Œ        | 971/6000 [57:09<4:51:05,  3.47s/it]                                                    {'loss': 0.0816, 'grad_norm': 3.640963554382324, 'learning_rate': 4.261864406779662e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 971/6000 [57:09<4:51:05,  3.47s/it] 16%|â–ˆâ–Œ        | 972/6000 [57:13<4:49:32,  3.46s/it]                                                    {'loss': 0.1132, 'grad_norm': 3.1507749557495117, 'learning_rate': 4.261016949152542e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 972/6000 [57:13<4:49:32,  3.46s/it] 16%|â–ˆâ–Œ        | 973/6000 [57:16<4:49:23,  3.45s/it]                                                    {'loss': 0.1631, 'grad_norm': 4.596284866333008, 'learning_rate': 4.2601694915254234e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 973/6000 [57:16<4:49:23,  3.45s/it] 16%|â–ˆâ–Œ        | 974/6000 [57:20<4:48:27,  3.44s/it]                                                    {'loss': 0.0167, 'grad_norm': 1.61650812625885, 'learning_rate': 4.259322033898305e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 974/6000 [57:20<4:48:27,  3.44s/it] 16%|â–ˆâ–‹        | 975/6000 [57:23<4:45:56,  3.41s/it]                                                    {'loss': 0.0578, 'grad_norm': 2.105435848236084, 'learning_rate': 4.258474576271186e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 975/6000 [57:23<4:45:56,  3.41s/it] 16%|â–ˆâ–‹        | 976/6000 [57:26<4:49:02,  3.45s/it]                                                    {'loss': 0.0015, 'grad_norm': 0.10166580229997635, 'learning_rate': 4.257627118644068e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 976/6000 [57:26<4:49:02,  3.45s/it] 16%|â–ˆâ–‹        | 977/6000 [57:30<4:46:09,  3.42s/it]                                                    {'loss': 0.054, 'grad_norm': 2.9532783031463623, 'learning_rate': 4.256779661016949e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 977/6000 [57:30<4:46:09,  3.42s/it] 16%|â–ˆâ–‹        | 978/6000 [57:33<4:43:23,  3.39s/it]                                                    {'loss': 0.0806, 'grad_norm': 4.601886749267578, 'learning_rate': 4.255932203389831e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 978/6000 [57:33<4:43:23,  3.39s/it] 16%|â–ˆâ–‹        | 979/6000 [57:36<4:42:01,  3.37s/it]                                                    {'loss': 0.0362, 'grad_norm': 1.7801976203918457, 'learning_rate': 4.255084745762712e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 979/6000 [57:36<4:42:01,  3.37s/it] 16%|â–ˆâ–‹        | 980/6000 [57:40<4:44:58,  3.41s/it]                                                    {'loss': 0.0875, 'grad_norm': 3.610213279724121, 'learning_rate': 4.254237288135593e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 980/6000 [57:40<4:44:58,  3.41s/it] 16%|â–ˆâ–‹        | 981/6000 [57:43<4:44:38,  3.40s/it]                                                    {'loss': 0.0518, 'grad_norm': 1.5290000438690186, 'learning_rate': 4.2533898305084744e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 981/6000 [57:43<4:44:38,  3.40s/it] 16%|â–ˆâ–‹        | 982/6000 [57:47<4:49:06,  3.46s/it]                                                    {'loss': 0.1357, 'grad_norm': 3.91756010055542, 'learning_rate': 4.252542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 982/6000 [57:47<4:49:06,  3.46s/it] 16%|â–ˆâ–‹        | 983/6000 [57:50<4:48:53,  3.45s/it]                                                    {'loss': 0.0152, 'grad_norm': 0.6503759622573853, 'learning_rate': 4.2516949152542374e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 983/6000 [57:50<4:48:53,  3.45s/it] 16%|â–ˆâ–‹        | 984/6000 [57:54<4:45:59,  3.42s/it]                                                    {'loss': 0.1043, 'grad_norm': 3.3184585571289062, 'learning_rate': 4.250847457627119e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 984/6000 [57:54<4:45:59,  3.42s/it] 16%|â–ˆâ–‹        | 985/6000 [57:57<4:49:44,  3.47s/it]                                                    {'loss': 0.0615, 'grad_norm': 2.144414186477661, 'learning_rate': 4.25e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 985/6000 [57:57<4:49:44,  3.47s/it] 16%|â–ˆâ–‹        | 986/6000 [58:01<4:46:12,  3.42s/it]                                                    {'loss': 0.1128, 'grad_norm': 2.6271767616271973, 'learning_rate': 4.2491525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 986/6000 [58:01<4:46:12,  3.42s/it] 16%|â–ˆâ–‹        | 987/6000 [58:04<4:48:48,  3.46s/it]                                                    {'loss': 0.0043, 'grad_norm': 0.537819504737854, 'learning_rate': 4.2483050847457626e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 987/6000 [58:04<4:48:48,  3.46s/it] 16%|â–ˆâ–‹        | 988/6000 [58:07<4:47:17,  3.44s/it]                                                    {'loss': 0.0585, 'grad_norm': 1.8466382026672363, 'learning_rate': 4.2474576271186444e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 988/6000 [58:07<4:47:17,  3.44s/it] 16%|â–ˆâ–‹        | 989/6000 [58:11<4:47:16,  3.44s/it]                                                    {'loss': 0.1408, 'grad_norm': 5.149502277374268, 'learning_rate': 4.2466101694915255e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 989/6000 [58:11<4:47:16,  3.44s/it] 16%|â–ˆâ–‹        | 990/6000 [58:14<4:48:30,  3.46s/it]                                                    {'loss': 0.0807, 'grad_norm': 4.308491230010986, 'learning_rate': 4.245762711864407e-05, 'epoch': 0.17}
 16%|â–ˆâ–‹        | 990/6000 [58:14<4:48:30,  3.46s/it] 17%|â–ˆâ–‹        | 991/6000 [58:18<5:01:02,  3.61s/it]                                                    {'loss': 0.0448, 'grad_norm': 2.3818249702453613, 'learning_rate': 4.2449152542372884e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 991/6000 [58:18<5:01:02,  3.61s/it] 17%|â–ˆâ–‹        | 992/6000 [58:22<4:57:29,  3.56s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.04541396722197533, 'learning_rate': 4.24406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 992/6000 [58:22<4:57:29,  3.56s/it] 17%|â–ˆâ–‹        | 993/6000 [58:25<4:54:55,  3.53s/it]                                                    {'loss': 0.0075, 'grad_norm': 0.4264219403266907, 'learning_rate': 4.2432203389830514e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 993/6000 [58:25<4:54:55,  3.53s/it] 17%|â–ˆâ–‹        | 994/6000 [58:29<4:54:10,  3.53s/it]                                                    {'loss': 0.005, 'grad_norm': 0.28408560156822205, 'learning_rate': 4.242372881355932e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 994/6000 [58:29<4:54:10,  3.53s/it] 17%|â–ˆâ–‹        | 995/6000 [58:32<4:54:29,  3.53s/it]                                                    {'loss': 0.1485, 'grad_norm': 4.311102867126465, 'learning_rate': 4.2415254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 995/6000 [58:32<4:54:29,  3.53s/it] 17%|â–ˆâ–‹        | 996/6000 [58:36<4:52:01,  3.50s/it]                                                    {'loss': 0.002, 'grad_norm': 0.15640904009342194, 'learning_rate': 4.240677966101695e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 996/6000 [58:36<4:52:01,  3.50s/it] 17%|â–ˆâ–‹        | 997/6000 [58:39<4:53:31,  3.52s/it]                                                    {'loss': 0.1636, 'grad_norm': 3.4290480613708496, 'learning_rate': 4.2398305084745766e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 997/6000 [58:39<4:53:31,  3.52s/it] 17%|â–ˆâ–‹        | 998/6000 [58:43<4:50:14,  3.48s/it]                                                    {'loss': 0.2116, 'grad_norm': 6.1896233558654785, 'learning_rate': 4.238983050847458e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 998/6000 [58:43<4:50:14,  3.48s/it] 17%|â–ˆâ–‹        | 999/6000 [58:46<4:48:08,  3.46s/it]                                                    {'loss': 0.038, 'grad_norm': 1.7081042528152466, 'learning_rate': 4.2381355932203395e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 999/6000 [58:46<4:48:08,  3.46s/it] 17%|â–ˆâ–‹        | 1000/6000 [58:50<4:50:54,  3.49s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.06645824015140533, 'learning_rate': 4.2372881355932206e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1000/6000 [58:50<4:50:54,  3.49s/it][2025-10-21 02:23:12,465] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 17%|â–ˆâ–‹        | 1001/6000 [58:55<5:41:50,  4.10s/it]                                                     {'loss': 0.2996, 'grad_norm': 5.456394672393799, 'learning_rate': 4.236440677966102e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1001/6000 [58:55<5:41:50,  4.10s/it] 17%|â–ˆâ–‹        | 1002/6000 [58:59<5:28:10,  3.94s/it]                                                     {'loss': 0.0022, 'grad_norm': 0.17969538271427155, 'learning_rate': 4.235593220338983e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1002/6000 [58:59<5:28:10,  3.94s/it] 17%|â–ˆâ–‹        | 1003/6000 [59:02<5:11:57,  3.75s/it]                                                     {'loss': 0.1737, 'grad_norm': 5.0552215576171875, 'learning_rate': 4.234745762711865e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1003/6000 [59:02<5:11:57,  3.75s/it] 17%|â–ˆâ–‹        | 1004/6000 [59:05<5:01:01,  3.62s/it]                                                     {'loss': 0.0157, 'grad_norm': 0.8864066004753113, 'learning_rate': 4.233898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1004/6000 [59:05<5:01:01,  3.62s/it] 17%|â–ˆâ–‹        | 1005/6000 [59:09<4:54:32,  3.54s/it]                                                     {'loss': 0.0322, 'grad_norm': 2.339334726333618, 'learning_rate': 4.2330508474576276e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1005/6000 [59:09<4:54:32,  3.54s/it] 17%|â–ˆâ–‹        | 1006/6000 [59:12<4:48:39,  3.47s/it]                                                     {'loss': 0.1218, 'grad_norm': 5.123220443725586, 'learning_rate': 4.232203389830509e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1006/6000 [59:12<4:48:39,  3.47s/it] 17%|â–ˆâ–‹        | 1007/6000 [59:15<4:46:47,  3.45s/it]                                                     {'loss': 0.0057, 'grad_norm': 0.43053409457206726, 'learning_rate': 4.23135593220339e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1007/6000 [59:15<4:46:47,  3.45s/it] 17%|â–ˆâ–‹        | 1008/6000 [59:19<4:46:26,  3.44s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.4639452397823334, 'learning_rate': 4.230508474576271e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1008/6000 [59:19<4:46:26,  3.44s/it] 17%|â–ˆâ–‹        | 1009/6000 [59:22<4:46:24,  3.44s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.040275443345308304, 'learning_rate': 4.229661016949153e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1009/6000 [59:22<4:46:24,  3.44s/it] 17%|â–ˆâ–‹        | 1010/6000 [59:26<4:43:16,  3.41s/it]                                                     {'loss': 0.0786, 'grad_norm': 3.208531379699707, 'learning_rate': 4.228813559322034e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1010/6000 [59:26<4:43:16,  3.41s/it] 17%|â–ˆâ–‹        | 1011/6000 [59:29<4:44:18,  3.42s/it]                                                     {'loss': 0.0546, 'grad_norm': 1.5380570888519287, 'learning_rate': 4.227966101694916e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1011/6000 [59:29<4:44:18,  3.42s/it] 17%|â–ˆâ–‹        | 1012/6000 [59:33<4:46:05,  3.44s/it]                                                     {'loss': 0.0313, 'grad_norm': 2.140711545944214, 'learning_rate': 4.227118644067797e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1012/6000 [59:33<4:46:05,  3.44s/it] 17%|â–ˆâ–‹        | 1013/6000 [59:36<4:43:52,  3.42s/it]                                                     {'loss': 0.065, 'grad_norm': 2.994584560394287, 'learning_rate': 4.226271186440679e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1013/6000 [59:36<4:43:52,  3.42s/it] 17%|â–ˆâ–‹        | 1014/6000 [59:39<4:40:56,  3.38s/it]                                                     {'loss': 0.185, 'grad_norm': 5.344532489776611, 'learning_rate': 4.22542372881356e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1014/6000 [59:39<4:40:56,  3.38s/it] 17%|â–ˆâ–‹        | 1015/6000 [59:43<4:41:37,  3.39s/it]                                                     {'loss': 0.0588, 'grad_norm': 4.5089311599731445, 'learning_rate': 4.224576271186441e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1015/6000 [59:43<4:41:37,  3.39s/it] 17%|â–ˆâ–‹        | 1016/6000 [59:46<4:42:50,  3.41s/it]                                                     {'loss': 0.0386, 'grad_norm': 2.3324947357177734, 'learning_rate': 4.223728813559322e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1016/6000 [59:46<4:42:50,  3.41s/it] 17%|â–ˆâ–‹        | 1017/6000 [59:50<4:46:22,  3.45s/it]                                                     {'loss': 0.0918, 'grad_norm': 2.3315677642822266, 'learning_rate': 4.222881355932203e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1017/6000 [59:50<4:46:22,  3.45s/it] 17%|â–ˆâ–‹        | 1018/6000 [59:53<4:47:22,  3.46s/it]                                                     {'loss': 0.0076, 'grad_norm': 0.3494073748588562, 'learning_rate': 4.222033898305085e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1018/6000 [59:53<4:47:22,  3.46s/it] 17%|â–ˆâ–‹        | 1019/6000 [59:57<4:45:21,  3.44s/it]                                                     {'loss': 0.0353, 'grad_norm': 1.8116745948791504, 'learning_rate': 4.221186440677966e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1019/6000 [59:57<4:45:21,  3.44s/it] 17%|â–ˆâ–‹        | 1020/6000 [1:00:00<4:45:54,  3.44s/it]                                                       {'loss': 0.174, 'grad_norm': 4.657515525817871, 'learning_rate': 4.220338983050848e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1020/6000 [1:00:00<4:45:54,  3.44s/it] 17%|â–ˆâ–‹        | 1021/6000 [1:00:03<4:46:49,  3.46s/it]                                                       {'loss': 0.0499, 'grad_norm': 1.7131479978561401, 'learning_rate': 4.219491525423729e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1021/6000 [1:00:03<4:46:49,  3.46s/it] 17%|â–ˆâ–‹        | 1022/6000 [1:00:07<4:51:41,  3.52s/it]                                                       {'loss': 0.0115, 'grad_norm': 0.8946365118026733, 'learning_rate': 4.21864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1022/6000 [1:00:07<4:51:41,  3.52s/it] 17%|â–ˆâ–‹        | 1023/6000 [1:00:11<4:48:43,  3.48s/it]                                                       {'loss': 0.1684, 'grad_norm': 5.12373685836792, 'learning_rate': 4.217796610169491e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1023/6000 [1:00:11<4:48:43,  3.48s/it] 17%|â–ˆâ–‹        | 1024/6000 [1:00:14<4:46:29,  3.45s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.2859834134578705, 'learning_rate': 4.216949152542373e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1024/6000 [1:00:14<4:46:29,  3.45s/it] 17%|â–ˆâ–‹        | 1025/6000 [1:00:17<4:44:10,  3.43s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.21910925209522247, 'learning_rate': 4.216101694915254e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1025/6000 [1:00:17<4:44:10,  3.43s/it] 17%|â–ˆâ–‹        | 1026/6000 [1:00:21<4:42:11,  3.40s/it]                                                       {'loss': 0.0683, 'grad_norm': 3.4554951190948486, 'learning_rate': 4.215254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1026/6000 [1:00:21<4:42:11,  3.40s/it] 17%|â–ˆâ–‹        | 1027/6000 [1:00:24<4:40:55,  3.39s/it]                                                       {'loss': 0.0156, 'grad_norm': 0.9607717990875244, 'learning_rate': 4.214406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1027/6000 [1:00:24<4:40:55,  3.39s/it] 17%|â–ˆâ–‹        | 1028/6000 [1:00:27<4:40:18,  3.38s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.28502365946769714, 'learning_rate': 4.213559322033899e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1028/6000 [1:00:27<4:40:18,  3.38s/it] 17%|â–ˆâ–‹        | 1029/6000 [1:00:31<4:40:05,  3.38s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.238215371966362, 'learning_rate': 4.2127118644067795e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1029/6000 [1:00:31<4:40:05,  3.38s/it] 17%|â–ˆâ–‹        | 1030/6000 [1:00:34<4:39:05,  3.37s/it]                                                       {'loss': 0.0301, 'grad_norm': 2.067232131958008, 'learning_rate': 4.211864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1030/6000 [1:00:34<4:39:05,  3.37s/it] 17%|â–ˆâ–‹        | 1031/6000 [1:00:38<4:40:15,  3.38s/it]                                                       {'loss': 0.0573, 'grad_norm': 3.625778913497925, 'learning_rate': 4.2110169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1031/6000 [1:00:38<4:40:15,  3.38s/it] 17%|â–ˆâ–‹        | 1032/6000 [1:00:41<4:39:21,  3.37s/it]                                                       {'loss': 0.0211, 'grad_norm': 1.517234444618225, 'learning_rate': 4.210169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1032/6000 [1:00:41<4:39:21,  3.37s/it] 17%|â–ˆâ–‹        | 1033/6000 [1:00:44<4:40:47,  3.39s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.3464778661727905, 'learning_rate': 4.209322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1033/6000 [1:00:44<4:40:47,  3.39s/it] 17%|â–ˆâ–‹        | 1034/6000 [1:00:48<4:38:14,  3.36s/it]                                                       {'loss': 0.0776, 'grad_norm': 1.5016154050827026, 'learning_rate': 4.208474576271187e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1034/6000 [1:00:48<4:38:14,  3.36s/it] 17%|â–ˆâ–‹        | 1035/6000 [1:00:51<4:41:12,  3.40s/it]                                                       {'loss': 0.0284, 'grad_norm': 1.765191912651062, 'learning_rate': 4.207627118644068e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1035/6000 [1:00:51<4:41:12,  3.40s/it] 17%|â–ˆâ–‹        | 1036/6000 [1:00:55<4:42:10,  3.41s/it]                                                       {'loss': 0.1475, 'grad_norm': 5.055253982543945, 'learning_rate': 4.2067796610169494e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1036/6000 [1:00:55<4:42:10,  3.41s/it] 17%|â–ˆâ–‹        | 1037/6000 [1:00:58<4:44:54,  3.44s/it]                                                       {'loss': 0.0578, 'grad_norm': 3.6313838958740234, 'learning_rate': 4.2059322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1037/6000 [1:00:58<4:44:54,  3.44s/it] 17%|â–ˆâ–‹        | 1038/6000 [1:01:02<4:53:01,  3.54s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.29214993119239807, 'learning_rate': 4.2050847457627116e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1038/6000 [1:01:02<4:53:01,  3.54s/it] 17%|â–ˆâ–‹        | 1039/6000 [1:01:05<4:52:02,  3.53s/it]                                                       {'loss': 0.041, 'grad_norm': 1.943746566772461, 'learning_rate': 4.2042372881355934e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1039/6000 [1:01:05<4:52:02,  3.53s/it] 17%|â–ˆâ–‹        | 1040/6000 [1:01:09<4:51:36,  3.53s/it]                                                       {'loss': 0.1015, 'grad_norm': 4.238868713378906, 'learning_rate': 4.2033898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1040/6000 [1:01:09<4:51:36,  3.53s/it] 17%|â–ˆâ–‹        | 1041/6000 [1:01:12<4:46:45,  3.47s/it]                                                       {'loss': 0.0667, 'grad_norm': 3.725952386856079, 'learning_rate': 4.2025423728813564e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1041/6000 [1:01:12<4:46:45,  3.47s/it] 17%|â–ˆâ–‹        | 1042/6000 [1:01:16<4:48:46,  3.49s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.4394121766090393, 'learning_rate': 4.2016949152542375e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1042/6000 [1:01:16<4:48:46,  3.49s/it] 17%|â–ˆâ–‹        | 1043/6000 [1:01:19<4:45:06,  3.45s/it]                                                       {'loss': 0.0991, 'grad_norm': 4.426085472106934, 'learning_rate': 4.2008474576271186e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1043/6000 [1:01:19<4:45:06,  3.45s/it] 17%|â–ˆâ–‹        | 1044/6000 [1:01:23<4:47:29,  3.48s/it]                                                       {'loss': 0.0187, 'grad_norm': 1.0952504873275757, 'learning_rate': 4.2e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1044/6000 [1:01:23<4:47:29,  3.48s/it] 17%|â–ˆâ–‹        | 1045/6000 [1:01:26<4:48:42,  3.50s/it]                                                       {'loss': 0.2613, 'grad_norm': 5.44277286529541, 'learning_rate': 4.1991525423728816e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1045/6000 [1:01:26<4:48:42,  3.50s/it] 17%|â–ˆâ–‹        | 1046/6000 [1:01:30<4:48:26,  3.49s/it]                                                       {'loss': 0.1235, 'grad_norm': 4.545006275177002, 'learning_rate': 4.198305084745763e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1046/6000 [1:01:30<4:48:26,  3.49s/it] 17%|â–ˆâ–‹        | 1047/6000 [1:01:33<4:55:50,  3.58s/it]                                                       {'loss': 0.3251, 'grad_norm': 6.223381042480469, 'learning_rate': 4.1974576271186445e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1047/6000 [1:01:33<4:55:50,  3.58s/it] 17%|â–ˆâ–‹        | 1048/6000 [1:01:37<4:50:17,  3.52s/it]                                                       {'loss': 0.0275, 'grad_norm': 3.135929822921753, 'learning_rate': 4.1966101694915256e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1048/6000 [1:01:37<4:50:17,  3.52s/it] 17%|â–ˆâ–‹        | 1049/6000 [1:01:40<4:47:35,  3.49s/it]                                                       {'loss': 0.1137, 'grad_norm': 3.2960753440856934, 'learning_rate': 4.1957627118644074e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1049/6000 [1:01:40<4:47:35,  3.49s/it] 18%|â–ˆâ–Š        | 1050/6000 [1:01:44<5:03:29,  3.68s/it]                                                       {'loss': 0.016, 'grad_norm': 1.0327309370040894, 'learning_rate': 4.1949152542372886e-05, 'epoch': 0.17}
 18%|â–ˆâ–Š        | 1050/6000 [1:01:44<5:03:29,  3.68s/it][2025-10-21 02:26:07,073] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1051/6000 [1:01:50<5:49:46,  4.24s/it]                                                       {'loss': 0.1444, 'grad_norm': 4.407992839813232, 'learning_rate': 4.19406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1051/6000 [1:01:50<5:49:46,  4.24s/it] 18%|â–ˆâ–Š        | 1052/6000 [1:01:53<5:29:57,  4.00s/it]                                                       {'loss': 0.009, 'grad_norm': 0.9572604894638062, 'learning_rate': 4.193220338983051e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1052/6000 [1:01:53<5:29:57,  4.00s/it] 18%|â–ˆâ–Š        | 1053/6000 [1:01:57<5:22:26,  3.91s/it]                                                       {'loss': 0.0355, 'grad_norm': 1.3831418752670288, 'learning_rate': 4.1923728813559326e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1053/6000 [1:01:57<5:22:26,  3.91s/it] 18%|â–ˆâ–Š        | 1054/6000 [1:02:01<5:11:46,  3.78s/it]                                                       {'loss': 0.03, 'grad_norm': 2.0175724029541016, 'learning_rate': 4.191525423728814e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1054/6000 [1:02:01<5:11:46,  3.78s/it] 18%|â–ˆâ–Š        | 1055/6000 [1:02:04<5:01:07,  3.65s/it]                                                       {'loss': 0.0851, 'grad_norm': 3.1519558429718018, 'learning_rate': 4.1906779661016956e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1055/6000 [1:02:04<5:01:07,  3.65s/it] 18%|â–ˆâ–Š        | 1056/6000 [1:02:07<4:55:14,  3.58s/it]                                                       {'loss': 0.0161, 'grad_norm': 0.8463954925537109, 'learning_rate': 4.189830508474577e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1056/6000 [1:02:07<4:55:14,  3.58s/it] 18%|â–ˆâ–Š        | 1057/6000 [1:02:11<4:50:04,  3.52s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.1269315630197525, 'learning_rate': 4.188983050847458e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1057/6000 [1:02:11<4:50:04,  3.52s/it] 18%|â–ˆâ–Š        | 1058/6000 [1:02:14<4:46:15,  3.48s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.7741228342056274, 'learning_rate': 4.188135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1058/6000 [1:02:14<4:46:15,  3.48s/it] 18%|â–ˆâ–Š        | 1059/6000 [1:02:17<4:46:13,  3.48s/it]                                                       {'loss': 0.1139, 'grad_norm': 4.667232036590576, 'learning_rate': 4.18728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1059/6000 [1:02:17<4:46:13,  3.48s/it] 18%|â–ˆâ–Š        | 1060/6000 [1:02:21<4:42:45,  3.43s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.148855209350586, 'learning_rate': 4.186440677966102e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1060/6000 [1:02:21<4:42:45,  3.43s/it] 18%|â–ˆâ–Š        | 1061/6000 [1:02:25<4:50:40,  3.53s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.0800236463546753, 'learning_rate': 4.185593220338983e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1061/6000 [1:02:25<4:50:40,  3.53s/it] 18%|â–ˆâ–Š        | 1062/6000 [1:02:28<4:49:44,  3.52s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.44728603959083557, 'learning_rate': 4.184745762711865e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1062/6000 [1:02:28<4:49:44,  3.52s/it] 18%|â–ˆâ–Š        | 1063/6000 [1:02:31<4:46:42,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.026814032346010208, 'learning_rate': 4.183898305084746e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1063/6000 [1:02:31<4:46:42,  3.48s/it] 18%|â–ˆâ–Š        | 1064/6000 [1:02:35<4:48:03,  3.50s/it]                                                       {'loss': 0.0256, 'grad_norm': 2.7293126583099365, 'learning_rate': 4.183050847457628e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1064/6000 [1:02:35<4:48:03,  3.50s/it] 18%|â–ˆâ–Š        | 1065/6000 [1:02:38<4:45:00,  3.47s/it]                                                       {'loss': 0.0288, 'grad_norm': 1.4129289388656616, 'learning_rate': 4.182203389830508e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1065/6000 [1:02:38<4:45:00,  3.47s/it] 18%|â–ˆâ–Š        | 1066/6000 [1:02:42<4:43:44,  3.45s/it]                                                       {'loss': 0.1045, 'grad_norm': 4.534428119659424, 'learning_rate': 4.18135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1066/6000 [1:02:42<4:43:44,  3.45s/it] 18%|â–ˆâ–Š        | 1067/6000 [1:02:45<4:43:58,  3.45s/it]                                                       {'loss': 0.0997, 'grad_norm': 3.5611703395843506, 'learning_rate': 4.180508474576271e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1067/6000 [1:02:45<4:43:58,  3.45s/it] 18%|â–ˆâ–Š        | 1068/6000 [1:02:49<4:40:38,  3.41s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.0750787258148193, 'learning_rate': 4.179661016949153e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1068/6000 [1:02:49<4:40:38,  3.41s/it] 18%|â–ˆâ–Š        | 1069/6000 [1:02:52<4:38:57,  3.39s/it]                                                       {'loss': 0.0187, 'grad_norm': 1.1604655981063843, 'learning_rate': 4.178813559322034e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1069/6000 [1:02:52<4:38:57,  3.39s/it] 18%|â–ˆâ–Š        | 1070/6000 [1:02:55<4:41:09,  3.42s/it]                                                       {'loss': 0.0982, 'grad_norm': 4.7110466957092285, 'learning_rate': 4.177966101694916e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1070/6000 [1:02:55<4:41:09,  3.42s/it] 18%|â–ˆâ–Š        | 1071/6000 [1:02:59<4:40:53,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1053069531917572, 'learning_rate': 4.177118644067797e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1071/6000 [1:02:59<4:40:53,  3.42s/it] 18%|â–ˆâ–Š        | 1072/6000 [1:03:02<4:39:30,  3.40s/it]                                                       {'loss': 0.1113, 'grad_norm': 5.322991371154785, 'learning_rate': 4.176271186440678e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1072/6000 [1:03:02<4:39:30,  3.40s/it] 18%|â–ˆâ–Š        | 1073/6000 [1:03:06<4:41:19,  3.43s/it]                                                       {'loss': 0.0213, 'grad_norm': 2.486877679824829, 'learning_rate': 4.175423728813559e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1073/6000 [1:03:06<4:41:19,  3.43s/it] 18%|â–ˆâ–Š        | 1074/6000 [1:03:09<4:42:32,  3.44s/it]                                                       {'loss': 0.0086, 'grad_norm': 0.6189626455307007, 'learning_rate': 4.174576271186441e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1074/6000 [1:03:09<4:42:32,  3.44s/it] 18%|â–ˆâ–Š        | 1075/6000 [1:03:13<4:42:03,  3.44s/it]                                                       {'loss': 0.0762, 'grad_norm': 3.740246295928955, 'learning_rate': 4.173728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1075/6000 [1:03:13<4:42:03,  3.44s/it] 18%|â–ˆâ–Š        | 1076/6000 [1:03:16<4:41:14,  3.43s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.459004521369934, 'learning_rate': 4.172881355932204e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1076/6000 [1:03:16<4:41:14,  3.43s/it] 18%|â–ˆâ–Š        | 1077/6000 [1:03:19<4:39:48,  3.41s/it]                                                       {'loss': 0.011, 'grad_norm': 1.0320905447006226, 'learning_rate': 4.172033898305085e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1077/6000 [1:03:19<4:39:48,  3.41s/it] 18%|â–ˆâ–Š        | 1078/6000 [1:03:23<4:39:23,  3.41s/it]                                                       {'loss': 0.0504, 'grad_norm': 3.187025785446167, 'learning_rate': 4.171186440677966e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1078/6000 [1:03:23<4:39:23,  3.41s/it] 18%|â–ˆâ–Š        | 1079/6000 [1:03:27<4:54:10,  3.59s/it]                                                       {'loss': 0.1828, 'grad_norm': 4.849191665649414, 'learning_rate': 4.1703389830508474e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1079/6000 [1:03:27<4:54:10,  3.59s/it] 18%|â–ˆâ–Š        | 1080/6000 [1:03:30<4:50:40,  3.54s/it]                                                       {'loss': 0.0558, 'grad_norm': 7.18616247177124, 'learning_rate': 4.1694915254237285e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1080/6000 [1:03:30<4:50:40,  3.54s/it] 18%|â–ˆâ–Š        | 1081/6000 [1:03:34<4:44:50,  3.47s/it]                                                       {'loss': 0.0464, 'grad_norm': 3.3673815727233887, 'learning_rate': 4.16864406779661e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1081/6000 [1:03:34<4:44:50,  3.47s/it] 18%|â–ˆâ–Š        | 1082/6000 [1:03:37<4:44:45,  3.47s/it]                                                       {'loss': 0.1076, 'grad_norm': 5.2745280265808105, 'learning_rate': 4.1677966101694915e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1082/6000 [1:03:37<4:44:45,  3.47s/it] 18%|â–ˆâ–Š        | 1083/6000 [1:03:40<4:42:04,  3.44s/it]                                                       {'loss': 0.0184, 'grad_norm': 1.187008261680603, 'learning_rate': 4.166949152542373e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1083/6000 [1:03:40<4:42:04,  3.44s/it] 18%|â–ˆâ–Š        | 1084/6000 [1:03:44<4:44:21,  3.47s/it]                                                       {'loss': 0.1211, 'grad_norm': 5.112621784210205, 'learning_rate': 4.1661016949152544e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1084/6000 [1:03:44<4:44:21,  3.47s/it] 18%|â–ˆâ–Š        | 1085/6000 [1:03:47<4:41:36,  3.44s/it]                                                       {'loss': 0.0283, 'grad_norm': 1.0465893745422363, 'learning_rate': 4.165254237288136e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1085/6000 [1:03:47<4:41:36,  3.44s/it] 18%|â–ˆâ–Š        | 1086/6000 [1:03:51<4:47:40,  3.51s/it]                                                       {'loss': 0.0273, 'grad_norm': 2.291747570037842, 'learning_rate': 4.164406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1086/6000 [1:03:51<4:47:40,  3.51s/it] 18%|â–ˆâ–Š        | 1087/6000 [1:03:54<4:46:24,  3.50s/it]                                                       {'loss': 0.0705, 'grad_norm': 4.196840286254883, 'learning_rate': 4.1635593220338985e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1087/6000 [1:03:55<4:46:24,  3.50s/it] 18%|â–ˆâ–Š        | 1088/6000 [1:03:58<4:47:48,  3.52s/it]                                                       {'loss': 0.1423, 'grad_norm': 5.528125762939453, 'learning_rate': 4.1627118644067796e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1088/6000 [1:03:58<4:47:48,  3.52s/it] 18%|â–ˆâ–Š        | 1089/6000 [1:04:02<5:08:14,  3.77s/it]                                                       {'loss': 0.1873, 'grad_norm': 4.920101165771484, 'learning_rate': 4.1618644067796614e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1089/6000 [1:04:02<5:08:14,  3.77s/it] 18%|â–ˆâ–Š        | 1090/6000 [1:04:06<5:00:19,  3.67s/it]                                                       {'loss': 0.0844, 'grad_norm': 4.180220603942871, 'learning_rate': 4.1610169491525425e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1090/6000 [1:04:06<5:00:19,  3.67s/it] 18%|â–ˆâ–Š        | 1091/6000 [1:04:09<4:53:16,  3.58s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.4380513429641724, 'learning_rate': 4.160169491525424e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1091/6000 [1:04:09<4:53:16,  3.58s/it] 18%|â–ˆâ–Š        | 1092/6000 [1:04:13<4:47:43,  3.52s/it]                                                       {'loss': 0.2048, 'grad_norm': 6.05433988571167, 'learning_rate': 4.1593220338983055e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1092/6000 [1:04:13<4:47:43,  3.52s/it] 18%|â–ˆâ–Š        | 1093/6000 [1:04:16<4:45:00,  3.48s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.02482263185083866, 'learning_rate': 4.1584745762711866e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1093/6000 [1:04:16<4:45:00,  3.48s/it] 18%|â–ˆâ–Š        | 1094/6000 [1:04:19<4:43:09,  3.46s/it]                                                       {'loss': 0.1019, 'grad_norm': 2.1852235794067383, 'learning_rate': 4.157627118644068e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1094/6000 [1:04:19<4:43:09,  3.46s/it] 18%|â–ˆâ–Š        | 1095/6000 [1:04:23<4:41:49,  3.45s/it]                                                       {'loss': 0.0162, 'grad_norm': 0.7575247883796692, 'learning_rate': 4.1567796610169495e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1095/6000 [1:04:23<4:41:49,  3.45s/it] 18%|â–ˆâ–Š        | 1096/6000 [1:04:26<4:44:23,  3.48s/it]                                                       {'loss': 0.0514, 'grad_norm': 2.7263453006744385, 'learning_rate': 4.1559322033898307e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1096/6000 [1:04:26<4:44:23,  3.48s/it] 18%|â–ˆâ–Š        | 1097/6000 [1:04:30<4:42:36,  3.46s/it]                                                       {'loss': 0.0145, 'grad_norm': 0.6966137886047363, 'learning_rate': 4.1550847457627125e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1097/6000 [1:04:30<4:42:36,  3.46s/it] 18%|â–ˆâ–Š        | 1098/6000 [1:04:34<4:56:00,  3.62s/it]                                                       {'loss': 0.1073, 'grad_norm': 4.325371265411377, 'learning_rate': 4.1542372881355936e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1098/6000 [1:04:34<4:56:00,  3.62s/it] 18%|â–ˆâ–Š        | 1099/6000 [1:04:38<5:06:56,  3.76s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.5208472013473511, 'learning_rate': 4.153389830508475e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1099/6000 [1:04:38<5:06:56,  3.76s/it] 18%|â–ˆâ–Š        | 1100/6000 [1:04:41<4:56:56,  3.64s/it]                                                       {'loss': 0.1529, 'grad_norm': 5.260182857513428, 'learning_rate': 4.152542372881356e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1100/6000 [1:04:41<4:56:56,  3.64s/it][2025-10-21 02:29:03,901] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1101/6000 [1:04:47<5:41:01,  4.18s/it]                                                       {'loss': 0.0554, 'grad_norm': 2.974475622177124, 'learning_rate': 4.151694915254237e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1101/6000 [1:04:47<5:41:01,  4.18s/it] 18%|â–ˆâ–Š        | 1102/6000 [1:04:50<5:20:42,  3.93s/it]                                                       {'loss': 0.0305, 'grad_norm': 2.4657552242279053, 'learning_rate': 4.150847457627119e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1102/6000 [1:04:50<5:20:42,  3.93s/it] 18%|â–ˆâ–Š        | 1103/6000 [1:04:53<5:08:31,  3.78s/it]                                                       {'loss': 0.1106, 'grad_norm': 3.824979066848755, 'learning_rate': 4.15e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1103/6000 [1:04:53<5:08:31,  3.78s/it] 18%|â–ˆâ–Š        | 1104/6000 [1:04:57<4:59:58,  3.68s/it]                                                       {'loss': 0.0327, 'grad_norm': 3.4459285736083984, 'learning_rate': 4.149152542372882e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1104/6000 [1:04:57<4:59:58,  3.68s/it] 18%|â–ˆâ–Š        | 1105/6000 [1:05:00<4:51:51,  3.58s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.3660726845264435, 'learning_rate': 4.148305084745763e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1105/6000 [1:05:00<4:51:51,  3.58s/it] 18%|â–ˆâ–Š        | 1106/6000 [1:05:04<4:47:54,  3.53s/it]                                                       {'loss': 0.052, 'grad_norm': 3.4500625133514404, 'learning_rate': 4.1474576271186446e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1106/6000 [1:05:04<4:47:54,  3.53s/it] 18%|â–ˆâ–Š        | 1107/6000 [1:05:07<4:44:58,  3.49s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.4675934314727783, 'learning_rate': 4.146610169491526e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1107/6000 [1:05:07<4:44:58,  3.49s/it] 18%|â–ˆâ–Š        | 1108/6000 [1:05:10<4:44:57,  3.50s/it]                                                       {'loss': 0.0381, 'grad_norm': 2.743187665939331, 'learning_rate': 4.145762711864407e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1108/6000 [1:05:10<4:44:57,  3.50s/it] 18%|â–ˆâ–Š        | 1109/6000 [1:05:14<4:42:34,  3.47s/it]                                                       {'loss': 0.051, 'grad_norm': 2.663642168045044, 'learning_rate': 4.144915254237288e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1109/6000 [1:05:14<4:42:34,  3.47s/it] 18%|â–ˆâ–Š        | 1110/6000 [1:05:17<4:40:19,  3.44s/it]                                                       {'loss': 0.1565, 'grad_norm': 4.4022722244262695, 'learning_rate': 4.14406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1110/6000 [1:05:17<4:40:19,  3.44s/it] 19%|â–ˆâ–Š        | 1111/6000 [1:05:21<4:39:46,  3.43s/it]                                                       {'loss': 0.1394, 'grad_norm': 5.17458963394165, 'learning_rate': 4.143220338983051e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1111/6000 [1:05:21<4:39:46,  3.43s/it] 19%|â–ˆâ–Š        | 1112/6000 [1:05:24<4:37:57,  3.41s/it]                                                       {'loss': 0.0104, 'grad_norm': 0.9257838726043701, 'learning_rate': 4.142372881355933e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1112/6000 [1:05:24<4:37:57,  3.41s/it] 19%|â–ˆâ–Š        | 1113/6000 [1:05:27<4:38:15,  3.42s/it]                                                       {'loss': 0.0209, 'grad_norm': 1.0643025636672974, 'learning_rate': 4.141525423728814e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1113/6000 [1:05:27<4:38:15,  3.42s/it] 19%|â–ˆâ–Š        | 1114/6000 [1:05:31<4:35:45,  3.39s/it]                                                       {'loss': 0.1481, 'grad_norm': 5.1888041496276855, 'learning_rate': 4.140677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1114/6000 [1:05:31<4:35:45,  3.39s/it] 19%|â–ˆâ–Š        | 1115/6000 [1:05:34<4:36:16,  3.39s/it]                                                       {'loss': 0.1808, 'grad_norm': 4.034430980682373, 'learning_rate': 4.139830508474576e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1115/6000 [1:05:34<4:36:16,  3.39s/it] 19%|â–ˆâ–Š        | 1116/6000 [1:05:38<4:35:46,  3.39s/it]                                                       {'loss': 0.1386, 'grad_norm': 4.483654499053955, 'learning_rate': 4.138983050847458e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1116/6000 [1:05:38<4:35:46,  3.39s/it] 19%|â–ˆâ–Š        | 1117/6000 [1:05:41<4:38:14,  3.42s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.8137181997299194, 'learning_rate': 4.138135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1117/6000 [1:05:41<4:38:14,  3.42s/it] 19%|â–ˆâ–Š        | 1118/6000 [1:05:44<4:38:13,  3.42s/it]                                                       {'loss': 0.5189, 'grad_norm': 7.986043453216553, 'learning_rate': 4.13728813559322e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1118/6000 [1:05:44<4:38:13,  3.42s/it] 19%|â–ˆâ–Š        | 1119/6000 [1:05:48<4:39:15,  3.43s/it]                                                       {'loss': 0.0505, 'grad_norm': 3.6736228466033936, 'learning_rate': 4.136440677966102e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1119/6000 [1:05:48<4:39:15,  3.43s/it] 19%|â–ˆâ–Š        | 1120/6000 [1:05:51<4:39:33,  3.44s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.23601622879505157, 'learning_rate': 4.135593220338983e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1120/6000 [1:05:51<4:39:33,  3.44s/it] 19%|â–ˆâ–Š        | 1121/6000 [1:05:55<4:37:41,  3.41s/it]                                                       {'loss': 0.0602, 'grad_norm': 2.5176873207092285, 'learning_rate': 4.134745762711865e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1121/6000 [1:05:55<4:37:41,  3.41s/it] 19%|â–ˆâ–Š        | 1122/6000 [1:05:58<4:38:02,  3.42s/it]                                                       {'loss': 0.001, 'grad_norm': 0.09359181672334671, 'learning_rate': 4.1338983050847454e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1122/6000 [1:05:58<4:38:02,  3.42s/it] 19%|â–ˆâ–Š        | 1123/6000 [1:06:02<4:38:11,  3.42s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.9413424134254456, 'learning_rate': 4.133050847457627e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1123/6000 [1:06:02<4:38:11,  3.42s/it] 19%|â–ˆâ–Š        | 1124/6000 [1:06:05<4:49:09,  3.56s/it]                                                       {'loss': 0.0887, 'grad_norm': 4.7186102867126465, 'learning_rate': 4.1322033898305084e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1124/6000 [1:06:05<4:49:09,  3.56s/it] 19%|â–ˆâ–‰        | 1125/6000 [1:06:09<4:49:14,  3.56s/it]                                                       {'loss': 0.1163, 'grad_norm': 4.398663520812988, 'learning_rate': 4.13135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1125/6000 [1:06:09<4:49:14,  3.56s/it] 19%|â–ˆâ–‰        | 1126/6000 [1:06:12<4:44:37,  3.50s/it]                                                       {'loss': 0.3529, 'grad_norm': 6.089210510253906, 'learning_rate': 4.130508474576271e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1126/6000 [1:06:12<4:44:37,  3.50s/it] 19%|â–ˆâ–‰        | 1127/6000 [1:06:16<4:44:17,  3.50s/it]                                                       {'loss': 0.0497, 'grad_norm': 3.0688815116882324, 'learning_rate': 4.129661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1127/6000 [1:06:16<4:44:17,  3.50s/it] 19%|â–ˆâ–‰        | 1128/6000 [1:06:19<4:42:31,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.021140914410352707, 'learning_rate': 4.128813559322034e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1128/6000 [1:06:19<4:42:31,  3.48s/it] 19%|â–ˆâ–‰        | 1129/6000 [1:06:23<4:40:35,  3.46s/it]                                                       {'loss': 0.0465, 'grad_norm': 2.130185127258301, 'learning_rate': 4.1279661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1129/6000 [1:06:23<4:40:35,  3.46s/it] 19%|â–ˆâ–‰        | 1130/6000 [1:06:26<4:40:18,  3.45s/it]                                                       {'loss': 0.0889, 'grad_norm': 1.7171999216079712, 'learning_rate': 4.1271186440677965e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1130/6000 [1:06:26<4:40:18,  3.45s/it] 19%|â–ˆâ–‰        | 1131/6000 [1:06:30<4:37:36,  3.42s/it]                                                       {'loss': 0.1151, 'grad_norm': 3.8977715969085693, 'learning_rate': 4.126271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1131/6000 [1:06:30<4:37:36,  3.42s/it] 19%|â–ˆâ–‰        | 1132/6000 [1:06:33<4:35:29,  3.40s/it]                                                       {'loss': 0.0455, 'grad_norm': 2.277451515197754, 'learning_rate': 4.1254237288135594e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1132/6000 [1:06:33<4:35:29,  3.40s/it] 19%|â–ˆâ–‰        | 1133/6000 [1:06:37<4:46:01,  3.53s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.32933762669563293, 'learning_rate': 4.124576271186441e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1133/6000 [1:06:37<4:46:01,  3.53s/it] 19%|â–ˆâ–‰        | 1134/6000 [1:06:41<4:55:18,  3.64s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.097731351852417, 'learning_rate': 4.1237288135593223e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1134/6000 [1:06:41<4:55:18,  3.64s/it] 19%|â–ˆâ–‰        | 1135/6000 [1:06:44<4:49:05,  3.57s/it]                                                       {'loss': 0.0901, 'grad_norm': 3.978300094604492, 'learning_rate': 4.1228813559322035e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1135/6000 [1:06:44<4:49:05,  3.57s/it] 19%|â–ˆâ–‰        | 1136/6000 [1:06:47<4:46:23,  3.53s/it]                                                       {'loss': 0.0269, 'grad_norm': 2.2747995853424072, 'learning_rate': 4.1220338983050846e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1136/6000 [1:06:47<4:46:23,  3.53s/it] 19%|â–ˆâ–‰        | 1137/6000 [1:06:51<4:42:46,  3.49s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.3439977765083313, 'learning_rate': 4.1211864406779664e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1137/6000 [1:06:51<4:42:46,  3.49s/it] 19%|â–ˆâ–‰        | 1138/6000 [1:06:54<4:39:26,  3.45s/it]                                                       {'loss': 0.0511, 'grad_norm': 4.024317264556885, 'learning_rate': 4.1203389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1138/6000 [1:06:54<4:39:26,  3.45s/it] 19%|â–ˆâ–‰        | 1139/6000 [1:06:58<4:39:25,  3.45s/it]                                                       {'loss': 0.0138, 'grad_norm': 0.882243275642395, 'learning_rate': 4.119491525423729e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1139/6000 [1:06:58<4:39:25,  3.45s/it] 19%|â–ˆâ–‰        | 1140/6000 [1:07:01<4:42:46,  3.49s/it]                                                       {'loss': 0.0584, 'grad_norm': 2.7410662174224854, 'learning_rate': 4.1186440677966105e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1140/6000 [1:07:01<4:42:46,  3.49s/it] 19%|â–ˆâ–‰        | 1141/6000 [1:07:05<4:40:50,  3.47s/it]                                                       {'loss': 0.1451, 'grad_norm': 4.644940376281738, 'learning_rate': 4.1177966101694916e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1141/6000 [1:07:05<4:40:50,  3.47s/it] 19%|â–ˆâ–‰        | 1142/6000 [1:07:08<4:42:03,  3.48s/it]                                                       {'loss': 0.112, 'grad_norm': 5.112401962280273, 'learning_rate': 4.1169491525423734e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1142/6000 [1:07:08<4:42:03,  3.48s/it] 19%|â–ˆâ–‰        | 1143/6000 [1:07:12<4:38:51,  3.44s/it]                                                       {'loss': 0.2888, 'grad_norm': 4.897841930389404, 'learning_rate': 4.1161016949152545e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1143/6000 [1:07:12<4:38:51,  3.44s/it] 19%|â–ˆâ–‰        | 1144/6000 [1:07:15<4:39:09,  3.45s/it]                                                       {'loss': 0.0444, 'grad_norm': 1.4370805025100708, 'learning_rate': 4.115254237288136e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1144/6000 [1:07:15<4:39:09,  3.45s/it] 19%|â–ˆâ–‰        | 1145/6000 [1:07:18<4:36:42,  3.42s/it]                                                       {'loss': 0.0661, 'grad_norm': 2.229269504547119, 'learning_rate': 4.114406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1145/6000 [1:07:18<4:36:42,  3.42s/it] 19%|â–ˆâ–‰        | 1146/6000 [1:07:22<4:38:02,  3.44s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.10370197892189026, 'learning_rate': 4.1135593220338986e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1146/6000 [1:07:22<4:38:02,  3.44s/it] 19%|â–ˆâ–‰        | 1147/6000 [1:07:25<4:37:02,  3.43s/it]                                                       {'loss': 0.0608, 'grad_norm': 2.4381513595581055, 'learning_rate': 4.11271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1147/6000 [1:07:25<4:37:02,  3.43s/it] 19%|â–ˆâ–‰        | 1148/6000 [1:07:29<4:36:03,  3.41s/it]                                                       {'loss': 0.0652, 'grad_norm': 4.278800010681152, 'learning_rate': 4.1118644067796615e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1148/6000 [1:07:29<4:36:03,  3.41s/it] 19%|â–ˆâ–‰        | 1149/6000 [1:07:32<4:44:57,  3.52s/it]                                                       {'loss': 0.1164, 'grad_norm': 3.4959559440612793, 'learning_rate': 4.111016949152543e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1149/6000 [1:07:32<4:44:57,  3.52s/it] 19%|â–ˆâ–‰        | 1150/6000 [1:07:36<4:44:34,  3.52s/it]                                                       {'loss': 0.0145, 'grad_norm': 0.8413864970207214, 'learning_rate': 4.110169491525424e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1150/6000 [1:07:36<4:44:34,  3.52s/it][2025-10-21 02:31:58,648] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 19%|â–ˆâ–‰        | 1151/6000 [1:07:41<5:33:56,  4.13s/it]                                                       {'loss': 0.0957, 'grad_norm': 4.373108386993408, 'learning_rate': 4.109322033898305e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1151/6000 [1:07:41<5:33:56,  4.13s/it] 19%|â–ˆâ–‰        | 1152/6000 [1:07:45<5:13:43,  3.88s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.1416005790233612, 'learning_rate': 4.108474576271187e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1152/6000 [1:07:45<5:13:43,  3.88s/it] 19%|â–ˆâ–‰        | 1153/6000 [1:07:48<5:04:13,  3.77s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.302041620016098, 'learning_rate': 4.107627118644068e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1153/6000 [1:07:48<5:04:13,  3.77s/it] 19%|â–ˆâ–‰        | 1154/6000 [1:07:52<4:55:17,  3.66s/it]                                                       {'loss': 0.0455, 'grad_norm': 2.6679158210754395, 'learning_rate': 4.10677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1154/6000 [1:07:52<4:55:17,  3.66s/it] 19%|â–ˆâ–‰        | 1155/6000 [1:07:55<4:53:58,  3.64s/it]                                                       {'loss': 0.0303, 'grad_norm': 2.4670798778533936, 'learning_rate': 4.105932203389831e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1155/6000 [1:07:55<4:53:58,  3.64s/it] 19%|â–ˆâ–‰        | 1156/6000 [1:07:59<4:46:32,  3.55s/it]                                                       {'loss': 0.1515, 'grad_norm': 5.160369396209717, 'learning_rate': 4.1050847457627126e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1156/6000 [1:07:59<4:46:32,  3.55s/it] 19%|â–ˆâ–‰        | 1157/6000 [1:08:02<4:43:28,  3.51s/it]                                                       {'loss': 0.1193, 'grad_norm': 4.184525012969971, 'learning_rate': 4.104237288135593e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1157/6000 [1:08:02<4:43:28,  3.51s/it] 19%|â–ˆâ–‰        | 1158/6000 [1:08:05<4:41:00,  3.48s/it]                                                       {'loss': 0.007, 'grad_norm': 0.6877774596214294, 'learning_rate': 4.103389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1158/6000 [1:08:05<4:41:00,  3.48s/it] 19%|â–ˆâ–‰        | 1159/6000 [1:08:09<4:39:02,  3.46s/it]                                                       {'loss': 0.0544, 'grad_norm': 3.212341785430908, 'learning_rate': 4.102542372881356e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1159/6000 [1:08:09<4:39:02,  3.46s/it] 19%|â–ˆâ–‰        | 1160/6000 [1:08:12<4:37:11,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02212875708937645, 'learning_rate': 4.101694915254237e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1160/6000 [1:08:12<4:37:11,  3.44s/it] 19%|â–ˆâ–‰        | 1161/6000 [1:08:16<4:34:38,  3.41s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.09116265922784805, 'learning_rate': 4.100847457627119e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1161/6000 [1:08:16<4:34:38,  3.41s/it] 19%|â–ˆâ–‰        | 1162/6000 [1:08:19<4:32:44,  3.38s/it]                                                       {'loss': 0.0128, 'grad_norm': 0.8804938197135925, 'learning_rate': 4.1e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1162/6000 [1:08:19<4:32:44,  3.38s/it] 19%|â–ˆâ–‰        | 1163/6000 [1:08:22<4:32:15,  3.38s/it]                                                       {'loss': 0.0203, 'grad_norm': 1.2645214796066284, 'learning_rate': 4.099152542372882e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1163/6000 [1:08:22<4:32:15,  3.38s/it] 19%|â–ˆâ–‰        | 1164/6000 [1:08:26<4:31:05,  3.36s/it]                                                       {'loss': 0.0911, 'grad_norm': 4.040063858032227, 'learning_rate': 4.098305084745763e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1164/6000 [1:08:26<4:31:05,  3.36s/it] 19%|â–ˆâ–‰        | 1165/6000 [1:08:29<4:34:20,  3.40s/it]                                                       {'loss': 0.0959, 'grad_norm': 3.803649425506592, 'learning_rate': 4.097457627118644e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1165/6000 [1:08:29<4:34:20,  3.40s/it] 19%|â–ˆâ–‰        | 1166/6000 [1:08:32<4:33:56,  3.40s/it]                                                       {'loss': 0.0617, 'grad_norm': 1.6829098463058472, 'learning_rate': 4.096610169491525e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1166/6000 [1:08:32<4:33:56,  3.40s/it] 19%|â–ˆâ–‰        | 1167/6000 [1:08:36<4:47:18,  3.57s/it]                                                       {'loss': 0.1604, 'grad_norm': 4.965522766113281, 'learning_rate': 4.095762711864407e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1167/6000 [1:08:36<4:47:18,  3.57s/it] 19%|â–ˆâ–‰        | 1168/6000 [1:08:40<4:42:41,  3.51s/it]                                                       {'loss': 0.1328, 'grad_norm': 5.741835594177246, 'learning_rate': 4.094915254237288e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1168/6000 [1:08:40<4:42:41,  3.51s/it] 19%|â–ˆâ–‰        | 1169/6000 [1:08:43<4:38:15,  3.46s/it]                                                       {'loss': 0.1584, 'grad_norm': 7.025350093841553, 'learning_rate': 4.09406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1169/6000 [1:08:43<4:38:15,  3.46s/it] 20%|â–ˆâ–‰        | 1170/6000 [1:08:47<4:36:51,  3.44s/it]                                                       {'loss': 0.013, 'grad_norm': 1.0011245012283325, 'learning_rate': 4.093220338983051e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1170/6000 [1:08:47<4:36:51,  3.44s/it] 20%|â–ˆâ–‰        | 1171/6000 [1:08:50<4:39:20,  3.47s/it]                                                       {'loss': 0.0166, 'grad_norm': 0.9379247426986694, 'learning_rate': 4.092372881355932e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1171/6000 [1:08:50<4:39:20,  3.47s/it] 20%|â–ˆâ–‰        | 1172/6000 [1:08:54<4:41:19,  3.50s/it]                                                       {'loss': 0.0239, 'grad_norm': 2.0476911067962646, 'learning_rate': 4.0915254237288134e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1172/6000 [1:08:54<4:41:19,  3.50s/it] 20%|â–ˆâ–‰        | 1173/6000 [1:08:57<4:38:44,  3.46s/it]                                                       {'loss': 0.0404, 'grad_norm': 2.243034839630127, 'learning_rate': 4.090677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1173/6000 [1:08:57<4:38:44,  3.46s/it] 20%|â–ˆâ–‰        | 1174/6000 [1:09:00<4:37:50,  3.45s/it]                                                       {'loss': 0.126, 'grad_norm': 4.542275905609131, 'learning_rate': 4.089830508474576e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1174/6000 [1:09:00<4:37:50,  3.45s/it] 20%|â–ˆâ–‰        | 1175/6000 [1:09:04<4:38:21,  3.46s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.8147372007369995, 'learning_rate': 4.088983050847458e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1175/6000 [1:09:04<4:38:21,  3.46s/it] 20%|â–ˆâ–‰        | 1176/6000 [1:09:07<4:36:55,  3.44s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.39746153354644775, 'learning_rate': 4.088135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1176/6000 [1:09:07<4:36:55,  3.44s/it] 20%|â–ˆâ–‰        | 1177/6000 [1:09:11<4:36:07,  3.44s/it]                                                       {'loss': 0.1331, 'grad_norm': 3.305152416229248, 'learning_rate': 4.087288135593221e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1177/6000 [1:09:11<4:36:07,  3.44s/it] 20%|â–ˆâ–‰        | 1178/6000 [1:09:15<4:47:49,  3.58s/it]                                                       {'loss': 0.0742, 'grad_norm': 1.8141957521438599, 'learning_rate': 4.086440677966102e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1178/6000 [1:09:15<4:47:49,  3.58s/it] 20%|â–ˆâ–‰        | 1179/6000 [1:09:19<4:53:45,  3.66s/it]                                                       {'loss': 0.0454, 'grad_norm': 2.6791720390319824, 'learning_rate': 4.085593220338983e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1179/6000 [1:09:19<4:53:45,  3.66s/it] 20%|â–ˆâ–‰        | 1180/6000 [1:09:22<4:57:34,  3.70s/it]                                                       {'loss': 0.0624, 'grad_norm': 1.3917218446731567, 'learning_rate': 4.0847457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1180/6000 [1:09:22<4:57:34,  3.70s/it] 20%|â–ˆâ–‰        | 1181/6000 [1:09:26<4:51:15,  3.63s/it]                                                       {'loss': 0.0269, 'grad_norm': 1.82429039478302, 'learning_rate': 4.0838983050847456e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1181/6000 [1:09:26<4:51:15,  3.63s/it] 20%|â–ˆâ–‰        | 1182/6000 [1:09:30<5:07:14,  3.83s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.38030579686164856, 'learning_rate': 4.0830508474576274e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1182/6000 [1:09:30<5:07:14,  3.83s/it] 20%|â–ˆâ–‰        | 1183/6000 [1:09:33<4:55:57,  3.69s/it]                                                       {'loss': 0.0397, 'grad_norm': 3.112579345703125, 'learning_rate': 4.0822033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1183/6000 [1:09:33<4:55:57,  3.69s/it] 20%|â–ˆâ–‰        | 1184/6000 [1:09:37<4:48:34,  3.60s/it]                                                       {'loss': 0.1385, 'grad_norm': 3.8056609630584717, 'learning_rate': 4.08135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1184/6000 [1:09:37<4:48:34,  3.60s/it] 20%|â–ˆâ–‰        | 1185/6000 [1:09:40<4:41:45,  3.51s/it]                                                       {'loss': 0.1243, 'grad_norm': 5.067291736602783, 'learning_rate': 4.0805084745762714e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1185/6000 [1:09:40<4:41:45,  3.51s/it] 20%|â–ˆâ–‰        | 1186/6000 [1:09:43<4:38:03,  3.47s/it]                                                       {'loss': 0.1323, 'grad_norm': 2.4965579509735107, 'learning_rate': 4.0796610169491526e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1186/6000 [1:09:43<4:38:03,  3.47s/it] 20%|â–ˆâ–‰        | 1187/6000 [1:09:47<4:37:07,  3.45s/it]                                                       {'loss': 0.0183, 'grad_norm': 0.8867756724357605, 'learning_rate': 4.078813559322034e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1187/6000 [1:09:47<4:37:07,  3.45s/it] 20%|â–ˆâ–‰        | 1188/6000 [1:09:50<4:32:13,  3.39s/it]                                                       {'loss': 0.0219, 'grad_norm': 1.2165316343307495, 'learning_rate': 4.0779661016949155e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1188/6000 [1:09:50<4:32:13,  3.39s/it] 20%|â–ˆâ–‰        | 1189/6000 [1:09:54<4:31:37,  3.39s/it]                                                       {'loss': 0.0577, 'grad_norm': 3.2116336822509766, 'learning_rate': 4.0771186440677966e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1189/6000 [1:09:54<4:31:37,  3.39s/it] 20%|â–ˆâ–‰        | 1190/6000 [1:09:57<4:35:33,  3.44s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.24884653091430664, 'learning_rate': 4.0762711864406784e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1190/6000 [1:09:57<4:35:33,  3.44s/it] 20%|â–ˆâ–‰        | 1191/6000 [1:10:01<4:36:00,  3.44s/it]                                                       {'loss': 0.0225, 'grad_norm': 1.6269211769104004, 'learning_rate': 4.0754237288135596e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1191/6000 [1:10:01<4:36:00,  3.44s/it] 20%|â–ˆâ–‰        | 1192/6000 [1:10:04<4:36:22,  3.45s/it]                                                       {'loss': 0.0123, 'grad_norm': 0.7382136583328247, 'learning_rate': 4.0745762711864414e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1192/6000 [1:10:04<4:36:22,  3.45s/it] 20%|â–ˆâ–‰        | 1193/6000 [1:10:07<4:34:35,  3.43s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.3055350184440613, 'learning_rate': 4.073728813559322e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1193/6000 [1:10:07<4:34:35,  3.43s/it] 20%|â–ˆâ–‰        | 1194/6000 [1:10:11<4:35:36,  3.44s/it]                                                       {'loss': 0.0496, 'grad_norm': 3.4980413913726807, 'learning_rate': 4.0728813559322036e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1194/6000 [1:10:11<4:35:36,  3.44s/it] 20%|â–ˆâ–‰        | 1195/6000 [1:10:14<4:36:26,  3.45s/it]                                                       {'loss': 0.0198, 'grad_norm': 2.1735494136810303, 'learning_rate': 4.072033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1195/6000 [1:10:14<4:36:26,  3.45s/it] 20%|â–ˆâ–‰        | 1196/6000 [1:10:18<4:35:37,  3.44s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.049520522356033325, 'learning_rate': 4.0711864406779666e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1196/6000 [1:10:18<4:35:37,  3.44s/it] 20%|â–ˆâ–‰        | 1197/6000 [1:10:21<4:37:23,  3.47s/it]                                                       {'loss': 0.0157, 'grad_norm': 0.8797584772109985, 'learning_rate': 4.070338983050848e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1197/6000 [1:10:21<4:37:23,  3.47s/it] 20%|â–ˆâ–‰        | 1198/6000 [1:10:25<4:37:06,  3.46s/it]                                                       {'loss': 0.0605, 'grad_norm': 4.067535400390625, 'learning_rate': 4.0694915254237295e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1198/6000 [1:10:25<4:37:06,  3.46s/it] 20%|â–ˆâ–‰        | 1199/6000 [1:10:28<4:34:18,  3.43s/it]                                                       {'loss': 0.0398, 'grad_norm': 2.6656334400177, 'learning_rate': 4.0686440677966106e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1199/6000 [1:10:28<4:34:18,  3.43s/it] 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:31<4:32:43,  3.41s/it]                                                       {'loss': 0.1152, 'grad_norm': 5.118667125701904, 'learning_rate': 4.067796610169492e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:31<4:32:43,  3.41s/it][2025-10-21 02:34:54,190] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:37<5:25:41,  4.07s/it]                                                       {'loss': 0.2352, 'grad_norm': 5.1291937828063965, 'learning_rate': 4.066949152542373e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:37<5:25:41,  4.07s/it] 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:40<5:08:31,  3.86s/it]                                                       {'loss': 0.0479, 'grad_norm': 4.520813465118408, 'learning_rate': 4.066101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:40<5:08:31,  3.86s/it] 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:44<4:57:49,  3.73s/it]                                                       {'loss': 0.0842, 'grad_norm': 4.038743019104004, 'learning_rate': 4.065254237288136e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:44<4:57:49,  3.73s/it] 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:48<5:00:29,  3.76s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.24472206830978394, 'learning_rate': 4.064406779661017e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:48<5:00:29,  3.76s/it] 20%|â–ˆâ–ˆ        | 1205/6000 [1:10:51<4:51:16,  3.64s/it]                                                       {'loss': 0.1285, 'grad_norm': 3.6640846729278564, 'learning_rate': 4.063559322033899e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1205/6000 [1:10:51<4:51:16,  3.64s/it] 20%|â–ˆâ–ˆ        | 1206/6000 [1:10:54<4:44:24,  3.56s/it]                                                       {'loss': 0.025, 'grad_norm': 2.0428249835968018, 'learning_rate': 4.06271186440678e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1206/6000 [1:10:54<4:44:24,  3.56s/it] 20%|â–ˆâ–ˆ        | 1207/6000 [1:10:58<4:40:05,  3.51s/it]                                                       {'loss': 0.0688, 'grad_norm': 2.701084852218628, 'learning_rate': 4.061864406779661e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1207/6000 [1:10:58<4:40:05,  3.51s/it] 20%|â–ˆâ–ˆ        | 1208/6000 [1:11:01<4:38:08,  3.48s/it]                                                       {'loss': 0.0338, 'grad_norm': 1.0642286539077759, 'learning_rate': 4.061016949152542e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1208/6000 [1:11:01<4:38:08,  3.48s/it] 20%|â–ˆâ–ˆ        | 1209/6000 [1:11:05<4:35:29,  3.45s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.4165436923503876, 'learning_rate': 4.060169491525424e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1209/6000 [1:11:05<4:35:29,  3.45s/it] 20%|â–ˆâ–ˆ        | 1210/6000 [1:11:08<4:37:12,  3.47s/it]                                                       {'loss': 0.3325, 'grad_norm': 5.8819661140441895, 'learning_rate': 4.059322033898305e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1210/6000 [1:11:08<4:37:12,  3.47s/it] 20%|â–ˆâ–ˆ        | 1211/6000 [1:11:12<4:35:44,  3.45s/it]                                                       {'loss': 0.0539, 'grad_norm': 3.4763102531433105, 'learning_rate': 4.058474576271187e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1211/6000 [1:11:12<4:35:44,  3.45s/it] 20%|â–ˆâ–ˆ        | 1212/6000 [1:11:15<4:33:17,  3.42s/it]                                                       {'loss': 0.1248, 'grad_norm': 5.042726516723633, 'learning_rate': 4.057627118644068e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1212/6000 [1:11:15<4:33:17,  3.42s/it] 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:18<4:29:59,  3.38s/it]                                                       {'loss': 0.0811, 'grad_norm': 3.5546352863311768, 'learning_rate': 4.05677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:18<4:29:59,  3.38s/it] 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:22<4:32:47,  3.42s/it]                                                       {'loss': 0.0118, 'grad_norm': 0.7389753460884094, 'learning_rate': 4.055932203389831e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:22<4:32:47,  3.42s/it] 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:25<4:32:56,  3.42s/it]                                                       {'loss': 0.0373, 'grad_norm': 2.6987509727478027, 'learning_rate': 4.055084745762712e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:25<4:32:56,  3.42s/it] 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:28<4:31:32,  3.41s/it]                                                       {'loss': 0.032, 'grad_norm': 1.9388765096664429, 'learning_rate': 4.054237288135593e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:28<4:31:32,  3.41s/it] 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:32<4:41:36,  3.53s/it]                                                       {'loss': 0.1811, 'grad_norm': 5.378576278686523, 'learning_rate': 4.053389830508475e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:32<4:41:36,  3.53s/it] 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:36<4:37:57,  3.49s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.1700083464384079, 'learning_rate': 4.052542372881356e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:36<4:37:57,  3.49s/it] 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:39<4:42:29,  3.55s/it]                                                       {'loss': 0.0292, 'grad_norm': 1.6756839752197266, 'learning_rate': 4.051694915254238e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:39<4:42:29,  3.55s/it] 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:43<4:39:32,  3.51s/it]                                                       {'loss': 0.0135, 'grad_norm': 1.1411263942718506, 'learning_rate': 4.050847457627119e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:43<4:39:32,  3.51s/it] 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:46<4:39:20,  3.51s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.08339743316173553, 'learning_rate': 4.05e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:46<4:39:20,  3.51s/it] 20%|â–ˆâ–ˆ        | 1222/6000 [1:11:50<4:38:01,  3.49s/it]                                                       {'loss': 0.1294, 'grad_norm': 12.313485145568848, 'learning_rate': 4.049152542372881e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1222/6000 [1:11:50<4:38:01,  3.49s/it] 20%|â–ˆâ–ˆ        | 1223/6000 [1:11:53<4:33:02,  3.43s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.0304927825927734, 'learning_rate': 4.0483050847457624e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1223/6000 [1:11:53<4:33:02,  3.43s/it] 20%|â–ˆâ–ˆ        | 1224/6000 [1:11:56<4:32:14,  3.42s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.19929172098636627, 'learning_rate': 4.047457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1224/6000 [1:11:56<4:32:14,  3.42s/it] 20%|â–ˆâ–ˆ        | 1225/6000 [1:12:00<4:37:10,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.0693696141242981, 'learning_rate': 4.0466101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1225/6000 [1:12:00<4:37:10,  3.48s/it] 20%|â–ˆâ–ˆ        | 1226/6000 [1:12:04<4:42:55,  3.56s/it]                                                       {'loss': 0.2982, 'grad_norm': 5.888424873352051, 'learning_rate': 4.045762711864407e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1226/6000 [1:12:04<4:42:55,  3.56s/it] 20%|â–ˆâ–ˆ        | 1227/6000 [1:12:08<4:49:55,  3.64s/it]                                                       {'loss': 0.011, 'grad_norm': 0.7932658791542053, 'learning_rate': 4.044915254237288e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1227/6000 [1:12:08<4:49:55,  3.64s/it] 20%|â–ˆâ–ˆ        | 1228/6000 [1:12:11<4:43:25,  3.56s/it]                                                       {'loss': 0.058, 'grad_norm': 1.1451497077941895, 'learning_rate': 4.0440677966101694e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1228/6000 [1:12:11<4:43:25,  3.56s/it] 20%|â–ˆâ–ˆ        | 1229/6000 [1:12:14<4:38:09,  3.50s/it]                                                       {'loss': 0.0107, 'grad_norm': 0.8584150671958923, 'learning_rate': 4.0432203389830506e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1229/6000 [1:12:14<4:38:09,  3.50s/it] 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:18<4:34:09,  3.45s/it]                                                       {'loss': 0.0544, 'grad_norm': 2.943821430206299, 'learning_rate': 4.0423728813559324e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:18<4:34:09,  3.45s/it] 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:21<4:32:19,  3.43s/it]                                                       {'loss': 0.2244, 'grad_norm': 8.05063247680664, 'learning_rate': 4.0415254237288135e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:21<4:32:19,  3.43s/it] 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:24<4:31:02,  3.41s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.08327551931142807, 'learning_rate': 4.040677966101695e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:24<4:31:02,  3.41s/it] 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:28<4:37:42,  3.50s/it]                                                       {'loss': 0.0309, 'grad_norm': 2.694326162338257, 'learning_rate': 4.0398305084745764e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:28<4:37:42,  3.50s/it] 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:32<4:50:53,  3.66s/it]                                                       {'loss': 0.1268, 'grad_norm': 5.65448522567749, 'learning_rate': 4.038983050847458e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:32<4:50:53,  3.66s/it] 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:36<4:44:57,  3.59s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.42649388313293457, 'learning_rate': 4.0381355932203394e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:36<4:44:57,  3.59s/it] 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:39<4:39:55,  3.53s/it]                                                       {'loss': 0.0808, 'grad_norm': 3.533632278442383, 'learning_rate': 4.0372881355932205e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:39<4:39:55,  3.53s/it] 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:42<4:37:32,  3.50s/it]                                                       {'loss': 0.0199, 'grad_norm': 1.267272710800171, 'learning_rate': 4.0364406779661016e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:42<4:37:32,  3.50s/it] 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:46<4:35:50,  3.48s/it]                                                       {'loss': 0.0357, 'grad_norm': 3.997610330581665, 'learning_rate': 4.0355932203389834e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:46<4:35:50,  3.48s/it] 21%|â–ˆâ–ˆ        | 1239/6000 [1:12:49<4:32:51,  3.44s/it]                                                       {'loss': 0.0407, 'grad_norm': 2.112004280090332, 'learning_rate': 4.0347457627118646e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1239/6000 [1:12:49<4:32:51,  3.44s/it] 21%|â–ˆâ–ˆ        | 1240/6000 [1:12:53<4:32:49,  3.44s/it]                                                       {'loss': 0.043, 'grad_norm': 1.6485003232955933, 'learning_rate': 4.0338983050847464e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1240/6000 [1:12:53<4:32:49,  3.44s/it] 21%|â–ˆâ–ˆ        | 1241/6000 [1:12:56<4:32:22,  3.43s/it]                                                       {'loss': 0.0241, 'grad_norm': 2.576625347137451, 'learning_rate': 4.0330508474576275e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1241/6000 [1:12:56<4:32:22,  3.43s/it] 21%|â–ˆâ–ˆ        | 1242/6000 [1:13:00<4:35:44,  3.48s/it]                                                       {'loss': 0.1446, 'grad_norm': 3.982809066772461, 'learning_rate': 4.0322033898305086e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1242/6000 [1:13:00<4:35:44,  3.48s/it] 21%|â–ˆâ–ˆ        | 1243/6000 [1:13:03<4:33:48,  3.45s/it]                                                       {'loss': 0.0084, 'grad_norm': 0.8591963648796082, 'learning_rate': 4.03135593220339e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1243/6000 [1:13:03<4:33:48,  3.45s/it] 21%|â–ˆâ–ˆ        | 1244/6000 [1:13:06<4:30:38,  3.41s/it]                                                       {'loss': 0.064, 'grad_norm': 3.9228665828704834, 'learning_rate': 4.030508474576271e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1244/6000 [1:13:06<4:30:38,  3.41s/it] 21%|â–ˆâ–ˆ        | 1245/6000 [1:13:10<4:28:56,  3.39s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.2966305613517761, 'learning_rate': 4.029661016949153e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1245/6000 [1:13:10<4:28:56,  3.39s/it] 21%|â–ˆâ–ˆ        | 1246/6000 [1:13:13<4:27:18,  3.37s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.5508310198783875, 'learning_rate': 4.028813559322034e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1246/6000 [1:13:13<4:27:18,  3.37s/it] 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:16<4:28:05,  3.38s/it]                                                       {'loss': 0.067, 'grad_norm': 2.194176435470581, 'learning_rate': 4.0279661016949156e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:16<4:28:05,  3.38s/it] 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:20<4:28:16,  3.39s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.1799752414226532, 'learning_rate': 4.027118644067797e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:20<4:28:16,  3.39s/it] 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:23<4:28:05,  3.39s/it]                                                       {'loss': 0.122, 'grad_norm': 4.53336238861084, 'learning_rate': 4.0262711864406786e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:23<4:28:05,  3.39s/it] 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:26<4:25:48,  3.36s/it]                                                       {'loss': 0.1048, 'grad_norm': 4.757577419281006, 'learning_rate': 4.025423728813559e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:26<4:25:48,  3.36s/it][2025-10-21 02:37:49,237] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:32<5:18:04,  4.02s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.26464536786079407, 'learning_rate': 4.024576271186441e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:32<5:18:04,  4.02s/it] 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:35<5:02:49,  3.83s/it]                                                       {'loss': 0.0979, 'grad_norm': 3.7085490226745605, 'learning_rate': 4.023728813559322e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:35<5:02:49,  3.83s/it] 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:39<5:06:14,  3.87s/it]                                                       {'loss': 0.1079, 'grad_norm': 3.876105785369873, 'learning_rate': 4.022881355932204e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:39<5:06:14,  3.87s/it] 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:43<4:53:44,  3.71s/it]                                                       {'loss': 0.0162, 'grad_norm': 0.8877408504486084, 'learning_rate': 4.022033898305085e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:43<4:53:44,  3.71s/it] 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:46<4:46:24,  3.62s/it]                                                       {'loss': 0.0205, 'grad_norm': 1.5274629592895508, 'learning_rate': 4.021186440677967e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:46<4:46:24,  3.62s/it] 21%|â–ˆâ–ˆ        | 1256/6000 [1:13:50<4:47:18,  3.63s/it]                                                       {'loss': 0.0121, 'grad_norm': 0.8190371990203857, 'learning_rate': 4.020338983050848e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1256/6000 [1:13:50<4:47:18,  3.63s/it] 21%|â–ˆâ–ˆ        | 1257/6000 [1:13:53<4:40:49,  3.55s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.9827483892440796, 'learning_rate': 4.019491525423729e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1257/6000 [1:13:53<4:40:49,  3.55s/it] 21%|â–ˆâ–ˆ        | 1258/6000 [1:13:57<4:41:04,  3.56s/it]                                                       {'loss': 0.0292, 'grad_norm': 1.0514905452728271, 'learning_rate': 4.01864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1258/6000 [1:13:57<4:41:04,  3.56s/it] 21%|â–ˆâ–ˆ        | 1259/6000 [1:14:00<4:37:33,  3.51s/it]                                                       {'loss': 0.5384, 'grad_norm': 7.859464645385742, 'learning_rate': 4.017796610169492e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1259/6000 [1:14:00<4:37:33,  3.51s/it] 21%|â–ˆâ–ˆ        | 1260/6000 [1:14:04<4:34:33,  3.48s/it]                                                       {'loss': 0.067, 'grad_norm': 1.8957312107086182, 'learning_rate': 4.016949152542373e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1260/6000 [1:14:04<4:34:33,  3.48s/it] 21%|â–ˆâ–ˆ        | 1261/6000 [1:14:07<4:34:19,  3.47s/it]                                                       {'loss': 0.138, 'grad_norm': 4.811175346374512, 'learning_rate': 4.016101694915255e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1261/6000 [1:14:07<4:34:19,  3.47s/it] 21%|â–ˆâ–ˆ        | 1262/6000 [1:14:11<4:43:45,  3.59s/it]                                                       {'loss': 0.1534, 'grad_norm': 3.232271432876587, 'learning_rate': 4.015254237288136e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1262/6000 [1:14:11<4:43:45,  3.59s/it] 21%|â–ˆâ–ˆ        | 1263/6000 [1:14:14<4:41:18,  3.56s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5327481031417847, 'learning_rate': 4.014406779661017e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1263/6000 [1:14:14<4:41:18,  3.56s/it] 21%|â–ˆâ–ˆ        | 1264/6000 [1:14:18<4:37:36,  3.52s/it]                                                       {'loss': 0.0139, 'grad_norm': 1.4920645952224731, 'learning_rate': 4.013559322033898e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1264/6000 [1:14:18<4:37:36,  3.52s/it] 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:21<4:35:22,  3.49s/it]                                                       {'loss': 0.1071, 'grad_norm': 4.500022888183594, 'learning_rate': 4.012711864406779e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:21<4:35:22,  3.49s/it] 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:25<4:33:00,  3.46s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.4941510260105133, 'learning_rate': 4.011864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:25<4:33:00,  3.46s/it] 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:28<4:41:10,  3.56s/it]                                                       {'loss': 0.0607, 'grad_norm': 3.9354207515716553, 'learning_rate': 4.011016949152542e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:28<4:41:10,  3.56s/it] 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:32<4:34:34,  3.48s/it]                                                       {'loss': 0.074, 'grad_norm': 4.1056599617004395, 'learning_rate': 4.010169491525424e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:32<4:34:34,  3.48s/it] 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:35<4:32:01,  3.45s/it]                                                       {'loss': 0.2283, 'grad_norm': 9.15119457244873, 'learning_rate': 4.009322033898305e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:35<4:32:01,  3.45s/it] 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:39<4:32:00,  3.45s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.16146491467952728, 'learning_rate': 4.008474576271187e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:39<4:32:00,  3.45s/it] 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:42<4:33:39,  3.47s/it]                                                       {'loss': 0.1727, 'grad_norm': 5.018957614898682, 'learning_rate': 4.007627118644068e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:42<4:33:39,  3.47s/it] 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:46<4:40:52,  3.56s/it]                                                       {'loss': 0.0996, 'grad_norm': 3.8183176517486572, 'learning_rate': 4.006779661016949e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:46<4:40:52,  3.56s/it] 21%|â–ˆâ–ˆ        | 1273/6000 [1:14:49<4:36:10,  3.51s/it]                                                       {'loss': 0.0338, 'grad_norm': 1.5985468626022339, 'learning_rate': 4.0059322033898304e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1273/6000 [1:14:49<4:36:10,  3.51s/it] 21%|â–ˆâ–ˆ        | 1274/6000 [1:14:53<4:31:46,  3.45s/it]                                                       {'loss': 0.0694, 'grad_norm': 4.849813938140869, 'learning_rate': 4.005084745762712e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1274/6000 [1:14:53<4:31:46,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:14:56<4:30:39,  3.44s/it]                                                       {'loss': 0.1824, 'grad_norm': 4.533412933349609, 'learning_rate': 4.004237288135593e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:14:56<4:30:39,  3.44s/it] 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:14:59<4:33:26,  3.47s/it]                                                       {'loss': 0.2815, 'grad_norm': 5.82999324798584, 'learning_rate': 4.003389830508475e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:14:59<4:33:26,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:15:03<4:33:42,  3.48s/it]                                                       {'loss': 0.2059, 'grad_norm': 7.527789115905762, 'learning_rate': 4.002542372881356e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:15:03<4:33:42,  3.48s/it] 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:15:06<4:33:14,  3.47s/it]                                                       {'loss': 0.0703, 'grad_norm': 2.600637435913086, 'learning_rate': 4.0016949152542374e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:15:06<4:33:14,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:15:10<4:31:13,  3.45s/it]                                                       {'loss': 0.1542, 'grad_norm': 3.1377785205841064, 'learning_rate': 4.0008474576271185e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:15:10<4:31:13,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:15:13<4:31:55,  3.46s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.3228079378604889, 'learning_rate': 4e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:15:13<4:31:55,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:15:17<4:31:54,  3.46s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.4270433187484741, 'learning_rate': 3.9991525423728815e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:15:17<4:31:54,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:20<4:30:12,  3.44s/it]                                                       {'loss': 0.0265, 'grad_norm': 1.770786166191101, 'learning_rate': 3.998305084745763e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:20<4:30:12,  3.44s/it] 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:23<4:27:07,  3.40s/it]                                                       {'loss': 0.0704, 'grad_norm': 2.7499618530273438, 'learning_rate': 3.9974576271186444e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:23<4:27:07,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:27<4:27:17,  3.40s/it]                                                       {'loss': 0.0241, 'grad_norm': 1.6359800100326538, 'learning_rate': 3.996610169491526e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:27<4:27:17,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:30<4:26:02,  3.39s/it]                                                       {'loss': 0.067, 'grad_norm': 2.223961353302002, 'learning_rate': 3.9957627118644066e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:30<4:26:02,  3.39s/it] 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:34<4:28:42,  3.42s/it]                                                       {'loss': 0.0914, 'grad_norm': 3.4322564601898193, 'learning_rate': 3.994915254237288e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:34<4:28:42,  3.42s/it] 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:37<4:31:19,  3.45s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.7089808583259583, 'learning_rate': 3.9940677966101696e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:37<4:31:19,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:41<4:31:59,  3.46s/it]                                                       {'loss': 0.0816, 'grad_norm': 3.3705873489379883, 'learning_rate': 3.993220338983051e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:41<4:31:59,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:44<4:28:35,  3.42s/it]                                                       {'loss': 0.0215, 'grad_norm': 1.4378154277801514, 'learning_rate': 3.9923728813559325e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:44<4:28:35,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:47<4:28:08,  3.42s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.044858768582344055, 'learning_rate': 3.9915254237288136e-05, 'epoch': 0.21}
 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:47<4:28:08,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:15:51<4:27:54,  3.41s/it]                                                       {'loss': 0.0385, 'grad_norm': 1.5025070905685425, 'learning_rate': 3.9906779661016955e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:15:51<4:27:54,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:15:54<4:27:16,  3.41s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.44299668073654175, 'learning_rate': 3.9898305084745766e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:15:54<4:27:16,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:15:58<4:29:34,  3.44s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.1841837614774704, 'learning_rate': 3.988983050847458e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:15:58<4:29:34,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:16:01<4:27:48,  3.41s/it]                                                       {'loss': 0.0296, 'grad_norm': 1.2303369045257568, 'learning_rate': 3.988135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:16:01<4:27:48,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:16:04<4:25:48,  3.39s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.1270321011543274, 'learning_rate': 3.9872881355932206e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:16:04<4:25:48,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:16:08<4:25:56,  3.39s/it]                                                       {'loss': 0.0098, 'grad_norm': 0.6338882446289062, 'learning_rate': 3.986440677966102e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:16:08<4:25:56,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:16:12<4:33:25,  3.49s/it]                                                       {'loss': 0.0266, 'grad_norm': 1.7020190954208374, 'learning_rate': 3.9855932203389836e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:16:12<4:33:25,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:16:15<4:31:31,  3.46s/it]                                                       {'loss': 0.0758, 'grad_norm': 2.952566623687744, 'learning_rate': 3.984745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:16:15<4:31:31,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:18<4:30:06,  3.45s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.3738001585006714, 'learning_rate': 3.983898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:18<4:30:06,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:22<4:29:27,  3.44s/it]                                                       {'loss': 0.1444, 'grad_norm': 4.637729167938232, 'learning_rate': 3.983050847457627e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:22<4:29:27,  3.44s/it][2025-10-21 02:40:44,561] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:27<5:20:36,  4.09s/it]                                                       {'loss': 0.0125, 'grad_norm': 0.894910454750061, 'learning_rate': 3.982203389830509e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:27<5:20:36,  4.09s/it] 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:31<5:03:30,  3.88s/it]                                                       {'loss': 0.0744, 'grad_norm': 2.881685972213745, 'learning_rate': 3.98135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:31<5:03:30,  3.88s/it] 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:34<4:51:38,  3.73s/it]                                                       {'loss': 0.0185, 'grad_norm': 1.3341461420059204, 'learning_rate': 3.980508474576272e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:34<4:51:38,  3.73s/it] 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:16:38<4:44:22,  3.63s/it]                                                       {'loss': 0.058, 'grad_norm': 3.528019905090332, 'learning_rate': 3.979661016949153e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:16:38<4:44:22,  3.63s/it] 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:16:41<4:36:18,  3.53s/it]                                                       {'loss': 0.0883, 'grad_norm': 4.252885818481445, 'learning_rate': 3.978813559322034e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:16:41<4:36:18,  3.53s/it] 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:16:44<4:35:57,  3.53s/it]                                                       {'loss': 0.0336, 'grad_norm': 1.961145043373108, 'learning_rate': 3.977966101694916e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:16:44<4:35:57,  3.53s/it] 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:16:48<4:32:39,  3.49s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.14012978971004486, 'learning_rate': 3.977118644067796e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:16:48<4:32:39,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:16:51<4:31:40,  3.47s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.7273905277252197, 'learning_rate': 3.976271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:16:51<4:31:40,  3.47s/it] 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:16:55<4:29:42,  3.45s/it]                                                       {'loss': 0.0139, 'grad_norm': 0.9415052533149719, 'learning_rate': 3.975423728813559e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:16:55<4:29:42,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:16:58<4:31:41,  3.48s/it]                                                       {'loss': 0.0623, 'grad_norm': 2.7152299880981445, 'learning_rate': 3.974576271186441e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:16:58<4:31:41,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:17:01<4:28:04,  3.43s/it]                                                       {'loss': 0.0153, 'grad_norm': 0.9603594541549683, 'learning_rate': 3.973728813559322e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:17:01<4:28:04,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:17:05<4:25:00,  3.39s/it]                                                       {'loss': 0.3953, 'grad_norm': 7.127848148345947, 'learning_rate': 3.972881355932204e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:17:05<4:25:00,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:17:08<4:25:14,  3.40s/it]                                                       {'loss': 0.1007, 'grad_norm': 3.5839929580688477, 'learning_rate': 3.972033898305085e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:17:08<4:25:14,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:17:12<4:24:26,  3.39s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.24291178584098816, 'learning_rate': 3.971186440677966e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:17:12<4:24:26,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:17:15<4:23:49,  3.38s/it]                                                       {'loss': 0.1833, 'grad_norm': 4.025622367858887, 'learning_rate': 3.970338983050847e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:17:15<4:23:49,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:18<4:25:21,  3.40s/it]                                                       {'loss': 0.278, 'grad_norm': 4.656380653381348, 'learning_rate': 3.969491525423729e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:18<4:25:21,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:22<4:24:05,  3.38s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.13079382479190826, 'learning_rate': 3.96864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:22<4:24:05,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:25<4:26:11,  3.41s/it]                                                       {'loss': 0.0742, 'grad_norm': 3.4894392490386963, 'learning_rate': 3.967796610169492e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:25<4:26:11,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:29<4:25:24,  3.40s/it]                                                       {'loss': 0.1699, 'grad_norm': 3.5531694889068604, 'learning_rate': 3.966949152542373e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:29<4:25:24,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:32<4:25:04,  3.40s/it]                                                       {'loss': 0.0311, 'grad_norm': 3.344856023788452, 'learning_rate': 3.966101694915255e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:32<4:25:04,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:35<4:27:23,  3.43s/it]                                                       {'loss': 0.1931, 'grad_norm': 6.159570217132568, 'learning_rate': 3.9652542372881354e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:35<4:27:23,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:17:39<4:38:23,  3.57s/it]                                                       {'loss': 0.0349, 'grad_norm': 1.8076473474502563, 'learning_rate': 3.964406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:17:39<4:38:23,  3.57s/it] 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:17:43<4:37:13,  3.56s/it]                                                       {'loss': 0.0325, 'grad_norm': 2.654430389404297, 'learning_rate': 3.9635593220338983e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:17:43<4:37:13,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:17:46<4:32:54,  3.50s/it]                                                       {'loss': 0.0556, 'grad_norm': 4.211447715759277, 'learning_rate': 3.96271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:17:46<4:32:54,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:17:50<4:29:09,  3.45s/it]                                                       {'loss': 0.0261, 'grad_norm': 1.3651831150054932, 'learning_rate': 3.961864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:17:50<4:29:09,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:17:53<4:27:34,  3.43s/it]                                                       {'loss': 0.1399, 'grad_norm': 6.199163913726807, 'learning_rate': 3.9610169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:17:53<4:27:34,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:17:56<4:28:24,  3.45s/it]                                                       {'loss': 0.0367, 'grad_norm': 3.3735389709472656, 'learning_rate': 3.960169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:17:56<4:28:24,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:18:00<4:27:54,  3.44s/it]                                                       {'loss': 0.037, 'grad_norm': 2.302639961242676, 'learning_rate': 3.9593220338983053e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:18:00<4:27:54,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:18:04<4:37:12,  3.56s/it]                                                       {'loss': 0.0452, 'grad_norm': 3.1061553955078125, 'learning_rate': 3.9584745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:18:04<4:37:12,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:18:07<4:34:15,  3.52s/it]                                                       {'loss': 0.1201, 'grad_norm': 3.169353485107422, 'learning_rate': 3.9576271186440676e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:18:07<4:34:15,  3.52s/it] 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:18:11<4:32:52,  3.51s/it]                                                       {'loss': 0.0947, 'grad_norm': 4.328056335449219, 'learning_rate': 3.9567796610169494e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:18:11<4:32:52,  3.51s/it] 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:18:14<4:30:41,  3.48s/it]                                                       {'loss': 0.0737, 'grad_norm': 2.97497820854187, 'learning_rate': 3.9559322033898305e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:18:14<4:30:41,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:17<4:29:30,  3.46s/it]                                                       {'loss': 0.0746, 'grad_norm': 5.308818817138672, 'learning_rate': 3.9550847457627123e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:17<4:29:30,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:21<4:28:56,  3.46s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.2481953352689743, 'learning_rate': 3.9542372881355935e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:21<4:28:56,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:24<4:26:52,  3.43s/it]                                                       {'loss': 0.0255, 'grad_norm': 1.6325434446334839, 'learning_rate': 3.9533898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:24<4:26:52,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:28<4:25:26,  3.41s/it]                                                       {'loss': 0.0351, 'grad_norm': 2.2101597785949707, 'learning_rate': 3.952542372881356e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:28<4:25:26,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:31<4:23:20,  3.39s/it]                                                       {'loss': 0.1, 'grad_norm': 2.788813591003418, 'learning_rate': 3.9516949152542375e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:31<4:23:20,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:34<4:23:18,  3.39s/it]                                                       {'loss': 0.0238, 'grad_norm': 2.0222504138946533, 'learning_rate': 3.9508474576271187e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:34<4:23:18,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:18:38<4:21:42,  3.37s/it]                                                       {'loss': 0.0262, 'grad_norm': 2.369091510772705, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:18:38<4:21:42,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:18:41<4:25:04,  3.41s/it]                                                       {'loss': 0.0746, 'grad_norm': 3.6335039138793945, 'learning_rate': 3.9491525423728816e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:18:41<4:25:04,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:18:45<4:26:58,  3.44s/it]                                                       {'loss': 0.1653, 'grad_norm': 5.21868896484375, 'learning_rate': 3.9483050847457634e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:18:45<4:26:58,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:18:48<4:34:15,  3.53s/it]                                                       {'loss': 0.1764, 'grad_norm': 5.982777118682861, 'learning_rate': 3.9474576271186445e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:18:48<4:34:15,  3.53s/it] 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:18:52<4:39:55,  3.61s/it]                                                       {'loss': 0.05, 'grad_norm': 1.676626443862915, 'learning_rate': 3.9466101694915257e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:18:52<4:39:55,  3.61s/it] 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:18:56<4:36:22,  3.56s/it]                                                       {'loss': 0.0168, 'grad_norm': 1.4851652383804321, 'learning_rate': 3.945762711864407e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:18:56<4:36:22,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:18:59<4:40:51,  3.62s/it]                                                       {'loss': 0.0681, 'grad_norm': 2.361194610595703, 'learning_rate': 3.9449152542372886e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:18:59<4:40:51,  3.62s/it] 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:19:03<4:36:16,  3.56s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.661116898059845, 'learning_rate': 3.94406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:19:03<4:36:16,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:19:06<4:35:35,  3.55s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.5139449238777161, 'learning_rate': 3.943220338983051e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:19:06<4:35:35,  3.55s/it] 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:19:10<4:31:25,  3.50s/it]                                                       {'loss': 0.0133, 'grad_norm': 0.814520001411438, 'learning_rate': 3.9423728813559327e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:19:10<4:31:25,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:19:14<4:39:01,  3.60s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.06910985708236694, 'learning_rate': 3.941525423728814e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:19:14<4:39:01,  3.60s/it] 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:17<4:39:27,  3.61s/it]                                                       {'loss': 0.1005, 'grad_norm': 4.255342960357666, 'learning_rate': 3.940677966101695e-05, 'epoch': 0.23}
 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:17<4:39:27,  3.61s/it][2025-10-21 02:43:40,003] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:23<5:25:15,  4.20s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.005541534163057804, 'learning_rate': 3.939830508474576e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:23<5:25:15,  4.20s/it] 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:26<5:07:50,  3.97s/it]                                                       {'loss': 0.0289, 'grad_norm': 1.2307853698730469, 'learning_rate': 3.938983050847458e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:26<5:07:50,  3.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:30<4:58:59,  3.86s/it]                                                       {'loss': 0.0425, 'grad_norm': 2.41167950630188, 'learning_rate': 3.938135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:30<4:58:59,  3.86s/it] 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:33<4:49:23,  3.74s/it]                                                       {'loss': 0.0094, 'grad_norm': 0.5687273740768433, 'learning_rate': 3.937288135593221e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:33<4:49:23,  3.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:37<4:43:42,  3.66s/it]                                                       {'loss': 0.0078, 'grad_norm': 0.7071846723556519, 'learning_rate': 3.936440677966102e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:37<4:43:42,  3.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:19:41<4:52:09,  3.77s/it]                                                       {'loss': 0.0216, 'grad_norm': 1.5858536958694458, 'learning_rate': 3.935593220338983e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:19:41<4:52:09,  3.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:19:44<4:46:41,  3.70s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.0494234561920166, 'learning_rate': 3.934745762711864e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:19:44<4:46:41,  3.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:19:48<4:41:33,  3.64s/it]                                                       {'loss': 0.1418, 'grad_norm': 5.4964985847473145, 'learning_rate': 3.933898305084746e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:19:48<4:41:33,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:19:52<4:43:03,  3.66s/it]                                                       {'loss': 0.016, 'grad_norm': 1.4503883123397827, 'learning_rate': 3.933050847457627e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:19:52<4:43:03,  3.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:19:55<4:35:27,  3.56s/it]                                                       {'loss': 0.0974, 'grad_norm': 3.058795690536499, 'learning_rate': 3.932203389830509e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:19:55<4:35:27,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:19:58<4:30:22,  3.50s/it]                                                       {'loss': 0.1469, 'grad_norm': 11.018122673034668, 'learning_rate': 3.93135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:19:58<4:30:22,  3.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:20:02<4:31:02,  3.51s/it]                                                       {'loss': 0.138, 'grad_norm': 4.924961566925049, 'learning_rate': 3.930508474576272e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:20:02<4:31:02,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:20:05<4:29:41,  3.49s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.18498112261295319, 'learning_rate': 3.929661016949153e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:20:05<4:29:41,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:20:09<4:26:04,  3.44s/it]                                                       {'loss': 0.0957, 'grad_norm': 4.156091213226318, 'learning_rate': 3.928813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:20:09<4:26:04,  3.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:20:12<4:35:44,  3.57s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.0608025789260864, 'learning_rate': 3.927966101694915e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:20:12<4:35:44,  3.57s/it] 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:20:16<4:44:36,  3.69s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.18248623609542847, 'learning_rate': 3.927118644067797e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:20:16<4:44:36,  3.69s/it] 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:20<4:49:16,  3.75s/it]                                                       {'loss': 0.0494, 'grad_norm': 3.5452661514282227, 'learning_rate': 3.926271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:20<4:49:16,  3.75s/it] 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:24<4:42:08,  3.65s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.5886965394020081, 'learning_rate': 3.925423728813559e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:24<4:42:08,  3.65s/it] 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:27<4:37:32,  3.60s/it]                                                       {'loss': 0.0228, 'grad_norm': 1.2671083211898804, 'learning_rate': 3.924576271186441e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:27<4:37:32,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:32<4:55:48,  3.83s/it]                                                       {'loss': 0.1298, 'grad_norm': 3.580895185470581, 'learning_rate': 3.923728813559322e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:32<4:55:48,  3.83s/it] 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:35<4:48:44,  3.74s/it]                                                       {'loss': 0.0215, 'grad_norm': 1.403771162033081, 'learning_rate': 3.9228813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:35<4:48:44,  3.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:20:39<4:40:39,  3.64s/it]                                                       {'loss': 0.0265, 'grad_norm': 1.9978322982788086, 'learning_rate': 3.9220338983050845e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:20:39<4:40:39,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:20:42<4:38:14,  3.61s/it]                                                       {'loss': 0.1156, 'grad_norm': 5.5218353271484375, 'learning_rate': 3.921186440677966e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:20:42<4:38:14,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:20:46<4:37:47,  3.60s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.2462569773197174, 'learning_rate': 3.9203389830508474e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:20:46<4:37:47,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:20:49<4:31:40,  3.52s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.3611610531806946, 'learning_rate': 3.919491525423729e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:20:49<4:31:40,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:20:53<4:32:51,  3.54s/it]                                                       {'loss': 0.2226, 'grad_norm': 8.29871654510498, 'learning_rate': 3.9186440677966104e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:20:53<4:32:51,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:20:56<4:28:01,  3.48s/it]                                                       {'loss': 0.1564, 'grad_norm': 2.7915236949920654, 'learning_rate': 3.917796610169492e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:20:56<4:28:01,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:20:59<4:24:27,  3.43s/it]                                                       {'loss': 0.0213, 'grad_norm': 1.7073731422424316, 'learning_rate': 3.9169491525423726e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:20:59<4:24:27,  3.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:21:03<4:23:39,  3.42s/it]                                                       {'loss': 0.0423, 'grad_norm': 2.4536893367767334, 'learning_rate': 3.9161016949152544e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:21:03<4:23:39,  3.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:21:06<4:22:08,  3.40s/it]                                                       {'loss': 0.0439, 'grad_norm': 2.4605934619903564, 'learning_rate': 3.9152542372881355e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:21:06<4:22:08,  3.40s/it] 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:21:10<4:29:47,  3.50s/it]                                                       {'loss': 0.1929, 'grad_norm': 5.708417892456055, 'learning_rate': 3.9144067796610174e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:21:10<4:29:47,  3.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:21:13<4:28:10,  3.48s/it]                                                       {'loss': 0.199, 'grad_norm': 3.7605366706848145, 'learning_rate': 3.9135593220338985e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:21:13<4:28:10,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:21:17<4:29:09,  3.50s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.2587124109268188, 'learning_rate': 3.91271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:21:17<4:29:09,  3.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:20<4:34:01,  3.56s/it]                                                       {'loss': 0.1943, 'grad_norm': 2.855285167694092, 'learning_rate': 3.9118644067796614e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:20<4:34:01,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:24<4:29:55,  3.51s/it]                                                       {'loss': 0.0714, 'grad_norm': 3.6388676166534424, 'learning_rate': 3.9110169491525425e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:24<4:29:55,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:27<4:28:23,  3.49s/it]                                                       {'loss': 0.1074, 'grad_norm': 4.9920806884765625, 'learning_rate': 3.910169491525424e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:27<4:28:23,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:31<4:25:47,  3.46s/it]                                                       {'loss': 0.0237, 'grad_norm': 1.5685158967971802, 'learning_rate': 3.9093220338983055e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:31<4:25:47,  3.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:34<4:28:10,  3.49s/it]                                                       {'loss': 0.141, 'grad_norm': 3.36262845993042, 'learning_rate': 3.9084745762711866e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:34<4:28:10,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:21:38<4:44:23,  3.70s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.26314908266067505, 'learning_rate': 3.907627118644068e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:21:38<4:44:23,  3.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:21:42<4:36:44,  3.60s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.3286900520324707, 'learning_rate': 3.9067796610169495e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:21:42<4:36:44,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:21:45<4:29:48,  3.51s/it]                                                       {'loss': 0.0417, 'grad_norm': 2.7839317321777344, 'learning_rate': 3.905932203389831e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:21:45<4:29:48,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:21:48<4:27:37,  3.48s/it]                                                       {'loss': 0.0198, 'grad_norm': 1.6036971807479858, 'learning_rate': 3.905084745762712e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:21:48<4:27:37,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:21:52<4:27:08,  3.48s/it]                                                       {'loss': 0.0504, 'grad_norm': 2.584198236465454, 'learning_rate': 3.904237288135593e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:21:52<4:27:08,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:21:55<4:24:16,  3.44s/it]                                                       {'loss': 0.0898, 'grad_norm': 2.003298282623291, 'learning_rate': 3.903389830508475e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:21:55<4:24:16,  3.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:21:59<4:23:58,  3.44s/it]                                                       {'loss': 0.1829, 'grad_norm': 3.5096755027770996, 'learning_rate': 3.902542372881356e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:21:59<4:23:58,  3.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:22:02<4:22:19,  3.42s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.3387700021266937, 'learning_rate': 3.901694915254238e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:22:02<4:22:19,  3.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:22:06<4:22:26,  3.42s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.10220901668071747, 'learning_rate': 3.900847457627119e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:22:06<4:22:26,  3.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:22:09<4:21:07,  3.40s/it]                                                       {'loss': 0.1376, 'grad_norm': 4.537137508392334, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:22:09<4:21:07,  3.40s/it] 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:22:12<4:20:00,  3.39s/it]                                                       {'loss': 0.1951, 'grad_norm': 4.178249835968018, 'learning_rate': 3.899152542372882e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:22:12<4:20:00,  3.39s/it] 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:22:16<4:20:08,  3.39s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.10312704741954803, 'learning_rate': 3.898305084745763e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:22:16<4:20:08,  3.39s/it][2025-10-21 02:46:38,381] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:21<5:07:57,  4.02s/it]                                                       {'loss': 0.051, 'grad_norm': 3.3403587341308594, 'learning_rate': 3.897457627118644e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:21<5:07:57,  4.02s/it] 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:25<4:53:43,  3.83s/it]                                                       {'loss': 0.1922, 'grad_norm': 3.7003374099731445, 'learning_rate': 3.896610169491526e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:25<4:53:43,  3.83s/it] 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:28<4:43:28,  3.70s/it]                                                       {'loss': 0.0536, 'grad_norm': 3.175443649291992, 'learning_rate': 3.895762711864407e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:28<4:43:28,  3.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:31<4:36:00,  3.60s/it]                                                       {'loss': 0.0395, 'grad_norm': 0.8490722179412842, 'learning_rate': 3.894915254237289e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:31<4:36:00,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:35<4:30:28,  3.53s/it]                                                       {'loss': 0.1808, 'grad_norm': 4.826047420501709, 'learning_rate': 3.89406779661017e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:35<4:30:28,  3.53s/it] 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:22:38<4:27:13,  3.49s/it]                                                       {'loss': 0.0455, 'grad_norm': 1.8400945663452148, 'learning_rate': 3.893220338983051e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:22:38<4:27:13,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:22:42<4:34:03,  3.58s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.0461307093501091, 'learning_rate': 3.892372881355932e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:22:42<4:34:03,  3.58s/it] 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:22:45<4:29:34,  3.52s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.2055053561925888, 'learning_rate': 3.891525423728814e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:22:45<4:29:34,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:22:49<4:26:40,  3.49s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.3202793598175049, 'learning_rate': 3.890677966101695e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:22:49<4:26:40,  3.49s/it] 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:22:52<4:33:31,  3.58s/it]                                                       {'loss': 0.0626, 'grad_norm': 1.1470940113067627, 'learning_rate': 3.889830508474576e-05, 'epoch': 0.23}
 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:22:52<4:33:31,  3.58s/it] 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:22:56<4:31:13,  3.55s/it]                                                       {'loss': 0.0133, 'grad_norm': 0.5908113121986389, 'learning_rate': 3.888983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:22:56<4:31:13,  3.55s/it] 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:23:00<4:41:15,  3.68s/it]                                                       {'loss': 0.0436, 'grad_norm': 1.9347528219223022, 'learning_rate': 3.888135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:23:00<4:41:15,  3.68s/it] 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:23:03<4:33:34,  3.58s/it]                                                       {'loss': 0.0076, 'grad_norm': 0.6309124231338501, 'learning_rate': 3.88728813559322e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:23:03<4:33:34,  3.58s/it] 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:23:07<4:28:12,  3.51s/it]                                                       {'loss': 0.3055, 'grad_norm': 4.076777935028076, 'learning_rate': 3.8864406779661014e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:23:07<4:28:12,  3.51s/it] 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:23:10<4:35:26,  3.60s/it]                                                       {'loss': 0.0413, 'grad_norm': 3.906799554824829, 'learning_rate': 3.885593220338983e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:23:10<4:35:26,  3.60s/it] 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:23:14<4:30:44,  3.54s/it]                                                       {'loss': 0.0096, 'grad_norm': 0.9610986113548279, 'learning_rate': 3.884745762711864e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:23:14<4:30:44,  3.54s/it] 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:23:17<4:29:36,  3.53s/it]                                                       {'loss': 0.1128, 'grad_norm': 4.138646125793457, 'learning_rate': 3.883898305084746e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:23:17<4:29:36,  3.53s/it] 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:21<4:27:42,  3.51s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.43467044830322266, 'learning_rate': 3.883050847457627e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:21<4:27:42,  3.51s/it] 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:24<4:29:01,  3.52s/it]                                                       {'loss': 0.0633, 'grad_norm': 2.42781138420105, 'learning_rate': 3.882203389830509e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:24<4:29:01,  3.52s/it] 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:28<4:26:11,  3.49s/it]                                                       {'loss': 0.0426, 'grad_norm': 0.8335318565368652, 'learning_rate': 3.88135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:28<4:26:11,  3.49s/it] 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:31<4:25:14,  3.48s/it]                                                       {'loss': 0.0473, 'grad_norm': 2.5733070373535156, 'learning_rate': 3.880508474576271e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:31<4:25:14,  3.48s/it] 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:35<4:23:35,  3.45s/it]                                                       {'loss': 0.1756, 'grad_norm': 5.400997638702393, 'learning_rate': 3.8796610169491524e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:35<4:23:35,  3.45s/it] 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:23:38<4:21:11,  3.42s/it]                                                       {'loss': 0.0137, 'grad_norm': 0.7245955467224121, 'learning_rate': 3.878813559322034e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:23:38<4:21:11,  3.42s/it] 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:23:41<4:19:31,  3.40s/it]                                                       {'loss': 0.3299, 'grad_norm': 5.387160301208496, 'learning_rate': 3.8779661016949154e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:23:41<4:19:31,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:23:45<4:24:49,  3.47s/it]                                                       {'loss': 0.0827, 'grad_norm': 5.106078147888184, 'learning_rate': 3.877118644067797e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:23:45<4:24:49,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:23:48<4:26:37,  3.50s/it]                                                       {'loss': 0.0638, 'grad_norm': 2.8392255306243896, 'learning_rate': 3.876271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:23:48<4:26:37,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:23:52<4:22:37,  3.45s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.4808651804924011, 'learning_rate': 3.8754237288135594e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:23:52<4:22:37,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:23:55<4:21:31,  3.43s/it]                                                       {'loss': 0.1176, 'grad_norm': 4.056329727172852, 'learning_rate': 3.8745762711864406e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:23:55<4:21:31,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:23:59<4:19:54,  3.41s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.397354245185852, 'learning_rate': 3.8737288135593224e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:23:59<4:19:54,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:24:02<4:19:41,  3.41s/it]                                                       {'loss': 0.0743, 'grad_norm': 3.704390048980713, 'learning_rate': 3.8728813559322035e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:24:02<4:19:41,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:24:05<4:19:23,  3.41s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.44920065999031067, 'learning_rate': 3.8720338983050846e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:24:05<4:19:23,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:24:09<4:19:33,  3.41s/it]                                                       {'loss': 0.078, 'grad_norm': 5.848823070526123, 'learning_rate': 3.8711864406779664e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:24:09<4:19:33,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:24:13<4:31:19,  3.56s/it]                                                       {'loss': 0.0554, 'grad_norm': 2.764497756958008, 'learning_rate': 3.8703389830508476e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:24:13<4:31:19,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:24:16<4:30:46,  3.56s/it]                                                       {'loss': 0.0204, 'grad_norm': 1.9807978868484497, 'learning_rate': 3.8694915254237294e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:24:16<4:30:46,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:20<4:26:54,  3.51s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.175742045044899, 'learning_rate': 3.86864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:20<4:26:54,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:23<4:30:32,  3.56s/it]                                                       {'loss': 0.0322, 'grad_norm': 1.8247590065002441, 'learning_rate': 3.8677966101694916e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:23<4:30:32,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:27<4:28:50,  3.54s/it]                                                       {'loss': 0.0856, 'grad_norm': 2.520127058029175, 'learning_rate': 3.866949152542373e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:27<4:28:50,  3.54s/it] 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:30<4:25:49,  3.50s/it]                                                       {'loss': 0.0424, 'grad_norm': 1.637932538986206, 'learning_rate': 3.8661016949152546e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:30<4:25:49,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:34<4:22:30,  3.45s/it]                                                       {'loss': 0.0192, 'grad_norm': 1.8718304634094238, 'learning_rate': 3.865254237288136e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:34<4:22:30,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:24:37<4:21:20,  3.44s/it]                                                       {'loss': 0.0563, 'grad_norm': 3.7360622882843018, 'learning_rate': 3.8644067796610175e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:24:37<4:21:20,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:24:40<4:20:54,  3.43s/it]                                                       {'loss': 0.0844, 'grad_norm': 3.451956272125244, 'learning_rate': 3.8635593220338986e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:24:40<4:20:54,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:24:44<4:24:15,  3.48s/it]                                                       {'loss': 0.2331, 'grad_norm': 6.25509786605835, 'learning_rate': 3.86271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:24:44<4:24:15,  3.48s/it] 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:24:47<4:21:45,  3.45s/it]                                                       {'loss': 0.032, 'grad_norm': 1.976181149482727, 'learning_rate': 3.861864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:24:47<4:21:45,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:24:51<4:19:37,  3.42s/it]                                                       {'loss': 0.0128, 'grad_norm': 0.8581798672676086, 'learning_rate': 3.861016949152543e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:24:51<4:19:37,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:24:54<4:18:02,  3.40s/it]                                                       {'loss': 0.0653, 'grad_norm': 4.431844711303711, 'learning_rate': 3.860169491525424e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:24:54<4:18:02,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:24:57<4:17:05,  3.39s/it]                                                       {'loss': 0.034, 'grad_norm': 2.6543209552764893, 'learning_rate': 3.8593220338983056e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:24:57<4:17:05,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:25:01<4:16:43,  3.38s/it]                                                       {'loss': 0.006, 'grad_norm': 0.24127019941806793, 'learning_rate': 3.858474576271187e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:25:01<4:16:43,  3.38s/it] 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:25:04<4:17:06,  3.39s/it]                                                       {'loss': 0.6238, 'grad_norm': 7.536718845367432, 'learning_rate': 3.8576271186440686e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:25:04<4:17:06,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:25:08<4:17:48,  3.40s/it]                                                       {'loss': 0.0104, 'grad_norm': 0.4749363362789154, 'learning_rate': 3.856779661016949e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:25:08<4:17:48,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:25:11<4:19:00,  3.42s/it]                                                       {'loss': 0.0223, 'grad_norm': 1.1577305793762207, 'learning_rate': 3.855932203389831e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:25:11<4:19:00,  3.42s/it][2025-10-21 02:49:33,792] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:25:17<5:08:51,  4.07s/it]                                                       {'loss': 0.0344, 'grad_norm': 1.8016870021820068, 'learning_rate': 3.855084745762712e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:25:17<5:08:51,  4.07s/it] 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:25:20<4:52:56,  3.86s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.5479397177696228, 'learning_rate': 3.854237288135593e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:25:20<4:52:56,  3.86s/it] 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:23<4:41:54,  3.72s/it]                                                       {'loss': 0.2288, 'grad_norm': 5.533717632293701, 'learning_rate': 3.853389830508475e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:23<4:41:54,  3.72s/it] 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:27<4:34:38,  3.62s/it]                                                       {'loss': 0.0437, 'grad_norm': 1.5394686460494995, 'learning_rate': 3.852542372881356e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:27<4:34:38,  3.62s/it] 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:30<4:28:26,  3.54s/it]                                                       {'loss': 0.0585, 'grad_norm': 2.452035903930664, 'learning_rate': 3.851694915254238e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:30<4:28:26,  3.54s/it] 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:34<4:26:08,  3.51s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2989449203014374, 'learning_rate': 3.850847457627119e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:34<4:26:08,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:25:37<4:23:33,  3.48s/it]                                                       {'loss': 0.0323, 'grad_norm': 1.7778434753417969, 'learning_rate': 3.85e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:25:37<4:23:33,  3.48s/it] 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:25:40<4:22:43,  3.47s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.22835136950016022, 'learning_rate': 3.849152542372881e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:25:40<4:22:43,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:25:44<4:20:40,  3.44s/it]                                                       {'loss': 0.0442, 'grad_norm': 3.1141505241394043, 'learning_rate': 3.848305084745763e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:25:44<4:20:40,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:25:47<4:17:42,  3.41s/it]                                                       {'loss': 0.2893, 'grad_norm': 7.527609348297119, 'learning_rate': 3.847457627118644e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:25:47<4:17:42,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:25:51<4:25:12,  3.51s/it]                                                       {'loss': 0.0845, 'grad_norm': 2.999566078186035, 'learning_rate': 3.846610169491526e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:25:51<4:25:12,  3.51s/it] 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:25:54<4:22:30,  3.47s/it]                                                       {'loss': 0.1329, 'grad_norm': 6.512930870056152, 'learning_rate': 3.845762711864407e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:25:54<4:22:30,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:25:58<4:21:23,  3.46s/it]                                                       {'loss': 0.0403, 'grad_norm': 2.4942569732666016, 'learning_rate': 3.844915254237288e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:25:58<4:21:23,  3.46s/it] 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:26:01<4:22:41,  3.47s/it]                                                       {'loss': 0.212, 'grad_norm': 7.721086502075195, 'learning_rate': 3.844067796610169e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:26:01<4:22:41,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:26:05<4:23:08,  3.48s/it]                                                       {'loss': 0.0613, 'grad_norm': 2.5734550952911377, 'learning_rate': 3.843220338983051e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:26:05<4:23:08,  3.48s/it] 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:26:08<4:20:08,  3.44s/it]                                                       {'loss': 0.0326, 'grad_norm': 1.694156289100647, 'learning_rate': 3.842372881355932e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:26:08<4:20:08,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:26:12<4:20:28,  3.45s/it]                                                       {'loss': 0.0593, 'grad_norm': 1.879073977470398, 'learning_rate': 3.841525423728814e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:26:12<4:20:28,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:26:15<4:19:53,  3.44s/it]                                                       {'loss': 0.3043, 'grad_norm': 6.959758281707764, 'learning_rate': 3.840677966101695e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:26:15<4:19:53,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:26:19<4:28:08,  3.55s/it]                                                       {'loss': 0.0164, 'grad_norm': 1.2592519521713257, 'learning_rate': 3.839830508474577e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:26:19<4:28:08,  3.55s/it] 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:22<4:29:56,  3.58s/it]                                                       {'loss': 0.2621, 'grad_norm': 6.1754984855651855, 'learning_rate': 3.838983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:22<4:29:56,  3.58s/it] 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:26<4:28:34,  3.56s/it]                                                       {'loss': 0.0996, 'grad_norm': 4.9972100257873535, 'learning_rate': 3.838135593220339e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:26<4:28:34,  3.56s/it] 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:29<4:25:26,  3.52s/it]                                                       {'loss': 0.0762, 'grad_norm': 3.9281885623931885, 'learning_rate': 3.8372881355932204e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:29<4:25:26,  3.52s/it] 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:33<4:22:42,  3.48s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.7486972808837891, 'learning_rate': 3.8364406779661015e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:33<4:22:42,  3.48s/it] 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:26:36<4:20:06,  3.45s/it]                                                       {'loss': 0.0582, 'grad_norm': 4.623086929321289, 'learning_rate': 3.835593220338983e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:26:36<4:20:06,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:26:40<4:35:48,  3.66s/it]                                                       {'loss': 0.1346, 'grad_norm': 4.236948490142822, 'learning_rate': 3.8347457627118644e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:26:40<4:35:48,  3.66s/it] 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:26:44<4:29:16,  3.57s/it]                                                       {'loss': 0.0459, 'grad_norm': 1.9164849519729614, 'learning_rate': 3.833898305084746e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:26:44<4:29:16,  3.57s/it] 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:26:47<4:23:27,  3.49s/it]                                                       {'loss': 0.0541, 'grad_norm': 3.218430995941162, 'learning_rate': 3.8330508474576274e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:26:47<4:23:27,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:26:50<4:20:08,  3.45s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.2148112952709198, 'learning_rate': 3.8322033898305085e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:26:50<4:20:08,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:26:54<4:18:57,  3.44s/it]                                                       {'loss': 0.2311, 'grad_norm': 5.242277145385742, 'learning_rate': 3.8313559322033896e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:26:54<4:18:57,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:26:57<4:17:24,  3.42s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.09088746458292007, 'learning_rate': 3.8305084745762714e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:26:57<4:17:24,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:27:00<4:16:46,  3.41s/it]                                                       {'loss': 0.1846, 'grad_norm': 5.758782863616943, 'learning_rate': 3.8296610169491526e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:27:00<4:16:46,  3.41s/it] 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:27:04<4:16:44,  3.41s/it]                                                       {'loss': 0.0719, 'grad_norm': 3.3832573890686035, 'learning_rate': 3.8288135593220344e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:27:04<4:16:44,  3.41s/it] 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:27:07<4:16:28,  3.41s/it]                                                       {'loss': 0.0563, 'grad_norm': 2.681152582168579, 'learning_rate': 3.8279661016949155e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:27:07<4:16:28,  3.41s/it] 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:27:11<4:15:23,  3.39s/it]                                                       {'loss': 0.0439, 'grad_norm': 3.2087976932525635, 'learning_rate': 3.8271186440677966e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:27:11<4:15:23,  3.39s/it] 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:27:14<4:16:15,  3.41s/it]                                                       {'loss': 0.3017, 'grad_norm': 5.744315147399902, 'learning_rate': 3.826271186440678e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:27:14<4:16:15,  3.41s/it] 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:27:18<4:16:59,  3.42s/it]                                                       {'loss': 0.0274, 'grad_norm': 3.0759716033935547, 'learning_rate': 3.8254237288135596e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:27:18<4:16:59,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:21<4:26:34,  3.54s/it]                                                       {'loss': 0.118, 'grad_norm': 3.6938376426696777, 'learning_rate': 3.824576271186441e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:21<4:26:34,  3.54s/it] 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:25<4:22:32,  3.49s/it]                                                       {'loss': 0.1158, 'grad_norm': 4.344069957733154, 'learning_rate': 3.8237288135593225e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:25<4:22:32,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:29<4:29:28,  3.58s/it]                                                       {'loss': 0.0919, 'grad_norm': 4.415650844573975, 'learning_rate': 3.8228813559322036e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:29<4:29:28,  3.58s/it] 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:32<4:29:09,  3.58s/it]                                                       {'loss': 0.0523, 'grad_norm': 1.4491381645202637, 'learning_rate': 3.8220338983050854e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:32<4:29:09,  3.58s/it] 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:27:36<4:26:18,  3.54s/it]                                                       {'loss': 0.0157, 'grad_norm': 1.2754920721054077, 'learning_rate': 3.8211864406779666e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:27:36<4:26:18,  3.54s/it] 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:27:39<4:33:49,  3.64s/it]                                                       {'loss': 0.0781, 'grad_norm': 3.333974838256836, 'learning_rate': 3.820338983050848e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:27:39<4:33:49,  3.64s/it] 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:27:43<4:26:30,  3.55s/it]                                                       {'loss': 0.009, 'grad_norm': 0.7241421937942505, 'learning_rate': 3.819491525423729e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:27:43<4:26:30,  3.55s/it] 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:27:46<4:22:03,  3.49s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.4634596109390259, 'learning_rate': 3.81864406779661e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:27:46<4:22:03,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:27:50<4:22:16,  3.49s/it]                                                       {'loss': 0.1418, 'grad_norm': 4.58241605758667, 'learning_rate': 3.817796610169492e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:27:50<4:22:16,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:27:53<4:22:18,  3.49s/it]                                                       {'loss': 0.1222, 'grad_norm': 3.716270923614502, 'learning_rate': 3.816949152542373e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:27:53<4:22:18,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:27:57<4:22:21,  3.50s/it]                                                       {'loss': 0.2967, 'grad_norm': 6.7171196937561035, 'learning_rate': 3.816101694915255e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:27:57<4:22:21,  3.50s/it] 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:28:00<4:20:40,  3.47s/it]                                                       {'loss': 0.0411, 'grad_norm': 1.8839765787124634, 'learning_rate': 3.815254237288136e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:28:00<4:20:40,  3.47s/it] 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:28:03<4:19:21,  3.46s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.6875198483467102, 'learning_rate': 3.814406779661017e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:28:03<4:19:21,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:28:07<4:18:59,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.15924400091171265, 'learning_rate': 3.813559322033898e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:28:07<4:18:59,  3.45s/it][2025-10-21 02:52:29,638] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:28:13<5:09:02,  4.12s/it]                                                       {'loss': 0.1011, 'grad_norm': 3.518827199935913, 'learning_rate': 3.81271186440678e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:28:13<5:09:02,  4.12s/it] 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:28:16<4:52:45,  3.91s/it]                                                       {'loss': 0.1154, 'grad_norm': 4.778691291809082, 'learning_rate': 3.811864406779661e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:28:16<4:52:45,  3.91s/it] 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:28:19<4:38:49,  3.72s/it]                                                       {'loss': 0.1095, 'grad_norm': 2.7980473041534424, 'learning_rate': 3.811016949152543e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:28:19<4:38:49,  3.72s/it] 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:23<4:33:54,  3.66s/it]                                                       {'loss': 0.0103, 'grad_norm': 0.9697437882423401, 'learning_rate': 3.810169491525424e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:23<4:33:54,  3.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:26<4:28:37,  3.59s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.12713393568992615, 'learning_rate': 3.809322033898306e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:26<4:28:37,  3.59s/it] 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:30<4:24:57,  3.54s/it]                                                       {'loss': 0.0306, 'grad_norm': 2.459789752960205, 'learning_rate': 3.808474576271186e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:30<4:24:57,  3.54s/it] 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:33<4:24:06,  3.53s/it]                                                       {'loss': 0.164, 'grad_norm': 4.16820764541626, 'learning_rate': 3.807627118644068e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:33<4:24:06,  3.53s/it] 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:28:37<4:23:26,  3.52s/it]                                                       {'loss': 0.0559, 'grad_norm': 2.905337333679199, 'learning_rate': 3.806779661016949e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:28:37<4:23:26,  3.52s/it] 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:28:40<4:24:18,  3.53s/it]                                                       {'loss': 0.0807, 'grad_norm': 4.054922103881836, 'learning_rate': 3.805932203389831e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:28:40<4:24:18,  3.53s/it] 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:28:44<4:20:42,  3.48s/it]                                                       {'loss': 0.0479, 'grad_norm': 1.5124098062515259, 'learning_rate': 3.805084745762712e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:28:44<4:20:42,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:28:47<4:18:51,  3.46s/it]                                                       {'loss': 0.0343, 'grad_norm': 2.910352945327759, 'learning_rate': 3.804237288135594e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:28:47<4:18:51,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:28:50<4:17:03,  3.44s/it]                                                       {'loss': 0.065, 'grad_norm': 3.227670907974243, 'learning_rate': 3.803389830508475e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:28:50<4:17:03,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:28:54<4:16:41,  3.43s/it]                                                       {'loss': 0.2121, 'grad_norm': 5.666468620300293, 'learning_rate': 3.802542372881356e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:28:54<4:16:41,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:28:57<4:14:17,  3.40s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.3098984658718109, 'learning_rate': 3.801694915254237e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:28:57<4:14:17,  3.40s/it] 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:29:00<4:13:38,  3.39s/it]                                                       {'loss': 0.1304, 'grad_norm': 4.847001075744629, 'learning_rate': 3.8008474576271184e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:29:00<4:13:38,  3.39s/it] 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:29:04<4:15:27,  3.42s/it]                                                       {'loss': 0.125, 'grad_norm': 3.734992504119873, 'learning_rate': 3.8e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:29:04<4:15:27,  3.42s/it] 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:29:08<4:21:47,  3.50s/it]                                                       {'loss': 0.0385, 'grad_norm': 1.193328857421875, 'learning_rate': 3.799152542372881e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:29:08<4:21:47,  3.50s/it] 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:29:11<4:18:18,  3.46s/it]                                                       {'loss': 0.01, 'grad_norm': 0.7004978656768799, 'learning_rate': 3.798305084745763e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:29:11<4:18:18,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:29:14<4:16:01,  3.43s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.3074444830417633, 'learning_rate': 3.797457627118644e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:29:14<4:16:01,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:29:18<4:19:25,  3.47s/it]                                                       {'loss': 0.1103, 'grad_norm': 3.8291146755218506, 'learning_rate': 3.7966101694915254e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:29:18<4:19:25,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:21<4:16:54,  3.44s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.3404025137424469, 'learning_rate': 3.7957627118644065e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:21<4:16:54,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:25<4:16:22,  3.44s/it]                                                       {'loss': 0.1568, 'grad_norm': 3.816742420196533, 'learning_rate': 3.794915254237288e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:25<4:16:22,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:28<4:16:16,  3.43s/it]                                                       {'loss': 0.0138, 'grad_norm': 0.8672749400138855, 'learning_rate': 3.7940677966101695e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:28<4:16:16,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:32<4:16:19,  3.44s/it]                                                       {'loss': 0.1126, 'grad_norm': 4.320345878601074, 'learning_rate': 3.793220338983051e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:32<4:16:19,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:35<4:18:18,  3.46s/it]                                                       {'loss': 0.0911, 'grad_norm': 3.2487282752990723, 'learning_rate': 3.7923728813559324e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:35<4:18:18,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:29:39<4:19:15,  3.48s/it]                                                       {'loss': 0.0174, 'grad_norm': 0.8418792486190796, 'learning_rate': 3.791525423728814e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:29:39<4:19:15,  3.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:29:42<4:26:08,  3.57s/it]                                                       {'loss': 0.0406, 'grad_norm': 2.329448699951172, 'learning_rate': 3.790677966101695e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:29:42<4:26:08,  3.57s/it] 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:29:46<4:35:26,  3.70s/it]                                                       {'loss': 0.0193, 'grad_norm': 1.4006695747375488, 'learning_rate': 3.7898305084745765e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:29:46<4:35:26,  3.70s/it] 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:29:50<4:27:19,  3.59s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.6195635795593262, 'learning_rate': 3.7889830508474576e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:29:50<4:27:19,  3.59s/it] 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:29:54<4:33:32,  3.67s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.281404048204422, 'learning_rate': 3.7881355932203394e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:29:54<4:33:32,  3.67s/it] 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:29:57<4:28:07,  3.60s/it]                                                       {'loss': 0.061, 'grad_norm': 2.7553493976593018, 'learning_rate': 3.7872881355932205e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:29:57<4:28:07,  3.60s/it] 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:30:00<4:23:11,  3.53s/it]                                                       {'loss': 0.1453, 'grad_norm': 3.5564682483673096, 'learning_rate': 3.786440677966102e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:30:00<4:23:11,  3.53s/it] 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:30:04<4:20:16,  3.50s/it]                                                       {'loss': 0.1606, 'grad_norm': 4.325870037078857, 'learning_rate': 3.7855932203389835e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:30:04<4:20:16,  3.50s/it] 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:30:07<4:16:33,  3.45s/it]                                                       {'loss': 0.0286, 'grad_norm': 1.573785662651062, 'learning_rate': 3.7847457627118646e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:30:07<4:16:33,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:30:11<4:14:24,  3.42s/it]                                                       {'loss': 0.0502, 'grad_norm': 1.1964404582977295, 'learning_rate': 3.783898305084746e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:30:11<4:14:24,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:30:14<4:12:36,  3.40s/it]                                                       {'loss': 0.0999, 'grad_norm': 4.341770648956299, 'learning_rate': 3.783050847457627e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:30:14<4:12:36,  3.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:30:17<4:14:49,  3.43s/it]                                                       {'loss': 0.0161, 'grad_norm': 1.246619462966919, 'learning_rate': 3.7822033898305087e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:30:17<4:14:49,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:21<4:17:10,  3.46s/it]                                                       {'loss': 0.0768, 'grad_norm': 1.3605989217758179, 'learning_rate': 3.78135593220339e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:21<4:17:10,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:24<4:16:11,  3.45s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.4214783310890198, 'learning_rate': 3.7805084745762716e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:24<4:16:11,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:28<4:16:31,  3.45s/it]                                                       {'loss': 0.0769, 'grad_norm': 3.5153257846832275, 'learning_rate': 3.779661016949153e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:28<4:16:31,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:31<4:20:37,  3.51s/it]                                                       {'loss': 0.1528, 'grad_norm': 4.2130656242370605, 'learning_rate': 3.778813559322034e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:31<4:20:37,  3.51s/it] 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:35<4:17:07,  3.46s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.10951496660709381, 'learning_rate': 3.777966101694915e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:35<4:17:07,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:30:38<4:17:11,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.002556048333644867, 'learning_rate': 3.777118644067797e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:30:38<4:17:11,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:30:42<4:14:55,  3.43s/it]                                                       {'loss': 0.1625, 'grad_norm': 5.483688831329346, 'learning_rate': 3.776271186440678e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:30:42<4:14:55,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:30:45<4:16:55,  3.46s/it]                                                       {'loss': 0.0432, 'grad_norm': 1.9118919372558594, 'learning_rate': 3.77542372881356e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:30:45<4:16:55,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:30:49<4:17:12,  3.46s/it]                                                       {'loss': 0.0549, 'grad_norm': 3.3653790950775146, 'learning_rate': 3.774576271186441e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:30:49<4:17:12,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:30:52<4:13:56,  3.42s/it]                                                       {'loss': 0.0529, 'grad_norm': 4.636200428009033, 'learning_rate': 3.7737288135593226e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:30:52<4:13:56,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:30:55<4:11:54,  3.39s/it]                                                       {'loss': 0.0629, 'grad_norm': 2.7550625801086426, 'learning_rate': 3.772881355932204e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:30:55<4:11:54,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:30:59<4:12:43,  3.41s/it]                                                       {'loss': 0.0396, 'grad_norm': 1.6374741792678833, 'learning_rate': 3.772033898305085e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:30:59<4:12:43,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:31:02<4:13:32,  3.42s/it]                                                       {'loss': 0.0208, 'grad_norm': 0.9291363954544067, 'learning_rate': 3.771186440677966e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:31:02<4:13:32,  3.42s/it][2025-10-21 02:55:24,854] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:31:08<5:01:32,  4.07s/it]                                                       {'loss': 0.0241, 'grad_norm': 0.5540138483047485, 'learning_rate': 3.770338983050848e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:31:08<5:01:32,  4.07s/it] 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:31:11<4:46:36,  3.87s/it]                                                       {'loss': 0.0146, 'grad_norm': 1.3747313022613525, 'learning_rate': 3.769491525423729e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:31:11<4:46:36,  3.87s/it] 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:31:14<4:34:10,  3.70s/it]                                                       {'loss': 0.0902, 'grad_norm': 2.6810121536254883, 'learning_rate': 3.768644067796611e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:31:14<4:34:10,  3.70s/it] 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:31:18<4:27:42,  3.61s/it]                                                       {'loss': 0.0705, 'grad_norm': 2.7932043075561523, 'learning_rate': 3.767796610169492e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:31:18<4:27:42,  3.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:31:21<4:21:06,  3.52s/it]                                                       {'loss': 0.0214, 'grad_norm': 0.7195794582366943, 'learning_rate': 3.766949152542373e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:31:21<4:21:06,  3.52s/it] 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:24<4:17:31,  3.48s/it]                                                       {'loss': 0.0099, 'grad_norm': 0.861594557762146, 'learning_rate': 3.766101694915254e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:25<4:17:31,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:28<4:16:05,  3.46s/it]                                                       {'loss': 0.0419, 'grad_norm': 1.5278470516204834, 'learning_rate': 3.765254237288135e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:28<4:16:05,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:31<4:16:00,  3.46s/it]                                                       {'loss': 0.0453, 'grad_norm': 1.2858576774597168, 'learning_rate': 3.764406779661017e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:31<4:16:00,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:35<4:26:04,  3.59s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.454812616109848, 'learning_rate': 3.763559322033898e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:35<4:26:04,  3.59s/it] 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:31:39<4:20:24,  3.52s/it]                                                       {'loss': 0.055, 'grad_norm': 1.874955654144287, 'learning_rate': 3.76271186440678e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:31:39<4:20:24,  3.52s/it] 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:31:42<4:23:03,  3.56s/it]                                                       {'loss': 0.0607, 'grad_norm': 1.228682041168213, 'learning_rate': 3.761864406779661e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:31:42<4:23:03,  3.56s/it] 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:31:46<4:21:43,  3.54s/it]                                                       {'loss': 0.0204, 'grad_norm': 1.676095962524414, 'learning_rate': 3.761016949152543e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:31:46<4:21:43,  3.54s/it] 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:31:49<4:17:35,  3.48s/it]                                                       {'loss': 0.0392, 'grad_norm': 2.5317437648773193, 'learning_rate': 3.7601694915254234e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:31:49<4:17:35,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:31:53<4:16:05,  3.46s/it]                                                       {'loss': 0.0543, 'grad_norm': 3.158252716064453, 'learning_rate': 3.759322033898305e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:31:53<4:16:05,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:31:56<4:13:02,  3.42s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.049024514853954315, 'learning_rate': 3.7584745762711864e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:31:56<4:13:02,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:31:59<4:15:48,  3.46s/it]                                                       {'loss': 0.0163, 'grad_norm': 1.0513523817062378, 'learning_rate': 3.757627118644068e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:31:59<4:15:48,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:32:03<4:13:37,  3.43s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.10715531557798386, 'learning_rate': 3.756779661016949e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:32:03<4:13:37,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:32:06<4:11:22,  3.40s/it]                                                       {'loss': 0.022, 'grad_norm': 1.5479949712753296, 'learning_rate': 3.755932203389831e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:32:06<4:11:22,  3.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:32:09<4:10:27,  3.39s/it]                                                       {'loss': 0.076, 'grad_norm': 4.041599750518799, 'learning_rate': 3.755084745762712e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:32:09<4:10:27,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:32:13<4:11:59,  3.41s/it]                                                       {'loss': 0.0855, 'grad_norm': 1.9171580076217651, 'learning_rate': 3.7542372881355934e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:32:13<4:11:59,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:32:16<4:12:58,  3.43s/it]                                                       {'loss': 0.0693, 'grad_norm': 1.313092827796936, 'learning_rate': 3.7533898305084745e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:32:16<4:12:58,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:32:20<4:12:46,  3.43s/it]                                                       {'loss': 0.0572, 'grad_norm': 4.531373500823975, 'learning_rate': 3.752542372881356e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:32:20<4:12:46,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:23<4:12:44,  3.43s/it]                                                       {'loss': 0.0155, 'grad_norm': 0.7893555164337158, 'learning_rate': 3.7516949152542374e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:23<4:12:44,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:27<4:14:09,  3.45s/it]                                                       {'loss': 0.0294, 'grad_norm': 2.704362154006958, 'learning_rate': 3.750847457627119e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:27<4:14:09,  3.45s/it] 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:30<4:12:28,  3.42s/it]                                                       {'loss': 0.0522, 'grad_norm': 4.633894920349121, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:30<4:12:28,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:34<4:13:36,  3.44s/it]                                                       {'loss': 0.0548, 'grad_norm': 3.0889947414398193, 'learning_rate': 3.7491525423728815e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:34<4:13:36,  3.44s/it] 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:32:37<4:11:53,  3.42s/it]                                                       {'loss': 0.1452, 'grad_norm': 5.152289390563965, 'learning_rate': 3.7483050847457626e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:32:37<4:11:53,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:32:40<4:11:52,  3.42s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.5367571115493774, 'learning_rate': 3.747457627118644e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:32:40<4:11:52,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:32:44<4:13:11,  3.44s/it]                                                       {'loss': 0.0238, 'grad_norm': 2.581465244293213, 'learning_rate': 3.7466101694915255e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:32:44<4:13:11,  3.44s/it] 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:32:47<4:10:29,  3.40s/it]                                                       {'loss': 0.1022, 'grad_norm': 3.0038347244262695, 'learning_rate': 3.745762711864407e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:32:47<4:10:29,  3.40s/it] 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:32:51<4:19:52,  3.53s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.4722767770290375, 'learning_rate': 3.7449152542372885e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:32:51<4:19:52,  3.53s/it] 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:32:54<4:18:39,  3.51s/it]                                                       {'loss': 0.084, 'grad_norm': 4.267644882202148, 'learning_rate': 3.7440677966101696e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:32:54<4:18:39,  3.51s/it] 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:32:58<4:14:40,  3.46s/it]                                                       {'loss': 0.0197, 'grad_norm': 1.1895389556884766, 'learning_rate': 3.7432203389830514e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:32:58<4:14:40,  3.46s/it] 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:33:01<4:11:20,  3.41s/it]                                                       {'loss': 0.1018, 'grad_norm': 5.548706531524658, 'learning_rate': 3.7423728813559325e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:33:01<4:11:20,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:33:05<4:11:02,  3.41s/it]                                                       {'loss': 0.0484, 'grad_norm': 3.924271583557129, 'learning_rate': 3.741525423728814e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:33:05<4:11:02,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:33:08<4:09:34,  3.39s/it]                                                       {'loss': 0.0679, 'grad_norm': 2.578943967819214, 'learning_rate': 3.740677966101695e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:33:08<4:09:34,  3.39s/it] 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:33:11<4:11:02,  3.41s/it]                                                       {'loss': 0.0179, 'grad_norm': 1.855224609375, 'learning_rate': 3.7398305084745766e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:33:11<4:11:02,  3.41s/it] 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:33:15<4:09:59,  3.40s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.277447372674942, 'learning_rate': 3.738983050847458e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:33:15<4:09:59,  3.40s/it] 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:33:19<4:19:05,  3.52s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.2876664698123932, 'learning_rate': 3.7381355932203395e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:33:19<4:19:05,  3.52s/it] 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:33:22<4:14:19,  3.46s/it]                                                       {'loss': 0.0237, 'grad_norm': 1.9361294507980347, 'learning_rate': 3.737288135593221e-05, 'epoch': 0.27}
 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:33:22<4:14:19,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:25<4:12:31,  3.44s/it]                                                       {'loss': 0.0498, 'grad_norm': 2.7794435024261475, 'learning_rate': 3.736440677966102e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:25<4:12:31,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:29<4:10:42,  3.41s/it]                                                       {'loss': 0.0386, 'grad_norm': 1.8159979581832886, 'learning_rate': 3.735593220338983e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:29<4:10:42,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:32<4:13:26,  3.45s/it]                                                       {'loss': 0.004, 'grad_norm': 0.4171130359172821, 'learning_rate': 3.734745762711865e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:32<4:13:26,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:33:35<4:10:52,  3.42s/it]                                                       {'loss': 0.0238, 'grad_norm': 1.6757169961929321, 'learning_rate': 3.733898305084746e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:33:35<4:10:52,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:33:39<4:11:09,  3.42s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.5964837074279785, 'learning_rate': 3.733050847457628e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:33:39<4:11:09,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:33:42<4:12:43,  3.44s/it]                                                       {'loss': 0.1018, 'grad_norm': 2.727173328399658, 'learning_rate': 3.732203389830509e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:33:42<4:12:43,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:33:46<4:12:41,  3.44s/it]                                                       {'loss': 0.0268, 'grad_norm': 1.0397099256515503, 'learning_rate': 3.73135593220339e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:33:46<4:12:41,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:33:49<4:11:48,  3.43s/it]                                                       {'loss': 0.255, 'grad_norm': 5.262521266937256, 'learning_rate': 3.730508474576272e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:33:49<4:11:48,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:33:53<4:10:43,  3.42s/it]                                                       {'loss': 0.1388, 'grad_norm': 4.956366539001465, 'learning_rate': 3.729661016949152e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:33:53<4:10:43,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:33:56<4:14:15,  3.47s/it]                                                       {'loss': 0.1036, 'grad_norm': 2.595301389694214, 'learning_rate': 3.728813559322034e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:33:56<4:14:15,  3.47s/it][2025-10-21 02:58:18,926] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:34:02<5:01:40,  4.11s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.231865167617798, 'learning_rate': 3.727966101694915e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:34:02<5:01:40,  4.11s/it] 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:34:06<4:56:11,  4.04s/it]                                                       {'loss': 0.0687, 'grad_norm': 2.570659875869751, 'learning_rate': 3.727118644067797e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:34:06<4:56:11,  4.04s/it] 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:34:09<4:48:55,  3.94s/it]                                                       {'loss': 0.019, 'grad_norm': 1.5843645334243774, 'learning_rate': 3.726271186440678e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:34:09<4:48:55,  3.94s/it] 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:34:14<4:54:46,  4.02s/it]                                                       {'loss': 0.0575, 'grad_norm': 2.8085975646972656, 'learning_rate': 3.72542372881356e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:34:14<4:54:46,  4.02s/it] 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:34:18<4:52:07,  3.99s/it]                                                       {'loss': 0.034, 'grad_norm': 1.3937734365463257, 'learning_rate': 3.724576271186441e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:34:18<4:52:07,  3.99s/it] 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:34:21<4:35:36,  3.76s/it]                                                       {'loss': 0.0272, 'grad_norm': 2.020031690597534, 'learning_rate': 3.723728813559322e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:34:21<4:35:36,  3.76s/it] 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:24<4:27:19,  3.65s/it]                                                       {'loss': 0.0107, 'grad_norm': 0.9511740803718567, 'learning_rate': 3.722881355932203e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:24<4:27:19,  3.65s/it] 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:28<4:30:37,  3.70s/it]                                                       {'loss': 0.0969, 'grad_norm': 3.5807993412017822, 'learning_rate': 3.722033898305085e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:28<4:30:37,  3.70s/it] 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:31<4:23:26,  3.60s/it]                                                       {'loss': 0.0306, 'grad_norm': 3.7493326663970947, 'learning_rate': 3.721186440677966e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:31<4:23:26,  3.60s/it] 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:35<4:18:21,  3.53s/it]                                                       {'loss': 0.0352, 'grad_norm': 3.1036436557769775, 'learning_rate': 3.720338983050848e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:35<4:18:21,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:34:38<4:15:43,  3.50s/it]                                                       {'loss': 0.082, 'grad_norm': 4.657528877258301, 'learning_rate': 3.719491525423729e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:34:38<4:15:43,  3.50s/it] 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:34:41<4:10:52,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.00809663999825716, 'learning_rate': 3.71864406779661e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:34:41<4:10:52,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:34:45<4:08:18,  3.40s/it]                                                       {'loss': 0.0733, 'grad_norm': 5.101491451263428, 'learning_rate': 3.7177966101694914e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:34:45<4:08:18,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:34:48<4:10:24,  3.43s/it]                                                       {'loss': 0.0823, 'grad_norm': 3.0715081691741943, 'learning_rate': 3.716949152542373e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:34:48<4:10:24,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:34:52<4:09:09,  3.41s/it]                                                       {'loss': 0.0277, 'grad_norm': 1.7836854457855225, 'learning_rate': 3.716101694915254e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:34:52<4:09:09,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:34:55<4:12:18,  3.45s/it]                                                       {'loss': 0.0407, 'grad_norm': 2.2105040550231934, 'learning_rate': 3.715254237288136e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:34:55<4:12:18,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:34:58<4:09:25,  3.41s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.032781749963760376, 'learning_rate': 3.714406779661017e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:34:58<4:09:25,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:35:02<4:18:09,  3.53s/it]                                                       {'loss': 0.0641, 'grad_norm': 3.319126844406128, 'learning_rate': 3.7135593220338984e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:35:02<4:18:09,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:35:06<4:16:06,  3.51s/it]                                                       {'loss': 0.02, 'grad_norm': 2.3699357509613037, 'learning_rate': 3.71271186440678e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:35:06<4:16:06,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:35:09<4:16:04,  3.51s/it]                                                       {'loss': 0.0298, 'grad_norm': 1.383948564529419, 'learning_rate': 3.711864406779661e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:35:09<4:16:04,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:35:13<4:26:57,  3.66s/it]                                                       {'loss': 0.0161, 'grad_norm': 1.14918851852417, 'learning_rate': 3.7110169491525424e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:35:13<4:26:57,  3.66s/it] 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:35:17<4:20:25,  3.57s/it]                                                       {'loss': 0.1188, 'grad_norm': 6.3540167808532715, 'learning_rate': 3.7101694915254236e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:35:17<4:20:25,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:35:20<4:17:24,  3.53s/it]                                                       {'loss': 0.1159, 'grad_norm': 5.929109573364258, 'learning_rate': 3.7093220338983054e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:35:20<4:17:24,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:23<4:16:18,  3.51s/it]                                                       {'loss': 0.1366, 'grad_norm': 4.9972825050354, 'learning_rate': 3.7084745762711865e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:23<4:16:18,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:27<4:15:38,  3.51s/it]                                                       {'loss': 0.0413, 'grad_norm': 1.7426166534423828, 'learning_rate': 3.707627118644068e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:27<4:15:38,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:30<4:12:07,  3.46s/it]                                                       {'loss': 0.0238, 'grad_norm': 1.4395400285720825, 'learning_rate': 3.7067796610169494e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:30<4:12:07,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:34<4:10:46,  3.44s/it]                                                       {'loss': 0.0388, 'grad_norm': 3.0900750160217285, 'learning_rate': 3.7059322033898306e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:34<4:10:46,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:35:37<4:13:42,  3.48s/it]                                                       {'loss': 0.098, 'grad_norm': 4.964450836181641, 'learning_rate': 3.705084745762712e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:35:37<4:13:42,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:35:41<4:13:18,  3.48s/it]                                                       {'loss': 0.0784, 'grad_norm': 5.53876256942749, 'learning_rate': 3.7042372881355935e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:35:41<4:13:18,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:35:44<4:14:06,  3.49s/it]                                                       {'loss': 0.232, 'grad_norm': 5.549351692199707, 'learning_rate': 3.7033898305084746e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:35:44<4:14:06,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:35:48<4:16:44,  3.53s/it]                                                       {'loss': 0.1102, 'grad_norm': 5.597808361053467, 'learning_rate': 3.7025423728813564e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:35:48<4:16:44,  3.53s/it] 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:35:51<4:13:02,  3.48s/it]                                                       {'loss': 0.1861, 'grad_norm': 5.79945707321167, 'learning_rate': 3.7016949152542376e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:35:51<4:13:02,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:35:55<4:10:12,  3.44s/it]                                                       {'loss': 0.1407, 'grad_norm': 3.631682872772217, 'learning_rate': 3.7008474576271194e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:35:55<4:10:12,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:35:58<4:08:41,  3.42s/it]                                                       {'loss': 0.1797, 'grad_norm': 4.242403507232666, 'learning_rate': 3.7e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:35:58<4:08:41,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:36:02<4:19:04,  3.56s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.3823978900909424, 'learning_rate': 3.6991525423728816e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:36:02<4:19:04,  3.56s/it] 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:36:06<4:22:00,  3.60s/it]                                                       {'loss': 0.122, 'grad_norm': 4.237087726593018, 'learning_rate': 3.698305084745763e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:36:06<4:22:00,  3.60s/it] 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:36:09<4:17:28,  3.54s/it]                                                       {'loss': 0.0303, 'grad_norm': 2.2070865631103516, 'learning_rate': 3.6974576271186446e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:36:09<4:17:28,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:36:12<4:13:40,  3.49s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.1535948514938354, 'learning_rate': 3.696610169491526e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:36:12<4:13:40,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:36:16<4:10:22,  3.44s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.2621980905532837, 'learning_rate': 3.695762711864407e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:36:16<4:10:22,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:36:19<4:10:21,  3.45s/it]                                                       {'loss': 0.0593, 'grad_norm': 3.2875499725341797, 'learning_rate': 3.6949152542372886e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:36:19<4:10:21,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:23<4:15:20,  3.51s/it]                                                       {'loss': 0.1866, 'grad_norm': 3.7128586769104004, 'learning_rate': 3.69406779661017e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:23<4:15:20,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:26<4:13:39,  3.49s/it]                                                       {'loss': 0.0623, 'grad_norm': 3.6528046131134033, 'learning_rate': 3.693220338983051e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:26<4:13:39,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:30<4:11:44,  3.47s/it]                                                       {'loss': 0.2422, 'grad_norm': 6.906991004943848, 'learning_rate': 3.692372881355932e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:30<4:11:44,  3.47s/it] 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:33<4:08:04,  3.42s/it]                                                       {'loss': 0.0271, 'grad_norm': 2.238386869430542, 'learning_rate': 3.691525423728814e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:33<4:08:04,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:36:36<4:07:45,  3.41s/it]                                                       {'loss': 0.0176, 'grad_norm': 1.2393701076507568, 'learning_rate': 3.690677966101695e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:36:36<4:07:45,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:36:40<4:05:52,  3.39s/it]                                                       {'loss': 0.3353, 'grad_norm': 5.712933540344238, 'learning_rate': 3.689830508474577e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:36:40<4:05:52,  3.39s/it] 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:36:43<4:05:47,  3.39s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.34219783544540405, 'learning_rate': 3.688983050847458e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:36:43<4:05:47,  3.39s/it] 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:36:46<4:04:52,  3.38s/it]                                                       {'loss': 0.3666, 'grad_norm': 4.683094024658203, 'learning_rate': 3.688135593220339e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:36:46<4:04:52,  3.38s/it] 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:36:50<4:03:44,  3.36s/it]                                                       {'loss': 0.1502, 'grad_norm': 3.451244592666626, 'learning_rate': 3.68728813559322e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:36:50<4:03:44,  3.36s/it] 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:36:53<4:04:00,  3.37s/it]                                                       {'loss': 0.292, 'grad_norm': 7.4481987953186035, 'learning_rate': 3.686440677966102e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:36:53<4:04:00,  3.37s/it][2025-10-21 03:01:15,864] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:36:59<4:50:03,  4.00s/it]                                                       {'loss': 0.0174, 'grad_norm': 1.9600969552993774, 'learning_rate': 3.685593220338983e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:36:59<4:50:03,  4.00s/it] 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:37:03<4:52:08,  4.03s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.025240972638130188, 'learning_rate': 3.684745762711865e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:37:03<4:52:08,  4.03s/it] 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:37:06<4:39:57,  3.86s/it]                                                       {'loss': 0.2317, 'grad_norm': 6.392549514770508, 'learning_rate': 3.683898305084746e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:37:06<4:39:57,  3.86s/it] 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:37:10<4:29:46,  3.72s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.3799705505371094, 'learning_rate': 3.683050847457628e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:37:10<4:29:46,  3.72s/it] 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:37:13<4:28:52,  3.71s/it]                                                       {'loss': 0.0269, 'grad_norm': 2.183352470397949, 'learning_rate': 3.682203389830509e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:37:13<4:28:52,  3.71s/it] 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:37:17<4:24:40,  3.66s/it]                                                       {'loss': 0.0575, 'grad_norm': 3.5266120433807373, 'learning_rate': 3.68135593220339e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:37:17<4:24:40,  3.66s/it] 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:37:20<4:22:53,  3.63s/it]                                                       {'loss': 0.043, 'grad_norm': 3.9604501724243164, 'learning_rate': 3.680508474576271e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:37:20<4:22:53,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:24<4:16:12,  3.54s/it]                                                       {'loss': 0.0272, 'grad_norm': 1.833349585533142, 'learning_rate': 3.679661016949153e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:24<4:16:12,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:28<4:39:37,  3.86s/it]                                                       {'loss': 0.0712, 'grad_norm': 4.445169925689697, 'learning_rate': 3.678813559322034e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:28<4:39:37,  3.86s/it] 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:32<4:36:02,  3.82s/it]                                                       {'loss': 0.1182, 'grad_norm': 4.259868621826172, 'learning_rate': 3.677966101694915e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:32<4:36:02,  3.82s/it] 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:37:35<4:27:23,  3.70s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.5141429901123047, 'learning_rate': 3.677118644067797e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:37:35<4:27:23,  3.70s/it] 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:37:39<4:22:28,  3.63s/it]                                                       {'loss': 0.0217, 'grad_norm': 1.3515126705169678, 'learning_rate': 3.676271186440678e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:37:39<4:22:28,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:37:42<4:16:59,  3.56s/it]                                                       {'loss': 0.0304, 'grad_norm': 4.211606979370117, 'learning_rate': 3.675423728813559e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:37:42<4:16:59,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:37:46<4:14:18,  3.52s/it]                                                       {'loss': 0.0241, 'grad_norm': 2.106701135635376, 'learning_rate': 3.6745762711864404e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:37:46<4:14:18,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:37:49<4:10:33,  3.47s/it]                                                       {'loss': 0.0545, 'grad_norm': 2.408601760864258, 'learning_rate': 3.673728813559322e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:37:49<4:10:33,  3.47s/it] 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:37:53<4:15:07,  3.53s/it]                                                       {'loss': 0.0531, 'grad_norm': 3.796969413757324, 'learning_rate': 3.6728813559322034e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:37:53<4:15:07,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:37:57<4:21:11,  3.62s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.31525906920433044, 'learning_rate': 3.672033898305085e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:37:57<4:21:11,  3.62s/it] 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:38:00<4:15:33,  3.54s/it]                                                       {'loss': 0.0313, 'grad_norm': 3.048490285873413, 'learning_rate': 3.671186440677966e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:38:00<4:15:33,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:38:03<4:11:19,  3.48s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.26361826062202454, 'learning_rate': 3.6703389830508474e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:38:03<4:11:19,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:38:07<4:08:01,  3.44s/it]                                                       {'loss': 0.2403, 'grad_norm': 6.535060405731201, 'learning_rate': 3.6694915254237286e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:38:07<4:08:01,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:38:10<4:05:15,  3.40s/it]                                                       {'loss': 0.0563, 'grad_norm': 2.8884599208831787, 'learning_rate': 3.6686440677966104e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:38:10<4:05:15,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:38:13<4:07:36,  3.43s/it]                                                       {'loss': 0.0914, 'grad_norm': 4.787746906280518, 'learning_rate': 3.6677966101694915e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:38:13<4:07:36,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:38:17<4:06:13,  3.41s/it]                                                       {'loss': 0.0234, 'grad_norm': 1.6234089136123657, 'learning_rate': 3.666949152542373e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:38:17<4:06:13,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:38:20<4:05:52,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08328121155500412, 'learning_rate': 3.6661016949152544e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:38:20<4:05:52,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:24<4:06:09,  3.41s/it]                                                       {'loss': 0.0714, 'grad_norm': 2.979565382003784, 'learning_rate': 3.665254237288136e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:24<4:06:09,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:27<4:05:12,  3.40s/it]                                                       {'loss': 0.0208, 'grad_norm': 1.920271396636963, 'learning_rate': 3.6644067796610174e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:27<4:05:12,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:30<4:04:43,  3.40s/it]                                                       {'loss': 0.0561, 'grad_norm': 3.490100145339966, 'learning_rate': 3.6635593220338985e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:31<4:04:43,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:34<4:06:34,  3.42s/it]                                                       {'loss': 0.1052, 'grad_norm': 5.420573711395264, 'learning_rate': 3.6627118644067796e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:34<4:06:34,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:38:38<4:23:26,  3.66s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.5979272127151489, 'learning_rate': 3.661864406779661e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:38:38<4:23:26,  3.66s/it] 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:38:41<4:17:40,  3.58s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.243509292602539, 'learning_rate': 3.6610169491525426e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:38:41<4:17:40,  3.58s/it] 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:38:45<4:12:10,  3.50s/it]                                                       {'loss': 0.1121, 'grad_norm': 3.7801005840301514, 'learning_rate': 3.660169491525424e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:38:45<4:12:10,  3.50s/it] 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:38:48<4:08:53,  3.46s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.3177328407764435, 'learning_rate': 3.6593220338983055e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:38:48<4:08:53,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:38:52<4:07:01,  3.43s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.7652642726898193, 'learning_rate': 3.6584745762711866e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:38:52<4:07:01,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:38:55<4:08:41,  3.46s/it]                                                       {'loss': 0.0591, 'grad_norm': 3.9422051906585693, 'learning_rate': 3.657627118644068e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:38:55<4:08:41,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:38:58<4:07:28,  3.44s/it]                                                       {'loss': 0.0349, 'grad_norm': 2.5766780376434326, 'learning_rate': 3.656779661016949e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:38:58<4:07:28,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:39:02<4:05:35,  3.42s/it]                                                       {'loss': 0.007, 'grad_norm': 0.7840719223022461, 'learning_rate': 3.655932203389831e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:39:02<4:05:35,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:39:06<4:23:27,  3.67s/it]                                                       {'loss': 0.0766, 'grad_norm': 3.7792646884918213, 'learning_rate': 3.655084745762712e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:39:06<4:23:27,  3.67s/it] 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:39:10<4:20:09,  3.62s/it]                                                       {'loss': 0.1478, 'grad_norm': 4.229618549346924, 'learning_rate': 3.6542372881355936e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:39:10<4:20:09,  3.62s/it] 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:39:13<4:16:08,  3.56s/it]                                                       {'loss': 0.0943, 'grad_norm': 3.9026808738708496, 'learning_rate': 3.653389830508475e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:39:13<4:16:08,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:39:16<4:14:24,  3.54s/it]                                                       {'loss': 0.0807, 'grad_norm': 3.783820629119873, 'learning_rate': 3.6525423728813566e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:39:16<4:14:24,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:39:20<4:14:02,  3.54s/it]                                                       {'loss': 0.0467, 'grad_norm': 3.4901247024536133, 'learning_rate': 3.651694915254237e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:39:20<4:14:02,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:24<4:14:34,  3.55s/it]                                                       {'loss': 0.0289, 'grad_norm': 1.775653600692749, 'learning_rate': 3.650847457627119e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:24<4:14:34,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:27<4:19:04,  3.61s/it]                                                       {'loss': 0.1403, 'grad_norm': 5.216682434082031, 'learning_rate': 3.65e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:27<4:19:04,  3.61s/it] 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:31<4:13:45,  3.54s/it]                                                       {'loss': 0.0767, 'grad_norm': 3.763436794281006, 'learning_rate': 3.649152542372882e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:31<4:13:45,  3.54s/it] 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:34<4:12:59,  3.53s/it]                                                       {'loss': 0.0101, 'grad_norm': 0.9838978052139282, 'learning_rate': 3.648305084745763e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:34<4:12:59,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:39:38<4:08:33,  3.47s/it]                                                       {'loss': 0.1114, 'grad_norm': 3.0822982788085938, 'learning_rate': 3.647457627118645e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:39:38<4:08:33,  3.47s/it] 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:39:41<4:07:37,  3.45s/it]                                                       {'loss': 0.0948, 'grad_norm': 3.1556079387664795, 'learning_rate': 3.646610169491526e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:39:41<4:07:37,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:39:45<4:11:28,  3.51s/it]                                                       {'loss': 0.2094, 'grad_norm': 5.635988235473633, 'learning_rate': 3.645762711864407e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:39:45<4:11:28,  3.51s/it] 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:39:48<4:07:52,  3.46s/it]                                                       {'loss': 0.0887, 'grad_norm': 6.136373519897461, 'learning_rate': 3.644915254237288e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:39:48<4:07:52,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:39:51<4:05:57,  3.43s/it]                                                       {'loss': 0.0584, 'grad_norm': 2.4780220985412598, 'learning_rate': 3.644067796610169e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:39:51<4:05:57,  3.43s/it][2025-10-21 03:04:14,040] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:39:57<4:51:26,  4.07s/it]                                                       {'loss': 0.2195, 'grad_norm': 5.194521427154541, 'learning_rate': 3.643220338983051e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:39:57<4:51:26,  4.07s/it] 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:40:00<4:35:46,  3.85s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.24436071515083313, 'learning_rate': 3.642372881355932e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:40:00<4:35:46,  3.85s/it] 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:40:04<4:26:25,  3.72s/it]                                                       {'loss': 0.264, 'grad_norm': 5.060210704803467, 'learning_rate': 3.641525423728814e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:40:04<4:26:25,  3.72s/it] 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:40:07<4:18:44,  3.61s/it]                                                       {'loss': 0.4153, 'grad_norm': 5.231616497039795, 'learning_rate': 3.640677966101695e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:40:07<4:18:44,  3.61s/it] 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:40:10<4:11:38,  3.52s/it]                                                       {'loss': 0.0519, 'grad_norm': 2.1125924587249756, 'learning_rate': 3.639830508474576e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:40:10<4:11:38,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:40:14<4:07:55,  3.46s/it]                                                       {'loss': 0.0198, 'grad_norm': 2.312230110168457, 'learning_rate': 3.638983050847457e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:40:14<4:07:55,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:40:17<4:06:36,  3.45s/it]                                                       {'loss': 0.072, 'grad_norm': 4.580474376678467, 'learning_rate': 3.638135593220339e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:40:17<4:06:36,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:40:20<4:06:25,  3.44s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.3792019486427307, 'learning_rate': 3.63728813559322e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:40:20<4:06:25,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:24<4:03:17,  3.40s/it]                                                       {'loss': 0.0568, 'grad_norm': 2.9608068466186523, 'learning_rate': 3.636440677966102e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:24<4:03:17,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:27<4:04:38,  3.42s/it]                                                       {'loss': 0.0834, 'grad_norm': 4.458662033081055, 'learning_rate': 3.635593220338983e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:27<4:04:38,  3.42s/it] 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:31<4:05:02,  3.43s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.6411829590797424, 'learning_rate': 3.634745762711865e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:31<4:05:02,  3.43s/it] 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:34<4:03:40,  3.41s/it]                                                       {'loss': 0.0197, 'grad_norm': 0.7958186864852905, 'learning_rate': 3.633898305084746e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:34<4:03:40,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:40:37<4:01:40,  3.38s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.8905124068260193, 'learning_rate': 3.633050847457627e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:40:37<4:01:40,  3.38s/it] 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:40:41<4:10:21,  3.50s/it]                                                       {'loss': 0.0148, 'grad_norm': 0.8123559951782227, 'learning_rate': 3.6322033898305084e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:40:41<4:10:21,  3.50s/it] 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:40:45<4:08:40,  3.48s/it]                                                       {'loss': 0.0234, 'grad_norm': 1.456270456314087, 'learning_rate': 3.63135593220339e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:40:45<4:08:40,  3.48s/it] 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:40:48<4:06:29,  3.45s/it]                                                       {'loss': 0.0727, 'grad_norm': 3.8680269718170166, 'learning_rate': 3.630508474576271e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:40:48<4:06:29,  3.45s/it] 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:40:51<4:03:51,  3.42s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.06847045570611954, 'learning_rate': 3.629661016949153e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:40:51<4:03:51,  3.42s/it] 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:40:55<4:02:01,  3.39s/it]                                                       {'loss': 0.0681, 'grad_norm': 1.422483205795288, 'learning_rate': 3.628813559322034e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:40:55<4:02:01,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:40:58<4:01:34,  3.39s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.19819989800453186, 'learning_rate': 3.6279661016949154e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:40:58<4:01:34,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:41:01<3:59:52,  3.36s/it]                                                       {'loss': 0.0282, 'grad_norm': 2.3122284412384033, 'learning_rate': 3.6271186440677965e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:41:01<3:59:52,  3.36s/it] 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:41:05<4:01:56,  3.39s/it]                                                       {'loss': 0.0495, 'grad_norm': 4.157266139984131, 'learning_rate': 3.6262711864406777e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:41:05<4:01:56,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:41:08<4:03:04,  3.41s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.3314518630504608, 'learning_rate': 3.6254237288135595e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:41:08<4:03:04,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:41:12<4:03:25,  3.41s/it]                                                       {'loss': 0.0237, 'grad_norm': 1.705843210220337, 'learning_rate': 3.6245762711864406e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:41:12<4:03:25,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:41:15<4:05:57,  3.45s/it]                                                       {'loss': 0.0962, 'grad_norm': 2.247411012649536, 'learning_rate': 3.6237288135593224e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:41:15<4:05:57,  3.45s/it] 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:41:19<4:04:24,  3.43s/it]                                                       {'loss': 0.1536, 'grad_norm': 4.979860782623291, 'learning_rate': 3.6228813559322035e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:41:19<4:04:24,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:22<4:03:50,  3.42s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.553902804851532, 'learning_rate': 3.622033898305085e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:22<4:03:50,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:25<4:02:38,  3.41s/it]                                                       {'loss': 0.0357, 'grad_norm': 2.369520664215088, 'learning_rate': 3.621186440677966e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:25<4:02:38,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:29<4:01:46,  3.40s/it]                                                       {'loss': 0.0284, 'grad_norm': 2.2532567977905273, 'learning_rate': 3.6203389830508476e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:29<4:01:46,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:32<4:01:47,  3.40s/it]                                                       {'loss': 0.0902, 'grad_norm': 3.7783029079437256, 'learning_rate': 3.619491525423729e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:32<4:01:47,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:41:36<4:02:29,  3.41s/it]                                                       {'loss': 0.016, 'grad_norm': 0.776006281375885, 'learning_rate': 3.6186440677966105e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:41:36<4:02:29,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:41:39<4:01:34,  3.40s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.3729774057865143, 'learning_rate': 3.6177966101694916e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:41:39<4:01:34,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:41:42<4:02:57,  3.42s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.5616310238838196, 'learning_rate': 3.6169491525423735e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:41:42<4:02:57,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:41:46<4:09:49,  3.51s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.2008342742919922, 'learning_rate': 3.6161016949152546e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:41:46<4:09:49,  3.51s/it] 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:41:49<4:05:53,  3.46s/it]                                                       {'loss': 0.1105, 'grad_norm': 5.254478454589844, 'learning_rate': 3.615254237288136e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:41:49<4:05:53,  3.46s/it] 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:41:53<4:06:32,  3.47s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.18365928530693054, 'learning_rate': 3.614406779661017e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:41:53<4:06:32,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:41:56<4:06:41,  3.47s/it]                                                       {'loss': 0.008, 'grad_norm': 0.5390047430992126, 'learning_rate': 3.6135593220338986e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:41:56<4:06:41,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:42:00<4:06:19,  3.47s/it]                                                       {'loss': 0.0522, 'grad_norm': 3.471677541732788, 'learning_rate': 3.61271186440678e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:42:00<4:06:19,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:42:03<4:06:34,  3.47s/it]                                                       {'loss': 0.0181, 'grad_norm': 1.5465965270996094, 'learning_rate': 3.6118644067796616e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:42:03<4:06:34,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:42:07<4:14:08,  3.58s/it]                                                       {'loss': 0.1936, 'grad_norm': 5.296456813812256, 'learning_rate': 3.611016949152543e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:42:07<4:14:08,  3.58s/it] 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:42:11<4:18:35,  3.64s/it]                                                       {'loss': 0.0728, 'grad_norm': 4.848855018615723, 'learning_rate': 3.610169491525424e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:42:11<4:18:35,  3.64s/it] 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:42:14<4:12:34,  3.56s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.4054965674877167, 'learning_rate': 3.609322033898305e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:42:14<4:12:34,  3.56s/it] 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:42:18<4:08:33,  3.50s/it]                                                       {'loss': 0.1838, 'grad_norm': 4.6881208419799805, 'learning_rate': 3.608474576271186e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:42:18<4:08:33,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:21<4:06:40,  3.48s/it]                                                       {'loss': 0.2549, 'grad_norm': 7.616901397705078, 'learning_rate': 3.607627118644068e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:21<4:06:40,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:25<4:06:03,  3.47s/it]                                                       {'loss': 0.0178, 'grad_norm': 2.0557875633239746, 'learning_rate': 3.606779661016949e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:25<4:06:03,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:28<4:03:59,  3.44s/it]                                                       {'loss': 0.0253, 'grad_norm': 1.3404675722122192, 'learning_rate': 3.605932203389831e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:28<4:03:59,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:31<4:00:55,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.03995642066001892, 'learning_rate': 3.605084745762712e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:31<4:00:55,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:42:35<4:00:09,  3.39s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.9608548283576965, 'learning_rate': 3.604237288135594e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:42:35<4:00:09,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:42:38<3:59:46,  3.38s/it]                                                       {'loss': 0.0831, 'grad_norm': 4.213165283203125, 'learning_rate': 3.603389830508475e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:42:38<3:59:46,  3.38s/it] 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:42:41<4:01:42,  3.41s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.14326588809490204, 'learning_rate': 3.602542372881356e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:42:41<4:01:42,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:42:45<4:11:03,  3.54s/it]                                                       {'loss': 0.0249, 'grad_norm': 1.9286092519760132, 'learning_rate': 3.601694915254237e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:42:45<4:11:03,  3.54s/it][2025-10-21 03:07:08,053] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:42:51<4:59:22,  4.23s/it]                                                       {'loss': 0.0133, 'grad_norm': 1.6369540691375732, 'learning_rate': 3.600847457627119e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:42:51<4:59:22,  4.23s/it] 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:42:55<4:42:55,  4.00s/it]                                                       {'loss': 0.0984, 'grad_norm': 4.874996662139893, 'learning_rate': 3.6e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:42:55<4:42:55,  4.00s/it] 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:42:58<4:29:46,  3.81s/it]                                                       {'loss': 0.002, 'grad_norm': 0.22838503122329712, 'learning_rate': 3.599152542372882e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:42:58<4:29:46,  3.81s/it] 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:43:01<4:20:09,  3.68s/it]                                                       {'loss': 0.0588, 'grad_norm': 3.673407554626465, 'learning_rate': 3.598305084745763e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:43:01<4:20:09,  3.68s/it] 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:43:05<4:20:34,  3.68s/it]                                                       {'loss': 0.0141, 'grad_norm': 1.7306129932403564, 'learning_rate': 3.597457627118644e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:43:05<4:20:34,  3.68s/it] 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:43:08<4:14:59,  3.60s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.2538086771965027, 'learning_rate': 3.596610169491525e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:43:08<4:14:59,  3.60s/it] 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:43:12<4:09:09,  3.52s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.0116822998970747, 'learning_rate': 3.595762711864407e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:43:12<4:09:09,  3.52s/it] 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:43:15<4:06:21,  3.48s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.3663228452205658, 'learning_rate': 3.594915254237288e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:43:15<4:06:21,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:43:19<4:05:42,  3.48s/it]                                                       {'loss': 0.1221, 'grad_norm': 5.641663074493408, 'learning_rate': 3.59406779661017e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:43:19<4:05:42,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:43:22<4:04:09,  3.45s/it]                                                       {'loss': 0.1475, 'grad_norm': 6.712000370025635, 'learning_rate': 3.593220338983051e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:43:22<4:04:09,  3.45s/it] 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:25<4:02:12,  3.43s/it]                                                       {'loss': 0.048, 'grad_norm': 2.8479721546173096, 'learning_rate': 3.592372881355933e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:25<4:02:12,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:29<4:14:13,  3.60s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.38151541352272034, 'learning_rate': 3.5915254237288134e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:29<4:14:13,  3.60s/it] 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:33<4:10:11,  3.54s/it]                                                       {'loss': 0.1196, 'grad_norm': 4.3845062255859375, 'learning_rate': 3.5906779661016945e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:33<4:10:11,  3.54s/it] 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:43:37<4:27:05,  3.78s/it]                                                       {'loss': 0.2794, 'grad_norm': 7.582086563110352, 'learning_rate': 3.5898305084745763e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:43:37<4:27:05,  3.78s/it] 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:43:42<4:41:55,  3.99s/it]                                                       {'loss': 0.1012, 'grad_norm': 5.2700018882751465, 'learning_rate': 3.5889830508474575e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:43:42<4:41:55,  3.99s/it] 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:43:45<4:29:29,  3.82s/it]                                                       {'loss': 0.0479, 'grad_norm': 2.3094077110290527, 'learning_rate': 3.588135593220339e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:43:45<4:29:29,  3.82s/it] 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:43:49<4:23:49,  3.74s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.021808000281453133, 'learning_rate': 3.5872881355932204e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:43:49<4:23:49,  3.74s/it] 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:43:53<4:32:47,  3.87s/it]                                                       {'loss': 0.0361, 'grad_norm': 2.0846049785614014, 'learning_rate': 3.586440677966102e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:43:53<4:32:47,  3.87s/it] 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:43:56<4:21:24,  3.71s/it]                                                       {'loss': 0.0086, 'grad_norm': 0.7250835299491882, 'learning_rate': 3.5855932203389833e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:43:56<4:21:24,  3.71s/it] 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:44:00<4:17:50,  3.66s/it]                                                       {'loss': 0.0884, 'grad_norm': 4.056258201599121, 'learning_rate': 3.5847457627118645e-05, 'epoch': 0.29}
 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:44:00<4:17:50,  3.66s/it] 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:44:03<4:21:04,  3.70s/it]                                                       {'loss': 0.018, 'grad_norm': 1.1998051404953003, 'learning_rate': 3.5838983050847456e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:44:03<4:21:04,  3.70s/it] 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:44:07<4:12:49,  3.59s/it]                                                       {'loss': 0.2186, 'grad_norm': 5.8935227394104, 'learning_rate': 3.5830508474576274e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:44:07<4:12:49,  3.59s/it] 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:44:10<4:06:06,  3.49s/it]                                                       {'loss': 0.0657, 'grad_norm': 3.010321617126465, 'learning_rate': 3.5822033898305085e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:44:10<4:06:06,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:44:13<4:03:34,  3.46s/it]                                                       {'loss': 0.0324, 'grad_norm': 2.2996175289154053, 'learning_rate': 3.5813559322033903e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:44:13<4:03:34,  3.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:44:17<4:04:56,  3.48s/it]                                                       {'loss': 0.107, 'grad_norm': 5.31518030166626, 'learning_rate': 3.5805084745762715e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:44:17<4:04:56,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:44:20<4:03:05,  3.45s/it]                                                       {'loss': 0.1404, 'grad_norm': 16.26443862915039, 'learning_rate': 3.5796610169491526e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:44:20<4:03:05,  3.45s/it] 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:24<4:05:23,  3.49s/it]                                                       {'loss': 0.0351, 'grad_norm': 1.5501129627227783, 'learning_rate': 3.578813559322034e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:24<4:05:23,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:27<4:07:39,  3.52s/it]                                                       {'loss': 0.0799, 'grad_norm': 4.358710289001465, 'learning_rate': 3.5779661016949155e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:28<4:07:39,  3.52s/it] 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:31<4:04:10,  3.47s/it]                                                       {'loss': 0.0446, 'grad_norm': 2.078174114227295, 'learning_rate': 3.577118644067797e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:31<4:04:10,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:44:34<4:03:22,  3.46s/it]                                                       {'loss': 0.0118, 'grad_norm': 0.8321550488471985, 'learning_rate': 3.5762711864406785e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:44:34<4:03:22,  3.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:44:38<4:03:42,  3.47s/it]                                                       {'loss': 0.0098, 'grad_norm': 0.7894261479377747, 'learning_rate': 3.5754237288135596e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:44:38<4:03:42,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:44:41<4:04:23,  3.48s/it]                                                       {'loss': 0.0278, 'grad_norm': 0.9854675531387329, 'learning_rate': 3.5745762711864414e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:44:41<4:04:23,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:44:45<4:02:02,  3.44s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.7003322243690491, 'learning_rate': 3.5737288135593225e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:44:45<4:02:02,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:44:48<4:02:11,  3.45s/it]                                                       {'loss': 0.002, 'grad_norm': 0.16461284458637238, 'learning_rate': 3.572881355932203e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:44:48<4:02:11,  3.45s/it] 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:44:52<4:01:23,  3.44s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.05695129185914993, 'learning_rate': 3.572033898305085e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:44:52<4:01:23,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:44:55<4:07:48,  3.53s/it]                                                       {'loss': 0.0291, 'grad_norm': 2.106112480163574, 'learning_rate': 3.571186440677966e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:44:55<4:07:48,  3.53s/it] 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:44:59<4:05:21,  3.49s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.15440452098846436, 'learning_rate': 3.570338983050848e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:44:59<4:05:21,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:45:02<4:03:18,  3.47s/it]                                                       {'loss': 0.052, 'grad_norm': 3.817103385925293, 'learning_rate': 3.569491525423729e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:45:02<4:03:18,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:45:05<4:00:52,  3.43s/it]                                                       {'loss': 0.0681, 'grad_norm': 3.676196336746216, 'learning_rate': 3.5686440677966107e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:45:05<4:00:52,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:45:09<4:00:03,  3.42s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.3782665729522705, 'learning_rate': 3.567796610169492e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:45:09<4:00:03,  3.42s/it] 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:45:12<3:59:09,  3.41s/it]                                                       {'loss': 0.0273, 'grad_norm': 1.7743898630142212, 'learning_rate': 3.566949152542373e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:45:12<3:59:09,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:45:16<4:00:43,  3.43s/it]                                                       {'loss': 0.1115, 'grad_norm': 3.461027145385742, 'learning_rate': 3.566101694915254e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:45:16<4:00:43,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:45:19<4:00:01,  3.42s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.32135048508644104, 'learning_rate': 3.565254237288136e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:45:19<4:00:01,  3.42s/it] 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:22<3:57:14,  3.38s/it]                                                       {'loss': 0.0601, 'grad_norm': 3.8642940521240234, 'learning_rate': 3.564406779661017e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:22<3:57:14,  3.38s/it] 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:26<3:57:18,  3.39s/it]                                                       {'loss': 0.1433, 'grad_norm': 4.0870747566223145, 'learning_rate': 3.563559322033899e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:26<3:57:18,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:29<3:59:12,  3.41s/it]                                                       {'loss': 0.007, 'grad_norm': 1.526511311531067, 'learning_rate': 3.56271186440678e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:29<3:59:12,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:33<3:57:38,  3.39s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.0112476348876953, 'learning_rate': 3.561864406779661e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:33<3:57:38,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:45:36<3:55:57,  3.37s/it]                                                       {'loss': 0.0265, 'grad_norm': 1.8787068128585815, 'learning_rate': 3.561016949152542e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:45:36<3:55:57,  3.37s/it] 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:45:39<3:55:21,  3.36s/it]                                                       {'loss': 0.0462, 'grad_norm': 1.9143389463424683, 'learning_rate': 3.560169491525424e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:45:39<3:55:21,  3.36s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:45:43<4:09:01,  3.56s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.1919853389263153, 'learning_rate': 3.559322033898305e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:45:43<4:09:01,  3.56s/it][2025-10-21 03:10:06,005] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:45:49<4:50:36,  4.15s/it]                                                       {'loss': 0.126, 'grad_norm': 5.938960075378418, 'learning_rate': 3.558474576271187e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:45:49<4:50:36,  4.15s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:45:52<4:34:22,  3.92s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.03643849492073059, 'learning_rate': 3.557627118644068e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:45:52<4:34:22,  3.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:45:56<4:22:48,  3.76s/it]                                                       {'loss': 0.0628, 'grad_norm': 3.455986738204956, 'learning_rate': 3.55677966101695e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:45:56<4:22:48,  3.76s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:45:59<4:15:28,  3.65s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.07551608979701996, 'learning_rate': 3.555932203389831e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:45:59<4:15:28,  3.65s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:46:02<4:09:38,  3.57s/it]                                                       {'loss': 0.0869, 'grad_norm': 3.3529443740844727, 'learning_rate': 3.555084745762712e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:46:02<4:09:38,  3.57s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:46:06<4:04:06,  3.49s/it]                                                       {'loss': 0.1551, 'grad_norm': 4.800084114074707, 'learning_rate': 3.554237288135593e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:46:06<4:04:06,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:46:09<4:02:39,  3.47s/it]                                                       {'loss': 0.2116, 'grad_norm': 5.411804676055908, 'learning_rate': 3.5533898305084744e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:46:09<4:02:39,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:46:12<4:01:17,  3.45s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.27703213691711426, 'learning_rate': 3.552542372881356e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:46:12<4:01:17,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:46:16<4:01:22,  3.46s/it]                                                       {'loss': 0.1759, 'grad_norm': 3.5370724201202393, 'learning_rate': 3.551694915254237e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:46:16<4:01:22,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:46:20<4:07:12,  3.54s/it]                                                       {'loss': 0.0997, 'grad_norm': 3.863325357437134, 'learning_rate': 3.550847457627119e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:46:20<4:07:12,  3.54s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:23<4:03:41,  3.49s/it]                                                       {'loss': 0.1199, 'grad_norm': 5.883844375610352, 'learning_rate': 3.55e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:23<4:03:41,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:26<4:02:15,  3.47s/it]                                                       {'loss': 0.1278, 'grad_norm': 4.0694475173950195, 'learning_rate': 3.5491525423728814e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:26<4:02:15,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:30<4:00:41,  3.45s/it]                                                       {'loss': 0.056, 'grad_norm': 2.457993745803833, 'learning_rate': 3.5483050847457625e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:30<4:00:41,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:46:33<4:02:20,  3.47s/it]                                                       {'loss': 0.0274, 'grad_norm': 2.0517959594726562, 'learning_rate': 3.547457627118644e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:46:33<4:02:20,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:46:37<4:01:10,  3.46s/it]                                                       {'loss': 0.0112, 'grad_norm': 0.8757163882255554, 'learning_rate': 3.5466101694915254e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:46:37<4:01:10,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:46:40<4:01:29,  3.46s/it]                                                       {'loss': 0.2315, 'grad_norm': 5.611141204833984, 'learning_rate': 3.545762711864407e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:46:40<4:01:29,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:46:44<4:00:53,  3.46s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.25573524832725525, 'learning_rate': 3.5449152542372884e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:46:44<4:00:53,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:46:47<3:59:49,  3.44s/it]                                                       {'loss': 0.042, 'grad_norm': 2.7614293098449707, 'learning_rate': 3.54406779661017e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:46:47<3:59:49,  3.44s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:46:51<4:06:08,  3.53s/it]                                                       {'loss': 0.2226, 'grad_norm': 3.9321484565734863, 'learning_rate': 3.5432203389830506e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:46:51<4:06:08,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:46:54<4:04:37,  3.51s/it]                                                       {'loss': 0.06, 'grad_norm': 1.3895310163497925, 'learning_rate': 3.5423728813559324e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:46:54<4:04:37,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:46:58<4:01:50,  3.47s/it]                                                       {'loss': 0.1504, 'grad_norm': 4.196229457855225, 'learning_rate': 3.5415254237288135e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:46:58<4:01:50,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:47:01<4:02:48,  3.49s/it]                                                       {'loss': 0.0798, 'grad_norm': 3.869711399078369, 'learning_rate': 3.5406779661016954e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:47:01<4:02:48,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:47:05<4:02:50,  3.49s/it]                                                       {'loss': 0.0383, 'grad_norm': 1.6348323822021484, 'learning_rate': 3.5398305084745765e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:47:05<4:02:50,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:47:08<4:01:40,  3.47s/it]                                                       {'loss': 0.1076, 'grad_norm': 4.370575428009033, 'learning_rate': 3.538983050847458e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:47:08<4:01:40,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:47:12<4:04:39,  3.52s/it]                                                       {'loss': 0.045, 'grad_norm': 1.119239330291748, 'learning_rate': 3.5381355932203394e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:47:12<4:04:39,  3.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:47:15<4:04:49,  3.52s/it]                                                       {'loss': 0.0311, 'grad_norm': 2.2237279415130615, 'learning_rate': 3.5372881355932205e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:47:15<4:04:49,  3.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:47:19<4:07:02,  3.55s/it]                                                       {'loss': 0.0639, 'grad_norm': 3.627169370651245, 'learning_rate': 3.536440677966102e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:47:19<4:07:02,  3.55s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:22<4:02:42,  3.49s/it]                                                       {'loss': 0.0993, 'grad_norm': 3.8360214233398438, 'learning_rate': 3.535593220338983e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:22<4:02:42,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:26<4:01:23,  3.47s/it]                                                       {'loss': 0.0316, 'grad_norm': 1.4607230424880981, 'learning_rate': 3.5347457627118646e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:26<4:01:23,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:30<4:09:50,  3.59s/it]                                                       {'loss': 0.0362, 'grad_norm': 2.388653516769409, 'learning_rate': 3.533898305084746e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:30<4:09:50,  3.59s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:33<4:05:46,  3.54s/it]                                                       {'loss': 0.0502, 'grad_norm': 3.0085947513580322, 'learning_rate': 3.5330508474576275e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:33<4:05:46,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:47:37<4:05:14,  3.53s/it]                                                       {'loss': 0.033, 'grad_norm': 2.6196138858795166, 'learning_rate': 3.532203389830509e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:47:37<4:05:14,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:47:40<4:02:16,  3.49s/it]                                                       {'loss': 0.0387, 'grad_norm': 1.7350959777832031, 'learning_rate': 3.53135593220339e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:47:40<4:02:16,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:47:43<3:58:53,  3.44s/it]                                                       {'loss': 0.0134, 'grad_norm': 0.5076104998588562, 'learning_rate': 3.530508474576271e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:47:43<3:58:53,  3.44s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:47:47<3:57:21,  3.42s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.23655229806900024, 'learning_rate': 3.529661016949153e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:47:47<3:57:21,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:47:50<3:59:59,  3.46s/it]                                                       {'loss': 0.0177, 'grad_norm': 1.1021718978881836, 'learning_rate': 3.528813559322034e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:47:50<3:59:59,  3.46s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:47:54<4:01:33,  3.48s/it]                                                       {'loss': 0.0112, 'grad_norm': 0.5915476679801941, 'learning_rate': 3.527966101694916e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:47:54<4:01:33,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:47:57<4:01:26,  3.48s/it]                                                       {'loss': 0.0102, 'grad_norm': 0.8205194473266602, 'learning_rate': 3.527118644067797e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:47:57<4:01:26,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:48:01<4:00:30,  3.47s/it]                                                       {'loss': 0.0127, 'grad_norm': 0.5830914378166199, 'learning_rate': 3.5262711864406786e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:48:01<4:00:30,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:48:04<4:08:31,  3.58s/it]                                                       {'loss': 0.0108, 'grad_norm': 0.9581097364425659, 'learning_rate': 3.52542372881356e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:48:04<4:08:31,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:48:08<4:04:13,  3.52s/it]                                                       {'loss': 0.3085, 'grad_norm': 5.581775188446045, 'learning_rate': 3.524576271186441e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:48:08<4:04:13,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:48:11<4:01:27,  3.48s/it]                                                       {'loss': 0.0299, 'grad_norm': 0.7352936267852783, 'learning_rate': 3.523728813559322e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:48:11<4:01:27,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:48:15<3:59:32,  3.46s/it]                                                       {'loss': 0.0177, 'grad_norm': 0.9483129382133484, 'learning_rate': 3.522881355932204e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:48:15<3:59:32,  3.46s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:48:18<3:57:12,  3.42s/it]                                                       {'loss': 0.0245, 'grad_norm': 1.6809494495391846, 'learning_rate': 3.522033898305085e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:48:18<3:57:12,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:22<4:03:13,  3.51s/it]                                                       {'loss': 0.0625, 'grad_norm': 1.1319390535354614, 'learning_rate': 3.521186440677967e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:22<4:03:13,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:25<4:08:35,  3.59s/it]                                                       {'loss': 0.1187, 'grad_norm': 3.5829291343688965, 'learning_rate': 3.520338983050848e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:25<4:08:35,  3.59s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:29<4:03:39,  3.52s/it]                                                       {'loss': 0.1762, 'grad_norm': 4.213310241699219, 'learning_rate': 3.519491525423729e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:29<4:03:39,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:32<4:01:30,  3.49s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.2819453477859497, 'learning_rate': 3.51864406779661e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:32<4:01:30,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:48:36<4:01:56,  3.50s/it]                                                       {'loss': 0.0813, 'grad_norm': 2.7858035564422607, 'learning_rate': 3.517796610169491e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:48:36<4:01:56,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:48:40<4:17:41,  3.73s/it]                                                       {'loss': 0.0777, 'grad_norm': 3.1665210723876953, 'learning_rate': 3.516949152542373e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:48:40<4:17:41,  3.73s/it][2025-10-21 03:13:02,791] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:48:46<4:59:49,  4.34s/it]                                                       {'loss': 0.1167, 'grad_norm': 3.779728412628174, 'learning_rate': 3.516101694915254e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:48:46<4:59:49,  4.34s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:48:49<4:40:05,  4.05s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.29551807045936584, 'learning_rate': 3.515254237288136e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:48:49<4:40:05,  4.05s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:48:53<4:24:39,  3.83s/it]                                                       {'loss': 0.1206, 'grad_norm': 3.0893683433532715, 'learning_rate': 3.514406779661017e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:48:53<4:24:39,  3.83s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:48:56<4:15:44,  3.70s/it]                                                       {'loss': 0.271, 'grad_norm': 4.934769630432129, 'learning_rate': 3.513559322033899e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:48:56<4:15:44,  3.70s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:48:59<4:08:26,  3.60s/it]                                                       {'loss': 0.0104, 'grad_norm': 0.5915533304214478, 'learning_rate': 3.5127118644067794e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:48:59<4:08:26,  3.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:49:03<4:05:59,  3.56s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.6510444283485413, 'learning_rate': 3.511864406779661e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:49:03<4:05:59,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:49:07<4:23:44,  3.82s/it]                                                       {'loss': 0.0878, 'grad_norm': 4.127364158630371, 'learning_rate': 3.511016949152542e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:49:07<4:23:44,  3.82s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:49:10<4:12:18,  3.65s/it]                                                       {'loss': 0.0141, 'grad_norm': 0.7773633003234863, 'learning_rate': 3.510169491525424e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:49:10<4:12:18,  3.65s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:49:14<4:16:35,  3.72s/it]                                                       {'loss': 0.009, 'grad_norm': 0.6005299091339111, 'learning_rate': 3.509322033898305e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:49:14<4:16:35,  3.72s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:49:18<4:10:57,  3.64s/it]                                                       {'loss': 0.0517, 'grad_norm': 2.489006996154785, 'learning_rate': 3.508474576271187e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:49:18<4:10:57,  3.64s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:49:21<4:06:56,  3.58s/it]                                                       {'loss': 0.0383, 'grad_norm': 3.151163101196289, 'learning_rate': 3.507627118644068e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:49:21<4:06:56,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:25<4:17:46,  3.74s/it]                                                       {'loss': 0.036, 'grad_norm': 2.209505319595337, 'learning_rate': 3.506779661016949e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:25<4:17:46,  3.74s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:29<4:10:34,  3.63s/it]                                                       {'loss': 0.007, 'grad_norm': 0.6152774095535278, 'learning_rate': 3.5059322033898304e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:29<4:10:34,  3.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:32<4:06:03,  3.57s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.5855973958969116, 'learning_rate': 3.505084745762712e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:32<4:06:03,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:49:35<4:01:17,  3.50s/it]                                                       {'loss': 0.2493, 'grad_norm': 2.870748996734619, 'learning_rate': 3.5042372881355934e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:49:35<4:01:17,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:49:39<4:02:41,  3.52s/it]                                                       {'loss': 0.0131, 'grad_norm': 1.0073754787445068, 'learning_rate': 3.5033898305084745e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:49:39<4:02:41,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:49:43<4:08:44,  3.61s/it]                                                       {'loss': 0.0216, 'grad_norm': 2.0223512649536133, 'learning_rate': 3.502542372881356e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:49:43<4:08:44,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:49:46<4:04:08,  3.55s/it]                                                       {'loss': 0.0343, 'grad_norm': 1.9489867687225342, 'learning_rate': 3.5016949152542374e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:49:46<4:04:08,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:49:50<4:02:40,  3.52s/it]                                                       {'loss': 0.026, 'grad_norm': 0.9770144820213318, 'learning_rate': 3.5008474576271186e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:49:50<4:02:40,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:49:53<4:00:01,  3.49s/it]                                                       {'loss': 0.0351, 'grad_norm': 2.7819979190826416, 'learning_rate': 3.5e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:49:53<4:00:01,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:49:57<3:58:38,  3.47s/it]                                                       {'loss': 0.1661, 'grad_norm': 5.400822162628174, 'learning_rate': 3.4991525423728815e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:49:57<3:58:38,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:50:00<4:06:13,  3.58s/it]                                                       {'loss': 0.0729, 'grad_norm': 2.298402786254883, 'learning_rate': 3.4983050847457626e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:50:00<4:06:13,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:50:04<4:06:12,  3.58s/it]                                                       {'loss': 0.1056, 'grad_norm': 5.5704569816589355, 'learning_rate': 3.4974576271186444e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:50:04<4:06:12,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:50:07<4:04:19,  3.55s/it]                                                       {'loss': 0.1444, 'grad_norm': 4.43125057220459, 'learning_rate': 3.4966101694915256e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:50:07<4:04:19,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:50:11<4:00:38,  3.50s/it]                                                       {'loss': 0.013, 'grad_norm': 0.6791166067123413, 'learning_rate': 3.4957627118644074e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:50:11<4:00:38,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:50:15<4:07:53,  3.61s/it]                                                       {'loss': 0.0595, 'grad_norm': 1.4512616395950317, 'learning_rate': 3.4949152542372885e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:50:15<4:07:53,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:50:18<4:05:49,  3.58s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.5666977167129517, 'learning_rate': 3.4940677966101696e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:50:18<4:05:49,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:50:21<4:00:28,  3.50s/it]                                                       {'loss': 0.0175, 'grad_norm': 1.1951587200164795, 'learning_rate': 3.493220338983051e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:50:22<4:00:28,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:25<3:59:21,  3.48s/it]                                                       {'loss': 0.0643, 'grad_norm': 2.850031614303589, 'learning_rate': 3.4923728813559326e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:25<3:59:21,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:29<4:01:11,  3.51s/it]                                                       {'loss': 0.007, 'grad_norm': 0.5760993957519531, 'learning_rate': 3.491525423728814e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:29<4:01:11,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:32<3:58:27,  3.47s/it]                                                       {'loss': 0.0453, 'grad_norm': 2.4190309047698975, 'learning_rate': 3.4906779661016955e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:32<3:58:27,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:50:35<3:56:30,  3.45s/it]                                                       {'loss': 0.0335, 'grad_norm': 1.9230384826660156, 'learning_rate': 3.4898305084745766e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:50:35<3:56:30,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:50:39<3:55:45,  3.44s/it]                                                       {'loss': 0.0144, 'grad_norm': 1.0615788698196411, 'learning_rate': 3.488983050847458e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:50:39<3:55:45,  3.44s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:50:42<3:56:23,  3.45s/it]                                                       {'loss': 0.0755, 'grad_norm': 5.248951435089111, 'learning_rate': 3.488135593220339e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:50:42<3:56:23,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:50:46<4:03:38,  3.55s/it]                                                       {'loss': 0.0233, 'grad_norm': 1.7995294332504272, 'learning_rate': 3.487288135593221e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:50:46<4:03:38,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:50:49<3:59:47,  3.50s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.40327054262161255, 'learning_rate': 3.486440677966102e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:50:49<3:59:47,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:50:53<3:58:29,  3.48s/it]                                                       {'loss': 0.0666, 'grad_norm': 2.034167528152466, 'learning_rate': 3.485593220338983e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:50:53<3:58:29,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:50:56<3:57:59,  3.47s/it]                                                       {'loss': 0.0186, 'grad_norm': 1.3967036008834839, 'learning_rate': 3.484745762711865e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:50:56<3:57:59,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:51:00<4:04:46,  3.57s/it]                                                       {'loss': 0.0863, 'grad_norm': 2.9052906036376953, 'learning_rate': 3.483898305084746e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:51:00<4:04:46,  3.57s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:51:04<4:02:54,  3.55s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.5000654458999634, 'learning_rate': 3.483050847457627e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:51:04<4:02:54,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:51:07<4:02:13,  3.54s/it]                                                       {'loss': 0.0221, 'grad_norm': 1.346800684928894, 'learning_rate': 3.482203389830508e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:51:07<4:02:13,  3.54s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:51:10<3:59:13,  3.49s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.4427998661994934, 'learning_rate': 3.48135593220339e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:51:10<3:59:13,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:51:14<3:56:22,  3.45s/it]                                                       {'loss': 0.0149, 'grad_norm': 1.000705361366272, 'learning_rate': 3.480508474576271e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:51:14<3:56:22,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:51:17<3:55:31,  3.44s/it]                                                       {'loss': 0.0247, 'grad_norm': 2.3066179752349854, 'learning_rate': 3.479661016949153e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:51:17<3:55:31,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:51:21<4:07:45,  3.62s/it]                                                       {'loss': 0.0316, 'grad_norm': 2.260324001312256, 'learning_rate': 3.478813559322034e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:51:21<4:07:45,  3.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:25<4:01:23,  3.53s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.47274547815322876, 'learning_rate': 3.477966101694916e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:25<4:01:23,  3.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:28<3:58:48,  3.49s/it]                                                       {'loss': 0.048, 'grad_norm': 1.9003734588623047, 'learning_rate': 3.477118644067797e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:28<3:58:48,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:31<3:56:47,  3.46s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.7901926636695862, 'learning_rate': 3.476271186440678e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:31<3:56:47,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:51:35<3:54:30,  3.43s/it]                                                       {'loss': 0.1981, 'grad_norm': 5.215648174285889, 'learning_rate': 3.475423728813559e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:51:35<3:54:30,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:51:38<3:53:09,  3.41s/it]                                                       {'loss': 0.0489, 'grad_norm': 2.6158716678619385, 'learning_rate': 3.474576271186441e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:51:38<3:53:09,  3.41s/it][2025-10-21 03:16:00,842] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:51:44<4:37:04,  4.06s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.42212629318237305, 'learning_rate': 3.473728813559322e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:51:44<4:37:04,  4.06s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:51:48<4:45:28,  4.18s/it]                                                       {'loss': 0.0075, 'grad_norm': 0.6144482493400574, 'learning_rate': 3.472881355932204e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:51:48<4:45:28,  4.18s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:51:51<4:28:37,  3.93s/it]                                                       {'loss': 0.0879, 'grad_norm': 1.2835932970046997, 'learning_rate': 3.472033898305085e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:51:51<4:28:37,  3.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:51:55<4:27:04,  3.91s/it]                                                       {'loss': 0.0101, 'grad_norm': 0.7228144407272339, 'learning_rate': 3.471186440677966e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:51:55<4:27:04,  3.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:51:59<4:25:15,  3.89s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.7737813591957092, 'learning_rate': 3.470338983050847e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:51:59<4:25:15,  3.89s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:52:02<4:13:01,  3.71s/it]                                                       {'loss': 0.1629, 'grad_norm': 4.417201519012451, 'learning_rate': 3.469491525423729e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:52:02<4:13:01,  3.71s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:52:06<4:06:15,  3.61s/it]                                                       {'loss': 0.0547, 'grad_norm': 3.507617950439453, 'learning_rate': 3.46864406779661e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:52:06<4:06:15,  3.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:52:09<4:00:45,  3.53s/it]                                                       {'loss': 0.018, 'grad_norm': 1.3402177095413208, 'learning_rate': 3.4677966101694914e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:52:09<4:00:45,  3.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:52:13<3:56:30,  3.47s/it]                                                       {'loss': 0.0308, 'grad_norm': 2.341129779815674, 'learning_rate': 3.466949152542373e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:52:13<3:56:30,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:52:16<3:57:26,  3.48s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.3596194386482239, 'learning_rate': 3.466101694915254e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:52:16<3:57:26,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:52:19<3:54:00,  3.43s/it]                                                       {'loss': 0.011, 'grad_norm': 1.0602200031280518, 'learning_rate': 3.465254237288136e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:52:19<3:54:00,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:52:23<3:52:01,  3.41s/it]                                                       {'loss': 0.1295, 'grad_norm': 5.1137800216674805, 'learning_rate': 3.4644067796610166e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:52:23<3:52:01,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:52:26<3:54:43,  3.45s/it]                                                       {'loss': 0.0819, 'grad_norm': 2.758571147918701, 'learning_rate': 3.4635593220338984e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:52:26<3:54:43,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:52:30<3:53:13,  3.42s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.3703341484069824, 'learning_rate': 3.4627118644067795e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:52:30<3:53:13,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:52:33<3:54:25,  3.44s/it]                                                       {'loss': 0.0385, 'grad_norm': 1.9629030227661133, 'learning_rate': 3.461864406779661e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:52:33<3:54:25,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:52:37<3:54:48,  3.45s/it]                                                       {'loss': 0.0725, 'grad_norm': 4.768843173980713, 'learning_rate': 3.4610169491525425e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:52:37<3:54:48,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:52:40<3:52:24,  3.42s/it]                                                       {'loss': 0.1638, 'grad_norm': 6.63910436630249, 'learning_rate': 3.460169491525424e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:52:40<3:52:24,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:52:43<3:51:32,  3.40s/it]                                                       {'loss': 0.0077, 'grad_norm': 0.6711081266403198, 'learning_rate': 3.4593220338983054e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:52:43<3:51:32,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:52:47<3:57:20,  3.49s/it]                                                       {'loss': 0.104, 'grad_norm': 1.4485130310058594, 'learning_rate': 3.4584745762711865e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:52:47<3:57:20,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:52:50<3:55:23,  3.46s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.13186955451965332, 'learning_rate': 3.4576271186440676e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:52:50<3:55:23,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:52:54<3:54:29,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.04278870299458504, 'learning_rate': 3.4567796610169494e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:52:54<3:54:29,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:52:57<3:52:27,  3.42s/it]                                                       {'loss': 0.1842, 'grad_norm': 5.3371782302856445, 'learning_rate': 3.4559322033898306e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:52:57<3:52:27,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:53:00<3:51:23,  3.41s/it]                                                       {'loss': 0.1096, 'grad_norm': 1.5608227252960205, 'learning_rate': 3.4550847457627124e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:53:00<3:51:23,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:53:04<3:54:05,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0512140654027462, 'learning_rate': 3.4542372881355935e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:53:04<3:54:05,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:53:07<3:52:55,  3.43s/it]                                                       {'loss': 0.0589, 'grad_norm': 3.0437374114990234, 'learning_rate': 3.4533898305084746e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:53:07<3:52:55,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:53:11<3:50:44,  3.40s/it]                                                       {'loss': 0.0713, 'grad_norm': 2.300934314727783, 'learning_rate': 3.452542372881356e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:53:11<3:50:44,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:53:14<3:51:52,  3.42s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.9622990489006042, 'learning_rate': 3.4516949152542376e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:53:14<3:51:52,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:53:18<3:50:10,  3.39s/it]                                                       {'loss': 0.1382, 'grad_norm': 4.342902183532715, 'learning_rate': 3.450847457627119e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:53:18<3:50:10,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:53:21<3:49:24,  3.38s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.23196269571781158, 'learning_rate': 3.45e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:53:21<3:49:24,  3.38s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:53:25<3:54:44,  3.46s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.3085893392562866, 'learning_rate': 3.4491525423728816e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:53:25<3:54:44,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:53:28<3:59:37,  3.53s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.25729310512542725, 'learning_rate': 3.448305084745763e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:53:28<3:59:37,  3.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:53:32<3:56:42,  3.49s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.48610252141952515, 'learning_rate': 3.4474576271186446e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:53:32<3:56:42,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:53:35<3:54:51,  3.46s/it]                                                       {'loss': 0.0287, 'grad_norm': 1.3705592155456543, 'learning_rate': 3.446610169491526e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:53:35<3:54:51,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:53:38<3:51:55,  3.42s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.34625327587127686, 'learning_rate': 3.445762711864407e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:53:38<3:51:55,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:53:42<3:52:47,  3.44s/it]                                                       {'loss': 0.0721, 'grad_norm': 3.679809808731079, 'learning_rate': 3.444915254237288e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:53:42<3:52:47,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:53:45<3:51:29,  3.42s/it]                                                       {'loss': 0.0566, 'grad_norm': 2.9798264503479004, 'learning_rate': 3.44406779661017e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:53:45<3:51:29,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:53:49<3:50:30,  3.40s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2623175382614136, 'learning_rate': 3.443220338983051e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:53:49<3:50:30,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:53:52<4:00:38,  3.55s/it]                                                       {'loss': 0.0098, 'grad_norm': 0.48715919256210327, 'learning_rate': 3.442372881355933e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:53:52<4:00:38,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:53:56<3:57:53,  3.51s/it]                                                       {'loss': 0.1025, 'grad_norm': 5.121315956115723, 'learning_rate': 3.441525423728814e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:53:56<3:57:53,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:53:59<3:56:09,  3.49s/it]                                                       {'loss': 0.0349, 'grad_norm': 2.554354667663574, 'learning_rate': 3.440677966101695e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:53:59<3:56:09,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:54:03<3:52:21,  3.43s/it]                                                       {'loss': 0.2246, 'grad_norm': 5.326237678527832, 'learning_rate': 3.439830508474576e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:54:03<3:52:21,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:54:06<3:51:05,  3.42s/it]                                                       {'loss': 0.1525, 'grad_norm': 4.64868688583374, 'learning_rate': 3.438983050847458e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:54:06<3:51:05,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:54:09<3:49:30,  3.39s/it]                                                       {'loss': 0.01, 'grad_norm': 1.0957939624786377, 'learning_rate': 3.438135593220339e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:54:09<3:49:30,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:54:13<3:52:33,  3.44s/it]                                                       {'loss': 0.095, 'grad_norm': 5.683433532714844, 'learning_rate': 3.437288135593221e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:54:13<3:52:33,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:54:17<4:00:00,  3.55s/it]                                                       {'loss': 0.0687, 'grad_norm': 3.8889198303222656, 'learning_rate': 3.436440677966102e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:54:17<4:00:00,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:54:20<3:55:34,  3.49s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.4517616033554077, 'learning_rate': 3.435593220338984e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:54:20<3:55:34,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:54:24<3:55:19,  3.48s/it]                                                       {'loss': 0.1256, 'grad_norm': 3.1755833625793457, 'learning_rate': 3.434745762711864e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:54:24<3:55:19,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:54:27<3:56:22,  3.50s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.12225573509931564, 'learning_rate': 3.433898305084746e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:54:27<3:56:22,  3.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:54:31<4:02:52,  3.60s/it]                                                       {'loss': 0.016, 'grad_norm': 1.5183229446411133, 'learning_rate': 3.433050847457627e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:54:31<4:02:52,  3.60s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:54:34<3:56:58,  3.51s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.4866056740283966, 'learning_rate': 3.432203389830508e-05, 'epoch': 0.33}
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:54:34<3:56:58,  3.51s/it][2025-10-21 03:18:56,959] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:54:40<4:39:44,  4.15s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.1564664989709854, 'learning_rate': 3.43135593220339e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:54:40<4:39:44,  4.15s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:54:43<4:22:57,  3.90s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.7236643433570862, 'learning_rate': 3.430508474576271e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:54:43<4:22:57,  3.90s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:54:47<4:12:13,  3.74s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.3291224539279938, 'learning_rate': 3.429661016949153e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:54:47<4:12:13,  3.74s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:54:50<4:05:35,  3.64s/it]                                                       {'loss': 0.0086, 'grad_norm': 0.9044369459152222, 'learning_rate': 3.428813559322034e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:54:50<4:05:35,  3.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:54:53<3:59:46,  3.56s/it]                                                       {'loss': 0.0395, 'grad_norm': 1.6837835311889648, 'learning_rate': 3.427966101694915e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:54:53<3:59:46,  3.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:54:57<3:58:36,  3.54s/it]                                                       {'loss': 0.0387, 'grad_norm': 2.5215446949005127, 'learning_rate': 3.4271186440677964e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:54:57<3:58:36,  3.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:55:00<3:56:22,  3.51s/it]                                                       {'loss': 0.0715, 'grad_norm': 2.870885133743286, 'learning_rate': 3.426271186440678e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:55:00<3:56:22,  3.51s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:55:04<3:52:39,  3.45s/it]                                                       {'loss': 0.043, 'grad_norm': 2.503082275390625, 'learning_rate': 3.4254237288135593e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:55:04<3:52:39,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:55:07<3:59:12,  3.55s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.6330704689025879, 'learning_rate': 3.424576271186441e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:55:07<3:59:12,  3.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:55:11<3:56:42,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.08052480965852737, 'learning_rate': 3.423728813559322e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:55:11<3:56:42,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:55:14<3:52:48,  3.46s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19027167558670044, 'learning_rate': 3.4228813559322034e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:55:14<3:52:48,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:55:18<3:55:35,  3.50s/it]                                                       {'loss': 0.2042, 'grad_norm': 6.431888103485107, 'learning_rate': 3.4220338983050845e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:55:18<3:55:35,  3.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:55:21<3:52:50,  3.46s/it]                                                       {'loss': 0.1078, 'grad_norm': 4.390388011932373, 'learning_rate': 3.421186440677966e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:55:21<3:52:50,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:55:24<3:51:14,  3.44s/it]                                                       {'loss': 0.0477, 'grad_norm': 2.384605646133423, 'learning_rate': 3.4203389830508475e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:55:24<3:51:14,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:55:28<3:50:43,  3.43s/it]                                                       {'loss': 0.0209, 'grad_norm': 0.7084375619888306, 'learning_rate': 3.419491525423729e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:55:28<3:50:43,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:55:32<4:04:18,  3.63s/it]                                                       {'loss': 0.0087, 'grad_norm': 0.7900540232658386, 'learning_rate': 3.4186440677966104e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:55:32<4:04:18,  3.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:55:35<3:59:20,  3.56s/it]                                                       {'loss': 0.0854, 'grad_norm': 3.959937810897827, 'learning_rate': 3.417796610169492e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:55:35<3:59:20,  3.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:55:39<3:58:11,  3.54s/it]                                                       {'loss': 0.1213, 'grad_norm': 5.312161922454834, 'learning_rate': 3.416949152542373e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:55:39<3:58:11,  3.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:55:42<3:56:28,  3.52s/it]                                                       {'loss': 0.0544, 'grad_norm': 2.8408994674682617, 'learning_rate': 3.4161016949152545e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:55:42<3:56:28,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:55:46<4:01:43,  3.60s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03057006187736988, 'learning_rate': 3.4152542372881356e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:55:46<4:01:43,  3.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:55:49<3:56:29,  3.52s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.44148141145706177, 'learning_rate': 3.414406779661017e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:55:49<3:56:29,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:55:53<3:52:23,  3.46s/it]                                                       {'loss': 0.0269, 'grad_norm': 1.0919365882873535, 'learning_rate': 3.4135593220338985e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:55:53<3:52:23,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:55:56<3:50:08,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.05138225480914116, 'learning_rate': 3.4127118644067797e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:55:56<3:50:08,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:56:00<3:50:30,  3.44s/it]                                                       {'loss': 0.0161, 'grad_norm': 1.098195195198059, 'learning_rate': 3.4118644067796615e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:56:00<3:50:30,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:56:03<3:52:25,  3.46s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.24516676366329193, 'learning_rate': 3.4110169491525426e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:56:03<3:52:25,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:56:06<3:49:38,  3.42s/it]                                                       {'loss': 0.0696, 'grad_norm': 3.110799551010132, 'learning_rate': 3.410169491525424e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:56:06<3:49:38,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:56:10<3:49:22,  3.42s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.19980685412883759, 'learning_rate': 3.409322033898305e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:56:10<3:49:22,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:56:13<3:48:36,  3.41s/it]                                                       {'loss': 0.0159, 'grad_norm': 1.7875638008117676, 'learning_rate': 3.4084745762711867e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:56:13<3:48:36,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:56:17<3:49:56,  3.43s/it]                                                       {'loss': 0.052, 'grad_norm': 3.4865763187408447, 'learning_rate': 3.407627118644068e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:56:17<3:49:56,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:56:20<3:49:35,  3.43s/it]                                                       {'loss': 0.0377, 'grad_norm': 1.7236733436584473, 'learning_rate': 3.4067796610169496e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:56:20<3:49:35,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:56:23<3:47:45,  3.40s/it]                                                       {'loss': 0.007, 'grad_norm': 0.6626222133636475, 'learning_rate': 3.405932203389831e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:56:23<3:47:45,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:56:27<3:48:13,  3.41s/it]                                                       {'loss': 0.2975, 'grad_norm': 7.9394211769104, 'learning_rate': 3.4050847457627125e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:56:27<3:48:13,  3.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:56:30<3:48:56,  3.42s/it]                                                       {'loss': 0.1305, 'grad_norm': 6.820959091186523, 'learning_rate': 3.404237288135593e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:56:30<3:48:56,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:56:34<3:53:39,  3.49s/it]                                                       {'loss': 0.1166, 'grad_norm': 4.84611701965332, 'learning_rate': 3.403389830508475e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:56:34<3:53:39,  3.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:56:37<3:51:44,  3.46s/it]                                                       {'loss': 0.022, 'grad_norm': 2.042263984680176, 'learning_rate': 3.402542372881356e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:56:37<3:51:44,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:56:41<3:51:21,  3.46s/it]                                                       {'loss': 0.0542, 'grad_norm': 2.9136226177215576, 'learning_rate': 3.401694915254238e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:56:41<3:51:21,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:56:44<3:51:05,  3.46s/it]                                                       {'loss': 0.0478, 'grad_norm': 3.431793689727783, 'learning_rate': 3.400847457627119e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:56:44<3:51:05,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:56:48<3:51:33,  3.46s/it]                                                       {'loss': 0.0511, 'grad_norm': 3.3442556858062744, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:56:48<3:51:33,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:56:51<3:54:40,  3.51s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.44028809666633606, 'learning_rate': 3.399152542372882e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:56:51<3:54:40,  3.51s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:56:55<3:51:21,  3.46s/it]                                                       {'loss': 0.0829, 'grad_norm': 4.191529273986816, 'learning_rate': 3.398305084745763e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:56:55<3:51:21,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:56:58<3:49:36,  3.44s/it]                                                       {'loss': 0.1208, 'grad_norm': 3.5296630859375, 'learning_rate': 3.397457627118644e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:56:58<3:49:36,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:57:01<3:47:14,  3.40s/it]                                                       {'loss': 0.054, 'grad_norm': 2.66344952583313, 'learning_rate': 3.396610169491525e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:57:01<3:47:14,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:57:05<3:47:03,  3.40s/it]                                                       {'loss': 0.0493, 'grad_norm': 3.780961513519287, 'learning_rate': 3.395762711864407e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:57:05<3:47:03,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:57:08<3:45:52,  3.38s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.15082524716854095, 'learning_rate': 3.394915254237288e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:57:08<3:45:52,  3.38s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:57:12<3:48:52,  3.43s/it]                                                       {'loss': 0.1159, 'grad_norm': 5.45613431930542, 'learning_rate': 3.39406779661017e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:57:12<3:48:52,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:57:15<3:48:28,  3.42s/it]                                                       {'loss': 0.0278, 'grad_norm': 2.084721088409424, 'learning_rate': 3.393220338983051e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:57:15<3:48:28,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:57:19<3:49:05,  3.43s/it]                                                       {'loss': 0.2003, 'grad_norm': 7.0963873863220215, 'learning_rate': 3.392372881355932e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:57:19<3:49:05,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:57:22<3:49:16,  3.44s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.2858484089374542, 'learning_rate': 3.391525423728813e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:57:22<3:49:16,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:57:26<3:58:25,  3.58s/it]                                                       {'loss': 0.0521, 'grad_norm': 3.0247578620910645, 'learning_rate': 3.390677966101695e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:57:26<3:58:25,  3.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:57:30<4:05:30,  3.68s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.19789479672908783, 'learning_rate': 3.389830508474576e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:57:30<4:05:30,  3.68s/it][2025-10-21 03:21:52,603] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:57:36<4:45:23,  4.28s/it]                                                       {'loss': 0.0501, 'grad_norm': 3.0149362087249756, 'learning_rate': 3.388983050847458e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:57:36<4:45:23,  4.28s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:57:39<4:27:47,  4.02s/it]                                                       {'loss': 0.0672, 'grad_norm': 3.555433988571167, 'learning_rate': 3.388135593220339e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:57:39<4:27:47,  4.02s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:57:42<4:14:02,  3.81s/it]                                                       {'loss': 0.0429, 'grad_norm': 2.883080005645752, 'learning_rate': 3.387288135593221e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:57:42<4:14:02,  3.81s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:57:46<4:06:24,  3.70s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.0721534714102745, 'learning_rate': 3.386440677966102e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:57:46<4:06:24,  3.70s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:57:49<4:00:31,  3.61s/it]                                                       {'loss': 0.0145, 'grad_norm': 1.375059723854065, 'learning_rate': 3.385593220338983e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:57:49<4:00:31,  3.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:57:53<4:01:59,  3.64s/it]                                                       {'loss': 0.0706, 'grad_norm': 1.964907169342041, 'learning_rate': 3.3847457627118644e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:57:53<4:01:59,  3.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:57:56<3:57:36,  3.57s/it]                                                       {'loss': 0.0214, 'grad_norm': 2.552687406539917, 'learning_rate': 3.383898305084746e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:57:56<3:57:36,  3.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:58:00<3:54:47,  3.53s/it]                                                       {'loss': 0.0844, 'grad_norm': 2.8001840114593506, 'learning_rate': 3.383050847457627e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:58:00<3:54:47,  3.53s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:58:03<3:51:18,  3.48s/it]                                                       {'loss': 0.0199, 'grad_norm': 2.180232524871826, 'learning_rate': 3.382203389830509e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:58:03<3:51:18,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:58:07<3:59:28,  3.60s/it]                                                       {'loss': 0.0933, 'grad_norm': 4.445828437805176, 'learning_rate': 3.38135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:58:07<3:59:28,  3.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:58:10<3:58:13,  3.58s/it]                                                       {'loss': 0.093, 'grad_norm': 4.579510688781738, 'learning_rate': 3.3805084745762714e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:58:10<3:58:13,  3.58s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:58:14<3:53:11,  3.51s/it]                                                       {'loss': 0.0046, 'grad_norm': 0.36711570620536804, 'learning_rate': 3.3796610169491525e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:58:14<3:53:11,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:58:17<3:50:59,  3.48s/it]                                                       {'loss': 0.2158, 'grad_norm': 6.484035491943359, 'learning_rate': 3.3788135593220336e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:58:17<3:50:59,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:58:21<3:50:40,  3.47s/it]                                                       {'loss': 0.0918, 'grad_norm': 5.44157075881958, 'learning_rate': 3.3779661016949154e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:58:21<3:50:40,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:58:24<3:48:25,  3.44s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.082198977470398, 'learning_rate': 3.3771186440677965e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:58:24<3:48:25,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:58:28<3:49:55,  3.46s/it]                                                       {'loss': 0.0946, 'grad_norm': 4.359163284301758, 'learning_rate': 3.3762711864406784e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:58:28<3:49:55,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:58:31<3:48:35,  3.44s/it]                                                       {'loss': 0.0464, 'grad_norm': 4.417989730834961, 'learning_rate': 3.3754237288135595e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:58:31<3:48:35,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:58:34<3:48:22,  3.44s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5076842308044434, 'learning_rate': 3.3745762711864406e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:58:34<3:48:22,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:58:38<3:51:39,  3.49s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.42296138405799866, 'learning_rate': 3.373728813559322e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:58:38<3:51:39,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:58:42<3:58:02,  3.59s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.5357751846313477, 'learning_rate': 3.3728813559322035e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:58:42<3:58:02,  3.59s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:58:45<3:53:17,  3.52s/it]                                                       {'loss': 0.0618, 'grad_norm': 4.69179105758667, 'learning_rate': 3.372033898305085e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:58:45<3:53:17,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:58:48<3:49:57,  3.47s/it]                                                       {'loss': 0.001, 'grad_norm': 0.10446229577064514, 'learning_rate': 3.3711864406779665e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:58:48<3:49:57,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:58:52<3:51:19,  3.49s/it]                                                       {'loss': 0.0109, 'grad_norm': 0.9014921188354492, 'learning_rate': 3.3703389830508476e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:58:52<3:51:19,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:58:55<3:49:02,  3.46s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.04678845405578613, 'learning_rate': 3.3694915254237294e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:58:55<3:49:02,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:58:59<3:46:08,  3.41s/it]                                                       {'loss': 0.0653, 'grad_norm': 3.8858542442321777, 'learning_rate': 3.3686440677966105e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:58:59<3:46:08,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:59:02<3:46:51,  3.43s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.8596079349517822, 'learning_rate': 3.367796610169492e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:59:02<3:46:51,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:59:06<3:45:14,  3.40s/it]                                                       {'loss': 0.0176, 'grad_norm': 1.3950425386428833, 'learning_rate': 3.366949152542373e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:59:06<3:45:14,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:59:09<3:44:39,  3.39s/it]                                                       {'loss': 0.1166, 'grad_norm': 4.457244396209717, 'learning_rate': 3.3661016949152546e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:59:09<3:44:39,  3.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:59:12<3:46:52,  3.43s/it]                                                       {'loss': 0.2081, 'grad_norm': 5.872504711151123, 'learning_rate': 3.365254237288136e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:59:12<3:46:52,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:59:17<4:03:16,  3.68s/it]                                                       {'loss': 0.1554, 'grad_norm': 4.479245185852051, 'learning_rate': 3.3644067796610175e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:59:17<4:03:16,  3.68s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:59:20<3:56:49,  3.58s/it]                                                       {'loss': 0.1092, 'grad_norm': 4.669834613800049, 'learning_rate': 3.363559322033899e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:59:20<3:56:49,  3.58s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:59:23<3:54:37,  3.55s/it]                                                       {'loss': 0.0194, 'grad_norm': 1.9876645803451538, 'learning_rate': 3.36271186440678e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:59:23<3:54:37,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:59:27<3:53:18,  3.53s/it]                                                       {'loss': 0.0145, 'grad_norm': 1.448403239250183, 'learning_rate': 3.361864406779661e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:59:27<3:53:18,  3.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:59:30<3:51:39,  3.50s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.5532427430152893, 'learning_rate': 3.361016949152542e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:59:30<3:51:39,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:59:34<3:57:31,  3.59s/it]                                                       {'loss': 0.0336, 'grad_norm': 2.0986642837524414, 'learning_rate': 3.360169491525424e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:59:34<3:57:31,  3.59s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:59:38<3:53:30,  3.53s/it]                                                       {'loss': 0.2039, 'grad_norm': 6.303664684295654, 'learning_rate': 3.359322033898305e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:59:38<3:53:30,  3.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:59:41<3:49:44,  3.48s/it]                                                       {'loss': 0.0198, 'grad_norm': 2.181450128555298, 'learning_rate': 3.358474576271187e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:59:41<3:49:44,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:59:44<3:48:43,  3.46s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.17838768661022186, 'learning_rate': 3.357627118644068e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:59:44<3:48:43,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:59:48<3:45:07,  3.41s/it]                                                       {'loss': 0.0944, 'grad_norm': 4.8302130699157715, 'learning_rate': 3.35677966101695e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:59:48<3:45:07,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:59:51<3:51:27,  3.51s/it]                                                       {'loss': 0.003, 'grad_norm': 0.3645145893096924, 'learning_rate': 3.35593220338983e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:59:51<3:51:27,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:59:55<3:47:58,  3.46s/it]                                                       {'loss': 0.028, 'grad_norm': 2.2259562015533447, 'learning_rate': 3.355084745762712e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:59:55<3:47:58,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:59:58<3:46:18,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.006314496044069529, 'learning_rate': 3.354237288135593e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:59:58<3:46:18,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [2:00:02<3:45:28,  3.42s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.442249596118927, 'learning_rate': 3.353389830508475e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [2:00:02<3:45:28,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [2:00:05<3:46:11,  3.43s/it]                                                       {'loss': 0.0552, 'grad_norm': 3.4545693397521973, 'learning_rate': 3.352542372881356e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [2:00:05<3:46:11,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [2:00:08<3:43:43,  3.39s/it]                                                       {'loss': 0.0168, 'grad_norm': 0.8925588130950928, 'learning_rate': 3.351694915254238e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [2:00:08<3:43:43,  3.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [2:00:12<3:45:18,  3.42s/it]                                                       {'loss': 0.0168, 'grad_norm': 2.3329272270202637, 'learning_rate': 3.350847457627119e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [2:00:12<3:45:18,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [2:00:15<3:45:53,  3.43s/it]                                                       {'loss': 0.0396, 'grad_norm': 3.2138164043426514, 'learning_rate': 3.35e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [2:00:15<3:45:53,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [2:00:19<3:48:49,  3.47s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.42542216181755066, 'learning_rate': 3.349152542372881e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [2:00:19<3:48:49,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:00:22<3:45:29,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.19316737353801727, 'learning_rate': 3.348305084745763e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:00:22<3:45:29,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:00:25<3:44:15,  3.41s/it]                                                       {'loss': 0.2223, 'grad_norm': 5.70821475982666, 'learning_rate': 3.347457627118644e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:00:25<3:44:15,  3.41s/it][2025-10-21 03:24:48,214] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:00:31<4:26:26,  4.05s/it]                                                       {'loss': 0.005, 'grad_norm': 0.3472451865673065, 'learning_rate': 3.346610169491526e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:00:31<4:26:26,  4.05s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:00:35<4:16:11,  3.89s/it]                                                       {'loss': 0.1443, 'grad_norm': 4.074281215667725, 'learning_rate': 3.345762711864407e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:00:35<4:16:11,  3.89s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:00:38<4:05:02,  3.72s/it]                                                       {'loss': 0.0326, 'grad_norm': 4.2718329429626465, 'learning_rate': 3.344915254237288e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:00:38<4:05:02,  3.72s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:00:41<3:57:49,  3.62s/it]                                                       {'loss': 0.0365, 'grad_norm': 2.157560110092163, 'learning_rate': 3.3440677966101694e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:00:41<3:57:49,  3.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:00:45<4:00:20,  3.66s/it]                                                       {'loss': 0.2263, 'grad_norm': 4.777191638946533, 'learning_rate': 3.3432203389830505e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:00:45<4:00:20,  3.66s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:00:48<3:54:17,  3.56s/it]                                                       {'loss': 0.0205, 'grad_norm': 2.0562260150909424, 'learning_rate': 3.342372881355932e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:00:48<3:54:17,  3.56s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:00:53<4:07:38,  3.77s/it]                                                       {'loss': 0.0847, 'grad_norm': 4.358191013336182, 'learning_rate': 3.3415254237288134e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:00:53<4:07:38,  3.77s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:00:56<3:59:34,  3.65s/it]                                                       {'loss': 0.0057, 'grad_norm': 0.7060317397117615, 'learning_rate': 3.340677966101695e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:00:56<3:59:34,  3.65s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:00:59<3:53:26,  3.55s/it]                                                       {'loss': 0.026, 'grad_norm': 2.8992629051208496, 'learning_rate': 3.3398305084745764e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:00:59<3:53:26,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:01:03<3:50:47,  3.51s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.18358246982097626, 'learning_rate': 3.338983050847458e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:01:03<3:50:47,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:01:06<3:49:10,  3.49s/it]                                                       {'loss': 0.0223, 'grad_norm': 3.0416808128356934, 'learning_rate': 3.338135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:01:06<3:49:10,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:01:10<3:46:54,  3.46s/it]                                                       {'loss': 0.1158, 'grad_norm': 4.034919738769531, 'learning_rate': 3.3372881355932204e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:01:10<3:46:54,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:01:13<3:46:13,  3.45s/it]                                                       {'loss': 0.042, 'grad_norm': 1.8749679327011108, 'learning_rate': 3.3364406779661016e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:01:13<3:46:13,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:01:16<3:45:54,  3.44s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.30954447388648987, 'learning_rate': 3.3355932203389834e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:01:16<3:45:54,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:01:20<3:52:54,  3.55s/it]                                                       {'loss': 0.0536, 'grad_norm': 1.7349438667297363, 'learning_rate': 3.3347457627118645e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:01:20<3:52:54,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:01:24<4:01:36,  3.68s/it]                                                       {'loss': 0.001, 'grad_norm': 0.0997159332036972, 'learning_rate': 3.333898305084746e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:01:24<4:01:36,  3.68s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:01:28<3:55:40,  3.60s/it]                                                       {'loss': 0.0958, 'grad_norm': 5.529706954956055, 'learning_rate': 3.3330508474576274e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:01:28<3:55:40,  3.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:01:31<3:50:58,  3.52s/it]                                                       {'loss': 0.0499, 'grad_norm': 4.721442222595215, 'learning_rate': 3.3322033898305086e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:01:31<3:50:58,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:01:35<4:06:19,  3.76s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.6454658508300781, 'learning_rate': 3.33135593220339e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:01:35<4:06:19,  3.76s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:01:39<3:59:00,  3.65s/it]                                                       {'loss': 0.2992, 'grad_norm': 5.497328281402588, 'learning_rate': 3.3305084745762715e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:01:39<3:59:00,  3.65s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:01:42<3:53:57,  3.57s/it]                                                       {'loss': 0.1162, 'grad_norm': 4.398464202880859, 'learning_rate': 3.3296610169491526e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:01:42<3:53:57,  3.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:01:45<3:51:04,  3.53s/it]                                                       {'loss': 0.0764, 'grad_norm': 2.8643076419830322, 'learning_rate': 3.3288135593220344e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:01:45<3:51:04,  3.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:01:49<3:46:03,  3.45s/it]                                                       {'loss': 0.0756, 'grad_norm': 4.449410915374756, 'learning_rate': 3.3279661016949156e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:01:49<3:46:03,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:01:52<3:49:40,  3.51s/it]                                                       {'loss': 0.0278, 'grad_norm': 2.301151990890503, 'learning_rate': 3.327118644067797e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:01:52<3:49:40,  3.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:01:56<3:51:22,  3.54s/it]                                                       {'loss': 0.1244, 'grad_norm': 3.9076972007751465, 'learning_rate': 3.326271186440678e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:01:56<3:51:22,  3.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:01:59<3:48:03,  3.49s/it]                                                       {'loss': 0.1684, 'grad_norm': 5.831454277038574, 'learning_rate': 3.325423728813559e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:01:59<3:48:03,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:02:03<3:48:11,  3.49s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.05186301842331886, 'learning_rate': 3.324576271186441e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:02:03<3:48:11,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:02:06<3:46:21,  3.46s/it]                                                       {'loss': 0.2195, 'grad_norm': 4.698170185089111, 'learning_rate': 3.323728813559322e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:02:06<3:46:21,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:02:10<3:44:56,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.21445833146572113, 'learning_rate': 3.322881355932204e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:02:10<3:44:56,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:02:13<3:44:59,  3.44s/it]                                                       {'loss': 0.0242, 'grad_norm': 1.0301676988601685, 'learning_rate': 3.322033898305085e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:02:13<3:44:59,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:02:16<3:43:20,  3.42s/it]                                                       {'loss': 0.2283, 'grad_norm': 6.304885387420654, 'learning_rate': 3.3211864406779666e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:02:16<3:43:20,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:02:20<3:43:34,  3.42s/it]                                                       {'loss': 0.0317, 'grad_norm': 2.55126690864563, 'learning_rate': 3.320338983050848e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:02:20<3:43:34,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:02:23<3:40:54,  3.38s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.26195165514945984, 'learning_rate': 3.319491525423729e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:02:23<3:40:54,  3.38s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:02:27<3:40:18,  3.38s/it]                                                       {'loss': 0.1416, 'grad_norm': 6.753146171569824, 'learning_rate': 3.31864406779661e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:02:27<3:40:18,  3.38s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:02:30<3:43:10,  3.42s/it]                                                       {'loss': 0.0596, 'grad_norm': 4.344804286956787, 'learning_rate': 3.317796610169492e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:02:30<3:43:10,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:02:34<3:44:15,  3.44s/it]                                                       {'loss': 0.037, 'grad_norm': 3.991520881652832, 'learning_rate': 3.316949152542373e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:02:34<3:44:15,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:02:37<3:51:26,  3.55s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.07780089229345322, 'learning_rate': 3.316101694915255e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:02:37<3:51:26,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:02:41<3:47:34,  3.49s/it]                                                       {'loss': 0.1362, 'grad_norm': 4.1265788078308105, 'learning_rate': 3.315254237288136e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:02:41<3:47:34,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:02:44<3:47:28,  3.49s/it]                                                       {'loss': 0.1355, 'grad_norm': 4.278951168060303, 'learning_rate': 3.314406779661017e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:02:44<3:47:28,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:02:47<3:44:12,  3.44s/it]                                                       {'loss': 0.0543, 'grad_norm': 1.233750343322754, 'learning_rate': 3.313559322033898e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:02:47<3:44:12,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:02:51<3:41:44,  3.40s/it]                                                       {'loss': 0.086, 'grad_norm': 4.192235469818115, 'learning_rate': 3.31271186440678e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:02:51<3:41:44,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:02:54<3:40:37,  3.39s/it]                                                       {'loss': 0.0675, 'grad_norm': 3.3770086765289307, 'learning_rate': 3.311864406779661e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:02:54<3:40:37,  3.39s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:02:58<3:41:10,  3.40s/it]                                                       {'loss': 0.1072, 'grad_norm': 5.106966972351074, 'learning_rate': 3.311016949152543e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:02:58<3:41:10,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:03:01<3:41:32,  3.40s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.30697181820869446, 'learning_rate': 3.310169491525424e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:03:01<3:41:32,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:03:05<3:50:18,  3.54s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.12299857288599014, 'learning_rate': 3.309322033898305e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:03:05<3:50:18,  3.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:03:08<3:47:48,  3.50s/it]                                                       {'loss': 0.0856, 'grad_norm': 3.3721213340759277, 'learning_rate': 3.308474576271187e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:03:08<3:47:48,  3.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:03:12<3:54:16,  3.60s/it]                                                       {'loss': 0.0287, 'grad_norm': 1.7444418668746948, 'learning_rate': 3.3076271186440674e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:03:12<3:54:16,  3.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:03:16<3:52:56,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.019415991380810738, 'learning_rate': 3.306779661016949e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:03:16<3:52:56,  3.58s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:03:19<3:55:52,  3.63s/it]                                                       {'loss': 0.0227, 'grad_norm': 1.4061557054519653, 'learning_rate': 3.30593220338983e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:03:19<3:55:52,  3.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:03:23<3:50:57,  3.55s/it]                                                       {'loss': 0.1122, 'grad_norm': 5.215702056884766, 'learning_rate': 3.305084745762712e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:03:23<3:50:57,  3.55s/it][2025-10-21 03:27:45,493] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:03:28<4:31:04,  4.17s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.5595934391021729, 'learning_rate': 3.304237288135593e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:03:28<4:31:04,  4.17s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:03:32<4:14:21,  3.92s/it]                                                       {'loss': 0.062, 'grad_norm': 3.9052741527557373, 'learning_rate': 3.303389830508475e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:03:32<4:14:21,  3.92s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:03:35<4:03:32,  3.75s/it]                                                       {'loss': 0.015, 'grad_norm': 1.0623466968536377, 'learning_rate': 3.302542372881356e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:03:35<4:03:32,  3.75s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:03:38<3:57:04,  3.65s/it]                                                       {'loss': 0.0847, 'grad_norm': 3.5445733070373535, 'learning_rate': 3.301694915254237e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:03:38<3:57:04,  3.65s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:03:42<3:53:26,  3.60s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.11897194385528564, 'learning_rate': 3.3008474576271184e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:03:42<3:53:26,  3.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:03:45<3:47:40,  3.51s/it]                                                       {'loss': 0.1673, 'grad_norm': 6.777167320251465, 'learning_rate': 3.3e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:03:45<3:47:40,  3.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:03:49<3:46:45,  3.49s/it]                                                       {'loss': 0.0157, 'grad_norm': 0.7183855175971985, 'learning_rate': 3.2991525423728814e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:03:49<3:46:45,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:03:52<3:45:08,  3.47s/it]                                                       {'loss': 0.1438, 'grad_norm': 5.280988693237305, 'learning_rate': 3.298305084745763e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:03:52<3:45:08,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:03:56<3:45:30,  3.48s/it]                                                       {'loss': 0.2176, 'grad_norm': 5.1471967697143555, 'learning_rate': 3.297457627118644e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:03:56<3:45:30,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:03:59<3:53:22,  3.60s/it]                                                       {'loss': 0.106, 'grad_norm': 4.813314437866211, 'learning_rate': 3.296610169491526e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:03:59<3:53:22,  3.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:04:03<3:50:46,  3.56s/it]                                                       {'loss': 0.0421, 'grad_norm': 3.3037590980529785, 'learning_rate': 3.2957627118644066e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:04:03<3:50:46,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:04:07<3:53:52,  3.61s/it]                                                       {'loss': 0.2701, 'grad_norm': 6.010778427124023, 'learning_rate': 3.2949152542372884e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:04:07<3:53:52,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:04:10<3:49:56,  3.55s/it]                                                       {'loss': 0.0367, 'grad_norm': 1.9735209941864014, 'learning_rate': 3.2940677966101695e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:04:10<3:49:56,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:04:13<3:46:35,  3.50s/it]                                                       {'loss': 0.0504, 'grad_norm': 2.7873694896698, 'learning_rate': 3.293220338983051e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:04:13<3:46:35,  3.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:04:17<3:44:52,  3.47s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.23882921040058136, 'learning_rate': 3.2923728813559324e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:04:17<3:44:52,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:04:20<3:44:36,  3.47s/it]                                                       {'loss': 0.0341, 'grad_norm': 2.5868778228759766, 'learning_rate': 3.2915254237288136e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:04:20<3:44:36,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:04:24<3:42:53,  3.44s/it]                                                       {'loss': 0.3516, 'grad_norm': 6.0973029136657715, 'learning_rate': 3.2906779661016954e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:04:24<3:42:53,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:04:27<3:43:00,  3.45s/it]                                                       {'loss': 0.0393, 'grad_norm': 2.655073881149292, 'learning_rate': 3.2898305084745765e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:04:27<3:43:00,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:04:31<3:42:55,  3.45s/it]                                                       {'loss': 0.0596, 'grad_norm': 3.707331895828247, 'learning_rate': 3.2889830508474576e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:04:31<3:42:55,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:04:34<3:41:22,  3.42s/it]                                                       {'loss': 0.0479, 'grad_norm': 2.9476587772369385, 'learning_rate': 3.288135593220339e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:04:34<3:41:22,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:04:37<3:39:56,  3.40s/it]                                                       {'loss': 0.0661, 'grad_norm': 2.7582712173461914, 'learning_rate': 3.2872881355932206e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:04:37<3:39:56,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:04:41<3:51:16,  3.58s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.1354345083236694, 'learning_rate': 3.286440677966102e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:04:41<3:51:16,  3.58s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:04:45<3:48:17,  3.53s/it]                                                       {'loss': 0.1492, 'grad_norm': 5.451277732849121, 'learning_rate': 3.2855932203389835e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:04:45<3:48:17,  3.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:04:48<3:44:23,  3.47s/it]                                                       {'loss': 0.1336, 'grad_norm': 4.055211067199707, 'learning_rate': 3.2847457627118646e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:04:48<3:44:23,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:04:51<3:40:50,  3.42s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.5400330424308777, 'learning_rate': 3.283898305084746e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:04:51<3:40:50,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:04:55<3:39:42,  3.40s/it]                                                       {'loss': 0.0104, 'grad_norm': 0.7628940939903259, 'learning_rate': 3.283050847457627e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:04:55<3:39:42,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:04:58<3:41:01,  3.42s/it]                                                       {'loss': 0.0431, 'grad_norm': 1.829216718673706, 'learning_rate': 3.282203389830509e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:04:58<3:41:01,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:05:02<3:40:01,  3.41s/it]                                                       {'loss': 0.1806, 'grad_norm': 4.137733459472656, 'learning_rate': 3.28135593220339e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:05:02<3:40:01,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:05:05<3:39:37,  3.40s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.12090695649385452, 'learning_rate': 3.2805084745762716e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:05:05<3:39:37,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:05:08<3:37:57,  3.38s/it]                                                       {'loss': 0.0445, 'grad_norm': 2.7022314071655273, 'learning_rate': 3.279661016949153e-05, 'epoch': 0.35}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:05:08<3:37:57,  3.38s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:05:12<3:39:11,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.012211166322231293, 'learning_rate': 3.2788135593220346e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:05:12<3:39:11,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:05:15<3:39:31,  3.41s/it]                                                       {'loss': 0.0134, 'grad_norm': 0.8716068267822266, 'learning_rate': 3.277966101694916e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:05:15<3:39:31,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:05:19<3:48:46,  3.55s/it]                                                       {'loss': 0.1229, 'grad_norm': 5.580479145050049, 'learning_rate': 3.277118644067797e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:05:19<3:48:46,  3.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:05:22<3:45:43,  3.50s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.829237699508667, 'learning_rate': 3.276271186440678e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:05:22<3:45:43,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:05:26<3:42:54,  3.46s/it]                                                       {'loss': 0.0151, 'grad_norm': 0.8001508116722107, 'learning_rate': 3.27542372881356e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:05:26<3:42:54,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:05:29<3:44:23,  3.48s/it]                                                       {'loss': 0.0284, 'grad_norm': 2.7373316287994385, 'learning_rate': 3.274576271186441e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:05:29<3:44:23,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:05:33<3:42:47,  3.46s/it]                                                       {'loss': 0.0281, 'grad_norm': 2.5254812240600586, 'learning_rate': 3.273728813559322e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:05:33<3:42:47,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:05:36<3:40:18,  3.42s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.38082849979400635, 'learning_rate': 3.272881355932204e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:05:36<3:40:18,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:05:39<3:37:41,  3.38s/it]                                                       {'loss': 0.044, 'grad_norm': 2.470500946044922, 'learning_rate': 3.272033898305085e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:05:39<3:37:41,  3.38s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:05:43<3:37:53,  3.39s/it]                                                       {'loss': 0.2934, 'grad_norm': 5.729709148406982, 'learning_rate': 3.271186440677966e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:05:43<3:37:53,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:05:46<3:37:30,  3.38s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.067922592163086, 'learning_rate': 3.270338983050847e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:05:46<3:37:30,  3.38s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:05:50<3:39:55,  3.42s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.41193363070487976, 'learning_rate': 3.269491525423729e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:05:50<3:39:55,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:05:53<3:46:20,  3.52s/it]                                                       {'loss': 0.0258, 'grad_norm': 1.9447851181030273, 'learning_rate': 3.26864406779661e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:05:53<3:46:20,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:05:57<3:43:42,  3.48s/it]                                                       {'loss': 0.1452, 'grad_norm': 4.1939592361450195, 'learning_rate': 3.267796610169492e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:05:57<3:43:42,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:06:00<3:42:32,  3.46s/it]                                                       {'loss': 0.1557, 'grad_norm': 4.262387275695801, 'learning_rate': 3.266949152542373e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:06:00<3:42:32,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:06:04<3:41:04,  3.44s/it]                                                       {'loss': 0.0822, 'grad_norm': 4.914941787719727, 'learning_rate': 3.266101694915254e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:06:04<3:41:04,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:06:07<3:39:31,  3.42s/it]                                                       {'loss': 0.0489, 'grad_norm': 2.282684564590454, 'learning_rate': 3.265254237288135e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:06:07<3:39:31,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:06:11<3:41:16,  3.45s/it]                                                       {'loss': 0.3664, 'grad_norm': 5.985877513885498, 'learning_rate': 3.264406779661017e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:06:11<3:41:16,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:06:14<3:40:22,  3.43s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.07798146456480026, 'learning_rate': 3.263559322033898e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:06:14<3:40:22,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:06:17<3:39:47,  3.43s/it]                                                       {'loss': 0.2, 'grad_norm': 4.159035682678223, 'learning_rate': 3.26271186440678e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:06:17<3:39:47,  3.43s/it][2025-10-21 03:30:40,073] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:06:24<4:33:13,  4.26s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.48886367678642273, 'learning_rate': 3.261864406779661e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:06:24<4:33:13,  4.26s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:06:27<4:16:07,  3.99s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.06487588584423065, 'learning_rate': 3.261016949152543e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:06:27<4:16:07,  3.99s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:06:30<4:04:40,  3.82s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.5451189279556274, 'learning_rate': 3.260169491525424e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:06:30<4:04:40,  3.82s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:06:34<3:58:30,  3.72s/it]                                                       {'loss': 0.0084, 'grad_norm': 0.9874669313430786, 'learning_rate': 3.259322033898305e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:06:34<3:58:30,  3.72s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:06:37<3:52:24,  3.63s/it]                                                       {'loss': 0.0067, 'grad_norm': 0.615405797958374, 'learning_rate': 3.2584745762711864e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:06:37<3:52:24,  3.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:06:41<3:47:42,  3.55s/it]                                                       {'loss': 0.1435, 'grad_norm': 4.791515350341797, 'learning_rate': 3.257627118644068e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:06:41<3:47:42,  3.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:06:44<3:45:15,  3.52s/it]                                                       {'loss': 0.0184, 'grad_norm': 1.1143145561218262, 'learning_rate': 3.256779661016949e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:06:44<3:45:15,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:06:47<3:41:58,  3.47s/it]                                                       {'loss': 0.0775, 'grad_norm': 3.2299766540527344, 'learning_rate': 3.2559322033898305e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:06:47<3:41:58,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:06:51<3:41:05,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.1534121334552765, 'learning_rate': 3.255084745762712e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:06:51<3:41:05,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:06:54<3:39:17,  3.43s/it]                                                       {'loss': 0.0181, 'grad_norm': 1.4849265813827515, 'learning_rate': 3.2542372881355934e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:06:54<3:39:17,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:06:58<3:39:03,  3.42s/it]                                                       {'loss': 0.0252, 'grad_norm': 2.368288993835449, 'learning_rate': 3.2533898305084745e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:06:58<3:39:03,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:07:01<3:36:45,  3.39s/it]                                                       {'loss': 0.141, 'grad_norm': 5.606955051422119, 'learning_rate': 3.2525423728813557e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:07:01<3:36:45,  3.39s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:07:05<3:46:15,  3.54s/it]                                                       {'loss': 0.103, 'grad_norm': 4.062215328216553, 'learning_rate': 3.2516949152542375e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:07:05<3:46:15,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:07:08<3:41:50,  3.47s/it]                                                       {'loss': 0.0787, 'grad_norm': 3.060213327407837, 'learning_rate': 3.2508474576271186e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:07:08<3:41:50,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:07:11<3:40:31,  3.45s/it]                                                       {'loss': 0.0173, 'grad_norm': 0.7938633561134338, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:07:11<3:40:31,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:07:15<3:38:49,  3.42s/it]                                                       {'loss': 0.2838, 'grad_norm': 5.827281475067139, 'learning_rate': 3.2491525423728815e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:07:15<3:38:49,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:07:18<3:40:46,  3.46s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.26275870203971863, 'learning_rate': 3.248305084745763e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:07:18<3:40:46,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:07:22<3:39:55,  3.44s/it]                                                       {'loss': 0.0084, 'grad_norm': 0.4785870611667633, 'learning_rate': 3.247457627118644e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:07:22<3:39:55,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:07:25<3:37:57,  3.41s/it]                                                       {'loss': 0.0153, 'grad_norm': 1.5273255109786987, 'learning_rate': 3.2466101694915256e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:07:25<3:37:57,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:07:29<3:37:22,  3.41s/it]                                                       {'loss': 0.0379, 'grad_norm': 1.8800280094146729, 'learning_rate': 3.245762711864407e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:07:29<3:37:22,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:07:32<3:37:00,  3.40s/it]                                                       {'loss': 0.0564, 'grad_norm': 1.7742449045181274, 'learning_rate': 3.2449152542372885e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:07:32<3:37:00,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:07:36<3:41:19,  3.47s/it]                                                       {'loss': 0.0236, 'grad_norm': 1.0258556604385376, 'learning_rate': 3.2440677966101696e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:07:36<3:41:19,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:07:39<3:39:21,  3.44s/it]                                                       {'loss': 0.0396, 'grad_norm': 3.51977276802063, 'learning_rate': 3.2432203389830515e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:07:39<3:39:21,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:07:42<3:42:10,  3.48s/it]                                                       {'loss': 0.0582, 'grad_norm': 2.919891595840454, 'learning_rate': 3.2423728813559326e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:07:42<3:42:10,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:07:46<3:42:28,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06547165662050247, 'learning_rate': 3.241525423728814e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:07:46<3:42:28,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:07:49<3:40:45,  3.46s/it]                                                       {'loss': 0.1229, 'grad_norm': 4.555552959442139, 'learning_rate': 3.240677966101695e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:07:49<3:40:45,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:07:53<3:37:21,  3.41s/it]                                                       {'loss': 0.0839, 'grad_norm': 4.836875915527344, 'learning_rate': 3.2398305084745766e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:07:53<3:37:21,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:07:56<3:40:02,  3.45s/it]                                                       {'loss': 0.0484, 'grad_norm': 2.8375420570373535, 'learning_rate': 3.238983050847458e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:07:56<3:40:02,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:08:00<3:38:13,  3.43s/it]                                                       {'loss': 0.1198, 'grad_norm': 3.4747729301452637, 'learning_rate': 3.238135593220339e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:08:00<3:38:13,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:08:03<3:36:57,  3.41s/it]                                                       {'loss': 0.049, 'grad_norm': 2.9282572269439697, 'learning_rate': 3.237288135593221e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:08:03<3:36:57,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:08:06<3:37:49,  3.42s/it]                                                       {'loss': 0.0228, 'grad_norm': 2.0028460025787354, 'learning_rate': 3.236440677966102e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:08:07<3:37:49,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:08:10<3:42:40,  3.50s/it]                                                       {'loss': 0.0565, 'grad_norm': 4.049853324890137, 'learning_rate': 3.235593220338983e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:08:10<3:42:40,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:08:14<3:52:29,  3.65s/it]                                                       {'loss': 0.0087, 'grad_norm': 0.8068611025810242, 'learning_rate': 3.234745762711864e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:08:14<3:52:29,  3.65s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:08:18<3:47:56,  3.58s/it]                                                       {'loss': 0.0492, 'grad_norm': 1.976288914680481, 'learning_rate': 3.233898305084746e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:08:18<3:47:56,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:08:21<3:44:14,  3.53s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.4424402117729187, 'learning_rate': 3.233050847457627e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:08:21<3:44:14,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:08:25<3:47:29,  3.58s/it]                                                       {'loss': 0.0986, 'grad_norm': 4.964450359344482, 'learning_rate': 3.232203389830509e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:08:25<3:47:29,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:08:28<3:51:16,  3.64s/it]                                                       {'loss': 0.0512, 'grad_norm': 3.8386290073394775, 'learning_rate': 3.23135593220339e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:08:28<3:51:16,  3.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:08:32<3:47:35,  3.58s/it]                                                       {'loss': 0.1742, 'grad_norm': 4.828569412231445, 'learning_rate': 3.230508474576272e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:08:32<3:47:35,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:08:35<3:43:50,  3.52s/it]                                                       {'loss': 0.1345, 'grad_norm': 5.361538410186768, 'learning_rate': 3.229661016949153e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:08:35<3:43:50,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:08:39<3:42:43,  3.51s/it]                                                       {'loss': 0.0181, 'grad_norm': 1.1173175573349, 'learning_rate': 3.228813559322034e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:08:39<3:42:43,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:08:42<3:40:30,  3.47s/it]                                                       {'loss': 0.2975, 'grad_norm': 5.7590179443359375, 'learning_rate': 3.227966101694915e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:08:42<3:40:30,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:08:46<3:39:53,  3.46s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.19357453286647797, 'learning_rate': 3.227118644067797e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:08:46<3:39:53,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:08:49<3:37:22,  3.43s/it]                                                       {'loss': 0.1905, 'grad_norm': 3.990302324295044, 'learning_rate': 3.226271186440678e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:08:49<3:37:22,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:08:52<3:39:30,  3.46s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2266465425491333, 'learning_rate': 3.22542372881356e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:08:52<3:39:30,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:08:56<3:37:54,  3.44s/it]                                                       {'loss': 0.062, 'grad_norm': 2.6215150356292725, 'learning_rate': 3.224576271186441e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:08:56<3:37:54,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:08:59<3:38:47,  3.45s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.350121408700943, 'learning_rate': 3.223728813559322e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:08:59<3:38:47,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:09:03<3:35:22,  3.40s/it]                                                       {'loss': 0.014, 'grad_norm': 1.0988824367523193, 'learning_rate': 3.222881355932203e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:09:03<3:35:22,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:09:06<3:35:13,  3.40s/it]                                                       {'loss': 0.0437, 'grad_norm': 2.4239823818206787, 'learning_rate': 3.222033898305085e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:09:06<3:35:13,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:09:09<3:36:45,  3.42s/it]                                                       {'loss': 0.2885, 'grad_norm': 7.111443042755127, 'learning_rate': 3.221186440677966e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:09:09<3:36:45,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:09:13<3:43:45,  3.53s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.21480484306812286, 'learning_rate': 3.2203389830508473e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:09:13<3:43:45,  3.53s/it][2025-10-21 03:33:35,989] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:09:19<4:22:56,  4.15s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.20623448491096497, 'learning_rate': 3.219491525423729e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:09:19<4:22:56,  4.15s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:09:22<4:08:20,  3.92s/it]                                                       {'loss': 0.1261, 'grad_norm': 2.717097759246826, 'learning_rate': 3.21864406779661e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:09:22<4:08:20,  3.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:09:26<4:00:12,  3.80s/it]                                                       {'loss': 0.0297, 'grad_norm': 2.4965851306915283, 'learning_rate': 3.2177966101694914e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:09:26<4:00:12,  3.80s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:09:29<3:53:10,  3.69s/it]                                                       {'loss': 0.1207, 'grad_norm': 5.928565979003906, 'learning_rate': 3.2169491525423725e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:09:29<3:53:10,  3.69s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:09:33<3:48:19,  3.61s/it]                                                       {'loss': 0.017, 'grad_norm': 2.965651750564575, 'learning_rate': 3.2161016949152543e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:09:33<3:48:19,  3.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:09:37<4:02:28,  3.83s/it]                                                       {'loss': 0.1316, 'grad_norm': 3.3187754154205322, 'learning_rate': 3.2152542372881355e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:09:37<4:02:28,  3.83s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:09:40<3:55:10,  3.72s/it]                                                       {'loss': 0.0335, 'grad_norm': 2.060500144958496, 'learning_rate': 3.214406779661017e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:09:40<3:55:10,  3.72s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:09:44<3:51:05,  3.66s/it]                                                       {'loss': 0.5196, 'grad_norm': 6.397294998168945, 'learning_rate': 3.2135593220338984e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:09:44<3:51:05,  3.66s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:09:47<3:46:52,  3.59s/it]                                                       {'loss': 0.0748, 'grad_norm': 4.229022979736328, 'learning_rate': 3.21271186440678e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:09:47<3:46:52,  3.59s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:09:51<3:43:59,  3.55s/it]                                                       {'loss': 0.0701, 'grad_norm': 3.5317301750183105, 'learning_rate': 3.2118644067796613e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:09:51<3:43:59,  3.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:09:54<3:40:53,  3.50s/it]                                                       {'loss': 0.0148, 'grad_norm': 0.8286745548248291, 'learning_rate': 3.2110169491525425e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:09:54<3:40:53,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:09:58<3:44:04,  3.55s/it]                                                       {'loss': 0.0172, 'grad_norm': 1.436149001121521, 'learning_rate': 3.2101694915254236e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:09:58<3:44:04,  3.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:10:01<3:41:29,  3.51s/it]                                                       {'loss': 0.1117, 'grad_norm': 4.334033489227295, 'learning_rate': 3.2093220338983054e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:10:01<3:41:29,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:10:05<3:38:19,  3.46s/it]                                                       {'loss': 0.0596, 'grad_norm': 2.917799472808838, 'learning_rate': 3.2084745762711865e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:10:05<3:38:19,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:10:08<3:37:29,  3.45s/it]                                                       {'loss': 0.059, 'grad_norm': 4.0474138259887695, 'learning_rate': 3.2076271186440683e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:10:08<3:37:29,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:10:12<3:40:18,  3.49s/it]                                                       {'loss': 0.0939, 'grad_norm': 4.182569980621338, 'learning_rate': 3.2067796610169495e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:10:12<3:40:18,  3.49s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:10:15<3:39:37,  3.48s/it]                                                       {'loss': 0.2591, 'grad_norm': 4.965479373931885, 'learning_rate': 3.2059322033898306e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:10:15<3:39:37,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:10:19<3:39:19,  3.48s/it]                                                       {'loss': 0.2134, 'grad_norm': 5.146154880523682, 'learning_rate': 3.205084745762712e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:10:19<3:39:19,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:10:22<3:38:38,  3.47s/it]                                                       {'loss': 0.0123, 'grad_norm': 0.4987744688987732, 'learning_rate': 3.2042372881355935e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:10:22<3:38:38,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:10:25<3:37:39,  3.45s/it]                                                       {'loss': 0.0419, 'grad_norm': 3.0642929077148438, 'learning_rate': 3.203389830508475e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:10:25<3:37:39,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:10:29<3:37:58,  3.46s/it]                                                       {'loss': 0.0164, 'grad_norm': 1.0732078552246094, 'learning_rate': 3.202542372881356e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:10:29<3:37:58,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:10:33<3:41:06,  3.51s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.5326559543609619, 'learning_rate': 3.2016949152542376e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:10:33<3:41:06,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:10:36<3:42:21,  3.53s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.11990195512771606, 'learning_rate': 3.200847457627119e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:10:36<3:42:21,  3.53s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:10:39<3:38:40,  3.47s/it]                                                       {'loss': 0.0119, 'grad_norm': 0.7850678563117981, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:10:39<3:38:40,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:10:43<3:36:47,  3.45s/it]                                                       {'loss': 0.0223, 'grad_norm': 1.7062044143676758, 'learning_rate': 3.199152542372881e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:10:43<3:36:47,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:10:46<3:33:55,  3.40s/it]                                                       {'loss': 0.1473, 'grad_norm': 5.056212425231934, 'learning_rate': 3.198305084745763e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:10:46<3:33:55,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:10:50<3:33:30,  3.40s/it]                                                       {'loss': 0.055, 'grad_norm': 3.1462790966033936, 'learning_rate': 3.197457627118644e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:10:50<3:33:30,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:10:53<3:35:52,  3.43s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.27736490964889526, 'learning_rate': 3.196610169491526e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:10:53<3:35:52,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:10:56<3:34:19,  3.41s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.1106274127960205, 'learning_rate': 3.195762711864407e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:10:56<3:34:19,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:11:00<3:41:22,  3.52s/it]                                                       {'loss': 0.049, 'grad_norm': 2.8593153953552246, 'learning_rate': 3.1949152542372887e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:11:00<3:41:22,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:11:04<3:40:36,  3.51s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.4513757824897766, 'learning_rate': 3.19406779661017e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:11:04<3:40:36,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:11:07<3:40:36,  3.51s/it]                                                       {'loss': 0.1357, 'grad_norm': 4.4116950035095215, 'learning_rate': 3.193220338983051e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:11:07<3:40:36,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:11:11<3:37:44,  3.47s/it]                                                       {'loss': 0.0652, 'grad_norm': 3.2018043994903564, 'learning_rate': 3.192372881355932e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:11:11<3:37:44,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:11:14<3:44:40,  3.58s/it]                                                       {'loss': 0.0597, 'grad_norm': 2.2974934577941895, 'learning_rate': 3.191525423728814e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:11:14<3:44:40,  3.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:11:18<3:40:27,  3.51s/it]                                                       {'loss': 0.2294, 'grad_norm': 6.2785844802856445, 'learning_rate': 3.190677966101695e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:11:18<3:40:27,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:11:21<3:38:17,  3.48s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.08391430228948593, 'learning_rate': 3.189830508474577e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:11:21<3:38:17,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:11:25<3:38:13,  3.48s/it]                                                       {'loss': 0.2183, 'grad_norm': 5.038248062133789, 'learning_rate': 3.188983050847458e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:11:25<3:38:13,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:11:28<3:37:01,  3.46s/it]                                                       {'loss': 0.0233, 'grad_norm': 1.9385757446289062, 'learning_rate': 3.18813559322034e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:11:28<3:37:01,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:11:31<3:34:34,  3.42s/it]                                                       {'loss': 0.0774, 'grad_norm': 4.658515930175781, 'learning_rate': 3.18728813559322e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:11:31<3:34:34,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:11:35<3:34:00,  3.41s/it]                                                       {'loss': 0.0885, 'grad_norm': 3.658780574798584, 'learning_rate': 3.186440677966101e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:11:35<3:34:00,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:11:38<3:32:54,  3.40s/it]                                                       {'loss': 0.0102, 'grad_norm': 0.7290281057357788, 'learning_rate': 3.185593220338983e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:11:38<3:32:54,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:11:42<3:40:16,  3.52s/it]                                                       {'loss': 0.013, 'grad_norm': 1.5483479499816895, 'learning_rate': 3.184745762711864e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:11:42<3:40:16,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:11:45<3:36:30,  3.46s/it]                                                       {'loss': 0.0103, 'grad_norm': 0.7615971565246582, 'learning_rate': 3.183898305084746e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:11:45<3:36:30,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:11:49<3:34:25,  3.43s/it]                                                       {'loss': 0.1968, 'grad_norm': 5.016439914703369, 'learning_rate': 3.183050847457627e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:11:49<3:34:25,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:11:52<3:35:56,  3.45s/it]                                                       {'loss': 0.0569, 'grad_norm': 3.1820411682128906, 'learning_rate': 3.182203389830509e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:11:52<3:35:56,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:11:55<3:33:03,  3.41s/it]                                                       {'loss': 0.0294, 'grad_norm': 1.6038938760757446, 'learning_rate': 3.18135593220339e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:11:55<3:33:03,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:11:59<3:34:16,  3.43s/it]                                                       {'loss': 0.0707, 'grad_norm': 3.329655408859253, 'learning_rate': 3.180508474576271e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:11:59<3:34:16,  3.43s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:12:02<3:32:51,  3.40s/it]                                                       {'loss': 0.0636, 'grad_norm': 1.8968931436538696, 'learning_rate': 3.1796610169491524e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:12:02<3:32:51,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:12:06<3:41:31,  3.54s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.14436838030815125, 'learning_rate': 3.178813559322034e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:12:06<3:41:31,  3.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:12:10<3:39:25,  3.51s/it]                                                       {'loss': 0.0253, 'grad_norm': 2.137026071548462, 'learning_rate': 3.177966101694915e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:12:10<3:39:25,  3.51s/it][2025-10-21 03:36:32,267] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:12:15<4:18:05,  4.13s/it]                                                       {'loss': 0.1465, 'grad_norm': 7.230607032775879, 'learning_rate': 3.177118644067797e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:12:15<4:18:05,  4.13s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:12:18<4:03:04,  3.89s/it]                                                       {'loss': 0.034, 'grad_norm': 2.385072946548462, 'learning_rate': 3.176271186440678e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:12:18<4:03:04,  3.89s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:12:22<3:52:58,  3.73s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.0082484483718872, 'learning_rate': 3.1754237288135594e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:12:22<3:52:58,  3.73s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:12:26<4:03:47,  3.90s/it]                                                       {'loss': 0.0579, 'grad_norm': 2.7224953174591064, 'learning_rate': 3.1745762711864405e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:12:26<4:03:47,  3.90s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:12:29<3:53:57,  3.75s/it]                                                       {'loss': 0.0698, 'grad_norm': 3.477743148803711, 'learning_rate': 3.173728813559322e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:12:29<3:53:57,  3.75s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:12:33<3:46:37,  3.63s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.40315860509872437, 'learning_rate': 3.1728813559322034e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:12:33<3:46:37,  3.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:12:36<3:43:31,  3.58s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.10025033354759216, 'learning_rate': 3.172033898305085e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:12:36<3:43:31,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:12:40<3:39:19,  3.52s/it]                                                       {'loss': 0.016, 'grad_norm': 1.05767023563385, 'learning_rate': 3.1711864406779664e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:12:40<3:39:19,  3.52s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:12:43<3:36:41,  3.48s/it]                                                       {'loss': 0.1041, 'grad_norm': 3.910815715789795, 'learning_rate': 3.170338983050848e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:12:43<3:36:41,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:12:46<3:35:18,  3.45s/it]                                                       {'loss': 0.128, 'grad_norm': 4.236875534057617, 'learning_rate': 3.169491525423729e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:12:46<3:35:18,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:12:51<3:47:10,  3.65s/it]                                                       {'loss': 0.0206, 'grad_norm': 1.3321765661239624, 'learning_rate': 3.16864406779661e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:12:51<3:47:10,  3.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:12:54<3:43:37,  3.59s/it]                                                       {'loss': 0.0738, 'grad_norm': 1.6608248949050903, 'learning_rate': 3.1677966101694916e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:12:54<3:43:37,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:12:58<3:42:41,  3.58s/it]                                                       {'loss': 0.1509, 'grad_norm': 4.569046497344971, 'learning_rate': 3.166949152542373e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:12:58<3:42:41,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:13:01<3:47:21,  3.65s/it]                                                       {'loss': 0.0483, 'grad_norm': 3.7166004180908203, 'learning_rate': 3.1661016949152545e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:13:01<3:47:21,  3.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:13:05<3:45:21,  3.62s/it]                                                       {'loss': 0.0989, 'grad_norm': 3.478949546813965, 'learning_rate': 3.1652542372881356e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:13:05<3:45:21,  3.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:13:09<3:44:38,  3.61s/it]                                                       {'loss': 0.0668, 'grad_norm': 3.3244571685791016, 'learning_rate': 3.1644067796610174e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:13:09<3:44:38,  3.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:13:12<3:40:32,  3.54s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2377421259880066, 'learning_rate': 3.1635593220338985e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:13:12<3:40:32,  3.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:13:15<3:38:26,  3.51s/it]                                                       {'loss': 0.0165, 'grad_norm': 1.2394722700119019, 'learning_rate': 3.16271186440678e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:13:15<3:38:26,  3.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:13:19<3:36:12,  3.48s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.10507918894290924, 'learning_rate': 3.161864406779661e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:13:19<3:36:12,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:13:23<3:44:55,  3.62s/it]                                                       {'loss': 0.0272, 'grad_norm': 2.0133986473083496, 'learning_rate': 3.1610169491525426e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:13:23<3:44:55,  3.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:13:26<3:41:27,  3.56s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.2714771032333374, 'learning_rate': 3.160169491525424e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:13:26<3:41:27,  3.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:13:29<3:37:34,  3.50s/it]                                                       {'loss': 0.0695, 'grad_norm': 3.7721168994903564, 'learning_rate': 3.1593220338983055e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:13:29<3:37:34,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:13:33<3:35:35,  3.47s/it]                                                       {'loss': 0.052, 'grad_norm': 2.6554625034332275, 'learning_rate': 3.158474576271187e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:13:33<3:35:35,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:13:36<3:36:49,  3.49s/it]                                                       {'loss': 0.0768, 'grad_norm': 4.641812324523926, 'learning_rate': 3.157627118644068e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:13:36<3:36:49,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:13:40<3:36:39,  3.49s/it]                                                       {'loss': 0.0936, 'grad_norm': 3.995556354522705, 'learning_rate': 3.156779661016949e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:13:40<3:36:39,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:13:43<3:37:54,  3.51s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.18815381824970245, 'learning_rate': 3.155932203389831e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:13:43<3:37:54,  3.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:13:47<3:34:59,  3.46s/it]                                                       {'loss': 0.082, 'grad_norm': 4.042109966278076, 'learning_rate': 3.155084745762712e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:13:47<3:34:59,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:13:50<3:32:05,  3.42s/it]                                                       {'loss': 0.0665, 'grad_norm': 3.909090280532837, 'learning_rate': 3.154237288135594e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:13:50<3:32:05,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:13:53<3:29:52,  3.38s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.3606091737747192, 'learning_rate': 3.153389830508475e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:13:53<3:29:52,  3.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:13:57<3:31:44,  3.42s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.18909987807273865, 'learning_rate': 3.1525423728813566e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:13:57<3:31:44,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:14:00<3:30:21,  3.39s/it]                                                       {'loss': 0.0924, 'grad_norm': 3.826326608657837, 'learning_rate': 3.151694915254238e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:14:00<3:30:21,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:14:04<3:30:18,  3.39s/it]                                                       {'loss': 0.0437, 'grad_norm': 3.0813710689544678, 'learning_rate': 3.150847457627118e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:14:04<3:30:18,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:14:07<3:29:32,  3.38s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.16661104559898376, 'learning_rate': 3.15e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:14:07<3:29:32,  3.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:14:10<3:30:06,  3.39s/it]                                                       {'loss': 0.0363, 'grad_norm': 2.299678087234497, 'learning_rate': 3.149152542372881e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:14:10<3:30:06,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:14:14<3:30:01,  3.39s/it]                                                       {'loss': 0.1337, 'grad_norm': 5.288541793823242, 'learning_rate': 3.148305084745763e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:14:14<3:30:01,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:14:17<3:30:10,  3.40s/it]                                                       {'loss': 0.188, 'grad_norm': 5.685996055603027, 'learning_rate': 3.147457627118644e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:14:17<3:30:10,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:14:21<3:33:57,  3.46s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.0473875999450684, 'learning_rate': 3.146610169491526e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:14:21<3:33:57,  3.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:14:24<3:32:42,  3.44s/it]                                                       {'loss': 0.0958, 'grad_norm': 3.4228007793426514, 'learning_rate': 3.145762711864407e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:14:24<3:32:42,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:14:28<3:31:47,  3.42s/it]                                                       {'loss': 0.1793, 'grad_norm': 3.196276903152466, 'learning_rate': 3.144915254237288e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:14:28<3:31:47,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:14:31<3:38:33,  3.53s/it]                                                       {'loss': 0.0605, 'grad_norm': 3.331467390060425, 'learning_rate': 3.144067796610169e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:14:31<3:38:33,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:14:35<3:34:15,  3.47s/it]                                                       {'loss': 0.0219, 'grad_norm': 1.8115830421447754, 'learning_rate': 3.143220338983051e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:14:35<3:34:15,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:14:38<3:31:54,  3.43s/it]                                                       {'loss': 0.0256, 'grad_norm': 1.7482563257217407, 'learning_rate': 3.142372881355932e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:14:38<3:31:54,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:14:41<3:30:53,  3.41s/it]                                                       {'loss': 0.1245, 'grad_norm': 1.980194091796875, 'learning_rate': 3.141525423728814e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:14:41<3:30:53,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:14:45<3:32:03,  3.43s/it]                                                       {'loss': 0.0188, 'grad_norm': 0.9363498687744141, 'learning_rate': 3.140677966101695e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:14:45<3:32:03,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:14:48<3:32:15,  3.44s/it]                                                       {'loss': 0.0187, 'grad_norm': 1.1311770677566528, 'learning_rate': 3.139830508474577e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:14:48<3:32:15,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:14:52<3:35:56,  3.50s/it]                                                       {'loss': 0.1964, 'grad_norm': 4.775588512420654, 'learning_rate': 3.1389830508474574e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:14:52<3:35:56,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:14:56<3:40:47,  3.58s/it]                                                       {'loss': 0.0097, 'grad_norm': 0.5042230486869812, 'learning_rate': 3.138135593220339e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:14:56<3:40:47,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:15:00<3:54:29,  3.80s/it]                                                       {'loss': 0.0154, 'grad_norm': 1.5301268100738525, 'learning_rate': 3.13728813559322e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:15:00<3:54:29,  3.80s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:15:04<3:47:28,  3.69s/it]                                                       {'loss': 0.0526, 'grad_norm': 2.109185218811035, 'learning_rate': 3.136440677966102e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:15:04<3:47:28,  3.69s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:15:07<3:41:27,  3.59s/it]                                                       {'loss': 0.0571, 'grad_norm': 2.5416431427001953, 'learning_rate': 3.135593220338983e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:15:07<3:41:27,  3.59s/it][2025-10-21 03:39:29,624] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:15:12<4:18:51,  4.20s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.0182784516364336, 'learning_rate': 3.134745762711865e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:15:12<4:18:51,  4.20s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:15:16<4:01:46,  3.92s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.5162886381149292, 'learning_rate': 3.133898305084746e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:15:16<4:01:46,  3.92s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:15:19<3:50:46,  3.75s/it]                                                       {'loss': 0.0287, 'grad_norm': 1.7589012384414673, 'learning_rate': 3.133050847457627e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:15:19<3:50:46,  3.75s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:15:22<3:44:10,  3.64s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.19891059398651123, 'learning_rate': 3.1322033898305084e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:15:22<3:44:10,  3.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:15:26<3:41:47,  3.60s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.4947475790977478, 'learning_rate': 3.1313559322033896e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:15:26<3:41:47,  3.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:15:29<3:39:19,  3.56s/it]                                                       {'loss': 0.0174, 'grad_norm': 1.8308502435684204, 'learning_rate': 3.1305084745762714e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:15:29<3:39:19,  3.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:15:33<3:45:30,  3.66s/it]                                                       {'loss': 0.0246, 'grad_norm': 1.75318443775177, 'learning_rate': 3.1296610169491525e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:15:33<3:45:30,  3.66s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:15:37<3:40:53,  3.59s/it]                                                       {'loss': 0.0373, 'grad_norm': 1.8468947410583496, 'learning_rate': 3.128813559322034e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:15:37<3:40:53,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:15:40<3:37:12,  3.53s/it]                                                       {'loss': 0.4261, 'grad_norm': 32.903236389160156, 'learning_rate': 3.1279661016949154e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:15:40<3:37:12,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:15:44<3:34:20,  3.49s/it]                                                       {'loss': 0.2085, 'grad_norm': 5.845301628112793, 'learning_rate': 3.1271186440677966e-05, 'epoch': 0.39}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:15:44<3:34:20,  3.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:15:47<3:32:23,  3.45s/it]                                                       {'loss': 0.0187, 'grad_norm': 0.941127598285675, 'learning_rate': 3.126271186440678e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:15:47<3:32:23,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:15:50<3:30:47,  3.43s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.29965782165527344, 'learning_rate': 3.1254237288135595e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:15:50<3:30:47,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:15:54<3:30:04,  3.42s/it]                                                       {'loss': 0.0391, 'grad_norm': 2.1255404949188232, 'learning_rate': 3.1245762711864406e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:15:54<3:30:04,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:15:57<3:29:36,  3.41s/it]                                                       {'loss': 0.0469, 'grad_norm': 1.8753434419631958, 'learning_rate': 3.1237288135593224e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:15:57<3:29:36,  3.41s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:16:01<3:29:47,  3.42s/it]                                                       {'loss': 0.0328, 'grad_norm': 2.115427017211914, 'learning_rate': 3.1228813559322036e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:16:01<3:29:47,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:16:04<3:28:08,  3.39s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.5197909474372864, 'learning_rate': 3.1220338983050854e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:16:04<3:28:08,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:16:07<3:26:30,  3.36s/it]                                                       {'loss': 0.3319, 'grad_norm': 6.5511016845703125, 'learning_rate': 3.1211864406779665e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:16:07<3:26:30,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:16:10<3:25:42,  3.35s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.4810951352119446, 'learning_rate': 3.1203389830508476e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:16:10<3:25:42,  3.35s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:16:14<3:26:55,  3.37s/it]                                                       {'loss': 0.12, 'grad_norm': 3.4186244010925293, 'learning_rate': 3.119491525423729e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:16:14<3:26:55,  3.37s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:16:17<3:28:43,  3.40s/it]                                                       {'loss': 0.1137, 'grad_norm': 4.0179009437561035, 'learning_rate': 3.1186440677966106e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:16:17<3:28:43,  3.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:16:21<3:27:43,  3.39s/it]                                                       {'loss': 0.1249, 'grad_norm': 4.893483638763428, 'learning_rate': 3.117796610169492e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:16:21<3:27:43,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:16:24<3:26:16,  3.37s/it]                                                       {'loss': 0.0279, 'grad_norm': 1.9915876388549805, 'learning_rate': 3.1169491525423735e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:16:24<3:26:16,  3.37s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:16:28<3:27:55,  3.39s/it]                                                       {'loss': 0.1579, 'grad_norm': 5.3991570472717285, 'learning_rate': 3.1161016949152546e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:16:28<3:27:55,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:16:31<3:30:22,  3.43s/it]                                                       {'loss': 0.0668, 'grad_norm': 3.3912250995635986, 'learning_rate': 3.115254237288136e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:16:31<3:30:22,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:16:34<3:29:13,  3.42s/it]                                                       {'loss': 0.0228, 'grad_norm': 1.0668936967849731, 'learning_rate': 3.114406779661017e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:16:34<3:29:13,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:16:38<3:28:18,  3.40s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.27591001987457275, 'learning_rate': 3.113559322033898e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:16:38<3:28:18,  3.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:16:41<3:26:46,  3.38s/it]                                                       {'loss': 0.0431, 'grad_norm': 3.2001402378082275, 'learning_rate': 3.11271186440678e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:16:41<3:26:46,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:16:44<3:26:26,  3.37s/it]                                                       {'loss': 0.206, 'grad_norm': 5.71859073638916, 'learning_rate': 3.111864406779661e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:16:44<3:26:26,  3.37s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:16:50<3:57:25,  3.88s/it]                                                       {'loss': 0.0769, 'grad_norm': 4.760926246643066, 'learning_rate': 3.111016949152543e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:16:50<3:57:25,  3.88s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:16:53<3:46:49,  3.71s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.24254101514816284, 'learning_rate': 3.110169491525424e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:16:53<3:46:49,  3.71s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:16:56<3:40:38,  3.61s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.06250175833702087, 'learning_rate': 3.109322033898305e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:16:56<3:40:38,  3.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:17:00<3:35:58,  3.53s/it]                                                       {'loss': 0.0671, 'grad_norm': 3.621802568435669, 'learning_rate': 3.108474576271186e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:17:00<3:35:58,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:17:03<3:32:16,  3.47s/it]                                                       {'loss': 0.046, 'grad_norm': 3.5871920585632324, 'learning_rate': 3.107627118644068e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:17:03<3:32:16,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:17:06<3:30:42,  3.45s/it]                                                       {'loss': 0.081, 'grad_norm': 3.066730260848999, 'learning_rate': 3.106779661016949e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:17:06<3:30:42,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:17:10<3:29:17,  3.43s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2636941075325012, 'learning_rate': 3.105932203389831e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:17:10<3:29:17,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:17:13<3:28:54,  3.42s/it]                                                       {'loss': 0.1536, 'grad_norm': 3.562675714492798, 'learning_rate': 3.105084745762712e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:17:13<3:28:54,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:17:17<3:34:56,  3.52s/it]                                                       {'loss': 0.1012, 'grad_norm': 6.067956924438477, 'learning_rate': 3.104237288135594e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:17:17<3:34:56,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:17:21<3:41:27,  3.63s/it]                                                       {'loss': 0.0342, 'grad_norm': 1.5304547548294067, 'learning_rate': 3.103389830508475e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:17:21<3:41:27,  3.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:17:24<3:36:39,  3.55s/it]                                                       {'loss': 0.0214, 'grad_norm': 1.314851999282837, 'learning_rate': 3.102542372881356e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:17:24<3:36:39,  3.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:17:27<3:33:32,  3.50s/it]                                                       {'loss': 0.0443, 'grad_norm': 2.5861120223999023, 'learning_rate': 3.101694915254237e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:17:27<3:33:32,  3.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:17:31<3:29:55,  3.44s/it]                                                       {'loss': 0.0591, 'grad_norm': 2.8166720867156982, 'learning_rate': 3.100847457627119e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:17:31<3:29:55,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:17:35<3:38:53,  3.59s/it]                                                       {'loss': 0.0213, 'grad_norm': 2.4792308807373047, 'learning_rate': 3.1e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:17:35<3:38:53,  3.59s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:17:38<3:35:08,  3.53s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.14218224585056305, 'learning_rate': 3.099152542372882e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:17:38<3:35:08,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:17:42<3:34:03,  3.51s/it]                                                       {'loss': 0.0223, 'grad_norm': 2.6126370429992676, 'learning_rate': 3.098305084745763e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:17:42<3:34:03,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:17:45<3:33:41,  3.51s/it]                                                       {'loss': 0.0066, 'grad_norm': 0.7052715420722961, 'learning_rate': 3.097457627118644e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:17:45<3:33:41,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:17:48<3:31:38,  3.48s/it]                                                       {'loss': 0.4797, 'grad_norm': 7.426975250244141, 'learning_rate': 3.096610169491525e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:17:48<3:31:38,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:17:52<3:31:55,  3.48s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.38776856660842896, 'learning_rate': 3.0957627118644065e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:17:52<3:31:55,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:17:55<3:29:10,  3.44s/it]                                                       {'loss': 0.024, 'grad_norm': 1.724354863166809, 'learning_rate': 3.094915254237288e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:17:55<3:29:10,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:17:59<3:34:15,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.0805356428027153, 'learning_rate': 3.0940677966101694e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:17:59<3:34:15,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:18:03<3:38:04,  3.58s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.2998632490634918, 'learning_rate': 3.093220338983051e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:18:03<3:38:04,  3.58s/it][2025-10-21 03:42:25,647] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:18:08<4:17:16,  4.23s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.36513641476631165, 'learning_rate': 3.092372881355932e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:18:08<4:17:16,  4.23s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:18:12<4:03:29,  4.00s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03260164335370064, 'learning_rate': 3.091525423728814e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:18:12<4:03:29,  4.00s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:18:16<4:00:12,  3.95s/it]                                                       {'loss': 0.197, 'grad_norm': 5.774930000305176, 'learning_rate': 3.0906779661016946e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:18:16<4:00:12,  3.95s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:18:19<3:53:12,  3.84s/it]                                                       {'loss': 0.1097, 'grad_norm': 4.884079456329346, 'learning_rate': 3.0898305084745764e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:18:19<3:53:12,  3.84s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:18:23<3:53:59,  3.85s/it]                                                       {'loss': 0.0546, 'grad_norm': 2.481224536895752, 'learning_rate': 3.0889830508474575e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:18:23<3:53:59,  3.85s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:18:27<3:53:29,  3.84s/it]                                                       {'loss': 0.1306, 'grad_norm': 5.13442850112915, 'learning_rate': 3.088135593220339e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:18:27<3:53:29,  3.84s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:18:31<3:46:29,  3.73s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.010028530843555927, 'learning_rate': 3.0872881355932205e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:18:31<3:46:29,  3.73s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:18:34<3:39:28,  3.62s/it]                                                       {'loss': 0.0211, 'grad_norm': 1.119652271270752, 'learning_rate': 3.086440677966102e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:18:34<3:39:28,  3.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:18:37<3:36:29,  3.57s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.937348484992981, 'learning_rate': 3.0855932203389834e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:18:37<3:36:29,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:18:41<3:37:22,  3.58s/it]                                                       {'loss': 0.0981, 'grad_norm': 4.121955394744873, 'learning_rate': 3.0847457627118645e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:18:41<3:37:22,  3.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:18:45<3:40:45,  3.64s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.04780634865164757, 'learning_rate': 3.0838983050847456e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:18:45<3:40:45,  3.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:18:48<3:36:21,  3.57s/it]                                                       {'loss': 0.0648, 'grad_norm': 2.851438522338867, 'learning_rate': 3.0830508474576275e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:18:48<3:36:21,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:18:52<3:35:05,  3.55s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.6578832268714905, 'learning_rate': 3.0822033898305086e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:18:52<3:35:05,  3.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:18:55<3:32:49,  3.51s/it]                                                       {'loss': 0.0562, 'grad_norm': 2.269688606262207, 'learning_rate': 3.0813559322033904e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:18:55<3:32:49,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:18:59<3:34:37,  3.54s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.05894145369529724, 'learning_rate': 3.0805084745762715e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:18:59<3:34:37,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:19:02<3:31:45,  3.50s/it]                                                       {'loss': 0.1249, 'grad_norm': 4.4298787117004395, 'learning_rate': 3.0796610169491526e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:19:02<3:31:45,  3.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:19:05<3:29:50,  3.47s/it]                                                       {'loss': 0.0387, 'grad_norm': 1.9865494966506958, 'learning_rate': 3.078813559322034e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:19:05<3:29:50,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:19:09<3:29:20,  3.46s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.06262792646884918, 'learning_rate': 3.077966101694915e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:19:09<3:29:20,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:19:12<3:29:41,  3.46s/it]                                                       {'loss': 0.0106, 'grad_norm': 0.9709938168525696, 'learning_rate': 3.077118644067797e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:19:12<3:29:41,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:19:16<3:27:51,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.04607725143432617, 'learning_rate': 3.076271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:19:16<3:27:51,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:19:19<3:26:15,  3.41s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.31208738684654236, 'learning_rate': 3.0754237288135596e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:19:19<3:26:15,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:19:23<3:26:25,  3.41s/it]                                                       {'loss': 0.2406, 'grad_norm': 7.469615459442139, 'learning_rate': 3.074576271186441e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:19:23<3:26:25,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:19:26<3:28:00,  3.44s/it]                                                       {'loss': 0.0671, 'grad_norm': 1.4661637544631958, 'learning_rate': 3.0737288135593226e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:19:26<3:28:00,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:19:29<3:27:28,  3.43s/it]                                                       {'loss': 0.0248, 'grad_norm': 1.4575189352035522, 'learning_rate': 3.072881355932204e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:19:29<3:27:28,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:19:33<3:27:47,  3.44s/it]                                                       {'loss': 0.1053, 'grad_norm': 4.555908203125, 'learning_rate': 3.072033898305085e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:19:33<3:27:47,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:19:36<3:27:29,  3.44s/it]                                                       {'loss': 0.048, 'grad_norm': 2.7433643341064453, 'learning_rate': 3.071186440677966e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:19:36<3:27:29,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:19:40<3:28:17,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.040587276220321655, 'learning_rate': 3.070338983050848e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:19:40<3:28:17,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:19:43<3:28:54,  3.46s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.08947192877531052, 'learning_rate': 3.069491525423729e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:19:43<3:28:54,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:19:47<3:27:51,  3.44s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.9406890869140625, 'learning_rate': 3.068644067796611e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:19:47<3:27:51,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:19:50<3:27:27,  3.44s/it]                                                       {'loss': 0.0515, 'grad_norm': 3.2215404510498047, 'learning_rate': 3.067796610169492e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:19:50<3:27:27,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:19:53<3:25:46,  3.41s/it]                                                       {'loss': 0.0082, 'grad_norm': 0.5858960151672363, 'learning_rate': 3.066949152542373e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:19:53<3:25:46,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:19:57<3:28:39,  3.46s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.24900507926940918, 'learning_rate': 3.066101694915254e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:19:57<3:28:39,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:20:00<3:26:49,  3.43s/it]                                                       {'loss': 0.0297, 'grad_norm': 2.676227331161499, 'learning_rate': 3.065254237288136e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:20:00<3:26:49,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:20:04<3:25:26,  3.41s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.06632011383771896, 'learning_rate': 3.064406779661017e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:20:04<3:25:26,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:20:07<3:24:24,  3.39s/it]                                                       {'loss': 0.2264, 'grad_norm': 6.761467456817627, 'learning_rate': 3.063559322033899e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:20:07<3:24:24,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:20:11<3:26:03,  3.42s/it]                                                       {'loss': 0.0093, 'grad_norm': 0.7821832299232483, 'learning_rate': 3.06271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:20:11<3:26:03,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:20:14<3:29:35,  3.48s/it]                                                       {'loss': 0.1043, 'grad_norm': 4.024728298187256, 'learning_rate': 3.061864406779661e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:20:14<3:29:35,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:20:18<3:29:35,  3.48s/it]                                                       {'loss': 0.2558, 'grad_norm': 5.512983798980713, 'learning_rate': 3.061016949152543e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:20:18<3:29:35,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:20:21<3:27:27,  3.45s/it]                                                       {'loss': 0.002, 'grad_norm': 0.16637997329235077, 'learning_rate': 3.0601694915254233e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:20:21<3:27:27,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:20:25<3:28:21,  3.46s/it]                                                       {'loss': 0.0097, 'grad_norm': 0.5629271268844604, 'learning_rate': 3.059322033898305e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:20:25<3:28:21,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:20:28<3:27:02,  3.44s/it]                                                       {'loss': 0.0167, 'grad_norm': 2.0810790061950684, 'learning_rate': 3.058474576271186e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:20:28<3:27:02,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:20:31<3:26:54,  3.44s/it]                                                       {'loss': 0.0505, 'grad_norm': 2.2255923748016357, 'learning_rate': 3.057627118644068e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:20:31<3:26:54,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:20:35<3:26:18,  3.43s/it]                                                       {'loss': 0.0386, 'grad_norm': 2.4938466548919678, 'learning_rate': 3.056779661016949e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:20:35<3:26:18,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:20:38<3:26:51,  3.44s/it]                                                       {'loss': 0.0569, 'grad_norm': 2.300487518310547, 'learning_rate': 3.055932203389831e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:20:38<3:26:51,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:20:42<3:24:48,  3.41s/it]                                                       {'loss': 0.0254, 'grad_norm': 2.0754611492156982, 'learning_rate': 3.055084745762712e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:20:42<3:24:48,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:20:45<3:29:59,  3.50s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.4549788534641266, 'learning_rate': 3.054237288135593e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:20:45<3:29:59,  3.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:20:49<3:30:16,  3.50s/it]                                                       {'loss': 0.0399, 'grad_norm': 2.4007229804992676, 'learning_rate': 3.0533898305084744e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:20:49<3:30:16,  3.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:20:52<3:28:33,  3.47s/it]                                                       {'loss': 0.0063, 'grad_norm': 0.9127558469772339, 'learning_rate': 3.052542372881356e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:20:52<3:28:33,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:20:56<3:26:58,  3.45s/it]                                                       {'loss': 0.065, 'grad_norm': 1.8440614938735962, 'learning_rate': 3.0516949152542373e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:20:56<3:26:58,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:20:59<3:25:52,  3.43s/it]                                                       {'loss': 0.0924, 'grad_norm': 5.429886817932129, 'learning_rate': 3.050847457627119e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:20:59<3:25:52,  3.43s/it][2025-10-21 03:45:21,763] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:21:05<4:04:06,  4.07s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.35703137516975403, 'learning_rate': 3.05e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:21:05<4:04:06,  4.07s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:21:08<3:56:20,  3.94s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11788567155599594, 'learning_rate': 3.0491525423728817e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:21:08<3:56:20,  3.94s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:21:12<3:45:41,  3.76s/it]                                                       {'loss': 0.1034, 'grad_norm': 4.464913368225098, 'learning_rate': 3.048305084745763e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:21:12<3:45:41,  3.76s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:21:15<3:39:02,  3.65s/it]                                                       {'loss': 0.0159, 'grad_norm': 0.5302000045776367, 'learning_rate': 3.0474576271186443e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:21:15<3:39:02,  3.65s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:21:18<3:34:45,  3.58s/it]                                                       {'loss': 0.0121, 'grad_norm': 0.9955978393554688, 'learning_rate': 3.0466101694915255e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:21:18<3:34:45,  3.58s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:21:22<3:32:04,  3.54s/it]                                                       {'loss': 0.0606, 'grad_norm': 3.29937481880188, 'learning_rate': 3.0457627118644066e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:21:22<3:32:04,  3.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:21:25<3:29:51,  3.50s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.4269235134124756, 'learning_rate': 3.0449152542372884e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:21:25<3:29:51,  3.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:21:29<3:28:06,  3.48s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.7610961198806763, 'learning_rate': 3.0440677966101695e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:21:29<3:28:06,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:21:32<3:25:10,  3.43s/it]                                                       {'loss': 0.1377, 'grad_norm': 5.095829486846924, 'learning_rate': 3.043220338983051e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:21:32<3:25:10,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:21:35<3:26:33,  3.45s/it]                                                       {'loss': 0.0556, 'grad_norm': 3.2790048122406006, 'learning_rate': 3.042372881355932e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:21:35<3:26:33,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:21:39<3:25:46,  3.44s/it]                                                       {'loss': 0.005, 'grad_norm': 0.4565567076206207, 'learning_rate': 3.041525423728814e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:21:39<3:25:46,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:21:42<3:28:11,  3.48s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.5881905555725098, 'learning_rate': 3.0406779661016947e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:21:42<3:28:11,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:21:46<3:26:27,  3.45s/it]                                                       {'loss': 0.0758, 'grad_norm': 3.3479907512664795, 'learning_rate': 3.0398305084745765e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:21:46<3:26:27,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:21:49<3:25:18,  3.44s/it]                                                       {'loss': 0.1589, 'grad_norm': 5.131464004516602, 'learning_rate': 3.0389830508474577e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:21:49<3:25:18,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:21:53<3:24:34,  3.42s/it]                                                       {'loss': 0.1641, 'grad_norm': 4.896758079528809, 'learning_rate': 3.038135593220339e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:21:53<3:24:34,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:21:56<3:24:20,  3.42s/it]                                                       {'loss': 0.0143, 'grad_norm': 0.9832442402839661, 'learning_rate': 3.0372881355932203e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:21:56<3:24:20,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:22:00<3:25:17,  3.44s/it]                                                       {'loss': 0.0249, 'grad_norm': 1.7470362186431885, 'learning_rate': 3.036440677966102e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:22:00<3:25:17,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:22:03<3:24:29,  3.43s/it]                                                       {'loss': 0.1661, 'grad_norm': 4.701324462890625, 'learning_rate': 3.0355932203389832e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:22:03<3:24:29,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:22:06<3:24:32,  3.43s/it]                                                       {'loss': 0.022, 'grad_norm': 1.2130024433135986, 'learning_rate': 3.0347457627118647e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:22:06<3:24:32,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:22:10<3:31:41,  3.55s/it]                                                       {'loss': 0.02, 'grad_norm': 1.4934985637664795, 'learning_rate': 3.0338983050847458e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:22:10<3:31:41,  3.55s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:22:14<3:29:23,  3.51s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.5855709314346313, 'learning_rate': 3.0330508474576276e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:22:14<3:29:23,  3.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:22:17<3:26:51,  3.47s/it]                                                       {'loss': 0.0084, 'grad_norm': 0.5388995409011841, 'learning_rate': 3.0322033898305087e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:22:17<3:26:51,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:22:20<3:25:00,  3.44s/it]                                                       {'loss': 0.092, 'grad_norm': 3.2177817821502686, 'learning_rate': 3.0313559322033902e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:22:20<3:25:00,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:22:24<3:24:22,  3.43s/it]                                                       {'loss': 0.2203, 'grad_norm': 6.608633995056152, 'learning_rate': 3.0305084745762713e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:22:24<3:24:22,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:22:27<3:27:04,  3.48s/it]                                                       {'loss': 0.0117, 'grad_norm': 1.3431799411773682, 'learning_rate': 3.0296610169491528e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:22:27<3:27:04,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:22:31<3:25:29,  3.45s/it]                                                       {'loss': 0.1222, 'grad_norm': 6.132616996765137, 'learning_rate': 3.028813559322034e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:22:31<3:25:29,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:22:34<3:25:44,  3.45s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.48252394795417786, 'learning_rate': 3.027966101694915e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:22:34<3:25:44,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:22:38<3:25:14,  3.45s/it]                                                       {'loss': 0.0583, 'grad_norm': 2.854801654815674, 'learning_rate': 3.027118644067797e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:22:38<3:25:14,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:22:41<3:26:13,  3.47s/it]                                                       {'loss': 0.0533, 'grad_norm': 4.578165531158447, 'learning_rate': 3.026271186440678e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:22:41<3:26:13,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:22:45<3:28:17,  3.50s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.6200196743011475, 'learning_rate': 3.0254237288135594e-05, 'epoch': 0.41}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:22:45<3:28:17,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:22:48<3:28:35,  3.51s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0026507105212658644, 'learning_rate': 3.0245762711864406e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:22:48<3:28:35,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:22:52<3:24:39,  3.44s/it]                                                       {'loss': 0.0944, 'grad_norm': 4.157861232757568, 'learning_rate': 3.0237288135593224e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:22:52<3:24:39,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:22:55<3:23:48,  3.43s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.10492097586393356, 'learning_rate': 3.0228813559322035e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:22:55<3:23:48,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:22:59<3:29:56,  3.53s/it]                                                       {'loss': 0.0089, 'grad_norm': 0.38861140608787537, 'learning_rate': 3.022033898305085e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:22:59<3:29:56,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:23:02<3:30:27,  3.54s/it]                                                       {'loss': 0.0432, 'grad_norm': 2.3051202297210693, 'learning_rate': 3.021186440677966e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:23:02<3:30:27,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:23:06<3:27:23,  3.49s/it]                                                       {'loss': 0.0549, 'grad_norm': 2.2857978343963623, 'learning_rate': 3.0203389830508476e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:23:06<3:27:23,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:23:09<3:24:00,  3.44s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.2467028796672821, 'learning_rate': 3.0194915254237287e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:23:09<3:24:00,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:23:12<3:23:13,  3.42s/it]                                                       {'loss': 0.0299, 'grad_norm': 2.1243069171905518, 'learning_rate': 3.0186440677966105e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:23:12<3:23:13,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:23:16<3:28:57,  3.52s/it]                                                       {'loss': 0.008, 'grad_norm': 0.5198243260383606, 'learning_rate': 3.0177966101694916e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:23:16<3:28:57,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:23:19<3:26:05,  3.47s/it]                                                       {'loss': 0.029, 'grad_norm': 1.3345907926559448, 'learning_rate': 3.016949152542373e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:23:19<3:26:05,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:23:23<3:31:04,  3.56s/it]                                                       {'loss': 0.0238, 'grad_norm': 1.5143513679504395, 'learning_rate': 3.0161016949152542e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:23:23<3:31:04,  3.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:23:27<3:27:21,  3.50s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.14556322991847992, 'learning_rate': 3.015254237288136e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:23:27<3:27:21,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:23:30<3:25:59,  3.47s/it]                                                       {'loss': 0.0361, 'grad_norm': 2.3604679107666016, 'learning_rate': 3.014406779661017e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:23:30<3:25:59,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:23:33<3:23:40,  3.44s/it]                                                       {'loss': 0.2584, 'grad_norm': 5.42454719543457, 'learning_rate': 3.0135593220338986e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:23:33<3:23:40,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:23:37<3:25:50,  3.47s/it]                                                       {'loss': 0.0618, 'grad_norm': 2.642364501953125, 'learning_rate': 3.0127118644067798e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:23:37<3:25:50,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:23:40<3:26:08,  3.48s/it]                                                       {'loss': 0.0147, 'grad_norm': 1.2108798027038574, 'learning_rate': 3.0118644067796616e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:23:40<3:26:08,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:23:44<3:26:08,  3.48s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.057205080986023, 'learning_rate': 3.0110169491525424e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:23:44<3:26:08,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:23:48<3:30:32,  3.56s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.05307038500905037, 'learning_rate': 3.0101694915254235e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:23:48<3:30:32,  3.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:23:51<3:26:59,  3.50s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.05366317182779312, 'learning_rate': 3.0093220338983053e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:23:51<3:26:59,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:23:54<3:24:48,  3.46s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.1076903343200684, 'learning_rate': 3.0084745762711864e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:23:54<3:24:48,  3.46s/it][2025-10-21 03:48:17,096] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:24:00<4:03:05,  4.11s/it]                                                       {'loss': 0.0847, 'grad_norm': 5.064089298248291, 'learning_rate': 3.007627118644068e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:24:00<4:03:05,  4.11s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:24:03<3:51:18,  3.91s/it]                                                       {'loss': 0.0713, 'grad_norm': 3.2567689418792725, 'learning_rate': 3.006779661016949e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:24:03<3:51:18,  3.91s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:24:07<3:44:24,  3.80s/it]                                                       {'loss': 0.1702, 'grad_norm': 4.55792760848999, 'learning_rate': 3.0059322033898308e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:24:07<3:44:24,  3.80s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:24:10<3:35:46,  3.65s/it]                                                       {'loss': 0.0229, 'grad_norm': 2.472078323364258, 'learning_rate': 3.005084745762712e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:24:10<3:35:46,  3.65s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:24:14<3:30:17,  3.56s/it]                                                       {'loss': 0.0758, 'grad_norm': 3.3701252937316895, 'learning_rate': 3.0042372881355934e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:24:14<3:30:17,  3.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:24:17<3:26:56,  3.50s/it]                                                       {'loss': 0.0122, 'grad_norm': 1.6611202955245972, 'learning_rate': 3.0033898305084745e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:24:17<3:26:56,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:24:21<3:27:34,  3.52s/it]                                                       {'loss': 0.1123, 'grad_norm': 3.7025930881500244, 'learning_rate': 3.0025423728813564e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:24:21<3:27:34,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:24:24<3:24:31,  3.46s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08016420155763626, 'learning_rate': 3.001694915254237e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:24:24<3:24:31,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:24:28<3:30:42,  3.57s/it]                                                       {'loss': 0.012, 'grad_norm': 1.0538872480392456, 'learning_rate': 3.000847457627119e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:24:28<3:30:42,  3.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:24:31<3:26:27,  3.50s/it]                                                       {'loss': 0.0953, 'grad_norm': 4.16530704498291, 'learning_rate': 3e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:24:31<3:26:27,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:24:35<3:29:02,  3.54s/it]                                                       {'loss': 0.0223, 'grad_norm': 0.778035581111908, 'learning_rate': 2.9991525423728815e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:24:35<3:29:02,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:24:38<3:26:04,  3.49s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.3181566894054413, 'learning_rate': 2.9983050847457627e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:24:38<3:26:04,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:24:41<3:24:37,  3.47s/it]                                                       {'loss': 0.149, 'grad_norm': 4.959216117858887, 'learning_rate': 2.9974576271186445e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:24:41<3:24:37,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:24:45<3:23:38,  3.46s/it]                                                       {'loss': 0.1989, 'grad_norm': 5.877745151519775, 'learning_rate': 2.9966101694915256e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:24:45<3:23:38,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:24:49<3:30:35,  3.57s/it]                                                       {'loss': 0.0096, 'grad_norm': 0.6678764224052429, 'learning_rate': 2.995762711864407e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:24:49<3:30:35,  3.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:24:52<3:28:21,  3.54s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.2788659632205963, 'learning_rate': 2.9949152542372882e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:24:52<3:28:21,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:24:56<3:24:52,  3.48s/it]                                                       {'loss': 0.0452, 'grad_norm': 4.022838115692139, 'learning_rate': 2.99406779661017e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:24:56<3:24:52,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:24:59<3:23:16,  3.45s/it]                                                       {'loss': 0.0357, 'grad_norm': 1.693047285079956, 'learning_rate': 2.993220338983051e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:24:59<3:23:16,  3.45s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:25:02<3:20:10,  3.40s/it]                                                       {'loss': 0.0283, 'grad_norm': 2.5176730155944824, 'learning_rate': 2.992372881355932e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:25:02<3:20:10,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:25:06<3:21:19,  3.42s/it]                                                       {'loss': 0.1001, 'grad_norm': 4.046558856964111, 'learning_rate': 2.9915254237288137e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:25:06<3:21:19,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:25:09<3:21:16,  3.42s/it]                                                       {'loss': 0.0838, 'grad_norm': 3.4712531566619873, 'learning_rate': 2.990677966101695e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:25:09<3:21:16,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:25:13<3:21:39,  3.43s/it]                                                       {'loss': 0.2505, 'grad_norm': 9.8477783203125, 'learning_rate': 2.9898305084745763e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:25:13<3:21:39,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:25:16<3:19:50,  3.40s/it]                                                       {'loss': 0.2266, 'grad_norm': 6.579477787017822, 'learning_rate': 2.9889830508474575e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:25:16<3:19:50,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:25:19<3:19:01,  3.39s/it]                                                       {'loss': 0.1066, 'grad_norm': 2.5831871032714844, 'learning_rate': 2.9881355932203393e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:25:19<3:19:01,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:25:23<3:18:11,  3.37s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.08016331493854523, 'learning_rate': 2.9872881355932204e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:25:23<3:18:11,  3.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:25:26<3:19:36,  3.40s/it]                                                       {'loss': 0.0884, 'grad_norm': 2.946690797805786, 'learning_rate': 2.986440677966102e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:25:26<3:19:36,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:25:29<3:18:57,  3.39s/it]                                                       {'loss': 0.1371, 'grad_norm': 5.065394401550293, 'learning_rate': 2.985593220338983e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:25:29<3:18:57,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:25:33<3:19:40,  3.40s/it]                                                       {'loss': 0.0092, 'grad_norm': 0.7432420253753662, 'learning_rate': 2.9847457627118648e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:25:33<3:19:40,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:25:36<3:19:38,  3.40s/it]                                                       {'loss': 0.1018, 'grad_norm': 5.3877363204956055, 'learning_rate': 2.983898305084746e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:25:36<3:19:38,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:25:40<3:20:14,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.09702461212873459, 'learning_rate': 2.9830508474576274e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:25:40<3:20:14,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:25:43<3:21:33,  3.44s/it]                                                       {'loss': 0.0719, 'grad_norm': 5.088571548461914, 'learning_rate': 2.9822033898305085e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:25:43<3:21:33,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:25:46<3:19:32,  3.40s/it]                                                       {'loss': 0.0116, 'grad_norm': 1.0806258916854858, 'learning_rate': 2.98135593220339e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:25:46<3:19:32,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:25:50<3:27:08,  3.53s/it]                                                       {'loss': 0.1046, 'grad_norm': 2.614546298980713, 'learning_rate': 2.980508474576271e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:25:50<3:27:08,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:25:54<3:31:07,  3.60s/it]                                                       {'loss': 0.3289, 'grad_norm': 5.331528663635254, 'learning_rate': 2.979661016949153e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:25:54<3:31:07,  3.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:25:58<3:29:32,  3.58s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.49361976981163025, 'learning_rate': 2.978813559322034e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:25:58<3:29:32,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:26:01<3:26:29,  3.53s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.5704714059829712, 'learning_rate': 2.9779661016949155e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:26:01<3:26:29,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:26:04<3:24:30,  3.49s/it]                                                       {'loss': 0.0755, 'grad_norm': 3.250248908996582, 'learning_rate': 2.9771186440677966e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:26:04<3:24:30,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:26:08<3:24:29,  3.49s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.052617624402046204, 'learning_rate': 2.9762711864406785e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:26:08<3:24:29,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:26:11<3:22:19,  3.46s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.5871379375457764, 'learning_rate': 2.9754237288135596e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:26:11<3:22:19,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:26:15<3:22:45,  3.47s/it]                                                       {'loss': 0.0831, 'grad_norm': 3.6046998500823975, 'learning_rate': 2.9745762711864407e-05, 'epoch': 0.41}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:26:15<3:22:45,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:26:18<3:19:27,  3.41s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.7598393559455872, 'learning_rate': 2.9737288135593222e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:26:18<3:19:27,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:26:21<3:19:44,  3.42s/it]                                                       {'loss': 0.0514, 'grad_norm': 3.2893545627593994, 'learning_rate': 2.9728813559322033e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:26:21<3:19:44,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:26:25<3:17:53,  3.39s/it]                                                       {'loss': 0.2029, 'grad_norm': 4.5551557540893555, 'learning_rate': 2.9720338983050848e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:26:25<3:17:53,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:26:28<3:18:24,  3.40s/it]                                                       {'loss': 0.1831, 'grad_norm': 5.471758842468262, 'learning_rate': 2.971186440677966e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:26:28<3:18:24,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:26:32<3:24:05,  3.49s/it]                                                       {'loss': 0.1391, 'grad_norm': 4.036203861236572, 'learning_rate': 2.9703389830508477e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:26:32<3:24:05,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:26:36<3:28:29,  3.57s/it]                                                       {'loss': 0.001, 'grad_norm': 0.07160027325153351, 'learning_rate': 2.969491525423729e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:26:36<3:28:29,  3.57s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:26:39<3:27:05,  3.55s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.6914104223251343, 'learning_rate': 2.9686440677966103e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:26:39<3:27:05,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:26:43<3:31:34,  3.63s/it]                                                       {'loss': 0.1327, 'grad_norm': 5.0924530029296875, 'learning_rate': 2.9677966101694914e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:26:43<3:31:34,  3.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:26:46<3:27:20,  3.55s/it]                                                       {'loss': 0.0114, 'grad_norm': 0.8383066058158875, 'learning_rate': 2.9669491525423732e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:26:46<3:27:20,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:26:50<3:25:34,  3.52s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.27277711033821106, 'learning_rate': 2.9661016949152544e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:26:50<3:25:34,  3.52s/it][2025-10-21 03:51:12,574] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:26:55<4:01:36,  4.14s/it]                                                       {'loss': 0.0544, 'grad_norm': 3.3332836627960205, 'learning_rate': 2.965254237288136e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:26:55<4:01:36,  4.14s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:26:59<3:48:29,  3.92s/it]                                                       {'loss': 0.1847, 'grad_norm': 5.048886299133301, 'learning_rate': 2.964406779661017e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:26:59<3:48:29,  3.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:27:02<3:39:06,  3.76s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.05779203400015831, 'learning_rate': 2.9635593220338988e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:27:02<3:39:06,  3.76s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:27:06<3:31:45,  3.63s/it]                                                       {'loss': 0.2483, 'grad_norm': 5.44087028503418, 'learning_rate': 2.9627118644067796e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:27:06<3:31:45,  3.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:27:09<3:27:37,  3.56s/it]                                                       {'loss': 0.064, 'grad_norm': 3.796036720275879, 'learning_rate': 2.9618644067796614e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:27:09<3:27:37,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:27:12<3:24:02,  3.50s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.05365638807415962, 'learning_rate': 2.9610169491525425e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:27:12<3:24:02,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:27:16<3:22:35,  3.48s/it]                                                       {'loss': 0.0457, 'grad_norm': 1.9153434038162231, 'learning_rate': 2.960169491525424e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:27:16<3:22:35,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:27:19<3:20:20,  3.44s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.05221660062670708, 'learning_rate': 2.959322033898305e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:27:19<3:20:20,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:27:22<3:19:28,  3.43s/it]                                                       {'loss': 0.2479, 'grad_norm': 5.198463439941406, 'learning_rate': 2.958474576271187e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:27:22<3:19:28,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:27:26<3:22:06,  3.47s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.1765012890100479, 'learning_rate': 2.957627118644068e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:27:26<3:22:06,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:27:30<3:27:54,  3.58s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.14545875787734985, 'learning_rate': 2.956779661016949e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:27:30<3:27:54,  3.58s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:27:33<3:24:47,  3.52s/it]                                                       {'loss': 0.0269, 'grad_norm': 2.115583658218384, 'learning_rate': 2.9559322033898306e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:27:33<3:24:47,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:27:37<3:22:30,  3.48s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.37253907322883606, 'learning_rate': 2.9550847457627118e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:27:37<3:22:30,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:27:40<3:20:47,  3.46s/it]                                                       {'loss': 0.0707, 'grad_norm': 2.562080144882202, 'learning_rate': 2.9542372881355936e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:27:40<3:20:47,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:27:44<3:22:16,  3.48s/it]                                                       {'loss': 0.4294, 'grad_norm': 6.417973518371582, 'learning_rate': 2.9533898305084743e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:27:44<3:22:16,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:27:47<3:20:01,  3.44s/it]                                                       {'loss': 0.1623, 'grad_norm': 4.556397438049316, 'learning_rate': 2.952542372881356e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:27:47<3:20:01,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:27:51<3:24:49,  3.53s/it]                                                       {'loss': 0.1435, 'grad_norm': 5.393616676330566, 'learning_rate': 2.9516949152542373e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:27:51<3:24:49,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:27:54<3:21:47,  3.48s/it]                                                       {'loss': 0.1534, 'grad_norm': 5.248920917510986, 'learning_rate': 2.9508474576271187e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:27:54<3:21:47,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:27:58<3:22:40,  3.49s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.510506510734558, 'learning_rate': 2.95e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:27:58<3:22:40,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:28:01<3:22:04,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.03260524570941925, 'learning_rate': 2.9491525423728817e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:28:01<3:22:04,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:28:04<3:20:51,  3.46s/it]                                                       {'loss': 0.0217, 'grad_norm': 1.2143869400024414, 'learning_rate': 2.9483050847457628e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:28:04<3:20:51,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:28:08<3:28:05,  3.59s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.6298177242279053, 'learning_rate': 2.9474576271186443e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:28:08<3:28:05,  3.59s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:28:12<3:26:38,  3.57s/it]                                                       {'loss': 0.168, 'grad_norm': 3.9445443153381348, 'learning_rate': 2.9466101694915254e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:28:12<3:26:38,  3.57s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:28:15<3:23:44,  3.52s/it]                                                       {'loss': 0.023, 'grad_norm': 1.8369333744049072, 'learning_rate': 2.9457627118644072e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:28:15<3:23:44,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:28:19<3:21:38,  3.48s/it]                                                       {'loss': 0.0859, 'grad_norm': 7.13905668258667, 'learning_rate': 2.9449152542372883e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:28:19<3:21:38,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:28:23<3:31:11,  3.65s/it]                                                       {'loss': 0.0195, 'grad_norm': 1.267951250076294, 'learning_rate': 2.9440677966101698e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:28:23<3:31:11,  3.65s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:28:27<3:35:18,  3.72s/it]                                                       {'loss': 0.0291, 'grad_norm': 2.2424674034118652, 'learning_rate': 2.943220338983051e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:28:27<3:35:18,  3.72s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:28:30<3:30:12,  3.63s/it]                                                       {'loss': 0.1067, 'grad_norm': 3.36317777633667, 'learning_rate': 2.9423728813559327e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:28:30<3:30:12,  3.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:28:33<3:25:07,  3.55s/it]                                                       {'loss': 0.0146, 'grad_norm': 1.572330355644226, 'learning_rate': 2.9415254237288135e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:28:33<3:25:07,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:28:37<3:23:59,  3.53s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.1868392378091812, 'learning_rate': 2.9406779661016953e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:28:37<3:23:59,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:28:40<3:21:49,  3.49s/it]                                                       {'loss': 0.0741, 'grad_norm': 3.025012493133545, 'learning_rate': 2.9398305084745765e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:28:40<3:21:49,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:28:44<3:21:01,  3.48s/it]                                                       {'loss': 0.0115, 'grad_norm': 1.417392611503601, 'learning_rate': 2.9389830508474576e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:28:44<3:21:01,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:28:47<3:20:50,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.05575665831565857, 'learning_rate': 2.938135593220339e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:28:47<3:20:50,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:28:51<3:19:53,  3.46s/it]                                                       {'loss': 0.1236, 'grad_norm': 4.0866217613220215, 'learning_rate': 2.9372881355932202e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:28:51<3:19:53,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:28:54<3:18:51,  3.44s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.34529754519462585, 'learning_rate': 2.936440677966102e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:28:54<3:18:51,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:28:57<3:18:02,  3.43s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.1779295653104782, 'learning_rate': 2.935593220338983e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:28:57<3:18:02,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:29:01<3:16:51,  3.41s/it]                                                       {'loss': 0.006, 'grad_norm': 0.5258331894874573, 'learning_rate': 2.9347457627118646e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:29:01<3:16:51,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:29:04<3:16:54,  3.41s/it]                                                       {'loss': 0.0181, 'grad_norm': 0.9899243712425232, 'learning_rate': 2.9338983050847457e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:29:04<3:16:54,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:29:08<3:16:22,  3.40s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.3799346685409546, 'learning_rate': 2.9330508474576275e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:29:08<3:16:22,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:29:11<3:18:08,  3.44s/it]                                                       {'loss': 0.1491, 'grad_norm': 4.149320602416992, 'learning_rate': 2.9322033898305083e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:29:11<3:18:08,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:29:14<3:17:03,  3.42s/it]                                                       {'loss': 0.0929, 'grad_norm': 4.652801513671875, 'learning_rate': 2.93135593220339e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:29:14<3:17:03,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:29:18<3:15:28,  3.39s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.15559470653533936, 'learning_rate': 2.9305084745762713e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:29:18<3:15:28,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:29:21<3:15:06,  3.39s/it]                                                       {'loss': 0.0448, 'grad_norm': 2.5552849769592285, 'learning_rate': 2.9296610169491527e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:29:21<3:15:06,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:29:25<3:15:24,  3.39s/it]                                                       {'loss': 0.0824, 'grad_norm': 4.061324119567871, 'learning_rate': 2.928813559322034e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:29:25<3:15:24,  3.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:29:28<3:15:43,  3.40s/it]                                                       {'loss': 0.0613, 'grad_norm': 4.03281307220459, 'learning_rate': 2.9279661016949157e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:29:28<3:15:43,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:29:31<3:17:01,  3.42s/it]                                                       {'loss': 0.0532, 'grad_norm': 1.4393689632415771, 'learning_rate': 2.9271186440677968e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:29:31<3:17:01,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:29:35<3:17:06,  3.42s/it]                                                       {'loss': 0.0099, 'grad_norm': 0.5920462608337402, 'learning_rate': 2.9262711864406783e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:29:35<3:17:06,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:29:39<3:21:36,  3.50s/it]                                                       {'loss': 0.1647, 'grad_norm': 4.609835624694824, 'learning_rate': 2.9254237288135594e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:29:39<3:21:36,  3.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:29:42<3:21:45,  3.51s/it]                                                       {'loss': 0.0241, 'grad_norm': 1.9376028776168823, 'learning_rate': 2.9245762711864412e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:29:42<3:21:45,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:29:45<3:20:05,  3.48s/it]                                                       {'loss': 0.1457, 'grad_norm': 4.383535861968994, 'learning_rate': 2.9237288135593223e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:29:45<3:20:05,  3.48s/it][2025-10-21 03:54:08,236] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:29:51<3:55:23,  4.10s/it]                                                       {'loss': 0.1256, 'grad_norm': 5.799289703369141, 'learning_rate': 2.9228813559322038e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:29:51<3:55:23,  4.10s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:29:54<3:43:23,  3.89s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.3347459137439728, 'learning_rate': 2.922033898305085e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:29:54<3:43:23,  3.89s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:29:58<3:34:13,  3.73s/it]                                                       {'loss': 0.0177, 'grad_norm': 0.927334189414978, 'learning_rate': 2.921186440677966e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:29:58<3:34:13,  3.73s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:30:02<3:35:45,  3.76s/it]                                                       {'loss': 0.0285, 'grad_norm': 1.4971401691436768, 'learning_rate': 2.9203389830508475e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:30:02<3:35:45,  3.76s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:30:05<3:29:10,  3.64s/it]                                                       {'loss': 0.0247, 'grad_norm': 2.0415546894073486, 'learning_rate': 2.9194915254237286e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:30:05<3:29:10,  3.64s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:30:08<3:25:04,  3.57s/it]                                                       {'loss': 0.2055, 'grad_norm': 5.342558860778809, 'learning_rate': 2.9186440677966104e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:30:08<3:25:04,  3.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:30:12<3:21:35,  3.51s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.1387057900428772, 'learning_rate': 2.9177966101694916e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:30:12<3:21:35,  3.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:30:15<3:20:09,  3.49s/it]                                                       {'loss': 0.0109, 'grad_norm': 1.3881500959396362, 'learning_rate': 2.916949152542373e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:30:15<3:20:09,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:30:19<3:21:17,  3.51s/it]                                                       {'loss': 0.1206, 'grad_norm': 3.716803789138794, 'learning_rate': 2.916101694915254e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:30:19<3:21:17,  3.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:30:22<3:21:22,  3.51s/it]                                                       {'loss': 0.0509, 'grad_norm': 2.9786853790283203, 'learning_rate': 2.915254237288136e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:30:22<3:21:22,  3.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:30:26<3:19:37,  3.48s/it]                                                       {'loss': 0.0175, 'grad_norm': 1.4496515989303589, 'learning_rate': 2.914406779661017e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:30:26<3:19:37,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:30:29<3:18:17,  3.46s/it]                                                       {'loss': 0.1178, 'grad_norm': 3.4612178802490234, 'learning_rate': 2.9135593220338986e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:30:29<3:18:17,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:30:32<3:15:16,  3.41s/it]                                                       {'loss': 0.1681, 'grad_norm': 3.9698872566223145, 'learning_rate': 2.9127118644067797e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:30:32<3:15:16,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:30:36<3:17:48,  3.45s/it]                                                       {'loss': 0.0237, 'grad_norm': 1.8016083240509033, 'learning_rate': 2.911864406779661e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:30:36<3:17:48,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:30:39<3:15:21,  3.41s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.12066973745822906, 'learning_rate': 2.9110169491525423e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:30:39<3:15:21,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:30:43<3:14:45,  3.40s/it]                                                       {'loss': 0.262, 'grad_norm': 6.884861946105957, 'learning_rate': 2.910169491525424e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:30:43<3:14:45,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:30:46<3:15:48,  3.42s/it]                                                       {'loss': 0.1007, 'grad_norm': 5.387681484222412, 'learning_rate': 2.9093220338983052e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:30:46<3:15:48,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:30:50<3:19:15,  3.48s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.4752410352230072, 'learning_rate': 2.9084745762711867e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:30:50<3:19:15,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:30:53<3:19:44,  3.49s/it]                                                       {'loss': 0.1183, 'grad_norm': 4.403634071350098, 'learning_rate': 2.9076271186440678e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:30:53<3:19:44,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:30:57<3:18:28,  3.47s/it]                                                       {'loss': 0.0401, 'grad_norm': 1.8041788339614868, 'learning_rate': 2.9067796610169496e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:30:57<3:18:28,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:31:00<3:16:33,  3.44s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.5012823939323425, 'learning_rate': 2.9059322033898308e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:31:00<3:16:33,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:31:03<3:15:56,  3.43s/it]                                                       {'loss': 0.0065, 'grad_norm': 0.5667104125022888, 'learning_rate': 2.9050847457627122e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:31:03<3:15:56,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:31:07<3:13:38,  3.39s/it]                                                       {'loss': 0.0464, 'grad_norm': 3.598756790161133, 'learning_rate': 2.9042372881355934e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:31:07<3:13:38,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:31:10<3:13:25,  3.39s/it]                                                       {'loss': 0.0113, 'grad_norm': 0.6624510884284973, 'learning_rate': 2.9033898305084745e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:31:10<3:13:25,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:31:14<3:14:55,  3.41s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.2412266582250595, 'learning_rate': 2.902542372881356e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:31:14<3:14:55,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:31:17<3:13:14,  3.39s/it]                                                       {'loss': 0.0777, 'grad_norm': 3.7793421745300293, 'learning_rate': 2.901694915254237e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:31:17<3:13:14,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:31:20<3:13:20,  3.39s/it]                                                       {'loss': 0.111, 'grad_norm': 4.3659467697143555, 'learning_rate': 2.900847457627119e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:31:20<3:13:20,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:31:24<3:13:04,  3.39s/it]                                                       {'loss': 0.0263, 'grad_norm': 2.0056116580963135, 'learning_rate': 2.9e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:31:24<3:13:04,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:31:27<3:13:04,  3.39s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.13106180727481842, 'learning_rate': 2.8991525423728815e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:31:27<3:13:04,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:31:31<3:14:42,  3.42s/it]                                                       {'loss': 0.006, 'grad_norm': 0.4565315842628479, 'learning_rate': 2.8983050847457626e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:31:31<3:14:42,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:31:34<3:16:19,  3.45s/it]                                                       {'loss': 0.0569, 'grad_norm': 3.1498801708221436, 'learning_rate': 2.8974576271186444e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:31:34<3:16:19,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:31:38<3:21:41,  3.54s/it]                                                       {'loss': 0.0859, 'grad_norm': 4.2284650802612305, 'learning_rate': 2.8966101694915255e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:31:38<3:21:41,  3.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:31:41<3:19:35,  3.50s/it]                                                       {'loss': 0.2618, 'grad_norm': 6.70184326171875, 'learning_rate': 2.895762711864407e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:31:41<3:19:35,  3.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:31:45<3:16:21,  3.45s/it]                                                       {'loss': 0.1421, 'grad_norm': 4.1525044441223145, 'learning_rate': 2.894915254237288e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:31:45<3:16:21,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:31:48<3:15:24,  3.43s/it]                                                       {'loss': 0.0861, 'grad_norm': 2.1084144115448, 'learning_rate': 2.89406779661017e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:31:48<3:15:24,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:31:51<3:14:29,  3.42s/it]                                                       {'loss': 0.2151, 'grad_norm': 3.9530653953552246, 'learning_rate': 2.8932203389830507e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:31:51<3:14:29,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:31:55<3:12:58,  3.39s/it]                                                       {'loss': 0.0179, 'grad_norm': 1.35456383228302, 'learning_rate': 2.8923728813559325e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:31:55<3:12:58,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:31:59<3:21:18,  3.54s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.0529918372631073, 'learning_rate': 2.8915254237288137e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:31:59<3:21:18,  3.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:32:02<3:18:19,  3.49s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.44224002957344055, 'learning_rate': 2.890677966101695e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:32:02<3:18:19,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:32:05<3:16:49,  3.46s/it]                                                       {'loss': 0.0101, 'grad_norm': 0.5463071465492249, 'learning_rate': 2.8898305084745763e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:32:05<3:16:49,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:32:09<3:15:01,  3.43s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.2628170847892761, 'learning_rate': 2.888983050847458e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:32:09<3:15:01,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:32:12<3:13:02,  3.40s/it]                                                       {'loss': 0.1287, 'grad_norm': 6.212342262268066, 'learning_rate': 2.8881355932203392e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:32:12<3:13:02,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:32:15<3:12:01,  3.38s/it]                                                       {'loss': 0.0177, 'grad_norm': 1.4171640872955322, 'learning_rate': 2.8872881355932203e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:32:15<3:12:01,  3.38s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:32:19<3:10:55,  3.36s/it]                                                       {'loss': 0.0148, 'grad_norm': 1.2237221002578735, 'learning_rate': 2.8864406779661018e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:32:19<3:10:55,  3.36s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:32:22<3:12:31,  3.39s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3383397161960602, 'learning_rate': 2.885593220338983e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:32:22<3:12:31,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:32:26<3:15:18,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0249549001455307, 'learning_rate': 2.8847457627118647e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:32:26<3:15:18,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:32:29<3:13:46,  3.42s/it]                                                       {'loss': 0.0683, 'grad_norm': 3.4937474727630615, 'learning_rate': 2.8838983050847455e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:32:29<3:13:46,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:32:32<3:12:45,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.04544205218553543, 'learning_rate': 2.8830508474576273e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:32:32<3:12:45,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:32:36<3:13:11,  3.41s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.8065952062606812, 'learning_rate': 2.8822033898305085e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:32:36<3:13:11,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:32:39<3:11:35,  3.38s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.1958438754081726, 'learning_rate': 2.88135593220339e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:32:39<3:11:35,  3.38s/it][2025-10-21 03:57:01,924] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:32:45<3:54:24,  4.14s/it]                                                       {'loss': 0.094, 'grad_norm': 2.775927782058716, 'learning_rate': 2.880508474576271e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:32:45<3:54:24,  4.14s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:32:48<3:40:42,  3.90s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.5704969763755798, 'learning_rate': 2.879661016949153e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:32:48<3:40:42,  3.90s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:32:52<3:31:46,  3.74s/it]                                                       {'loss': 0.0434, 'grad_norm': 1.3415641784667969, 'learning_rate': 2.878813559322034e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:32:52<3:31:46,  3.74s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:32:55<3:28:59,  3.69s/it]                                                       {'loss': 0.0103, 'grad_norm': 0.8095055222511292, 'learning_rate': 2.8779661016949155e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:32:55<3:28:59,  3.69s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:32:59<3:24:16,  3.61s/it]                                                       {'loss': 0.0809, 'grad_norm': 2.825960874557495, 'learning_rate': 2.8771186440677966e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:32:59<3:24:16,  3.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:33:02<3:19:49,  3.53s/it]                                                       {'loss': 0.0183, 'grad_norm': 0.7961446642875671, 'learning_rate': 2.8762711864406784e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:33:02<3:19:49,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:33:05<3:16:44,  3.48s/it]                                                       {'loss': 0.0495, 'grad_norm': 3.656614303588867, 'learning_rate': 2.8754237288135595e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:33:05<3:16:44,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:33:09<3:14:56,  3.45s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.1088646948337555, 'learning_rate': 2.874576271186441e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:33:09<3:14:56,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:33:12<3:13:38,  3.43s/it]                                                       {'loss': 0.0333, 'grad_norm': 2.6114346981048584, 'learning_rate': 2.873728813559322e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:33:12<3:13:38,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:33:16<3:12:40,  3.41s/it]                                                       {'loss': 0.0216, 'grad_norm': 1.7741014957427979, 'learning_rate': 2.8728813559322036e-05, 'epoch': 0.43}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:33:16<3:12:40,  3.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:33:19<3:13:51,  3.43s/it]                                                       {'loss': 0.121, 'grad_norm': 3.2276804447174072, 'learning_rate': 2.8720338983050847e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:33:19<3:13:51,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:33:22<3:12:50,  3.42s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.008269156329333782, 'learning_rate': 2.8711864406779665e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:33:22<3:12:50,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:33:26<3:18:17,  3.51s/it]                                                       {'loss': 0.0708, 'grad_norm': 2.9469637870788574, 'learning_rate': 2.8703389830508476e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:33:26<3:18:17,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:33:30<3:15:22,  3.46s/it]                                                       {'loss': 0.0417, 'grad_norm': 3.0134174823760986, 'learning_rate': 2.8694915254237288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:33:30<3:15:22,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:33:33<3:13:12,  3.42s/it]                                                       {'loss': 0.0358, 'grad_norm': 2.6023168563842773, 'learning_rate': 2.8686440677966102e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:33:33<3:13:12,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:33:36<3:13:03,  3.42s/it]                                                       {'loss': 0.2308, 'grad_norm': 4.98867130279541, 'learning_rate': 2.8677966101694914e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:33:36<3:13:03,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:33:40<3:11:37,  3.40s/it]                                                       {'loss': 0.0297, 'grad_norm': 2.0504958629608154, 'learning_rate': 2.8669491525423732e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:33:40<3:11:37,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:33:43<3:11:30,  3.40s/it]                                                       {'loss': 0.0401, 'grad_norm': 2.4626259803771973, 'learning_rate': 2.8661016949152543e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:33:43<3:11:30,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:33:47<3:14:42,  3.46s/it]                                                       {'loss': 0.0788, 'grad_norm': 4.012478351593018, 'learning_rate': 2.8652542372881358e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:33:47<3:14:42,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:33:50<3:17:22,  3.50s/it]                                                       {'loss': 0.0085, 'grad_norm': 0.6827146410942078, 'learning_rate': 2.864406779661017e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:33:50<3:17:22,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:33:54<3:17:17,  3.50s/it]                                                       {'loss': 0.0282, 'grad_norm': 1.723858118057251, 'learning_rate': 2.8635593220338984e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:33:54<3:17:17,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:33:57<3:16:10,  3.48s/it]                                                       {'loss': 0.1384, 'grad_norm': 3.9678525924682617, 'learning_rate': 2.8627118644067795e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:33:57<3:16:10,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:34:01<3:14:04,  3.45s/it]                                                       {'loss': 0.0212, 'grad_norm': 1.7561043500900269, 'learning_rate': 2.8618644067796613e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:34:01<3:14:04,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:34:04<3:12:39,  3.42s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.2667551040649414, 'learning_rate': 2.8610169491525424e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:34:04<3:12:39,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:34:07<3:13:31,  3.44s/it]                                                       {'loss': 0.007, 'grad_norm': 0.5311169624328613, 'learning_rate': 2.860169491525424e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:34:07<3:13:31,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:34:11<3:15:42,  3.48s/it]                                                       {'loss': 0.1179, 'grad_norm': 5.490950107574463, 'learning_rate': 2.859322033898305e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:34:11<3:15:42,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:34:15<3:16:23,  3.49s/it]                                                       {'loss': 0.1365, 'grad_norm': 3.3848917484283447, 'learning_rate': 2.858474576271187e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:34:15<3:16:23,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:34:18<3:14:21,  3.46s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.07179683446884155, 'learning_rate': 2.857627118644068e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:34:18<3:14:21,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:34:21<3:13:08,  3.44s/it]                                                       {'loss': 0.0224, 'grad_norm': 1.9794591665267944, 'learning_rate': 2.8567796610169494e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:34:21<3:13:08,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:34:25<3:12:28,  3.43s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.03602702543139458, 'learning_rate': 2.8559322033898306e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:34:25<3:12:28,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:34:28<3:11:07,  3.40s/it]                                                       {'loss': 0.0213, 'grad_norm': 1.4181827306747437, 'learning_rate': 2.8550847457627124e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:34:28<3:11:07,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:34:31<3:09:47,  3.38s/it]                                                       {'loss': 0.2313, 'grad_norm': 4.822265625, 'learning_rate': 2.854237288135593e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:34:31<3:09:47,  3.38s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:34:35<3:08:28,  3.36s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.6066093444824219, 'learning_rate': 2.853389830508475e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:34:35<3:08:28,  3.36s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:34:38<3:10:37,  3.40s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.22753937542438507, 'learning_rate': 2.852542372881356e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:34:38<3:10:37,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:34:42<3:11:47,  3.42s/it]                                                       {'loss': 0.0439, 'grad_norm': 3.4141807556152344, 'learning_rate': 2.8516949152542372e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:34:42<3:11:47,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:34:46<3:25:31,  3.67s/it]                                                       {'loss': 0.0457, 'grad_norm': 2.31465744972229, 'learning_rate': 2.8508474576271187e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:34:46<3:25:31,  3.67s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:34:49<3:22:19,  3.61s/it]                                                       {'loss': 0.1302, 'grad_norm': 2.6005935668945312, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:34:49<3:22:19,  3.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:34:53<3:19:59,  3.57s/it]                                                       {'loss': 0.0556, 'grad_norm': 2.0244414806365967, 'learning_rate': 2.8491525423728816e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:34:53<3:19:59,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:34:56<3:20:28,  3.58s/it]                                                       {'loss': 0.0322, 'grad_norm': 2.088317632675171, 'learning_rate': 2.8483050847457628e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:34:56<3:20:28,  3.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:35:00<3:21:01,  3.59s/it]                                                       {'loss': 0.1768, 'grad_norm': 4.738698482513428, 'learning_rate': 2.8474576271186442e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:35:00<3:21:01,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:35:04<3:26:15,  3.68s/it]                                                       {'loss': 0.0823, 'grad_norm': 3.869828224182129, 'learning_rate': 2.8466101694915253e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:35:04<3:26:15,  3.68s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:35:07<3:21:07,  3.59s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.11875199526548386, 'learning_rate': 2.845762711864407e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:35:07<3:21:07,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:35:11<3:17:40,  3.53s/it]                                                       {'loss': 0.0169, 'grad_norm': 1.6084718704223633, 'learning_rate': 2.844915254237288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:35:11<3:17:40,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:35:14<3:15:02,  3.49s/it]                                                       {'loss': 0.1926, 'grad_norm': 4.697248458862305, 'learning_rate': 2.8440677966101698e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:35:14<3:15:02,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:35:18<3:14:35,  3.48s/it]                                                       {'loss': 0.0071, 'grad_norm': 0.6364123821258545, 'learning_rate': 2.843220338983051e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:35:18<3:14:35,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:35:21<3:12:47,  3.45s/it]                                                       {'loss': 0.0954, 'grad_norm': 5.852852821350098, 'learning_rate': 2.8423728813559323e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:35:21<3:12:47,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:35:24<3:12:41,  3.45s/it]                                                       {'loss': 0.0839, 'grad_norm': 3.6130306720733643, 'learning_rate': 2.8415254237288135e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:35:24<3:12:41,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:35:28<3:10:18,  3.41s/it]                                                       {'loss': 0.2007, 'grad_norm': 4.968382835388184, 'learning_rate': 2.8406779661016953e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:35:28<3:10:18,  3.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:35:31<3:11:42,  3.43s/it]                                                       {'loss': 0.0257, 'grad_norm': 1.6714376211166382, 'learning_rate': 2.8398305084745764e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:35:31<3:11:42,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:35:35<3:11:33,  3.43s/it]                                                       {'loss': 0.0154, 'grad_norm': 1.428032398223877, 'learning_rate': 2.838983050847458e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:35:35<3:11:33,  3.43s/it][2025-10-21 03:59:57,349] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:35:40<3:46:52,  4.06s/it]                                                       {'loss': 0.01, 'grad_norm': 0.7494899034500122, 'learning_rate': 2.838135593220339e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:35:40<3:46:52,  4.06s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:35:44<3:38:03,  3.91s/it]                                                       {'loss': 0.1567, 'grad_norm': 4.772806644439697, 'learning_rate': 2.8372881355932208e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:35:44<3:38:03,  3.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:35:48<3:38:05,  3.91s/it]                                                       {'loss': 0.0552, 'grad_norm': 1.4468975067138672, 'learning_rate': 2.836440677966102e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:35:48<3:38:05,  3.91s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:35:51<3:28:55,  3.75s/it]                                                       {'loss': 0.0527, 'grad_norm': 2.4573967456817627, 'learning_rate': 2.8355932203389834e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:35:51<3:28:55,  3.75s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:35:54<3:22:22,  3.63s/it]                                                       {'loss': 0.0869, 'grad_norm': 4.534671783447266, 'learning_rate': 2.8347457627118645e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:35:54<3:22:22,  3.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:35:58<3:17:52,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.017335744574666023, 'learning_rate': 2.8338983050847457e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:35:58<3:17:52,  3.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:36:02<3:24:08,  3.66s/it]                                                       {'loss': 0.0568, 'grad_norm': 2.328947067260742, 'learning_rate': 2.833050847457627e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:36:02<3:24:08,  3.66s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:36:05<3:19:09,  3.58s/it]                                                       {'loss': 0.0205, 'grad_norm': 1.8925364017486572, 'learning_rate': 2.8322033898305083e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:36:05<3:19:09,  3.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:36:09<3:23:37,  3.66s/it]                                                       {'loss': 0.0531, 'grad_norm': 1.5606900453567505, 'learning_rate': 2.83135593220339e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:36:09<3:23:37,  3.66s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:36:13<3:25:44,  3.70s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.37889572978019714, 'learning_rate': 2.8305084745762712e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:36:13<3:25:44,  3.70s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:36:16<3:20:58,  3.61s/it]                                                       {'loss': 0.1542, 'grad_norm': 6.522609233856201, 'learning_rate': 2.8296610169491527e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:36:16<3:20:58,  3.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:36:19<3:18:25,  3.57s/it]                                                       {'loss': 0.0357, 'grad_norm': 2.5658228397369385, 'learning_rate': 2.8288135593220338e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:36:20<3:18:25,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:36:23<3:16:02,  3.52s/it]                                                       {'loss': 0.0649, 'grad_norm': 2.289323091506958, 'learning_rate': 2.8279661016949156e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:36:23<3:16:02,  3.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:36:26<3:13:27,  3.48s/it]                                                       {'loss': 0.013, 'grad_norm': 1.6518826484680176, 'learning_rate': 2.8271186440677967e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:36:26<3:13:27,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:36:30<3:16:37,  3.54s/it]                                                       {'loss': 0.0416, 'grad_norm': 1.8188285827636719, 'learning_rate': 2.8262711864406782e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:36:30<3:16:37,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:36:33<3:15:04,  3.51s/it]                                                       {'loss': 0.0982, 'grad_norm': 3.5744996070861816, 'learning_rate': 2.8254237288135593e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:36:33<3:15:04,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:36:37<3:14:56,  3.51s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.039317574352025986, 'learning_rate': 2.824576271186441e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:36:37<3:14:56,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:36:41<3:19:50,  3.60s/it]                                                       {'loss': 0.0688, 'grad_norm': 4.143864154815674, 'learning_rate': 2.823728813559322e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:36:41<3:19:50,  3.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:36:44<3:16:32,  3.54s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.3499830961227417, 'learning_rate': 2.8228813559322037e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:36:44<3:16:32,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:36:47<3:12:58,  3.48s/it]                                                       {'loss': 0.0933, 'grad_norm': 3.0701959133148193, 'learning_rate': 2.822033898305085e-05, 'epoch': 0.45}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:36:47<3:12:58,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:36:51<3:11:52,  3.46s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.2461935579776764, 'learning_rate': 2.8211864406779663e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:36:51<3:11:52,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:36:54<3:12:20,  3.47s/it]                                                       {'loss': 0.0338, 'grad_norm': 1.533223271369934, 'learning_rate': 2.8203389830508475e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:36:54<3:12:20,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:36:58<3:11:55,  3.46s/it]                                                       {'loss': 0.0073, 'grad_norm': 0.8472145795822144, 'learning_rate': 2.8194915254237293e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:36:58<3:11:55,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:37:01<3:11:30,  3.45s/it]                                                       {'loss': 0.0336, 'grad_norm': 1.8781379461288452, 'learning_rate': 2.8186440677966104e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:37:01<3:11:30,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:37:05<3:16:22,  3.54s/it]                                                       {'loss': 0.0953, 'grad_norm': 3.40106201171875, 'learning_rate': 2.817796610169492e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:37:05<3:16:22,  3.54s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:37:08<3:12:54,  3.48s/it]                                                       {'loss': 0.0247, 'grad_norm': 1.5600401163101196, 'learning_rate': 2.816949152542373e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:37:08<3:12:54,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:37:12<3:13:00,  3.48s/it]                                                       {'loss': 0.0884, 'grad_norm': 4.617191314697266, 'learning_rate': 2.816101694915254e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:37:12<3:13:00,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:37:15<3:12:43,  3.48s/it]                                                       {'loss': 0.1576, 'grad_norm': 6.224385738372803, 'learning_rate': 2.815254237288136e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:37:15<3:12:43,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:37:19<3:10:11,  3.44s/it]                                                       {'loss': 0.0608, 'grad_norm': 3.8620944023132324, 'learning_rate': 2.8144067796610167e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:37:19<3:10:11,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:37:22<3:11:31,  3.46s/it]                                                       {'loss': 0.0103, 'grad_norm': 0.6071174740791321, 'learning_rate': 2.8135593220338985e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:37:22<3:11:31,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:37:26<3:10:18,  3.44s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.4922237992286682, 'learning_rate': 2.8127118644067796e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:37:26<3:10:18,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:37:29<3:10:05,  3.44s/it]                                                       {'loss': 0.0056, 'grad_norm': 0.6925992369651794, 'learning_rate': 2.811864406779661e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:37:29<3:10:05,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:37:32<3:09:22,  3.43s/it]                                                       {'loss': 0.0334, 'grad_norm': 2.614314556121826, 'learning_rate': 2.8110169491525422e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:37:32<3:09:22,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:37:36<3:07:55,  3.40s/it]                                                       {'loss': 0.5933, 'grad_norm': 6.569411277770996, 'learning_rate': 2.810169491525424e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:37:36<3:07:55,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:37:39<3:08:13,  3.41s/it]                                                       {'loss': 0.0137, 'grad_norm': 1.315906047821045, 'learning_rate': 2.8093220338983052e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:37:39<3:08:13,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:37:43<3:09:01,  3.42s/it]                                                       {'loss': 0.1378, 'grad_norm': 2.1507575511932373, 'learning_rate': 2.8084745762711866e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:37:43<3:09:01,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:37:46<3:08:37,  3.42s/it]                                                       {'loss': 0.028, 'grad_norm': 1.4705175161361694, 'learning_rate': 2.8076271186440678e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:37:46<3:08:37,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:37:50<3:10:34,  3.45s/it]                                                       {'loss': 0.0398, 'grad_norm': 2.3021585941314697, 'learning_rate': 2.8067796610169496e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:37:50<3:10:34,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:37:53<3:08:57,  3.42s/it]                                                       {'loss': 0.0072, 'grad_norm': 0.6073334813117981, 'learning_rate': 2.8059322033898307e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:37:53<3:08:57,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:37:56<3:07:23,  3.40s/it]                                                       {'loss': 0.1549, 'grad_norm': 5.205433368682861, 'learning_rate': 2.8050847457627122e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:37:56<3:07:23,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:38:00<3:07:23,  3.40s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.26588982343673706, 'learning_rate': 2.8042372881355933e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:38:00<3:07:23,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:38:03<3:08:56,  3.43s/it]                                                       {'loss': 0.0217, 'grad_norm': 1.5520381927490234, 'learning_rate': 2.8033898305084748e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:38:03<3:08:56,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:38:07<3:09:04,  3.43s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.10687852650880814, 'learning_rate': 2.802542372881356e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:38:07<3:09:04,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:38:10<3:14:38,  3.53s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.004331698175519705, 'learning_rate': 2.8016949152542377e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:38:10<3:14:38,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:38:14<3:16:30,  3.57s/it]                                                       {'loss': 0.0097, 'grad_norm': 0.8112704157829285, 'learning_rate': 2.8008474576271188e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:38:14<3:16:30,  3.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:38:17<3:14:32,  3.53s/it]                                                       {'loss': 0.2859, 'grad_norm': 4.594639301300049, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:38:17<3:14:32,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:38:21<3:13:38,  3.52s/it]                                                       {'loss': 0.0143, 'grad_norm': 0.9210554361343384, 'learning_rate': 2.7991525423728814e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:38:21<3:13:38,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:38:24<3:11:28,  3.48s/it]                                                       {'loss': 0.0655, 'grad_norm': 1.3805902004241943, 'learning_rate': 2.7983050847457626e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:38:24<3:11:28,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:38:28<3:09:10,  3.44s/it]                                                       {'loss': 0.0096, 'grad_norm': 0.6331869959831238, 'learning_rate': 2.7974576271186444e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:38:28<3:09:10,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:38:31<3:08:08,  3.42s/it]                                                       {'loss': 0.0091, 'grad_norm': 0.5889217853546143, 'learning_rate': 2.7966101694915255e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:38:31<3:08:08,  3.42s/it][2025-10-21 04:02:53,788] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:38:37<3:49:19,  4.17s/it]                                                       {'loss': 0.0995, 'grad_norm': 3.473250389099121, 'learning_rate': 2.795762711864407e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:38:37<3:49:19,  4.17s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:38:41<3:43:24,  4.06s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.39071741700172424, 'learning_rate': 2.794915254237288e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:38:41<3:43:24,  4.06s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:38:44<3:32:45,  3.87s/it]                                                       {'loss': 0.0153, 'grad_norm': 0.9912666082382202, 'learning_rate': 2.7940677966101696e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:38:44<3:32:45,  3.87s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:38:48<3:25:57,  3.75s/it]                                                       {'loss': 0.1627, 'grad_norm': 5.667546272277832, 'learning_rate': 2.7932203389830507e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:38:48<3:25:57,  3.75s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:38:51<3:22:16,  3.68s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.08171968162059784, 'learning_rate': 2.7923728813559325e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:38:51<3:22:16,  3.68s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:38:55<3:16:43,  3.58s/it]                                                       {'loss': 0.0698, 'grad_norm': 4.2901291847229, 'learning_rate': 2.7915254237288136e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:38:55<3:16:43,  3.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:38:58<3:13:59,  3.53s/it]                                                       {'loss': 0.0068, 'grad_norm': 0.4692670404911041, 'learning_rate': 2.790677966101695e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:38:58<3:13:59,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:39:02<3:17:41,  3.60s/it]                                                       {'loss': 0.0502, 'grad_norm': 3.762615919113159, 'learning_rate': 2.7898305084745762e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:39:02<3:17:41,  3.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:39:05<3:16:31,  3.58s/it]                                                       {'loss': 0.0907, 'grad_norm': 4.033099174499512, 'learning_rate': 2.788983050847458e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:39:05<3:16:31,  3.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:39:09<3:14:32,  3.55s/it]                                                       {'loss': 0.0481, 'grad_norm': 1.819566011428833, 'learning_rate': 2.788135593220339e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:39:09<3:14:32,  3.55s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:39:12<3:11:45,  3.50s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.1009746566414833, 'learning_rate': 2.7872881355932206e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:39:12<3:11:45,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:39:16<3:11:15,  3.49s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.1858450323343277, 'learning_rate': 2.7864406779661017e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:39:16<3:11:15,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:39:19<3:09:38,  3.46s/it]                                                       {'loss': 0.0132, 'grad_norm': 0.8193057179450989, 'learning_rate': 2.7855932203389835e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:39:19<3:09:38,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:39:22<3:08:50,  3.45s/it]                                                       {'loss': 0.0222, 'grad_norm': 2.1339030265808105, 'learning_rate': 2.7847457627118643e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:39:22<3:08:50,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:39:26<3:09:56,  3.47s/it]                                                       {'loss': 0.0657, 'grad_norm': 3.2083938121795654, 'learning_rate': 2.783898305084746e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:39:26<3:09:56,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:39:29<3:11:02,  3.49s/it]                                                       {'loss': 0.2346, 'grad_norm': 6.934046745300293, 'learning_rate': 2.7830508474576273e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:39:29<3:11:02,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:39:33<3:09:20,  3.46s/it]                                                       {'loss': 0.0517, 'grad_norm': 3.101572036743164, 'learning_rate': 2.7822033898305087e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:39:33<3:09:20,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:39:36<3:10:04,  3.47s/it]                                                       {'loss': 0.0225, 'grad_norm': 1.6404207944869995, 'learning_rate': 2.78135593220339e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:39:36<3:10:04,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:39:40<3:09:43,  3.47s/it]                                                       {'loss': 0.1269, 'grad_norm': 3.507694721221924, 'learning_rate': 2.780508474576271e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:39:40<3:09:43,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:39:43<3:11:34,  3.50s/it]                                                       {'loss': 0.0101, 'grad_norm': 0.821922779083252, 'learning_rate': 2.7796610169491528e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:39:43<3:11:34,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:39:47<3:10:11,  3.48s/it]                                                       {'loss': 0.037, 'grad_norm': 2.599294662475586, 'learning_rate': 2.778813559322034e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:39:47<3:10:11,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:39:50<3:09:20,  3.47s/it]                                                       {'loss': 0.1494, 'grad_norm': 5.410612106323242, 'learning_rate': 2.7779661016949154e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:39:50<3:09:20,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:39:54<3:06:59,  3.42s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.030169975012540817, 'learning_rate': 2.7771186440677965e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:39:54<3:06:59,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:39:57<3:05:40,  3.40s/it]                                                       {'loss': 0.0298, 'grad_norm': 1.615339994430542, 'learning_rate': 2.7762711864406783e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:39:57<3:05:40,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:40:00<3:06:27,  3.42s/it]                                                       {'loss': 0.0264, 'grad_norm': 2.1490566730499268, 'learning_rate': 2.775423728813559e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:40:00<3:06:27,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:40:04<3:07:32,  3.44s/it]                                                       {'loss': 0.0242, 'grad_norm': 2.788750171661377, 'learning_rate': 2.774576271186441e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:40:04<3:07:32,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:40:07<3:06:08,  3.41s/it]                                                       {'loss': 0.0903, 'grad_norm': 4.24806547164917, 'learning_rate': 2.773728813559322e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:40:07<3:06:08,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:40:11<3:04:56,  3.39s/it]                                                       {'loss': 0.0172, 'grad_norm': 1.1287751197814941, 'learning_rate': 2.7728813559322035e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:40:11<3:04:56,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:40:14<3:05:29,  3.40s/it]                                                       {'loss': 0.0454, 'grad_norm': 2.9139342308044434, 'learning_rate': 2.7720338983050847e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:40:14<3:05:29,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:40:17<3:03:41,  3.37s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.22967231273651123, 'learning_rate': 2.7711864406779665e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:40:17<3:03:41,  3.37s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:40:21<3:03:58,  3.38s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.4504905343055725, 'learning_rate': 2.7703389830508476e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:40:21<3:03:58,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:40:24<3:04:04,  3.38s/it]                                                       {'loss': 0.0115, 'grad_norm': 0.8042322993278503, 'learning_rate': 2.769491525423729e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:40:24<3:04:04,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:40:27<3:03:00,  3.36s/it]                                                       {'loss': 0.1513, 'grad_norm': 6.041730880737305, 'learning_rate': 2.7686440677966102e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:40:27<3:03:00,  3.36s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:40:31<3:09:37,  3.48s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.39629799127578735, 'learning_rate': 2.767796610169492e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:40:31<3:09:37,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:40:35<3:08:15,  3.46s/it]                                                       {'loss': 0.004, 'grad_norm': 0.27898868918418884, 'learning_rate': 2.766949152542373e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:40:35<3:08:15,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:40:38<3:12:14,  3.53s/it]                                                       {'loss': 0.0124, 'grad_norm': 0.6184998750686646, 'learning_rate': 2.7661016949152546e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:40:38<3:12:14,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:40:42<3:10:31,  3.50s/it]                                                       {'loss': 0.1576, 'grad_norm': 5.281492233276367, 'learning_rate': 2.7652542372881357e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:40:42<3:10:31,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:40:45<3:08:35,  3.47s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.13243113458156586, 'learning_rate': 2.7644067796610172e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:40:45<3:08:35,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:40:49<3:09:58,  3.50s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.06432905048131943, 'learning_rate': 2.7635593220338983e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:40:49<3:09:58,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:40:52<3:08:14,  3.46s/it]                                                       {'loss': 0.0128, 'grad_norm': 0.8460472822189331, 'learning_rate': 2.7627118644067794e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:40:52<3:08:14,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:40:56<3:09:01,  3.48s/it]                                                       {'loss': 0.0337, 'grad_norm': 2.9628472328186035, 'learning_rate': 2.7618644067796612e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:40:56<3:09:01,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:40:59<3:06:45,  3.44s/it]                                                       {'loss': 0.1839, 'grad_norm': 4.83107852935791, 'learning_rate': 2.7610169491525424e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:40:59<3:06:45,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:41:02<3:05:19,  3.41s/it]                                                       {'loss': 0.0485, 'grad_norm': 2.650763750076294, 'learning_rate': 2.760169491525424e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:41:02<3:05:19,  3.41s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:41:06<3:03:34,  3.38s/it]                                                       {'loss': 0.02, 'grad_norm': 0.8765933513641357, 'learning_rate': 2.759322033898305e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:41:06<3:03:34,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:41:09<3:06:09,  3.43s/it]                                                       {'loss': 0.0542, 'grad_norm': 3.741914987564087, 'learning_rate': 2.7584745762711868e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:41:09<3:06:09,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:41:13<3:13:52,  3.57s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.0354317426681519, 'learning_rate': 2.757627118644068e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:41:13<3:13:52,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:41:17<3:18:00,  3.65s/it]                                                       {'loss': 0.0483, 'grad_norm': 2.7095773220062256, 'learning_rate': 2.7567796610169494e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:41:17<3:18:00,  3.65s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:41:20<3:13:35,  3.57s/it]                                                       {'loss': 0.1488, 'grad_norm': 2.8781299591064453, 'learning_rate': 2.7559322033898305e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:41:20<3:13:35,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:41:24<3:10:12,  3.51s/it]                                                       {'loss': 0.0097, 'grad_norm': 0.5162750482559204, 'learning_rate': 2.755084745762712e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:41:24<3:10:12,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:41:27<3:06:55,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.037901926785707474, 'learning_rate': 2.754237288135593e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:41:27<3:06:55,  3.45s/it][2025-10-21 04:05:49,647] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:41:32<3:41:34,  4.09s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.06732776015996933, 'learning_rate': 2.753389830508475e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:41:32<3:41:34,  4.09s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:41:36<3:30:29,  3.89s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.32495778799057007, 'learning_rate': 2.752542372881356e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:41:36<3:30:29,  3.89s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:41:39<3:22:08,  3.74s/it]                                                       {'loss': 0.142, 'grad_norm': 2.602342367172241, 'learning_rate': 2.7516949152542375e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:41:39<3:22:08,  3.74s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:41:43<3:24:01,  3.77s/it]                                                       {'loss': 0.001, 'grad_norm': 0.11937038600444794, 'learning_rate': 2.7508474576271186e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:41:43<3:24:01,  3.77s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:41:47<3:19:59,  3.70s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.5305988192558289, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:41:47<3:19:59,  3.70s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:41:50<3:18:53,  3.68s/it]                                                       {'loss': 0.034, 'grad_norm': 2.3979291915893555, 'learning_rate': 2.7491525423728816e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:41:50<3:18:53,  3.68s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:41:54<3:13:51,  3.59s/it]                                                       {'loss': 0.0867, 'grad_norm': 3.2752208709716797, 'learning_rate': 2.748305084745763e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:41:54<3:13:51,  3.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:41:57<3:09:52,  3.51s/it]                                                       {'loss': 0.0455, 'grad_norm': 2.6280155181884766, 'learning_rate': 2.747457627118644e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:41:57<3:09:52,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:42:01<3:11:17,  3.54s/it]                                                       {'loss': 0.1336, 'grad_norm': 3.9274370670318604, 'learning_rate': 2.746610169491526e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:42:01<3:11:17,  3.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:42:04<3:08:36,  3.49s/it]                                                       {'loss': 0.0617, 'grad_norm': 1.827885389328003, 'learning_rate': 2.7457627118644068e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:42:04<3:08:36,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:42:07<3:08:09,  3.49s/it]                                                       {'loss': 0.0957, 'grad_norm': 3.964740037918091, 'learning_rate': 2.744915254237288e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:42:07<3:08:09,  3.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:42:11<3:06:52,  3.46s/it]                                                       {'loss': 0.1881, 'grad_norm': 4.6345906257629395, 'learning_rate': 2.7440677966101697e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:42:11<3:06:52,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:42:14<3:05:48,  3.44s/it]                                                       {'loss': 0.1367, 'grad_norm': 4.395071506500244, 'learning_rate': 2.7432203389830508e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:42:14<3:05:48,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:42:18<3:07:03,  3.47s/it]                                                       {'loss': 0.009, 'grad_norm': 0.8561700582504272, 'learning_rate': 2.7423728813559323e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:42:18<3:07:03,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:42:21<3:07:23,  3.48s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.5211595296859741, 'learning_rate': 2.7415254237288134e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:42:21<3:07:23,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:42:25<3:06:03,  3.45s/it]                                                       {'loss': 0.002, 'grad_norm': 0.19543136656284332, 'learning_rate': 2.7406779661016952e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:42:25<3:06:03,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:42:28<3:08:29,  3.50s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.06768858432769775, 'learning_rate': 2.7398305084745764e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:42:28<3:08:29,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:42:32<3:06:40,  3.47s/it]                                                       {'loss': 0.0173, 'grad_norm': 1.2797168493270874, 'learning_rate': 2.7389830508474578e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:42:32<3:06:40,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:42:35<3:07:01,  3.47s/it]                                                       {'loss': 0.1545, 'grad_norm': 2.5139036178588867, 'learning_rate': 2.738135593220339e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:42:35<3:07:01,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:42:39<3:05:33,  3.45s/it]                                                       {'loss': 0.0251, 'grad_norm': 1.9471657276153564, 'learning_rate': 2.7372881355932208e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:42:39<3:05:33,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:42:42<3:04:52,  3.44s/it]                                                       {'loss': 0.0214, 'grad_norm': 1.7334105968475342, 'learning_rate': 2.7364406779661015e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:42:42<3:04:52,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:42:46<3:06:45,  3.47s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.03950290009379387, 'learning_rate': 2.7355932203389833e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:42:46<3:06:45,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:42:49<3:13:59,  3.61s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.5738180875778198, 'learning_rate': 2.7347457627118645e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:42:49<3:13:59,  3.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:42:53<3:09:17,  3.52s/it]                                                       {'loss': 0.0245, 'grad_norm': 1.0630803108215332, 'learning_rate': 2.733898305084746e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:42:53<3:09:17,  3.52s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:42:56<3:05:57,  3.46s/it]                                                       {'loss': 0.196, 'grad_norm': 3.893584966659546, 'learning_rate': 2.733050847457627e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:42:56<3:05:57,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:43:00<3:07:08,  3.48s/it]                                                       {'loss': 0.0488, 'grad_norm': 1.1455459594726562, 'learning_rate': 2.732203389830509e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:43:00<3:07:08,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:43:03<3:04:37,  3.44s/it]                                                       {'loss': 0.0267, 'grad_norm': 1.9998630285263062, 'learning_rate': 2.73135593220339e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:43:03<3:04:37,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:43:06<3:06:15,  3.47s/it]                                                       {'loss': 0.1279, 'grad_norm': 4.418071746826172, 'learning_rate': 2.7305084745762715e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:43:07<3:06:15,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:43:10<3:05:07,  3.45s/it]                                                       {'loss': 0.0226, 'grad_norm': 1.2379683256149292, 'learning_rate': 2.7296610169491526e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:43:10<3:05:07,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:43:13<3:03:29,  3.42s/it]                                                       {'loss': 0.0175, 'grad_norm': 1.4735432863235474, 'learning_rate': 2.7288135593220337e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:43:13<3:03:29,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:43:17<3:05:54,  3.47s/it]                                                       {'loss': 0.042, 'grad_norm': 2.104391098022461, 'learning_rate': 2.7279661016949155e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:43:17<3:05:54,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:43:20<3:03:23,  3.42s/it]                                                       {'loss': 0.017, 'grad_norm': 1.0411509275436401, 'learning_rate': 2.7271186440677963e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:43:20<3:03:23,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:43:23<3:01:56,  3.39s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.2431749850511551, 'learning_rate': 2.726271186440678e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:43:23<3:01:56,  3.39s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:43:27<3:03:53,  3.43s/it]                                                       {'loss': 0.0472, 'grad_norm': 2.369769811630249, 'learning_rate': 2.7254237288135593e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:43:27<3:03:53,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:43:31<3:09:00,  3.53s/it]                                                       {'loss': 0.008, 'grad_norm': 0.5855798125267029, 'learning_rate': 2.7245762711864407e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:43:31<3:09:00,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:43:34<3:08:57,  3.53s/it]                                                       {'loss': 0.0387, 'grad_norm': 2.6591672897338867, 'learning_rate': 2.723728813559322e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:43:34<3:08:57,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:43:38<3:07:27,  3.50s/it]                                                       {'loss': 0.1306, 'grad_norm': 4.894260883331299, 'learning_rate': 2.7228813559322037e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:43:38<3:07:27,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:43:41<3:05:20,  3.46s/it]                                                       {'loss': 0.1662, 'grad_norm': 3.882554769515991, 'learning_rate': 2.7220338983050848e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:43:41<3:05:20,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:43:44<3:03:09,  3.42s/it]                                                       {'loss': 0.1034, 'grad_norm': 6.438259124755859, 'learning_rate': 2.7211864406779663e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:43:44<3:03:09,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:43:48<3:02:32,  3.41s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.13337557017803192, 'learning_rate': 2.7203389830508474e-05, 'epoch': 0.47}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:43:48<3:02:32,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:43:51<3:02:50,  3.42s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.2438107132911682, 'learning_rate': 2.7194915254237292e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:43:51<3:02:50,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:43:55<3:02:46,  3.42s/it]                                                       {'loss': 0.0685, 'grad_norm': 3.820035934448242, 'learning_rate': 2.7186440677966103e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:43:55<3:02:46,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:43:58<3:02:58,  3.42s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.07943315804004669, 'learning_rate': 2.7177966101694918e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:43:58<3:02:58,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:44:02<3:09:39,  3.55s/it]                                                       {'loss': 0.022, 'grad_norm': 1.171581745147705, 'learning_rate': 2.716949152542373e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:44:02<3:09:39,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:44:05<3:07:43,  3.51s/it]                                                       {'loss': 0.1127, 'grad_norm': 3.5560789108276367, 'learning_rate': 2.7161016949152547e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:44:05<3:07:43,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:44:09<3:05:00,  3.46s/it]                                                       {'loss': 0.2057, 'grad_norm': 4.613821983337402, 'learning_rate': 2.7152542372881355e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:44:09<3:05:00,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:44:12<3:05:28,  3.47s/it]                                                       {'loss': 0.0691, 'grad_norm': 3.286328077316284, 'learning_rate': 2.7144067796610173e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:44:12<3:05:28,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:44:16<3:08:35,  3.53s/it]                                                       {'loss': 0.0902, 'grad_norm': 2.1007308959960938, 'learning_rate': 2.7135593220338985e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:44:16<3:08:35,  3.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:44:19<3:07:02,  3.51s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.06278669834136963, 'learning_rate': 2.71271186440678e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:44:19<3:07:02,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:44:23<3:03:23,  3.44s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.2585783302783966, 'learning_rate': 2.711864406779661e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:44:23<3:03:23,  3.44s/it][2025-10-21 04:08:45,335] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:44:28<3:38:07,  4.09s/it]                                                       {'loss': 0.1352, 'grad_norm': 3.50156569480896, 'learning_rate': 2.7110169491525422e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:44:28<3:38:07,  4.09s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:44:32<3:26:17,  3.87s/it]                                                       {'loss': 0.0423, 'grad_norm': 1.4490972757339478, 'learning_rate': 2.710169491525424e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:44:32<3:26:17,  3.87s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:44:35<3:18:05,  3.72s/it]                                                       {'loss': 0.0162, 'grad_norm': 0.7809219360351562, 'learning_rate': 2.709322033898305e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:44:35<3:18:05,  3.72s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:44:38<3:13:03,  3.62s/it]                                                       {'loss': 0.0894, 'grad_norm': 3.19343638420105, 'learning_rate': 2.7084745762711866e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:44:38<3:13:03,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:44:42<3:14:53,  3.66s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.08614809066057205, 'learning_rate': 2.7076271186440677e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:44:42<3:14:53,  3.66s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:44:45<3:10:33,  3.58s/it]                                                       {'loss': 0.0905, 'grad_norm': 3.2513442039489746, 'learning_rate': 2.7067796610169495e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:44:45<3:10:33,  3.58s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:44:49<3:08:41,  3.55s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015634337440133095, 'learning_rate': 2.7059322033898303e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:44:49<3:08:41,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:44:52<3:06:16,  3.50s/it]                                                       {'loss': 0.0677, 'grad_norm': 1.743538737297058, 'learning_rate': 2.705084745762712e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:44:52<3:06:16,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:44:56<3:04:14,  3.46s/it]                                                       {'loss': 0.2371, 'grad_norm': 5.6009016036987305, 'learning_rate': 2.7042372881355932e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:44:56<3:04:14,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:45:00<3:12:32,  3.62s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.147449016571045, 'learning_rate': 2.7033898305084747e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:45:00<3:12:32,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:45:03<3:11:08,  3.60s/it]                                                       {'loss': 0.1253, 'grad_norm': 5.670042514801025, 'learning_rate': 2.702542372881356e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:45:03<3:11:08,  3.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:45:07<3:07:37,  3.53s/it]                                                       {'loss': 0.0398, 'grad_norm': 2.597409248352051, 'learning_rate': 2.7016949152542376e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:45:07<3:07:37,  3.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:45:10<3:06:20,  3.51s/it]                                                       {'loss': 0.0287, 'grad_norm': 2.0146677494049072, 'learning_rate': 2.7008474576271188e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:45:10<3:06:20,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:45:13<3:04:35,  3.48s/it]                                                       {'loss': 0.0692, 'grad_norm': 3.7361624240875244, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:45:13<3:04:35,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:45:17<3:03:15,  3.45s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.12326910346746445, 'learning_rate': 2.6991525423728814e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:45:17<3:03:15,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:45:20<3:01:32,  3.42s/it]                                                       {'loss': 0.081, 'grad_norm': 3.0216825008392334, 'learning_rate': 2.6983050847457632e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:45:20<3:01:32,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:45:24<3:04:50,  3.48s/it]                                                       {'loss': 0.0771, 'grad_norm': 4.607018947601318, 'learning_rate': 2.6974576271186443e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:45:24<3:04:50,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:45:27<3:05:23,  3.50s/it]                                                       {'loss': 0.1544, 'grad_norm': 4.31733512878418, 'learning_rate': 2.6966101694915258e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:45:27<3:05:23,  3.50s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:45:31<3:04:35,  3.48s/it]                                                       {'loss': 0.0327, 'grad_norm': 1.6728131771087646, 'learning_rate': 2.695762711864407e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:45:31<3:04:35,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:45:35<3:16:22,  3.71s/it]                                                       {'loss': 0.0291, 'grad_norm': 2.2609012126922607, 'learning_rate': 2.6949152542372884e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:45:35<3:16:22,  3.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:45:38<3:11:55,  3.62s/it]                                                       {'loss': 0.0213, 'grad_norm': 2.30973219871521, 'learning_rate': 2.6940677966101695e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:45:38<3:11:55,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:45:42<3:07:19,  3.54s/it]                                                       {'loss': 0.0794, 'grad_norm': 2.0309131145477295, 'learning_rate': 2.6932203389830506e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:45:42<3:07:19,  3.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:45:45<3:04:03,  3.48s/it]                                                       {'loss': 0.0929, 'grad_norm': 3.2449610233306885, 'learning_rate': 2.6923728813559324e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:45:45<3:04:03,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:45:49<3:02:45,  3.45s/it]                                                       {'loss': 0.1616, 'grad_norm': 5.321524620056152, 'learning_rate': 2.6915254237288136e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:45:49<3:02:45,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:45:52<3:02:51,  3.46s/it]                                                       {'loss': 0.0106, 'grad_norm': 0.6546883583068848, 'learning_rate': 2.690677966101695e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:45:52<3:02:51,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:45:55<3:02:08,  3.44s/it]                                                       {'loss': 0.0077, 'grad_norm': 0.5310576558113098, 'learning_rate': 2.689830508474576e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:45:55<3:02:08,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:45:59<3:02:18,  3.45s/it]                                                       {'loss': 0.0512, 'grad_norm': 3.0044894218444824, 'learning_rate': 2.688983050847458e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:45:59<3:02:18,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:46:02<3:01:59,  3.44s/it]                                                       {'loss': 0.0193, 'grad_norm': 1.4910235404968262, 'learning_rate': 2.688135593220339e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:46:02<3:01:59,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:46:06<3:01:16,  3.43s/it]                                                       {'loss': 0.2412, 'grad_norm': 6.95451021194458, 'learning_rate': 2.6872881355932206e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:46:06<3:01:16,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:46:09<3:02:32,  3.46s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.050884414464235306, 'learning_rate': 2.6864406779661017e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:46:09<3:02:32,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:46:13<3:01:57,  3.45s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.06213458254933357, 'learning_rate': 2.685593220338983e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:46:13<3:01:57,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:46:16<2:59:35,  3.40s/it]                                                       {'loss': 0.0114, 'grad_norm': 0.584403932094574, 'learning_rate': 2.6847457627118643e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:46:16<2:59:35,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:46:19<2:59:58,  3.41s/it]                                                       {'loss': 0.0306, 'grad_norm': 2.4234962463378906, 'learning_rate': 2.683898305084746e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:46:19<2:59:58,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:46:23<2:59:14,  3.40s/it]                                                       {'loss': 0.0438, 'grad_norm': 1.733991026878357, 'learning_rate': 2.6830508474576272e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:46:23<2:59:14,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:46:26<3:00:24,  3.42s/it]                                                       {'loss': 0.0593, 'grad_norm': 3.4335038661956787, 'learning_rate': 2.6822033898305087e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:46:26<3:00:24,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:46:30<3:00:23,  3.42s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.1475636214017868, 'learning_rate': 2.6813559322033898e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:46:30<3:00:23,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:46:33<2:59:47,  3.41s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.035043563693761826, 'learning_rate': 2.6805084745762716e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:46:33<2:59:47,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:46:36<2:59:48,  3.41s/it]                                                       {'loss': 0.0827, 'grad_norm': 4.74102258682251, 'learning_rate': 2.6796610169491527e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:46:36<2:59:48,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:46:40<2:58:48,  3.39s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.5425673723220825, 'learning_rate': 2.6788135593220342e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:46:40<2:58:48,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:46:43<3:00:06,  3.42s/it]                                                       {'loss': 0.0569, 'grad_norm': 3.040933132171631, 'learning_rate': 2.6779661016949153e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:46:43<3:00:06,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:46:47<3:00:12,  3.42s/it]                                                       {'loss': 0.0285, 'grad_norm': 2.9224050045013428, 'learning_rate': 2.677118644067797e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:46:47<3:00:12,  3.42s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:46:51<3:06:22,  3.54s/it]                                                       {'loss': 0.04, 'grad_norm': 1.6491199731826782, 'learning_rate': 2.676271186440678e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:46:51<3:06:22,  3.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:46:54<3:10:44,  3.63s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.16997621953487396, 'learning_rate': 2.675423728813559e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:46:54<3:10:44,  3.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:46:58<3:05:36,  3.53s/it]                                                       {'loss': 0.1982, 'grad_norm': 3.6266796588897705, 'learning_rate': 2.674576271186441e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:46:58<3:05:36,  3.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:47:01<3:03:44,  3.49s/it]                                                       {'loss': 0.0392, 'grad_norm': 1.4478282928466797, 'learning_rate': 2.673728813559322e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:47:01<3:03:44,  3.49s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:47:05<3:09:26,  3.60s/it]                                                       {'loss': 0.1797, 'grad_norm': 4.009155750274658, 'learning_rate': 2.6728813559322035e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:47:05<3:09:26,  3.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:47:09<3:11:35,  3.65s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.08530427515506744, 'learning_rate': 2.6720338983050846e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:47:09<3:11:35,  3.65s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:47:12<3:14:18,  3.70s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.24501314759254456, 'learning_rate': 2.6711864406779664e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:47:12<3:14:18,  3.70s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:47:16<3:11:07,  3.64s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.0463363453745842, 'learning_rate': 2.6703389830508475e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:47:16<3:11:07,  3.64s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:47:19<3:06:11,  3.55s/it]                                                       {'loss': 0.0411, 'grad_norm': 3.3567373752593994, 'learning_rate': 2.669491525423729e-05, 'epoch': 0.47}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:47:19<3:06:11,  3.55s/it][2025-10-21 04:11:42,061] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenBlockPF-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:47:25<3:39:54,  4.19s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.3882558345794678, 'learning_rate': 2.66864406779661e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:47:25<3:39:54,  4.19s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:47:28<3:28:14,  3.97s/it]                                                       {'loss': 0.2242, 'grad_norm': 3.5524446964263916, 'learning_rate': 2.667796610169492e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:47:28<3:28:14,  3.97s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:47:32<3:18:13,  3.78s/it]                                                       {'loss': 0.079, 'grad_norm': 3.6946446895599365, 'learning_rate': 2.6669491525423727e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:47:32<3:18:13,  3.78s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:47:36<3:17:25,  3.77s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.207082748413086, 'learning_rate': 2.6661016949152545e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:47:36<3:17:25,  3.77s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:47:39<3:10:22,  3.63s/it]                                                       {'loss': 0.1484, 'grad_norm': 4.748077392578125, 'learning_rate': 2.6652542372881357e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:47:39<3:10:22,  3.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:47:42<3:08:57,  3.61s/it]                                                       {'loss': 0.0404, 'grad_norm': 1.7310454845428467, 'learning_rate': 2.664406779661017e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:47:42<3:08:57,  3.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:47:46<3:04:55,  3.53s/it]                                                       {'loss': 0.2633, 'grad_norm': 5.813192844390869, 'learning_rate': 2.6635593220338983e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:47:46<3:04:55,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:47:49<3:02:51,  3.49s/it]                                                       {'loss': 0.0701, 'grad_norm': 3.4196486473083496, 'learning_rate': 2.66271186440678e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:47:49<3:02:51,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:47:53<3:02:46,  3.49s/it]                                                       {'loss': 0.0611, 'grad_norm': 3.082662343978882, 'learning_rate': 2.6618644067796612e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:47:53<3:02:46,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:47:56<3:02:20,  3.48s/it]                                                       {'loss': 0.0745, 'grad_norm': 2.1377065181732178, 'learning_rate': 2.6610169491525427e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:47:56<3:02:20,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:48:00<3:02:43,  3.49s/it]                                                       {'loss': 0.0422, 'grad_norm': 3.2217118740081787, 'learning_rate': 2.6601694915254238e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:48:00<3:02:43,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:48:03<3:01:28,  3.47s/it]                                                       {'loss': 0.1484, 'grad_norm': 4.957766532897949, 'learning_rate': 2.6593220338983056e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:48:03<3:01:28,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:48:06<3:01:18,  3.47s/it]                                                       {'loss': 0.0673, 'grad_norm': 2.7467894554138184, 'learning_rate': 2.6584745762711867e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:48:06<3:01:18,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:48:10<2:58:55,  3.42s/it]                                                       {'loss': 0.0166, 'grad_norm': 1.2043118476867676, 'learning_rate': 2.6576271186440675e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:48:10<2:58:55,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:48:13<2:59:00,  3.43s/it]                                                       {'loss': 0.0222, 'grad_norm': 1.6709424257278442, 'learning_rate': 2.6567796610169493e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:48:13<2:59:00,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:48:17<2:58:32,  3.42s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.3663906157016754, 'learning_rate': 2.6559322033898304e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:48:17<2:58:32,  3.42s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:48:20<2:57:41,  3.40s/it]                                                       {'loss': 0.0138, 'grad_norm': 0.9281922578811646, 'learning_rate': 2.655084745762712e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:48:20<2:57:41,  3.40s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:48:24<2:59:27,  3.44s/it]                                                       {'loss': 0.004, 'grad_norm': 0.3019516170024872, 'learning_rate': 2.654237288135593e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:48:24<2:59:27,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:48:27<3:03:00,  3.51s/it]                                                       {'loss': 0.032, 'grad_norm': 1.2766835689544678, 'learning_rate': 2.653389830508475e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:48:27<3:03:00,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:48:31<3:00:13,  3.45s/it]                                                       {'loss': 0.0088, 'grad_norm': 0.559544563293457, 'learning_rate': 2.652542372881356e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:48:31<3:00:13,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:48:34<2:59:38,  3.44s/it]                                                       {'loss': 0.1296, 'grad_norm': 4.545300483703613, 'learning_rate': 2.6516949152542374e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:48:34<2:59:38,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:48:37<2:58:52,  3.43s/it]                                                       {'loss': 0.0111, 'grad_norm': 0.5312567949295044, 'learning_rate': 2.6508474576271186e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:48:37<2:58:52,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:48:41<2:58:43,  3.43s/it]                                                       {'loss': 0.032, 'grad_norm': 2.372439384460449, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:48:41<2:58:43,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:48:44<2:59:05,  3.44s/it]                                                       {'loss': 0.0768, 'grad_norm': 4.489250183105469, 'learning_rate': 2.6491525423728815e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:48:44<2:59:05,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:48:48<2:57:42,  3.41s/it]                                                       {'loss': 0.0487, 'grad_norm': 4.176641464233398, 'learning_rate': 2.648305084745763e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:48:48<2:57:42,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:48:51<3:02:45,  3.51s/it]                                                       {'loss': 0.0635, 'grad_norm': 4.726816654205322, 'learning_rate': 2.647457627118644e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:48:51<3:02:45,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:48:55<3:02:05,  3.50s/it]                                                       {'loss': 0.0404, 'grad_norm': 2.860191822052002, 'learning_rate': 2.6466101694915256e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:48:55<3:02:05,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:48:58<3:01:09,  3.48s/it]                                                       {'loss': 0.0484, 'grad_norm': 2.114067554473877, 'learning_rate': 2.6457627118644067e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:48:58<3:01:09,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:49:02<2:59:21,  3.45s/it]                                                       {'loss': 0.067, 'grad_norm': 1.4160405397415161, 'learning_rate': 2.6449152542372885e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:49:02<2:59:21,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:49:05<3:05:50,  3.57s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.19460636377334595, 'learning_rate': 2.6440677966101696e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:49:05<3:05:50,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:49:09<3:02:11,  3.50s/it]                                                       {'loss': 0.0578, 'grad_norm': 2.851472854614258, 'learning_rate': 2.643220338983051e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:49:09<3:02:11,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:49:12<2:59:59,  3.46s/it]                                                       {'loss': 0.0077, 'grad_norm': 0.8462070226669312, 'learning_rate': 2.6423728813559322e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:49:12<2:59:59,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:49:16<2:59:32,  3.46s/it]                                                       {'loss': 0.068, 'grad_norm': 3.651413917541504, 'learning_rate': 2.641525423728814e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:49:16<2:59:32,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:49:19<2:59:27,  3.46s/it]                                                       {'loss': 0.0782, 'grad_norm': 4.234682083129883, 'learning_rate': 2.640677966101695e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:49:19<2:59:27,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:49:23<3:13:24,  3.73s/it]                                                       {'loss': 0.0342, 'grad_norm': 1.5193753242492676, 'learning_rate': 2.6398305084745763e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:49:23<3:13:24,  3.73s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:49:27<3:07:49,  3.62s/it]                                                       {'loss': 0.01, 'grad_norm': 0.4432172179222107, 'learning_rate': 2.6389830508474578e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:49:27<3:07:49,  3.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:49:30<3:05:15,  3.57s/it]                                                       {'loss': 0.0392, 'grad_norm': 1.4943735599517822, 'learning_rate': 2.638135593220339e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:49:30<3:05:15,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:49:34<3:03:36,  3.54s/it]                                                       {'loss': 0.1227, 'grad_norm': 3.7721309661865234, 'learning_rate': 2.6372881355932204e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:49:34<3:03:36,  3.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:49:37<3:01:14,  3.50s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.3751547336578369, 'learning_rate': 2.6364406779661015e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:49:37<3:01:14,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:49:41<3:00:55,  3.49s/it]                                                       {'loss': 0.0514, 'grad_norm': 3.748389959335327, 'learning_rate': 2.6355932203389833e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:49:41<3:00:55,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:49:44<3:01:30,  3.50s/it]                                                       {'loss': 0.1428, 'grad_norm': 4.029402256011963, 'learning_rate': 2.6347457627118644e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:49:44<3:01:30,  3.50s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:49:47<2:58:30,  3.45s/it]                                                       {'loss': 0.277, 'grad_norm': 5.113460540771484, 'learning_rate': 2.633898305084746e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:49:47<2:58:30,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:49:51<3:00:18,  3.48s/it]                                                       {'loss': 0.0752, 'grad_norm': 4.810100555419922, 'learning_rate': 2.633050847457627e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:49:51<3:00:18,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:49:54<2:58:37,  3.45s/it]                                                       {'loss': 0.0385, 'grad_norm': 1.9578583240509033, 'learning_rate': 2.6322033898305088e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:49:54<2:58:37,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:49:58<2:57:43,  3.43s/it]                                                       {'loss': 0.02, 'grad_norm': 1.4842491149902344, 'learning_rate': 2.63135593220339e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:49:58<2:57:43,  3.43s/it]