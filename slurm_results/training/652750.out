==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name 05Nov-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 1e-5 --max_steps 6000 --warmup_steps 100 --save_steps 100 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/train.log
W1106 22:50:39.212000 139967737603904 torch/distributed/run.py:779] 
W1106 22:50:39.212000 139967737603904 torch/distributed/run.py:779] *****************************************
W1106 22:50:39.212000 139967737603904 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1106 22:50:39.212000 139967737603904 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-11-06 22:50:47,436] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.06it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.83it/s]
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251106_225047-ddhzgqnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 05Nov-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/ddhzgqnm
[2025-11-06 22:50:49,138] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.05it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.70it/s]
[2025-11-06 22:50:49,838] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-11-06 22:50:58,751] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-11-06 22:51:00,130] INFO [src.utils:19] PeftModel(
  (base_model): LoraModel(
    (model): Qwen2VLForConditionalGeneration(
      (visual): Qwen2VisionTransformerPretrainedModel(
        (patch_embed): PatchEmbed(
          (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
        )
        (rotary_pos_emb): VisionRotaryEmbedding()
        (blocks): ModuleList(
          (0-31): 32 x Qwen2VLVisionBlock(
            (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (attn): VisionFlashAttention2(
              (qkv): Linear(in_features=1280, out_features=3840, bias=True)
              (proj): Linear(in_features=1280, out_features=1280, bias=True)
            )
            (mlp): VisionMlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): QuickGELUActivation()
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            )
          )
        )
        (merger): PatchMerger(
          (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=5120, out_features=5120, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=5120, out_features=1536, bias=True)
          )
        )
      )
      (model): Qwen2VLModel(
        (embed_tokens): Embedding(151936, 1536)
        (layers): ModuleList(
          (0-27): 28 x Qwen2VLDecoderLayer(
            (self_attn): Qwen2VLFlashAttention2(
              (q_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=1536, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (k_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=256, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=256, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (v_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=256, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=256, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=1536, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=1536, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (rotary_emb): Qwen2VLRotaryEmbedding()
            )
            (mlp): Qwen2MLP(
              (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
              (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
              (down_proj): lora.Linear(
                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8960, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=1536, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict(
                  (default): lora.dora.DoraLinearLayer()
                )
              )
              (act_fn): SiLU()
            )
            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
          )
        )
        (norm): Qwen2RMSNorm((1536,), eps=1e-06)
        (rotary_emb): Qwen2VLRotaryEmbedding()
      )
      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
    )
  )
)
[2025-11-06 22:51:00,141] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-11-06 22:51:00,141] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-11-06 22:51:05,038] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-11-06 22:51:05,039] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-11-06 22:51:05,883] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-11-06 22:51:05,884] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-11-06 22:51:05,885] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-11-06 22:51:05,886] INFO [src.utils:19] ==================================================
[2025-11-06 22:51:05,886] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-11-06 22:51:05,887] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-06 22:51:05,888] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-11-06 22:51:05,888] INFO [src.utils:19] ==================================================
[2025-11-06 22:51:09,286] INFO [src.trainer:342] ***** Running training *****
[2025-11-06 22:51:09,286] INFO [src.trainer:342] ***** Running training *****
[2025-11-06 22:51:09,286] INFO [src.trainer:343]   Num examples = 192,000
[2025-11-06 22:51:09,286] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-06 22:51:09,286] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-11-06 22:51:09,286] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-06 22:51:09,286] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-11-06 22:51:09,286] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-11-06 22:51:09,287] INFO [src.trainer:343]   Num examples = 192,000
[2025-11-06 22:51:09,288] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-11-06 22:51:09,288] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-11-06 22:51:09,288] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-11-06 22:51:09,288] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-11-06 22:51:09,289] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-11-06 22:51:09,298] INFO [src.trainer:351]   Number of trainable parameters = 9,205,248
[2025-11-06 22:51:09,302] INFO [src.trainer:351]   Number of trainable parameters = 9,205,248
[2025-11-06 22:51:09,309] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.tail_token', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-11-06 22:51:09,314] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.tail_token', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/6000 [00:04<8:16:11,  4.96s/it]                                                  {'loss': 20.6106, 'grad_norm': 1370.5103759765625, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<8:16:11,  4.96s/it]  0%|          | 2/6000 [00:08<6:36:08,  3.96s/it]                                                  {'loss': 17.9095, 'grad_norm': 2169.52880859375, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}
  0%|          | 2/6000 [00:08<6:36:08,  3.96s/it]  0%|          | 3/6000 [00:11<6:12:04,  3.72s/it]                                                  {'loss': 16.0816, 'grad_norm': 2000.1663818359375, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.0}
  0%|          | 3/6000 [00:11<6:12:04,  3.72s/it]  0%|          | 4/6000 [00:15<6:01:35,  3.62s/it]                                                  {'loss': 16.4792, 'grad_norm': 1893.58447265625, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.0}
  0%|          | 4/6000 [00:15<6:01:35,  3.62s/it]  0%|          | 5/6000 [00:18<5:49:36,  3.50s/it]                                                  {'loss': 17.092, 'grad_norm': 1964.8497314453125, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 5/6000 [00:18<5:49:36,  3.50s/it]  0%|          | 6/6000 [00:21<5:46:03,  3.46s/it]                                                  {'loss': 18.4483, 'grad_norm': 1513.8033447265625, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.0}
  0%|          | 6/6000 [00:21<5:46:03,  3.46s/it]  0%|          | 7/6000 [00:25<5:43:09,  3.44s/it]                                                  {'loss': 17.8132, 'grad_norm': 1825.7178955078125, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.0}
  0%|          | 7/6000 [00:25<5:43:09,  3.44s/it]  0%|          | 8/6000 [00:28<5:37:10,  3.38s/it]                                                  {'loss': 19.5331, 'grad_norm': 1751.4205322265625, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.0}
  0%|          | 8/6000 [00:28<5:37:10,  3.38s/it]  0%|          | 9/6000 [00:31<5:36:57,  3.37s/it]                                                  {'loss': 15.4396, 'grad_norm': 1745.2808837890625, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.0}
  0%|          | 9/6000 [00:31<5:36:57,  3.37s/it]  0%|          | 10/6000 [00:35<5:35:16,  3.36s/it]                                                   {'loss': 18.4717, 'grad_norm': 1368.7529296875, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:35<5:35:16,  3.36s/it]  0%|          | 11/6000 [00:38<5:44:24,  3.45s/it]                                                   {'loss': 20.9234, 'grad_norm': 1566.4903564453125, 'learning_rate': 1.1e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:38<5:44:24,  3.45s/it]  0%|          | 12/6000 [00:42<5:46:02,  3.47s/it]                                                   {'loss': 18.1812, 'grad_norm': 1856.38037109375, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:42<5:46:02,  3.47s/it]  0%|          | 13/6000 [00:45<5:43:14,  3.44s/it]                                                   {'loss': 17.9952, 'grad_norm': 2398.949951171875, 'learning_rate': 1.3e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:45<5:43:14,  3.44s/it]  0%|          | 14/6000 [00:49<5:44:31,  3.45s/it]                                                   {'loss': 17.827, 'grad_norm': 2891.142822265625, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:49<5:44:31,  3.45s/it]  0%|          | 15/6000 [00:52<5:40:38,  3.41s/it]                                                   {'loss': 14.4755, 'grad_norm': 2429.1455078125, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:52<5:40:38,  3.41s/it]  0%|          | 16/6000 [00:55<5:38:27,  3.39s/it]                                                   {'loss': 16.4778, 'grad_norm': 1609.235107421875, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:55<5:38:27,  3.39s/it]  0%|          | 17/6000 [00:59<5:36:48,  3.38s/it]                                                   {'loss': 15.683, 'grad_norm': 1378.2183837890625, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:59<5:36:48,  3.38s/it]  0%|          | 18/6000 [01:02<5:38:09,  3.39s/it]                                                   {'loss': 12.4139, 'grad_norm': 1453.872802734375, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.0}
  0%|          | 18/6000 [01:02<5:38:09,  3.39s/it]  0%|          | 19/6000 [01:05<5:36:41,  3.38s/it]                                                   {'loss': 13.6225, 'grad_norm': 2056.66552734375, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.0}
  0%|          | 19/6000 [01:05<5:36:41,  3.38s/it]  0%|          | 20/6000 [01:09<5:38:43,  3.40s/it]                                                   {'loss': 15.0098, 'grad_norm': 1987.5517578125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 20/6000 [01:09<5:38:43,  3.40s/it]  0%|          | 21/6000 [01:12<5:43:38,  3.45s/it]                                                   {'loss': 12.5734, 'grad_norm': 1830.7860107421875, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.0}
  0%|          | 21/6000 [01:12<5:43:38,  3.45s/it]  0%|          | 22/6000 [01:16<5:44:41,  3.46s/it]                                                   {'loss': 11.8047, 'grad_norm': 1779.0953369140625, 'learning_rate': 2.2e-06, 'epoch': 0.0}
  0%|          | 22/6000 [01:16<5:44:41,  3.46s/it]  0%|          | 23/6000 [01:19<5:41:44,  3.43s/it]                                                   {'loss': 11.2982, 'grad_norm': 1926.8822021484375, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.0}
  0%|          | 23/6000 [01:19<5:41:44,  3.43s/it]  0%|          | 24/6000 [01:23<5:46:41,  3.48s/it]                                                   {'loss': 10.965, 'grad_norm': 1664.4820556640625, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.0}
  0%|          | 24/6000 [01:23<5:46:41,  3.48s/it]  0%|          | 25/6000 [01:26<5:45:08,  3.47s/it]                                                   {'loss': 11.3946, 'grad_norm': 2851.974853515625, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 25/6000 [01:26<5:45:08,  3.47s/it]  0%|          | 26/6000 [01:30<5:45:39,  3.47s/it]                                                   {'loss': 9.6922, 'grad_norm': 2829.543701171875, 'learning_rate': 2.6e-06, 'epoch': 0.0}
  0%|          | 26/6000 [01:30<5:45:39,  3.47s/it]  0%|          | 27/6000 [01:33<5:46:06,  3.48s/it]                                                   {'loss': 7.5696, 'grad_norm': 1750.48583984375, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.0}
  0%|          | 27/6000 [01:33<5:46:06,  3.48s/it]  0%|          | 28/6000 [01:38<6:12:10,  3.74s/it]                                                   {'loss': 8.1159, 'grad_norm': 2648.505615234375, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.0}
  0%|          | 28/6000 [01:38<6:12:10,  3.74s/it]  0%|          | 29/6000 [01:41<6:02:02,  3.64s/it]                                                   {'loss': 7.4719, 'grad_norm': 2014.66796875, 'learning_rate': 2.9e-06, 'epoch': 0.0}
  0%|          | 29/6000 [01:41<6:02:02,  3.64s/it]  0%|          | 30/6000 [01:44<5:55:21,  3.57s/it]                                                   {'loss': 5.9142, 'grad_norm': 2869.73388671875, 'learning_rate': 3e-06, 'epoch': 0.01}
  0%|          | 30/6000 [01:44<5:55:21,  3.57s/it]  1%|          | 31/6000 [01:48<5:47:49,  3.50s/it]                                                   {'loss': 6.6341, 'grad_norm': 2545.9912109375, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.01}
  1%|          | 31/6000 [01:48<5:47:49,  3.50s/it]  1%|          | 32/6000 [01:51<5:46:20,  3.48s/it]                                                   {'loss': 5.4997, 'grad_norm': 3885.850830078125, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.01}
  1%|          | 32/6000 [01:51<5:46:20,  3.48s/it]  1%|          | 33/6000 [01:55<5:45:00,  3.47s/it]                                                   {'loss': 4.0657, 'grad_norm': 753.2557373046875, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.01}
  1%|          | 33/6000 [01:55<5:45:00,  3.47s/it]  1%|          | 34/6000 [01:58<5:42:43,  3.45s/it]                                                   {'loss': 4.6429, 'grad_norm': 2900.9228515625, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.01}
  1%|          | 34/6000 [01:58<5:42:43,  3.45s/it]  1%|          | 35/6000 [02:02<5:43:35,  3.46s/it]                                                   {'loss': 4.6288, 'grad_norm': 1247.5489501953125, 'learning_rate': 3.5e-06, 'epoch': 0.01}
  1%|          | 35/6000 [02:02<5:43:35,  3.46s/it]  1%|          | 36/6000 [02:05<5:39:48,  3.42s/it]                                                   {'loss': 4.9996, 'grad_norm': 1123.2041015625, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.01}
  1%|          | 36/6000 [02:05<5:39:48,  3.42s/it]  1%|          | 37/6000 [02:08<5:39:01,  3.41s/it]                                                   {'loss': 4.4746, 'grad_norm': 975.6617431640625, 'learning_rate': 3.7e-06, 'epoch': 0.01}
  1%|          | 37/6000 [02:08<5:39:01,  3.41s/it]  1%|          | 38/6000 [02:12<5:37:00,  3.39s/it]                                                   {'loss': 3.9839, 'grad_norm': 622.7181396484375, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.01}
  1%|          | 38/6000 [02:12<5:37:00,  3.39s/it]  1%|          | 39/6000 [02:15<5:35:11,  3.37s/it]                                                   {'loss': 4.2229, 'grad_norm': 762.3016967773438, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.01}
  1%|          | 39/6000 [02:15<5:35:11,  3.37s/it]  1%|          | 40/6000 [02:18<5:37:44,  3.40s/it]                                                   {'loss': 4.2946, 'grad_norm': 322.2309875488281, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 40/6000 [02:18<5:37:44,  3.40s/it]  1%|          | 41/6000 [02:22<5:38:09,  3.40s/it]                                                   {'loss': 3.4664, 'grad_norm': 630.9425659179688, 'learning_rate': 4.1e-06, 'epoch': 0.01}
  1%|          | 41/6000 [02:22<5:38:09,  3.40s/it]  1%|          | 42/6000 [02:25<5:37:37,  3.40s/it]                                                   {'loss': 3.17, 'grad_norm': 262.0728759765625, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.01}
  1%|          | 42/6000 [02:25<5:37:37,  3.40s/it]  1%|          | 43/6000 [02:30<6:10:18,  3.73s/it]                                                   {'loss': 3.8052, 'grad_norm': 543.544677734375, 'learning_rate': 4.3e-06, 'epoch': 0.01}
  1%|          | 43/6000 [02:30<6:10:18,  3.73s/it]  1%|          | 44/6000 [02:34<6:28:00,  3.91s/it]                                                   {'loss': 3.4345, 'grad_norm': 811.6814575195312, 'learning_rate': 4.4e-06, 'epoch': 0.01}
  1%|          | 44/6000 [02:34<6:28:00,  3.91s/it]  1%|          | 45/6000 [02:38<6:16:26,  3.79s/it]                                                   {'loss': 3.3377, 'grad_norm': 330.1759948730469, 'learning_rate': 4.5e-06, 'epoch': 0.01}
  1%|          | 45/6000 [02:38<6:16:26,  3.79s/it]  1%|          | 46/6000 [02:41<6:08:49,  3.72s/it]                                                   {'loss': 3.094, 'grad_norm': 242.229736328125, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.01}
  1%|          | 46/6000 [02:41<6:08:49,  3.72s/it]  1%|          | 47/6000 [02:45<6:00:56,  3.64s/it]                                                   {'loss': 3.4025, 'grad_norm': 223.71826171875, 'learning_rate': 4.7e-06, 'epoch': 0.01}
  1%|          | 47/6000 [02:45<6:00:56,  3.64s/it]  1%|          | 48/6000 [02:48<5:57:31,  3.60s/it]                                                   {'loss': 3.0899, 'grad_norm': 192.31825256347656, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.01}
  1%|          | 48/6000 [02:48<5:57:31,  3.60s/it]  1%|          | 49/6000 [02:51<5:49:55,  3.53s/it]                                                   {'loss': 3.1013, 'grad_norm': 231.49658203125, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.01}
  1%|          | 49/6000 [02:51<5:49:55,  3.53s/it]  1%|          | 50/6000 [02:55<5:51:34,  3.55s/it]                                                   {'loss': 3.2439, 'grad_norm': 282.2385559082031, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 50/6000 [02:55<5:51:34,  3.55s/it]  1%|          | 51/6000 [02:58<5:45:41,  3.49s/it]                                                   {'loss': 3.0842, 'grad_norm': 256.429443359375, 'learning_rate': 5.1e-06, 'epoch': 0.01}
  1%|          | 51/6000 [02:58<5:45:41,  3.49s/it]  1%|          | 52/6000 [03:02<5:40:50,  3.44s/it]                                                   {'loss': 3.6482, 'grad_norm': 1315.1007080078125, 'learning_rate': 5.2e-06, 'epoch': 0.01}
  1%|          | 52/6000 [03:02<5:40:50,  3.44s/it]  1%|          | 53/6000 [03:05<5:40:43,  3.44s/it]                                                   {'loss': 4.1371, 'grad_norm': 522.299072265625, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.01}
  1%|          | 53/6000 [03:05<5:40:43,  3.44s/it]  1%|          | 54/6000 [03:08<5:37:50,  3.41s/it]                                                   {'loss': 3.0912, 'grad_norm': 249.35647583007812, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.01}
  1%|          | 54/6000 [03:08<5:37:50,  3.41s/it]  1%|          | 55/6000 [03:12<5:38:01,  3.41s/it]                                                   {'loss': 3.019, 'grad_norm': 181.27857971191406, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.01}
  1%|          | 55/6000 [03:12<5:38:01,  3.41s/it]  1%|          | 56/6000 [03:15<5:37:03,  3.40s/it]                                                   {'loss': 3.138, 'grad_norm': 200.1629180908203, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.01}
  1%|          | 56/6000 [03:15<5:37:03,  3.40s/it]  1%|          | 57/6000 [03:19<5:37:32,  3.41s/it]                                                   {'loss': 2.978, 'grad_norm': 269.4146728515625, 'learning_rate': 5.7e-06, 'epoch': 0.01}
  1%|          | 57/6000 [03:19<5:37:32,  3.41s/it]  1%|          | 58/6000 [03:22<5:36:48,  3.40s/it]                                                   {'loss': 2.9652, 'grad_norm': 153.97509765625, 'learning_rate': 5.8e-06, 'epoch': 0.01}
  1%|          | 58/6000 [03:22<5:36:48,  3.40s/it]  1%|          | 59/6000 [03:25<5:33:59,  3.37s/it]                                                   {'loss': 2.8555, 'grad_norm': 174.4888153076172, 'learning_rate': 5.9e-06, 'epoch': 0.01}
  1%|          | 59/6000 [03:25<5:33:59,  3.37s/it]  1%|          | 60/6000 [03:29<5:34:14,  3.38s/it]                                                   {'loss': 2.9447, 'grad_norm': 162.8309326171875, 'learning_rate': 6e-06, 'epoch': 0.01}
  1%|          | 60/6000 [03:29<5:34:14,  3.38s/it]  1%|          | 61/6000 [03:32<5:32:38,  3.36s/it]                                                   {'loss': 3.0166, 'grad_norm': 194.2220916748047, 'learning_rate': 6.1e-06, 'epoch': 0.01}
  1%|          | 61/6000 [03:32<5:32:38,  3.36s/it]  1%|          | 62/6000 [03:36<5:34:46,  3.38s/it]                                                   {'loss': 2.93, 'grad_norm': 215.3595733642578, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.01}
  1%|          | 62/6000 [03:36<5:34:46,  3.38s/it]  1%|          | 63/6000 [03:39<5:35:17,  3.39s/it]                                                   {'loss': 2.6717, 'grad_norm': 156.78045654296875, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.01}
  1%|          | 63/6000 [03:39<5:35:17,  3.39s/it]  1%|          | 64/6000 [03:42<5:32:35,  3.36s/it]                                                   {'loss': 2.7682, 'grad_norm': 200.43333435058594, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.01}
  1%|          | 64/6000 [03:42<5:32:35,  3.36s/it]  1%|          | 65/6000 [03:46<5:31:41,  3.35s/it]                                                   {'loss': 2.9994, 'grad_norm': 192.42298889160156, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.01}
  1%|          | 65/6000 [03:46<5:31:41,  3.35s/it]  1%|          | 66/6000 [03:49<5:48:02,  3.52s/it]                                                   {'loss': 2.9517, 'grad_norm': 875.4346313476562, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.01}
  1%|          | 66/6000 [03:49<5:48:02,  3.52s/it]  1%|          | 67/6000 [03:53<5:44:32,  3.48s/it]                                                   {'loss': 2.4647, 'grad_norm': 271.08270263671875, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.01}
  1%|          | 67/6000 [03:53<5:44:32,  3.48s/it]  1%|          | 68/6000 [03:56<5:39:48,  3.44s/it]                                                   {'loss': 2.8895, 'grad_norm': 204.59487915039062, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.01}
  1%|          | 68/6000 [03:56<5:39:48,  3.44s/it]  1%|          | 69/6000 [04:00<5:38:12,  3.42s/it]                                                   {'loss': 3.0147, 'grad_norm': 733.1795654296875, 'learning_rate': 6.9e-06, 'epoch': 0.01}
  1%|          | 69/6000 [04:00<5:38:12,  3.42s/it]  1%|          | 70/6000 [04:03<5:41:14,  3.45s/it]                                                   {'loss': 2.8295, 'grad_norm': 137.68260192871094, 'learning_rate': 7e-06, 'epoch': 0.01}
  1%|          | 70/6000 [04:03<5:41:14,  3.45s/it]  1%|          | 71/6000 [04:06<5:37:33,  3.42s/it]                                                   {'loss': 2.9147, 'grad_norm': 144.60293579101562, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.01}
  1%|          | 71/6000 [04:06<5:37:33,  3.42s/it]  1%|          | 72/6000 [04:10<5:49:15,  3.54s/it]                                                   {'loss': 2.697, 'grad_norm': 154.34539794921875, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.01}
  1%|          | 72/6000 [04:10<5:49:15,  3.54s/it]  1%|          | 73/6000 [04:14<5:56:25,  3.61s/it]                                                   {'loss': 2.5434, 'grad_norm': 178.6719512939453, 'learning_rate': 7.3e-06, 'epoch': 0.01}
  1%|          | 73/6000 [04:14<5:56:25,  3.61s/it]  1%|          | 74/6000 [04:17<5:47:24,  3.52s/it]                                                   {'loss': 2.4495, 'grad_norm': 133.02296447753906, 'learning_rate': 7.4e-06, 'epoch': 0.01}
  1%|          | 74/6000 [04:17<5:47:24,  3.52s/it]  1%|â–         | 75/6000 [04:21<5:42:19,  3.47s/it]                                                   {'loss': 2.4182, 'grad_norm': 167.60372924804688, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.01}
  1%|â–         | 75/6000 [04:21<5:42:19,  3.47s/it]  1%|â–         | 76/6000 [04:24<5:52:27,  3.57s/it]                                                   {'loss': 2.4197, 'grad_norm': 124.60115051269531, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.01}
  1%|â–         | 76/6000 [04:24<5:52:27,  3.57s/it]  1%|â–         | 77/6000 [04:28<5:48:16,  3.53s/it]                                                   {'loss': 2.7237, 'grad_norm': 129.66470336914062, 'learning_rate': 7.7e-06, 'epoch': 0.01}
  1%|â–         | 77/6000 [04:28<5:48:16,  3.53s/it]  1%|â–         | 78/6000 [04:32<5:56:16,  3.61s/it]                                                   {'loss': 2.5201, 'grad_norm': 145.11221313476562, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.01}
  1%|â–         | 78/6000 [04:32<5:56:16,  3.61s/it]  1%|â–         | 79/6000 [04:35<5:49:38,  3.54s/it]                                                   {'loss': 2.2636, 'grad_norm': 130.51145935058594, 'learning_rate': 7.9e-06, 'epoch': 0.01}
  1%|â–         | 79/6000 [04:35<5:49:38,  3.54s/it]  1%|â–         | 80/6000 [04:39<5:45:21,  3.50s/it]                                                   {'loss': 2.3351, 'grad_norm': 146.6398468017578, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  1%|â–         | 80/6000 [04:39<5:45:21,  3.50s/it]  1%|â–         | 81/6000 [04:42<5:41:42,  3.46s/it]                                                   {'loss': 2.235, 'grad_norm': 126.35832977294922, 'learning_rate': 8.1e-06, 'epoch': 0.01}
  1%|â–         | 81/6000 [04:42<5:41:42,  3.46s/it]  1%|â–         | 82/6000 [04:45<5:41:07,  3.46s/it]                                                   {'loss': 2.0795, 'grad_norm': 143.43768310546875, 'learning_rate': 8.2e-06, 'epoch': 0.01}
  1%|â–         | 82/6000 [04:45<5:41:07,  3.46s/it]  1%|â–         | 83/6000 [04:49<5:40:27,  3.45s/it]                                                   {'loss': 2.1305, 'grad_norm': 161.7203826904297, 'learning_rate': 8.3e-06, 'epoch': 0.01}
  1%|â–         | 83/6000 [04:49<5:40:27,  3.45s/it]  1%|â–         | 84/6000 [04:52<5:41:38,  3.46s/it]                                                   {'loss': 1.762, 'grad_norm': 132.64495849609375, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.01}
  1%|â–         | 84/6000 [04:52<5:41:38,  3.46s/it]  1%|â–         | 85/6000 [04:56<5:54:38,  3.60s/it]                                                   {'loss': 1.6873, 'grad_norm': 165.7062225341797, 'learning_rate': 8.5e-06, 'epoch': 0.01}
  1%|â–         | 85/6000 [04:56<5:54:38,  3.60s/it]  1%|â–         | 86/6000 [05:00<5:51:06,  3.56s/it]                                                   {'loss': 1.7932, 'grad_norm': 246.9585723876953, 'learning_rate': 8.6e-06, 'epoch': 0.01}
  1%|â–         | 86/6000 [05:00<5:51:06,  3.56s/it]  1%|â–         | 87/6000 [05:03<5:43:54,  3.49s/it]                                                   {'loss': 1.3976, 'grad_norm': 172.85870361328125, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.01}
  1%|â–         | 87/6000 [05:03<5:43:54,  3.49s/it]  1%|â–         | 88/6000 [05:06<5:38:48,  3.44s/it]                                                   {'loss': 1.8399, 'grad_norm': 299.9961242675781, 'learning_rate': 8.8e-06, 'epoch': 0.01}
  1%|â–         | 88/6000 [05:06<5:38:48,  3.44s/it]  1%|â–         | 89/6000 [05:10<5:34:52,  3.40s/it]                                                   {'loss': 1.2733, 'grad_norm': 1595.890625, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.01}
  1%|â–         | 89/6000 [05:10<5:34:52,  3.40s/it]  2%|â–         | 90/6000 [05:13<5:37:13,  3.42s/it]                                                   {'loss': 0.6812, 'grad_norm': 106.06771850585938, 'learning_rate': 9e-06, 'epoch': 0.01}
  2%|â–         | 90/6000 [05:13<5:37:13,  3.42s/it]  2%|â–         | 91/6000 [05:16<5:36:44,  3.42s/it]                                                   {'loss': 1.0212, 'grad_norm': 132.6889190673828, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.02}
  2%|â–         | 91/6000 [05:16<5:36:44,  3.42s/it]  2%|â–         | 92/6000 [05:20<5:48:29,  3.54s/it]                                                   {'loss': 1.0255, 'grad_norm': 811.42138671875, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.02}
  2%|â–         | 92/6000 [05:20<5:48:29,  3.54s/it]  2%|â–         | 93/6000 [05:24<5:50:13,  3.56s/it]                                                   {'loss': 0.774, 'grad_norm': 215.01202392578125, 'learning_rate': 9.3e-06, 'epoch': 0.02}
  2%|â–         | 93/6000 [05:24<5:50:13,  3.56s/it]  2%|â–         | 94/6000 [05:27<5:43:55,  3.49s/it]                                                   {'loss': 1.1239, 'grad_norm': 298.9125061035156, 'learning_rate': 9.4e-06, 'epoch': 0.02}
  2%|â–         | 94/6000 [05:27<5:43:55,  3.49s/it]  2%|â–         | 95/6000 [05:31<5:41:56,  3.47s/it]                                                   {'loss': 0.5431, 'grad_norm': 321.0304260253906, 'learning_rate': 9.5e-06, 'epoch': 0.02}
  2%|â–         | 95/6000 [05:31<5:41:56,  3.47s/it]  2%|â–         | 96/6000 [05:34<5:39:24,  3.45s/it]                                                   {'loss': 0.6571, 'grad_norm': 216.0405731201172, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.02}
  2%|â–         | 96/6000 [05:34<5:39:24,  3.45s/it]  2%|â–         | 97/6000 [05:37<5:36:24,  3.42s/it]                                                   {'loss': 1.2357, 'grad_norm': 164.74942016601562, 'learning_rate': 9.7e-06, 'epoch': 0.02}
  2%|â–         | 97/6000 [05:37<5:36:24,  3.42s/it]  2%|â–         | 98/6000 [05:41<5:36:16,  3.42s/it]                                                   {'loss': 0.779, 'grad_norm': 164.9439697265625, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.02}
  2%|â–         | 98/6000 [05:41<5:36:16,  3.42s/it]  2%|â–         | 99/6000 [05:44<5:33:06,  3.39s/it]                                                   {'loss': 0.5703, 'grad_norm': 138.8079376220703, 'learning_rate': 9.9e-06, 'epoch': 0.02}
  2%|â–         | 99/6000 [05:44<5:33:06,  3.39s/it]  2%|â–         | 100/6000 [05:47<5:31:03,  3.37s/it]                                                    {'loss': 1.0229, 'grad_norm': 242.8694610595703, 'learning_rate': 1e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [05:47<5:31:03,  3.37s/it][2025-11-06 22:56:57,469] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
[2025-11-06 22:56:57,484] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 22:56:58,183] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  2%|â–         | 101/6000 [05:54<7:12:28,  4.40s/it]                                                    {'loss': 0.5648, 'grad_norm': 108.21739196777344, 'learning_rate': 9.998305084745762e-06, 'epoch': 0.02}
  2%|â–         | 101/6000 [05:54<7:12:28,  4.40s/it]  2%|â–         | 102/6000 [05:58<6:41:16,  4.08s/it]                                                    {'loss': 0.3867, 'grad_norm': 69.59712982177734, 'learning_rate': 9.996610169491526e-06, 'epoch': 0.02}
  2%|â–         | 102/6000 [05:58<6:41:16,  4.08s/it]  2%|â–         | 103/6000 [06:01<6:23:59,  3.91s/it]                                                    {'loss': 0.3527, 'grad_norm': 73.17548370361328, 'learning_rate': 9.994915254237289e-06, 'epoch': 0.02}
  2%|â–         | 103/6000 [06:01<6:23:59,  3.91s/it]  2%|â–         | 104/6000 [06:05<6:17:33,  3.84s/it]                                                    {'loss': 0.4287, 'grad_norm': 73.20089721679688, 'learning_rate': 9.993220338983052e-06, 'epoch': 0.02}
  2%|â–         | 104/6000 [06:05<6:17:33,  3.84s/it]  2%|â–         | 105/6000 [06:08<6:06:03,  3.73s/it]                                                    {'loss': 0.663, 'grad_norm': 72.44263458251953, 'learning_rate': 9.991525423728814e-06, 'epoch': 0.02}
  2%|â–         | 105/6000 [06:08<6:06:03,  3.73s/it]  2%|â–         | 106/6000 [06:12<6:01:50,  3.68s/it]                                                    {'loss': 0.2587, 'grad_norm': 43.630455017089844, 'learning_rate': 9.989830508474577e-06, 'epoch': 0.02}
  2%|â–         | 106/6000 [06:12<6:01:50,  3.68s/it]  2%|â–         | 107/6000 [06:15<5:53:13,  3.60s/it]                                                    {'loss': 0.4736, 'grad_norm': 57.864444732666016, 'learning_rate': 9.988135593220339e-06, 'epoch': 0.02}
  2%|â–         | 107/6000 [06:15<5:53:13,  3.60s/it]  2%|â–         | 108/6000 [06:19<5:51:49,  3.58s/it]                                                    {'loss': 0.3215, 'grad_norm': 74.68048095703125, 'learning_rate': 9.986440677966102e-06, 'epoch': 0.02}
  2%|â–         | 108/6000 [06:19<5:51:49,  3.58s/it]  2%|â–         | 109/6000 [06:23<5:59:16,  3.66s/it]                                                    {'loss': 0.4436, 'grad_norm': 41.69659423828125, 'learning_rate': 9.984745762711865e-06, 'epoch': 0.02}
  2%|â–         | 109/6000 [06:23<5:59:16,  3.66s/it]  2%|â–         | 110/6000 [06:26<5:52:43,  3.59s/it]                                                    {'loss': 0.3784, 'grad_norm': 394.9842834472656, 'learning_rate': 9.983050847457628e-06, 'epoch': 0.02}
  2%|â–         | 110/6000 [06:26<5:52:43,  3.59s/it]  2%|â–         | 111/6000 [06:30<5:51:05,  3.58s/it]                                                    {'loss': 0.4015, 'grad_norm': 148.19383239746094, 'learning_rate': 9.98135593220339e-06, 'epoch': 0.02}
  2%|â–         | 111/6000 [06:30<5:51:05,  3.58s/it]  2%|â–         | 112/6000 [06:34<6:02:13,  3.69s/it]                                                    {'loss': 0.489, 'grad_norm': 601.6388549804688, 'learning_rate': 9.979661016949153e-06, 'epoch': 0.02}
  2%|â–         | 112/6000 [06:34<6:02:13,  3.69s/it]  2%|â–         | 113/6000 [06:37<5:55:10,  3.62s/it]                                                    {'loss': 0.3005, 'grad_norm': 51.11073684692383, 'learning_rate': 9.977966101694917e-06, 'epoch': 0.02}
  2%|â–         | 113/6000 [06:37<5:55:10,  3.62s/it]  2%|â–         | 114/6000 [06:40<5:49:32,  3.56s/it]                                                    {'loss': 0.2951, 'grad_norm': 42.15408706665039, 'learning_rate': 9.97627118644068e-06, 'epoch': 0.02}
  2%|â–         | 114/6000 [06:40<5:49:32,  3.56s/it]  2%|â–         | 115/6000 [06:44<5:45:34,  3.52s/it]                                                    {'loss': 0.3667, 'grad_norm': 110.50492095947266, 'learning_rate': 9.974576271186441e-06, 'epoch': 0.02}
  2%|â–         | 115/6000 [06:44<5:45:34,  3.52s/it]  2%|â–         | 116/6000 [06:47<5:40:35,  3.47s/it]                                                    {'loss': 0.4145, 'grad_norm': 53.63681411743164, 'learning_rate': 9.972881355932205e-06, 'epoch': 0.02}
  2%|â–         | 116/6000 [06:47<5:40:35,  3.47s/it]  2%|â–         | 117/6000 [06:51<5:40:52,  3.48s/it]                                                    {'loss': 0.5961, 'grad_norm': 68.35948944091797, 'learning_rate': 9.971186440677966e-06, 'epoch': 0.02}
  2%|â–         | 117/6000 [06:51<5:40:52,  3.48s/it]  2%|â–         | 118/6000 [06:55<5:56:36,  3.64s/it]                                                    {'loss': 0.5648, 'grad_norm': 55.28799819946289, 'learning_rate': 9.96949152542373e-06, 'epoch': 0.02}
  2%|â–         | 118/6000 [06:55<5:56:36,  3.64s/it]  2%|â–         | 119/6000 [06:58<5:46:22,  3.53s/it]                                                    {'loss': 0.3272, 'grad_norm': 77.97366333007812, 'learning_rate': 9.967796610169493e-06, 'epoch': 0.02}
  2%|â–         | 119/6000 [06:58<5:46:22,  3.53s/it]  2%|â–         | 120/6000 [07:01<5:41:58,  3.49s/it]                                                    {'loss': 0.4611, 'grad_norm': 111.44940185546875, 'learning_rate': 9.966101694915256e-06, 'epoch': 0.02}
  2%|â–         | 120/6000 [07:01<5:41:58,  3.49s/it]  2%|â–         | 121/6000 [07:05<5:39:49,  3.47s/it]                                                    {'loss': 0.1819, 'grad_norm': 100.04718780517578, 'learning_rate': 9.964406779661018e-06, 'epoch': 0.02}
  2%|â–         | 121/6000 [07:05<5:39:49,  3.47s/it]  2%|â–         | 122/6000 [07:08<5:43:45,  3.51s/it]                                                    {'loss': 0.2315, 'grad_norm': 43.845088958740234, 'learning_rate': 9.96271186440678e-06, 'epoch': 0.02}
  2%|â–         | 122/6000 [07:08<5:43:45,  3.51s/it]  2%|â–         | 123/6000 [07:12<5:39:11,  3.46s/it]                                                    {'loss': 0.2061, 'grad_norm': 92.24093627929688, 'learning_rate': 9.961016949152543e-06, 'epoch': 0.02}
  2%|â–         | 123/6000 [07:12<5:39:11,  3.46s/it]  2%|â–         | 124/6000 [07:15<5:35:44,  3.43s/it]                                                    {'loss': 0.2169, 'grad_norm': 39.67334747314453, 'learning_rate': 9.959322033898306e-06, 'epoch': 0.02}
  2%|â–         | 124/6000 [07:15<5:35:44,  3.43s/it]  2%|â–         | 125/6000 [07:19<5:44:53,  3.52s/it]                                                    {'loss': 0.2153, 'grad_norm': 65.13499450683594, 'learning_rate': 9.957627118644069e-06, 'epoch': 0.02}
  2%|â–         | 125/6000 [07:19<5:44:53,  3.52s/it]  2%|â–         | 126/6000 [07:22<5:43:36,  3.51s/it]                                                    {'loss': 0.2281, 'grad_norm': 43.0129280090332, 'learning_rate': 9.95593220338983e-06, 'epoch': 0.02}
  2%|â–         | 126/6000 [07:22<5:43:36,  3.51s/it]  2%|â–         | 127/6000 [07:26<5:47:37,  3.55s/it]                                                    {'loss': 0.237, 'grad_norm': 29.080846786499023, 'learning_rate': 9.954237288135594e-06, 'epoch': 0.02}
  2%|â–         | 127/6000 [07:26<5:47:37,  3.55s/it]  2%|â–         | 128/6000 [07:29<5:43:01,  3.50s/it]                                                    {'loss': 0.2629, 'grad_norm': 52.8875846862793, 'learning_rate': 9.952542372881356e-06, 'epoch': 0.02}
  2%|â–         | 128/6000 [07:29<5:43:01,  3.50s/it]  2%|â–         | 129/6000 [07:33<5:40:41,  3.48s/it]                                                    {'loss': 0.5998, 'grad_norm': 45.268096923828125, 'learning_rate': 9.95084745762712e-06, 'epoch': 0.02}
  2%|â–         | 129/6000 [07:33<5:40:41,  3.48s/it]  2%|â–         | 130/6000 [07:36<5:37:19,  3.45s/it]                                                    {'loss': 0.1933, 'grad_norm': 28.53034019470215, 'learning_rate': 9.949152542372882e-06, 'epoch': 0.02}
  2%|â–         | 130/6000 [07:36<5:37:19,  3.45s/it]  2%|â–         | 131/6000 [07:40<5:35:45,  3.43s/it]                                                    {'loss': 0.348, 'grad_norm': 49.85209655761719, 'learning_rate': 9.947457627118645e-06, 'epoch': 0.02}
  2%|â–         | 131/6000 [07:40<5:35:45,  3.43s/it]  2%|â–         | 132/6000 [07:43<5:33:19,  3.41s/it]                                                    {'loss': 0.1161, 'grad_norm': 23.820186614990234, 'learning_rate': 9.945762711864407e-06, 'epoch': 0.02}
  2%|â–         | 132/6000 [07:43<5:33:19,  3.41s/it]  2%|â–         | 133/6000 [07:46<5:33:47,  3.41s/it]                                                    {'loss': 0.3779, 'grad_norm': 58.68413543701172, 'learning_rate': 9.94406779661017e-06, 'epoch': 0.02}
  2%|â–         | 133/6000 [07:46<5:33:47,  3.41s/it]  2%|â–         | 134/6000 [07:50<5:39:23,  3.47s/it]                                                    {'loss': 0.3277, 'grad_norm': 50.73967361450195, 'learning_rate': 9.942372881355933e-06, 'epoch': 0.02}
  2%|â–         | 134/6000 [07:50<5:39:23,  3.47s/it]  2%|â–         | 135/6000 [07:54<5:40:49,  3.49s/it]                                                    {'loss': 0.4136, 'grad_norm': 63.63880920410156, 'learning_rate': 9.940677966101697e-06, 'epoch': 0.02}
  2%|â–         | 135/6000 [07:54<5:40:49,  3.49s/it]  2%|â–         | 136/6000 [07:57<5:38:21,  3.46s/it]                                                    {'loss': 0.2705, 'grad_norm': 44.02122116088867, 'learning_rate': 9.938983050847458e-06, 'epoch': 0.02}
  2%|â–         | 136/6000 [07:57<5:38:21,  3.46s/it]  2%|â–         | 137/6000 [08:01<5:50:43,  3.59s/it]                                                    {'loss': 0.1881, 'grad_norm': 31.175411224365234, 'learning_rate': 9.937288135593222e-06, 'epoch': 0.02}
  2%|â–         | 137/6000 [08:01<5:50:43,  3.59s/it]  2%|â–         | 138/6000 [08:04<5:42:53,  3.51s/it]                                                    {'loss': 0.2436, 'grad_norm': 36.141754150390625, 'learning_rate': 9.935593220338983e-06, 'epoch': 0.02}
  2%|â–         | 138/6000 [08:04<5:42:53,  3.51s/it]  2%|â–         | 139/6000 [08:08<5:44:18,  3.52s/it]                                                    {'loss': 0.3481, 'grad_norm': 56.00901794433594, 'learning_rate': 9.933898305084746e-06, 'epoch': 0.02}
  2%|â–         | 139/6000 [08:08<5:44:18,  3.52s/it]  2%|â–         | 140/6000 [08:12<5:55:37,  3.64s/it]                                                    {'loss': 0.2959, 'grad_norm': 54.964229583740234, 'learning_rate': 9.93220338983051e-06, 'epoch': 0.02}
  2%|â–         | 140/6000 [08:12<5:55:37,  3.64s/it]  2%|â–         | 141/6000 [08:15<5:48:29,  3.57s/it]                                                    {'loss': 0.3124, 'grad_norm': 38.80043411254883, 'learning_rate': 9.930508474576273e-06, 'epoch': 0.02}
  2%|â–         | 141/6000 [08:15<5:48:29,  3.57s/it]  2%|â–         | 142/6000 [08:18<5:42:16,  3.51s/it]                                                    {'loss': 0.1739, 'grad_norm': 25.993078231811523, 'learning_rate': 9.928813559322035e-06, 'epoch': 0.02}
  2%|â–         | 142/6000 [08:18<5:42:16,  3.51s/it]  2%|â–         | 143/6000 [08:22<5:38:30,  3.47s/it]                                                    {'loss': 0.1719, 'grad_norm': 34.458003997802734, 'learning_rate': 9.927118644067796e-06, 'epoch': 0.02}
  2%|â–         | 143/6000 [08:22<5:38:30,  3.47s/it]  2%|â–         | 144/6000 [08:25<5:37:26,  3.46s/it]                                                    {'loss': 0.1043, 'grad_norm': 22.158615112304688, 'learning_rate': 9.92542372881356e-06, 'epoch': 0.02}
  2%|â–         | 144/6000 [08:25<5:37:26,  3.46s/it]  2%|â–         | 145/6000 [08:28<5:32:33,  3.41s/it]                                                    {'loss': 0.0883, 'grad_norm': 21.537282943725586, 'learning_rate': 9.923728813559323e-06, 'epoch': 0.02}
  2%|â–         | 145/6000 [08:28<5:32:33,  3.41s/it]  2%|â–         | 146/6000 [08:32<5:41:13,  3.50s/it]                                                    {'loss': 0.1879, 'grad_norm': 37.83506774902344, 'learning_rate': 9.922033898305086e-06, 'epoch': 0.02}
  2%|â–         | 146/6000 [08:32<5:41:13,  3.50s/it]  2%|â–         | 147/6000 [08:36<5:37:13,  3.46s/it]                                                    {'loss': 0.3303, 'grad_norm': 38.481300354003906, 'learning_rate': 9.920338983050848e-06, 'epoch': 0.02}
  2%|â–         | 147/6000 [08:36<5:37:13,  3.46s/it]  2%|â–         | 148/6000 [08:39<5:36:14,  3.45s/it]                                                    {'loss': 0.1055, 'grad_norm': 26.026962280273438, 'learning_rate': 9.918644067796611e-06, 'epoch': 0.02}
  2%|â–         | 148/6000 [08:39<5:36:14,  3.45s/it]  2%|â–         | 149/6000 [08:42<5:32:31,  3.41s/it]                                                    {'loss': 0.1267, 'grad_norm': 44.920326232910156, 'learning_rate': 9.916949152542374e-06, 'epoch': 0.02}
  2%|â–         | 149/6000 [08:42<5:32:31,  3.41s/it]  2%|â–Ž         | 150/6000 [08:46<5:32:32,  3.41s/it]                                                    {'loss': 0.0575, 'grad_norm': 23.653417587280273, 'learning_rate': 9.915254237288137e-06, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [08:46<5:32:32,  3.41s/it]  3%|â–Ž         | 151/6000 [08:49<5:35:20,  3.44s/it]                                                    {'loss': 0.099, 'grad_norm': 13.789375305175781, 'learning_rate': 9.913559322033899e-06, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [08:49<5:35:20,  3.44s/it]  3%|â–Ž         | 152/6000 [08:53<5:36:58,  3.46s/it]                                                    {'loss': 0.0861, 'grad_norm': 21.229698181152344, 'learning_rate': 9.911864406779662e-06, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [08:53<5:36:58,  3.46s/it]  3%|â–Ž         | 153/6000 [08:56<5:33:36,  3.42s/it]                                                    {'loss': 0.1144, 'grad_norm': 23.76308250427246, 'learning_rate': 9.910169491525424e-06, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [08:56<5:33:36,  3.42s/it]  3%|â–Ž         | 154/6000 [09:00<5:36:07,  3.45s/it]                                                    {'loss': 0.1623, 'grad_norm': 35.2220344543457, 'learning_rate': 9.908474576271187e-06, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [09:00<5:36:07,  3.45s/it]  3%|â–Ž         | 155/6000 [09:03<5:35:03,  3.44s/it]                                                    {'loss': 0.1473, 'grad_norm': 21.907230377197266, 'learning_rate': 9.90677966101695e-06, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [09:03<5:35:03,  3.44s/it]  3%|â–Ž         | 156/6000 [09:07<5:37:59,  3.47s/it]                                                    {'loss': 0.0535, 'grad_norm': 12.551724433898926, 'learning_rate': 9.905084745762714e-06, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [09:07<5:37:59,  3.47s/it]  3%|â–Ž         | 157/6000 [09:10<5:52:48,  3.62s/it]                                                    {'loss': 0.0859, 'grad_norm': 16.646642684936523, 'learning_rate': 9.903389830508475e-06, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [09:10<5:52:48,  3.62s/it]  3%|â–Ž         | 158/6000 [09:14<5:45:28,  3.55s/it]                                                    {'loss': 0.0441, 'grad_norm': 10.094442367553711, 'learning_rate': 9.901694915254239e-06, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [09:14<5:45:28,  3.55s/it]  3%|â–Ž         | 159/6000 [09:17<5:41:32,  3.51s/it]                                                    {'loss': 0.1417, 'grad_norm': 31.11097526550293, 'learning_rate': 9.9e-06, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [09:17<5:41:32,  3.51s/it]  3%|â–Ž         | 160/6000 [09:21<5:59:07,  3.69s/it]                                                    {'loss': 0.1691, 'grad_norm': 44.82453155517578, 'learning_rate': 9.898305084745763e-06, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [09:21<5:59:07,  3.69s/it]  3%|â–Ž         | 161/6000 [09:25<5:57:24,  3.67s/it]                                                    {'loss': 0.2259, 'grad_norm': 36.395259857177734, 'learning_rate': 9.896610169491527e-06, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [09:25<5:57:24,  3.67s/it]  3%|â–Ž         | 162/6000 [09:28<5:47:24,  3.57s/it]                                                    {'loss': 0.0324, 'grad_norm': 5.994685649871826, 'learning_rate': 9.89491525423729e-06, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [09:28<5:47:24,  3.57s/it]  3%|â–Ž         | 163/6000 [09:32<5:55:02,  3.65s/it]                                                    {'loss': 0.173, 'grad_norm': 38.36474609375, 'learning_rate': 9.893220338983051e-06, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [09:32<5:55:02,  3.65s/it]  3%|â–Ž         | 164/6000 [09:36<5:47:09,  3.57s/it]                                                    {'loss': 0.4086, 'grad_norm': 53.54051208496094, 'learning_rate': 9.891525423728813e-06, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [09:36<5:47:09,  3.57s/it]  3%|â–Ž         | 165/6000 [09:39<5:46:42,  3.57s/it]                                                    {'loss': 0.0488, 'grad_norm': 14.462920188903809, 'learning_rate': 9.889830508474576e-06, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [09:39<5:46:42,  3.57s/it]  3%|â–Ž         | 166/6000 [09:42<5:39:03,  3.49s/it]                                                    {'loss': 0.1412, 'grad_norm': 21.70069694519043, 'learning_rate': 9.88813559322034e-06, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [09:42<5:39:03,  3.49s/it]  3%|â–Ž         | 167/6000 [09:46<5:35:42,  3.45s/it]                                                    {'loss': 0.3414, 'grad_norm': 68.9521255493164, 'learning_rate': 9.886440677966103e-06, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [09:46<5:35:42,  3.45s/it]  3%|â–Ž         | 168/6000 [09:49<5:33:31,  3.43s/it]                                                    {'loss': 0.2554, 'grad_norm': 49.383113861083984, 'learning_rate': 9.884745762711864e-06, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [09:49<5:33:31,  3.43s/it]  3%|â–Ž         | 169/6000 [09:53<5:45:59,  3.56s/it]                                                    {'loss': 0.235, 'grad_norm': 38.13349151611328, 'learning_rate': 9.883050847457628e-06, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [09:53<5:45:59,  3.56s/it]  3%|â–Ž         | 170/6000 [09:56<5:39:07,  3.49s/it]                                                    {'loss': 0.1925, 'grad_norm': 55.48265838623047, 'learning_rate': 9.881355932203391e-06, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [09:56<5:39:07,  3.49s/it]  3%|â–Ž         | 171/6000 [10:00<5:34:25,  3.44s/it]                                                    {'loss': 0.1311, 'grad_norm': 34.0235710144043, 'learning_rate': 9.879661016949154e-06, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [10:00<5:34:25,  3.44s/it]  3%|â–Ž         | 172/6000 [10:03<5:37:06,  3.47s/it]                                                    {'loss': 0.2586, 'grad_norm': 181.61102294921875, 'learning_rate': 9.877966101694916e-06, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [10:03<5:37:06,  3.47s/it]  3%|â–Ž         | 173/6000 [10:07<5:37:21,  3.47s/it]                                                    {'loss': 0.1446, 'grad_norm': 41.54903793334961, 'learning_rate': 9.876271186440679e-06, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [10:07<5:37:21,  3.47s/it]  3%|â–Ž         | 174/6000 [10:11<5:58:48,  3.70s/it]                                                    {'loss': 0.0543, 'grad_norm': 15.767609596252441, 'learning_rate': 9.87457627118644e-06, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [10:11<5:58:48,  3.70s/it]  3%|â–Ž         | 175/6000 [10:14<5:51:36,  3.62s/it]                                                    {'loss': 0.3373, 'grad_norm': 118.28654479980469, 'learning_rate': 9.872881355932204e-06, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [10:14<5:51:36,  3.62s/it]  3%|â–Ž         | 176/6000 [10:18<5:55:41,  3.66s/it]                                                    {'loss': 0.999, 'grad_norm': 556.930908203125, 'learning_rate': 9.871186440677967e-06, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [10:18<5:55:41,  3.66s/it]  3%|â–Ž         | 177/6000 [10:22<5:46:49,  3.57s/it]                                                    {'loss': 0.1988, 'grad_norm': 34.85820007324219, 'learning_rate': 9.86949152542373e-06, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [10:22<5:46:49,  3.57s/it]  3%|â–Ž         | 178/6000 [10:25<5:43:17,  3.54s/it]                                                    {'loss': 0.1993, 'grad_norm': 42.76774215698242, 'learning_rate': 9.867796610169492e-06, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [10:25<5:43:17,  3.54s/it]  3%|â–Ž         | 179/6000 [10:28<5:39:02,  3.49s/it]                                                    {'loss': 0.2504, 'grad_norm': 82.6951675415039, 'learning_rate': 9.866101694915255e-06, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [10:28<5:39:02,  3.49s/it]  3%|â–Ž         | 180/6000 [10:32<5:41:11,  3.52s/it]                                                    {'loss': 0.2647, 'grad_norm': 135.96234130859375, 'learning_rate': 9.864406779661017e-06, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [10:32<5:41:11,  3.52s/it]  3%|â–Ž         | 181/6000 [10:35<5:39:07,  3.50s/it]                                                    {'loss': 0.3269, 'grad_norm': 36.40024948120117, 'learning_rate': 9.86271186440678e-06, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [10:35<5:39:07,  3.50s/it]  3%|â–Ž         | 182/6000 [10:39<5:35:17,  3.46s/it]                                                    {'loss': 0.2484, 'grad_norm': 119.2619400024414, 'learning_rate': 9.861016949152544e-06, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [10:39<5:35:17,  3.46s/it]  3%|â–Ž         | 183/6000 [10:42<5:33:55,  3.44s/it]                                                    {'loss': 0.1697, 'grad_norm': 75.23773193359375, 'learning_rate': 9.859322033898307e-06, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [10:42<5:33:55,  3.44s/it]  3%|â–Ž         | 184/6000 [10:46<5:36:29,  3.47s/it]                                                    {'loss': 0.1159, 'grad_norm': 20.891752243041992, 'learning_rate': 9.857627118644068e-06, 'epoch': 0.03}
  3%|â–Ž         | 184/6000 [10:46<5:36:29,  3.47s/it]  3%|â–Ž         | 185/6000 [10:49<5:35:25,  3.46s/it]                                                    {'loss': 0.0671, 'grad_norm': 17.754026412963867, 'learning_rate': 9.855932203389832e-06, 'epoch': 0.03}
  3%|â–Ž         | 185/6000 [10:49<5:35:25,  3.46s/it]  3%|â–Ž         | 186/6000 [10:53<5:35:45,  3.46s/it]                                                    {'loss': 0.2304, 'grad_norm': 45.06401824951172, 'learning_rate': 9.854237288135595e-06, 'epoch': 0.03}
  3%|â–Ž         | 186/6000 [10:53<5:35:45,  3.46s/it]  3%|â–Ž         | 187/6000 [10:56<5:34:20,  3.45s/it]                                                    {'loss': 0.1507, 'grad_norm': 29.361751556396484, 'learning_rate': 9.852542372881356e-06, 'epoch': 0.03}
  3%|â–Ž         | 187/6000 [10:56<5:34:20,  3.45s/it]  3%|â–Ž         | 188/6000 [10:59<5:32:11,  3.43s/it]                                                    {'loss': 0.2609, 'grad_norm': 101.40843963623047, 'learning_rate': 9.85084745762712e-06, 'epoch': 0.03}
  3%|â–Ž         | 188/6000 [10:59<5:32:11,  3.43s/it]  3%|â–Ž         | 189/6000 [11:03<5:31:32,  3.42s/it]                                                    {'loss': 0.2561, 'grad_norm': 90.20469665527344, 'learning_rate': 9.849152542372881e-06, 'epoch': 0.03}
  3%|â–Ž         | 189/6000 [11:03<5:31:32,  3.42s/it]  3%|â–Ž         | 190/6000 [11:06<5:28:42,  3.39s/it]                                                    {'loss': 0.1014, 'grad_norm': 18.650569915771484, 'learning_rate': 9.847457627118645e-06, 'epoch': 0.03}
  3%|â–Ž         | 190/6000 [11:06<5:28:42,  3.39s/it]  3%|â–Ž         | 191/6000 [11:10<5:31:38,  3.43s/it]                                                    {'loss': 0.1117, 'grad_norm': 26.302236557006836, 'learning_rate': 9.845762711864408e-06, 'epoch': 0.03}
  3%|â–Ž         | 191/6000 [11:10<5:31:38,  3.43s/it]  3%|â–Ž         | 192/6000 [11:14<5:50:38,  3.62s/it]                                                    {'loss': 0.1585, 'grad_norm': 30.19717025756836, 'learning_rate': 9.844067796610171e-06, 'epoch': 0.03}
  3%|â–Ž         | 192/6000 [11:14<5:50:38,  3.62s/it]  3%|â–Ž         | 193/6000 [11:17<5:55:01,  3.67s/it]                                                    {'loss': 0.3383, 'grad_norm': 40.79595947265625, 'learning_rate': 9.842372881355933e-06, 'epoch': 0.03}
  3%|â–Ž         | 193/6000 [11:17<5:55:01,  3.67s/it]  3%|â–Ž         | 194/6000 [11:21<5:45:36,  3.57s/it]                                                    {'loss': 0.256, 'grad_norm': 30.090761184692383, 'learning_rate': 9.840677966101696e-06, 'epoch': 0.03}
  3%|â–Ž         | 194/6000 [11:21<5:45:36,  3.57s/it]  3%|â–Ž         | 195/6000 [11:24<5:41:36,  3.53s/it]                                                    {'loss': 0.0184, 'grad_norm': 4.53205680847168, 'learning_rate': 9.838983050847458e-06, 'epoch': 0.03}
  3%|â–Ž         | 195/6000 [11:24<5:41:36,  3.53s/it]  3%|â–Ž         | 196/6000 [11:28<5:39:17,  3.51s/it]                                                    {'loss': 0.046, 'grad_norm': 13.055888175964355, 'learning_rate': 9.837288135593221e-06, 'epoch': 0.03}
  3%|â–Ž         | 196/6000 [11:28<5:39:17,  3.51s/it]  3%|â–Ž         | 197/6000 [11:31<5:40:32,  3.52s/it]                                                    {'loss': 0.0767, 'grad_norm': 14.639277458190918, 'learning_rate': 9.835593220338984e-06, 'epoch': 0.03}
  3%|â–Ž         | 197/6000 [11:31<5:40:32,  3.52s/it]  3%|â–Ž         | 198/6000 [11:35<5:40:20,  3.52s/it]                                                    {'loss': 0.0558, 'grad_norm': 10.173118591308594, 'learning_rate': 9.833898305084747e-06, 'epoch': 0.03}
  3%|â–Ž         | 198/6000 [11:35<5:40:20,  3.52s/it]  3%|â–Ž         | 199/6000 [11:38<5:35:24,  3.47s/it]                                                    {'loss': 0.1136, 'grad_norm': 20.956920623779297, 'learning_rate': 9.832203389830509e-06, 'epoch': 0.03}
  3%|â–Ž         | 199/6000 [11:38<5:35:24,  3.47s/it]  3%|â–Ž         | 200/6000 [11:42<5:47:38,  3.60s/it]                                                    {'loss': 0.2194, 'grad_norm': 39.043701171875, 'learning_rate': 9.830508474576272e-06, 'epoch': 0.03}
  3%|â–Ž         | 200/6000 [11:42<5:47:38,  3.60s/it][2025-11-06 23:02:52,031] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200
[2025-11-06 23:02:52,044] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:02:52,731] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 201/6000 [11:48<6:51:27,  4.26s/it]                                                    {'loss': 0.3059, 'grad_norm': 34.77241516113281, 'learning_rate': 9.828813559322034e-06, 'epoch': 0.03}
  3%|â–Ž         | 201/6000 [11:48<6:51:27,  4.26s/it]  3%|â–Ž         | 202/6000 [11:51<6:24:31,  3.98s/it]                                                    {'loss': 0.2587, 'grad_norm': 31.687728881835938, 'learning_rate': 9.827118644067797e-06, 'epoch': 0.03}
  3%|â–Ž         | 202/6000 [11:51<6:24:31,  3.98s/it]  3%|â–Ž         | 203/6000 [11:55<6:10:03,  3.83s/it]                                                    {'loss': 0.0913, 'grad_norm': 14.200106620788574, 'learning_rate': 9.82542372881356e-06, 'epoch': 0.03}
  3%|â–Ž         | 203/6000 [11:55<6:10:03,  3.83s/it]  3%|â–Ž         | 204/6000 [11:58<6:00:16,  3.73s/it]                                                    {'loss': 0.055, 'grad_norm': 10.258594512939453, 'learning_rate': 9.823728813559322e-06, 'epoch': 0.03}
  3%|â–Ž         | 204/6000 [11:58<6:00:16,  3.73s/it]  3%|â–Ž         | 205/6000 [12:01<5:48:38,  3.61s/it]                                                    {'loss': 0.2113, 'grad_norm': 23.22956657409668, 'learning_rate': 9.822033898305085e-06, 'epoch': 0.03}
  3%|â–Ž         | 205/6000 [12:01<5:48:38,  3.61s/it]  3%|â–Ž         | 206/6000 [12:05<5:39:44,  3.52s/it]                                                    {'loss': 0.0217, 'grad_norm': 6.6879472732543945, 'learning_rate': 9.820338983050849e-06, 'epoch': 0.03}
  3%|â–Ž         | 206/6000 [12:05<5:39:44,  3.52s/it]  3%|â–Ž         | 207/6000 [12:08<5:38:39,  3.51s/it]                                                    {'loss': 0.0211, 'grad_norm': 4.857183933258057, 'learning_rate': 9.818644067796612e-06, 'epoch': 0.03}
  3%|â–Ž         | 207/6000 [12:08<5:38:39,  3.51s/it]  3%|â–Ž         | 208/6000 [12:12<5:32:10,  3.44s/it]                                                    {'loss': 0.1834, 'grad_norm': 48.54136276245117, 'learning_rate': 9.816949152542373e-06, 'epoch': 0.03}
  3%|â–Ž         | 208/6000 [12:12<5:32:10,  3.44s/it]  3%|â–Ž         | 209/6000 [12:15<5:30:14,  3.42s/it]                                                    {'loss': 0.0364, 'grad_norm': 10.085060119628906, 'learning_rate': 9.815254237288137e-06, 'epoch': 0.03}
  3%|â–Ž         | 209/6000 [12:15<5:30:14,  3.42s/it]  4%|â–Ž         | 210/6000 [12:19<5:42:47,  3.55s/it]                                                    {'loss': 0.0477, 'grad_norm': 15.438921928405762, 'learning_rate': 9.813559322033898e-06, 'epoch': 0.04}
  4%|â–Ž         | 210/6000 [12:19<5:42:47,  3.55s/it]  4%|â–Ž         | 211/6000 [12:22<5:42:52,  3.55s/it]                                                    {'loss': 0.0712, 'grad_norm': 16.29297637939453, 'learning_rate': 9.811864406779662e-06, 'epoch': 0.04}
  4%|â–Ž         | 211/6000 [12:22<5:42:52,  3.55s/it]  4%|â–Ž         | 212/6000 [12:26<5:50:25,  3.63s/it]                                                    {'loss': 0.2437, 'grad_norm': 18.716880798339844, 'learning_rate': 9.810169491525425e-06, 'epoch': 0.04}
  4%|â–Ž         | 212/6000 [12:26<5:50:25,  3.63s/it]  4%|â–Ž         | 213/6000 [12:30<5:45:40,  3.58s/it]                                                    {'loss': 0.1236, 'grad_norm': 18.23131561279297, 'learning_rate': 9.808474576271188e-06, 'epoch': 0.04}
  4%|â–Ž         | 213/6000 [12:30<5:45:40,  3.58s/it]  4%|â–Ž         | 214/6000 [12:33<5:39:14,  3.52s/it]                                                    {'loss': 0.059, 'grad_norm': 12.226388931274414, 'learning_rate': 9.80677966101695e-06, 'epoch': 0.04}
  4%|â–Ž         | 214/6000 [12:33<5:39:14,  3.52s/it]  4%|â–Ž         | 215/6000 [12:36<5:34:33,  3.47s/it]                                                    {'loss': 0.0672, 'grad_norm': 14.540135383605957, 'learning_rate': 9.805084745762713e-06, 'epoch': 0.04}
  4%|â–Ž         | 215/6000 [12:36<5:34:33,  3.47s/it]  4%|â–Ž         | 216/6000 [12:40<5:34:13,  3.47s/it]                                                    {'loss': 0.024, 'grad_norm': 5.182026386260986, 'learning_rate': 9.803389830508474e-06, 'epoch': 0.04}
  4%|â–Ž         | 216/6000 [12:40<5:34:13,  3.47s/it]  4%|â–Ž         | 217/6000 [12:43<5:38:17,  3.51s/it]                                                    {'loss': 0.0844, 'grad_norm': 14.851099967956543, 'learning_rate': 9.801694915254238e-06, 'epoch': 0.04}
  4%|â–Ž         | 217/6000 [12:43<5:38:17,  3.51s/it]  4%|â–Ž         | 218/6000 [12:47<5:36:00,  3.49s/it]                                                    {'loss': 0.1112, 'grad_norm': 16.434762954711914, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.04}
  4%|â–Ž         | 218/6000 [12:47<5:36:00,  3.49s/it]  4%|â–Ž         | 219/6000 [12:50<5:31:36,  3.44s/it]                                                    {'loss': 0.2132, 'grad_norm': 35.95257568359375, 'learning_rate': 9.798305084745764e-06, 'epoch': 0.04}
  4%|â–Ž         | 219/6000 [12:50<5:31:36,  3.44s/it]  4%|â–Ž         | 220/6000 [12:54<5:31:43,  3.44s/it]                                                    {'loss': 0.4793, 'grad_norm': 36.812583923339844, 'learning_rate': 9.796610169491526e-06, 'epoch': 0.04}
  4%|â–Ž         | 220/6000 [12:54<5:31:43,  3.44s/it]  4%|â–Ž         | 221/6000 [12:57<5:30:19,  3.43s/it]                                                    {'loss': 0.0748, 'grad_norm': 8.55960464477539, 'learning_rate': 9.79491525423729e-06, 'epoch': 0.04}
  4%|â–Ž         | 221/6000 [12:57<5:30:19,  3.43s/it]  4%|â–Ž         | 222/6000 [13:01<5:33:52,  3.47s/it]                                                    {'loss': 0.1076, 'grad_norm': 14.19888973236084, 'learning_rate': 9.79322033898305e-06, 'epoch': 0.04}
  4%|â–Ž         | 222/6000 [13:01<5:33:52,  3.47s/it]  4%|â–Ž         | 223/6000 [13:04<5:32:22,  3.45s/it]                                                    {'loss': 0.1634, 'grad_norm': 15.642768859863281, 'learning_rate': 9.791525423728816e-06, 'epoch': 0.04}
  4%|â–Ž         | 223/6000 [13:04<5:32:22,  3.45s/it]  4%|â–Ž         | 224/6000 [13:07<5:27:44,  3.40s/it]                                                    {'loss': 0.0902, 'grad_norm': 13.35488510131836, 'learning_rate': 9.789830508474577e-06, 'epoch': 0.04}
  4%|â–Ž         | 224/6000 [13:07<5:27:44,  3.40s/it]  4%|â–         | 225/6000 [13:11<5:29:26,  3.42s/it]                                                    {'loss': 0.2381, 'grad_norm': 18.113088607788086, 'learning_rate': 9.788135593220339e-06, 'epoch': 0.04}
  4%|â–         | 225/6000 [13:11<5:29:26,  3.42s/it]  4%|â–         | 226/6000 [13:15<5:44:12,  3.58s/it]                                                    {'loss': 0.0704, 'grad_norm': 20.102705001831055, 'learning_rate': 9.786440677966102e-06, 'epoch': 0.04}
  4%|â–         | 226/6000 [13:15<5:44:12,  3.58s/it]  4%|â–         | 227/6000 [13:18<5:38:40,  3.52s/it]                                                    {'loss': 0.2056, 'grad_norm': 24.939775466918945, 'learning_rate': 9.784745762711865e-06, 'epoch': 0.04}
  4%|â–         | 227/6000 [13:18<5:38:40,  3.52s/it]  4%|â–         | 228/6000 [13:22<5:37:58,  3.51s/it]                                                    {'loss': 0.0691, 'grad_norm': 9.852935791015625, 'learning_rate': 9.783050847457629e-06, 'epoch': 0.04}
  4%|â–         | 228/6000 [13:22<5:37:58,  3.51s/it]  4%|â–         | 229/6000 [13:25<5:31:27,  3.45s/it]                                                    {'loss': 0.1072, 'grad_norm': 20.654855728149414, 'learning_rate': 9.78135593220339e-06, 'epoch': 0.04}
  4%|â–         | 229/6000 [13:25<5:31:27,  3.45s/it]  4%|â–         | 230/6000 [13:28<5:32:36,  3.46s/it]                                                    {'loss': 0.0468, 'grad_norm': 12.240196228027344, 'learning_rate': 9.779661016949154e-06, 'epoch': 0.04}
  4%|â–         | 230/6000 [13:28<5:32:36,  3.46s/it]  4%|â–         | 231/6000 [13:32<5:29:02,  3.42s/it]                                                    {'loss': 0.0736, 'grad_norm': 15.9409761428833, 'learning_rate': 9.777966101694915e-06, 'epoch': 0.04}
  4%|â–         | 231/6000 [13:32<5:29:02,  3.42s/it]  4%|â–         | 232/6000 [13:35<5:28:24,  3.42s/it]                                                    {'loss': 0.2604, 'grad_norm': 45.97188186645508, 'learning_rate': 9.776271186440678e-06, 'epoch': 0.04}
  4%|â–         | 232/6000 [13:35<5:28:24,  3.42s/it]  4%|â–         | 233/6000 [13:39<5:37:37,  3.51s/it]                                                    {'loss': 0.1029, 'grad_norm': 19.607421875, 'learning_rate': 9.774576271186442e-06, 'epoch': 0.04}
  4%|â–         | 233/6000 [13:39<5:37:37,  3.51s/it]  4%|â–         | 234/6000 [13:43<5:43:32,  3.57s/it]                                                    {'loss': 0.0592, 'grad_norm': 9.21088695526123, 'learning_rate': 9.772881355932205e-06, 'epoch': 0.04}
  4%|â–         | 234/6000 [13:43<5:43:32,  3.57s/it]  4%|â–         | 235/6000 [13:46<5:35:43,  3.49s/it]                                                    {'loss': 0.1249, 'grad_norm': 16.18160629272461, 'learning_rate': 9.771186440677967e-06, 'epoch': 0.04}
  4%|â–         | 235/6000 [13:46<5:35:43,  3.49s/it]  4%|â–         | 236/6000 [13:49<5:34:34,  3.48s/it]                                                    {'loss': 0.1174, 'grad_norm': 12.080294609069824, 'learning_rate': 9.76949152542373e-06, 'epoch': 0.04}
  4%|â–         | 236/6000 [13:49<5:34:34,  3.48s/it]  4%|â–         | 237/6000 [13:53<5:33:06,  3.47s/it]                                                    {'loss': 0.2579, 'grad_norm': 21.974191665649414, 'learning_rate': 9.767796610169491e-06, 'epoch': 0.04}
  4%|â–         | 237/6000 [13:53<5:33:06,  3.47s/it]  4%|â–         | 238/6000 [13:57<5:45:27,  3.60s/it]                                                    {'loss': 0.3709, 'grad_norm': 23.234577178955078, 'learning_rate': 9.766101694915255e-06, 'epoch': 0.04}
  4%|â–         | 238/6000 [13:57<5:45:27,  3.60s/it]  4%|â–         | 239/6000 [14:00<5:41:49,  3.56s/it]                                                    {'loss': 0.0654, 'grad_norm': 17.343948364257812, 'learning_rate': 9.764406779661018e-06, 'epoch': 0.04}
  4%|â–         | 239/6000 [14:00<5:41:49,  3.56s/it]  4%|â–         | 240/6000 [14:04<5:36:56,  3.51s/it]                                                    {'loss': 0.1659, 'grad_norm': 16.732858657836914, 'learning_rate': 9.762711864406781e-06, 'epoch': 0.04}
  4%|â–         | 240/6000 [14:04<5:36:56,  3.51s/it]  4%|â–         | 241/6000 [14:07<5:38:12,  3.52s/it]                                                    {'loss': 0.0997, 'grad_norm': 16.669519424438477, 'learning_rate': 9.761016949152543e-06, 'epoch': 0.04}
  4%|â–         | 241/6000 [14:07<5:38:12,  3.52s/it]  4%|â–         | 242/6000 [14:10<5:33:16,  3.47s/it]                                                    {'loss': 0.0978, 'grad_norm': 17.90516471862793, 'learning_rate': 9.759322033898306e-06, 'epoch': 0.04}
  4%|â–         | 242/6000 [14:10<5:33:16,  3.47s/it]  4%|â–         | 243/6000 [14:14<5:41:44,  3.56s/it]                                                    {'loss': 0.2698, 'grad_norm': 25.953744888305664, 'learning_rate': 9.75762711864407e-06, 'epoch': 0.04}
  4%|â–         | 243/6000 [14:14<5:41:44,  3.56s/it]  4%|â–         | 244/6000 [14:18<5:35:26,  3.50s/it]                                                    {'loss': 0.0792, 'grad_norm': 15.939784049987793, 'learning_rate': 9.755932203389833e-06, 'epoch': 0.04}
  4%|â–         | 244/6000 [14:18<5:35:26,  3.50s/it]  4%|â–         | 245/6000 [14:21<5:37:18,  3.52s/it]                                                    {'loss': 0.097, 'grad_norm': 18.7656307220459, 'learning_rate': 9.754237288135594e-06, 'epoch': 0.04}
  4%|â–         | 245/6000 [14:21<5:37:18,  3.52s/it]  4%|â–         | 246/6000 [14:25<5:37:26,  3.52s/it]                                                    {'loss': 0.0093, 'grad_norm': 1.9097774028778076, 'learning_rate': 9.752542372881356e-06, 'epoch': 0.04}
  4%|â–         | 246/6000 [14:25<5:37:26,  3.52s/it]  4%|â–         | 247/6000 [14:28<5:32:31,  3.47s/it]                                                    {'loss': 0.1193, 'grad_norm': 20.594696044921875, 'learning_rate': 9.750847457627119e-06, 'epoch': 0.04}
  4%|â–         | 247/6000 [14:28<5:32:31,  3.47s/it]  4%|â–         | 248/6000 [14:32<5:34:53,  3.49s/it]                                                    {'loss': 0.0387, 'grad_norm': 10.164693832397461, 'learning_rate': 9.749152542372882e-06, 'epoch': 0.04}
  4%|â–         | 248/6000 [14:32<5:34:53,  3.49s/it]  4%|â–         | 249/6000 [14:35<5:29:21,  3.44s/it]                                                    {'loss': 0.0382, 'grad_norm': 13.614034652709961, 'learning_rate': 9.747457627118646e-06, 'epoch': 0.04}
  4%|â–         | 249/6000 [14:35<5:29:21,  3.44s/it]  4%|â–         | 250/6000 [14:38<5:25:40,  3.40s/it]                                                    {'loss': 0.076, 'grad_norm': 11.255346298217773, 'learning_rate': 9.745762711864407e-06, 'epoch': 0.04}
  4%|â–         | 250/6000 [14:38<5:25:40,  3.40s/it]  4%|â–         | 251/6000 [14:41<5:22:00,  3.36s/it]                                                    {'loss': 0.1211, 'grad_norm': 21.29943084716797, 'learning_rate': 9.74406779661017e-06, 'epoch': 0.04}
  4%|â–         | 251/6000 [14:41<5:22:00,  3.36s/it]  4%|â–         | 252/6000 [14:45<5:30:07,  3.45s/it]                                                    {'loss': 0.1089, 'grad_norm': 21.263769149780273, 'learning_rate': 9.742372881355932e-06, 'epoch': 0.04}
  4%|â–         | 252/6000 [14:45<5:30:07,  3.45s/it]  4%|â–         | 253/6000 [14:48<5:28:56,  3.43s/it]                                                    {'loss': 0.2088, 'grad_norm': 37.396400451660156, 'learning_rate': 9.740677966101695e-06, 'epoch': 0.04}
  4%|â–         | 253/6000 [14:48<5:28:56,  3.43s/it]  4%|â–         | 254/6000 [14:52<5:29:31,  3.44s/it]                                                    {'loss': 0.2069, 'grad_norm': 22.577255249023438, 'learning_rate': 9.738983050847459e-06, 'epoch': 0.04}
  4%|â–         | 254/6000 [14:52<5:29:31,  3.44s/it]  4%|â–         | 255/6000 [14:55<5:28:35,  3.43s/it]                                                    {'loss': 0.1294, 'grad_norm': 37.15478515625, 'learning_rate': 9.737288135593222e-06, 'epoch': 0.04}
  4%|â–         | 255/6000 [14:55<5:28:35,  3.43s/it]  4%|â–         | 256/6000 [14:59<5:40:53,  3.56s/it]                                                    {'loss': 0.1248, 'grad_norm': 23.331146240234375, 'learning_rate': 9.735593220338983e-06, 'epoch': 0.04}
  4%|â–         | 256/6000 [14:59<5:40:53,  3.56s/it]  4%|â–         | 257/6000 [15:03<5:36:55,  3.52s/it]                                                    {'loss': 0.0414, 'grad_norm': 10.763968467712402, 'learning_rate': 9.733898305084747e-06, 'epoch': 0.04}
  4%|â–         | 257/6000 [15:03<5:36:55,  3.52s/it]  4%|â–         | 258/6000 [15:06<5:32:41,  3.48s/it]                                                    {'loss': 0.0527, 'grad_norm': 8.213644027709961, 'learning_rate': 9.732203389830508e-06, 'epoch': 0.04}
  4%|â–         | 258/6000 [15:06<5:32:41,  3.48s/it]  4%|â–         | 259/6000 [15:09<5:27:44,  3.43s/it]                                                    {'loss': 0.0384, 'grad_norm': 10.796273231506348, 'learning_rate': 9.730508474576272e-06, 'epoch': 0.04}
  4%|â–         | 259/6000 [15:09<5:27:44,  3.43s/it]  4%|â–         | 260/6000 [15:13<5:27:00,  3.42s/it]                                                    {'loss': 0.0041, 'grad_norm': 1.2337371110916138, 'learning_rate': 9.728813559322035e-06, 'epoch': 0.04}
  4%|â–         | 260/6000 [15:13<5:27:00,  3.42s/it]  4%|â–         | 261/6000 [15:16<5:30:02,  3.45s/it]                                                    {'loss': 0.0328, 'grad_norm': 6.3552327156066895, 'learning_rate': 9.727118644067798e-06, 'epoch': 0.04}
  4%|â–         | 261/6000 [15:16<5:30:02,  3.45s/it]  4%|â–         | 262/6000 [15:20<5:28:05,  3.43s/it]                                                    {'loss': 0.0086, 'grad_norm': 2.1844053268432617, 'learning_rate': 9.72542372881356e-06, 'epoch': 0.04}
  4%|â–         | 262/6000 [15:20<5:28:05,  3.43s/it]  4%|â–         | 263/6000 [15:24<5:41:12,  3.57s/it]                                                    {'loss': 0.0516, 'grad_norm': 8.69075870513916, 'learning_rate': 9.723728813559323e-06, 'epoch': 0.04}
  4%|â–         | 263/6000 [15:24<5:41:12,  3.57s/it]  4%|â–         | 264/6000 [15:27<5:34:28,  3.50s/it]                                                    {'loss': 0.2806, 'grad_norm': 90.73429870605469, 'learning_rate': 9.722033898305086e-06, 'epoch': 0.04}
  4%|â–         | 264/6000 [15:27<5:34:28,  3.50s/it]  4%|â–         | 265/6000 [15:30<5:36:13,  3.52s/it]                                                    {'loss': 0.0557, 'grad_norm': 16.148433685302734, 'learning_rate': 9.72033898305085e-06, 'epoch': 0.04}
  4%|â–         | 265/6000 [15:30<5:36:13,  3.52s/it]  4%|â–         | 266/6000 [15:34<5:35:13,  3.51s/it]                                                    {'loss': 0.0177, 'grad_norm': 3.360912799835205, 'learning_rate': 9.718644067796611e-06, 'epoch': 0.04}
  4%|â–         | 266/6000 [15:34<5:35:13,  3.51s/it]  4%|â–         | 267/6000 [15:37<5:28:33,  3.44s/it]                                                    {'loss': 0.083, 'grad_norm': 10.691776275634766, 'learning_rate': 9.716949152542373e-06, 'epoch': 0.04}
  4%|â–         | 267/6000 [15:37<5:28:33,  3.44s/it]  4%|â–         | 268/6000 [15:41<5:27:03,  3.42s/it]                                                    {'loss': 0.0339, 'grad_norm': 8.118677139282227, 'learning_rate': 9.715254237288136e-06, 'epoch': 0.04}
  4%|â–         | 268/6000 [15:41<5:27:03,  3.42s/it]  4%|â–         | 269/6000 [15:44<5:34:02,  3.50s/it]                                                    {'loss': 0.0457, 'grad_norm': 14.225387573242188, 'learning_rate': 9.7135593220339e-06, 'epoch': 0.04}
  4%|â–         | 269/6000 [15:44<5:34:02,  3.50s/it]  4%|â–         | 270/6000 [15:48<5:30:14,  3.46s/it]                                                    {'loss': 0.0417, 'grad_norm': 7.574519634246826, 'learning_rate': 9.711864406779662e-06, 'epoch': 0.04}
  4%|â–         | 270/6000 [15:48<5:30:14,  3.46s/it]  5%|â–         | 271/6000 [15:51<5:29:16,  3.45s/it]                                                    {'loss': 0.0148, 'grad_norm': 4.387695789337158, 'learning_rate': 9.710169491525424e-06, 'epoch': 0.05}
  5%|â–         | 271/6000 [15:51<5:29:16,  3.45s/it]  5%|â–         | 272/6000 [15:54<5:26:22,  3.42s/it]                                                    {'loss': 0.1495, 'grad_norm': 22.232269287109375, 'learning_rate': 9.708474576271187e-06, 'epoch': 0.05}
  5%|â–         | 272/6000 [15:54<5:26:22,  3.42s/it]  5%|â–         | 273/6000 [15:58<5:25:21,  3.41s/it]                                                    {'loss': 0.0344, 'grad_norm': 11.48599624633789, 'learning_rate': 9.706779661016949e-06, 'epoch': 0.05}
  5%|â–         | 273/6000 [15:58<5:25:21,  3.41s/it]  5%|â–         | 274/6000 [16:02<5:36:35,  3.53s/it]                                                    {'loss': 0.1641, 'grad_norm': 23.042600631713867, 'learning_rate': 9.705084745762712e-06, 'epoch': 0.05}
  5%|â–         | 274/6000 [16:02<5:36:35,  3.53s/it]  5%|â–         | 275/6000 [16:05<5:34:27,  3.51s/it]                                                    {'loss': 0.1977, 'grad_norm': 27.699325561523438, 'learning_rate': 9.703389830508475e-06, 'epoch': 0.05}
  5%|â–         | 275/6000 [16:05<5:34:27,  3.51s/it]  5%|â–         | 276/6000 [16:08<5:33:58,  3.50s/it]                                                    {'loss': 0.1247, 'grad_norm': 15.890789985656738, 'learning_rate': 9.701694915254239e-06, 'epoch': 0.05}
  5%|â–         | 276/6000 [16:09<5:33:58,  3.50s/it]  5%|â–         | 277/6000 [16:12<5:29:16,  3.45s/it]                                                    {'loss': 0.1421, 'grad_norm': 21.660442352294922, 'learning_rate': 9.7e-06, 'epoch': 0.05}
  5%|â–         | 277/6000 [16:12<5:29:16,  3.45s/it]  5%|â–         | 278/6000 [16:15<5:27:36,  3.44s/it]                                                    {'loss': 0.0278, 'grad_norm': 10.652298927307129, 'learning_rate': 9.698305084745764e-06, 'epoch': 0.05}
  5%|â–         | 278/6000 [16:15<5:27:36,  3.44s/it]  5%|â–         | 279/6000 [16:19<5:29:05,  3.45s/it]                                                    {'loss': 0.2548, 'grad_norm': 24.22513771057129, 'learning_rate': 9.696610169491527e-06, 'epoch': 0.05}
  5%|â–         | 279/6000 [16:19<5:29:05,  3.45s/it]  5%|â–         | 280/6000 [16:22<5:27:23,  3.43s/it]                                                    {'loss': 0.1093, 'grad_norm': 16.57261085510254, 'learning_rate': 9.69491525423729e-06, 'epoch': 0.05}
  5%|â–         | 280/6000 [16:22<5:27:23,  3.43s/it]  5%|â–         | 281/6000 [16:26<5:27:33,  3.44s/it]                                                    {'loss': 0.3794, 'grad_norm': 22.155101776123047, 'learning_rate': 9.693220338983052e-06, 'epoch': 0.05}
  5%|â–         | 281/6000 [16:26<5:27:33,  3.44s/it]  5%|â–         | 282/6000 [16:29<5:41:20,  3.58s/it]                                                    {'loss': 0.0996, 'grad_norm': 12.912755966186523, 'learning_rate': 9.691525423728815e-06, 'epoch': 0.05}
  5%|â–         | 282/6000 [16:29<5:41:20,  3.58s/it]  5%|â–         | 283/6000 [16:33<5:45:42,  3.63s/it]                                                    {'loss': 0.0148, 'grad_norm': 3.110943078994751, 'learning_rate': 9.689830508474577e-06, 'epoch': 0.05}
  5%|â–         | 283/6000 [16:33<5:45:42,  3.63s/it]  5%|â–         | 284/6000 [16:37<5:58:33,  3.76s/it]                                                    {'loss': 0.0668, 'grad_norm': 19.319232940673828, 'learning_rate': 9.68813559322034e-06, 'epoch': 0.05}
  5%|â–         | 284/6000 [16:37<5:58:33,  3.76s/it]  5%|â–         | 285/6000 [16:41<5:52:53,  3.70s/it]                                                    {'loss': 0.1113, 'grad_norm': 16.926698684692383, 'learning_rate': 9.686440677966103e-06, 'epoch': 0.05}
  5%|â–         | 285/6000 [16:41<5:52:53,  3.70s/it]  5%|â–         | 286/6000 [16:44<5:43:25,  3.61s/it]                                                    {'loss': 0.1229, 'grad_norm': 22.578903198242188, 'learning_rate': 9.684745762711866e-06, 'epoch': 0.05}
  5%|â–         | 286/6000 [16:44<5:43:25,  3.61s/it]  5%|â–         | 287/6000 [16:48<5:36:58,  3.54s/it]                                                    {'loss': 0.0552, 'grad_norm': 12.914388656616211, 'learning_rate': 9.683050847457628e-06, 'epoch': 0.05}
  5%|â–         | 287/6000 [16:48<5:36:58,  3.54s/it]  5%|â–         | 288/6000 [16:51<5:31:10,  3.48s/it]                                                    {'loss': 0.0122, 'grad_norm': 3.3070130348205566, 'learning_rate': 9.68135593220339e-06, 'epoch': 0.05}
  5%|â–         | 288/6000 [16:51<5:31:10,  3.48s/it]  5%|â–         | 289/6000 [16:55<5:34:30,  3.51s/it]                                                    {'loss': 0.119, 'grad_norm': 14.162599563598633, 'learning_rate': 9.679661016949153e-06, 'epoch': 0.05}
  5%|â–         | 289/6000 [16:55<5:34:30,  3.51s/it]  5%|â–         | 290/6000 [16:58<5:33:17,  3.50s/it]                                                    {'loss': 0.0556, 'grad_norm': 14.530817031860352, 'learning_rate': 9.677966101694916e-06, 'epoch': 0.05}
  5%|â–         | 290/6000 [16:58<5:33:17,  3.50s/it]  5%|â–         | 291/6000 [17:01<5:31:00,  3.48s/it]                                                    {'loss': 0.2663, 'grad_norm': 25.37936019897461, 'learning_rate': 9.67627118644068e-06, 'epoch': 0.05}
  5%|â–         | 291/6000 [17:01<5:31:00,  3.48s/it]  5%|â–         | 292/6000 [17:05<5:26:58,  3.44s/it]                                                    {'loss': 0.2795, 'grad_norm': 27.44681739807129, 'learning_rate': 9.674576271186441e-06, 'epoch': 0.05}
  5%|â–         | 292/6000 [17:05<5:26:58,  3.44s/it]  5%|â–         | 293/6000 [17:08<5:25:10,  3.42s/it]                                                    {'loss': 0.0642, 'grad_norm': 9.92977237701416, 'learning_rate': 9.672881355932204e-06, 'epoch': 0.05}
  5%|â–         | 293/6000 [17:08<5:25:10,  3.42s/it]  5%|â–         | 294/6000 [17:12<5:23:43,  3.40s/it]                                                    {'loss': 0.4258, 'grad_norm': 32.6007194519043, 'learning_rate': 9.671186440677966e-06, 'epoch': 0.05}
  5%|â–         | 294/6000 [17:12<5:23:43,  3.40s/it]  5%|â–         | 295/6000 [17:15<5:22:10,  3.39s/it]                                                    {'loss': 0.1176, 'grad_norm': 14.42868423461914, 'learning_rate': 9.669491525423729e-06, 'epoch': 0.05}
  5%|â–         | 295/6000 [17:15<5:22:10,  3.39s/it]  5%|â–         | 296/6000 [17:19<5:30:19,  3.47s/it]                                                    {'loss': 0.1086, 'grad_norm': 12.481338500976562, 'learning_rate': 9.667796610169492e-06, 'epoch': 0.05}
  5%|â–         | 296/6000 [17:19<5:30:19,  3.47s/it]  5%|â–         | 297/6000 [17:22<5:27:30,  3.45s/it]                                                    {'loss': 0.1093, 'grad_norm': 27.654577255249023, 'learning_rate': 9.666101694915256e-06, 'epoch': 0.05}
  5%|â–         | 297/6000 [17:22<5:27:30,  3.45s/it]  5%|â–         | 298/6000 [17:26<5:31:34,  3.49s/it]                                                    {'loss': 0.0819, 'grad_norm': 6.96032190322876, 'learning_rate': 9.664406779661017e-06, 'epoch': 0.05}
  5%|â–         | 298/6000 [17:26<5:31:34,  3.49s/it]  5%|â–         | 299/6000 [17:30<5:55:36,  3.74s/it]                                                    {'loss': 0.1132, 'grad_norm': 13.277689933776855, 'learning_rate': 9.66271186440678e-06, 'epoch': 0.05}
  5%|â–         | 299/6000 [17:30<5:55:36,  3.74s/it]  5%|â–Œ         | 300/6000 [17:33<5:46:41,  3.65s/it]                                                    {'loss': 0.0091, 'grad_norm': 4.264097213745117, 'learning_rate': 9.661016949152544e-06, 'epoch': 0.05}
  5%|â–Œ         | 300/6000 [17:33<5:46:41,  3.65s/it][2025-11-06 23:08:43,294] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300
[2025-11-06 23:08:43,307] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:08:43,986] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  5%|â–Œ         | 301/6000 [17:39<6:53:14,  4.35s/it]                                                    {'loss': 0.1331, 'grad_norm': 31.435747146606445, 'learning_rate': 9.659322033898307e-06, 'epoch': 0.05}
  5%|â–Œ         | 301/6000 [17:39<6:53:14,  4.35s/it]  5%|â–Œ         | 302/6000 [17:43<6:27:43,  4.08s/it]                                                    {'loss': 0.0413, 'grad_norm': 9.105016708374023, 'learning_rate': 9.657627118644069e-06, 'epoch': 0.05}
  5%|â–Œ         | 302/6000 [17:43<6:27:43,  4.08s/it]  5%|â–Œ         | 303/6000 [17:46<6:08:13,  3.88s/it]                                                    {'loss': 0.0196, 'grad_norm': 5.343202114105225, 'learning_rate': 9.655932203389832e-06, 'epoch': 0.05}
  5%|â–Œ         | 303/6000 [17:46<6:08:13,  3.88s/it]  5%|â–Œ         | 304/6000 [17:50<5:56:54,  3.76s/it]                                                    {'loss': 0.05, 'grad_norm': 14.293680191040039, 'learning_rate': 9.654237288135593e-06, 'epoch': 0.05}
  5%|â–Œ         | 304/6000 [17:50<5:56:54,  3.76s/it]  5%|â–Œ         | 305/6000 [17:53<5:46:04,  3.65s/it]                                                    {'loss': 0.2595, 'grad_norm': 29.445655822753906, 'learning_rate': 9.652542372881357e-06, 'epoch': 0.05}
  5%|â–Œ         | 305/6000 [17:53<5:46:04,  3.65s/it]  5%|â–Œ         | 306/6000 [17:56<5:38:41,  3.57s/it]                                                    {'loss': 0.0404, 'grad_norm': 8.137747764587402, 'learning_rate': 9.65084745762712e-06, 'epoch': 0.05}
  5%|â–Œ         | 306/6000 [17:56<5:38:41,  3.57s/it]  5%|â–Œ         | 307/6000 [18:00<5:32:26,  3.50s/it]                                                    {'loss': 0.0305, 'grad_norm': 4.611482620239258, 'learning_rate': 9.649152542372883e-06, 'epoch': 0.05}
  5%|â–Œ         | 307/6000 [18:00<5:32:26,  3.50s/it]  5%|â–Œ         | 308/6000 [18:03<5:28:53,  3.47s/it]                                                    {'loss': 0.0807, 'grad_norm': 11.510882377624512, 'learning_rate': 9.647457627118645e-06, 'epoch': 0.05}
  5%|â–Œ         | 308/6000 [18:03<5:28:53,  3.47s/it]  5%|â–Œ         | 309/6000 [18:07<5:31:46,  3.50s/it]                                                    {'loss': 0.2132, 'grad_norm': 29.896543502807617, 'learning_rate': 9.645762711864406e-06, 'epoch': 0.05}
  5%|â–Œ         | 309/6000 [18:07<5:31:46,  3.50s/it]  5%|â–Œ         | 310/6000 [18:10<5:27:42,  3.46s/it]                                                    {'loss': 0.0591, 'grad_norm': 7.1286516189575195, 'learning_rate': 9.64406779661017e-06, 'epoch': 0.05}
  5%|â–Œ         | 310/6000 [18:10<5:27:42,  3.46s/it]  5%|â–Œ         | 311/6000 [18:13<5:25:28,  3.43s/it]                                                    {'loss': 0.2072, 'grad_norm': 22.99054527282715, 'learning_rate': 9.642372881355933e-06, 'epoch': 0.05}
  5%|â–Œ         | 311/6000 [18:13<5:25:28,  3.43s/it]  5%|â–Œ         | 312/6000 [18:17<5:24:32,  3.42s/it]                                                    {'loss': 0.2928, 'grad_norm': 38.63496398925781, 'learning_rate': 9.640677966101696e-06, 'epoch': 0.05}
  5%|â–Œ         | 312/6000 [18:17<5:24:32,  3.42s/it]  5%|â–Œ         | 313/6000 [18:20<5:24:00,  3.42s/it]                                                    {'loss': 0.1575, 'grad_norm': 29.82919692993164, 'learning_rate': 9.638983050847458e-06, 'epoch': 0.05}
  5%|â–Œ         | 313/6000 [18:20<5:24:00,  3.42s/it]  5%|â–Œ         | 314/6000 [18:24<5:26:15,  3.44s/it]                                                    {'loss': 0.093, 'grad_norm': 11.715738296508789, 'learning_rate': 9.637288135593221e-06, 'epoch': 0.05}
  5%|â–Œ         | 314/6000 [18:24<5:26:15,  3.44s/it]  5%|â–Œ         | 315/6000 [18:27<5:24:44,  3.43s/it]                                                    {'loss': 0.0698, 'grad_norm': 13.682765007019043, 'learning_rate': 9.635593220338983e-06, 'epoch': 0.05}
  5%|â–Œ         | 315/6000 [18:27<5:24:44,  3.43s/it]  5%|â–Œ         | 316/6000 [18:30<5:22:45,  3.41s/it]                                                    {'loss': 0.0202, 'grad_norm': 5.765392780303955, 'learning_rate': 9.633898305084746e-06, 'epoch': 0.05}
  5%|â–Œ         | 316/6000 [18:31<5:22:45,  3.41s/it]  5%|â–Œ         | 317/6000 [18:34<5:28:07,  3.46s/it]                                                    {'loss': 0.146, 'grad_norm': 24.785409927368164, 'learning_rate': 9.63220338983051e-06, 'epoch': 0.05}
  5%|â–Œ         | 317/6000 [18:34<5:28:07,  3.46s/it]  5%|â–Œ         | 318/6000 [18:38<5:36:05,  3.55s/it]                                                    {'loss': 0.1177, 'grad_norm': 21.743022918701172, 'learning_rate': 9.630508474576272e-06, 'epoch': 0.05}
  5%|â–Œ         | 318/6000 [18:38<5:36:05,  3.55s/it]  5%|â–Œ         | 319/6000 [18:41<5:32:21,  3.51s/it]                                                    {'loss': 0.4899, 'grad_norm': 23.333633422851562, 'learning_rate': 9.628813559322034e-06, 'epoch': 0.05}
  5%|â–Œ         | 319/6000 [18:41<5:32:21,  3.51s/it]  5%|â–Œ         | 320/6000 [18:45<5:30:59,  3.50s/it]                                                    {'loss': 0.1431, 'grad_norm': 20.22340965270996, 'learning_rate': 9.627118644067797e-06, 'epoch': 0.05}
  5%|â–Œ         | 320/6000 [18:45<5:30:59,  3.50s/it]  5%|â–Œ         | 321/6000 [18:49<5:42:36,  3.62s/it]                                                    {'loss': 0.067, 'grad_norm': 12.211505889892578, 'learning_rate': 9.62542372881356e-06, 'epoch': 0.05}
  5%|â–Œ         | 321/6000 [18:49<5:42:36,  3.62s/it]  5%|â–Œ         | 322/6000 [18:52<5:35:21,  3.54s/it]                                                    {'loss': 0.1067, 'grad_norm': 21.27567481994629, 'learning_rate': 9.623728813559324e-06, 'epoch': 0.05}
  5%|â–Œ         | 322/6000 [18:52<5:35:21,  3.54s/it]  5%|â–Œ         | 323/6000 [18:56<5:49:48,  3.70s/it]                                                    {'loss': 0.0433, 'grad_norm': 8.120748519897461, 'learning_rate': 9.622033898305085e-06, 'epoch': 0.05}
  5%|â–Œ         | 323/6000 [18:56<5:49:48,  3.70s/it]  5%|â–Œ         | 324/6000 [18:59<5:40:35,  3.60s/it]                                                    {'loss': 0.1445, 'grad_norm': 21.80435562133789, 'learning_rate': 9.620338983050849e-06, 'epoch': 0.05}
  5%|â–Œ         | 324/6000 [18:59<5:40:35,  3.60s/it]  5%|â–Œ         | 325/6000 [19:03<5:33:25,  3.53s/it]                                                    {'loss': 0.1578, 'grad_norm': 25.415626525878906, 'learning_rate': 9.61864406779661e-06, 'epoch': 0.05}
  5%|â–Œ         | 325/6000 [19:03<5:33:25,  3.53s/it]  5%|â–Œ         | 326/6000 [19:06<5:28:49,  3.48s/it]                                                    {'loss': 0.1307, 'grad_norm': 23.1487979888916, 'learning_rate': 9.616949152542374e-06, 'epoch': 0.05}
  5%|â–Œ         | 326/6000 [19:06<5:28:49,  3.48s/it]  5%|â–Œ         | 327/6000 [19:09<5:24:03,  3.43s/it]                                                    {'loss': 0.0689, 'grad_norm': 16.84820556640625, 'learning_rate': 9.615254237288137e-06, 'epoch': 0.05}
  5%|â–Œ         | 327/6000 [19:09<5:24:03,  3.43s/it]  5%|â–Œ         | 328/6000 [19:13<5:23:37,  3.42s/it]                                                    {'loss': 0.01, 'grad_norm': 3.098944664001465, 'learning_rate': 9.6135593220339e-06, 'epoch': 0.05}
  5%|â–Œ         | 328/6000 [19:13<5:23:37,  3.42s/it]  5%|â–Œ         | 329/6000 [19:17<5:30:15,  3.49s/it]                                                    {'loss': 0.0988, 'grad_norm': 16.636205673217773, 'learning_rate': 9.611864406779662e-06, 'epoch': 0.05}
  5%|â–Œ         | 329/6000 [19:17<5:30:15,  3.49s/it]  6%|â–Œ         | 330/6000 [19:20<5:27:28,  3.47s/it]                                                    {'loss': 0.069, 'grad_norm': 13.941180229187012, 'learning_rate': 9.610169491525423e-06, 'epoch': 0.06}
  6%|â–Œ         | 330/6000 [19:20<5:27:28,  3.47s/it]  6%|â–Œ         | 331/6000 [19:23<5:25:59,  3.45s/it]                                                    {'loss': 0.1032, 'grad_norm': 19.03752899169922, 'learning_rate': 9.608474576271187e-06, 'epoch': 0.06}
  6%|â–Œ         | 331/6000 [19:23<5:25:59,  3.45s/it]  6%|â–Œ         | 332/6000 [19:27<5:21:16,  3.40s/it]                                                    {'loss': 0.0785, 'grad_norm': 21.789670944213867, 'learning_rate': 9.60677966101695e-06, 'epoch': 0.06}
  6%|â–Œ         | 332/6000 [19:27<5:21:16,  3.40s/it]  6%|â–Œ         | 333/6000 [19:30<5:20:50,  3.40s/it]                                                    {'loss': 0.0301, 'grad_norm': 8.861479759216309, 'learning_rate': 9.605084745762713e-06, 'epoch': 0.06}
  6%|â–Œ         | 333/6000 [19:30<5:20:50,  3.40s/it]  6%|â–Œ         | 334/6000 [19:33<5:20:18,  3.39s/it]                                                    {'loss': 0.0524, 'grad_norm': 12.898146629333496, 'learning_rate': 9.603389830508475e-06, 'epoch': 0.06}
  6%|â–Œ         | 334/6000 [19:33<5:20:18,  3.39s/it]  6%|â–Œ         | 335/6000 [19:37<5:22:29,  3.42s/it]                                                    {'loss': 0.0236, 'grad_norm': 4.180819034576416, 'learning_rate': 9.601694915254238e-06, 'epoch': 0.06}
  6%|â–Œ         | 335/6000 [19:37<5:22:29,  3.42s/it]  6%|â–Œ         | 336/6000 [19:40<5:20:44,  3.40s/it]                                                    {'loss': 0.0686, 'grad_norm': 13.213486671447754, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.06}
  6%|â–Œ         | 336/6000 [19:40<5:20:44,  3.40s/it]  6%|â–Œ         | 337/6000 [19:44<5:25:09,  3.45s/it]                                                    {'loss': 0.0435, 'grad_norm': 4.832355499267578, 'learning_rate': 9.598305084745765e-06, 'epoch': 0.06}
  6%|â–Œ         | 337/6000 [19:44<5:25:09,  3.45s/it]  6%|â–Œ         | 338/6000 [19:47<5:22:03,  3.41s/it]                                                    {'loss': 0.0789, 'grad_norm': 7.632974147796631, 'learning_rate': 9.596610169491526e-06, 'epoch': 0.06}
  6%|â–Œ         | 338/6000 [19:47<5:22:03,  3.41s/it]  6%|â–Œ         | 339/6000 [19:51<5:22:09,  3.41s/it]                                                    {'loss': 0.0145, 'grad_norm': 8.21189022064209, 'learning_rate': 9.59491525423729e-06, 'epoch': 0.06}
  6%|â–Œ         | 339/6000 [19:51<5:22:09,  3.41s/it]  6%|â–Œ         | 340/6000 [19:54<5:30:22,  3.50s/it]                                                    {'loss': 0.1779, 'grad_norm': 28.072303771972656, 'learning_rate': 9.593220338983051e-06, 'epoch': 0.06}
  6%|â–Œ         | 340/6000 [19:54<5:30:22,  3.50s/it]  6%|â–Œ         | 341/6000 [19:58<5:25:25,  3.45s/it]                                                    {'loss': 0.0548, 'grad_norm': 13.318099975585938, 'learning_rate': 9.591525423728814e-06, 'epoch': 0.06}
  6%|â–Œ         | 341/6000 [19:58<5:25:25,  3.45s/it]  6%|â–Œ         | 342/6000 [20:01<5:21:51,  3.41s/it]                                                    {'loss': 0.2056, 'grad_norm': 21.780607223510742, 'learning_rate': 9.589830508474578e-06, 'epoch': 0.06}
  6%|â–Œ         | 342/6000 [20:01<5:21:51,  3.41s/it]  6%|â–Œ         | 343/6000 [20:05<5:41:05,  3.62s/it]                                                    {'loss': 0.2219, 'grad_norm': 36.97879409790039, 'learning_rate': 9.58813559322034e-06, 'epoch': 0.06}
  6%|â–Œ         | 343/6000 [20:05<5:41:05,  3.62s/it]  6%|â–Œ         | 344/6000 [20:08<5:35:15,  3.56s/it]                                                    {'loss': 0.2194, 'grad_norm': 43.04542922973633, 'learning_rate': 9.586440677966102e-06, 'epoch': 0.06}
  6%|â–Œ         | 344/6000 [20:08<5:35:15,  3.56s/it]  6%|â–Œ         | 345/6000 [20:12<5:30:39,  3.51s/it]                                                    {'loss': 0.0641, 'grad_norm': 14.604415893554688, 'learning_rate': 9.584745762711866e-06, 'epoch': 0.06}
  6%|â–Œ         | 345/6000 [20:12<5:30:39,  3.51s/it]  6%|â–Œ         | 346/6000 [20:15<5:29:58,  3.50s/it]                                                    {'loss': 0.1466, 'grad_norm': 23.923229217529297, 'learning_rate': 9.583050847457627e-06, 'epoch': 0.06}
  6%|â–Œ         | 346/6000 [20:15<5:29:58,  3.50s/it]  6%|â–Œ         | 347/6000 [20:19<5:24:46,  3.45s/it]                                                    {'loss': 0.0237, 'grad_norm': 4.753714084625244, 'learning_rate': 9.58135593220339e-06, 'epoch': 0.06}
  6%|â–Œ         | 347/6000 [20:19<5:24:46,  3.45s/it]  6%|â–Œ         | 348/6000 [20:22<5:25:46,  3.46s/it]                                                    {'loss': 0.144, 'grad_norm': 17.613357543945312, 'learning_rate': 9.579661016949154e-06, 'epoch': 0.06}
  6%|â–Œ         | 348/6000 [20:22<5:25:46,  3.46s/it]  6%|â–Œ         | 349/6000 [20:26<5:25:34,  3.46s/it]                                                    {'loss': 0.0132, 'grad_norm': 7.589087963104248, 'learning_rate': 9.577966101694917e-06, 'epoch': 0.06}
  6%|â–Œ         | 349/6000 [20:26<5:25:34,  3.46s/it]  6%|â–Œ         | 350/6000 [20:29<5:24:26,  3.45s/it]                                                    {'loss': 0.196, 'grad_norm': 17.956249237060547, 'learning_rate': 9.576271186440679e-06, 'epoch': 0.06}
  6%|â–Œ         | 350/6000 [20:29<5:24:26,  3.45s/it]  6%|â–Œ         | 351/6000 [20:33<5:34:07,  3.55s/it]                                                    {'loss': 0.083, 'grad_norm': 19.41269302368164, 'learning_rate': 9.57457627118644e-06, 'epoch': 0.06}
  6%|â–Œ         | 351/6000 [20:33<5:34:07,  3.55s/it]  6%|â–Œ         | 352/6000 [20:36<5:27:35,  3.48s/it]                                                    {'loss': 0.0183, 'grad_norm': 6.910629749298096, 'learning_rate': 9.572881355932203e-06, 'epoch': 0.06}
  6%|â–Œ         | 352/6000 [20:36<5:27:35,  3.48s/it]  6%|â–Œ         | 353/6000 [20:39<5:23:08,  3.43s/it]                                                    {'loss': 0.0892, 'grad_norm': 20.5788516998291, 'learning_rate': 9.571186440677967e-06, 'epoch': 0.06}
  6%|â–Œ         | 353/6000 [20:39<5:23:08,  3.43s/it]  6%|â–Œ         | 354/6000 [20:43<5:21:07,  3.41s/it]                                                    {'loss': 0.1041, 'grad_norm': 23.829269409179688, 'learning_rate': 9.56949152542373e-06, 'epoch': 0.06}
  6%|â–Œ         | 354/6000 [20:43<5:21:07,  3.41s/it]  6%|â–Œ         | 355/6000 [20:46<5:19:17,  3.39s/it]                                                    {'loss': 0.0192, 'grad_norm': 6.806588172912598, 'learning_rate': 9.567796610169492e-06, 'epoch': 0.06}
  6%|â–Œ         | 355/6000 [20:46<5:19:17,  3.39s/it]  6%|â–Œ         | 356/6000 [20:50<5:25:29,  3.46s/it]                                                    {'loss': 0.108, 'grad_norm': 27.233219146728516, 'learning_rate': 9.566101694915255e-06, 'epoch': 0.06}
  6%|â–Œ         | 356/6000 [20:50<5:25:29,  3.46s/it]  6%|â–Œ         | 357/6000 [20:53<5:24:12,  3.45s/it]                                                    {'loss': 0.0732, 'grad_norm': 10.562630653381348, 'learning_rate': 9.564406779661018e-06, 'epoch': 0.06}
  6%|â–Œ         | 357/6000 [20:53<5:24:12,  3.45s/it]  6%|â–Œ         | 358/6000 [20:56<5:19:18,  3.40s/it]                                                    {'loss': 0.0644, 'grad_norm': 25.63877296447754, 'learning_rate': 9.562711864406781e-06, 'epoch': 0.06}
  6%|â–Œ         | 358/6000 [20:56<5:19:18,  3.40s/it]  6%|â–Œ         | 359/6000 [21:00<5:19:40,  3.40s/it]                                                    {'loss': 0.0368, 'grad_norm': 7.5596489906311035, 'learning_rate': 9.561016949152543e-06, 'epoch': 0.06}
  6%|â–Œ         | 359/6000 [21:00<5:19:40,  3.40s/it]  6%|â–Œ         | 360/6000 [21:03<5:19:20,  3.40s/it]                                                    {'loss': 0.1716, 'grad_norm': 24.42333221435547, 'learning_rate': 9.559322033898306e-06, 'epoch': 0.06}
  6%|â–Œ         | 360/6000 [21:03<5:19:20,  3.40s/it]  6%|â–Œ         | 361/6000 [21:07<5:17:49,  3.38s/it]                                                    {'loss': 0.3286, 'grad_norm': 42.53457260131836, 'learning_rate': 9.557627118644068e-06, 'epoch': 0.06}
  6%|â–Œ         | 361/6000 [21:07<5:17:49,  3.38s/it]  6%|â–Œ         | 362/6000 [21:10<5:15:41,  3.36s/it]                                                    {'loss': 0.1275, 'grad_norm': 46.80195999145508, 'learning_rate': 9.555932203389831e-06, 'epoch': 0.06}
  6%|â–Œ         | 362/6000 [21:10<5:15:41,  3.36s/it]  6%|â–Œ         | 363/6000 [21:13<5:15:52,  3.36s/it]                                                    {'loss': 0.0171, 'grad_norm': 5.316586494445801, 'learning_rate': 9.554237288135594e-06, 'epoch': 0.06}
  6%|â–Œ         | 363/6000 [21:13<5:15:52,  3.36s/it]  6%|â–Œ         | 364/6000 [21:17<5:21:17,  3.42s/it]                                                    {'loss': 0.1034, 'grad_norm': 30.54053497314453, 'learning_rate': 9.552542372881358e-06, 'epoch': 0.06}
  6%|â–Œ         | 364/6000 [21:17<5:21:17,  3.42s/it]  6%|â–Œ         | 365/6000 [21:20<5:22:05,  3.43s/it]                                                    {'loss': 0.1223, 'grad_norm': 130.37289428710938, 'learning_rate': 9.55084745762712e-06, 'epoch': 0.06}
  6%|â–Œ         | 365/6000 [21:20<5:22:05,  3.43s/it]  6%|â–Œ         | 366/6000 [21:24<5:20:37,  3.41s/it]                                                    {'loss': 0.0193, 'grad_norm': 3.0611355304718018, 'learning_rate': 9.549152542372883e-06, 'epoch': 0.06}
  6%|â–Œ         | 366/6000 [21:24<5:20:37,  3.41s/it]  6%|â–Œ         | 367/6000 [21:27<5:20:22,  3.41s/it]                                                    {'loss': 0.067, 'grad_norm': 10.321014404296875, 'learning_rate': 9.547457627118644e-06, 'epoch': 0.06}
  6%|â–Œ         | 367/6000 [21:27<5:20:22,  3.41s/it]  6%|â–Œ         | 368/6000 [21:31<5:33:44,  3.56s/it]                                                    {'loss': 0.0621, 'grad_norm': 11.517203330993652, 'learning_rate': 9.545762711864407e-06, 'epoch': 0.06}
  6%|â–Œ         | 368/6000 [21:31<5:33:44,  3.56s/it]  6%|â–Œ         | 369/6000 [21:34<5:27:30,  3.49s/it]                                                    {'loss': 0.0585, 'grad_norm': 8.407159805297852, 'learning_rate': 9.54406779661017e-06, 'epoch': 0.06}
  6%|â–Œ         | 369/6000 [21:34<5:27:30,  3.49s/it]  6%|â–Œ         | 370/6000 [21:38<5:26:57,  3.48s/it]                                                    {'loss': 0.0074, 'grad_norm': 3.228423833847046, 'learning_rate': 9.542372881355934e-06, 'epoch': 0.06}
  6%|â–Œ         | 370/6000 [21:38<5:26:57,  3.48s/it]  6%|â–Œ         | 371/6000 [21:41<5:25:48,  3.47s/it]                                                    {'loss': 0.1043, 'grad_norm': 16.716815948486328, 'learning_rate': 9.540677966101696e-06, 'epoch': 0.06}
  6%|â–Œ         | 371/6000 [21:41<5:25:48,  3.47s/it]  6%|â–Œ         | 372/6000 [21:45<5:23:22,  3.45s/it]                                                    {'loss': 0.0155, 'grad_norm': 4.727128028869629, 'learning_rate': 9.538983050847457e-06, 'epoch': 0.06}
  6%|â–Œ         | 372/6000 [21:45<5:23:22,  3.45s/it]  6%|â–Œ         | 373/6000 [21:48<5:21:33,  3.43s/it]                                                    {'loss': 0.0084, 'grad_norm': 2.9925882816314697, 'learning_rate': 9.53728813559322e-06, 'epoch': 0.06}
  6%|â–Œ         | 373/6000 [21:48<5:21:33,  3.43s/it]  6%|â–Œ         | 374/6000 [21:51<5:22:03,  3.43s/it]                                                    {'loss': 0.3509, 'grad_norm': 37.379520416259766, 'learning_rate': 9.535593220338984e-06, 'epoch': 0.06}
  6%|â–Œ         | 374/6000 [21:51<5:22:03,  3.43s/it]  6%|â–‹         | 375/6000 [21:55<5:21:15,  3.43s/it]                                                    {'loss': 0.0513, 'grad_norm': 22.920166015625, 'learning_rate': 9.533898305084747e-06, 'epoch': 0.06}
  6%|â–‹         | 375/6000 [21:55<5:21:15,  3.43s/it]  6%|â–‹         | 376/6000 [21:58<5:18:26,  3.40s/it]                                                    {'loss': 0.0479, 'grad_norm': 20.300241470336914, 'learning_rate': 9.532203389830508e-06, 'epoch': 0.06}
  6%|â–‹         | 376/6000 [21:58<5:18:26,  3.40s/it]  6%|â–‹         | 377/6000 [22:02<5:17:30,  3.39s/it]                                                    {'loss': 0.1423, 'grad_norm': 49.70009994506836, 'learning_rate': 9.530508474576272e-06, 'epoch': 0.06}
  6%|â–‹         | 377/6000 [22:02<5:17:30,  3.39s/it]  6%|â–‹         | 378/6000 [22:05<5:20:48,  3.42s/it]                                                    {'loss': 0.0715, 'grad_norm': 6.446547508239746, 'learning_rate': 9.528813559322035e-06, 'epoch': 0.06}
  6%|â–‹         | 378/6000 [22:05<5:20:48,  3.42s/it]  6%|â–‹         | 379/6000 [22:08<5:21:18,  3.43s/it]                                                    {'loss': 0.024, 'grad_norm': 13.718389511108398, 'learning_rate': 9.527118644067798e-06, 'epoch': 0.06}
  6%|â–‹         | 379/6000 [22:08<5:21:18,  3.43s/it]  6%|â–‹         | 380/6000 [22:12<5:33:09,  3.56s/it]                                                    {'loss': 0.121, 'grad_norm': 15.321139335632324, 'learning_rate': 9.52542372881356e-06, 'epoch': 0.06}
  6%|â–‹         | 380/6000 [22:12<5:33:09,  3.56s/it]  6%|â–‹         | 381/6000 [22:16<5:29:51,  3.52s/it]                                                    {'loss': 0.0865, 'grad_norm': 24.59954833984375, 'learning_rate': 9.523728813559323e-06, 'epoch': 0.06}
  6%|â–‹         | 381/6000 [22:16<5:29:51,  3.52s/it]  6%|â–‹         | 382/6000 [22:19<5:32:07,  3.55s/it]                                                    {'loss': 0.0946, 'grad_norm': 12.924177169799805, 'learning_rate': 9.522033898305085e-06, 'epoch': 0.06}
  6%|â–‹         | 382/6000 [22:19<5:32:07,  3.55s/it]  6%|â–‹         | 383/6000 [22:23<5:28:51,  3.51s/it]                                                    {'loss': 0.0484, 'grad_norm': 9.67276382446289, 'learning_rate': 9.520338983050848e-06, 'epoch': 0.06}
  6%|â–‹         | 383/6000 [22:23<5:28:51,  3.51s/it]  6%|â–‹         | 384/6000 [22:26<5:27:03,  3.49s/it]                                                    {'loss': 0.1316, 'grad_norm': 34.638755798339844, 'learning_rate': 9.518644067796611e-06, 'epoch': 0.06}
  6%|â–‹         | 384/6000 [22:26<5:27:03,  3.49s/it]  6%|â–‹         | 385/6000 [22:30<5:34:36,  3.58s/it]                                                    {'loss': 0.0114, 'grad_norm': 5.189053058624268, 'learning_rate': 9.516949152542375e-06, 'epoch': 0.06}
  6%|â–‹         | 385/6000 [22:30<5:34:36,  3.58s/it]  6%|â–‹         | 386/6000 [22:33<5:31:10,  3.54s/it]                                                    {'loss': 0.0316, 'grad_norm': 13.604255676269531, 'learning_rate': 9.515254237288136e-06, 'epoch': 0.06}
  6%|â–‹         | 386/6000 [22:33<5:31:10,  3.54s/it]  6%|â–‹         | 387/6000 [22:37<5:41:31,  3.65s/it]                                                    {'loss': 0.0771, 'grad_norm': 19.768985748291016, 'learning_rate': 9.5135593220339e-06, 'epoch': 0.06}
  6%|â–‹         | 387/6000 [22:37<5:41:31,  3.65s/it]  6%|â–‹         | 388/6000 [22:41<5:41:22,  3.65s/it]                                                    {'loss': 0.0487, 'grad_norm': 16.154481887817383, 'learning_rate': 9.511864406779661e-06, 'epoch': 0.06}
  6%|â–‹         | 388/6000 [22:41<5:41:22,  3.65s/it]  6%|â–‹         | 389/6000 [22:44<5:32:42,  3.56s/it]                                                    {'loss': 0.041, 'grad_norm': 18.786352157592773, 'learning_rate': 9.510169491525424e-06, 'epoch': 0.06}
  6%|â–‹         | 389/6000 [22:44<5:32:42,  3.56s/it]  6%|â–‹         | 390/6000 [22:48<5:29:36,  3.53s/it]                                                    {'loss': 0.0147, 'grad_norm': 8.080248832702637, 'learning_rate': 9.508474576271188e-06, 'epoch': 0.07}
  6%|â–‹         | 390/6000 [22:48<5:29:36,  3.53s/it]  7%|â–‹         | 391/6000 [22:51<5:23:36,  3.46s/it]                                                    {'loss': 0.4197, 'grad_norm': 40.774375915527344, 'learning_rate': 9.506779661016949e-06, 'epoch': 0.07}
  7%|â–‹         | 391/6000 [22:51<5:23:36,  3.46s/it]  7%|â–‹         | 392/6000 [22:55<5:25:42,  3.48s/it]                                                    {'loss': 0.0123, 'grad_norm': 5.956827640533447, 'learning_rate': 9.505084745762712e-06, 'epoch': 0.07}
  7%|â–‹         | 392/6000 [22:55<5:25:42,  3.48s/it]  7%|â–‹         | 393/6000 [22:58<5:25:21,  3.48s/it]                                                    {'loss': 0.0195, 'grad_norm': 5.426395893096924, 'learning_rate': 9.503389830508476e-06, 'epoch': 0.07}
  7%|â–‹         | 393/6000 [22:58<5:25:21,  3.48s/it]  7%|â–‹         | 394/6000 [23:02<5:26:21,  3.49s/it]                                                    {'loss': 0.0604, 'grad_norm': 17.38536262512207, 'learning_rate': 9.501694915254239e-06, 'epoch': 0.07}
  7%|â–‹         | 394/6000 [23:02<5:26:21,  3.49s/it]  7%|â–‹         | 395/6000 [23:05<5:23:24,  3.46s/it]                                                    {'loss': 0.0646, 'grad_norm': 24.404142379760742, 'learning_rate': 9.5e-06, 'epoch': 0.07}
  7%|â–‹         | 395/6000 [23:05<5:23:24,  3.46s/it]  7%|â–‹         | 396/6000 [23:08<5:21:32,  3.44s/it]                                                    {'loss': 0.0281, 'grad_norm': 4.919869422912598, 'learning_rate': 9.498305084745764e-06, 'epoch': 0.07}
  7%|â–‹         | 396/6000 [23:08<5:21:32,  3.44s/it]  7%|â–‹         | 397/6000 [23:12<5:35:37,  3.59s/it]                                                    {'loss': 0.0988, 'grad_norm': 8.995336532592773, 'learning_rate': 9.496610169491525e-06, 'epoch': 0.07}
  7%|â–‹         | 397/6000 [23:12<5:35:37,  3.59s/it]  7%|â–‹         | 398/6000 [23:16<5:29:39,  3.53s/it]                                                    {'loss': 0.0921, 'grad_norm': 15.23881721496582, 'learning_rate': 9.494915254237289e-06, 'epoch': 0.07}
  7%|â–‹         | 398/6000 [23:16<5:29:39,  3.53s/it]  7%|â–‹         | 399/6000 [23:19<5:28:21,  3.52s/it]                                                    {'loss': 0.1549, 'grad_norm': 26.280792236328125, 'learning_rate': 9.493220338983052e-06, 'epoch': 0.07}
  7%|â–‹         | 399/6000 [23:19<5:28:21,  3.52s/it]  7%|â–‹         | 400/6000 [23:23<5:25:42,  3.49s/it]                                                    {'loss': 0.008, 'grad_norm': 1.7676002979278564, 'learning_rate': 9.491525423728815e-06, 'epoch': 0.07}
  7%|â–‹         | 400/6000 [23:23<5:25:42,  3.49s/it][2025-11-06 23:14:32,681] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400
[2025-11-06 23:14:32,700] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:14:33,404] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  7%|â–‹         | 401/6000 [23:28<6:24:33,  4.12s/it]                                                    {'loss': 0.0456, 'grad_norm': 4.562441349029541, 'learning_rate': 9.489830508474577e-06, 'epoch': 0.07}
  7%|â–‹         | 401/6000 [23:28<6:24:33,  4.12s/it]  7%|â–‹         | 402/6000 [23:32<6:01:18,  3.87s/it]                                                    {'loss': 0.1206, 'grad_norm': 22.653657913208008, 'learning_rate': 9.48813559322034e-06, 'epoch': 0.07}
  7%|â–‹         | 402/6000 [23:32<6:01:18,  3.87s/it]  7%|â–‹         | 403/6000 [23:35<5:47:39,  3.73s/it]                                                    {'loss': 0.2487, 'grad_norm': 24.54006576538086, 'learning_rate': 9.486440677966102e-06, 'epoch': 0.07}
  7%|â–‹         | 403/6000 [23:35<5:47:39,  3.73s/it]  7%|â–‹         | 404/6000 [23:39<5:42:58,  3.68s/it]                                                    {'loss': 0.2227, 'grad_norm': 19.32412338256836, 'learning_rate': 9.484745762711865e-06, 'epoch': 0.07}
  7%|â–‹         | 404/6000 [23:39<5:42:58,  3.68s/it]  7%|â–‹         | 405/6000 [23:42<5:36:31,  3.61s/it]                                                    {'loss': 0.1343, 'grad_norm': 22.968414306640625, 'learning_rate': 9.483050847457628e-06, 'epoch': 0.07}
  7%|â–‹         | 405/6000 [23:42<5:36:31,  3.61s/it]  7%|â–‹         | 406/6000 [23:45<5:32:33,  3.57s/it]                                                    {'loss': 0.0021, 'grad_norm': 0.7367407083511353, 'learning_rate': 9.481355932203391e-06, 'epoch': 0.07}
  7%|â–‹         | 406/6000 [23:45<5:32:33,  3.57s/it]  7%|â–‹         | 407/6000 [23:49<5:28:48,  3.53s/it]                                                    {'loss': 0.0617, 'grad_norm': 13.537630081176758, 'learning_rate': 9.479661016949153e-06, 'epoch': 0.07}
  7%|â–‹         | 407/6000 [23:49<5:28:48,  3.53s/it]  7%|â–‹         | 408/6000 [23:53<5:46:42,  3.72s/it]                                                    {'loss': 0.0514, 'grad_norm': 11.577038764953613, 'learning_rate': 9.477966101694916e-06, 'epoch': 0.07}
  7%|â–‹         | 408/6000 [23:53<5:46:42,  3.72s/it]  7%|â–‹         | 409/6000 [23:57<5:41:27,  3.66s/it]                                                    {'loss': 0.0878, 'grad_norm': 21.51140594482422, 'learning_rate': 9.476271186440678e-06, 'epoch': 0.07}
  7%|â–‹         | 409/6000 [23:57<5:41:27,  3.66s/it]  7%|â–‹         | 410/6000 [24:00<5:34:10,  3.59s/it]                                                    {'loss': 0.1467, 'grad_norm': 25.88433265686035, 'learning_rate': 9.474576271186441e-06, 'epoch': 0.07}
  7%|â–‹         | 410/6000 [24:00<5:34:10,  3.59s/it]  7%|â–‹         | 411/6000 [24:04<5:59:14,  3.86s/it]                                                    {'loss': 0.0113, 'grad_norm': 1.963363766670227, 'learning_rate': 9.472881355932204e-06, 'epoch': 0.07}
  7%|â–‹         | 411/6000 [24:04<5:59:14,  3.86s/it]  7%|â–‹         | 412/6000 [24:08<5:44:24,  3.70s/it]                                                    {'loss': 0.0942, 'grad_norm': 9.0857515335083, 'learning_rate': 9.471186440677966e-06, 'epoch': 0.07}
  7%|â–‹         | 412/6000 [24:08<5:44:24,  3.70s/it]  7%|â–‹         | 413/6000 [24:11<5:41:15,  3.66s/it]                                                    {'loss': 0.3168, 'grad_norm': 28.42852783203125, 'learning_rate': 9.46949152542373e-06, 'epoch': 0.07}
  7%|â–‹         | 413/6000 [24:11<5:41:15,  3.66s/it]  7%|â–‹         | 414/6000 [24:15<5:31:00,  3.56s/it]                                                    {'loss': 0.1275, 'grad_norm': 23.860918045043945, 'learning_rate': 9.467796610169493e-06, 'epoch': 0.07}
  7%|â–‹         | 414/6000 [24:15<5:31:00,  3.56s/it]  7%|â–‹         | 415/6000 [24:18<5:32:01,  3.57s/it]                                                    {'loss': 0.0501, 'grad_norm': 11.648268699645996, 'learning_rate': 9.466101694915256e-06, 'epoch': 0.07}
  7%|â–‹         | 415/6000 [24:18<5:32:01,  3.57s/it]  7%|â–‹         | 416/6000 [24:22<5:29:33,  3.54s/it]                                                    {'loss': 0.0685, 'grad_norm': 19.4387149810791, 'learning_rate': 9.464406779661017e-06, 'epoch': 0.07}
  7%|â–‹         | 416/6000 [24:22<5:29:33,  3.54s/it]  7%|â–‹         | 417/6000 [24:25<5:27:52,  3.52s/it]                                                    {'loss': 0.0072, 'grad_norm': 3.0883939266204834, 'learning_rate': 9.46271186440678e-06, 'epoch': 0.07}
  7%|â–‹         | 417/6000 [24:25<5:27:52,  3.52s/it]  7%|â–‹         | 418/6000 [24:29<5:25:31,  3.50s/it]                                                    {'loss': 0.0739, 'grad_norm': 13.973494529724121, 'learning_rate': 9.461016949152542e-06, 'epoch': 0.07}
  7%|â–‹         | 418/6000 [24:29<5:25:31,  3.50s/it]  7%|â–‹         | 419/6000 [24:33<5:36:43,  3.62s/it]                                                    {'loss': 0.0632, 'grad_norm': 9.212364196777344, 'learning_rate': 9.459322033898306e-06, 'epoch': 0.07}
  7%|â–‹         | 419/6000 [24:33<5:36:43,  3.62s/it]  7%|â–‹         | 420/6000 [24:36<5:32:02,  3.57s/it]                                                    {'loss': 0.0056, 'grad_norm': 2.95931339263916, 'learning_rate': 9.457627118644069e-06, 'epoch': 0.07}
  7%|â–‹         | 420/6000 [24:36<5:32:02,  3.57s/it]  7%|â–‹         | 421/6000 [24:40<5:28:53,  3.54s/it]                                                    {'loss': 0.2358, 'grad_norm': 35.42975616455078, 'learning_rate': 9.455932203389832e-06, 'epoch': 0.07}
  7%|â–‹         | 421/6000 [24:40<5:28:53,  3.54s/it]  7%|â–‹         | 422/6000 [24:43<5:24:13,  3.49s/it]                                                    {'loss': 0.0688, 'grad_norm': 17.647125244140625, 'learning_rate': 9.454237288135594e-06, 'epoch': 0.07}
  7%|â–‹         | 422/6000 [24:43<5:24:13,  3.49s/it]  7%|â–‹         | 423/6000 [24:46<5:22:32,  3.47s/it]                                                    {'loss': 0.0788, 'grad_norm': 19.57874298095703, 'learning_rate': 9.452542372881357e-06, 'epoch': 0.07}
  7%|â–‹         | 423/6000 [24:46<5:22:32,  3.47s/it]  7%|â–‹         | 424/6000 [24:50<5:20:49,  3.45s/it]                                                    {'loss': 0.0056, 'grad_norm': 1.601007103919983, 'learning_rate': 9.450847457627119e-06, 'epoch': 0.07}
  7%|â–‹         | 424/6000 [24:50<5:20:49,  3.45s/it]  7%|â–‹         | 425/6000 [24:53<5:19:23,  3.44s/it]                                                    {'loss': 0.0878, 'grad_norm': 25.962772369384766, 'learning_rate': 9.449152542372882e-06, 'epoch': 0.07}
  7%|â–‹         | 425/6000 [24:53<5:19:23,  3.44s/it]  7%|â–‹         | 426/6000 [24:57<5:20:00,  3.44s/it]                                                    {'loss': 0.0475, 'grad_norm': 10.51805591583252, 'learning_rate': 9.447457627118645e-06, 'epoch': 0.07}
  7%|â–‹         | 426/6000 [24:57<5:20:00,  3.44s/it]  7%|â–‹         | 427/6000 [25:00<5:20:59,  3.46s/it]                                                    {'loss': 0.1874, 'grad_norm': 195.87364196777344, 'learning_rate': 9.445762711864408e-06, 'epoch': 0.07}
  7%|â–‹         | 427/6000 [25:00<5:20:59,  3.46s/it]  7%|â–‹         | 428/6000 [25:03<5:19:19,  3.44s/it]                                                    {'loss': 0.0204, 'grad_norm': 23.918230056762695, 'learning_rate': 9.44406779661017e-06, 'epoch': 0.07}
  7%|â–‹         | 428/6000 [25:03<5:19:19,  3.44s/it]  7%|â–‹         | 429/6000 [25:07<5:17:18,  3.42s/it]                                                    {'loss': 0.0686, 'grad_norm': 18.55255126953125, 'learning_rate': 9.442372881355933e-06, 'epoch': 0.07}
  7%|â–‹         | 429/6000 [25:07<5:17:18,  3.42s/it]  7%|â–‹         | 430/6000 [25:10<5:16:33,  3.41s/it]                                                    {'loss': 0.2939, 'grad_norm': 22.25762176513672, 'learning_rate': 9.440677966101696e-06, 'epoch': 0.07}
  7%|â–‹         | 430/6000 [25:10<5:16:33,  3.41s/it]  7%|â–‹         | 431/6000 [25:14<5:16:07,  3.41s/it]                                                    {'loss': 0.1359, 'grad_norm': 17.32027244567871, 'learning_rate': 9.43898305084746e-06, 'epoch': 0.07}
  7%|â–‹         | 431/6000 [25:14<5:16:07,  3.41s/it]  7%|â–‹         | 432/6000 [25:17<5:16:38,  3.41s/it]                                                    {'loss': 0.0897, 'grad_norm': 13.04502010345459, 'learning_rate': 9.437288135593221e-06, 'epoch': 0.07}
  7%|â–‹         | 432/6000 [25:17<5:16:38,  3.41s/it]  7%|â–‹         | 433/6000 [25:20<5:14:42,  3.39s/it]                                                    {'loss': 0.0108, 'grad_norm': 4.56439208984375, 'learning_rate': 9.435593220338983e-06, 'epoch': 0.07}
  7%|â–‹         | 433/6000 [25:20<5:14:42,  3.39s/it]  7%|â–‹         | 434/6000 [25:24<5:14:01,  3.39s/it]                                                    {'loss': 0.0106, 'grad_norm': 3.752652883529663, 'learning_rate': 9.433898305084746e-06, 'epoch': 0.07}
  7%|â–‹         | 434/6000 [25:24<5:14:01,  3.39s/it]  7%|â–‹         | 435/6000 [25:27<5:15:29,  3.40s/it]                                                    {'loss': 0.0606, 'grad_norm': 19.50658416748047, 'learning_rate': 9.43220338983051e-06, 'epoch': 0.07}
  7%|â–‹         | 435/6000 [25:27<5:15:29,  3.40s/it]  7%|â–‹         | 436/6000 [25:31<5:17:21,  3.42s/it]                                                    {'loss': 0.0137, 'grad_norm': 4.692798614501953, 'learning_rate': 9.430508474576273e-06, 'epoch': 0.07}
  7%|â–‹         | 436/6000 [25:31<5:17:21,  3.42s/it]  7%|â–‹         | 437/6000 [25:34<5:18:28,  3.43s/it]                                                    {'loss': 0.1045, 'grad_norm': 12.645783424377441, 'learning_rate': 9.428813559322034e-06, 'epoch': 0.07}
  7%|â–‹         | 437/6000 [25:34<5:18:28,  3.43s/it]  7%|â–‹         | 438/6000 [25:38<5:21:24,  3.47s/it]                                                    {'loss': 0.0541, 'grad_norm': 11.603241920471191, 'learning_rate': 9.427118644067798e-06, 'epoch': 0.07}
  7%|â–‹         | 438/6000 [25:38<5:21:24,  3.47s/it]  7%|â–‹         | 439/6000 [25:41<5:19:07,  3.44s/it]                                                    {'loss': 0.0154, 'grad_norm': 5.475751876831055, 'learning_rate': 9.425423728813559e-06, 'epoch': 0.07}
  7%|â–‹         | 439/6000 [25:41<5:19:07,  3.44s/it]  7%|â–‹         | 440/6000 [25:45<5:20:16,  3.46s/it]                                                    {'loss': 0.0185, 'grad_norm': 5.104204177856445, 'learning_rate': 9.423728813559322e-06, 'epoch': 0.07}
  7%|â–‹         | 440/6000 [25:45<5:20:16,  3.46s/it]  7%|â–‹         | 441/6000 [25:48<5:26:45,  3.53s/it]                                                    {'loss': 0.0096, 'grad_norm': 2.746568202972412, 'learning_rate': 9.422033898305086e-06, 'epoch': 0.07}
  7%|â–‹         | 441/6000 [25:48<5:26:45,  3.53s/it]  7%|â–‹         | 442/6000 [25:52<5:32:03,  3.58s/it]                                                    {'loss': 0.1604, 'grad_norm': 35.16243362426758, 'learning_rate': 9.420338983050849e-06, 'epoch': 0.07}
  7%|â–‹         | 442/6000 [25:52<5:32:03,  3.58s/it]  7%|â–‹         | 443/6000 [25:55<5:27:44,  3.54s/it]                                                    {'loss': 0.0242, 'grad_norm': 5.839653491973877, 'learning_rate': 9.41864406779661e-06, 'epoch': 0.07}
  7%|â–‹         | 443/6000 [25:55<5:27:44,  3.54s/it]  7%|â–‹         | 444/6000 [25:59<5:23:13,  3.49s/it]                                                    {'loss': 0.0342, 'grad_norm': 13.559094429016113, 'learning_rate': 9.416949152542374e-06, 'epoch': 0.07}
  7%|â–‹         | 444/6000 [25:59<5:23:13,  3.49s/it]  7%|â–‹         | 445/6000 [26:02<5:23:58,  3.50s/it]                                                    {'loss': 0.1199, 'grad_norm': 19.06214714050293, 'learning_rate': 9.415254237288135e-06, 'epoch': 0.07}
  7%|â–‹         | 445/6000 [26:02<5:23:58,  3.50s/it]  7%|â–‹         | 446/6000 [26:06<5:20:38,  3.46s/it]                                                    {'loss': 0.0176, 'grad_norm': 6.944109916687012, 'learning_rate': 9.413559322033899e-06, 'epoch': 0.07}
  7%|â–‹         | 446/6000 [26:06<5:20:38,  3.46s/it]  7%|â–‹         | 447/6000 [26:09<5:20:46,  3.47s/it]                                                    {'loss': 0.0461, 'grad_norm': 13.751325607299805, 'learning_rate': 9.411864406779662e-06, 'epoch': 0.07}
  7%|â–‹         | 447/6000 [26:09<5:20:46,  3.47s/it]  7%|â–‹         | 448/6000 [26:13<5:19:48,  3.46s/it]                                                    {'loss': 0.0235, 'grad_norm': 6.808838367462158, 'learning_rate': 9.410169491525425e-06, 'epoch': 0.07}
  7%|â–‹         | 448/6000 [26:13<5:19:48,  3.46s/it]  7%|â–‹         | 449/6000 [26:16<5:20:39,  3.47s/it]                                                    {'loss': 0.0346, 'grad_norm': 14.999314308166504, 'learning_rate': 9.408474576271187e-06, 'epoch': 0.07}
  7%|â–‹         | 449/6000 [26:16<5:20:39,  3.47s/it]  8%|â–Š         | 450/6000 [26:20<5:23:57,  3.50s/it]                                                    {'loss': 0.048, 'grad_norm': 13.695820808410645, 'learning_rate': 9.40677966101695e-06, 'epoch': 0.07}
  8%|â–Š         | 450/6000 [26:20<5:23:57,  3.50s/it]  8%|â–Š         | 451/6000 [26:23<5:23:11,  3.49s/it]                                                    {'loss': 0.0241, 'grad_norm': 11.4474458694458, 'learning_rate': 9.405084745762713e-06, 'epoch': 0.08}
  8%|â–Š         | 451/6000 [26:23<5:23:11,  3.49s/it]  8%|â–Š         | 452/6000 [26:27<5:31:13,  3.58s/it]                                                    {'loss': 0.1269, 'grad_norm': 14.00251293182373, 'learning_rate': 9.403389830508477e-06, 'epoch': 0.08}
  8%|â–Š         | 452/6000 [26:27<5:31:13,  3.58s/it]  8%|â–Š         | 453/6000 [26:30<5:26:55,  3.54s/it]                                                    {'loss': 0.1075, 'grad_norm': 16.794021606445312, 'learning_rate': 9.401694915254238e-06, 'epoch': 0.08}
  8%|â–Š         | 453/6000 [26:30<5:26:55,  3.54s/it]  8%|â–Š         | 454/6000 [26:34<5:24:00,  3.51s/it]                                                    {'loss': 0.1277, 'grad_norm': 17.76327896118164, 'learning_rate': 9.4e-06, 'epoch': 0.08}
  8%|â–Š         | 454/6000 [26:34<5:24:00,  3.51s/it]  8%|â–Š         | 455/6000 [26:37<5:19:37,  3.46s/it]                                                    {'loss': 0.0322, 'grad_norm': 5.523698329925537, 'learning_rate': 9.398305084745763e-06, 'epoch': 0.08}
  8%|â–Š         | 455/6000 [26:37<5:19:37,  3.46s/it]  8%|â–Š         | 456/6000 [26:41<5:19:31,  3.46s/it]                                                    {'loss': 0.3324, 'grad_norm': 30.41819953918457, 'learning_rate': 9.396610169491526e-06, 'epoch': 0.08}
  8%|â–Š         | 456/6000 [26:41<5:19:31,  3.46s/it]  8%|â–Š         | 457/6000 [26:44<5:15:52,  3.42s/it]                                                    {'loss': 0.0409, 'grad_norm': 7.131831169128418, 'learning_rate': 9.39491525423729e-06, 'epoch': 0.08}
  8%|â–Š         | 457/6000 [26:44<5:15:52,  3.42s/it]  8%|â–Š         | 458/6000 [26:47<5:13:48,  3.40s/it]                                                    {'loss': 0.039, 'grad_norm': 12.070971488952637, 'learning_rate': 9.393220338983051e-06, 'epoch': 0.08}
  8%|â–Š         | 458/6000 [26:47<5:13:48,  3.40s/it]  8%|â–Š         | 459/6000 [26:51<5:21:16,  3.48s/it]                                                    {'loss': 0.1945, 'grad_norm': 20.942487716674805, 'learning_rate': 9.391525423728814e-06, 'epoch': 0.08}
  8%|â–Š         | 459/6000 [26:51<5:21:16,  3.48s/it]  8%|â–Š         | 460/6000 [26:54<5:19:04,  3.46s/it]                                                    {'loss': 0.0178, 'grad_norm': 4.041075229644775, 'learning_rate': 9.389830508474576e-06, 'epoch': 0.08}
  8%|â–Š         | 460/6000 [26:54<5:19:04,  3.46s/it]  8%|â–Š         | 461/6000 [26:58<5:16:55,  3.43s/it]                                                    {'loss': 0.0402, 'grad_norm': 4.68527889251709, 'learning_rate': 9.38813559322034e-06, 'epoch': 0.08}
  8%|â–Š         | 461/6000 [26:58<5:16:55,  3.43s/it]  8%|â–Š         | 462/6000 [27:01<5:12:57,  3.39s/it]                                                    {'loss': 0.0453, 'grad_norm': 4.175189018249512, 'learning_rate': 9.386440677966103e-06, 'epoch': 0.08}
  8%|â–Š         | 462/6000 [27:01<5:12:57,  3.39s/it]  8%|â–Š         | 463/6000 [27:04<5:14:11,  3.40s/it]                                                    {'loss': 0.1117, 'grad_norm': 21.684545516967773, 'learning_rate': 9.384745762711866e-06, 'epoch': 0.08}
  8%|â–Š         | 463/6000 [27:04<5:14:11,  3.40s/it]  8%|â–Š         | 464/6000 [27:08<5:10:52,  3.37s/it]                                                    {'loss': 0.1793, 'grad_norm': 29.21942710876465, 'learning_rate': 9.383050847457627e-06, 'epoch': 0.08}
  8%|â–Š         | 464/6000 [27:08<5:10:52,  3.37s/it]  8%|â–Š         | 465/6000 [27:11<5:16:45,  3.43s/it]                                                    {'loss': 0.251, 'grad_norm': 33.81131362915039, 'learning_rate': 9.38135593220339e-06, 'epoch': 0.08}
  8%|â–Š         | 465/6000 [27:11<5:16:45,  3.43s/it]  8%|â–Š         | 466/6000 [27:15<5:14:55,  3.41s/it]                                                    {'loss': 0.0712, 'grad_norm': 9.422534942626953, 'learning_rate': 9.379661016949152e-06, 'epoch': 0.08}
  8%|â–Š         | 466/6000 [27:15<5:14:55,  3.41s/it]  8%|â–Š         | 467/6000 [27:18<5:15:45,  3.42s/it]                                                    {'loss': 0.1262, 'grad_norm': 17.927461624145508, 'learning_rate': 9.377966101694916e-06, 'epoch': 0.08}
  8%|â–Š         | 467/6000 [27:18<5:15:45,  3.42s/it]  8%|â–Š         | 468/6000 [27:22<5:17:32,  3.44s/it]                                                    {'loss': 0.0847, 'grad_norm': 13.068260192871094, 'learning_rate': 9.376271186440679e-06, 'epoch': 0.08}
  8%|â–Š         | 468/6000 [27:22<5:17:32,  3.44s/it]  8%|â–Š         | 469/6000 [27:25<5:15:15,  3.42s/it]                                                    {'loss': 0.3497, 'grad_norm': 20.812122344970703, 'learning_rate': 9.374576271186442e-06, 'epoch': 0.08}
  8%|â–Š         | 469/6000 [27:25<5:15:15,  3.42s/it]  8%|â–Š         | 470/6000 [27:28<5:13:54,  3.41s/it]                                                    {'loss': 0.0268, 'grad_norm': 6.744152069091797, 'learning_rate': 9.372881355932204e-06, 'epoch': 0.08}
  8%|â–Š         | 470/6000 [27:28<5:13:54,  3.41s/it]  8%|â–Š         | 471/6000 [27:32<5:11:01,  3.38s/it]                                                    {'loss': 0.3286, 'grad_norm': 24.9423770904541, 'learning_rate': 9.371186440677967e-06, 'epoch': 0.08}
  8%|â–Š         | 471/6000 [27:32<5:11:01,  3.38s/it]  8%|â–Š         | 472/6000 [27:35<5:11:30,  3.38s/it]                                                    {'loss': 0.2366, 'grad_norm': 14.19710922241211, 'learning_rate': 9.36949152542373e-06, 'epoch': 0.08}
  8%|â–Š         | 472/6000 [27:35<5:11:30,  3.38s/it]  8%|â–Š         | 473/6000 [27:39<5:14:05,  3.41s/it]                                                    {'loss': 0.0989, 'grad_norm': 12.988740921020508, 'learning_rate': 9.367796610169494e-06, 'epoch': 0.08}
  8%|â–Š         | 473/6000 [27:39<5:14:05,  3.41s/it]  8%|â–Š         | 474/6000 [27:42<5:10:43,  3.37s/it]                                                    {'loss': 0.0331, 'grad_norm': 4.921629905700684, 'learning_rate': 9.366101694915255e-06, 'epoch': 0.08}
  8%|â–Š         | 474/6000 [27:42<5:10:43,  3.37s/it]  8%|â–Š         | 475/6000 [27:45<5:11:33,  3.38s/it]                                                    {'loss': 0.0896, 'grad_norm': 8.254351615905762, 'learning_rate': 9.364406779661017e-06, 'epoch': 0.08}
  8%|â–Š         | 475/6000 [27:45<5:11:33,  3.38s/it]  8%|â–Š         | 476/6000 [27:49<5:11:05,  3.38s/it]                                                    {'loss': 0.0321, 'grad_norm': 6.176269054412842, 'learning_rate': 9.36271186440678e-06, 'epoch': 0.08}
  8%|â–Š         | 476/6000 [27:49<5:11:05,  3.38s/it]  8%|â–Š         | 477/6000 [27:52<5:10:21,  3.37s/it]                                                    {'loss': 0.0219, 'grad_norm': 6.433053970336914, 'learning_rate': 9.361016949152543e-06, 'epoch': 0.08}
  8%|â–Š         | 477/6000 [27:52<5:10:21,  3.37s/it]  8%|â–Š         | 478/6000 [27:55<5:11:20,  3.38s/it]                                                    {'loss': 0.0437, 'grad_norm': 12.685532569885254, 'learning_rate': 9.359322033898306e-06, 'epoch': 0.08}
  8%|â–Š         | 478/6000 [27:55<5:11:20,  3.38s/it]  8%|â–Š         | 479/6000 [27:59<5:12:28,  3.40s/it]                                                    {'loss': 0.0715, 'grad_norm': 15.289322853088379, 'learning_rate': 9.357627118644068e-06, 'epoch': 0.08}
  8%|â–Š         | 479/6000 [27:59<5:12:28,  3.40s/it]  8%|â–Š         | 480/6000 [28:02<5:09:31,  3.36s/it]                                                    {'loss': 0.044, 'grad_norm': 8.810796737670898, 'learning_rate': 9.355932203389831e-06, 'epoch': 0.08}
  8%|â–Š         | 480/6000 [28:02<5:09:31,  3.36s/it]  8%|â–Š         | 481/6000 [28:06<5:15:13,  3.43s/it]                                                    {'loss': 0.0079, 'grad_norm': 2.5818026065826416, 'learning_rate': 9.354237288135593e-06, 'epoch': 0.08}
  8%|â–Š         | 481/6000 [28:06<5:15:13,  3.43s/it]  8%|â–Š         | 482/6000 [28:09<5:14:49,  3.42s/it]                                                    {'loss': 0.0156, 'grad_norm': 3.5324270725250244, 'learning_rate': 9.352542372881356e-06, 'epoch': 0.08}
  8%|â–Š         | 482/6000 [28:09<5:14:49,  3.42s/it]  8%|â–Š         | 483/6000 [28:12<5:13:46,  3.41s/it]                                                    {'loss': 0.0945, 'grad_norm': 19.2861270904541, 'learning_rate': 9.35084745762712e-06, 'epoch': 0.08}
  8%|â–Š         | 483/6000 [28:12<5:13:46,  3.41s/it]  8%|â–Š         | 484/6000 [28:16<5:18:46,  3.47s/it]                                                    {'loss': 0.0205, 'grad_norm': 10.281743049621582, 'learning_rate': 9.349152542372883e-06, 'epoch': 0.08}
  8%|â–Š         | 484/6000 [28:16<5:18:46,  3.47s/it]  8%|â–Š         | 485/6000 [28:20<5:32:12,  3.61s/it]                                                    {'loss': 0.0254, 'grad_norm': 6.164140701293945, 'learning_rate': 9.347457627118644e-06, 'epoch': 0.08}
  8%|â–Š         | 485/6000 [28:20<5:32:12,  3.61s/it]  8%|â–Š         | 486/6000 [28:23<5:24:28,  3.53s/it]                                                    {'loss': 0.0054, 'grad_norm': 1.9681295156478882, 'learning_rate': 9.345762711864408e-06, 'epoch': 0.08}
  8%|â–Š         | 486/6000 [28:23<5:24:28,  3.53s/it]  8%|â–Š         | 487/6000 [28:27<5:25:48,  3.55s/it]                                                    {'loss': 0.2885, 'grad_norm': 15.497932434082031, 'learning_rate': 9.344067796610171e-06, 'epoch': 0.08}
  8%|â–Š         | 487/6000 [28:27<5:25:48,  3.55s/it]  8%|â–Š         | 488/6000 [28:31<5:28:54,  3.58s/it]                                                    {'loss': 0.3881, 'grad_norm': 27.956024169921875, 'learning_rate': 9.342372881355934e-06, 'epoch': 0.08}
  8%|â–Š         | 488/6000 [28:31<5:28:54,  3.58s/it]  8%|â–Š         | 489/6000 [28:34<5:27:22,  3.56s/it]                                                    {'loss': 0.1404, 'grad_norm': 20.928396224975586, 'learning_rate': 9.340677966101696e-06, 'epoch': 0.08}
  8%|â–Š         | 489/6000 [28:34<5:27:22,  3.56s/it]  8%|â–Š         | 490/6000 [28:38<5:24:55,  3.54s/it]                                                    {'loss': 0.1246, 'grad_norm': 16.648189544677734, 'learning_rate': 9.338983050847459e-06, 'epoch': 0.08}
  8%|â–Š         | 490/6000 [28:38<5:24:55,  3.54s/it]  8%|â–Š         | 491/6000 [28:41<5:25:19,  3.54s/it]                                                    {'loss': 0.2063, 'grad_norm': 23.78084945678711, 'learning_rate': 9.33728813559322e-06, 'epoch': 0.08}
  8%|â–Š         | 491/6000 [28:41<5:25:19,  3.54s/it]  8%|â–Š         | 492/6000 [28:45<5:21:52,  3.51s/it]                                                    {'loss': 0.0471, 'grad_norm': 7.286249160766602, 'learning_rate': 9.335593220338984e-06, 'epoch': 0.08}
  8%|â–Š         | 492/6000 [28:45<5:21:52,  3.51s/it]  8%|â–Š         | 493/6000 [28:48<5:21:56,  3.51s/it]                                                    {'loss': 0.1115, 'grad_norm': 17.093549728393555, 'learning_rate': 9.333898305084747e-06, 'epoch': 0.08}
  8%|â–Š         | 493/6000 [28:48<5:21:56,  3.51s/it]  8%|â–Š         | 494/6000 [28:52<5:24:36,  3.54s/it]                                                    {'loss': 0.0727, 'grad_norm': 19.175642013549805, 'learning_rate': 9.33220338983051e-06, 'epoch': 0.08}
  8%|â–Š         | 494/6000 [28:52<5:24:36,  3.54s/it]  8%|â–Š         | 495/6000 [28:55<5:26:11,  3.56s/it]                                                    {'loss': 0.1643, 'grad_norm': 20.387847900390625, 'learning_rate': 9.330508474576272e-06, 'epoch': 0.08}
  8%|â–Š         | 495/6000 [28:55<5:26:11,  3.56s/it]  8%|â–Š         | 496/6000 [28:59<5:20:45,  3.50s/it]                                                    {'loss': 0.0136, 'grad_norm': 4.664308547973633, 'learning_rate': 9.328813559322034e-06, 'epoch': 0.08}
  8%|â–Š         | 496/6000 [28:59<5:20:45,  3.50s/it]  8%|â–Š         | 497/6000 [29:02<5:16:01,  3.45s/it]                                                    {'loss': 0.005, 'grad_norm': 1.4650484323501587, 'learning_rate': 9.327118644067797e-06, 'epoch': 0.08}
  8%|â–Š         | 497/6000 [29:02<5:16:01,  3.45s/it]  8%|â–Š         | 498/6000 [29:05<5:13:58,  3.42s/it]                                                    {'loss': 0.0918, 'grad_norm': 14.779805183410645, 'learning_rate': 9.32542372881356e-06, 'epoch': 0.08}
  8%|â–Š         | 498/6000 [29:05<5:13:58,  3.42s/it]  8%|â–Š         | 499/6000 [29:09<5:12:52,  3.41s/it]                                                    {'loss': 0.0714, 'grad_norm': 9.208168983459473, 'learning_rate': 9.323728813559323e-06, 'epoch': 0.08}
  8%|â–Š         | 499/6000 [29:09<5:12:52,  3.41s/it]  8%|â–Š         | 500/6000 [29:12<5:12:51,  3.41s/it]                                                    {'loss': 0.0831, 'grad_norm': 7.466088771820068, 'learning_rate': 9.322033898305085e-06, 'epoch': 0.08}
  8%|â–Š         | 500/6000 [29:12<5:12:51,  3.41s/it][2025-11-06 23:20:22,120] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500
[2025-11-06 23:20:22,140] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:20:22,851] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 501/6000 [29:18<6:14:23,  4.09s/it]                                                    {'loss': 0.0873, 'grad_norm': 11.718362808227539, 'learning_rate': 9.320338983050848e-06, 'epoch': 0.08}
  8%|â–Š         | 501/6000 [29:18<6:14:23,  4.09s/it]  8%|â–Š         | 502/6000 [29:21<6:01:50,  3.95s/it]                                                    {'loss': 0.058, 'grad_norm': 12.230234146118164, 'learning_rate': 9.31864406779661e-06, 'epoch': 0.08}
  8%|â–Š         | 502/6000 [29:21<6:01:50,  3.95s/it]  8%|â–Š         | 503/6000 [29:25<5:45:26,  3.77s/it]                                                    {'loss': 0.0404, 'grad_norm': 11.307097434997559, 'learning_rate': 9.316949152542373e-06, 'epoch': 0.08}
  8%|â–Š         | 503/6000 [29:25<5:45:26,  3.77s/it]  8%|â–Š         | 504/6000 [29:28<5:33:44,  3.64s/it]                                                    {'loss': 0.0291, 'grad_norm': 4.119085788726807, 'learning_rate': 9.315254237288136e-06, 'epoch': 0.08}
  8%|â–Š         | 504/6000 [29:28<5:33:44,  3.64s/it]  8%|â–Š         | 505/6000 [29:31<5:26:18,  3.56s/it]                                                    {'loss': 0.0418, 'grad_norm': 10.489651679992676, 'learning_rate': 9.3135593220339e-06, 'epoch': 0.08}
  8%|â–Š         | 505/6000 [29:31<5:26:18,  3.56s/it]  8%|â–Š         | 506/6000 [29:35<5:32:07,  3.63s/it]                                                    {'loss': 0.1077, 'grad_norm': 19.838647842407227, 'learning_rate': 9.311864406779661e-06, 'epoch': 0.08}
  8%|â–Š         | 506/6000 [29:35<5:32:07,  3.63s/it]  8%|â–Š         | 507/6000 [29:39<5:28:20,  3.59s/it]                                                    {'loss': 0.1123, 'grad_norm': 17.27382469177246, 'learning_rate': 9.310169491525424e-06, 'epoch': 0.08}
  8%|â–Š         | 507/6000 [29:39<5:28:20,  3.59s/it]  8%|â–Š         | 508/6000 [29:42<5:20:16,  3.50s/it]                                                    {'loss': 0.0665, 'grad_norm': 13.72983169555664, 'learning_rate': 9.308474576271188e-06, 'epoch': 0.08}
  8%|â–Š         | 508/6000 [29:42<5:20:16,  3.50s/it]  8%|â–Š         | 509/6000 [29:45<5:14:23,  3.44s/it]                                                    {'loss': 0.0461, 'grad_norm': 6.543953895568848, 'learning_rate': 9.306779661016951e-06, 'epoch': 0.08}
  8%|â–Š         | 509/6000 [29:45<5:14:23,  3.44s/it]  8%|â–Š         | 510/6000 [29:49<5:14:59,  3.44s/it]                                                    {'loss': 0.0417, 'grad_norm': 11.916284561157227, 'learning_rate': 9.305084745762713e-06, 'epoch': 0.09}
  8%|â–Š         | 510/6000 [29:49<5:14:59,  3.44s/it]  9%|â–Š         | 511/6000 [29:52<5:15:08,  3.44s/it]                                                    {'loss': 0.0741, 'grad_norm': 10.82521915435791, 'learning_rate': 9.303389830508476e-06, 'epoch': 0.09}
  9%|â–Š         | 511/6000 [29:52<5:15:08,  3.44s/it]  9%|â–Š         | 512/6000 [29:56<5:13:44,  3.43s/it]                                                    {'loss': 0.1341, 'grad_norm': 18.42176055908203, 'learning_rate': 9.301694915254237e-06, 'epoch': 0.09}
  9%|â–Š         | 512/6000 [29:56<5:13:44,  3.43s/it]  9%|â–Š         | 513/6000 [29:59<5:18:34,  3.48s/it]                                                    {'loss': 0.0266, 'grad_norm': 9.744909286499023, 'learning_rate': 9.3e-06, 'epoch': 0.09}
  9%|â–Š         | 513/6000 [29:59<5:18:34,  3.48s/it]  9%|â–Š         | 514/6000 [30:03<5:17:03,  3.47s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.2767420709133148, 'learning_rate': 9.298305084745764e-06, 'epoch': 0.09}
  9%|â–Š         | 514/6000 [30:03<5:17:03,  3.47s/it]  9%|â–Š         | 515/6000 [30:06<5:14:11,  3.44s/it]                                                    {'loss': 0.1271, 'grad_norm': 15.314634323120117, 'learning_rate': 9.296610169491527e-06, 'epoch': 0.09}
  9%|â–Š         | 515/6000 [30:06<5:14:11,  3.44s/it]  9%|â–Š         | 516/6000 [30:10<5:21:09,  3.51s/it]                                                    {'loss': 0.09, 'grad_norm': 18.45464515686035, 'learning_rate': 9.294915254237289e-06, 'epoch': 0.09}
  9%|â–Š         | 516/6000 [30:10<5:21:09,  3.51s/it]  9%|â–Š         | 517/6000 [30:13<5:20:08,  3.50s/it]                                                    {'loss': 0.0034, 'grad_norm': 1.631892442703247, 'learning_rate': 9.29322033898305e-06, 'epoch': 0.09}
  9%|â–Š         | 517/6000 [30:13<5:20:08,  3.50s/it]  9%|â–Š         | 518/6000 [30:17<5:15:36,  3.45s/it]                                                    {'loss': 0.1101, 'grad_norm': 16.259523391723633, 'learning_rate': 9.291525423728814e-06, 'epoch': 0.09}
  9%|â–Š         | 518/6000 [30:17<5:15:36,  3.45s/it]  9%|â–Š         | 519/6000 [30:20<5:14:35,  3.44s/it]                                                    {'loss': 0.0311, 'grad_norm': 7.156976222991943, 'learning_rate': 9.289830508474577e-06, 'epoch': 0.09}
  9%|â–Š         | 519/6000 [30:20<5:14:35,  3.44s/it]  9%|â–Š         | 520/6000 [30:24<5:18:53,  3.49s/it]                                                    {'loss': 0.0916, 'grad_norm': 15.329415321350098, 'learning_rate': 9.28813559322034e-06, 'epoch': 0.09}
  9%|â–Š         | 520/6000 [30:24<5:18:53,  3.49s/it]  9%|â–Š         | 521/6000 [30:27<5:13:31,  3.43s/it]                                                    {'loss': 0.0408, 'grad_norm': 11.051806449890137, 'learning_rate': 9.286440677966102e-06, 'epoch': 0.09}
  9%|â–Š         | 521/6000 [30:27<5:13:31,  3.43s/it]  9%|â–Š         | 522/6000 [30:30<5:10:21,  3.40s/it]                                                    {'loss': 0.015, 'grad_norm': 5.806495666503906, 'learning_rate': 9.284745762711865e-06, 'epoch': 0.09}
  9%|â–Š         | 522/6000 [30:30<5:10:21,  3.40s/it]  9%|â–Š         | 523/6000 [30:34<5:13:34,  3.44s/it]                                                    {'loss': 0.0244, 'grad_norm': 8.314040184020996, 'learning_rate': 9.283050847457627e-06, 'epoch': 0.09}
  9%|â–Š         | 523/6000 [30:34<5:13:34,  3.44s/it]  9%|â–Š         | 524/6000 [30:37<5:12:54,  3.43s/it]                                                    {'loss': 0.1643, 'grad_norm': 22.850370407104492, 'learning_rate': 9.28135593220339e-06, 'epoch': 0.09}
  9%|â–Š         | 524/6000 [30:37<5:12:54,  3.43s/it]  9%|â–‰         | 525/6000 [30:40<5:10:23,  3.40s/it]                                                    {'loss': 0.0937, 'grad_norm': 17.36360740661621, 'learning_rate': 9.279661016949153e-06, 'epoch': 0.09}
  9%|â–‰         | 525/6000 [30:40<5:10:23,  3.40s/it]  9%|â–‰         | 526/6000 [30:44<5:07:41,  3.37s/it]                                                    {'loss': 0.0361, 'grad_norm': 8.055071830749512, 'learning_rate': 9.277966101694917e-06, 'epoch': 0.09}
  9%|â–‰         | 526/6000 [30:44<5:07:41,  3.37s/it]  9%|â–‰         | 527/6000 [30:47<5:09:13,  3.39s/it]                                                    {'loss': 0.0969, 'grad_norm': 23.06470489501953, 'learning_rate': 9.276271186440678e-06, 'epoch': 0.09}
  9%|â–‰         | 527/6000 [30:47<5:09:13,  3.39s/it]  9%|â–‰         | 528/6000 [30:51<5:12:15,  3.42s/it]                                                    {'loss': 0.1339, 'grad_norm': 16.933521270751953, 'learning_rate': 9.274576271186441e-06, 'epoch': 0.09}
  9%|â–‰         | 528/6000 [30:51<5:12:15,  3.42s/it]  9%|â–‰         | 529/6000 [30:54<5:09:51,  3.40s/it]                                                    {'loss': 0.0052, 'grad_norm': 2.62821626663208, 'learning_rate': 9.272881355932205e-06, 'epoch': 0.09}
  9%|â–‰         | 529/6000 [30:54<5:09:51,  3.40s/it]  9%|â–‰         | 530/6000 [30:57<5:10:57,  3.41s/it]                                                    {'loss': 0.0143, 'grad_norm': 3.569394826889038, 'learning_rate': 9.271186440677968e-06, 'epoch': 0.09}
  9%|â–‰         | 530/6000 [30:57<5:10:57,  3.41s/it]  9%|â–‰         | 531/6000 [31:01<5:09:11,  3.39s/it]                                                    {'loss': 0.0882, 'grad_norm': 22.137784957885742, 'learning_rate': 9.26949152542373e-06, 'epoch': 0.09}
  9%|â–‰         | 531/6000 [31:01<5:09:11,  3.39s/it]  9%|â–‰         | 532/6000 [31:04<5:10:47,  3.41s/it]                                                    {'loss': 0.0305, 'grad_norm': 8.303689956665039, 'learning_rate': 9.267796610169493e-06, 'epoch': 0.09}
  9%|â–‰         | 532/6000 [31:04<5:10:47,  3.41s/it]  9%|â–‰         | 533/6000 [31:08<5:07:12,  3.37s/it]                                                    {'loss': 0.0542, 'grad_norm': 14.273545265197754, 'learning_rate': 9.266101694915254e-06, 'epoch': 0.09}
  9%|â–‰         | 533/6000 [31:08<5:07:12,  3.37s/it]  9%|â–‰         | 534/6000 [31:11<5:09:44,  3.40s/it]                                                    {'loss': 0.036, 'grad_norm': 11.70150089263916, 'learning_rate': 9.264406779661018e-06, 'epoch': 0.09}
  9%|â–‰         | 534/6000 [31:11<5:09:44,  3.40s/it]  9%|â–‰         | 535/6000 [31:15<5:13:00,  3.44s/it]                                                    {'loss': 0.0047, 'grad_norm': 2.4972355365753174, 'learning_rate': 9.262711864406781e-06, 'epoch': 0.09}
  9%|â–‰         | 535/6000 [31:15<5:13:00,  3.44s/it]  9%|â–‰         | 536/6000 [31:18<5:12:28,  3.43s/it]                                                    {'loss': 0.2381, 'grad_norm': 22.295719146728516, 'learning_rate': 9.261016949152544e-06, 'epoch': 0.09}
  9%|â–‰         | 536/6000 [31:18<5:12:28,  3.43s/it]  9%|â–‰         | 537/6000 [31:22<5:19:36,  3.51s/it]                                                    {'loss': 0.0178, 'grad_norm': 3.449272871017456, 'learning_rate': 9.259322033898306e-06, 'epoch': 0.09}
  9%|â–‰         | 537/6000 [31:22<5:19:36,  3.51s/it]  9%|â–‰         | 538/6000 [31:25<5:14:07,  3.45s/it]                                                    {'loss': 0.0065, 'grad_norm': 1.831982970237732, 'learning_rate': 9.257627118644067e-06, 'epoch': 0.09}
  9%|â–‰         | 538/6000 [31:25<5:14:07,  3.45s/it]  9%|â–‰         | 539/6000 [31:28<5:09:21,  3.40s/it]                                                    {'loss': 0.0008, 'grad_norm': 0.15174750983715057, 'learning_rate': 9.25593220338983e-06, 'epoch': 0.09}
  9%|â–‰         | 539/6000 [31:28<5:09:21,  3.40s/it]  9%|â–‰         | 540/6000 [31:32<5:06:45,  3.37s/it]                                                    {'loss': 0.1358, 'grad_norm': 22.119346618652344, 'learning_rate': 9.254237288135594e-06, 'epoch': 0.09}
  9%|â–‰         | 540/6000 [31:32<5:06:45,  3.37s/it]  9%|â–‰         | 541/6000 [31:35<5:12:43,  3.44s/it]                                                    {'loss': 0.0489, 'grad_norm': 19.6358642578125, 'learning_rate': 9.252542372881357e-06, 'epoch': 0.09}
  9%|â–‰         | 541/6000 [31:35<5:12:43,  3.44s/it]  9%|â–‰         | 542/6000 [31:39<5:13:44,  3.45s/it]                                                    {'loss': 0.0279, 'grad_norm': 5.198561191558838, 'learning_rate': 9.250847457627119e-06, 'epoch': 0.09}
  9%|â–‰         | 542/6000 [31:39<5:13:44,  3.45s/it]  9%|â–‰         | 543/6000 [31:42<5:14:23,  3.46s/it]                                                    {'loss': 0.1284, 'grad_norm': 17.975475311279297, 'learning_rate': 9.249152542372882e-06, 'epoch': 0.09}
  9%|â–‰         | 543/6000 [31:42<5:14:23,  3.46s/it]  9%|â–‰         | 544/6000 [31:46<5:13:07,  3.44s/it]                                                    {'loss': 0.105, 'grad_norm': 15.977964401245117, 'learning_rate': 9.247457627118645e-06, 'epoch': 0.09}
  9%|â–‰         | 544/6000 [31:46<5:13:07,  3.44s/it]  9%|â–‰         | 545/6000 [31:49<5:13:58,  3.45s/it]                                                    {'loss': 0.2401, 'grad_norm': 31.293235778808594, 'learning_rate': 9.245762711864409e-06, 'epoch': 0.09}
  9%|â–‰         | 545/6000 [31:49<5:13:58,  3.45s/it]  9%|â–‰         | 546/6000 [31:53<5:15:49,  3.47s/it]                                                    {'loss': 0.0074, 'grad_norm': 1.4441559314727783, 'learning_rate': 9.24406779661017e-06, 'epoch': 0.09}
  9%|â–‰         | 546/6000 [31:53<5:15:49,  3.47s/it]  9%|â–‰         | 547/6000 [31:56<5:17:08,  3.49s/it]                                                    {'loss': 0.0389, 'grad_norm': 14.190956115722656, 'learning_rate': 9.242372881355933e-06, 'epoch': 0.09}
  9%|â–‰         | 547/6000 [31:56<5:17:08,  3.49s/it]  9%|â–‰         | 548/6000 [31:59<5:15:05,  3.47s/it]                                                    {'loss': 0.0218, 'grad_norm': 7.611383438110352, 'learning_rate': 9.240677966101695e-06, 'epoch': 0.09}
  9%|â–‰         | 548/6000 [31:59<5:15:05,  3.47s/it]  9%|â–‰         | 549/6000 [32:03<5:10:45,  3.42s/it]                                                    {'loss': 0.0329, 'grad_norm': 7.048301696777344, 'learning_rate': 9.238983050847458e-06, 'epoch': 0.09}
  9%|â–‰         | 549/6000 [32:03<5:10:45,  3.42s/it]  9%|â–‰         | 550/6000 [32:06<5:08:56,  3.40s/it]                                                    {'loss': 0.2358, 'grad_norm': 22.765853881835938, 'learning_rate': 9.237288135593222e-06, 'epoch': 0.09}
  9%|â–‰         | 550/6000 [32:06<5:08:56,  3.40s/it]  9%|â–‰         | 551/6000 [32:11<5:36:37,  3.71s/it]                                                    {'loss': 0.0389, 'grad_norm': 11.245579719543457, 'learning_rate': 9.235593220338985e-06, 'epoch': 0.09}
  9%|â–‰         | 551/6000 [32:11<5:36:37,  3.71s/it]  9%|â–‰         | 552/6000 [32:14<5:29:47,  3.63s/it]                                                    {'loss': 0.0036, 'grad_norm': 1.7638176679611206, 'learning_rate': 9.233898305084746e-06, 'epoch': 0.09}
  9%|â–‰         | 552/6000 [32:14<5:29:47,  3.63s/it]  9%|â–‰         | 553/6000 [32:18<5:28:26,  3.62s/it]                                                    {'loss': 0.1243, 'grad_norm': 18.19081687927246, 'learning_rate': 9.23220338983051e-06, 'epoch': 0.09}
  9%|â–‰         | 553/6000 [32:18<5:28:26,  3.62s/it]  9%|â–‰         | 554/6000 [32:21<5:21:01,  3.54s/it]                                                    {'loss': 0.3508, 'grad_norm': 22.65528106689453, 'learning_rate': 9.230508474576271e-06, 'epoch': 0.09}
  9%|â–‰         | 554/6000 [32:21<5:21:01,  3.54s/it]  9%|â–‰         | 555/6000 [32:24<5:14:37,  3.47s/it]                                                    {'loss': 0.0878, 'grad_norm': 18.307615280151367, 'learning_rate': 9.228813559322035e-06, 'epoch': 0.09}
  9%|â–‰         | 555/6000 [32:24<5:14:37,  3.47s/it]  9%|â–‰         | 556/6000 [32:28<5:11:58,  3.44s/it]                                                    {'loss': 0.0341, 'grad_norm': 5.483693599700928, 'learning_rate': 9.227118644067798e-06, 'epoch': 0.09}
  9%|â–‰         | 556/6000 [32:28<5:11:58,  3.44s/it]  9%|â–‰         | 557/6000 [32:31<5:10:36,  3.42s/it]                                                    {'loss': 0.0569, 'grad_norm': 4.0014142990112305, 'learning_rate': 9.225423728813561e-06, 'epoch': 0.09}
  9%|â–‰         | 557/6000 [32:31<5:10:36,  3.42s/it]  9%|â–‰         | 558/6000 [32:35<5:13:34,  3.46s/it]                                                    {'loss': 0.1023, 'grad_norm': 25.374109268188477, 'learning_rate': 9.223728813559323e-06, 'epoch': 0.09}
  9%|â–‰         | 558/6000 [32:35<5:13:34,  3.46s/it]  9%|â–‰         | 559/6000 [32:38<5:16:29,  3.49s/it]                                                    {'loss': 0.075, 'grad_norm': 26.856565475463867, 'learning_rate': 9.222033898305084e-06, 'epoch': 0.09}
  9%|â–‰         | 559/6000 [32:38<5:16:29,  3.49s/it]  9%|â–‰         | 560/6000 [32:42<5:15:13,  3.48s/it]                                                    {'loss': 0.2284, 'grad_norm': 28.147645950317383, 'learning_rate': 9.220338983050847e-06, 'epoch': 0.09}
  9%|â–‰         | 560/6000 [32:42<5:15:13,  3.48s/it]  9%|â–‰         | 561/6000 [32:46<5:29:18,  3.63s/it]                                                    {'loss': 0.0343, 'grad_norm': 11.428300857543945, 'learning_rate': 9.21864406779661e-06, 'epoch': 0.09}
  9%|â–‰         | 561/6000 [32:46<5:29:18,  3.63s/it]  9%|â–‰         | 562/6000 [32:49<5:20:38,  3.54s/it]                                                    {'loss': 0.2939, 'grad_norm': 24.130752563476562, 'learning_rate': 9.216949152542374e-06, 'epoch': 0.09}
  9%|â–‰         | 562/6000 [32:49<5:20:38,  3.54s/it]  9%|â–‰         | 563/6000 [32:52<5:18:18,  3.51s/it]                                                    {'loss': 0.0475, 'grad_norm': 11.769506454467773, 'learning_rate': 9.215254237288136e-06, 'epoch': 0.09}
  9%|â–‰         | 563/6000 [32:52<5:18:18,  3.51s/it]  9%|â–‰         | 564/6000 [32:56<5:15:52,  3.49s/it]                                                    {'loss': 0.0099, 'grad_norm': 2.0544655323028564, 'learning_rate': 9.213559322033899e-06, 'epoch': 0.09}
  9%|â–‰         | 564/6000 [32:56<5:15:52,  3.49s/it]  9%|â–‰         | 565/6000 [33:00<5:23:05,  3.57s/it]                                                    {'loss': 0.0459, 'grad_norm': 47.69993209838867, 'learning_rate': 9.211864406779662e-06, 'epoch': 0.09}
  9%|â–‰         | 565/6000 [33:00<5:23:05,  3.57s/it]  9%|â–‰         | 566/6000 [33:03<5:18:34,  3.52s/it]                                                    {'loss': 0.0407, 'grad_norm': 13.53896427154541, 'learning_rate': 9.210169491525425e-06, 'epoch': 0.09}
  9%|â–‰         | 566/6000 [33:03<5:18:34,  3.52s/it]  9%|â–‰         | 567/6000 [33:07<5:29:21,  3.64s/it]                                                    {'loss': 0.0793, 'grad_norm': 26.34207534790039, 'learning_rate': 9.208474576271187e-06, 'epoch': 0.09}
  9%|â–‰         | 567/6000 [33:07<5:29:21,  3.64s/it]  9%|â–‰         | 568/6000 [33:10<5:25:23,  3.59s/it]                                                    {'loss': 0.0545, 'grad_norm': 4.066303730010986, 'learning_rate': 9.20677966101695e-06, 'epoch': 0.09}
  9%|â–‰         | 568/6000 [33:10<5:25:23,  3.59s/it]  9%|â–‰         | 569/6000 [33:14<5:21:35,  3.55s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.8886809349060059, 'learning_rate': 9.205084745762712e-06, 'epoch': 0.09}
  9%|â–‰         | 569/6000 [33:14<5:21:35,  3.55s/it] 10%|â–‰         | 570/6000 [33:17<5:17:39,  3.51s/it]                                                    {'loss': 0.0935, 'grad_norm': 10.87879467010498, 'learning_rate': 9.203389830508475e-06, 'epoch': 0.1}
 10%|â–‰         | 570/6000 [33:17<5:17:39,  3.51s/it] 10%|â–‰         | 571/6000 [33:22<5:53:00,  3.90s/it]                                                    {'loss': 0.0416, 'grad_norm': 12.072896003723145, 'learning_rate': 9.201694915254238e-06, 'epoch': 0.1}
 10%|â–‰         | 571/6000 [33:22<5:53:00,  3.90s/it] 10%|â–‰         | 572/6000 [33:25<5:39:49,  3.76s/it]                                                    {'loss': 0.4086, 'grad_norm': 28.180587768554688, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.1}
 10%|â–‰         | 572/6000 [33:25<5:39:49,  3.76s/it] 10%|â–‰         | 573/6000 [33:29<5:27:54,  3.63s/it]                                                    {'loss': 0.1825, 'grad_norm': 15.990748405456543, 'learning_rate': 9.198305084745763e-06, 'epoch': 0.1}
 10%|â–‰         | 573/6000 [33:29<5:27:54,  3.63s/it] 10%|â–‰         | 574/6000 [33:32<5:22:38,  3.57s/it]                                                    {'loss': 0.3547, 'grad_norm': 27.320444107055664, 'learning_rate': 9.196610169491527e-06, 'epoch': 0.1}
 10%|â–‰         | 574/6000 [33:32<5:22:38,  3.57s/it] 10%|â–‰         | 575/6000 [33:36<5:18:18,  3.52s/it]                                                    {'loss': 0.0243, 'grad_norm': 6.870088577270508, 'learning_rate': 9.194915254237288e-06, 'epoch': 0.1}
 10%|â–‰         | 575/6000 [33:36<5:18:18,  3.52s/it] 10%|â–‰         | 576/6000 [33:39<5:19:15,  3.53s/it]                                                    {'loss': 0.1732, 'grad_norm': 16.981842041015625, 'learning_rate': 9.193220338983051e-06, 'epoch': 0.1}
 10%|â–‰         | 576/6000 [33:39<5:19:15,  3.53s/it] 10%|â–‰         | 577/6000 [33:43<5:27:48,  3.63s/it]                                                    {'loss': 0.0747, 'grad_norm': 9.141847610473633, 'learning_rate': 9.191525423728815e-06, 'epoch': 0.1}
 10%|â–‰         | 577/6000 [33:43<5:27:48,  3.63s/it] 10%|â–‰         | 578/6000 [33:47<5:41:19,  3.78s/it]                                                    {'loss': 0.223, 'grad_norm': 21.68876838684082, 'learning_rate': 9.189830508474576e-06, 'epoch': 0.1}
 10%|â–‰         | 578/6000 [33:47<5:41:19,  3.78s/it] 10%|â–‰         | 579/6000 [33:51<5:45:58,  3.83s/it]                                                    {'loss': 0.0255, 'grad_norm': 8.376378059387207, 'learning_rate': 9.18813559322034e-06, 'epoch': 0.1}
 10%|â–‰         | 579/6000 [33:51<5:45:58,  3.83s/it] 10%|â–‰         | 580/6000 [33:55<5:37:10,  3.73s/it]                                                    {'loss': 0.1562, 'grad_norm': 14.981653213500977, 'learning_rate': 9.186440677966101e-06, 'epoch': 0.1}
 10%|â–‰         | 580/6000 [33:55<5:37:10,  3.73s/it] 10%|â–‰         | 581/6000 [33:59<5:52:09,  3.90s/it]                                                    {'loss': 0.3631, 'grad_norm': 19.56146240234375, 'learning_rate': 9.184745762711866e-06, 'epoch': 0.1}
 10%|â–‰         | 581/6000 [33:59<5:52:09,  3.90s/it] 10%|â–‰         | 582/6000 [34:03<6:09:06,  4.09s/it]                                                    {'loss': 0.143, 'grad_norm': 29.952369689941406, 'learning_rate': 9.183050847457628e-06, 'epoch': 0.1}
 10%|â–‰         | 582/6000 [34:03<6:09:06,  4.09s/it] 10%|â–‰         | 583/6000 [34:07<5:53:27,  3.91s/it]                                                    {'loss': 0.0335, 'grad_norm': 6.984187602996826, 'learning_rate': 9.181355932203391e-06, 'epoch': 0.1}
 10%|â–‰         | 583/6000 [34:07<5:53:27,  3.91s/it] 10%|â–‰         | 584/6000 [34:10<5:40:53,  3.78s/it]                                                    {'loss': 0.588, 'grad_norm': 19.19525718688965, 'learning_rate': 9.179661016949153e-06, 'epoch': 0.1}
 10%|â–‰         | 584/6000 [34:10<5:40:53,  3.78s/it] 10%|â–‰         | 585/6000 [34:14<5:48:47,  3.86s/it]                                                    {'loss': 0.004, 'grad_norm': 1.1155312061309814, 'learning_rate': 9.177966101694916e-06, 'epoch': 0.1}
 10%|â–‰         | 585/6000 [34:14<5:48:47,  3.86s/it] 10%|â–‰         | 586/6000 [34:18<5:38:20,  3.75s/it]                                                    {'loss': 0.0821, 'grad_norm': 16.309036254882812, 'learning_rate': 9.176271186440679e-06, 'epoch': 0.1}
 10%|â–‰         | 586/6000 [34:18<5:38:20,  3.75s/it] 10%|â–‰         | 587/6000 [34:21<5:25:21,  3.61s/it]                                                    {'loss': 0.0501, 'grad_norm': 9.558390617370605, 'learning_rate': 9.174576271186442e-06, 'epoch': 0.1}
 10%|â–‰         | 587/6000 [34:21<5:25:21,  3.61s/it] 10%|â–‰         | 588/6000 [34:25<5:19:29,  3.54s/it]                                                    {'loss': 0.0079, 'grad_norm': 2.745647430419922, 'learning_rate': 9.172881355932204e-06, 'epoch': 0.1}
 10%|â–‰         | 588/6000 [34:25<5:19:29,  3.54s/it] 10%|â–‰         | 589/6000 [34:28<5:19:38,  3.54s/it]                                                    {'loss': 0.0183, 'grad_norm': 5.046544075012207, 'learning_rate': 9.171186440677967e-06, 'epoch': 0.1}
 10%|â–‰         | 589/6000 [34:28<5:19:38,  3.54s/it] 10%|â–‰         | 590/6000 [34:32<5:20:14,  3.55s/it]                                                    {'loss': 0.0887, 'grad_norm': 17.13805389404297, 'learning_rate': 9.169491525423729e-06, 'epoch': 0.1}
 10%|â–‰         | 590/6000 [34:32<5:20:14,  3.55s/it] 10%|â–‰         | 591/6000 [34:35<5:16:00,  3.51s/it]                                                    {'loss': 0.0977, 'grad_norm': 13.85757064819336, 'learning_rate': 9.167796610169492e-06, 'epoch': 0.1}
 10%|â–‰         | 591/6000 [34:35<5:16:00,  3.51s/it] 10%|â–‰         | 592/6000 [34:38<5:11:29,  3.46s/it]                                                    {'loss': 0.1438, 'grad_norm': 20.495906829833984, 'learning_rate': 9.166101694915255e-06, 'epoch': 0.1}
 10%|â–‰         | 592/6000 [34:38<5:11:29,  3.46s/it] 10%|â–‰         | 593/6000 [34:42<5:10:32,  3.45s/it]                                                    {'loss': 0.0374, 'grad_norm': 7.684473037719727, 'learning_rate': 9.164406779661019e-06, 'epoch': 0.1}
 10%|â–‰         | 593/6000 [34:42<5:10:32,  3.45s/it] 10%|â–‰         | 594/6000 [34:45<5:12:35,  3.47s/it]                                                    {'loss': 0.0876, 'grad_norm': 13.336257934570312, 'learning_rate': 9.16271186440678e-06, 'epoch': 0.1}
 10%|â–‰         | 594/6000 [34:45<5:12:35,  3.47s/it] 10%|â–‰         | 595/6000 [34:49<5:20:36,  3.56s/it]                                                    {'loss': 0.0887, 'grad_norm': 15.38983154296875, 'learning_rate': 9.161016949152543e-06, 'epoch': 0.1}
 10%|â–‰         | 595/6000 [34:49<5:20:36,  3.56s/it] 10%|â–‰         | 596/6000 [34:54<5:42:32,  3.80s/it]                                                    {'loss': 0.07, 'grad_norm': 4.166810989379883, 'learning_rate': 9.159322033898305e-06, 'epoch': 0.1}
 10%|â–‰         | 596/6000 [34:54<5:42:32,  3.80s/it] 10%|â–‰         | 597/6000 [34:57<5:28:38,  3.65s/it]                                                    {'loss': 0.0278, 'grad_norm': 3.843121290206909, 'learning_rate': 9.157627118644068e-06, 'epoch': 0.1}
 10%|â–‰         | 597/6000 [34:57<5:28:38,  3.65s/it] 10%|â–‰         | 598/6000 [35:00<5:20:56,  3.56s/it]                                                    {'loss': 0.0965, 'grad_norm': 14.721759796142578, 'learning_rate': 9.155932203389832e-06, 'epoch': 0.1}
 10%|â–‰         | 598/6000 [35:00<5:20:56,  3.56s/it] 10%|â–‰         | 599/6000 [35:03<5:13:11,  3.48s/it]                                                    {'loss': 0.0171, 'grad_norm': 2.3342740535736084, 'learning_rate': 9.154237288135593e-06, 'epoch': 0.1}
 10%|â–‰         | 599/6000 [35:03<5:13:11,  3.48s/it] 10%|â–ˆ         | 600/6000 [35:07<5:11:50,  3.46s/it]                                                    {'loss': 0.029, 'grad_norm': 10.718451499938965, 'learning_rate': 9.152542372881356e-06, 'epoch': 0.1}
 10%|â–ˆ         | 600/6000 [35:07<5:11:50,  3.46s/it][2025-11-06 23:26:16,871] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600
[2025-11-06 23:26:16,884] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:26:17,545] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 10%|â–ˆ         | 601/6000 [35:12<6:09:38,  4.11s/it]                                                    {'loss': 0.1237, 'grad_norm': 16.443208694458008, 'learning_rate': 9.15084745762712e-06, 'epoch': 0.1}
 10%|â–ˆ         | 601/6000 [35:12<6:09:38,  4.11s/it] 10%|â–ˆ         | 602/6000 [35:16<5:51:37,  3.91s/it]                                                    {'loss': 0.0173, 'grad_norm': 5.826435565948486, 'learning_rate': 9.149152542372883e-06, 'epoch': 0.1}
 10%|â–ˆ         | 602/6000 [35:16<5:51:37,  3.91s/it] 10%|â–ˆ         | 603/6000 [35:19<5:37:24,  3.75s/it]                                                    {'loss': 0.2629, 'grad_norm': 29.346664428710938, 'learning_rate': 9.147457627118645e-06, 'epoch': 0.1}
 10%|â–ˆ         | 603/6000 [35:19<5:37:24,  3.75s/it] 10%|â–ˆ         | 604/6000 [35:23<5:44:04,  3.83s/it]                                                    {'loss': 0.0722, 'grad_norm': 16.5711727142334, 'learning_rate': 9.145762711864408e-06, 'epoch': 0.1}
 10%|â–ˆ         | 604/6000 [35:23<5:44:04,  3.83s/it] 10%|â–ˆ         | 605/6000 [35:27<5:32:27,  3.70s/it]                                                    {'loss': 0.0833, 'grad_norm': 10.892329216003418, 'learning_rate': 9.14406779661017e-06, 'epoch': 0.1}
 10%|â–ˆ         | 605/6000 [35:27<5:32:27,  3.70s/it] 10%|â–ˆ         | 606/6000 [35:30<5:29:53,  3.67s/it]                                                    {'loss': 0.0276, 'grad_norm': 5.580790042877197, 'learning_rate': 9.142372881355933e-06, 'epoch': 0.1}
 10%|â–ˆ         | 606/6000 [35:30<5:29:53,  3.67s/it] 10%|â–ˆ         | 607/6000 [35:34<5:20:36,  3.57s/it]                                                    {'loss': 0.0367, 'grad_norm': 17.95940399169922, 'learning_rate': 9.140677966101696e-06, 'epoch': 0.1}
 10%|â–ˆ         | 607/6000 [35:34<5:20:36,  3.57s/it] 10%|â–ˆ         | 608/6000 [35:37<5:20:51,  3.57s/it]                                                    {'loss': 0.1121, 'grad_norm': 14.107820510864258, 'learning_rate': 9.13898305084746e-06, 'epoch': 0.1}
 10%|â–ˆ         | 608/6000 [35:37<5:20:51,  3.57s/it] 10%|â–ˆ         | 609/6000 [35:41<5:14:57,  3.51s/it]                                                    {'loss': 0.0994, 'grad_norm': 10.503379821777344, 'learning_rate': 9.13728813559322e-06, 'epoch': 0.1}
 10%|â–ˆ         | 609/6000 [35:41<5:14:57,  3.51s/it] 10%|â–ˆ         | 610/6000 [35:44<5:12:06,  3.47s/it]                                                    {'loss': 0.0318, 'grad_norm': 8.725666999816895, 'learning_rate': 9.135593220338984e-06, 'epoch': 0.1}
 10%|â–ˆ         | 610/6000 [35:44<5:12:06,  3.47s/it] 10%|â–ˆ         | 611/6000 [35:47<5:09:21,  3.44s/it]                                                    {'loss': 0.1864, 'grad_norm': 18.61509132385254, 'learning_rate': 9.133898305084746e-06, 'epoch': 0.1}
 10%|â–ˆ         | 611/6000 [35:47<5:09:21,  3.44s/it] 10%|â–ˆ         | 612/6000 [35:51<5:11:40,  3.47s/it]                                                    {'loss': 0.0204, 'grad_norm': 3.056471109390259, 'learning_rate': 9.132203389830509e-06, 'epoch': 0.1}
 10%|â–ˆ         | 612/6000 [35:51<5:11:40,  3.47s/it] 10%|â–ˆ         | 613/6000 [35:54<5:14:56,  3.51s/it]                                                    {'loss': 0.0851, 'grad_norm': 10.6806001663208, 'learning_rate': 9.130508474576272e-06, 'epoch': 0.1}
 10%|â–ˆ         | 613/6000 [35:54<5:14:56,  3.51s/it] 10%|â–ˆ         | 614/6000 [35:58<5:09:24,  3.45s/it]                                                    {'loss': 0.0133, 'grad_norm': 3.473151922225952, 'learning_rate': 9.128813559322035e-06, 'epoch': 0.1}
 10%|â–ˆ         | 614/6000 [35:58<5:09:24,  3.45s/it] 10%|â–ˆ         | 615/6000 [36:01<5:13:48,  3.50s/it]                                                    {'loss': 0.103, 'grad_norm': 10.203372955322266, 'learning_rate': 9.127118644067797e-06, 'epoch': 0.1}
 10%|â–ˆ         | 615/6000 [36:01<5:13:48,  3.50s/it] 10%|â–ˆ         | 616/6000 [36:05<5:09:01,  3.44s/it]                                                    {'loss': 0.088, 'grad_norm': 8.879745483398438, 'learning_rate': 9.12542372881356e-06, 'epoch': 0.1}
 10%|â–ˆ         | 616/6000 [36:05<5:09:01,  3.44s/it] 10%|â–ˆ         | 617/6000 [36:08<5:08:35,  3.44s/it]                                                    {'loss': 0.0021, 'grad_norm': 0.5591070652008057, 'learning_rate': 9.123728813559322e-06, 'epoch': 0.1}
 10%|â–ˆ         | 617/6000 [36:08<5:08:35,  3.44s/it] 10%|â–ˆ         | 618/6000 [36:12<5:07:44,  3.43s/it]                                                    {'loss': 0.0489, 'grad_norm': 11.978323936462402, 'learning_rate': 9.122033898305085e-06, 'epoch': 0.1}
 10%|â–ˆ         | 618/6000 [36:12<5:07:44,  3.43s/it] 10%|â–ˆ         | 619/6000 [36:15<5:06:58,  3.42s/it]                                                    {'loss': 0.1633, 'grad_norm': 20.91069793701172, 'learning_rate': 9.120338983050848e-06, 'epoch': 0.1}
 10%|â–ˆ         | 619/6000 [36:15<5:06:58,  3.42s/it] 10%|â–ˆ         | 620/6000 [36:18<5:03:40,  3.39s/it]                                                    {'loss': 0.0214, 'grad_norm': 5.00872802734375, 'learning_rate': 9.11864406779661e-06, 'epoch': 0.1}
 10%|â–ˆ         | 620/6000 [36:18<5:03:40,  3.39s/it] 10%|â–ˆ         | 621/6000 [36:22<5:00:33,  3.35s/it]                                                    {'loss': 0.0415, 'grad_norm': 5.993915557861328, 'learning_rate': 9.116949152542373e-06, 'epoch': 0.1}
 10%|â–ˆ         | 621/6000 [36:22<5:00:33,  3.35s/it] 10%|â–ˆ         | 622/6000 [36:25<4:59:53,  3.35s/it]                                                    {'loss': 0.2742, 'grad_norm': 21.684467315673828, 'learning_rate': 9.115254237288137e-06, 'epoch': 0.1}
 10%|â–ˆ         | 622/6000 [36:25<4:59:53,  3.35s/it] 10%|â–ˆ         | 623/6000 [36:28<5:00:48,  3.36s/it]                                                    {'loss': 0.1571, 'grad_norm': 13.562814712524414, 'learning_rate': 9.1135593220339e-06, 'epoch': 0.1}
 10%|â–ˆ         | 623/6000 [36:28<5:00:48,  3.36s/it] 10%|â–ˆ         | 624/6000 [36:32<4:59:49,  3.35s/it]                                                    {'loss': 0.2186, 'grad_norm': 21.799480438232422, 'learning_rate': 9.111864406779661e-06, 'epoch': 0.1}
 10%|â–ˆ         | 624/6000 [36:32<4:59:49,  3.35s/it] 10%|â–ˆ         | 625/6000 [36:35<5:08:45,  3.45s/it]                                                    {'loss': 0.0052, 'grad_norm': 0.9647641181945801, 'learning_rate': 9.110169491525425e-06, 'epoch': 0.1}
 10%|â–ˆ         | 625/6000 [36:35<5:08:45,  3.45s/it] 10%|â–ˆ         | 626/6000 [36:39<5:07:37,  3.43s/it]                                                    {'loss': 0.0577, 'grad_norm': 9.079675674438477, 'learning_rate': 9.108474576271186e-06, 'epoch': 0.1}
 10%|â–ˆ         | 626/6000 [36:39<5:07:37,  3.43s/it] 10%|â–ˆ         | 627/6000 [36:43<5:28:08,  3.66s/it]                                                    {'loss': 0.0243, 'grad_norm': 7.281651973724365, 'learning_rate': 9.10677966101695e-06, 'epoch': 0.1}
 10%|â–ˆ         | 627/6000 [36:43<5:28:08,  3.66s/it] 10%|â–ˆ         | 628/6000 [36:46<5:22:39,  3.60s/it]                                                    {'loss': 0.2008, 'grad_norm': 28.155580520629883, 'learning_rate': 9.105084745762713e-06, 'epoch': 0.1}
 10%|â–ˆ         | 628/6000 [36:46<5:22:39,  3.60s/it] 10%|â–ˆ         | 629/6000 [36:50<5:16:04,  3.53s/it]                                                    {'loss': 0.0142, 'grad_norm': 2.8381433486938477, 'learning_rate': 9.103389830508476e-06, 'epoch': 0.1}
 10%|â–ˆ         | 629/6000 [36:50<5:16:04,  3.53s/it] 10%|â–ˆ         | 630/6000 [36:53<5:11:57,  3.49s/it]                                                    {'loss': 0.5147, 'grad_norm': 19.31556510925293, 'learning_rate': 9.101694915254238e-06, 'epoch': 0.1}
 10%|â–ˆ         | 630/6000 [36:53<5:11:57,  3.49s/it] 11%|â–ˆ         | 631/6000 [36:56<5:09:49,  3.46s/it]                                                    {'loss': 0.2283, 'grad_norm': 23.30607795715332, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.11}
 11%|â–ˆ         | 631/6000 [36:56<5:09:49,  3.46s/it] 11%|â–ˆ         | 632/6000 [37:00<5:11:11,  3.48s/it]                                                    {'loss': 0.1213, 'grad_norm': 11.007689476013184, 'learning_rate': 9.098305084745763e-06, 'epoch': 0.11}
 11%|â–ˆ         | 632/6000 [37:00<5:11:11,  3.48s/it] 11%|â–ˆ         | 633/6000 [37:04<5:12:37,  3.50s/it]                                                    {'loss': 0.085, 'grad_norm': 12.161687850952148, 'learning_rate': 9.096610169491526e-06, 'epoch': 0.11}
 11%|â–ˆ         | 633/6000 [37:04<5:12:37,  3.50s/it] 11%|â–ˆ         | 634/6000 [37:07<5:19:53,  3.58s/it]                                                    {'loss': 0.0325, 'grad_norm': 7.510732173919678, 'learning_rate': 9.094915254237289e-06, 'epoch': 0.11}
 11%|â–ˆ         | 634/6000 [37:07<5:19:53,  3.58s/it] 11%|â–ˆ         | 635/6000 [37:11<5:20:58,  3.59s/it]                                                    {'loss': 0.0141, 'grad_norm': 3.4052462577819824, 'learning_rate': 9.093220338983052e-06, 'epoch': 0.11}
 11%|â–ˆ         | 635/6000 [37:11<5:20:58,  3.59s/it] 11%|â–ˆ         | 636/6000 [37:14<5:15:36,  3.53s/it]                                                    {'loss': 0.0144, 'grad_norm': 4.3488383293151855, 'learning_rate': 9.091525423728814e-06, 'epoch': 0.11}
 11%|â–ˆ         | 636/6000 [37:14<5:15:36,  3.53s/it] 11%|â–ˆ         | 637/6000 [37:18<5:12:29,  3.50s/it]                                                    {'loss': 0.0137, 'grad_norm': 2.2068018913269043, 'learning_rate': 9.089830508474577e-06, 'epoch': 0.11}
 11%|â–ˆ         | 637/6000 [37:18<5:12:29,  3.50s/it] 11%|â–ˆ         | 638/6000 [37:22<5:26:29,  3.65s/it]                                                    {'loss': 0.0446, 'grad_norm': 5.979258060455322, 'learning_rate': 9.08813559322034e-06, 'epoch': 0.11}
 11%|â–ˆ         | 638/6000 [37:22<5:26:29,  3.65s/it] 11%|â–ˆ         | 639/6000 [37:25<5:20:55,  3.59s/it]                                                    {'loss': 0.0202, 'grad_norm': 2.936239719390869, 'learning_rate': 9.086440677966104e-06, 'epoch': 0.11}
 11%|â–ˆ         | 639/6000 [37:25<5:20:55,  3.59s/it] 11%|â–ˆ         | 640/6000 [37:29<5:27:27,  3.67s/it]                                                    {'loss': 0.0351, 'grad_norm': 8.113412857055664, 'learning_rate': 9.084745762711865e-06, 'epoch': 0.11}
 11%|â–ˆ         | 640/6000 [37:29<5:27:27,  3.67s/it] 11%|â–ˆ         | 641/6000 [37:33<5:35:51,  3.76s/it]                                                    {'loss': 0.0082, 'grad_norm': 1.9376490116119385, 'learning_rate': 9.083050847457627e-06, 'epoch': 0.11}
 11%|â–ˆ         | 641/6000 [37:33<5:35:51,  3.76s/it] 11%|â–ˆ         | 642/6000 [37:36<5:24:32,  3.63s/it]                                                    {'loss': 0.011, 'grad_norm': 3.7615485191345215, 'learning_rate': 9.08135593220339e-06, 'epoch': 0.11}
 11%|â–ˆ         | 642/6000 [37:36<5:24:32,  3.63s/it] 11%|â–ˆ         | 643/6000 [37:40<5:18:56,  3.57s/it]                                                    {'loss': 0.0327, 'grad_norm': 6.922123432159424, 'learning_rate': 9.079661016949153e-06, 'epoch': 0.11}
 11%|â–ˆ         | 643/6000 [37:40<5:18:56,  3.57s/it] 11%|â–ˆ         | 644/6000 [37:43<5:16:29,  3.55s/it]                                                    {'loss': 0.0253, 'grad_norm': 9.008255958557129, 'learning_rate': 9.077966101694917e-06, 'epoch': 0.11}
 11%|â–ˆ         | 644/6000 [37:43<5:16:29,  3.55s/it] 11%|â–ˆ         | 645/6000 [37:47<5:12:50,  3.51s/it]                                                    {'loss': 0.1175, 'grad_norm': 17.162782669067383, 'learning_rate': 9.076271186440678e-06, 'epoch': 0.11}
 11%|â–ˆ         | 645/6000 [37:47<5:12:50,  3.51s/it] 11%|â–ˆ         | 646/6000 [37:50<5:18:41,  3.57s/it]                                                    {'loss': 0.0424, 'grad_norm': 10.634551048278809, 'learning_rate': 9.074576271186442e-06, 'epoch': 0.11}
 11%|â–ˆ         | 646/6000 [37:50<5:18:41,  3.57s/it] 11%|â–ˆ         | 647/6000 [37:54<5:12:05,  3.50s/it]                                                    {'loss': 0.1645, 'grad_norm': 14.231534957885742, 'learning_rate': 9.072881355932203e-06, 'epoch': 0.11}
 11%|â–ˆ         | 647/6000 [37:54<5:12:05,  3.50s/it] 11%|â–ˆ         | 648/6000 [37:58<5:21:00,  3.60s/it]                                                    {'loss': 0.0889, 'grad_norm': 11.541914939880371, 'learning_rate': 9.071186440677966e-06, 'epoch': 0.11}
 11%|â–ˆ         | 648/6000 [37:58<5:21:00,  3.60s/it] 11%|â–ˆ         | 649/6000 [38:01<5:14:17,  3.52s/it]                                                    {'loss': 0.0625, 'grad_norm': 16.8352108001709, 'learning_rate': 9.06949152542373e-06, 'epoch': 0.11}
 11%|â–ˆ         | 649/6000 [38:01<5:14:17,  3.52s/it] 11%|â–ˆ         | 650/6000 [38:04<5:09:04,  3.47s/it]                                                    {'loss': 0.2376, 'grad_norm': 18.96891975402832, 'learning_rate': 9.067796610169493e-06, 'epoch': 0.11}
 11%|â–ˆ         | 650/6000 [38:04<5:09:04,  3.47s/it] 11%|â–ˆ         | 651/6000 [38:08<5:05:24,  3.43s/it]                                                    {'loss': 0.1353, 'grad_norm': 12.055813789367676, 'learning_rate': 9.066101694915255e-06, 'epoch': 0.11}
 11%|â–ˆ         | 651/6000 [38:08<5:05:24,  3.43s/it] 11%|â–ˆ         | 652/6000 [38:11<5:15:07,  3.54s/it]                                                    {'loss': 0.0095, 'grad_norm': 2.0465903282165527, 'learning_rate': 9.064406779661018e-06, 'epoch': 0.11}
 11%|â–ˆ         | 652/6000 [38:11<5:15:07,  3.54s/it] 11%|â–ˆ         | 653/6000 [38:15<5:15:27,  3.54s/it]                                                    {'loss': 0.1538, 'grad_norm': 13.391749382019043, 'learning_rate': 9.06271186440678e-06, 'epoch': 0.11}
 11%|â–ˆ         | 653/6000 [38:15<5:15:27,  3.54s/it] 11%|â–ˆ         | 654/6000 [38:18<5:10:13,  3.48s/it]                                                    {'loss': 0.0267, 'grad_norm': 8.112552642822266, 'learning_rate': 9.061016949152543e-06, 'epoch': 0.11}
 11%|â–ˆ         | 654/6000 [38:18<5:10:13,  3.48s/it] 11%|â–ˆ         | 655/6000 [38:22<5:06:10,  3.44s/it]                                                    {'loss': 0.0361, 'grad_norm': 3.3409225940704346, 'learning_rate': 9.059322033898306e-06, 'epoch': 0.11}
 11%|â–ˆ         | 655/6000 [38:22<5:06:10,  3.44s/it] 11%|â–ˆ         | 656/6000 [38:25<5:04:30,  3.42s/it]                                                    {'loss': 0.1905, 'grad_norm': 19.845121383666992, 'learning_rate': 9.05762711864407e-06, 'epoch': 0.11}
 11%|â–ˆ         | 656/6000 [38:25<5:04:30,  3.42s/it] 11%|â–ˆ         | 657/6000 [38:29<5:08:43,  3.47s/it]                                                    {'loss': 0.189, 'grad_norm': 18.363916397094727, 'learning_rate': 9.05593220338983e-06, 'epoch': 0.11}
 11%|â–ˆ         | 657/6000 [38:29<5:08:43,  3.47s/it] 11%|â–ˆ         | 658/6000 [38:32<5:16:46,  3.56s/it]                                                    {'loss': 0.0211, 'grad_norm': 6.969398021697998, 'learning_rate': 9.054237288135594e-06, 'epoch': 0.11}
 11%|â–ˆ         | 658/6000 [38:32<5:16:46,  3.56s/it] 11%|â–ˆ         | 659/6000 [38:36<5:10:55,  3.49s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.4292683005332947, 'learning_rate': 9.052542372881357e-06, 'epoch': 0.11}
 11%|â–ˆ         | 659/6000 [38:36<5:10:55,  3.49s/it] 11%|â–ˆ         | 660/6000 [38:39<5:09:09,  3.47s/it]                                                    {'loss': 0.0056, 'grad_norm': 1.2352032661437988, 'learning_rate': 9.05084745762712e-06, 'epoch': 0.11}
 11%|â–ˆ         | 660/6000 [38:39<5:09:09,  3.47s/it] 11%|â–ˆ         | 661/6000 [38:42<5:05:20,  3.43s/it]                                                    {'loss': 0.0069, 'grad_norm': 2.2262308597564697, 'learning_rate': 9.049152542372882e-06, 'epoch': 0.11}
 11%|â–ˆ         | 661/6000 [38:42<5:05:20,  3.43s/it] 11%|â–ˆ         | 662/6000 [38:46<5:09:26,  3.48s/it]                                                    {'loss': 0.0539, 'grad_norm': 16.25982093811035, 'learning_rate': 9.047457627118644e-06, 'epoch': 0.11}
 11%|â–ˆ         | 662/6000 [38:46<5:09:26,  3.48s/it] 11%|â–ˆ         | 663/6000 [38:49<5:04:59,  3.43s/it]                                                    {'loss': 0.1595, 'grad_norm': 15.137060165405273, 'learning_rate': 9.045762711864407e-06, 'epoch': 0.11}
 11%|â–ˆ         | 663/6000 [38:49<5:04:59,  3.43s/it] 11%|â–ˆ         | 664/6000 [38:53<5:06:43,  3.45s/it]                                                    {'loss': 0.0194, 'grad_norm': 6.805805206298828, 'learning_rate': 9.04406779661017e-06, 'epoch': 0.11}
 11%|â–ˆ         | 664/6000 [38:53<5:06:43,  3.45s/it] 11%|â–ˆ         | 665/6000 [38:56<5:06:41,  3.45s/it]                                                    {'loss': 0.0746, 'grad_norm': 9.363780975341797, 'learning_rate': 9.042372881355934e-06, 'epoch': 0.11}
 11%|â–ˆ         | 665/6000 [38:56<5:06:41,  3.45s/it] 11%|â–ˆ         | 666/6000 [39:00<5:07:51,  3.46s/it]                                                    {'loss': 0.0383, 'grad_norm': 3.761864423751831, 'learning_rate': 9.040677966101695e-06, 'epoch': 0.11}
 11%|â–ˆ         | 666/6000 [39:00<5:07:51,  3.46s/it] 11%|â–ˆ         | 667/6000 [39:03<5:10:38,  3.49s/it]                                                    {'loss': 0.0963, 'grad_norm': 11.554121971130371, 'learning_rate': 9.038983050847458e-06, 'epoch': 0.11}
 11%|â–ˆ         | 667/6000 [39:03<5:10:38,  3.49s/it] 11%|â–ˆ         | 668/6000 [39:07<5:08:41,  3.47s/it]                                                    {'loss': 0.111, 'grad_norm': 19.918622970581055, 'learning_rate': 9.03728813559322e-06, 'epoch': 0.11}
 11%|â–ˆ         | 668/6000 [39:07<5:08:41,  3.47s/it] 11%|â–ˆ         | 669/6000 [39:10<5:05:37,  3.44s/it]                                                    {'loss': 0.0118, 'grad_norm': 2.37925124168396, 'learning_rate': 9.035593220338983e-06, 'epoch': 0.11}
 11%|â–ˆ         | 669/6000 [39:10<5:05:37,  3.44s/it] 11%|â–ˆ         | 670/6000 [39:14<5:10:01,  3.49s/it]                                                    {'loss': 0.0729, 'grad_norm': 13.482390403747559, 'learning_rate': 9.033898305084747e-06, 'epoch': 0.11}
 11%|â–ˆ         | 670/6000 [39:14<5:10:01,  3.49s/it] 11%|â–ˆ         | 671/6000 [39:17<5:07:50,  3.47s/it]                                                    {'loss': 0.0225, 'grad_norm': 2.5236854553222656, 'learning_rate': 9.03220338983051e-06, 'epoch': 0.11}
 11%|â–ˆ         | 671/6000 [39:17<5:07:50,  3.47s/it] 11%|â–ˆ         | 672/6000 [39:20<5:03:52,  3.42s/it]                                                    {'loss': 0.1178, 'grad_norm': 17.96527862548828, 'learning_rate': 9.030508474576271e-06, 'epoch': 0.11}
 11%|â–ˆ         | 672/6000 [39:20<5:03:52,  3.42s/it] 11%|â–ˆ         | 673/6000 [39:24<5:04:08,  3.43s/it]                                                    {'loss': 0.0695, 'grad_norm': 13.178753852844238, 'learning_rate': 9.028813559322035e-06, 'epoch': 0.11}
 11%|â–ˆ         | 673/6000 [39:24<5:04:08,  3.43s/it] 11%|â–ˆ         | 674/6000 [39:27<5:01:54,  3.40s/it]                                                    {'loss': 0.069, 'grad_norm': 9.229924201965332, 'learning_rate': 9.027118644067796e-06, 'epoch': 0.11}
 11%|â–ˆ         | 674/6000 [39:27<5:01:54,  3.40s/it] 11%|â–ˆâ–        | 675/6000 [39:31<5:01:50,  3.40s/it]                                                    {'loss': 0.2103, 'grad_norm': 24.10590934753418, 'learning_rate': 9.02542372881356e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 675/6000 [39:31<5:01:50,  3.40s/it] 11%|â–ˆâ–        | 676/6000 [39:34<5:03:29,  3.42s/it]                                                    {'loss': 0.0446, 'grad_norm': 4.226205348968506, 'learning_rate': 9.023728813559323e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 676/6000 [39:34<5:03:29,  3.42s/it] 11%|â–ˆâ–        | 677/6000 [39:37<5:01:34,  3.40s/it]                                                    {'loss': 0.0619, 'grad_norm': 14.060004234313965, 'learning_rate': 9.022033898305086e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 677/6000 [39:37<5:01:34,  3.40s/it] 11%|â–ˆâ–        | 678/6000 [39:41<5:02:49,  3.41s/it]                                                    {'loss': 0.0244, 'grad_norm': 4.458028316497803, 'learning_rate': 9.020338983050848e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 678/6000 [39:41<5:02:49,  3.41s/it] 11%|â–ˆâ–        | 679/6000 [39:44<4:59:52,  3.38s/it]                                                    {'loss': 0.0677, 'grad_norm': 13.826725959777832, 'learning_rate': 9.018644067796611e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 679/6000 [39:44<4:59:52,  3.38s/it] 11%|â–ˆâ–        | 680/6000 [39:48<5:01:04,  3.40s/it]                                                    {'loss': 0.0277, 'grad_norm': 7.739563941955566, 'learning_rate': 9.016949152542374e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 680/6000 [39:48<5:01:04,  3.40s/it] 11%|â–ˆâ–        | 681/6000 [39:51<5:12:39,  3.53s/it]                                                    {'loss': 0.0295, 'grad_norm': 6.543615341186523, 'learning_rate': 9.015254237288138e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 681/6000 [39:51<5:12:39,  3.53s/it] 11%|â–ˆâ–        | 682/6000 [39:55<5:12:19,  3.52s/it]                                                    {'loss': 0.0311, 'grad_norm': 8.397027969360352, 'learning_rate': 9.013559322033899e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 682/6000 [39:55<5:12:19,  3.52s/it] 11%|â–ˆâ–        | 683/6000 [39:58<5:10:32,  3.50s/it]                                                    {'loss': 0.1384, 'grad_norm': 14.480545043945312, 'learning_rate': 9.01186440677966e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 683/6000 [39:58<5:10:32,  3.50s/it] 11%|â–ˆâ–        | 684/6000 [40:02<5:06:47,  3.46s/it]                                                    {'loss': 0.1431, 'grad_norm': 16.0830020904541, 'learning_rate': 9.010169491525424e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 684/6000 [40:02<5:06:47,  3.46s/it] 11%|â–ˆâ–        | 685/6000 [40:05<5:04:46,  3.44s/it]                                                    {'loss': 0.0584, 'grad_norm': 16.145854949951172, 'learning_rate': 9.008474576271187e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 685/6000 [40:05<5:04:46,  3.44s/it] 11%|â–ˆâ–        | 686/6000 [40:09<5:20:44,  3.62s/it]                                                    {'loss': 0.1015, 'grad_norm': 14.804529190063477, 'learning_rate': 9.00677966101695e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 686/6000 [40:09<5:20:44,  3.62s/it] 11%|â–ˆâ–        | 687/6000 [40:13<5:12:53,  3.53s/it]                                                    {'loss': 0.002, 'grad_norm': 0.9711830019950867, 'learning_rate': 9.005084745762712e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 687/6000 [40:13<5:12:53,  3.53s/it] 11%|â–ˆâ–        | 688/6000 [40:16<5:08:32,  3.49s/it]                                                    {'loss': 0.0202, 'grad_norm': 4.515558242797852, 'learning_rate': 9.003389830508475e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 688/6000 [40:16<5:08:32,  3.49s/it] 11%|â–ˆâ–        | 689/6000 [40:19<5:05:34,  3.45s/it]                                                    {'loss': 0.1891, 'grad_norm': 22.35257339477539, 'learning_rate': 9.001694915254237e-06, 'epoch': 0.11}
 11%|â–ˆâ–        | 689/6000 [40:19<5:05:34,  3.45s/it] 12%|â–ˆâ–        | 690/6000 [40:23<5:03:47,  3.43s/it]                                                    {'loss': 0.0918, 'grad_norm': 11.285022735595703, 'learning_rate': 9e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 690/6000 [40:23<5:03:47,  3.43s/it] 12%|â–ˆâ–        | 691/6000 [40:26<5:05:15,  3.45s/it]                                                    {'loss': 0.0262, 'grad_norm': 4.649247169494629, 'learning_rate': 8.998305084745764e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 691/6000 [40:26<5:05:15,  3.45s/it] 12%|â–ˆâ–        | 692/6000 [40:30<5:05:14,  3.45s/it]                                                    {'loss': 0.3106, 'grad_norm': 22.650745391845703, 'learning_rate': 8.996610169491527e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 692/6000 [40:30<5:05:14,  3.45s/it] 12%|â–ˆâ–        | 693/6000 [40:33<5:07:49,  3.48s/it]                                                    {'loss': 0.1055, 'grad_norm': 15.667159080505371, 'learning_rate': 8.994915254237288e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 693/6000 [40:33<5:07:49,  3.48s/it] 12%|â–ˆâ–        | 694/6000 [40:37<5:05:10,  3.45s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.7412298321723938, 'learning_rate': 8.993220338983052e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 694/6000 [40:37<5:05:10,  3.45s/it] 12%|â–ˆâ–        | 695/6000 [40:40<5:03:59,  3.44s/it]                                                    {'loss': 0.0091, 'grad_norm': 1.7163621187210083, 'learning_rate': 8.991525423728815e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 695/6000 [40:40<5:03:59,  3.44s/it] 12%|â–ˆâ–        | 696/6000 [40:44<5:12:18,  3.53s/it]                                                    {'loss': 0.1003, 'grad_norm': 17.63218879699707, 'learning_rate': 8.989830508474578e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 696/6000 [40:44<5:12:18,  3.53s/it] 12%|â–ˆâ–        | 697/6000 [40:47<5:10:54,  3.52s/it]                                                    {'loss': 0.0817, 'grad_norm': 16.46300506591797, 'learning_rate': 8.98813559322034e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 697/6000 [40:47<5:10:54,  3.52s/it] 12%|â–ˆâ–        | 698/6000 [40:51<5:08:58,  3.50s/it]                                                    {'loss': 0.066, 'grad_norm': 14.359464645385742, 'learning_rate': 8.986440677966103e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 698/6000 [40:51<5:08:58,  3.50s/it] 12%|â–ˆâ–        | 699/6000 [40:54<5:08:11,  3.49s/it]                                                    {'loss': 0.0405, 'grad_norm': 9.071115493774414, 'learning_rate': 8.984745762711865e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 699/6000 [40:54<5:08:11,  3.49s/it] 12%|â–ˆâ–        | 700/6000 [40:58<5:09:05,  3.50s/it]                                                    {'loss': 0.0097, 'grad_norm': 2.124324083328247, 'learning_rate': 8.983050847457628e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 700/6000 [40:58<5:09:05,  3.50s/it][2025-11-06 23:32:07,642] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700
[2025-11-06 23:32:07,655] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:32:08,316] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|â–ˆâ–        | 701/6000 [41:03<6:11:18,  4.20s/it]                                                    {'loss': 0.0141, 'grad_norm': 4.226707458496094, 'learning_rate': 8.981355932203391e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 701/6000 [41:04<6:11:18,  4.20s/it] 12%|â–ˆâ–        | 702/6000 [41:07<6:03:59,  4.12s/it]                                                    {'loss': 0.0602, 'grad_norm': 11.066707611083984, 'learning_rate': 8.979661016949154e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 702/6000 [41:07<6:03:59,  4.12s/it] 12%|â–ˆâ–        | 703/6000 [41:11<5:45:35,  3.91s/it]                                                    {'loss': 0.0393, 'grad_norm': 10.275562286376953, 'learning_rate': 8.977966101694916e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 703/6000 [41:11<5:45:35,  3.91s/it] 12%|â–ˆâ–        | 704/6000 [41:15<5:44:43,  3.91s/it]                                                    {'loss': 0.0058, 'grad_norm': 1.2216134071350098, 'learning_rate': 8.976271186440678e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 704/6000 [41:15<5:44:43,  3.91s/it] 12%|â–ˆâ–        | 705/6000 [41:18<5:33:19,  3.78s/it]                                                    {'loss': 0.2132, 'grad_norm': 21.680198669433594, 'learning_rate': 8.974576271186441e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 705/6000 [41:18<5:33:19,  3.78s/it] 12%|â–ˆâ–        | 706/6000 [41:22<5:22:27,  3.65s/it]                                                    {'loss': 0.0775, 'grad_norm': 6.71514892578125, 'learning_rate': 8.972881355932204e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 706/6000 [41:22<5:22:27,  3.65s/it] 12%|â–ˆâ–        | 707/6000 [41:25<5:17:03,  3.59s/it]                                                    {'loss': 0.036, 'grad_norm': 11.631183624267578, 'learning_rate': 8.971186440677967e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 707/6000 [41:25<5:17:03,  3.59s/it] 12%|â–ˆâ–        | 708/6000 [41:28<5:12:03,  3.54s/it]                                                    {'loss': 0.0319, 'grad_norm': 7.69635534286499, 'learning_rate': 8.969491525423729e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 708/6000 [41:28<5:12:03,  3.54s/it] 12%|â–ˆâ–        | 709/6000 [41:32<5:10:32,  3.52s/it]                                                    {'loss': 0.1447, 'grad_norm': 16.850191116333008, 'learning_rate': 8.967796610169492e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 709/6000 [41:32<5:10:32,  3.52s/it] 12%|â–ˆâ–        | 710/6000 [41:36<5:16:30,  3.59s/it]                                                    {'loss': 0.0359, 'grad_norm': 8.27399730682373, 'learning_rate': 8.966101694915254e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 710/6000 [41:36<5:16:30,  3.59s/it] 12%|â–ˆâ–        | 711/6000 [41:39<5:11:11,  3.53s/it]                                                    {'loss': 0.0008, 'grad_norm': 0.4060150384902954, 'learning_rate': 8.964406779661017e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 711/6000 [41:39<5:11:11,  3.53s/it] 12%|â–ˆâ–        | 712/6000 [41:43<5:10:55,  3.53s/it]                                                    {'loss': 0.0121, 'grad_norm': 2.6134192943573, 'learning_rate': 8.96271186440678e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 712/6000 [41:43<5:10:55,  3.53s/it] 12%|â–ˆâ–        | 713/6000 [41:46<5:07:24,  3.49s/it]                                                    {'loss': 0.0916, 'grad_norm': 13.353532791137695, 'learning_rate': 8.961016949152544e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 713/6000 [41:46<5:07:24,  3.49s/it] 12%|â–ˆâ–        | 714/6000 [41:49<5:05:21,  3.47s/it]                                                    {'loss': 0.0153, 'grad_norm': 4.533115386962891, 'learning_rate': 8.959322033898305e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 714/6000 [41:49<5:05:21,  3.47s/it] 12%|â–ˆâ–        | 715/6000 [41:53<5:03:14,  3.44s/it]                                                    {'loss': 0.0155, 'grad_norm': 5.772280216217041, 'learning_rate': 8.957627118644069e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 715/6000 [41:53<5:03:14,  3.44s/it] 12%|â–ˆâ–        | 716/6000 [41:56<5:00:53,  3.42s/it]                                                    {'loss': 0.0702, 'grad_norm': 14.84269905090332, 'learning_rate': 8.955932203389832e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 716/6000 [41:56<5:00:53,  3.42s/it] 12%|â–ˆâ–        | 717/6000 [42:00<5:11:05,  3.53s/it]                                                    {'loss': 0.1708, 'grad_norm': 21.659208297729492, 'learning_rate': 8.954237288135595e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 717/6000 [42:00<5:11:05,  3.53s/it] 12%|â–ˆâ–        | 718/6000 [42:03<5:05:21,  3.47s/it]                                                    {'loss': 0.0323, 'grad_norm': 7.183841705322266, 'learning_rate': 8.952542372881357e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 718/6000 [42:03<5:05:21,  3.47s/it] 12%|â–ˆâ–        | 719/6000 [42:07<5:06:21,  3.48s/it]                                                    {'loss': 0.0382, 'grad_norm': 11.045896530151367, 'learning_rate': 8.95084745762712e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 719/6000 [42:07<5:06:21,  3.48s/it] 12%|â–ˆâ–        | 720/6000 [42:10<5:02:03,  3.43s/it]                                                    {'loss': 0.0048, 'grad_norm': 1.3730634450912476, 'learning_rate': 8.949152542372881e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 720/6000 [42:10<5:02:03,  3.43s/it] 12%|â–ˆâ–        | 721/6000 [42:14<5:05:53,  3.48s/it]                                                    {'loss': 0.0645, 'grad_norm': 12.98554801940918, 'learning_rate': 8.947457627118645e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 721/6000 [42:14<5:05:53,  3.48s/it] 12%|â–ˆâ–        | 722/6000 [42:17<5:07:05,  3.49s/it]                                                    {'loss': 0.1042, 'grad_norm': 12.446500778198242, 'learning_rate': 8.945762711864408e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 722/6000 [42:17<5:07:05,  3.49s/it] 12%|â–ˆâ–        | 723/6000 [42:21<5:19:05,  3.63s/it]                                                    {'loss': 0.0372, 'grad_norm': 9.193243980407715, 'learning_rate': 8.944067796610171e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 723/6000 [42:21<5:19:05,  3.63s/it] 12%|â–ˆâ–        | 724/6000 [42:25<5:11:41,  3.54s/it]                                                    {'loss': 0.1169, 'grad_norm': 15.499258995056152, 'learning_rate': 8.942372881355933e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 724/6000 [42:25<5:11:41,  3.54s/it] 12%|â–ˆâ–        | 725/6000 [42:28<5:06:47,  3.49s/it]                                                    {'loss': 0.101, 'grad_norm': 16.7771053314209, 'learning_rate': 8.940677966101694e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 725/6000 [42:28<5:06:47,  3.49s/it] 12%|â–ˆâ–        | 726/6000 [42:31<5:04:05,  3.46s/it]                                                    {'loss': 0.0172, 'grad_norm': 3.8418405055999756, 'learning_rate': 8.938983050847458e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 726/6000 [42:31<5:04:05,  3.46s/it] 12%|â–ˆâ–        | 727/6000 [42:35<5:01:33,  3.43s/it]                                                    {'loss': 0.1843, 'grad_norm': 19.376768112182617, 'learning_rate': 8.937288135593221e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 727/6000 [42:35<5:01:33,  3.43s/it] 12%|â–ˆâ–        | 728/6000 [42:38<5:00:16,  3.42s/it]                                                    {'loss': 0.0533, 'grad_norm': 41.55176544189453, 'learning_rate': 8.935593220338984e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 728/6000 [42:38<5:00:16,  3.42s/it] 12%|â–ˆâ–        | 729/6000 [42:41<4:59:49,  3.41s/it]                                                    {'loss': 0.009, 'grad_norm': 2.4241223335266113, 'learning_rate': 8.933898305084746e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 729/6000 [42:41<4:59:49,  3.41s/it] 12%|â–ˆâ–        | 730/6000 [42:45<4:57:00,  3.38s/it]                                                    {'loss': 0.1416, 'grad_norm': 8.83165454864502, 'learning_rate': 8.932203389830509e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 730/6000 [42:45<4:57:00,  3.38s/it] 12%|â–ˆâ–        | 731/6000 [42:48<4:55:15,  3.36s/it]                                                    {'loss': 0.0066, 'grad_norm': 1.9440221786499023, 'learning_rate': 8.93050847457627e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 731/6000 [42:48<4:55:15,  3.36s/it] 12%|â–ˆâ–        | 732/6000 [42:52<4:59:47,  3.41s/it]                                                    {'loss': 0.0906, 'grad_norm': 12.397647857666016, 'learning_rate': 8.928813559322036e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 732/6000 [42:52<4:59:47,  3.41s/it] 12%|â–ˆâ–        | 733/6000 [42:55<5:05:20,  3.48s/it]                                                    {'loss': 0.0398, 'grad_norm': 12.174944877624512, 'learning_rate': 8.927118644067797e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 733/6000 [42:55<5:05:20,  3.48s/it] 12%|â–ˆâ–        | 734/6000 [42:59<5:18:21,  3.63s/it]                                                    {'loss': 0.0024, 'grad_norm': 0.8457428812980652, 'learning_rate': 8.92542372881356e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 734/6000 [42:59<5:18:21,  3.63s/it] 12%|â–ˆâ–        | 735/6000 [43:03<5:12:20,  3.56s/it]                                                    {'loss': 0.0041, 'grad_norm': 1.5383220911026, 'learning_rate': 8.923728813559322e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 735/6000 [43:03<5:12:20,  3.56s/it] 12%|â–ˆâ–        | 736/6000 [43:06<5:05:36,  3.48s/it]                                                    {'loss': 0.0411, 'grad_norm': 5.979902267456055, 'learning_rate': 8.922033898305085e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 736/6000 [43:06<5:05:36,  3.48s/it] 12%|â–ˆâ–        | 737/6000 [43:09<5:04:43,  3.47s/it]                                                    {'loss': 0.0718, 'grad_norm': 10.988030433654785, 'learning_rate': 8.920338983050849e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 737/6000 [43:09<5:04:43,  3.47s/it] 12%|â–ˆâ–        | 738/6000 [43:13<5:00:13,  3.42s/it]                                                    {'loss': 0.2767, 'grad_norm': 23.0842342376709, 'learning_rate': 8.918644067796612e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 738/6000 [43:13<5:00:13,  3.42s/it] 12%|â–ˆâ–        | 739/6000 [43:16<5:00:57,  3.43s/it]                                                    {'loss': 0.0233, 'grad_norm': 2.310586929321289, 'learning_rate': 8.916949152542374e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 739/6000 [43:16<5:00:57,  3.43s/it] 12%|â–ˆâ–        | 740/6000 [43:20<5:01:59,  3.44s/it]                                                    {'loss': 0.2896, 'grad_norm': 21.653886795043945, 'learning_rate': 8.915254237288137e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 740/6000 [43:20<5:01:59,  3.44s/it] 12%|â–ˆâ–        | 741/6000 [43:23<5:03:06,  3.46s/it]                                                    {'loss': 0.0781, 'grad_norm': 12.585905075073242, 'learning_rate': 8.913559322033898e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 741/6000 [43:23<5:03:06,  3.46s/it] 12%|â–ˆâ–        | 742/6000 [43:26<5:00:16,  3.43s/it]                                                    {'loss': 0.0099, 'grad_norm': 2.9323320388793945, 'learning_rate': 8.911864406779662e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 742/6000 [43:26<5:00:16,  3.43s/it] 12%|â–ˆâ–        | 743/6000 [43:30<4:55:39,  3.37s/it]                                                    {'loss': 0.0353, 'grad_norm': 9.198104858398438, 'learning_rate': 8.910169491525425e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 743/6000 [43:30<4:55:39,  3.37s/it] 12%|â–ˆâ–        | 744/6000 [43:33<4:53:38,  3.35s/it]                                                    {'loss': 0.0072, 'grad_norm': 1.0622700452804565, 'learning_rate': 8.908474576271188e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 744/6000 [43:33<4:53:38,  3.35s/it] 12%|â–ˆâ–        | 745/6000 [43:36<4:52:50,  3.34s/it]                                                    {'loss': 0.215, 'grad_norm': 16.07279396057129, 'learning_rate': 8.90677966101695e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 745/6000 [43:36<4:52:50,  3.34s/it] 12%|â–ˆâ–        | 746/6000 [43:40<4:54:12,  3.36s/it]                                                    {'loss': 0.322, 'grad_norm': 18.271242141723633, 'learning_rate': 8.905084745762711e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 746/6000 [43:40<4:54:12,  3.36s/it] 12%|â–ˆâ–        | 747/6000 [43:43<5:01:45,  3.45s/it]                                                    {'loss': 0.0915, 'grad_norm': 20.18096351623535, 'learning_rate': 8.903389830508475e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 747/6000 [43:43<5:01:45,  3.45s/it] 12%|â–ˆâ–        | 748/6000 [43:47<5:03:12,  3.46s/it]                                                    {'loss': 0.1394, 'grad_norm': 17.715974807739258, 'learning_rate': 8.901694915254238e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 748/6000 [43:47<5:03:12,  3.46s/it] 12%|â–ˆâ–        | 749/6000 [43:51<5:24:04,  3.70s/it]                                                    {'loss': 0.2003, 'grad_norm': 22.079387664794922, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.12}
 12%|â–ˆâ–        | 749/6000 [43:51<5:24:04,  3.70s/it] 12%|â–ˆâ–Ž        | 750/6000 [43:55<5:25:32,  3.72s/it]                                                    {'loss': 0.2089, 'grad_norm': 17.147001266479492, 'learning_rate': 8.898305084745763e-06, 'epoch': 0.12}
 12%|â–ˆâ–Ž        | 750/6000 [43:55<5:25:32,  3.72s/it] 13%|â–ˆâ–Ž        | 751/6000 [43:58<5:17:04,  3.62s/it]                                                    {'loss': 0.0268, 'grad_norm': 3.388516902923584, 'learning_rate': 8.896610169491526e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 751/6000 [43:58<5:17:04,  3.62s/it] 13%|â–ˆâ–Ž        | 752/6000 [44:02<5:23:57,  3.70s/it]                                                    {'loss': 0.0433, 'grad_norm': 8.706554412841797, 'learning_rate': 8.89491525423729e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 752/6000 [44:02<5:23:57,  3.70s/it] 13%|â–ˆâ–Ž        | 753/6000 [44:06<5:19:08,  3.65s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.8156498074531555, 'learning_rate': 8.893220338983053e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 753/6000 [44:06<5:19:08,  3.65s/it] 13%|â–ˆâ–Ž        | 754/6000 [44:09<5:13:45,  3.59s/it]                                                    {'loss': 0.0834, 'grad_norm': 9.140738487243652, 'learning_rate': 8.891525423728814e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 754/6000 [44:09<5:13:45,  3.59s/it] 13%|â–ˆâ–Ž        | 755/6000 [44:12<5:07:24,  3.52s/it]                                                    {'loss': 0.0048, 'grad_norm': 1.4806638956069946, 'learning_rate': 8.889830508474577e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 755/6000 [44:12<5:07:24,  3.52s/it] 13%|â–ˆâ–Ž        | 756/6000 [44:16<5:02:07,  3.46s/it]                                                    {'loss': 0.0009, 'grad_norm': 0.29470494389533997, 'learning_rate': 8.888135593220339e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 756/6000 [44:16<5:02:07,  3.46s/it] 13%|â–ˆâ–Ž        | 757/6000 [44:19<5:07:04,  3.51s/it]                                                    {'loss': 0.0169, 'grad_norm': 3.7740700244903564, 'learning_rate': 8.886440677966102e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 757/6000 [44:19<5:07:04,  3.51s/it] 13%|â–ˆâ–Ž        | 758/6000 [44:23<5:05:04,  3.49s/it]                                                    {'loss': 0.1173, 'grad_norm': 14.3644437789917, 'learning_rate': 8.884745762711866e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 758/6000 [44:23<5:05:04,  3.49s/it] 13%|â–ˆâ–Ž        | 759/6000 [44:26<5:00:20,  3.44s/it]                                                    {'loss': 0.2665, 'grad_norm': 19.73687171936035, 'learning_rate': 8.883050847457629e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 759/6000 [44:26<5:00:20,  3.44s/it] 13%|â–ˆâ–Ž        | 760/6000 [44:30<4:59:32,  3.43s/it]                                                    {'loss': 0.0125, 'grad_norm': 3.4316635131835938, 'learning_rate': 8.88135593220339e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 760/6000 [44:30<4:59:32,  3.43s/it] 13%|â–ˆâ–Ž        | 761/6000 [44:33<4:59:26,  3.43s/it]                                                    {'loss': 0.0733, 'grad_norm': 8.214158058166504, 'learning_rate': 8.879661016949154e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 761/6000 [44:33<4:59:26,  3.43s/it] 13%|â–ˆâ–Ž        | 762/6000 [44:37<5:04:07,  3.48s/it]                                                    {'loss': 0.0259, 'grad_norm': 7.228366851806641, 'learning_rate': 8.877966101694915e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 762/6000 [44:37<5:04:07,  3.48s/it] 13%|â–ˆâ–Ž        | 763/6000 [44:40<5:00:34,  3.44s/it]                                                    {'loss': 0.1872, 'grad_norm': 13.468259811401367, 'learning_rate': 8.876271186440679e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 763/6000 [44:40<5:00:34,  3.44s/it] 13%|â–ˆâ–Ž        | 764/6000 [44:43<4:57:33,  3.41s/it]                                                    {'loss': 0.0462, 'grad_norm': 10.86391544342041, 'learning_rate': 8.874576271186442e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 764/6000 [44:43<4:57:33,  3.41s/it] 13%|â–ˆâ–Ž        | 765/6000 [44:47<4:55:06,  3.38s/it]                                                    {'loss': 0.0339, 'grad_norm': 6.149917125701904, 'learning_rate': 8.872881355932203e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 765/6000 [44:47<4:55:06,  3.38s/it] 13%|â–ˆâ–Ž        | 766/6000 [44:50<4:57:40,  3.41s/it]                                                    {'loss': 0.0005, 'grad_norm': 0.1044035479426384, 'learning_rate': 8.871186440677967e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 766/6000 [44:50<4:57:40,  3.41s/it] 13%|â–ˆâ–Ž        | 767/6000 [44:54<5:08:06,  3.53s/it]                                                    {'loss': 0.0043, 'grad_norm': 1.531086802482605, 'learning_rate': 8.869491525423728e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 767/6000 [44:54<5:08:06,  3.53s/it] 13%|â–ˆâ–Ž        | 768/6000 [44:57<5:04:47,  3.50s/it]                                                    {'loss': 0.0029, 'grad_norm': 1.100304126739502, 'learning_rate': 8.867796610169492e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 768/6000 [44:57<5:04:47,  3.50s/it] 13%|â–ˆâ–Ž        | 769/6000 [45:01<5:09:51,  3.55s/it]                                                    {'loss': 0.0349, 'grad_norm': 2.8576581478118896, 'learning_rate': 8.866101694915255e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 769/6000 [45:01<5:09:51,  3.55s/it] 13%|â–ˆâ–Ž        | 770/6000 [45:04<5:05:38,  3.51s/it]                                                    {'loss': 0.2374, 'grad_norm': 22.335063934326172, 'learning_rate': 8.864406779661018e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 770/6000 [45:04<5:05:38,  3.51s/it] 13%|â–ˆâ–Ž        | 771/6000 [45:08<5:06:04,  3.51s/it]                                                    {'loss': 0.0072, 'grad_norm': 2.1832468509674072, 'learning_rate': 8.86271186440678e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 771/6000 [45:08<5:06:04,  3.51s/it] 13%|â–ˆâ–Ž        | 772/6000 [45:11<5:01:57,  3.47s/it]                                                    {'loss': 0.0268, 'grad_norm': 10.976755142211914, 'learning_rate': 8.861016949152543e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 772/6000 [45:11<5:01:57,  3.47s/it] 13%|â–ˆâ–Ž        | 773/6000 [45:15<4:59:31,  3.44s/it]                                                    {'loss': 0.1891, 'grad_norm': 18.363967895507812, 'learning_rate': 8.859322033898306e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 773/6000 [45:15<4:59:31,  3.44s/it] 13%|â–ˆâ–Ž        | 774/6000 [45:18<4:58:17,  3.42s/it]                                                    {'loss': 0.008, 'grad_norm': 2.1216211318969727, 'learning_rate': 8.85762711864407e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 774/6000 [45:18<4:58:17,  3.42s/it] 13%|â–ˆâ–Ž        | 775/6000 [45:22<5:03:00,  3.48s/it]                                                    {'loss': 0.0107, 'grad_norm': 3.2976901531219482, 'learning_rate': 8.855932203389831e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 775/6000 [45:22<5:03:00,  3.48s/it] 13%|â–ˆâ–Ž        | 776/6000 [45:25<5:02:45,  3.48s/it]                                                    {'loss': 0.0637, 'grad_norm': 13.341501235961914, 'learning_rate': 8.854237288135594e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 776/6000 [45:25<5:02:45,  3.48s/it] 13%|â–ˆâ–Ž        | 777/6000 [45:29<5:07:02,  3.53s/it]                                                    {'loss': 0.0176, 'grad_norm': 4.966181755065918, 'learning_rate': 8.852542372881356e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 777/6000 [45:29<5:07:02,  3.53s/it] 13%|â–ˆâ–Ž        | 778/6000 [45:32<5:11:17,  3.58s/it]                                                    {'loss': 0.1675, 'grad_norm': 19.375320434570312, 'learning_rate': 8.85084745762712e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 778/6000 [45:32<5:11:17,  3.58s/it] 13%|â–ˆâ–Ž        | 779/6000 [45:36<5:05:23,  3.51s/it]                                                    {'loss': 0.0717, 'grad_norm': 13.096980094909668, 'learning_rate': 8.849152542372882e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 779/6000 [45:36<5:05:23,  3.51s/it] 13%|â–ˆâ–Ž        | 780/6000 [45:39<5:02:32,  3.48s/it]                                                    {'loss': 0.0061, 'grad_norm': 1.417306900024414, 'learning_rate': 8.847457627118646e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 780/6000 [45:39<5:02:32,  3.48s/it] 13%|â–ˆâ–Ž        | 781/6000 [45:43<5:01:56,  3.47s/it]                                                    {'loss': 0.024, 'grad_norm': 9.058756828308105, 'learning_rate': 8.845762711864407e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 781/6000 [45:43<5:01:56,  3.47s/it] 13%|â–ˆâ–Ž        | 782/6000 [45:46<4:59:10,  3.44s/it]                                                    {'loss': 0.0448, 'grad_norm': 12.245977401733398, 'learning_rate': 8.84406779661017e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 782/6000 [45:46<4:59:10,  3.44s/it] 13%|â–ˆâ–Ž        | 783/6000 [45:49<4:56:24,  3.41s/it]                                                    {'loss': 0.0962, 'grad_norm': 14.833234786987305, 'learning_rate': 8.842372881355932e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 783/6000 [45:49<4:56:24,  3.41s/it] 13%|â–ˆâ–Ž        | 784/6000 [45:53<4:54:43,  3.39s/it]                                                    {'loss': 0.0961, 'grad_norm': 12.083121299743652, 'learning_rate': 8.840677966101695e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 784/6000 [45:53<4:54:43,  3.39s/it] 13%|â–ˆâ–Ž        | 785/6000 [45:56<4:52:58,  3.37s/it]                                                    {'loss': 0.3608, 'grad_norm': 26.24221420288086, 'learning_rate': 8.838983050847459e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 785/6000 [45:56<4:52:58,  3.37s/it] 13%|â–ˆâ–Ž        | 786/6000 [45:59<4:52:13,  3.36s/it]                                                    {'loss': 0.0792, 'grad_norm': 16.34709358215332, 'learning_rate': 8.83728813559322e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 786/6000 [45:59<4:52:13,  3.36s/it] 13%|â–ˆâ–Ž        | 787/6000 [46:03<4:53:14,  3.38s/it]                                                    {'loss': 0.0229, 'grad_norm': 6.629960536956787, 'learning_rate': 8.835593220338984e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 787/6000 [46:03<4:53:14,  3.38s/it] 13%|â–ˆâ–Ž        | 788/6000 [46:06<4:53:28,  3.38s/it]                                                    {'loss': 0.0414, 'grad_norm': 7.615813732147217, 'learning_rate': 8.833898305084747e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 788/6000 [46:06<4:53:28,  3.38s/it] 13%|â–ˆâ–Ž        | 789/6000 [46:10<4:55:32,  3.40s/it]                                                    {'loss': 0.0568, 'grad_norm': 12.024971961975098, 'learning_rate': 8.83220338983051e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 789/6000 [46:10<4:55:32,  3.40s/it] 13%|â–ˆâ–Ž        | 790/6000 [46:13<4:53:12,  3.38s/it]                                                    {'loss': 0.1694, 'grad_norm': 17.236042022705078, 'learning_rate': 8.830508474576272e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 790/6000 [46:13<4:53:12,  3.38s/it] 13%|â–ˆâ–Ž        | 791/6000 [46:16<4:54:22,  3.39s/it]                                                    {'loss': 0.0397, 'grad_norm': 5.202035903930664, 'learning_rate': 8.828813559322035e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 791/6000 [46:16<4:54:22,  3.39s/it] 13%|â–ˆâ–Ž        | 792/6000 [46:20<4:55:18,  3.40s/it]                                                    {'loss': 0.1955, 'grad_norm': 21.215259552001953, 'learning_rate': 8.827118644067797e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 792/6000 [46:20<4:55:18,  3.40s/it] 13%|â–ˆâ–Ž        | 793/6000 [46:23<4:53:50,  3.39s/it]                                                    {'loss': 0.0045, 'grad_norm': 1.0094623565673828, 'learning_rate': 8.82542372881356e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 793/6000 [46:23<4:53:50,  3.39s/it] 13%|â–ˆâ–Ž        | 794/6000 [46:27<4:56:19,  3.42s/it]                                                    {'loss': 0.0101, 'grad_norm': 2.750046491622925, 'learning_rate': 8.823728813559323e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 794/6000 [46:27<4:56:19,  3.42s/it] 13%|â–ˆâ–Ž        | 795/6000 [46:30<5:04:36,  3.51s/it]                                                    {'loss': 0.0254, 'grad_norm': 7.440540313720703, 'learning_rate': 8.822033898305086e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 795/6000 [46:30<5:04:36,  3.51s/it] 13%|â–ˆâ–Ž        | 796/6000 [46:34<5:00:08,  3.46s/it]                                                    {'loss': 0.2077, 'grad_norm': 19.742610931396484, 'learning_rate': 8.820338983050848e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 796/6000 [46:34<5:00:08,  3.46s/it] 13%|â–ˆâ–Ž        | 797/6000 [46:37<4:59:54,  3.46s/it]                                                    {'loss': 0.0408, 'grad_norm': 10.866710662841797, 'learning_rate': 8.818644067796611e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 797/6000 [46:37<4:59:54,  3.46s/it] 13%|â–ˆâ–Ž        | 798/6000 [46:40<4:55:29,  3.41s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.5038508772850037, 'learning_rate': 8.816949152542373e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 798/6000 [46:40<4:55:29,  3.41s/it] 13%|â–ˆâ–Ž        | 799/6000 [46:44<4:56:18,  3.42s/it]                                                    {'loss': 0.1375, 'grad_norm': 16.514057159423828, 'learning_rate': 8.815254237288136e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 799/6000 [46:44<4:56:18,  3.42s/it] 13%|â–ˆâ–Ž        | 800/6000 [46:47<4:58:04,  3.44s/it]                                                    {'loss': 0.0235, 'grad_norm': 6.608599662780762, 'learning_rate': 8.8135593220339e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 800/6000 [46:47<4:58:04,  3.44s/it][2025-11-06 23:37:57,413] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800
[2025-11-06 23:37:57,425] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:37:58,081] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 801/6000 [46:53<5:57:52,  4.13s/it]                                                    {'loss': 0.0119, 'grad_norm': 3.881301164627075, 'learning_rate': 8.811864406779663e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 801/6000 [46:53<5:57:52,  4.13s/it] 13%|â–ˆâ–Ž        | 802/6000 [46:57<5:43:03,  3.96s/it]                                                    {'loss': 0.0554, 'grad_norm': 13.23171329498291, 'learning_rate': 8.810169491525424e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 802/6000 [46:57<5:43:03,  3.96s/it] 13%|â–ˆâ–Ž        | 803/6000 [47:00<5:27:26,  3.78s/it]                                                    {'loss': 0.1826, 'grad_norm': 11.617998123168945, 'learning_rate': 8.808474576271187e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 803/6000 [47:00<5:27:26,  3.78s/it] 13%|â–ˆâ–Ž        | 804/6000 [47:03<5:17:49,  3.67s/it]                                                    {'loss': 0.1692, 'grad_norm': 16.832420349121094, 'learning_rate': 8.806779661016949e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 804/6000 [47:04<5:17:49,  3.67s/it] 13%|â–ˆâ–Ž        | 805/6000 [47:07<5:13:12,  3.62s/it]                                                    {'loss': 0.0138, 'grad_norm': 2.3121488094329834, 'learning_rate': 8.805084745762712e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 805/6000 [47:07<5:13:12,  3.62s/it] 13%|â–ˆâ–Ž        | 806/6000 [47:11<5:12:03,  3.60s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.5407595038414001, 'learning_rate': 8.803389830508476e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 806/6000 [47:11<5:12:03,  3.60s/it] 13%|â–ˆâ–Ž        | 807/6000 [47:14<5:04:53,  3.52s/it]                                                    {'loss': 0.0157, 'grad_norm': 5.2640581130981445, 'learning_rate': 8.801694915254237e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 807/6000 [47:14<5:04:53,  3.52s/it] 13%|â–ˆâ–Ž        | 808/6000 [47:17<5:01:26,  3.48s/it]                                                    {'loss': 0.0426, 'grad_norm': 9.73897933959961, 'learning_rate': 8.8e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 808/6000 [47:17<5:01:26,  3.48s/it] 13%|â–ˆâ–Ž        | 809/6000 [47:21<4:57:38,  3.44s/it]                                                    {'loss': 0.0126, 'grad_norm': 3.619701385498047, 'learning_rate': 8.798305084745764e-06, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 809/6000 [47:21<4:57:38,  3.44s/it] 14%|â–ˆâ–Ž        | 810/6000 [47:24<4:59:52,  3.47s/it]                                                    {'loss': 0.3814, 'grad_norm': 21.151657104492188, 'learning_rate': 8.796610169491527e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 810/6000 [47:24<4:59:52,  3.47s/it] 14%|â–ˆâ–Ž        | 811/6000 [47:28<4:59:45,  3.47s/it]                                                    {'loss': 0.0164, 'grad_norm': 3.9749975204467773, 'learning_rate': 8.794915254237289e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 811/6000 [47:28<4:59:45,  3.47s/it] 14%|â–ˆâ–Ž        | 812/6000 [47:31<4:57:15,  3.44s/it]                                                    {'loss': 0.0273, 'grad_norm': 7.296891212463379, 'learning_rate': 8.793220338983052e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 812/6000 [47:31<4:57:15,  3.44s/it] 14%|â–ˆâ–Ž        | 813/6000 [47:35<5:16:42,  3.66s/it]                                                    {'loss': 0.062, 'grad_norm': 6.769468307495117, 'learning_rate': 8.791525423728813e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 813/6000 [47:35<5:16:42,  3.66s/it] 14%|â–ˆâ–Ž        | 814/6000 [47:39<5:09:24,  3.58s/it]                                                    {'loss': 0.086, 'grad_norm': 10.821513175964355, 'learning_rate': 8.789830508474577e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 814/6000 [47:39<5:09:24,  3.58s/it] 14%|â–ˆâ–Ž        | 815/6000 [47:42<5:02:18,  3.50s/it]                                                    {'loss': 0.0122, 'grad_norm': 2.1729259490966797, 'learning_rate': 8.78813559322034e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 815/6000 [47:42<5:02:18,  3.50s/it] 14%|â–ˆâ–Ž        | 816/6000 [47:45<4:57:36,  3.44s/it]                                                    {'loss': 0.1283, 'grad_norm': 17.67206573486328, 'learning_rate': 8.786440677966103e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 816/6000 [47:45<4:57:36,  3.44s/it] 14%|â–ˆâ–Ž        | 817/6000 [47:49<5:17:52,  3.68s/it]                                                    {'loss': 0.1317, 'grad_norm': 15.592071533203125, 'learning_rate': 8.784745762711865e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 817/6000 [47:49<5:17:52,  3.68s/it] 14%|â–ˆâ–Ž        | 818/6000 [47:53<5:10:07,  3.59s/it]                                                    {'loss': 0.044, 'grad_norm': 8.414373397827148, 'learning_rate': 8.783050847457628e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 818/6000 [47:53<5:10:07,  3.59s/it] 14%|â–ˆâ–Ž        | 819/6000 [47:56<5:07:01,  3.56s/it]                                                    {'loss': 0.0753, 'grad_norm': 6.756026744842529, 'learning_rate': 8.78135593220339e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 819/6000 [47:56<5:07:01,  3.56s/it] 14%|â–ˆâ–Ž        | 820/6000 [48:00<5:03:09,  3.51s/it]                                                    {'loss': 0.0847, 'grad_norm': 13.957837104797363, 'learning_rate': 8.779661016949153e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 820/6000 [48:00<5:03:09,  3.51s/it] 14%|â–ˆâ–Ž        | 821/6000 [48:03<5:00:18,  3.48s/it]                                                    {'loss': 0.0175, 'grad_norm': 5.36029577255249, 'learning_rate': 8.777966101694916e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 821/6000 [48:03<5:00:18,  3.48s/it] 14%|â–ˆâ–Ž        | 822/6000 [48:06<4:57:08,  3.44s/it]                                                    {'loss': 0.0039, 'grad_norm': 1.1788616180419922, 'learning_rate': 8.77627118644068e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 822/6000 [48:06<4:57:08,  3.44s/it] 14%|â–ˆâ–Ž        | 823/6000 [48:10<4:56:15,  3.43s/it]                                                    {'loss': 0.1482, 'grad_norm': 18.07858657836914, 'learning_rate': 8.774576271186441e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 823/6000 [48:10<4:56:15,  3.43s/it] 14%|â–ˆâ–Ž        | 824/6000 [48:13<4:53:57,  3.41s/it]                                                    {'loss': 0.003, 'grad_norm': 0.9760133028030396, 'learning_rate': 8.772881355932204e-06, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 824/6000 [48:13<4:53:57,  3.41s/it] 14%|â–ˆâ–        | 825/6000 [48:17<5:00:35,  3.49s/it]                                                    {'loss': 0.0825, 'grad_norm': 12.138798713684082, 'learning_rate': 8.771186440677966e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 825/6000 [48:17<5:00:35,  3.49s/it] 14%|â–ˆâ–        | 826/6000 [48:20<4:57:59,  3.46s/it]                                                    {'loss': 0.0026, 'grad_norm': 0.604651927947998, 'learning_rate': 8.76949152542373e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 826/6000 [48:20<4:57:59,  3.46s/it] 14%|â–ˆâ–        | 827/6000 [48:24<4:55:49,  3.43s/it]                                                    {'loss': 0.0214, 'grad_norm': 6.079517364501953, 'learning_rate': 8.767796610169492e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 827/6000 [48:24<4:55:49,  3.43s/it] 14%|â–ˆâ–        | 828/6000 [48:27<4:55:08,  3.42s/it]                                                    {'loss': 0.2769, 'grad_norm': 17.876625061035156, 'learning_rate': 8.766101694915254e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 828/6000 [48:27<4:55:08,  3.42s/it] 14%|â–ˆâ–        | 829/6000 [48:31<4:56:20,  3.44s/it]                                                    {'loss': 0.1087, 'grad_norm': 9.280828475952148, 'learning_rate': 8.764406779661017e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 829/6000 [48:31<4:56:20,  3.44s/it] 14%|â–ˆâ–        | 830/6000 [48:35<5:20:35,  3.72s/it]                                                    {'loss': 0.0006, 'grad_norm': 0.22002649307250977, 'learning_rate': 8.76271186440678e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 830/6000 [48:35<5:20:35,  3.72s/it] 14%|â–ˆâ–        | 831/6000 [48:39<5:22:47,  3.75s/it]                                                    {'loss': 0.1201, 'grad_norm': 14.041552543640137, 'learning_rate': 8.761016949152544e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 831/6000 [48:39<5:22:47,  3.75s/it] 14%|â–ˆâ–        | 832/6000 [48:42<5:14:14,  3.65s/it]                                                    {'loss': 0.1143, 'grad_norm': 14.771310806274414, 'learning_rate': 8.759322033898305e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 832/6000 [48:42<5:14:14,  3.65s/it] 14%|â–ˆâ–        | 833/6000 [48:45<5:07:04,  3.57s/it]                                                    {'loss': 0.0082, 'grad_norm': 2.508859634399414, 'learning_rate': 8.757627118644069e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 833/6000 [48:46<5:07:04,  3.57s/it] 14%|â–ˆâ–        | 834/6000 [48:49<5:01:47,  3.51s/it]                                                    {'loss': 0.0554, 'grad_norm': 10.402332305908203, 'learning_rate': 8.75593220338983e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 834/6000 [48:49<5:01:47,  3.51s/it] 14%|â–ˆâ–        | 835/6000 [48:53<5:12:22,  3.63s/it]                                                    {'loss': 0.0296, 'grad_norm': 6.63271951675415, 'learning_rate': 8.754237288135594e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 835/6000 [48:53<5:12:22,  3.63s/it] 14%|â–ˆâ–        | 836/6000 [48:56<5:03:56,  3.53s/it]                                                    {'loss': 0.1515, 'grad_norm': 16.808887481689453, 'learning_rate': 8.752542372881357e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 836/6000 [48:56<5:03:56,  3.53s/it] 14%|â–ˆâ–        | 837/6000 [49:00<5:23:39,  3.76s/it]                                                    {'loss': 0.016, 'grad_norm': 4.367899417877197, 'learning_rate': 8.75084745762712e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 837/6000 [49:00<5:23:39,  3.76s/it] 14%|â–ˆâ–        | 838/6000 [49:04<5:25:32,  3.78s/it]                                                    {'loss': 0.1302, 'grad_norm': 19.78317642211914, 'learning_rate': 8.749152542372882e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 838/6000 [49:04<5:25:32,  3.78s/it] 14%|â–ˆâ–        | 839/6000 [49:08<5:16:35,  3.68s/it]                                                    {'loss': 0.0046, 'grad_norm': 0.9845240116119385, 'learning_rate': 8.747457627118645e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 839/6000 [49:08<5:16:35,  3.68s/it] 14%|â–ˆâ–        | 840/6000 [49:11<5:10:19,  3.61s/it]                                                    {'loss': 0.0018, 'grad_norm': 0.4525850713253021, 'learning_rate': 8.745762711864407e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 840/6000 [49:11<5:10:19,  3.61s/it] 14%|â–ˆâ–        | 841/6000 [49:15<5:16:44,  3.68s/it]                                                    {'loss': 0.0611, 'grad_norm': 10.302535057067871, 'learning_rate': 8.74406779661017e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 841/6000 [49:15<5:16:44,  3.68s/it] 14%|â–ˆâ–        | 842/6000 [49:18<5:08:16,  3.59s/it]                                                    {'loss': 0.1712, 'grad_norm': 17.55906867980957, 'learning_rate': 8.742372881355933e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 842/6000 [49:18<5:08:16,  3.59s/it] 14%|â–ˆâ–        | 843/6000 [49:22<5:00:12,  3.49s/it]                                                    {'loss': 0.0071, 'grad_norm': 1.3040727376937866, 'learning_rate': 8.740677966101696e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 843/6000 [49:22<5:00:12,  3.49s/it] 14%|â–ˆâ–        | 844/6000 [49:25<5:00:41,  3.50s/it]                                                    {'loss': 0.0122, 'grad_norm': 3.377347946166992, 'learning_rate': 8.738983050847458e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 844/6000 [49:25<5:00:41,  3.50s/it] 14%|â–ˆâ–        | 845/6000 [49:28<4:56:58,  3.46s/it]                                                    {'loss': 0.0236, 'grad_norm': 4.146167755126953, 'learning_rate': 8.737288135593221e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 845/6000 [49:28<4:56:58,  3.46s/it] 14%|â–ˆâ–        | 846/6000 [49:32<5:02:56,  3.53s/it]                                                    {'loss': 0.009, 'grad_norm': 2.26054048538208, 'learning_rate': 8.735593220338985e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 846/6000 [49:32<5:02:56,  3.53s/it] 14%|â–ˆâ–        | 847/6000 [49:36<4:59:30,  3.49s/it]                                                    {'loss': 0.072, 'grad_norm': 6.1434712409973145, 'learning_rate': 8.733898305084748e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 847/6000 [49:36<4:59:30,  3.49s/it] 14%|â–ˆâ–        | 848/6000 [49:39<5:06:14,  3.57s/it]                                                    {'loss': 0.0883, 'grad_norm': 11.28134822845459, 'learning_rate': 8.73220338983051e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 848/6000 [49:39<5:06:14,  3.57s/it] 14%|â–ˆâ–        | 849/6000 [49:43<5:05:10,  3.55s/it]                                                    {'loss': 0.012, 'grad_norm': 4.678722858428955, 'learning_rate': 8.730508474576271e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 849/6000 [49:43<5:05:10,  3.55s/it] 14%|â–ˆâ–        | 850/6000 [49:46<5:02:32,  3.52s/it]                                                    {'loss': 0.0274, 'grad_norm': 5.941619873046875, 'learning_rate': 8.728813559322034e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 850/6000 [49:46<5:02:32,  3.52s/it] 14%|â–ˆâ–        | 851/6000 [49:50<4:57:01,  3.46s/it]                                                    {'loss': 0.1005, 'grad_norm': 13.169500350952148, 'learning_rate': 8.727118644067797e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 851/6000 [49:50<4:57:01,  3.46s/it] 14%|â–ˆâ–        | 852/6000 [49:53<4:55:03,  3.44s/it]                                                    {'loss': 0.1213, 'grad_norm': 8.297220230102539, 'learning_rate': 8.72542372881356e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 852/6000 [49:53<4:55:03,  3.44s/it] 14%|â–ˆâ–        | 853/6000 [49:56<4:52:53,  3.41s/it]                                                    {'loss': 0.0186, 'grad_norm': 3.8362388610839844, 'learning_rate': 8.723728813559322e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 853/6000 [49:56<4:52:53,  3.41s/it] 14%|â–ˆâ–        | 854/6000 [50:00<4:54:23,  3.43s/it]                                                    {'loss': 0.0523, 'grad_norm': 11.68966293334961, 'learning_rate': 8.722033898305086e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 854/6000 [50:00<4:54:23,  3.43s/it] 14%|â–ˆâ–        | 855/6000 [50:03<4:54:15,  3.43s/it]                                                    {'loss': 0.0028, 'grad_norm': 0.7809377312660217, 'learning_rate': 8.720338983050847e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 855/6000 [50:03<4:54:15,  3.43s/it] 14%|â–ˆâ–        | 856/6000 [50:07<5:05:27,  3.56s/it]                                                    {'loss': 0.1523, 'grad_norm': 18.239139556884766, 'learning_rate': 8.71864406779661e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 856/6000 [50:07<5:05:27,  3.56s/it] 14%|â–ˆâ–        | 857/6000 [50:11<5:02:13,  3.53s/it]                                                    {'loss': 0.0023, 'grad_norm': 0.5057552456855774, 'learning_rate': 8.716949152542374e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 857/6000 [50:11<5:02:13,  3.53s/it] 14%|â–ˆâ–        | 858/6000 [50:14<5:00:40,  3.51s/it]                                                    {'loss': 0.02, 'grad_norm': 2.997952938079834, 'learning_rate': 8.715254237288137e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 858/6000 [50:14<5:00:40,  3.51s/it] 14%|â–ˆâ–        | 859/6000 [50:17<4:57:06,  3.47s/it]                                                    {'loss': 0.0119, 'grad_norm': 2.494446039199829, 'learning_rate': 8.713559322033899e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 859/6000 [50:17<4:57:06,  3.47s/it] 14%|â–ˆâ–        | 860/6000 [50:21<5:07:23,  3.59s/it]                                                    {'loss': 0.0858, 'grad_norm': 9.904611587524414, 'learning_rate': 8.711864406779662e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 860/6000 [50:21<5:07:23,  3.59s/it] 14%|â–ˆâ–        | 861/6000 [50:25<5:02:13,  3.53s/it]                                                    {'loss': 0.0027, 'grad_norm': 0.9139416813850403, 'learning_rate': 8.710169491525423e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 861/6000 [50:25<5:02:13,  3.53s/it] 14%|â–ˆâ–        | 862/6000 [50:28<4:57:50,  3.48s/it]                                                    {'loss': 0.2154, 'grad_norm': 23.257884979248047, 'learning_rate': 8.708474576271187e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 862/6000 [50:28<4:57:50,  3.48s/it] 14%|â–ˆâ–        | 863/6000 [50:31<4:57:26,  3.47s/it]                                                    {'loss': 0.039, 'grad_norm': 9.771966934204102, 'learning_rate': 8.70677966101695e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 863/6000 [50:31<4:57:26,  3.47s/it] 14%|â–ˆâ–        | 864/6000 [50:35<4:55:37,  3.45s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.035813409835100174, 'learning_rate': 8.705084745762713e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 864/6000 [50:35<4:55:37,  3.45s/it] 14%|â–ˆâ–        | 865/6000 [50:39<5:04:22,  3.56s/it]                                                    {'loss': 0.2255, 'grad_norm': 19.056785583496094, 'learning_rate': 8.703389830508475e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 865/6000 [50:39<5:04:22,  3.56s/it] 14%|â–ˆâ–        | 866/6000 [50:42<4:59:50,  3.50s/it]                                                    {'loss': 0.1067, 'grad_norm': 14.397672653198242, 'learning_rate': 8.701694915254238e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 866/6000 [50:42<4:59:50,  3.50s/it] 14%|â–ˆâ–        | 867/6000 [50:46<4:58:19,  3.49s/it]                                                    {'loss': 0.2129, 'grad_norm': 18.357074737548828, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 867/6000 [50:46<4:58:19,  3.49s/it] 14%|â–ˆâ–        | 868/6000 [50:49<4:53:09,  3.43s/it]                                                    {'loss': 0.2274, 'grad_norm': 17.165510177612305, 'learning_rate': 8.698305084745765e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 868/6000 [50:49<4:53:09,  3.43s/it] 14%|â–ˆâ–        | 869/6000 [50:52<4:52:07,  3.42s/it]                                                    {'loss': 0.0023, 'grad_norm': 0.5771986842155457, 'learning_rate': 8.696610169491526e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 869/6000 [50:52<4:52:07,  3.42s/it] 14%|â–ˆâ–        | 870/6000 [50:56<4:51:44,  3.41s/it]                                                    {'loss': 0.0799, 'grad_norm': 12.290804862976074, 'learning_rate': 8.694915254237288e-06, 'epoch': 0.14}
 14%|â–ˆâ–        | 870/6000 [50:56<4:51:44,  3.41s/it] 15%|â–ˆâ–        | 871/6000 [50:59<4:52:51,  3.43s/it]                                                    {'loss': 0.0205, 'grad_norm': 6.534690856933594, 'learning_rate': 8.693220338983051e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 871/6000 [50:59<4:52:51,  3.43s/it] 15%|â–ˆâ–        | 872/6000 [51:02<4:53:15,  3.43s/it]                                                    {'loss': 0.1244, 'grad_norm': 12.65896987915039, 'learning_rate': 8.691525423728814e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 872/6000 [51:02<4:53:15,  3.43s/it] 15%|â–ˆâ–        | 873/6000 [51:06<4:53:56,  3.44s/it]                                                    {'loss': 0.0322, 'grad_norm': 6.056390285491943, 'learning_rate': 8.689830508474578e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 873/6000 [51:06<4:53:56,  3.44s/it] 15%|â–ˆâ–        | 874/6000 [51:09<4:53:26,  3.43s/it]                                                    {'loss': 0.0671, 'grad_norm': 10.980697631835938, 'learning_rate': 8.68813559322034e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 874/6000 [51:09<4:53:26,  3.43s/it] 15%|â–ˆâ–        | 875/6000 [51:13<5:01:01,  3.52s/it]                                                    {'loss': 0.0714, 'grad_norm': 12.369812965393066, 'learning_rate': 8.686440677966103e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 875/6000 [51:13<5:01:01,  3.52s/it] 15%|â–ˆâ–        | 876/6000 [51:16<4:57:05,  3.48s/it]                                                    {'loss': 0.0437, 'grad_norm': 9.932133674621582, 'learning_rate': 8.684745762711864e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 876/6000 [51:16<4:57:05,  3.48s/it] 15%|â–ˆâ–        | 877/6000 [51:20<4:55:59,  3.47s/it]                                                    {'loss': 0.1558, 'grad_norm': 19.92735481262207, 'learning_rate': 8.683050847457627e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 877/6000 [51:20<4:55:59,  3.47s/it] 15%|â–ˆâ–        | 878/6000 [51:23<4:55:53,  3.47s/it]                                                    {'loss': 0.0536, 'grad_norm': 11.044774055480957, 'learning_rate': 8.68135593220339e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 878/6000 [51:23<4:55:53,  3.47s/it] 15%|â–ˆâ–        | 879/6000 [51:27<5:08:50,  3.62s/it]                                                    {'loss': 0.1254, 'grad_norm': 11.200188636779785, 'learning_rate': 8.679661016949154e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 879/6000 [51:27<5:08:50,  3.62s/it] 15%|â–ˆâ–        | 880/6000 [51:31<5:02:37,  3.55s/it]                                                    {'loss': 0.4639, 'grad_norm': 32.02573013305664, 'learning_rate': 8.677966101694915e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 880/6000 [51:31<5:02:37,  3.55s/it] 15%|â–ˆâ–        | 881/6000 [51:34<4:58:38,  3.50s/it]                                                    {'loss': 0.0039, 'grad_norm': 1.7042791843414307, 'learning_rate': 8.676271186440679e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 881/6000 [51:34<4:58:38,  3.50s/it] 15%|â–ˆâ–        | 882/6000 [51:38<4:58:48,  3.50s/it]                                                    {'loss': 0.0185, 'grad_norm': 5.6599884033203125, 'learning_rate': 8.67457627118644e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 882/6000 [51:38<4:58:48,  3.50s/it] 15%|â–ˆâ–        | 883/6000 [51:41<4:56:12,  3.47s/it]                                                    {'loss': 0.0231, 'grad_norm': 5.2470598220825195, 'learning_rate': 8.672881355932205e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 883/6000 [51:41<4:56:12,  3.47s/it] 15%|â–ˆâ–        | 884/6000 [51:45<5:00:33,  3.53s/it]                                                    {'loss': 0.2152, 'grad_norm': 15.320883750915527, 'learning_rate': 8.671186440677967e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 884/6000 [51:45<5:00:33,  3.53s/it] 15%|â–ˆâ–        | 885/6000 [51:48<4:59:22,  3.51s/it]                                                    {'loss': 0.0069, 'grad_norm': 2.00433349609375, 'learning_rate': 8.66949152542373e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 885/6000 [51:48<4:59:22,  3.51s/it] 15%|â–ˆâ–        | 886/6000 [51:52<4:59:20,  3.51s/it]                                                    {'loss': 0.1253, 'grad_norm': 14.114655494689941, 'learning_rate': 8.667796610169492e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 886/6000 [51:52<4:59:20,  3.51s/it] 15%|â–ˆâ–        | 887/6000 [51:55<4:58:54,  3.51s/it]                                                    {'loss': 0.0016, 'grad_norm': 0.37559589743614197, 'learning_rate': 8.666101694915255e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 887/6000 [51:55<4:58:54,  3.51s/it] 15%|â–ˆâ–        | 888/6000 [51:59<4:58:41,  3.51s/it]                                                    {'loss': 0.0181, 'grad_norm': 4.151295185089111, 'learning_rate': 8.664406779661018e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 888/6000 [51:59<4:58:41,  3.51s/it] 15%|â–ˆâ–        | 889/6000 [52:02<4:55:29,  3.47s/it]                                                    {'loss': 0.1148, 'grad_norm': 14.31103515625, 'learning_rate': 8.662711864406782e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 889/6000 [52:02<4:55:29,  3.47s/it] 15%|â–ˆâ–        | 890/6000 [52:05<4:54:00,  3.45s/it]                                                    {'loss': 0.0073, 'grad_norm': 1.625437617301941, 'learning_rate': 8.661016949152543e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 890/6000 [52:05<4:54:00,  3.45s/it] 15%|â–ˆâ–        | 891/6000 [52:09<4:51:23,  3.42s/it]                                                    {'loss': 0.0319, 'grad_norm': 4.566128253936768, 'learning_rate': 8.659322033898305e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 891/6000 [52:09<4:51:23,  3.42s/it] 15%|â–ˆâ–        | 892/6000 [52:12<4:50:27,  3.41s/it]                                                    {'loss': 0.0725, 'grad_norm': 9.482253074645996, 'learning_rate': 8.657627118644068e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 892/6000 [52:12<4:50:27,  3.41s/it] 15%|â–ˆâ–        | 893/6000 [52:16<4:49:34,  3.40s/it]                                                    {'loss': 0.2199, 'grad_norm': 16.97088623046875, 'learning_rate': 8.655932203389831e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 893/6000 [52:16<4:49:34,  3.40s/it] 15%|â–ˆâ–        | 894/6000 [52:19<4:51:45,  3.43s/it]                                                    {'loss': 0.0879, 'grad_norm': 13.444296836853027, 'learning_rate': 8.654237288135595e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 894/6000 [52:19<4:51:45,  3.43s/it] 15%|â–ˆâ–        | 895/6000 [52:22<4:48:59,  3.40s/it]                                                    {'loss': 0.0351, 'grad_norm': 8.953030586242676, 'learning_rate': 8.652542372881356e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 895/6000 [52:22<4:48:59,  3.40s/it] 15%|â–ˆâ–        | 896/6000 [52:26<4:48:02,  3.39s/it]                                                    {'loss': 0.0022, 'grad_norm': 0.6723628640174866, 'learning_rate': 8.65084745762712e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 896/6000 [52:26<4:48:02,  3.39s/it] 15%|â–ˆâ–        | 897/6000 [52:29<4:48:44,  3.39s/it]                                                    {'loss': 0.0101, 'grad_norm': 1.9885929822921753, 'learning_rate': 8.649152542372881e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 897/6000 [52:29<4:48:44,  3.39s/it] 15%|â–ˆâ–        | 898/6000 [52:33<4:48:25,  3.39s/it]                                                    {'loss': 0.0857, 'grad_norm': 7.115367412567139, 'learning_rate': 8.647457627118644e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 898/6000 [52:33<4:48:25,  3.39s/it] 15%|â–ˆâ–        | 899/6000 [52:37<5:12:48,  3.68s/it]                                                    {'loss': 0.0028, 'grad_norm': 0.8320981860160828, 'learning_rate': 8.645762711864408e-06, 'epoch': 0.15}
 15%|â–ˆâ–        | 899/6000 [52:37<5:12:48,  3.68s/it] 15%|â–ˆâ–Œ        | 900/6000 [52:40<5:07:29,  3.62s/it]                                                    {'loss': 0.0608, 'grad_norm': 11.637638092041016, 'learning_rate': 8.64406779661017e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 900/6000 [52:40<5:07:29,  3.62s/it][2025-11-06 23:43:50,381] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900
[2025-11-06 23:43:50,395] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:43:51,073] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|â–ˆâ–Œ        | 901/6000 [52:46<6:08:30,  4.34s/it]                                                    {'loss': 0.0156, 'grad_norm': 4.0262250900268555, 'learning_rate': 8.642372881355932e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 901/6000 [52:46<6:08:30,  4.34s/it] 15%|â–ˆâ–Œ        | 902/6000 [52:50<5:43:44,  4.05s/it]                                                    {'loss': 0.0171, 'grad_norm': 4.194820880889893, 'learning_rate': 8.640677966101696e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 902/6000 [52:50<5:43:44,  4.05s/it] 15%|â–ˆâ–Œ        | 903/6000 [52:53<5:27:06,  3.85s/it]                                                    {'loss': 0.0754, 'grad_norm': 9.729547500610352, 'learning_rate': 8.638983050847459e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 903/6000 [52:53<5:27:06,  3.85s/it] 15%|â–ˆâ–Œ        | 904/6000 [52:57<5:15:21,  3.71s/it]                                                    {'loss': 0.2528, 'grad_norm': 15.63940715789795, 'learning_rate': 8.637288135593222e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 904/6000 [52:57<5:15:21,  3.71s/it] 15%|â–ˆâ–Œ        | 905/6000 [53:01<5:23:59,  3.82s/it]                                                    {'loss': 0.1086, 'grad_norm': 17.43906021118164, 'learning_rate': 8.635593220338984e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 905/6000 [53:01<5:23:59,  3.82s/it] 15%|â–ˆâ–Œ        | 906/6000 [53:04<5:17:35,  3.74s/it]                                                    {'loss': 0.0197, 'grad_norm': 4.711864948272705, 'learning_rate': 8.633898305084747e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 906/6000 [53:04<5:17:35,  3.74s/it] 15%|â–ˆâ–Œ        | 907/6000 [53:08<5:19:23,  3.76s/it]                                                    {'loss': 0.1194, 'grad_norm': 5.788440227508545, 'learning_rate': 8.632203389830509e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 907/6000 [53:08<5:19:23,  3.76s/it] 15%|â–ˆâ–Œ        | 908/6000 [53:12<5:19:06,  3.76s/it]                                                    {'loss': 0.2048, 'grad_norm': 17.981914520263672, 'learning_rate': 8.630508474576272e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 908/6000 [53:12<5:19:06,  3.76s/it] 15%|â–ˆâ–Œ        | 909/6000 [53:15<5:08:37,  3.64s/it]                                                    {'loss': 0.0419, 'grad_norm': 8.658496856689453, 'learning_rate': 8.628813559322035e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 909/6000 [53:15<5:08:37,  3.64s/it] 15%|â–ˆâ–Œ        | 910/6000 [53:19<5:03:21,  3.58s/it]                                                    {'loss': 0.0181, 'grad_norm': 4.860323429107666, 'learning_rate': 8.627118644067798e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 910/6000 [53:19<5:03:21,  3.58s/it] 15%|â–ˆâ–Œ        | 911/6000 [53:22<5:00:41,  3.55s/it]                                                    {'loss': 0.0469, 'grad_norm': 13.8522367477417, 'learning_rate': 8.62542372881356e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 911/6000 [53:22<5:00:41,  3.55s/it] 15%|â–ˆâ–Œ        | 912/6000 [53:25<4:57:04,  3.50s/it]                                                    {'loss': 0.0321, 'grad_norm': 8.307222366333008, 'learning_rate': 8.623728813559322e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 912/6000 [53:25<4:57:04,  3.50s/it] 15%|â–ˆâ–Œ        | 913/6000 [53:29<4:51:33,  3.44s/it]                                                    {'loss': 0.0283, 'grad_norm': 4.08924674987793, 'learning_rate': 8.622033898305085e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 913/6000 [53:29<4:51:33,  3.44s/it] 15%|â–ˆâ–Œ        | 914/6000 [53:33<5:01:13,  3.55s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.3518179655075073, 'learning_rate': 8.620338983050848e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 914/6000 [53:33<5:01:13,  3.55s/it] 15%|â–ˆâ–Œ        | 915/6000 [53:37<5:26:26,  3.85s/it]                                                    {'loss': 0.1038, 'grad_norm': 14.889318466186523, 'learning_rate': 8.618644067796611e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 915/6000 [53:37<5:26:26,  3.85s/it] 15%|â–ˆâ–Œ        | 916/6000 [53:40<5:14:52,  3.72s/it]                                                    {'loss': 0.0469, 'grad_norm': 7.111477851867676, 'learning_rate': 8.616949152542373e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 916/6000 [53:40<5:14:52,  3.72s/it] 15%|â–ˆâ–Œ        | 917/6000 [53:44<5:05:33,  3.61s/it]                                                    {'loss': 0.0014, 'grad_norm': 0.4359305500984192, 'learning_rate': 8.615254237288136e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 917/6000 [53:44<5:05:33,  3.61s/it] 15%|â–ˆâ–Œ        | 918/6000 [53:47<5:00:22,  3.55s/it]                                                    {'loss': 0.0076, 'grad_norm': 1.3177268505096436, 'learning_rate': 8.613559322033898e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 918/6000 [53:47<5:00:22,  3.55s/it] 15%|â–ˆâ–Œ        | 919/6000 [53:51<4:57:42,  3.52s/it]                                                    {'loss': 0.0909, 'grad_norm': 9.28908634185791, 'learning_rate': 8.611864406779661e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 919/6000 [53:51<4:57:42,  3.52s/it] 15%|â–ˆâ–Œ        | 920/6000 [53:54<4:55:33,  3.49s/it]                                                    {'loss': 0.0374, 'grad_norm': 8.525487899780273, 'learning_rate': 8.610169491525424e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 920/6000 [53:54<4:55:33,  3.49s/it] 15%|â–ˆâ–Œ        | 921/6000 [53:58<4:54:48,  3.48s/it]                                                    {'loss': 0.1031, 'grad_norm': 14.257134437561035, 'learning_rate': 8.608474576271188e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 921/6000 [53:58<4:54:48,  3.48s/it] 15%|â–ˆâ–Œ        | 922/6000 [54:01<4:58:36,  3.53s/it]                                                    {'loss': 0.0043, 'grad_norm': 1.1089606285095215, 'learning_rate': 8.60677966101695e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 922/6000 [54:01<4:58:36,  3.53s/it] 15%|â–ˆâ–Œ        | 923/6000 [54:05<4:56:27,  3.50s/it]                                                    {'loss': 0.117, 'grad_norm': 12.91921615600586, 'learning_rate': 8.605084745762713e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 923/6000 [54:05<4:56:27,  3.50s/it] 15%|â–ˆâ–Œ        | 924/6000 [54:08<4:51:16,  3.44s/it]                                                    {'loss': 0.0019, 'grad_norm': 0.5131272673606873, 'learning_rate': 8.603389830508476e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 924/6000 [54:08<4:51:16,  3.44s/it] 15%|â–ˆâ–Œ        | 925/6000 [54:11<4:49:17,  3.42s/it]                                                    {'loss': 0.0509, 'grad_norm': 5.893857002258301, 'learning_rate': 8.601694915254239e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 925/6000 [54:11<4:49:17,  3.42s/it] 15%|â–ˆâ–Œ        | 926/6000 [54:15<4:51:45,  3.45s/it]                                                    {'loss': 0.0655, 'grad_norm': 10.716854095458984, 'learning_rate': 8.6e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 926/6000 [54:15<4:51:45,  3.45s/it] 15%|â–ˆâ–Œ        | 927/6000 [54:18<4:49:13,  3.42s/it]                                                    {'loss': 0.3001, 'grad_norm': 18.912282943725586, 'learning_rate': 8.598305084745764e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 927/6000 [54:18<4:49:13,  3.42s/it] 15%|â–ˆâ–Œ        | 928/6000 [54:22<4:48:39,  3.41s/it]                                                    {'loss': 0.0702, 'grad_norm': 10.332603454589844, 'learning_rate': 8.596610169491526e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 928/6000 [54:22<4:48:39,  3.41s/it] 15%|â–ˆâ–Œ        | 929/6000 [54:25<4:49:52,  3.43s/it]                                                    {'loss': 0.0584, 'grad_norm': 8.383788108825684, 'learning_rate': 8.594915254237289e-06, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 929/6000 [54:25<4:49:52,  3.43s/it] 16%|â–ˆâ–Œ        | 930/6000 [54:28<4:47:58,  3.41s/it]                                                    {'loss': 0.268, 'grad_norm': 16.142702102661133, 'learning_rate': 8.593220338983052e-06, 'epoch': 0.15}
 16%|â–ˆâ–Œ        | 930/6000 [54:28<4:47:58,  3.41s/it] 16%|â–ˆâ–Œ        | 931/6000 [54:32<4:47:36,  3.40s/it]                                                    {'loss': 0.03, 'grad_norm': 5.771903038024902, 'learning_rate': 8.591525423728814e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 931/6000 [54:32<4:47:36,  3.40s/it] 16%|â–ˆâ–Œ        | 932/6000 [54:35<4:48:23,  3.41s/it]                                                    {'loss': 0.0258, 'grad_norm': 6.687137603759766, 'learning_rate': 8.589830508474577e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 932/6000 [54:35<4:48:23,  3.41s/it] 16%|â–ˆâ–Œ        | 933/6000 [54:39<4:46:51,  3.40s/it]                                                    {'loss': 0.0523, 'grad_norm': 13.120125770568848, 'learning_rate': 8.588135593220339e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 933/6000 [54:39<4:46:51,  3.40s/it] 16%|â–ˆâ–Œ        | 934/6000 [54:43<4:59:40,  3.55s/it]                                                    {'loss': 0.0583, 'grad_norm': 9.46971321105957, 'learning_rate': 8.586440677966102e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 934/6000 [54:43<4:59:40,  3.55s/it] 16%|â–ˆâ–Œ        | 935/6000 [54:46<4:53:36,  3.48s/it]                                                    {'loss': 0.0158, 'grad_norm': 2.042145252227783, 'learning_rate': 8.584745762711865e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 935/6000 [54:46<4:53:36,  3.48s/it] 16%|â–ˆâ–Œ        | 936/6000 [54:49<4:50:19,  3.44s/it]                                                    {'loss': 0.1017, 'grad_norm': 11.805805206298828, 'learning_rate': 8.583050847457628e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 936/6000 [54:49<4:50:19,  3.44s/it] 16%|â–ˆâ–Œ        | 937/6000 [54:53<4:51:13,  3.45s/it]                                                    {'loss': 0.0998, 'grad_norm': 15.114923477172852, 'learning_rate': 8.58135593220339e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 937/6000 [54:53<4:51:13,  3.45s/it] 16%|â–ˆâ–Œ        | 938/6000 [54:56<4:50:03,  3.44s/it]                                                    {'loss': 0.0103, 'grad_norm': 4.329377174377441, 'learning_rate': 8.579661016949153e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 938/6000 [54:56<4:50:03,  3.44s/it] 16%|â–ˆâ–Œ        | 939/6000 [55:00<4:52:44,  3.47s/it]                                                    {'loss': 0.0206, 'grad_norm': 6.888092517852783, 'learning_rate': 8.577966101694916e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 939/6000 [55:00<4:52:44,  3.47s/it] 16%|â–ˆâ–Œ        | 940/6000 [55:03<4:53:08,  3.48s/it]                                                    {'loss': 0.0012, 'grad_norm': 0.33783090114593506, 'learning_rate': 8.57627118644068e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 940/6000 [55:03<4:53:08,  3.48s/it] 16%|â–ˆâ–Œ        | 941/6000 [55:07<5:09:45,  3.67s/it]                                                    {'loss': 0.0377, 'grad_norm': 8.915603637695312, 'learning_rate': 8.574576271186441e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 941/6000 [55:07<5:09:45,  3.67s/it] 16%|â–ˆâ–Œ        | 942/6000 [55:11<5:03:04,  3.60s/it]                                                    {'loss': 0.0209, 'grad_norm': 10.680459022521973, 'learning_rate': 8.572881355932205e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 942/6000 [55:11<5:03:04,  3.60s/it] 16%|â–ˆâ–Œ        | 943/6000 [55:14<4:58:06,  3.54s/it]                                                    {'loss': 0.0151, 'grad_norm': 3.908268928527832, 'learning_rate': 8.571186440677966e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 943/6000 [55:14<4:58:06,  3.54s/it] 16%|â–ˆâ–Œ        | 944/6000 [55:17<4:54:06,  3.49s/it]                                                    {'loss': 0.0986, 'grad_norm': 13.103761672973633, 'learning_rate': 8.56949152542373e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 944/6000 [55:17<4:54:06,  3.49s/it] 16%|â–ˆâ–Œ        | 945/6000 [55:21<5:01:48,  3.58s/it]                                                    {'loss': 0.2306, 'grad_norm': 15.76101016998291, 'learning_rate': 8.567796610169493e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 945/6000 [55:21<5:01:48,  3.58s/it] 16%|â–ˆâ–Œ        | 946/6000 [55:25<4:59:37,  3.56s/it]                                                    {'loss': 0.0068, 'grad_norm': 2.152308464050293, 'learning_rate': 8.566101694915256e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 946/6000 [55:25<4:59:37,  3.56s/it] 16%|â–ˆâ–Œ        | 947/6000 [55:28<4:57:46,  3.54s/it]                                                    {'loss': 0.0975, 'grad_norm': 9.7532320022583, 'learning_rate': 8.564406779661018e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 947/6000 [55:28<4:57:46,  3.54s/it] 16%|â–ˆâ–Œ        | 948/6000 [55:32<5:02:30,  3.59s/it]                                                    {'loss': 0.0669, 'grad_norm': 9.453962326049805, 'learning_rate': 8.56271186440678e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 948/6000 [55:32<5:02:30,  3.59s/it] 16%|â–ˆâ–Œ        | 949/6000 [55:36<5:08:30,  3.66s/it]                                                    {'loss': 0.1636, 'grad_norm': 16.505077362060547, 'learning_rate': 8.561016949152542e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 949/6000 [55:36<5:08:30,  3.66s/it] 16%|â–ˆâ–Œ        | 950/6000 [55:39<5:04:29,  3.62s/it]                                                    {'loss': 0.0209, 'grad_norm': 7.838314533233643, 'learning_rate': 8.559322033898306e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 950/6000 [55:39<5:04:29,  3.62s/it] 16%|â–ˆâ–Œ        | 951/6000 [55:43<4:58:40,  3.55s/it]                                                    {'loss': 0.0827, 'grad_norm': 9.312540054321289, 'learning_rate': 8.557627118644069e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 951/6000 [55:43<4:58:40,  3.55s/it] 16%|â–ˆâ–Œ        | 952/6000 [55:46<4:55:04,  3.51s/it]                                                    {'loss': 0.1096, 'grad_norm': 13.948042869567871, 'learning_rate': 8.55593220338983e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 952/6000 [55:46<4:55:04,  3.51s/it] 16%|â–ˆâ–Œ        | 953/6000 [55:50<4:56:57,  3.53s/it]                                                    {'loss': 0.0009, 'grad_norm': 0.17801743745803833, 'learning_rate': 8.554237288135594e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 953/6000 [55:50<4:56:57,  3.53s/it] 16%|â–ˆâ–Œ        | 954/6000 [55:53<4:53:57,  3.50s/it]                                                    {'loss': 0.0417, 'grad_norm': 9.392513275146484, 'learning_rate': 8.552542372881355e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 954/6000 [55:53<4:53:57,  3.50s/it] 16%|â–ˆâ–Œ        | 955/6000 [55:57<4:53:04,  3.49s/it]                                                    {'loss': 0.1057, 'grad_norm': 18.96509552001953, 'learning_rate': 8.550847457627119e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 955/6000 [55:57<4:53:04,  3.49s/it] 16%|â–ˆâ–Œ        | 956/6000 [56:00<4:56:13,  3.52s/it]                                                    {'loss': 0.0555, 'grad_norm': 10.85860824584961, 'learning_rate': 8.549152542372882e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 956/6000 [56:00<4:56:13,  3.52s/it] 16%|â–ˆâ–Œ        | 957/6000 [56:03<4:51:44,  3.47s/it]                                                    {'loss': 0.056, 'grad_norm': 9.037220001220703, 'learning_rate': 8.547457627118645e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 957/6000 [56:03<4:51:44,  3.47s/it] 16%|â–ˆâ–Œ        | 958/6000 [56:07<4:54:36,  3.51s/it]                                                    {'loss': 0.1513, 'grad_norm': 13.563745498657227, 'learning_rate': 8.545762711864407e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 958/6000 [56:07<4:54:36,  3.51s/it] 16%|â–ˆâ–Œ        | 959/6000 [56:10<4:50:06,  3.45s/it]                                                    {'loss': 0.0411, 'grad_norm': 6.160853385925293, 'learning_rate': 8.54406779661017e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 959/6000 [56:10<4:50:06,  3.45s/it] 16%|â–ˆâ–Œ        | 960/6000 [56:14<4:51:04,  3.47s/it]                                                    {'loss': 0.4124, 'grad_norm': 21.35904884338379, 'learning_rate': 8.542372881355933e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 960/6000 [56:14<4:51:04,  3.47s/it] 16%|â–ˆâ–Œ        | 961/6000 [56:17<4:52:42,  3.49s/it]                                                    {'loss': 0.0574, 'grad_norm': 9.677553176879883, 'learning_rate': 8.540677966101697e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 961/6000 [56:17<4:52:42,  3.49s/it] 16%|â–ˆâ–Œ        | 962/6000 [56:21<5:02:07,  3.60s/it]                                                    {'loss': 0.1481, 'grad_norm': 14.762199401855469, 'learning_rate': 8.538983050847458e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 962/6000 [56:21<5:02:07,  3.60s/it] 16%|â–ˆâ–Œ        | 963/6000 [56:25<4:56:27,  3.53s/it]                                                    {'loss': 0.1032, 'grad_norm': 10.284659385681152, 'learning_rate': 8.537288135593221e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 963/6000 [56:25<4:56:27,  3.53s/it] 16%|â–ˆâ–Œ        | 964/6000 [56:28<4:51:52,  3.48s/it]                                                    {'loss': 0.15, 'grad_norm': 16.00701141357422, 'learning_rate': 8.535593220338983e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 964/6000 [56:28<4:51:52,  3.48s/it] 16%|â–ˆâ–Œ        | 965/6000 [56:32<4:53:28,  3.50s/it]                                                    {'loss': 0.0648, 'grad_norm': 8.673431396484375, 'learning_rate': 8.533898305084746e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 965/6000 [56:32<4:53:28,  3.50s/it] 16%|â–ˆâ–Œ        | 966/6000 [56:35<4:55:34,  3.52s/it]                                                    {'loss': 0.001, 'grad_norm': 0.28837376832962036, 'learning_rate': 8.53220338983051e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 966/6000 [56:35<4:55:34,  3.52s/it] 16%|â–ˆâ–Œ        | 967/6000 [56:39<4:57:57,  3.55s/it]                                                    {'loss': 0.0043, 'grad_norm': 0.7617471814155579, 'learning_rate': 8.530508474576273e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 967/6000 [56:39<4:57:57,  3.55s/it] 16%|â–ˆâ–Œ        | 968/6000 [56:43<5:05:33,  3.64s/it]                                                    {'loss': 0.0018, 'grad_norm': 0.41485193371772766, 'learning_rate': 8.528813559322034e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 968/6000 [56:43<5:05:33,  3.64s/it] 16%|â–ˆâ–Œ        | 969/6000 [56:46<5:01:14,  3.59s/it]                                                    {'loss': 0.0218, 'grad_norm': 5.1449713706970215, 'learning_rate': 8.527118644067798e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 969/6000 [56:46<5:01:14,  3.59s/it] 16%|â–ˆâ–Œ        | 970/6000 [56:50<5:01:59,  3.60s/it]                                                    {'loss': 0.0893, 'grad_norm': 16.481264114379883, 'learning_rate': 8.52542372881356e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 970/6000 [56:50<5:01:59,  3.60s/it] 16%|â–ˆâ–Œ        | 971/6000 [56:53<4:55:18,  3.52s/it]                                                    {'loss': 0.1941, 'grad_norm': 16.700618743896484, 'learning_rate': 8.523728813559323e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 971/6000 [56:53<4:55:18,  3.52s/it] 16%|â–ˆâ–Œ        | 972/6000 [56:56<4:52:49,  3.49s/it]                                                    {'loss': 0.086, 'grad_norm': 13.91739559173584, 'learning_rate': 8.522033898305086e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 972/6000 [56:56<4:52:49,  3.49s/it] 16%|â–ˆâ–Œ        | 973/6000 [57:00<4:50:51,  3.47s/it]                                                    {'loss': 0.234, 'grad_norm': 20.56160545349121, 'learning_rate': 8.520338983050847e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 973/6000 [57:00<4:50:51,  3.47s/it] 16%|â–ˆâ–Œ        | 974/6000 [57:03<4:49:55,  3.46s/it]                                                    {'loss': 0.0017, 'grad_norm': 0.5159554481506348, 'learning_rate': 8.51864406779661e-06, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 974/6000 [57:03<4:49:55,  3.46s/it] 16%|â–ˆâ–‹        | 975/6000 [57:07<4:46:59,  3.43s/it]                                                    {'loss': 0.1025, 'grad_norm': 10.013960838317871, 'learning_rate': 8.516949152542372e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 975/6000 [57:07<4:46:59,  3.43s/it] 16%|â–ˆâ–‹        | 976/6000 [57:10<4:49:32,  3.46s/it]                                                    {'loss': 0.002, 'grad_norm': 0.5082643628120422, 'learning_rate': 8.515254237288136e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 976/6000 [57:10<4:49:32,  3.46s/it] 16%|â–ˆâ–‹        | 977/6000 [57:14<4:46:39,  3.42s/it]                                                    {'loss': 0.1287, 'grad_norm': 16.75299644470215, 'learning_rate': 8.513559322033899e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 977/6000 [57:14<4:46:39,  3.42s/it] 16%|â–ˆâ–‹        | 978/6000 [57:17<4:42:53,  3.38s/it]                                                    {'loss': 0.0334, 'grad_norm': 3.3438448905944824, 'learning_rate': 8.511864406779662e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 978/6000 [57:17<4:42:53,  3.38s/it] 16%|â–ˆâ–‹        | 979/6000 [57:20<4:43:12,  3.38s/it]                                                    {'loss': 0.0254, 'grad_norm': 3.4485998153686523, 'learning_rate': 8.510169491525424e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 979/6000 [57:20<4:43:12,  3.38s/it] 16%|â–ˆâ–‹        | 980/6000 [57:24<4:46:24,  3.42s/it]                                                    {'loss': 0.1488, 'grad_norm': 14.353982925415039, 'learning_rate': 8.508474576271187e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 980/6000 [57:24<4:46:24,  3.42s/it] 16%|â–ˆâ–‹        | 981/6000 [57:27<4:47:10,  3.43s/it]                                                    {'loss': 0.0466, 'grad_norm': 5.748071670532227, 'learning_rate': 8.50677966101695e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 981/6000 [57:27<4:47:10,  3.43s/it] 16%|â–ˆâ–‹        | 982/6000 [57:31<4:50:20,  3.47s/it]                                                    {'loss': 0.0912, 'grad_norm': 10.617035865783691, 'learning_rate': 8.505084745762714e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 982/6000 [57:31<4:50:20,  3.47s/it] 16%|â–ˆâ–‹        | 983/6000 [57:34<4:49:56,  3.47s/it]                                                    {'loss': 0.0205, 'grad_norm': 3.557140350341797, 'learning_rate': 8.503389830508475e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 983/6000 [57:34<4:49:56,  3.47s/it] 16%|â–ˆâ–‹        | 984/6000 [57:38<4:46:44,  3.43s/it]                                                    {'loss': 0.1112, 'grad_norm': 9.339115142822266, 'learning_rate': 8.501694915254238e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 984/6000 [57:38<4:46:44,  3.43s/it] 16%|â–ˆâ–‹        | 985/6000 [57:41<4:50:48,  3.48s/it]                                                    {'loss': 0.049, 'grad_norm': 8.772551536560059, 'learning_rate': 8.5e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 985/6000 [57:41<4:50:48,  3.48s/it] 16%|â–ˆâ–‹        | 986/6000 [57:44<4:46:42,  3.43s/it]                                                    {'loss': 0.0722, 'grad_norm': 6.812859535217285, 'learning_rate': 8.498305084745763e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 986/6000 [57:44<4:46:42,  3.43s/it] 16%|â–ˆâ–‹        | 987/6000 [57:48<4:50:36,  3.48s/it]                                                    {'loss': 0.0004, 'grad_norm': 0.07748907804489136, 'learning_rate': 8.496610169491526e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 987/6000 [57:48<4:50:36,  3.48s/it] 16%|â–ˆâ–‹        | 988/6000 [57:51<4:47:12,  3.44s/it]                                                    {'loss': 0.0633, 'grad_norm': 8.78605842590332, 'learning_rate': 8.49491525423729e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 988/6000 [57:51<4:47:12,  3.44s/it] 16%|â–ˆâ–‹        | 989/6000 [57:55<4:48:34,  3.46s/it]                                                    {'loss': 0.19, 'grad_norm': 17.11415672302246, 'learning_rate': 8.493220338983051e-06, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 989/6000 [57:55<4:48:34,  3.46s/it] 16%|â–ˆâ–‹        | 990/6000 [57:58<4:48:42,  3.46s/it]                                                    {'loss': 0.0533, 'grad_norm': 12.055498123168945, 'learning_rate': 8.491525423728815e-06, 'epoch': 0.17}
 16%|â–ˆâ–‹        | 990/6000 [57:58<4:48:42,  3.46s/it] 17%|â–ˆâ–‹        | 991/6000 [58:02<5:04:10,  3.64s/it]                                                    {'loss': 0.0106, 'grad_norm': 1.7660390138626099, 'learning_rate': 8.489830508474576e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 991/6000 [58:02<5:04:10,  3.64s/it] 17%|â–ˆâ–‹        | 992/6000 [58:06<5:00:11,  3.60s/it]                                                    {'loss': 0.0003, 'grad_norm': 0.07129119336605072, 'learning_rate': 8.48813559322034e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 992/6000 [58:06<5:00:11,  3.60s/it] 17%|â–ˆâ–‹        | 993/6000 [58:09<4:57:11,  3.56s/it]                                                    {'loss': 0.0285, 'grad_norm': 6.83193302154541, 'learning_rate': 8.486440677966103e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 993/6000 [58:09<4:57:11,  3.56s/it] 17%|â–ˆâ–‹        | 994/6000 [58:13<4:56:06,  3.55s/it]                                                    {'loss': 0.0231, 'grad_norm': 3.7043912410736084, 'learning_rate': 8.484745762711864e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 994/6000 [58:13<4:56:06,  3.55s/it] 17%|â–ˆâ–‹        | 995/6000 [58:16<4:53:32,  3.52s/it]                                                    {'loss': 0.1263, 'grad_norm': 11.446002006530762, 'learning_rate': 8.483050847457628e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 995/6000 [58:16<4:53:32,  3.52s/it] 17%|â–ˆâ–‹        | 996/6000 [58:20<4:51:50,  3.50s/it]                                                    {'loss': 0.0047, 'grad_norm': 1.6145843267440796, 'learning_rate': 8.481355932203391e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 996/6000 [58:20<4:51:50,  3.50s/it] 17%|â–ˆâ–‹        | 997/6000 [58:23<4:51:33,  3.50s/it]                                                    {'loss': 0.1757, 'grad_norm': 10.884909629821777, 'learning_rate': 8.479661016949154e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 997/6000 [58:23<4:51:33,  3.50s/it] 17%|â–ˆâ–‹        | 998/6000 [58:27<4:47:11,  3.44s/it]                                                    {'loss': 0.1267, 'grad_norm': 15.624797821044922, 'learning_rate': 8.477966101694916e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 998/6000 [58:27<4:47:11,  3.44s/it] 17%|â–ˆâ–‹        | 999/6000 [58:30<4:46:56,  3.44s/it]                                                    {'loss': 0.1004, 'grad_norm': 15.479086875915527, 'learning_rate': 8.476271186440679e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 999/6000 [58:30<4:46:56,  3.44s/it] 17%|â–ˆâ–‹        | 1000/6000 [58:34<4:53:30,  3.52s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.08221996575593948, 'learning_rate': 8.47457627118644e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1000/6000 [58:34<4:53:30,  3.52s/it][2025-11-06 23:49:43,784] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000
[2025-11-06 23:49:43,802] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:49:44,816] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 17%|â–ˆâ–‹        | 1001/6000 [58:40<5:55:32,  4.27s/it]                                                     {'loss': 0.3771, 'grad_norm': 20.070322036743164, 'learning_rate': 8.472881355932204e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1001/6000 [58:40<5:55:32,  4.27s/it] 17%|â–ˆâ–‹        | 1002/6000 [58:43<5:33:32,  4.00s/it]                                                     {'loss': 0.0037, 'grad_norm': 1.69590163230896, 'learning_rate': 8.471186440677967e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1002/6000 [58:43<5:33:32,  4.00s/it] 17%|â–ˆâ–‹        | 1003/6000 [58:46<5:15:03,  3.78s/it]                                                     {'loss': 0.1762, 'grad_norm': 18.72902488708496, 'learning_rate': 8.46949152542373e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1003/6000 [58:46<5:15:03,  3.78s/it] 17%|â–ˆâ–‹        | 1004/6000 [58:50<5:03:30,  3.65s/it]                                                     {'loss': 0.0292, 'grad_norm': 6.687236785888672, 'learning_rate': 8.467796610169492e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1004/6000 [58:50<5:03:30,  3.65s/it] 17%|â–ˆâ–‹        | 1005/6000 [58:53<4:56:54,  3.57s/it]                                                     {'loss': 0.0508, 'grad_norm': 12.49090576171875, 'learning_rate': 8.466101694915255e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1005/6000 [58:53<4:56:54,  3.57s/it] 17%|â–ˆâ–‹        | 1006/6000 [58:56<4:51:00,  3.50s/it]                                                     {'loss': 0.0914, 'grad_norm': 14.836195945739746, 'learning_rate': 8.464406779661017e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1006/6000 [58:57<4:51:00,  3.50s/it] 17%|â–ˆâ–‹        | 1007/6000 [59:00<4:48:32,  3.47s/it]                                                     {'loss': 0.0476, 'grad_norm': 11.64899730682373, 'learning_rate': 8.46271186440678e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1007/6000 [59:00<4:48:32,  3.47s/it] 17%|â–ˆâ–‹        | 1008/6000 [59:03<4:47:41,  3.46s/it]                                                     {'loss': 0.0091, 'grad_norm': 2.086282968521118, 'learning_rate': 8.461016949152543e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1008/6000 [59:03<4:47:41,  3.46s/it] 17%|â–ˆâ–‹        | 1009/6000 [59:07<4:46:42,  3.45s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.1916630119085312, 'learning_rate': 8.459322033898307e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1009/6000 [59:07<4:46:42,  3.45s/it] 17%|â–ˆâ–‹        | 1010/6000 [59:10<4:43:23,  3.41s/it]                                                     {'loss': 0.0667, 'grad_norm': 9.655621528625488, 'learning_rate': 8.457627118644068e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1010/6000 [59:10<4:43:23,  3.41s/it] 17%|â–ˆâ–‹        | 1011/6000 [59:13<4:43:37,  3.41s/it]                                                     {'loss': 0.0837, 'grad_norm': 8.553750991821289, 'learning_rate': 8.455932203389831e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1011/6000 [59:13<4:43:37,  3.41s/it] 17%|â–ˆâ–‹        | 1012/6000 [59:17<4:45:59,  3.44s/it]                                                     {'loss': 0.0205, 'grad_norm': 6.9068121910095215, 'learning_rate': 8.454237288135593e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1012/6000 [59:17<4:45:59,  3.44s/it] 17%|â–ˆâ–‹        | 1013/6000 [59:20<4:43:07,  3.41s/it]                                                     {'loss': 0.0726, 'grad_norm': 13.49388313293457, 'learning_rate': 8.452542372881356e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1013/6000 [59:20<4:43:07,  3.41s/it] 17%|â–ˆâ–‹        | 1014/6000 [59:24<4:40:55,  3.38s/it]                                                     {'loss': 0.3, 'grad_norm': 16.36649513244629, 'learning_rate': 8.45084745762712e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1014/6000 [59:24<4:40:55,  3.38s/it] 17%|â–ˆâ–‹        | 1015/6000 [59:27<4:41:09,  3.38s/it]                                                     {'loss': 0.0627, 'grad_norm': 13.971328735351562, 'learning_rate': 8.449152542372881e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1015/6000 [59:27<4:41:09,  3.38s/it] 17%|â–ˆâ–‹        | 1016/6000 [59:30<4:42:18,  3.40s/it]                                                     {'loss': 0.0331, 'grad_norm': 6.005617618560791, 'learning_rate': 8.447457627118644e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1016/6000 [59:30<4:42:18,  3.40s/it] 17%|â–ˆâ–‹        | 1017/6000 [59:34<4:44:59,  3.43s/it]                                                     {'loss': 0.1638, 'grad_norm': 13.278401374816895, 'learning_rate': 8.445762711864408e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1017/6000 [59:34<4:44:59,  3.43s/it] 17%|â–ˆâ–‹        | 1018/6000 [59:37<4:45:39,  3.44s/it]                                                     {'loss': 0.0106, 'grad_norm': 2.0416676998138428, 'learning_rate': 8.444067796610171e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1018/6000 [59:37<4:45:39,  3.44s/it] 17%|â–ˆâ–‹        | 1019/6000 [59:41<4:43:48,  3.42s/it]                                                     {'loss': 0.0317, 'grad_norm': 5.896533966064453, 'learning_rate': 8.442372881355933e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1019/6000 [59:41<4:43:48,  3.42s/it] 17%|â–ˆâ–‹        | 1020/6000 [59:44<4:43:52,  3.42s/it]                                                     {'loss': 0.186, 'grad_norm': 16.121662139892578, 'learning_rate': 8.440677966101696e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1020/6000 [59:44<4:43:52,  3.42s/it] 17%|â–ˆâ–‹        | 1021/6000 [59:48<4:43:00,  3.41s/it]                                                     {'loss': 0.0464, 'grad_norm': 4.8307952880859375, 'learning_rate': 8.438983050847457e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1021/6000 [59:48<4:43:00,  3.41s/it] 17%|â–ˆâ–‹        | 1022/6000 [59:51<4:48:39,  3.48s/it]                                                     {'loss': 0.0468, 'grad_norm': 16.617218017578125, 'learning_rate': 8.43728813559322e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1022/6000 [59:51<4:48:39,  3.48s/it] 17%|â–ˆâ–‹        | 1023/6000 [59:55<4:45:49,  3.45s/it]                                                     {'loss': 0.0924, 'grad_norm': 13.346673965454102, 'learning_rate': 8.435593220338984e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1023/6000 [59:55<4:45:49,  3.45s/it] 17%|â–ˆâ–‹        | 1024/6000 [59:58<4:43:53,  3.42s/it]                                                     {'loss': 0.0049, 'grad_norm': 1.6929566860198975, 'learning_rate': 8.433898305084747e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1024/6000 [59:58<4:43:53,  3.42s/it] 17%|â–ˆâ–‹        | 1025/6000 [1:00:01<4:44:27,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02178368903696537, 'learning_rate': 8.432203389830509e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1025/6000 [1:00:01<4:44:27,  3.43s/it] 17%|â–ˆâ–‹        | 1026/6000 [1:00:05<4:42:46,  3.41s/it]                                                       {'loss': 0.1633, 'grad_norm': 20.647674560546875, 'learning_rate': 8.430508474576272e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1026/6000 [1:00:05<4:42:46,  3.41s/it] 17%|â–ˆâ–‹        | 1027/6000 [1:00:08<4:43:04,  3.42s/it]                                                       {'loss': 0.0111, 'grad_norm': 2.246739149093628, 'learning_rate': 8.428813559322034e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1027/6000 [1:00:08<4:43:04,  3.42s/it] 17%|â–ˆâ–‹        | 1028/6000 [1:00:12<4:42:33,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.17967964708805084, 'learning_rate': 8.427118644067797e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1028/6000 [1:00:12<4:42:33,  3.41s/it] 17%|â–ˆâ–‹        | 1029/6000 [1:00:15<4:42:55,  3.41s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.544402003288269, 'learning_rate': 8.42542372881356e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1029/6000 [1:00:15<4:42:55,  3.41s/it] 17%|â–ˆâ–‹        | 1030/6000 [1:00:18<4:40:52,  3.39s/it]                                                       {'loss': 0.0567, 'grad_norm': 10.6305570602417, 'learning_rate': 8.423728813559324e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1030/6000 [1:00:18<4:40:52,  3.39s/it] 17%|â–ˆâ–‹        | 1031/6000 [1:00:22<4:41:10,  3.40s/it]                                                       {'loss': 0.0735, 'grad_norm': 11.406966209411621, 'learning_rate': 8.422033898305085e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1031/6000 [1:00:22<4:41:10,  3.40s/it] 17%|â–ˆâ–‹        | 1032/6000 [1:00:25<4:39:48,  3.38s/it]                                                       {'loss': 0.0398, 'grad_norm': 6.150029182434082, 'learning_rate': 8.420338983050848e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1032/6000 [1:00:25<4:39:48,  3.38s/it] 17%|â–ˆâ–‹        | 1033/6000 [1:00:29<4:40:06,  3.38s/it]                                                       {'loss': 0.0075, 'grad_norm': 2.8470864295959473, 'learning_rate': 8.41864406779661e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1033/6000 [1:00:29<4:40:06,  3.38s/it] 17%|â–ˆâ–‹        | 1034/6000 [1:00:32<4:38:08,  3.36s/it]                                                       {'loss': 0.0618, 'grad_norm': 4.615321636199951, 'learning_rate': 8.416949152542375e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1034/6000 [1:00:32<4:38:08,  3.36s/it] 17%|â–ˆâ–‹        | 1035/6000 [1:00:35<4:40:46,  3.39s/it]                                                       {'loss': 0.0471, 'grad_norm': 7.94978666305542, 'learning_rate': 8.415254237288137e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1035/6000 [1:00:35<4:40:46,  3.39s/it] 17%|â–ˆâ–‹        | 1036/6000 [1:00:39<4:42:05,  3.41s/it]                                                       {'loss': 0.1309, 'grad_norm': 16.05211639404297, 'learning_rate': 8.413559322033898e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1036/6000 [1:00:39<4:42:05,  3.41s/it] 17%|â–ˆâ–‹        | 1037/6000 [1:00:42<4:42:56,  3.42s/it]                                                       {'loss': 0.0653, 'grad_norm': 11.383889198303223, 'learning_rate': 8.411864406779661e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1037/6000 [1:00:42<4:42:56,  3.42s/it] 17%|â–ˆâ–‹        | 1038/6000 [1:00:46<4:52:15,  3.53s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.3774312734603882, 'learning_rate': 8.410169491525425e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1038/6000 [1:00:46<4:52:15,  3.53s/it] 17%|â–ˆâ–‹        | 1039/6000 [1:00:50<4:52:56,  3.54s/it]                                                       {'loss': 0.034, 'grad_norm': 6.7147746086120605, 'learning_rate': 8.408474576271188e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1039/6000 [1:00:50<4:52:56,  3.54s/it] 17%|â–ˆâ–‹        | 1040/6000 [1:00:53<4:51:57,  3.53s/it]                                                       {'loss': 0.0755, 'grad_norm': 8.088579177856445, 'learning_rate': 8.40677966101695e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1040/6000 [1:00:53<4:51:57,  3.53s/it] 17%|â–ˆâ–‹        | 1041/6000 [1:00:56<4:47:10,  3.47s/it]                                                       {'loss': 0.1856, 'grad_norm': 18.307479858398438, 'learning_rate': 8.405084745762713e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1041/6000 [1:00:56<4:47:10,  3.47s/it] 17%|â–ˆâ–‹        | 1042/6000 [1:01:00<4:45:33,  3.46s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.8645431995391846, 'learning_rate': 8.403389830508474e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1042/6000 [1:01:00<4:45:33,  3.46s/it] 17%|â–ˆâ–‹        | 1043/6000 [1:01:03<4:43:00,  3.43s/it]                                                       {'loss': 0.1037, 'grad_norm': 14.658863067626953, 'learning_rate': 8.401694915254238e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1043/6000 [1:01:03<4:43:00,  3.43s/it] 17%|â–ˆâ–‹        | 1044/6000 [1:01:07<4:44:57,  3.45s/it]                                                       {'loss': 0.0999, 'grad_norm': 12.932080268859863, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1044/6000 [1:01:07<4:44:57,  3.45s/it] 17%|â–ˆâ–‹        | 1045/6000 [1:01:10<4:46:53,  3.47s/it]                                                       {'loss': 0.1258, 'grad_norm': 15.81187915802002, 'learning_rate': 8.398305084745764e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1045/6000 [1:01:10<4:46:53,  3.47s/it] 17%|â–ˆâ–‹        | 1046/6000 [1:01:14<4:46:28,  3.47s/it]                                                       {'loss': 0.1272, 'grad_norm': 17.91129493713379, 'learning_rate': 8.396610169491526e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1046/6000 [1:01:14<4:46:28,  3.47s/it] 17%|â–ˆâ–‹        | 1047/6000 [1:01:17<4:54:37,  3.57s/it]                                                       {'loss': 0.2914, 'grad_norm': 21.07754135131836, 'learning_rate': 8.394915254237289e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1047/6000 [1:01:17<4:54:37,  3.57s/it] 17%|â–ˆâ–‹        | 1048/6000 [1:01:21<4:48:54,  3.50s/it]                                                       {'loss': 0.0037, 'grad_norm': 1.287657380104065, 'learning_rate': 8.39322033898305e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1048/6000 [1:01:21<4:48:54,  3.50s/it] 17%|â–ˆâ–‹        | 1049/6000 [1:01:24<4:45:16,  3.46s/it]                                                       {'loss': 0.1596, 'grad_norm': 11.066010475158691, 'learning_rate': 8.391525423728814e-06, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1049/6000 [1:01:24<4:45:16,  3.46s/it] 18%|â–ˆâ–Š        | 1050/6000 [1:01:28<5:03:08,  3.67s/it]                                                       {'loss': 0.0106, 'grad_norm': 3.9206933975219727, 'learning_rate': 8.389830508474577e-06, 'epoch': 0.17}
 18%|â–ˆâ–Š        | 1050/6000 [1:01:28<5:03:08,  3.67s/it] 18%|â–ˆâ–Š        | 1051/6000 [1:01:32<4:56:45,  3.60s/it]                                                       {'loss': 0.129, 'grad_norm': 11.206217765808105, 'learning_rate': 8.38813559322034e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1051/6000 [1:01:32<4:56:45,  3.60s/it] 18%|â–ˆâ–Š        | 1052/6000 [1:01:35<4:52:51,  3.55s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.4039320945739746, 'learning_rate': 8.386440677966102e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1052/6000 [1:01:35<4:52:51,  3.55s/it] 18%|â–ˆâ–Š        | 1053/6000 [1:01:39<4:56:16,  3.59s/it]                                                       {'loss': 0.0434, 'grad_norm': 5.070391654968262, 'learning_rate': 8.384745762711865e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1053/6000 [1:01:39<4:56:16,  3.59s/it] 18%|â–ˆâ–Š        | 1054/6000 [1:01:42<4:55:14,  3.58s/it]                                                       {'loss': 0.0691, 'grad_norm': 13.887394905090332, 'learning_rate': 8.383050847457629e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1054/6000 [1:01:42<4:55:14,  3.58s/it] 18%|â–ˆâ–Š        | 1055/6000 [1:01:46<4:49:24,  3.51s/it]                                                       {'loss': 0.0439, 'grad_norm': 5.116587162017822, 'learning_rate': 8.381355932203392e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1055/6000 [1:01:46<4:49:24,  3.51s/it] 18%|â–ˆâ–Š        | 1056/6000 [1:01:49<4:46:37,  3.48s/it]                                                       {'loss': 0.038, 'grad_norm': 10.76648998260498, 'learning_rate': 8.379661016949153e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1056/6000 [1:01:49<4:46:37,  3.48s/it] 18%|â–ˆâ–Š        | 1057/6000 [1:01:53<4:44:47,  3.46s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.43276476860046387, 'learning_rate': 8.377966101694915e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1057/6000 [1:01:53<4:44:47,  3.46s/it] 18%|â–ˆâ–Š        | 1058/6000 [1:01:56<4:42:20,  3.43s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.2649352550506592, 'learning_rate': 8.376271186440678e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1058/6000 [1:01:56<4:42:20,  3.43s/it] 18%|â–ˆâ–Š        | 1059/6000 [1:01:59<4:42:41,  3.43s/it]                                                       {'loss': 0.1145, 'grad_norm': 20.26987648010254, 'learning_rate': 8.374576271186442e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1059/6000 [1:01:59<4:42:41,  3.43s/it] 18%|â–ˆâ–Š        | 1060/6000 [1:02:03<4:39:52,  3.40s/it]                                                       {'loss': 0.0457, 'grad_norm': 8.861613273620605, 'learning_rate': 8.372881355932205e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1060/6000 [1:02:03<4:39:52,  3.40s/it] 18%|â–ˆâ–Š        | 1061/6000 [1:02:07<4:49:36,  3.52s/it]                                                       {'loss': 0.0148, 'grad_norm': 4.2678327560424805, 'learning_rate': 8.371186440677966e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1061/6000 [1:02:07<4:49:36,  3.52s/it] 18%|â–ˆâ–Š        | 1062/6000 [1:02:10<4:49:05,  3.51s/it]                                                       {'loss': 0.018, 'grad_norm': 3.891935348510742, 'learning_rate': 8.36949152542373e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1062/6000 [1:02:10<4:49:05,  3.51s/it] 18%|â–ˆâ–Š        | 1063/6000 [1:02:13<4:46:21,  3.48s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.11896413564682007, 'learning_rate': 8.367796610169491e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1063/6000 [1:02:13<4:46:21,  3.48s/it] 18%|â–ˆâ–Š        | 1064/6000 [1:02:17<4:46:27,  3.48s/it]                                                       {'loss': 0.0134, 'grad_norm': 6.048922061920166, 'learning_rate': 8.366101694915255e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1064/6000 [1:02:17<4:46:27,  3.48s/it] 18%|â–ˆâ–Š        | 1065/6000 [1:02:20<4:42:17,  3.43s/it]                                                       {'loss': 0.0509, 'grad_norm': 8.210174560546875, 'learning_rate': 8.364406779661018e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1065/6000 [1:02:20<4:42:17,  3.43s/it] 18%|â–ˆâ–Š        | 1066/6000 [1:02:24<4:42:41,  3.44s/it]                                                       {'loss': 0.1137, 'grad_norm': 14.677825927734375, 'learning_rate': 8.362711864406781e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1066/6000 [1:02:24<4:42:41,  3.44s/it] 18%|â–ˆâ–Š        | 1067/6000 [1:02:27<4:44:26,  3.46s/it]                                                       {'loss': 0.054, 'grad_norm': 8.13282585144043, 'learning_rate': 8.361016949152543e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1067/6000 [1:02:27<4:44:26,  3.46s/it] 18%|â–ˆâ–Š        | 1068/6000 [1:02:31<4:41:15,  3.42s/it]                                                       {'loss': 0.007, 'grad_norm': 1.944071888923645, 'learning_rate': 8.359322033898306e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1068/6000 [1:02:31<4:41:15,  3.42s/it] 18%|â–ˆâ–Š        | 1069/6000 [1:02:34<4:39:38,  3.40s/it]                                                       {'loss': 0.025, 'grad_norm': 5.834869861602783, 'learning_rate': 8.357627118644067e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1069/6000 [1:02:34<4:39:38,  3.40s/it] 18%|â–ˆâ–Š        | 1070/6000 [1:02:37<4:41:04,  3.42s/it]                                                       {'loss': 0.1995, 'grad_norm': 19.306568145751953, 'learning_rate': 8.35593220338983e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1070/6000 [1:02:37<4:41:04,  3.42s/it] 18%|â–ˆâ–Š        | 1071/6000 [1:02:41<4:40:48,  3.42s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.940349817276001, 'learning_rate': 8.354237288135594e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1071/6000 [1:02:41<4:40:48,  3.42s/it] 18%|â–ˆâ–Š        | 1072/6000 [1:02:44<4:39:55,  3.41s/it]                                                       {'loss': 0.088, 'grad_norm': 14.522544860839844, 'learning_rate': 8.352542372881357e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1072/6000 [1:02:44<4:39:55,  3.41s/it] 18%|â–ˆâ–Š        | 1073/6000 [1:02:48<4:42:26,  3.44s/it]                                                       {'loss': 0.0115, 'grad_norm': 5.063516139984131, 'learning_rate': 8.350847457627119e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1073/6000 [1:02:48<4:42:26,  3.44s/it] 18%|â–ˆâ–Š        | 1074/6000 [1:02:51<4:42:26,  3.44s/it]                                                       {'loss': 0.0131, 'grad_norm': 2.659292459487915, 'learning_rate': 8.349152542372882e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1074/6000 [1:02:51<4:42:26,  3.44s/it] 18%|â–ˆâ–Š        | 1075/6000 [1:02:55<4:43:01,  3.45s/it]                                                       {'loss': 0.1037, 'grad_norm': 11.177569389343262, 'learning_rate': 8.347457627118645e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1075/6000 [1:02:55<4:43:01,  3.45s/it] 18%|â–ˆâ–Š        | 1076/6000 [1:02:58<4:44:52,  3.47s/it]                                                       {'loss': 0.0366, 'grad_norm': 8.166496276855469, 'learning_rate': 8.345762711864409e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1076/6000 [1:02:58<4:44:52,  3.47s/it] 18%|â–ˆâ–Š        | 1077/6000 [1:03:01<4:42:49,  3.45s/it]                                                       {'loss': 0.0142, 'grad_norm': 3.6927006244659424, 'learning_rate': 8.34406779661017e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1077/6000 [1:03:01<4:42:49,  3.45s/it] 18%|â–ˆâ–Š        | 1078/6000 [1:03:05<4:42:46,  3.45s/it]                                                       {'loss': 0.0221, 'grad_norm': 3.580495834350586, 'learning_rate': 8.342372881355932e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1078/6000 [1:03:05<4:42:46,  3.45s/it] 18%|â–ˆâ–Š        | 1079/6000 [1:03:09<4:57:35,  3.63s/it]                                                       {'loss': 0.1263, 'grad_norm': 13.701725006103516, 'learning_rate': 8.340677966101695e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1079/6000 [1:03:09<4:57:35,  3.63s/it] 18%|â–ˆâ–Š        | 1080/6000 [1:03:12<4:51:33,  3.56s/it]                                                       {'loss': 0.0254, 'grad_norm': 4.8883209228515625, 'learning_rate': 8.338983050847458e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1080/6000 [1:03:12<4:51:33,  3.56s/it] 18%|â–ˆâ–Š        | 1081/6000 [1:03:16<4:47:31,  3.51s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.252908229827881, 'learning_rate': 8.337288135593222e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1081/6000 [1:03:16<4:47:31,  3.51s/it] 18%|â–ˆâ–Š        | 1082/6000 [1:03:19<4:48:06,  3.51s/it]                                                       {'loss': 0.0591, 'grad_norm': 11.005192756652832, 'learning_rate': 8.335593220338983e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1082/6000 [1:03:19<4:48:06,  3.51s/it] 18%|â–ˆâ–Š        | 1083/6000 [1:03:23<4:50:50,  3.55s/it]                                                       {'loss': 0.0121, 'grad_norm': 1.8392854928970337, 'learning_rate': 8.333898305084747e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1083/6000 [1:03:23<4:50:50,  3.55s/it] 18%|â–ˆâ–Š        | 1084/6000 [1:03:27<4:52:40,  3.57s/it]                                                       {'loss': 0.1466, 'grad_norm': 15.25538444519043, 'learning_rate': 8.332203389830508e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1084/6000 [1:03:27<4:52:40,  3.57s/it] 18%|â–ˆâ–Š        | 1085/6000 [1:03:30<4:47:36,  3.51s/it]                                                       {'loss': 0.0219, 'grad_norm': 1.5006169080734253, 'learning_rate': 8.330508474576271e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1085/6000 [1:03:30<4:47:36,  3.51s/it] 18%|â–ˆâ–Š        | 1086/6000 [1:03:34<4:52:33,  3.57s/it]                                                       {'loss': 0.0466, 'grad_norm': 8.85785961151123, 'learning_rate': 8.328813559322035e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1086/6000 [1:03:34<4:52:33,  3.57s/it] 18%|â–ˆâ–Š        | 1087/6000 [1:03:37<4:49:21,  3.53s/it]                                                       {'loss': 0.0162, 'grad_norm': 4.207422256469727, 'learning_rate': 8.327118644067798e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1087/6000 [1:03:37<4:49:21,  3.53s/it] 18%|â–ˆâ–Š        | 1088/6000 [1:03:41<4:46:22,  3.50s/it]                                                       {'loss': 0.1413, 'grad_norm': 13.215031623840332, 'learning_rate': 8.32542372881356e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1088/6000 [1:03:41<4:46:22,  3.50s/it] 18%|â–ˆâ–Š        | 1089/6000 [1:03:45<5:08:44,  3.77s/it]                                                       {'loss': 0.1899, 'grad_norm': 17.269826889038086, 'learning_rate': 8.323728813559323e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1089/6000 [1:03:45<5:08:44,  3.77s/it] 18%|â–ˆâ–Š        | 1090/6000 [1:03:48<4:58:55,  3.65s/it]                                                       {'loss': 0.1063, 'grad_norm': 12.780028343200684, 'learning_rate': 8.322033898305086e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1090/6000 [1:03:48<4:58:55,  3.65s/it] 18%|â–ˆâ–Š        | 1091/6000 [1:03:52<4:53:57,  3.59s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.1287175416946411, 'learning_rate': 8.32033898305085e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1091/6000 [1:03:52<4:53:57,  3.59s/it] 18%|â–ˆâ–Š        | 1092/6000 [1:03:55<4:47:56,  3.52s/it]                                                       {'loss': 0.1916, 'grad_norm': 24.940662384033203, 'learning_rate': 8.318644067796611e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1092/6000 [1:03:55<4:47:56,  3.52s/it] 18%|â–ˆâ–Š        | 1093/6000 [1:03:58<4:44:00,  3.47s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.12458058446645737, 'learning_rate': 8.316949152542374e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1093/6000 [1:03:58<4:44:00,  3.47s/it] 18%|â–ˆâ–Š        | 1094/6000 [1:04:02<4:43:01,  3.46s/it]                                                       {'loss': 0.0928, 'grad_norm': 7.078555583953857, 'learning_rate': 8.315254237288136e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1094/6000 [1:04:02<4:43:01,  3.46s/it] 18%|â–ˆâ–Š        | 1095/6000 [1:04:05<4:41:02,  3.44s/it]                                                       {'loss': 0.0234, 'grad_norm': 3.8709073066711426, 'learning_rate': 8.313559322033899e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1095/6000 [1:04:05<4:41:02,  3.44s/it] 18%|â–ˆâ–Š        | 1096/6000 [1:04:09<4:43:49,  3.47s/it]                                                       {'loss': 0.0628, 'grad_norm': 9.409063339233398, 'learning_rate': 8.311864406779662e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1096/6000 [1:04:09<4:43:49,  3.47s/it] 18%|â–ˆâ–Š        | 1097/6000 [1:04:12<4:42:25,  3.46s/it]                                                       {'loss': 0.0169, 'grad_norm': 3.5108301639556885, 'learning_rate': 8.310169491525426e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1097/6000 [1:04:12<4:42:25,  3.46s/it] 18%|â–ˆâ–Š        | 1098/6000 [1:04:16<4:56:26,  3.63s/it]                                                       {'loss': 0.1166, 'grad_norm': 15.580521583557129, 'learning_rate': 8.308474576271187e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1098/6000 [1:04:16<4:56:26,  3.63s/it] 18%|â–ˆâ–Š        | 1099/6000 [1:04:20<5:08:02,  3.77s/it]                                                       {'loss': 0.0175, 'grad_norm': 5.009353160858154, 'learning_rate': 8.306779661016949e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1099/6000 [1:04:20<5:08:02,  3.77s/it] 18%|â–ˆâ–Š        | 1100/6000 [1:04:24<4:58:40,  3.66s/it]                                                       {'loss': 0.1344, 'grad_norm': 15.63098430633545, 'learning_rate': 8.305084745762712e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1100/6000 [1:04:24<4:58:40,  3.66s/it][2025-11-06 23:55:33,760] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100
[2025-11-06 23:55:33,780] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-06 23:55:34,448] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1101/6000 [1:04:29<5:47:52,  4.26s/it]                                                       {'loss': 0.0976, 'grad_norm': 15.720805168151855, 'learning_rate': 8.303389830508475e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1101/6000 [1:04:29<5:47:52,  4.26s/it] 18%|â–ˆâ–Š        | 1102/6000 [1:04:33<5:25:24,  3.99s/it]                                                       {'loss': 0.0354, 'grad_norm': 9.901111602783203, 'learning_rate': 8.301694915254239e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1102/6000 [1:04:33<5:25:24,  3.99s/it] 18%|â–ˆâ–Š        | 1103/6000 [1:04:36<5:13:31,  3.84s/it]                                                       {'loss': 0.1093, 'grad_norm': 11.701059341430664, 'learning_rate': 8.3e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1103/6000 [1:04:36<5:13:31,  3.84s/it] 18%|â–ˆâ–Š        | 1104/6000 [1:04:40<5:03:38,  3.72s/it]                                                       {'loss': 0.0225, 'grad_norm': 7.551330089569092, 'learning_rate': 8.298305084745763e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1104/6000 [1:04:40<5:03:38,  3.72s/it] 18%|â–ˆâ–Š        | 1105/6000 [1:04:43<4:55:47,  3.63s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.227977991104126, 'learning_rate': 8.296610169491525e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1105/6000 [1:04:43<4:55:47,  3.63s/it] 18%|â–ˆâ–Š        | 1106/6000 [1:04:47<4:50:10,  3.56s/it]                                                       {'loss': 0.0389, 'grad_norm': 6.905710697174072, 'learning_rate': 8.294915254237288e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1106/6000 [1:04:47<4:50:10,  3.56s/it] 18%|â–ˆâ–Š        | 1107/6000 [1:04:50<4:47:32,  3.53s/it]                                                       {'loss': 0.0114, 'grad_norm': 3.463820695877075, 'learning_rate': 8.293220338983052e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1107/6000 [1:04:50<4:47:32,  3.53s/it] 18%|â–ˆâ–Š        | 1108/6000 [1:04:54<4:48:15,  3.54s/it]                                                       {'loss': 0.0297, 'grad_norm': 6.549564838409424, 'learning_rate': 8.291525423728815e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1108/6000 [1:04:54<4:48:15,  3.54s/it] 18%|â–ˆâ–Š        | 1109/6000 [1:04:57<4:45:40,  3.50s/it]                                                       {'loss': 0.0327, 'grad_norm': 2.882581949234009, 'learning_rate': 8.289830508474576e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1109/6000 [1:04:57<4:45:40,  3.50s/it] 18%|â–ˆâ–Š        | 1110/6000 [1:05:00<4:44:01,  3.48s/it]                                                       {'loss': 0.1461, 'grad_norm': 11.10356330871582, 'learning_rate': 8.28813559322034e-06, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1110/6000 [1:05:00<4:44:01,  3.48s/it] 19%|â–ˆâ–Š        | 1111/6000 [1:05:04<4:41:00,  3.45s/it]                                                       {'loss': 0.083, 'grad_norm': 9.233541488647461, 'learning_rate': 8.286440677966103e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1111/6000 [1:05:04<4:41:00,  3.45s/it] 19%|â–ˆâ–Š        | 1112/6000 [1:05:07<4:37:56,  3.41s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.1510796546936035, 'learning_rate': 8.284745762711866e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1112/6000 [1:05:07<4:37:56,  3.41s/it] 19%|â–ˆâ–Š        | 1113/6000 [1:05:11<4:37:50,  3.41s/it]                                                       {'loss': 0.0181, 'grad_norm': 3.9348058700561523, 'learning_rate': 8.283050847457628e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1113/6000 [1:05:11<4:37:50,  3.41s/it] 19%|â–ˆâ–Š        | 1114/6000 [1:05:14<4:35:57,  3.39s/it]                                                       {'loss': 0.1392, 'grad_norm': 13.471511840820312, 'learning_rate': 8.281355932203391e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1114/6000 [1:05:14<4:35:57,  3.39s/it] 19%|â–ˆâ–Š        | 1115/6000 [1:05:17<4:36:43,  3.40s/it]                                                       {'loss': 0.136, 'grad_norm': 10.255965232849121, 'learning_rate': 8.279661016949153e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1115/6000 [1:05:17<4:36:43,  3.40s/it] 19%|â–ˆâ–Š        | 1116/6000 [1:05:21<4:36:53,  3.40s/it]                                                       {'loss': 0.2864, 'grad_norm': 21.85021209716797, 'learning_rate': 8.277966101694916e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1116/6000 [1:05:21<4:36:53,  3.40s/it] 19%|â–ˆâ–Š        | 1117/6000 [1:05:24<4:39:26,  3.43s/it]                                                       {'loss': 0.0067, 'grad_norm': 2.203760862350464, 'learning_rate': 8.27627118644068e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1117/6000 [1:05:24<4:39:26,  3.43s/it] 19%|â–ˆâ–Š        | 1118/6000 [1:05:28<4:39:38,  3.44s/it]                                                       {'loss': 0.5722, 'grad_norm': 33.58810806274414, 'learning_rate': 8.27457627118644e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1118/6000 [1:05:28<4:39:38,  3.44s/it] 19%|â–ˆâ–Š        | 1119/6000 [1:05:31<4:41:58,  3.47s/it]                                                       {'loss': 0.0417, 'grad_norm': 9.895702362060547, 'learning_rate': 8.272881355932204e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1119/6000 [1:05:31<4:41:58,  3.47s/it] 19%|â–ˆâ–Š        | 1120/6000 [1:05:35<4:41:48,  3.46s/it]                                                       {'loss': 0.007, 'grad_norm': 2.440673589706421, 'learning_rate': 8.271186440677966e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1120/6000 [1:05:35<4:41:48,  3.46s/it] 19%|â–ˆâ–Š        | 1121/6000 [1:05:38<4:40:02,  3.44s/it]                                                       {'loss': 0.0878, 'grad_norm': 10.794842720031738, 'learning_rate': 8.269491525423729e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1121/6000 [1:05:38<4:40:02,  3.44s/it] 19%|â–ˆâ–Š        | 1122/6000 [1:05:41<4:40:43,  3.45s/it]                                                       {'loss': 0.0033, 'grad_norm': 1.153892993927002, 'learning_rate': 8.267796610169492e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1122/6000 [1:05:41<4:40:43,  3.45s/it] 19%|â–ˆâ–Š        | 1123/6000 [1:05:45<4:39:49,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3715795576572418, 'learning_rate': 8.266101694915255e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1123/6000 [1:05:45<4:39:49,  3.44s/it] 19%|â–ˆâ–Š        | 1124/6000 [1:05:49<4:49:55,  3.57s/it]                                                       {'loss': 0.1507, 'grad_norm': 16.062660217285156, 'learning_rate': 8.264406779661017e-06, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1124/6000 [1:05:49<4:49:55,  3.57s/it] 19%|â–ˆâ–‰        | 1125/6000 [1:05:52<4:49:57,  3.57s/it]                                                       {'loss': 0.0996, 'grad_norm': 13.748499870300293, 'learning_rate': 8.26271186440678e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1125/6000 [1:05:52<4:49:57,  3.57s/it] 19%|â–ˆâ–‰        | 1126/6000 [1:05:56<4:47:07,  3.53s/it]                                                       {'loss': 0.4257, 'grad_norm': 19.54671859741211, 'learning_rate': 8.261016949152542e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1126/6000 [1:05:56<4:47:07,  3.53s/it] 19%|â–ˆâ–‰        | 1127/6000 [1:06:00<4:53:15,  3.61s/it]                                                       {'loss': 0.1008, 'grad_norm': 15.777983665466309, 'learning_rate': 8.259322033898305e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1127/6000 [1:06:00<4:53:15,  3.61s/it] 19%|â–ˆâ–‰        | 1128/6000 [1:06:03<4:48:41,  3.56s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.40859872102737427, 'learning_rate': 8.257627118644068e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1128/6000 [1:06:03<4:48:41,  3.56s/it] 19%|â–ˆâ–‰        | 1129/6000 [1:06:06<4:45:09,  3.51s/it]                                                       {'loss': 0.0302, 'grad_norm': 3.9696226119995117, 'learning_rate': 8.255932203389832e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1129/6000 [1:06:06<4:45:09,  3.51s/it] 19%|â–ˆâ–‰        | 1130/6000 [1:06:10<4:44:13,  3.50s/it]                                                       {'loss': 0.0984, 'grad_norm': 11.093084335327148, 'learning_rate': 8.254237288135593e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1130/6000 [1:06:10<4:44:13,  3.50s/it] 19%|â–ˆâ–‰        | 1131/6000 [1:06:13<4:39:51,  3.45s/it]                                                       {'loss': 0.1856, 'grad_norm': 16.20070457458496, 'learning_rate': 8.252542372881357e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1131/6000 [1:06:13<4:39:51,  3.45s/it] 19%|â–ˆâ–‰        | 1132/6000 [1:06:17<4:37:52,  3.42s/it]                                                       {'loss': 0.021, 'grad_norm': 2.781975030899048, 'learning_rate': 8.25084745762712e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1132/6000 [1:06:17<4:37:52,  3.42s/it] 19%|â–ˆâ–‰        | 1133/6000 [1:06:20<4:48:16,  3.55s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.6973362565040588, 'learning_rate': 8.249152542372883e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1133/6000 [1:06:20<4:48:16,  3.55s/it] 19%|â–ˆâ–‰        | 1134/6000 [1:06:24<4:58:31,  3.68s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.4746487140655518, 'learning_rate': 8.247457627118645e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1134/6000 [1:06:24<4:58:31,  3.68s/it] 19%|â–ˆâ–‰        | 1135/6000 [1:06:28<4:51:30,  3.60s/it]                                                       {'loss': 0.0207, 'grad_norm': 5.362756729125977, 'learning_rate': 8.245762711864408e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1135/6000 [1:06:28<4:51:30,  3.60s/it] 19%|â–ˆâ–‰        | 1136/6000 [1:06:31<4:47:38,  3.55s/it]                                                       {'loss': 0.0249, 'grad_norm': 7.452752590179443, 'learning_rate': 8.24406779661017e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1136/6000 [1:06:31<4:47:38,  3.55s/it] 19%|â–ˆâ–‰        | 1137/6000 [1:06:35<4:43:46,  3.50s/it]                                                       {'loss': 0.013, 'grad_norm': 3.391744375228882, 'learning_rate': 8.242372881355933e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1137/6000 [1:06:35<4:43:46,  3.50s/it] 19%|â–ˆâ–‰        | 1138/6000 [1:06:38<4:40:52,  3.47s/it]                                                       {'loss': 0.0344, 'grad_norm': 9.723282814025879, 'learning_rate': 8.240677966101696e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1138/6000 [1:06:38<4:40:52,  3.47s/it] 19%|â–ˆâ–‰        | 1139/6000 [1:06:42<4:41:00,  3.47s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.2153147459030151, 'learning_rate': 8.238983050847458e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1139/6000 [1:06:42<4:41:00,  3.47s/it] 19%|â–ˆâ–‰        | 1140/6000 [1:06:45<4:44:17,  3.51s/it]                                                       {'loss': 0.2242, 'grad_norm': 23.655471801757812, 'learning_rate': 8.237288135593221e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1140/6000 [1:06:45<4:44:17,  3.51s/it] 19%|â–ˆâ–‰        | 1141/6000 [1:06:49<4:43:06,  3.50s/it]                                                       {'loss': 0.1952, 'grad_norm': 14.594916343688965, 'learning_rate': 8.235593220338983e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1141/6000 [1:06:49<4:43:06,  3.50s/it] 19%|â–ˆâ–‰        | 1142/6000 [1:06:52<4:43:20,  3.50s/it]                                                       {'loss': 0.0451, 'grad_norm': 11.015421867370605, 'learning_rate': 8.233898305084746e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1142/6000 [1:06:52<4:43:20,  3.50s/it] 19%|â–ˆâ–‰        | 1143/6000 [1:06:55<4:37:31,  3.43s/it]                                                       {'loss': 0.3111, 'grad_norm': 15.437213897705078, 'learning_rate': 8.232203389830509e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1143/6000 [1:06:55<4:37:31,  3.43s/it] 19%|â–ˆâ–‰        | 1144/6000 [1:06:59<4:37:53,  3.43s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.335153579711914, 'learning_rate': 8.230508474576272e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1144/6000 [1:06:59<4:37:53,  3.43s/it] 19%|â–ˆâ–‰        | 1145/6000 [1:07:02<4:37:06,  3.42s/it]                                                       {'loss': 0.0792, 'grad_norm': 8.774754524230957, 'learning_rate': 8.228813559322034e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1145/6000 [1:07:02<4:37:06,  3.42s/it] 19%|â–ˆâ–‰        | 1146/6000 [1:07:06<4:38:11,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07811559736728668, 'learning_rate': 8.227118644067797e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1146/6000 [1:07:06<4:38:11,  3.44s/it] 19%|â–ˆâ–‰        | 1147/6000 [1:07:09<4:36:41,  3.42s/it]                                                       {'loss': 0.0895, 'grad_norm': 9.969730377197266, 'learning_rate': 8.22542372881356e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1147/6000 [1:07:09<4:36:41,  3.42s/it] 19%|â–ˆâ–‰        | 1148/6000 [1:07:12<4:35:51,  3.41s/it]                                                       {'loss': 0.0947, 'grad_norm': 17.290971755981445, 'learning_rate': 8.223728813559324e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1148/6000 [1:07:12<4:35:51,  3.41s/it] 19%|â–ˆâ–‰        | 1149/6000 [1:07:16<4:45:56,  3.54s/it]                                                       {'loss': 0.1532, 'grad_norm': 12.956425666809082, 'learning_rate': 8.222033898305085e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1149/6000 [1:07:16<4:45:56,  3.54s/it] 19%|â–ˆâ–‰        | 1150/6000 [1:07:20<4:44:49,  3.52s/it]                                                       {'loss': 0.0244, 'grad_norm': 4.086923122406006, 'learning_rate': 8.220338983050849e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1150/6000 [1:07:20<4:44:49,  3.52s/it] 19%|â–ˆâ–‰        | 1151/6000 [1:07:23<4:42:19,  3.49s/it]                                                       {'loss': 0.1052, 'grad_norm': 14.465024948120117, 'learning_rate': 8.21864406779661e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1151/6000 [1:07:23<4:42:19,  3.49s/it] 19%|â–ˆâ–‰        | 1152/6000 [1:07:26<4:37:53,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.12594862282276154, 'learning_rate': 8.216949152542373e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1152/6000 [1:07:27<4:37:53,  3.44s/it] 19%|â–ˆâ–‰        | 1153/6000 [1:07:30<4:40:23,  3.47s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.052113138139247894, 'learning_rate': 8.215254237288137e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1153/6000 [1:07:30<4:40:23,  3.47s/it] 19%|â–ˆâ–‰        | 1154/6000 [1:07:34<4:40:14,  3.47s/it]                                                       {'loss': 0.0277, 'grad_norm': 5.984457969665527, 'learning_rate': 8.2135593220339e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1154/6000 [1:07:34<4:40:14,  3.47s/it] 19%|â–ˆâ–‰        | 1155/6000 [1:07:37<4:45:48,  3.54s/it]                                                       {'loss': 0.0344, 'grad_norm': 8.012585639953613, 'learning_rate': 8.211864406779662e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1155/6000 [1:07:37<4:45:48,  3.54s/it] 19%|â–ˆâ–‰        | 1156/6000 [1:07:41<4:41:27,  3.49s/it]                                                       {'loss': 0.2556, 'grad_norm': 21.394893646240234, 'learning_rate': 8.210169491525425e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1156/6000 [1:07:41<4:41:27,  3.49s/it] 19%|â–ˆâ–‰        | 1157/6000 [1:07:44<4:40:27,  3.47s/it]                                                       {'loss': 0.0739, 'grad_norm': 10.960289001464844, 'learning_rate': 8.208474576271186e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1157/6000 [1:07:44<4:40:27,  3.47s/it] 19%|â–ˆâ–‰        | 1158/6000 [1:07:47<4:38:59,  3.46s/it]                                                       {'loss': 0.0169, 'grad_norm': 6.006208896636963, 'learning_rate': 8.20677966101695e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1158/6000 [1:07:47<4:38:59,  3.46s/it] 19%|â–ˆâ–‰        | 1159/6000 [1:07:51<4:37:35,  3.44s/it]                                                       {'loss': 0.0604, 'grad_norm': 11.370085716247559, 'learning_rate': 8.205084745762713e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1159/6000 [1:07:51<4:37:35,  3.44s/it] 19%|â–ˆâ–‰        | 1160/6000 [1:07:54<4:35:42,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.044317182153463364, 'learning_rate': 8.203389830508475e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1160/6000 [1:07:54<4:35:42,  3.42s/it] 19%|â–ˆâ–‰        | 1161/6000 [1:07:58<4:33:02,  3.39s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.17200398445129395, 'learning_rate': 8.201694915254238e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1161/6000 [1:07:58<4:33:02,  3.39s/it] 19%|â–ˆâ–‰        | 1162/6000 [1:08:01<4:30:34,  3.36s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.9676542282104492, 'learning_rate': 8.2e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1162/6000 [1:08:01<4:30:34,  3.36s/it] 19%|â–ˆâ–‰        | 1163/6000 [1:08:04<4:30:47,  3.36s/it]                                                       {'loss': 0.0198, 'grad_norm': 4.2532172203063965, 'learning_rate': 8.198305084745763e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1163/6000 [1:08:04<4:30:47,  3.36s/it] 19%|â–ˆâ–‰        | 1164/6000 [1:08:08<4:30:39,  3.36s/it]                                                       {'loss': 0.1261, 'grad_norm': 12.11842155456543, 'learning_rate': 8.196610169491526e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1164/6000 [1:08:08<4:30:39,  3.36s/it] 19%|â–ˆâ–‰        | 1165/6000 [1:08:11<4:34:02,  3.40s/it]                                                       {'loss': 0.0518, 'grad_norm': 8.344231605529785, 'learning_rate': 8.19491525423729e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1165/6000 [1:08:11<4:34:02,  3.40s/it] 19%|â–ˆâ–‰        | 1166/6000 [1:08:14<4:32:25,  3.38s/it]                                                       {'loss': 0.0521, 'grad_norm': 5.878153324127197, 'learning_rate': 8.19322033898305e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1166/6000 [1:08:14<4:32:25,  3.38s/it] 19%|â–ˆâ–‰        | 1167/6000 [1:08:18<4:46:13,  3.55s/it]                                                       {'loss': 0.1438, 'grad_norm': 12.39421272277832, 'learning_rate': 8.191525423728814e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1167/6000 [1:08:18<4:46:13,  3.55s/it] 19%|â–ˆâ–‰        | 1168/6000 [1:08:22<4:42:36,  3.51s/it]                                                       {'loss': 0.0805, 'grad_norm': 13.487746238708496, 'learning_rate': 8.189830508474577e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1168/6000 [1:08:22<4:42:36,  3.51s/it] 19%|â–ˆâ–‰        | 1169/6000 [1:08:25<4:39:38,  3.47s/it]                                                       {'loss': 0.15, 'grad_norm': 15.592902183532715, 'learning_rate': 8.18813559322034e-06, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1169/6000 [1:08:25<4:39:38,  3.47s/it] 20%|â–ˆâ–‰        | 1170/6000 [1:08:29<4:37:38,  3.45s/it]                                                       {'loss': 0.0201, 'grad_norm': 6.061947345733643, 'learning_rate': 8.186440677966102e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1170/6000 [1:08:29<4:37:38,  3.45s/it] 20%|â–ˆâ–‰        | 1171/6000 [1:08:32<4:40:26,  3.48s/it]                                                       {'loss': 0.0317, 'grad_norm': 6.014899730682373, 'learning_rate': 8.184745762711865e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1171/6000 [1:08:32<4:40:26,  3.48s/it] 20%|â–ˆâ–‰        | 1172/6000 [1:08:36<4:41:07,  3.49s/it]                                                       {'loss': 0.0609, 'grad_norm': 14.741278648376465, 'learning_rate': 8.183050847457627e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1172/6000 [1:08:36<4:41:07,  3.49s/it] 20%|â–ˆâ–‰        | 1173/6000 [1:08:39<4:38:54,  3.47s/it]                                                       {'loss': 0.0267, 'grad_norm': 5.357677936553955, 'learning_rate': 8.18135593220339e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1173/6000 [1:08:39<4:38:54,  3.47s/it] 20%|â–ˆâ–‰        | 1174/6000 [1:08:42<4:39:30,  3.48s/it]                                                       {'loss': 0.1413, 'grad_norm': 13.669732093811035, 'learning_rate': 8.179661016949154e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1174/6000 [1:08:42<4:39:30,  3.48s/it] 20%|â–ˆâ–‰        | 1175/6000 [1:08:46<4:38:48,  3.47s/it]                                                       {'loss': 0.0122, 'grad_norm': 3.931363344192505, 'learning_rate': 8.177966101694917e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1175/6000 [1:08:46<4:38:48,  3.47s/it] 20%|â–ˆâ–‰        | 1176/6000 [1:08:49<4:35:38,  3.43s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.261575698852539, 'learning_rate': 8.176271186440678e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1176/6000 [1:08:49<4:35:38,  3.43s/it] 20%|â–ˆâ–‰        | 1177/6000 [1:08:53<4:34:36,  3.42s/it]                                                       {'loss': 0.0607, 'grad_norm': 4.6905999183654785, 'learning_rate': 8.174576271186442e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1177/6000 [1:08:53<4:34:36,  3.42s/it] 20%|â–ˆâ–‰        | 1178/6000 [1:08:57<4:47:20,  3.58s/it]                                                       {'loss': 0.0479, 'grad_norm': 3.74980092048645, 'learning_rate': 8.172881355932203e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1178/6000 [1:08:57<4:47:20,  3.58s/it] 20%|â–ˆâ–‰        | 1179/6000 [1:09:00<4:53:57,  3.66s/it]                                                       {'loss': 0.0637, 'grad_norm': 10.223917007446289, 'learning_rate': 8.171186440677967e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1179/6000 [1:09:00<4:53:57,  3.66s/it] 20%|â–ˆâ–‰        | 1180/6000 [1:09:04<4:57:04,  3.70s/it]                                                       {'loss': 0.0373, 'grad_norm': 2.4270756244659424, 'learning_rate': 8.16949152542373e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1180/6000 [1:09:04<4:57:04,  3.70s/it] 20%|â–ˆâ–‰        | 1181/6000 [1:09:08<4:51:37,  3.63s/it]                                                       {'loss': 0.0461, 'grad_norm': 9.419707298278809, 'learning_rate': 8.167796610169491e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1181/6000 [1:09:08<4:51:37,  3.63s/it] 20%|â–ˆâ–‰        | 1182/6000 [1:09:12<5:09:21,  3.85s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.7390190362930298, 'learning_rate': 8.166101694915255e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1182/6000 [1:09:12<5:09:21,  3.85s/it] 20%|â–ˆâ–‰        | 1183/6000 [1:09:15<4:57:46,  3.71s/it]                                                       {'loss': 0.0475, 'grad_norm': 11.384541511535645, 'learning_rate': 8.164406779661016e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1183/6000 [1:09:15<4:57:46,  3.71s/it] 20%|â–ˆâ–‰        | 1184/6000 [1:09:19<4:50:16,  3.62s/it]                                                       {'loss': 0.2019, 'grad_norm': 14.565465927124023, 'learning_rate': 8.162711864406781e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1184/6000 [1:09:19<4:50:16,  3.62s/it] 20%|â–ˆâ–‰        | 1185/6000 [1:09:22<4:43:36,  3.53s/it]                                                       {'loss': 0.1133, 'grad_norm': 14.012694358825684, 'learning_rate': 8.161016949152543e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1185/6000 [1:09:22<4:43:36,  3.53s/it] 20%|â–ˆâ–‰        | 1186/6000 [1:09:26<4:40:39,  3.50s/it]                                                       {'loss': 0.1716, 'grad_norm': 8.959001541137695, 'learning_rate': 8.159322033898306e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1186/6000 [1:09:26<4:40:39,  3.50s/it] 20%|â–ˆâ–‰        | 1187/6000 [1:09:29<4:39:33,  3.49s/it]                                                       {'loss': 0.0157, 'grad_norm': 2.2210023403167725, 'learning_rate': 8.157627118644068e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1187/6000 [1:09:29<4:39:33,  3.49s/it] 20%|â–ˆâ–‰        | 1188/6000 [1:09:32<4:34:19,  3.42s/it]                                                       {'loss': 0.0255, 'grad_norm': 5.361295223236084, 'learning_rate': 8.155932203389831e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1188/6000 [1:09:32<4:34:19,  3.42s/it] 20%|â–ˆâ–‰        | 1189/6000 [1:09:36<4:32:20,  3.40s/it]                                                       {'loss': 0.0347, 'grad_norm': 5.9707770347595215, 'learning_rate': 8.154237288135594e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1189/6000 [1:09:36<4:32:20,  3.40s/it] 20%|â–ˆâ–‰        | 1190/6000 [1:09:39<4:36:44,  3.45s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.2955005168914795, 'learning_rate': 8.152542372881358e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1190/6000 [1:09:39<4:36:44,  3.45s/it] 20%|â–ˆâ–‰        | 1191/6000 [1:09:43<4:37:54,  3.47s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.281502604484558, 'learning_rate': 8.150847457627119e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1191/6000 [1:09:43<4:37:54,  3.47s/it] 20%|â–ˆâ–‰        | 1192/6000 [1:09:46<4:38:44,  3.48s/it]                                                       {'loss': 0.0117, 'grad_norm': 2.452273368835449, 'learning_rate': 8.149152542372882e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1192/6000 [1:09:46<4:38:44,  3.48s/it] 20%|â–ˆâ–‰        | 1193/6000 [1:09:50<4:36:56,  3.46s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5613476037979126, 'learning_rate': 8.147457627118644e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1193/6000 [1:09:50<4:36:56,  3.46s/it] 20%|â–ˆâ–‰        | 1194/6000 [1:09:53<4:39:19,  3.49s/it]                                                       {'loss': 0.0532, 'grad_norm': 10.190323829650879, 'learning_rate': 8.145762711864407e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1194/6000 [1:09:53<4:39:19,  3.49s/it] 20%|â–ˆâ–‰        | 1195/6000 [1:09:57<4:38:22,  3.48s/it]                                                       {'loss': 0.0124, 'grad_norm': 4.854721546173096, 'learning_rate': 8.14406779661017e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1195/6000 [1:09:57<4:38:22,  3.48s/it] 20%|â–ˆâ–‰        | 1196/6000 [1:10:00<4:37:20,  3.46s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.17740373313426971, 'learning_rate': 8.142372881355934e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1196/6000 [1:10:00<4:37:20,  3.46s/it] 20%|â–ˆâ–‰        | 1197/6000 [1:10:04<4:38:27,  3.48s/it]                                                       {'loss': 0.017, 'grad_norm': 2.725982427597046, 'learning_rate': 8.140677966101695e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1197/6000 [1:10:04<4:38:27,  3.48s/it] 20%|â–ˆâ–‰        | 1198/6000 [1:10:07<4:38:24,  3.48s/it]                                                       {'loss': 0.0389, 'grad_norm': 9.57426643371582, 'learning_rate': 8.138983050847459e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1198/6000 [1:10:07<4:38:24,  3.48s/it] 20%|â–ˆâ–‰        | 1199/6000 [1:10:10<4:35:13,  3.44s/it]                                                       {'loss': 0.0807, 'grad_norm': 12.18882942199707, 'learning_rate': 8.13728813559322e-06, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1199/6000 [1:10:10<4:35:13,  3.44s/it] 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:14<4:33:03,  3.41s/it]                                                       {'loss': 0.2688, 'grad_norm': 21.480960845947266, 'learning_rate': 8.135593220338983e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1200/6000 [1:10:14<4:33:03,  3.41s/it][2025-11-07 00:01:23,813] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200
[2025-11-07 00:01:23,828] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:01:24,485] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:20<5:28:31,  4.11s/it]                                                       {'loss': 0.2079, 'grad_norm': 13.291753768920898, 'learning_rate': 8.133898305084747e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1201/6000 [1:10:20<5:28:31,  4.11s/it] 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:23<5:10:31,  3.88s/it]                                                       {'loss': 0.0198, 'grad_norm': 6.449520111083984, 'learning_rate': 8.132203389830508e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1202/6000 [1:10:23<5:10:31,  3.88s/it] 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:26<4:59:43,  3.75s/it]                                                       {'loss': 0.0474, 'grad_norm': 9.15656852722168, 'learning_rate': 8.130508474576272e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1203/6000 [1:10:26<4:59:43,  3.75s/it] 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:30<5:01:59,  3.78s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.42351776361465454, 'learning_rate': 8.128813559322035e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1204/6000 [1:10:30<5:01:59,  3.78s/it] 20%|â–ˆâ–ˆ        | 1205/6000 [1:10:34<4:53:49,  3.68s/it]                                                       {'loss': 0.1471, 'grad_norm': 12.602643013000488, 'learning_rate': 8.127118644067798e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1205/6000 [1:10:34<4:53:49,  3.68s/it] 20%|â–ˆâ–ˆ        | 1206/6000 [1:10:37<4:46:50,  3.59s/it]                                                       {'loss': 0.0313, 'grad_norm': 7.325778484344482, 'learning_rate': 8.12542372881356e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1206/6000 [1:10:37<4:46:50,  3.59s/it] 20%|â–ˆâ–ˆ        | 1207/6000 [1:10:40<4:42:17,  3.53s/it]                                                       {'loss': 0.0769, 'grad_norm': 7.865669250488281, 'learning_rate': 8.123728813559323e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1207/6000 [1:10:40<4:42:17,  3.53s/it] 20%|â–ˆâ–ˆ        | 1208/6000 [1:10:44<4:40:27,  3.51s/it]                                                       {'loss': 0.0482, 'grad_norm': 3.6371586322784424, 'learning_rate': 8.122033898305085e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1208/6000 [1:10:44<4:40:27,  3.51s/it] 20%|â–ˆâ–ˆ        | 1209/6000 [1:10:47<4:36:39,  3.46s/it]                                                       {'loss': 0.0098, 'grad_norm': 1.6694892644882202, 'learning_rate': 8.120338983050848e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1209/6000 [1:10:47<4:36:39,  3.46s/it] 20%|â–ˆâ–ˆ        | 1210/6000 [1:10:51<4:37:27,  3.48s/it]                                                       {'loss': 0.2295, 'grad_norm': 16.374177932739258, 'learning_rate': 8.118644067796611e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1210/6000 [1:10:51<4:37:27,  3.48s/it] 20%|â–ˆâ–ˆ        | 1211/6000 [1:10:54<4:38:30,  3.49s/it]                                                       {'loss': 0.0114, 'grad_norm': 2.008636236190796, 'learning_rate': 8.116949152542374e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1211/6000 [1:10:54<4:38:30,  3.49s/it] 20%|â–ˆâ–ˆ        | 1212/6000 [1:10:58<4:37:20,  3.48s/it]                                                       {'loss': 0.1161, 'grad_norm': 13.266048431396484, 'learning_rate': 8.115254237288136e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1212/6000 [1:10:58<4:37:20,  3.48s/it] 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:01<4:34:14,  3.44s/it]                                                       {'loss': 0.058, 'grad_norm': 10.035723686218262, 'learning_rate': 8.1135593220339e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1213/6000 [1:11:01<4:34:14,  3.44s/it] 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:05<4:35:13,  3.45s/it]                                                       {'loss': 0.0372, 'grad_norm': 8.068846702575684, 'learning_rate': 8.111864406779661e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1214/6000 [1:11:05<4:35:13,  3.45s/it] 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:08<4:34:22,  3.44s/it]                                                       {'loss': 0.0431, 'grad_norm': 10.87402629852295, 'learning_rate': 8.110169491525424e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1215/6000 [1:11:08<4:34:22,  3.44s/it] 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:11<4:32:53,  3.42s/it]                                                       {'loss': 0.055, 'grad_norm': 8.14867877960205, 'learning_rate': 8.108474576271187e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1216/6000 [1:11:11<4:32:53,  3.42s/it] 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:15<4:43:59,  3.56s/it]                                                       {'loss': 0.1532, 'grad_norm': 13.471774101257324, 'learning_rate': 8.10677966101695e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1217/6000 [1:11:15<4:43:59,  3.56s/it] 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:19<4:41:25,  3.53s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.8107068538665771, 'learning_rate': 8.105084745762712e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1218/6000 [1:11:19<4:41:25,  3.53s/it] 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:22<4:45:54,  3.59s/it]                                                       {'loss': 0.0279, 'grad_norm': 4.307799816131592, 'learning_rate': 8.103389830508476e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1219/6000 [1:11:22<4:45:54,  3.59s/it] 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:26<4:41:03,  3.53s/it]                                                       {'loss': 0.0447, 'grad_norm': 7.778788089752197, 'learning_rate': 8.101694915254237e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1220/6000 [1:11:26<4:41:03,  3.53s/it] 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:29<4:40:59,  3.53s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.5937984585762024, 'learning_rate': 8.1e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1221/6000 [1:11:29<4:40:59,  3.53s/it] 20%|â–ˆâ–ˆ        | 1222/6000 [1:11:33<4:38:52,  3.50s/it]                                                       {'loss': 0.1391, 'grad_norm': 11.018671989440918, 'learning_rate': 8.098305084745764e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1222/6000 [1:11:33<4:38:52,  3.50s/it] 20%|â–ˆâ–ˆ        | 1223/6000 [1:11:36<4:34:36,  3.45s/it]                                                       {'loss': 0.031, 'grad_norm': 7.706198215484619, 'learning_rate': 8.096610169491525e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1223/6000 [1:11:36<4:34:36,  3.45s/it] 20%|â–ˆâ–ˆ        | 1224/6000 [1:11:39<4:32:32,  3.42s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.9797263145446777, 'learning_rate': 8.094915254237289e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1224/6000 [1:11:39<4:32:32,  3.42s/it] 20%|â–ˆâ–ˆ        | 1225/6000 [1:11:43<4:36:48,  3.48s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.2651132047176361, 'learning_rate': 8.093220338983052e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1225/6000 [1:11:43<4:36:48,  3.48s/it] 20%|â–ˆâ–ˆ        | 1226/6000 [1:11:47<4:43:42,  3.57s/it]                                                       {'loss': 0.1564, 'grad_norm': 12.814732551574707, 'learning_rate': 8.091525423728815e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1226/6000 [1:11:47<4:43:42,  3.57s/it] 20%|â–ˆâ–ˆ        | 1227/6000 [1:11:51<4:51:17,  3.66s/it]                                                       {'loss': 0.0154, 'grad_norm': 4.161064624786377, 'learning_rate': 8.089830508474577e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1227/6000 [1:11:51<4:51:17,  3.66s/it] 20%|â–ˆâ–ˆ        | 1228/6000 [1:11:54<4:45:29,  3.59s/it]                                                       {'loss': 0.0519, 'grad_norm': 2.633378744125366, 'learning_rate': 8.08813559322034e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1228/6000 [1:11:54<4:45:29,  3.59s/it] 20%|â–ˆâ–ˆ        | 1229/6000 [1:11:57<4:39:16,  3.51s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.9075273275375366, 'learning_rate': 8.086440677966101e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1229/6000 [1:11:57<4:39:16,  3.51s/it] 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:01<4:36:45,  3.48s/it]                                                       {'loss': 0.0943, 'grad_norm': 10.5435791015625, 'learning_rate': 8.084745762711865e-06, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1230/6000 [1:12:01<4:36:45,  3.48s/it] 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:04<4:34:33,  3.45s/it]                                                       {'loss': 0.1775, 'grad_norm': 17.398012161254883, 'learning_rate': 8.083050847457628e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1231/6000 [1:12:04<4:34:33,  3.45s/it] 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:08<4:33:51,  3.45s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.3850786089897156, 'learning_rate': 8.081355932203391e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1232/6000 [1:12:08<4:33:51,  3.45s/it] 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:12<4:45:29,  3.59s/it]                                                       {'loss': 0.0153, 'grad_norm': 3.5803048610687256, 'learning_rate': 8.079661016949153e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1233/6000 [1:12:12<4:45:29,  3.59s/it] 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:15<4:52:16,  3.68s/it]                                                       {'loss': 0.2602, 'grad_norm': 20.89600372314453, 'learning_rate': 8.077966101694916e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1234/6000 [1:12:16<4:52:16,  3.68s/it] 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:19<4:46:01,  3.60s/it]                                                       {'loss': 0.0076, 'grad_norm': 2.8164284229278564, 'learning_rate': 8.076271186440678e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1235/6000 [1:12:19<4:46:01,  3.60s/it] 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:22<4:41:00,  3.54s/it]                                                       {'loss': 0.0664, 'grad_norm': 9.321102142333984, 'learning_rate': 8.074576271186441e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1236/6000 [1:12:22<4:41:00,  3.54s/it] 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:26<4:37:05,  3.49s/it]                                                       {'loss': 0.0272, 'grad_norm': 5.100062847137451, 'learning_rate': 8.072881355932204e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1237/6000 [1:12:26<4:37:05,  3.49s/it] 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:29<4:35:50,  3.48s/it]                                                       {'loss': 0.0536, 'grad_norm': 12.558065414428711, 'learning_rate': 8.071186440677968e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1238/6000 [1:12:29<4:35:50,  3.48s/it] 21%|â–ˆâ–ˆ        | 1239/6000 [1:12:33<4:36:18,  3.48s/it]                                                       {'loss': 0.0578, 'grad_norm': 6.559774875640869, 'learning_rate': 8.069491525423729e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1239/6000 [1:12:33<4:36:18,  3.48s/it] 21%|â–ˆâ–ˆ        | 1240/6000 [1:12:36<4:36:08,  3.48s/it]                                                       {'loss': 0.0446, 'grad_norm': 6.263091564178467, 'learning_rate': 8.067796610169492e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1240/6000 [1:12:36<4:36:08,  3.48s/it] 21%|â–ˆâ–ˆ        | 1241/6000 [1:12:39<4:33:50,  3.45s/it]                                                       {'loss': 0.0159, 'grad_norm': 5.773860931396484, 'learning_rate': 8.066101694915256e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1241/6000 [1:12:39<4:33:50,  3.45s/it] 21%|â–ˆâ–ˆ        | 1242/6000 [1:12:43<4:36:56,  3.49s/it]                                                       {'loss': 0.2205, 'grad_norm': 21.181123733520508, 'learning_rate': 8.064406779661019e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1242/6000 [1:12:43<4:36:56,  3.49s/it] 21%|â–ˆâ–ˆ        | 1243/6000 [1:12:47<4:35:21,  3.47s/it]                                                       {'loss': 0.0109, 'grad_norm': 3.135247230529785, 'learning_rate': 8.06271186440678e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1243/6000 [1:12:47<4:35:21,  3.47s/it] 21%|â–ˆâ–ˆ        | 1244/6000 [1:12:50<4:32:30,  3.44s/it]                                                       {'loss': 0.0687, 'grad_norm': 11.24184799194336, 'learning_rate': 8.061016949152542e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1244/6000 [1:12:50<4:32:30,  3.44s/it] 21%|â–ˆâ–ˆ        | 1245/6000 [1:12:53<4:30:37,  3.41s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.39823436737060547, 'learning_rate': 8.059322033898305e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1245/6000 [1:12:53<4:30:37,  3.41s/it] 21%|â–ˆâ–ˆ        | 1246/6000 [1:12:57<4:29:30,  3.40s/it]                                                       {'loss': 0.0095, 'grad_norm': 2.6304495334625244, 'learning_rate': 8.057627118644069e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1246/6000 [1:12:57<4:29:30,  3.40s/it] 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:00<4:30:20,  3.41s/it]                                                       {'loss': 0.044, 'grad_norm': 4.165726184844971, 'learning_rate': 8.055932203389832e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1247/6000 [1:13:00<4:30:20,  3.41s/it] 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:03<4:29:53,  3.41s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.41724663972854614, 'learning_rate': 8.054237288135594e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1248/6000 [1:13:03<4:29:53,  3.41s/it] 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:07<4:30:01,  3.41s/it]                                                       {'loss': 0.152, 'grad_norm': 12.47577953338623, 'learning_rate': 8.052542372881357e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1249/6000 [1:13:07<4:30:01,  3.41s/it] 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:10<4:33:00,  3.45s/it]                                                       {'loss': 0.1385, 'grad_norm': 13.289422988891602, 'learning_rate': 8.050847457627118e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1250/6000 [1:13:10<4:33:00,  3.45s/it] 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:14<4:31:38,  3.43s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.798008143901825, 'learning_rate': 8.049152542372882e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1251/6000 [1:13:14<4:31:38,  3.43s/it] 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:17<4:29:13,  3.40s/it]                                                       {'loss': 0.2208, 'grad_norm': 17.113874435424805, 'learning_rate': 8.047457627118645e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1252/6000 [1:13:17<4:29:13,  3.40s/it] 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:21<4:43:10,  3.58s/it]                                                       {'loss': 0.1228, 'grad_norm': 12.832052230834961, 'learning_rate': 8.045762711864408e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1253/6000 [1:13:21<4:43:10,  3.58s/it] 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:24<4:36:52,  3.50s/it]                                                       {'loss': 0.0154, 'grad_norm': 2.5385639667510986, 'learning_rate': 8.04406779661017e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1254/6000 [1:13:24<4:36:52,  3.50s/it] 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:28<4:35:14,  3.48s/it]                                                       {'loss': 0.0319, 'grad_norm': 8.78764533996582, 'learning_rate': 8.042372881355933e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1255/6000 [1:13:28<4:35:14,  3.48s/it] 21%|â–ˆâ–ˆ        | 1256/6000 [1:13:31<4:34:42,  3.47s/it]                                                       {'loss': 0.0174, 'grad_norm': 3.725802183151245, 'learning_rate': 8.040677966101695e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1256/6000 [1:13:31<4:34:42,  3.47s/it] 21%|â–ˆâ–ˆ        | 1257/6000 [1:13:35<4:32:21,  3.45s/it]                                                       {'loss': 0.0269, 'grad_norm': 8.336357116699219, 'learning_rate': 8.038983050847458e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1257/6000 [1:13:35<4:32:21,  3.45s/it] 21%|â–ˆâ–ˆ        | 1258/6000 [1:13:38<4:35:38,  3.49s/it]                                                       {'loss': 0.0439, 'grad_norm': 7.039372444152832, 'learning_rate': 8.037288135593221e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1258/6000 [1:13:38<4:35:38,  3.49s/it] 21%|â–ˆâ–ˆ        | 1259/6000 [1:13:42<4:33:13,  3.46s/it]                                                       {'loss': 0.4319, 'grad_norm': 18.986879348754883, 'learning_rate': 8.035593220338984e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1259/6000 [1:13:42<4:33:13,  3.46s/it] 21%|â–ˆâ–ˆ        | 1260/6000 [1:13:45<4:32:18,  3.45s/it]                                                       {'loss': 0.056, 'grad_norm': 6.972418308258057, 'learning_rate': 8.033898305084746e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1260/6000 [1:13:45<4:32:18,  3.45s/it] 21%|â–ˆâ–ˆ        | 1261/6000 [1:13:49<4:32:15,  3.45s/it]                                                       {'loss': 0.0537, 'grad_norm': 10.046673774719238, 'learning_rate': 8.03220338983051e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1261/6000 [1:13:49<4:32:15,  3.45s/it] 21%|â–ˆâ–ˆ        | 1262/6000 [1:13:52<4:42:13,  3.57s/it]                                                       {'loss': 0.067, 'grad_norm': 7.339526653289795, 'learning_rate': 8.030508474576273e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1262/6000 [1:13:52<4:42:13,  3.57s/it] 21%|â–ˆâ–ˆ        | 1263/6000 [1:13:56<4:43:31,  3.59s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.8616605997085571, 'learning_rate': 8.028813559322036e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1263/6000 [1:13:56<4:43:31,  3.59s/it] 21%|â–ˆâ–ˆ        | 1264/6000 [1:13:59<4:39:41,  3.54s/it]                                                       {'loss': 0.0181, 'grad_norm': 6.217051029205322, 'learning_rate': 8.027118644067797e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1264/6000 [1:13:59<4:39:41,  3.54s/it] 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:03<4:39:21,  3.54s/it]                                                       {'loss': 0.0597, 'grad_norm': 7.478448867797852, 'learning_rate': 8.025423728813559e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1265/6000 [1:14:03<4:39:21,  3.54s/it] 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:07<4:38:59,  3.54s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.5615047812461853, 'learning_rate': 8.023728813559322e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1266/6000 [1:14:07<4:38:59,  3.54s/it] 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:10<4:46:30,  3.63s/it]                                                       {'loss': 0.0759, 'grad_norm': 11.194385528564453, 'learning_rate': 8.022033898305086e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1267/6000 [1:14:10<4:46:30,  3.63s/it] 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:14<4:39:10,  3.54s/it]                                                       {'loss': 0.0378, 'grad_norm': 7.729430198669434, 'learning_rate': 8.020338983050849e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1268/6000 [1:14:14<4:39:10,  3.54s/it] 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:17<4:37:25,  3.52s/it]                                                       {'loss': 0.0509, 'grad_norm': 11.967803001403809, 'learning_rate': 8.01864406779661e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1269/6000 [1:14:17<4:37:25,  3.52s/it] 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:21<4:35:10,  3.49s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3761807978153229, 'learning_rate': 8.016949152542374e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1270/6000 [1:14:21<4:35:10,  3.49s/it] 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:24<4:36:06,  3.50s/it]                                                       {'loss': 0.1085, 'grad_norm': 14.383737564086914, 'learning_rate': 8.015254237288135e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1271/6000 [1:14:24<4:36:06,  3.50s/it] 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:28<4:42:39,  3.59s/it]                                                       {'loss': 0.0452, 'grad_norm': 6.9977240562438965, 'learning_rate': 8.013559322033899e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1272/6000 [1:14:28<4:42:39,  3.59s/it] 21%|â–ˆâ–ˆ        | 1273/6000 [1:14:31<4:36:39,  3.51s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.73987078666687, 'learning_rate': 8.011864406779662e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1273/6000 [1:14:31<4:36:39,  3.51s/it] 21%|â–ˆâ–ˆ        | 1274/6000 [1:14:35<4:32:25,  3.46s/it]                                                       {'loss': 0.0178, 'grad_norm': 6.462172031402588, 'learning_rate': 8.010169491525425e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1274/6000 [1:14:35<4:32:25,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:14:38<4:31:37,  3.45s/it]                                                       {'loss': 0.1736, 'grad_norm': 12.256689071655273, 'learning_rate': 8.008474576271187e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1275/6000 [1:14:38<4:31:37,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:14:42<4:33:15,  3.47s/it]                                                       {'loss': 0.2626, 'grad_norm': 19.378446578979492, 'learning_rate': 8.00677966101695e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1276/6000 [1:14:42<4:33:15,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:14:45<4:33:03,  3.47s/it]                                                       {'loss': 0.2997, 'grad_norm': 25.981760025024414, 'learning_rate': 8.005084745762712e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1277/6000 [1:14:45<4:33:03,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:14:48<4:33:05,  3.47s/it]                                                       {'loss': 0.1211, 'grad_norm': 9.05313491821289, 'learning_rate': 8.003389830508475e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1278/6000 [1:14:48<4:33:05,  3.47s/it] 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:14:52<4:30:29,  3.44s/it]                                                       {'loss': 0.2749, 'grad_norm': 19.441993713378906, 'learning_rate': 8.001694915254238e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1279/6000 [1:14:52<4:30:29,  3.44s/it] 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:14:55<4:31:42,  3.45s/it]                                                       {'loss': 0.0133, 'grad_norm': 4.056140422821045, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1280/6000 [1:14:55<4:31:42,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:14:59<4:33:46,  3.48s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.465989828109741, 'learning_rate': 7.998305084745763e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1281/6000 [1:14:59<4:33:46,  3.48s/it] 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:02<4:31:12,  3.45s/it]                                                       {'loss': 0.0205, 'grad_norm': 3.300321578979492, 'learning_rate': 7.996610169491526e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1282/6000 [1:15:02<4:31:12,  3.45s/it] 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:06<4:27:12,  3.40s/it]                                                       {'loss': 0.0433, 'grad_norm': 6.517421722412109, 'learning_rate': 7.99491525423729e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1283/6000 [1:15:06<4:27:12,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:09<4:27:21,  3.40s/it]                                                       {'loss': 0.0374, 'grad_norm': 6.71877384185791, 'learning_rate': 7.993220338983053e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1284/6000 [1:15:09<4:27:21,  3.40s/it] 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:12<4:26:30,  3.39s/it]                                                       {'loss': 0.0385, 'grad_norm': 3.9728901386260986, 'learning_rate': 7.991525423728814e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1285/6000 [1:15:12<4:26:30,  3.39s/it] 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:16<4:28:35,  3.42s/it]                                                       {'loss': 0.0592, 'grad_norm': 8.953888893127441, 'learning_rate': 7.989830508474576e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1286/6000 [1:15:16<4:28:35,  3.42s/it] 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:19<4:31:53,  3.46s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.8228672742843628, 'learning_rate': 7.98813559322034e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1287/6000 [1:15:19<4:31:53,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:23<4:31:21,  3.46s/it]                                                       {'loss': 0.108, 'grad_norm': 11.963822364807129, 'learning_rate': 7.986440677966102e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:15:23<4:31:21,  3.46s/it] 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:26<4:28:13,  3.42s/it]                                                       {'loss': 0.0393, 'grad_norm': 8.167784690856934, 'learning_rate': 7.984745762711866e-06, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:15:26<4:28:13,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:30<4:28:55,  3.43s/it]                                                       {'loss': 0.0027, 'grad_norm': 1.2272897958755493, 'learning_rate': 7.983050847457627e-06, 'epoch': 0.21}
 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:15:30<4:28:55,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:15:33<4:27:36,  3.41s/it]                                                       {'loss': 0.0525, 'grad_norm': 8.597405433654785, 'learning_rate': 7.98135593220339e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:15:33<4:27:36,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:15:36<4:27:34,  3.41s/it]                                                       {'loss': 0.0367, 'grad_norm': 8.786832809448242, 'learning_rate': 7.979661016949152e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:15:36<4:27:34,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:15:40<4:29:23,  3.43s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5036866068840027, 'learning_rate': 7.977966101694915e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:15:40<4:29:23,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:15:43<4:25:43,  3.39s/it]                                                       {'loss': 0.0791, 'grad_norm': 9.808394432067871, 'learning_rate': 7.976271186440679e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:15:43<4:25:43,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:15:46<4:24:30,  3.37s/it]                                                       {'loss': 0.0061, 'grad_norm': 2.2169718742370605, 'learning_rate': 7.974576271186442e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:15:46<4:24:30,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:15:50<4:25:58,  3.39s/it]                                                       {'loss': 0.009, 'grad_norm': 2.1088433265686035, 'learning_rate': 7.972881355932204e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:15:50<4:25:58,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:15:54<4:33:48,  3.49s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.5686736106872559, 'learning_rate': 7.971186440677967e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:15:54<4:33:48,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:15:57<4:33:06,  3.48s/it]                                                       {'loss': 0.1236, 'grad_norm': 12.452154159545898, 'learning_rate': 7.96949152542373e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:15:57<4:33:06,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:01<4:31:42,  3.47s/it]                                                       {'loss': 0.0171, 'grad_norm': 4.032228946685791, 'learning_rate': 7.967796610169493e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:16:01<4:31:42,  3.47s/it] 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:04<4:30:54,  3.46s/it]                                                       {'loss': 0.0799, 'grad_norm': 10.016631126403809, 'learning_rate': 7.966101694915255e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:16:04<4:30:54,  3.46s/it][2025-11-07 00:07:13,941] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300
[2025-11-07 00:07:13,954] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:07:14,612] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:10<5:23:04,  4.13s/it]                                                       {'loss': 0.0165, 'grad_norm': 3.2019574642181396, 'learning_rate': 7.964406779661018e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:16:10<5:23:04,  4.13s/it] 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:13<5:04:51,  3.89s/it]                                                       {'loss': 0.0332, 'grad_norm': 5.421543598175049, 'learning_rate': 7.96271186440678e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:16:13<5:04:51,  3.89s/it] 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:16<4:52:21,  3.73s/it]                                                       {'loss': 0.0219, 'grad_norm': 4.312017917633057, 'learning_rate': 7.961016949152543e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:16:16<4:52:21,  3.73s/it] 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:16:20<4:45:37,  3.65s/it]                                                       {'loss': 0.0634, 'grad_norm': 12.554283142089844, 'learning_rate': 7.959322033898306e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:16:20<4:45:37,  3.65s/it] 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:16:23<4:37:26,  3.55s/it]                                                       {'loss': 0.0875, 'grad_norm': 12.776884078979492, 'learning_rate': 7.957627118644068e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:16:23<4:37:26,  3.55s/it] 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:16:27<4:37:14,  3.54s/it]                                                       {'loss': 0.0361, 'grad_norm': 6.274105072021484, 'learning_rate': 7.955932203389831e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:16:27<4:37:14,  3.54s/it] 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:16:30<4:33:44,  3.50s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.5814329385757446, 'learning_rate': 7.954237288135593e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:16:30<4:33:44,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:16:34<4:33:33,  3.50s/it]                                                       {'loss': 0.1231, 'grad_norm': 16.289073944091797, 'learning_rate': 7.952542372881356e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:16:34<4:33:33,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:16:37<4:31:47,  3.48s/it]                                                       {'loss': 0.0075, 'grad_norm': 2.233578681945801, 'learning_rate': 7.95084745762712e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:16:37<4:31:47,  3.48s/it] 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:16:40<4:30:36,  3.46s/it]                                                       {'loss': 0.0682, 'grad_norm': 7.847659587860107, 'learning_rate': 7.949152542372883e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:16:40<4:30:36,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:16:44<4:26:52,  3.41s/it]                                                       {'loss': 0.0137, 'grad_norm': 2.444751739501953, 'learning_rate': 7.947457627118644e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:16:44<4:26:52,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:16:47<4:28:57,  3.44s/it]                                                       {'loss': 0.4694, 'grad_norm': 23.162429809570312, 'learning_rate': 7.945762711864407e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:16:47<4:28:57,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:16:51<4:27:10,  3.42s/it]                                                       {'loss': 0.0803, 'grad_norm': 8.94834041595459, 'learning_rate': 7.944067796610169e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:16:51<4:27:10,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:16:54<4:25:09,  3.40s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5420681834220886, 'learning_rate': 7.942372881355932e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:16:54<4:25:09,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:16:57<4:23:51,  3.38s/it]                                                       {'loss': 0.2105, 'grad_norm': 10.64113712310791, 'learning_rate': 7.940677966101696e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:16:57<4:23:51,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:01<4:25:27,  3.40s/it]                                                       {'loss': 0.3, 'grad_norm': 11.887306213378906, 'learning_rate': 7.938983050847459e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:17:01<4:25:27,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:04<4:24:00,  3.38s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.49138787388801575, 'learning_rate': 7.93728813559322e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:17:04<4:24:00,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:07<4:23:53,  3.38s/it]                                                       {'loss': 0.0406, 'grad_norm': 6.614527225494385, 'learning_rate': 7.935593220338984e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:17:07<4:23:53,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:11<4:23:06,  3.37s/it]                                                       {'loss': 0.2104, 'grad_norm': 14.863029479980469, 'learning_rate': 7.933898305084747e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:17:11<4:23:06,  3.37s/it] 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:14<4:23:50,  3.38s/it]                                                       {'loss': 0.1085, 'grad_norm': 18.517608642578125, 'learning_rate': 7.93220338983051e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:17:14<4:23:50,  3.38s/it] 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:18<4:25:43,  3.41s/it]                                                       {'loss': 0.3049, 'grad_norm': 20.69586753845215, 'learning_rate': 7.930508474576272e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:17:18<4:25:43,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:17:22<4:38:14,  3.57s/it]                                                       {'loss': 0.0641, 'grad_norm': 12.755060195922852, 'learning_rate': 7.928813559322035e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:17:22<4:38:14,  3.57s/it] 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:17:25<4:36:40,  3.55s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.8962562084198, 'learning_rate': 7.927118644067797e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:17:25<4:36:40,  3.55s/it] 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:17:28<4:32:51,  3.50s/it]                                                       {'loss': 0.0259, 'grad_norm': 6.947087287902832, 'learning_rate': 7.92542372881356e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:17:28<4:32:51,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:17:32<4:29:25,  3.46s/it]                                                       {'loss': 0.0419, 'grad_norm': 8.217235565185547, 'learning_rate': 7.923728813559323e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:17:32<4:29:25,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:17:35<4:27:04,  3.43s/it]                                                       {'loss': 0.0791, 'grad_norm': 16.34524154663086, 'learning_rate': 7.922033898305085e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:17:35<4:27:04,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:17:39<4:27:26,  3.43s/it]                                                       {'loss': 0.0136, 'grad_norm': 4.205998420715332, 'learning_rate': 7.920338983050848e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:17:39<4:27:26,  3.43s/it] 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:17:42<4:26:30,  3.42s/it]                                                       {'loss': 0.0858, 'grad_norm': 13.984919548034668, 'learning_rate': 7.91864406779661e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:17:42<4:26:30,  3.42s/it] 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:17:46<4:35:10,  3.53s/it]                                                       {'loss': 0.0177, 'grad_norm': 4.348350524902344, 'learning_rate': 7.916949152542373e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:17:46<4:35:10,  3.53s/it] 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:17:49<4:32:03,  3.50s/it]                                                       {'loss': 0.0514, 'grad_norm': 6.533438205718994, 'learning_rate': 7.915254237288136e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:17:49<4:32:03,  3.50s/it] 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:17:53<4:31:33,  3.49s/it]                                                       {'loss': 0.186, 'grad_norm': 14.160493850708008, 'learning_rate': 7.9135593220339e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:17:53<4:31:33,  3.49s/it] 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:17:56<4:28:19,  3.45s/it]                                                       {'loss': 0.1321, 'grad_norm': 11.241432189941406, 'learning_rate': 7.911864406779661e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:17:56<4:28:19,  3.45s/it] 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:00<4:29:05,  3.46s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.9096591472625732, 'learning_rate': 7.910169491525424e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:18:00<4:29:05,  3.46s/it] 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:03<4:34:22,  3.53s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.8556944131851196, 'learning_rate': 7.908474576271186e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:18:03<4:34:22,  3.53s/it] 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:07<4:29:47,  3.47s/it]                                                       {'loss': 0.078, 'grad_norm': 9.422800064086914, 'learning_rate': 7.906779661016951e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:18:07<4:29:47,  3.47s/it] 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:10<4:27:18,  3.44s/it]                                                       {'loss': 0.0159, 'grad_norm': 3.6710402965545654, 'learning_rate': 7.905084745762712e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:18:10<4:27:18,  3.44s/it] 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:13<4:24:29,  3.40s/it]                                                       {'loss': 0.0947, 'grad_norm': 9.778867721557617, 'learning_rate': 7.903389830508476e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:18:13<4:24:29,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:17<4:24:03,  3.40s/it]                                                       {'loss': 0.01, 'grad_norm': 2.830960273742676, 'learning_rate': 7.901694915254237e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:18:17<4:24:03,  3.40s/it] 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:18:20<4:23:16,  3.39s/it]                                                       {'loss': 0.0145, 'grad_norm': 2.1912612915039062, 'learning_rate': 7.9e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:18:20<4:23:16,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:18:23<4:23:01,  3.39s/it]                                                       {'loss': 0.0933, 'grad_norm': 14.345001220703125, 'learning_rate': 7.898305084745764e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:18:23<4:23:01,  3.39s/it] 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:18:27<4:24:25,  3.41s/it]                                                       {'loss': 0.2198, 'grad_norm': 18.438772201538086, 'learning_rate': 7.896610169491527e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:18:27<4:24:25,  3.41s/it] 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:18:31<4:33:17,  3.52s/it]                                                       {'loss': 0.3003, 'grad_norm': 20.2120418548584, 'learning_rate': 7.894915254237289e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:18:31<4:33:17,  3.52s/it] 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:18:34<4:40:30,  3.61s/it]                                                       {'loss': 0.0963, 'grad_norm': 8.424736976623535, 'learning_rate': 7.893220338983052e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:18:34<4:40:30,  3.61s/it] 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:18:38<4:36:07,  3.56s/it]                                                       {'loss': 0.0085, 'grad_norm': 2.998915433883667, 'learning_rate': 7.891525423728814e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:18:38<4:36:07,  3.56s/it] 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:18:42<4:40:23,  3.61s/it]                                                       {'loss': 0.0856, 'grad_norm': 9.556790351867676, 'learning_rate': 7.889830508474577e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:18:42<4:40:23,  3.61s/it] 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:18:45<4:37:00,  3.57s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2473619431257248, 'learning_rate': 7.88813559322034e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:18:45<4:37:00,  3.57s/it] 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:18:49<4:37:11,  3.57s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.6737786531448364, 'learning_rate': 7.886440677966102e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:18:49<4:37:11,  3.57s/it] 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:18:52<4:33:11,  3.52s/it]                                                       {'loss': 0.0094, 'grad_norm': 1.8522456884384155, 'learning_rate': 7.884745762711865e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:18:52<4:33:11,  3.52s/it] 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:18:56<4:39:29,  3.61s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.6974059343338013, 'learning_rate': 7.883050847457627e-06, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:18:56<4:39:29,  3.61s/it] 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:00<4:39:46,  3.61s/it]                                                       {'loss': 0.0717, 'grad_norm': 12.773274421691895, 'learning_rate': 7.88135593220339e-06, 'epoch': 0.23}
 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:19:00<4:39:46,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:03<4:34:03,  3.54s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016146261245012283, 'learning_rate': 7.879661016949153e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:19:03<4:34:03,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:06<4:32:26,  3.52s/it]                                                       {'loss': 0.0348, 'grad_norm': 6.475218772888184, 'learning_rate': 7.877966101694916e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:19:06<4:32:26,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:10<4:35:24,  3.56s/it]                                                       {'loss': 0.033, 'grad_norm': 6.947249889373779, 'learning_rate': 7.876271186440678e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:19:10<4:35:24,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:13<4:32:30,  3.52s/it]                                                       {'loss': 0.0233, 'grad_norm': 6.737204551696777, 'learning_rate': 7.874576271186441e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:19:13<4:32:30,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:17<4:33:52,  3.54s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.1853930950164795, 'learning_rate': 7.872881355932205e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:19:17<4:33:52,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:19:21<4:46:19,  3.70s/it]                                                       {'loss': 0.0219, 'grad_norm': 4.835008144378662, 'learning_rate': 7.871186440677968e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:19:21<4:46:19,  3.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:19:25<4:43:36,  3.66s/it]                                                       {'loss': 0.0292, 'grad_norm': 8.045376777648926, 'learning_rate': 7.86949152542373e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:19:25<4:43:36,  3.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:19:28<4:39:22,  3.61s/it]                                                       {'loss': 0.0754, 'grad_norm': 14.27833366394043, 'learning_rate': 7.867796610169493e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:19:28<4:39:22,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:19:32<4:41:34,  3.64s/it]                                                       {'loss': 0.007, 'grad_norm': 1.4707260131835938, 'learning_rate': 7.866101694915254e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:19:32<4:41:34,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:19:35<4:34:27,  3.55s/it]                                                       {'loss': 0.1194, 'grad_norm': 8.277283668518066, 'learning_rate': 7.864406779661017e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:19:35<4:34:27,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:19:39<4:29:27,  3.49s/it]                                                       {'loss': 0.1241, 'grad_norm': 20.78478240966797, 'learning_rate': 7.86271186440678e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:19:39<4:29:27,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:19:42<4:32:02,  3.52s/it]                                                       {'loss': 0.0449, 'grad_norm': 11.073339462280273, 'learning_rate': 7.861016949152544e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:19:42<4:32:02,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:19:46<4:30:40,  3.50s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.23432879149913788, 'learning_rate': 7.859322033898306e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:19:46<4:30:40,  3.50s/it] 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:19:49<4:25:46,  3.44s/it]                                                       {'loss': 0.0358, 'grad_norm': 6.062198162078857, 'learning_rate': 7.857627118644069e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:19:49<4:25:46,  3.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:19:53<4:34:07,  3.55s/it]                                                       {'loss': 0.0098, 'grad_norm': 4.306515216827393, 'learning_rate': 7.85593220338983e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:19:53<4:34:07,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:19:57<4:44:36,  3.69s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.7627397179603577, 'learning_rate': 7.854237288135594e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:19:57<4:44:36,  3.69s/it] 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:01<4:48:47,  3.74s/it]                                                       {'loss': 0.0813, 'grad_norm': 10.643537521362305, 'learning_rate': 7.852542372881357e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:20:01<4:48:47,  3.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:04<4:40:40,  3.64s/it]                                                       {'loss': 0.0187, 'grad_norm': 8.900355339050293, 'learning_rate': 7.850847457627119e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:20:04<4:40:40,  3.64s/it] 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:07<4:34:09,  3.55s/it]                                                       {'loss': 0.0283, 'grad_norm': 5.505924701690674, 'learning_rate': 7.849152542372882e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:20:07<4:34:09,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:12<4:53:36,  3.80s/it]                                                       {'loss': 0.1251, 'grad_norm': 10.4619722366333, 'learning_rate': 7.847457627118643e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:20:12<4:53:36,  3.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:15<4:47:52,  3.73s/it]                                                       {'loss': 0.0338, 'grad_norm': 6.713650226593018, 'learning_rate': 7.845762711864407e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:20:15<4:47:52,  3.73s/it] 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:20:19<4:39:27,  3.62s/it]                                                       {'loss': 0.021, 'grad_norm': 4.490299224853516, 'learning_rate': 7.84406779661017e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:20:19<4:39:27,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:20:22<4:38:06,  3.61s/it]                                                       {'loss': 0.0493, 'grad_norm': 13.163383483886719, 'learning_rate': 7.842372881355933e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:20:22<4:38:06,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:20:26<4:38:55,  3.62s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.4869076907634735, 'learning_rate': 7.840677966101695e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:20:26<4:38:55,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:20:29<4:36:49,  3.59s/it]                                                       {'loss': 0.0562, 'grad_norm': 13.770727157592773, 'learning_rate': 7.838983050847458e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:20:29<4:36:49,  3.59s/it] 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:20:33<4:38:10,  3.61s/it]                                                       {'loss': 0.1973, 'grad_norm': 22.638460159301758, 'learning_rate': 7.837288135593221e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:20:33<4:38:10,  3.61s/it] 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:20:36<4:32:05,  3.53s/it]                                                       {'loss': 0.1959, 'grad_norm': 9.907580375671387, 'learning_rate': 7.835593220338985e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:20:36<4:32:05,  3.53s/it] 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:20:40<4:27:25,  3.47s/it]                                                       {'loss': 0.0145, 'grad_norm': 3.7080724239349365, 'learning_rate': 7.833898305084746e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:20:40<4:27:25,  3.47s/it] 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:20:43<4:25:56,  3.45s/it]                                                       {'loss': 0.0988, 'grad_norm': 13.789315223693848, 'learning_rate': 7.83220338983051e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:20:43<4:25:56,  3.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:20:46<4:22:33,  3.41s/it]                                                       {'loss': 0.0601, 'grad_norm': 8.364126205444336, 'learning_rate': 7.830508474576271e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:20:46<4:22:33,  3.41s/it] 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:20:50<4:30:17,  3.51s/it]                                                       {'loss': 0.3845, 'grad_norm': 23.019941329956055, 'learning_rate': 7.828813559322034e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:20:50<4:30:17,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:20:54<4:30:06,  3.51s/it]                                                       {'loss': 0.2463, 'grad_norm': 14.904558181762695, 'learning_rate': 7.827118644067798e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:20:54<4:30:06,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:20:57<4:31:03,  3.52s/it]                                                       {'loss': 0.007, 'grad_norm': 2.083807945251465, 'learning_rate': 7.825423728813561e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:20:57<4:31:03,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:01<4:35:42,  3.58s/it]                                                       {'loss': 0.141, 'grad_norm': 6.145825386047363, 'learning_rate': 7.823728813559322e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:21:01<4:35:42,  3.58s/it] 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:04<4:31:01,  3.52s/it]                                                       {'loss': 0.0933, 'grad_norm': 14.139666557312012, 'learning_rate': 7.822033898305086e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:21:04<4:31:01,  3.52s/it] 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:08<4:30:10,  3.51s/it]                                                       {'loss': 0.0315, 'grad_norm': 9.475747108459473, 'learning_rate': 7.820338983050847e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:21:08<4:30:10,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:11<4:27:28,  3.48s/it]                                                       {'loss': 0.0436, 'grad_norm': 8.415322303771973, 'learning_rate': 7.81864406779661e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:21:11<4:27:28,  3.48s/it] 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:15<4:29:37,  3.51s/it]                                                       {'loss': 0.1307, 'grad_norm': 12.887704849243164, 'learning_rate': 7.816949152542374e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:21:15<4:29:37,  3.51s/it] 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:21:19<4:45:58,  3.72s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2262677252292633, 'learning_rate': 7.815254237288135e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:21:19<4:45:58,  3.72s/it] 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:21:22<4:38:05,  3.62s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.623333215713501, 'learning_rate': 7.813559322033899e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:21:22<4:38:05,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:21:26<4:31:20,  3.53s/it]                                                       {'loss': 0.0198, 'grad_norm': 5.467604637145996, 'learning_rate': 7.811864406779662e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:21:26<4:31:20,  3.53s/it] 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:21:29<4:35:03,  3.58s/it]                                                       {'loss': 0.0585, 'grad_norm': 11.486738204956055, 'learning_rate': 7.810169491525425e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:21:29<4:35:03,  3.58s/it] 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:21:33<4:33:27,  3.56s/it]                                                       {'loss': 0.0581, 'grad_norm': 13.419852256774902, 'learning_rate': 7.808474576271187e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:21:33<4:33:27,  3.56s/it] 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:21:36<4:28:10,  3.49s/it]                                                       {'loss': 0.08, 'grad_norm': 7.395994663238525, 'learning_rate': 7.80677966101695e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:21:36<4:28:10,  3.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:21:40<4:26:40,  3.47s/it]                                                       {'loss': 0.2492, 'grad_norm': 14.70354175567627, 'learning_rate': 7.805084745762712e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:21:40<4:26:40,  3.47s/it] 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:21:43<4:25:31,  3.46s/it]                                                       {'loss': 0.0109, 'grad_norm': 3.4157800674438477, 'learning_rate': 7.803389830508475e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:21:43<4:25:31,  3.46s/it] 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:21:47<4:24:32,  3.45s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.6735928058624268, 'learning_rate': 7.801694915254238e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:21:47<4:24:32,  3.45s/it] 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:21:50<4:22:31,  3.42s/it]                                                       {'loss': 0.0389, 'grad_norm': 6.571635723114014, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:21:50<4:22:31,  3.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:21:53<4:21:56,  3.42s/it]                                                       {'loss': 0.172, 'grad_norm': 13.299400329589844, 'learning_rate': 7.798305084745763e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:21:53<4:21:56,  3.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:21:57<4:21:20,  3.41s/it]                                                       {'loss': 0.0107, 'grad_norm': 4.407431125640869, 'learning_rate': 7.796610169491526e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:21:57<4:21:20,  3.41s/it][2025-11-07 00:13:06,713] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400
[2025-11-07 00:13:06,726] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:13:07,403] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:02<5:13:05,  4.08s/it]                                                       {'loss': 0.0513, 'grad_norm': 10.817037582397461, 'learning_rate': 7.794915254237288e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:22:02<5:13:05,  4.08s/it] 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:06<4:58:05,  3.89s/it]                                                       {'loss': 0.1851, 'grad_norm': 13.752202987670898, 'learning_rate': 7.793220338983051e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:22:06<4:58:05,  3.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:09<4:46:31,  3.74s/it]                                                       {'loss': 0.0473, 'grad_norm': 8.941268920898438, 'learning_rate': 7.791525423728815e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:22:09<4:46:31,  3.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:13<4:37:27,  3.62s/it]                                                       {'loss': 0.0535, 'grad_norm': 5.130894184112549, 'learning_rate': 7.789830508474578e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:22:13<4:37:27,  3.62s/it] 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:16<4:32:00,  3.55s/it]                                                       {'loss': 0.223, 'grad_norm': 12.40120792388916, 'learning_rate': 7.78813559322034e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:22:16<4:32:00,  3.55s/it] 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:22:19<4:29:59,  3.53s/it]                                                       {'loss': 0.0631, 'grad_norm': 7.984808921813965, 'learning_rate': 7.786440677966103e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:22:19<4:29:59,  3.53s/it] 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:22:23<4:35:57,  3.60s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.30741459131240845, 'learning_rate': 7.784745762711864e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:22:23<4:35:57,  3.60s/it] 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:22:27<4:31:16,  3.54s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07047419995069504, 'learning_rate': 7.783050847457628e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:22:27<4:31:16,  3.54s/it] 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:22:30<4:27:53,  3.50s/it]                                                       {'loss': 0.004, 'grad_norm': 0.6495026350021362, 'learning_rate': 7.78135593220339e-06, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:22:30<4:27:53,  3.50s/it] 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:22:34<4:34:37,  3.59s/it]                                                       {'loss': 0.0888, 'grad_norm': 8.546388626098633, 'learning_rate': 7.779661016949152e-06, 'epoch': 0.23}
 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:22:34<4:34:37,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:22:37<4:31:15,  3.55s/it]                                                       {'loss': 0.0129, 'grad_norm': 2.1896657943725586, 'learning_rate': 7.777966101694916e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:22:37<4:31:15,  3.55s/it] 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:22:41<4:42:16,  3.69s/it]                                                       {'loss': 0.1535, 'grad_norm': 18.633087158203125, 'learning_rate': 7.776271186440679e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:22:41<4:42:16,  3.69s/it] 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:22:45<4:34:15,  3.59s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.536692500114441, 'learning_rate': 7.774576271186442e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:22:45<4:34:15,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:22:48<4:28:50,  3.52s/it]                                                       {'loss': 0.3323, 'grad_norm': 14.019397735595703, 'learning_rate': 7.772881355932204e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:22:48<4:28:50,  3.52s/it] 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:22:52<4:35:19,  3.60s/it]                                                       {'loss': 0.0254, 'grad_norm': 5.617403507232666, 'learning_rate': 7.771186440677967e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:22:52<4:35:19,  3.60s/it] 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:22:55<4:32:00,  3.56s/it]                                                       {'loss': 0.0082, 'grad_norm': 2.9094908237457275, 'learning_rate': 7.769491525423729e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:22:55<4:32:00,  3.56s/it] 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:22:59<4:30:33,  3.54s/it]                                                       {'loss': 0.0973, 'grad_norm': 11.450325965881348, 'learning_rate': 7.767796610169492e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:22:59<4:30:33,  3.54s/it] 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:02<4:33:52,  3.59s/it]                                                       {'loss': 0.0185, 'grad_norm': 6.266055107116699, 'learning_rate': 7.766101694915255e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:23:02<4:33:52,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:06<4:34:27,  3.59s/it]                                                       {'loss': 0.081, 'grad_norm': 11.084663391113281, 'learning_rate': 7.764406779661018e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:23:06<4:34:27,  3.59s/it] 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:09<4:30:31,  3.54s/it]                                                       {'loss': 0.0719, 'grad_norm': 7.6170454025268555, 'learning_rate': 7.76271186440678e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:23:09<4:30:31,  3.54s/it] 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:13<4:27:20,  3.50s/it]                                                       {'loss': 0.0485, 'grad_norm': 7.693583965301514, 'learning_rate': 7.761016949152543e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:23:13<4:27:20,  3.50s/it] 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:16<4:25:13,  3.48s/it]                                                       {'loss': 0.0751, 'grad_norm': 10.802765846252441, 'learning_rate': 7.759322033898305e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:23:16<4:25:13,  3.48s/it] 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:23:20<4:22:28,  3.44s/it]                                                       {'loss': 0.0288, 'grad_norm': 5.502131462097168, 'learning_rate': 7.757627118644068e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:23:20<4:22:28,  3.44s/it] 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:23:23<4:20:37,  3.42s/it]                                                       {'loss': 0.2411, 'grad_norm': 15.85224723815918, 'learning_rate': 7.755932203389831e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:23:23<4:20:37,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:23:27<4:23:44,  3.46s/it]                                                       {'loss': 0.0637, 'grad_norm': 12.502453804016113, 'learning_rate': 7.754237288135595e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:23:27<4:23:44,  3.46s/it] 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:23:30<4:26:24,  3.49s/it]                                                       {'loss': 0.0618, 'grad_norm': 7.495507717132568, 'learning_rate': 7.752542372881356e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:23:30<4:26:24,  3.49s/it] 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:23:33<4:23:15,  3.45s/it]                                                       {'loss': 0.0241, 'grad_norm': 5.96129846572876, 'learning_rate': 7.75084745762712e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:23:33<4:23:15,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:23:37<4:22:25,  3.44s/it]                                                       {'loss': 0.0372, 'grad_norm': 7.950199127197266, 'learning_rate': 7.749152542372881e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:23:37<4:22:25,  3.44s/it] 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:23:40<4:20:15,  3.42s/it]                                                       {'loss': 0.064, 'grad_norm': 13.453569412231445, 'learning_rate': 7.747457627118644e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:23:40<4:20:15,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:23:44<4:19:55,  3.41s/it]                                                       {'loss': 0.0401, 'grad_norm': 9.042463302612305, 'learning_rate': 7.745762711864408e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:23:44<4:19:55,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:23:47<4:19:51,  3.41s/it]                                                       {'loss': 0.0233, 'grad_norm': 5.934303283691406, 'learning_rate': 7.74406779661017e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:23:47<4:19:51,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:23:50<4:19:40,  3.41s/it]                                                       {'loss': 0.0272, 'grad_norm': 7.149891376495361, 'learning_rate': 7.742372881355933e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:23:50<4:19:40,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:23:54<4:31:34,  3.57s/it]                                                       {'loss': 0.0491, 'grad_norm': 8.457680702209473, 'learning_rate': 7.740677966101696e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:23:54<4:31:34,  3.57s/it] 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:23:58<4:31:09,  3.56s/it]                                                       {'loss': 0.028, 'grad_norm': 4.305582046508789, 'learning_rate': 7.738983050847459e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:23:58<4:31:09,  3.56s/it] 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:01<4:26:15,  3.50s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.9013862013816833, 'learning_rate': 7.73728813559322e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:24:01<4:26:15,  3.50s/it] 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:05<4:32:59,  3.59s/it]                                                       {'loss': 0.0556, 'grad_norm': 8.558703422546387, 'learning_rate': 7.735593220338984e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:24:05<4:32:59,  3.59s/it] 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:09<4:31:14,  3.57s/it]                                                       {'loss': 0.1025, 'grad_norm': 8.951712608337402, 'learning_rate': 7.733898305084746e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:24:09<4:31:14,  3.57s/it] 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:12<4:27:45,  3.52s/it]                                                       {'loss': 0.0374, 'grad_norm': 3.6886870861053467, 'learning_rate': 7.732203389830509e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:24:12<4:27:45,  3.52s/it] 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:15<4:23:59,  3.47s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.0403693914413452, 'learning_rate': 7.730508474576272e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:24:15<4:23:59,  3.47s/it] 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:24:19<4:22:16,  3.45s/it]                                                       {'loss': 0.119, 'grad_norm': 15.010865211486816, 'learning_rate': 7.728813559322035e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:24:19<4:22:16,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:24:22<4:19:29,  3.42s/it]                                                       {'loss': 0.0579, 'grad_norm': 8.525879859924316, 'learning_rate': 7.727118644067797e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:24:22<4:19:29,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:24:26<4:22:25,  3.45s/it]                                                       {'loss': 0.2006, 'grad_norm': 17.819398880004883, 'learning_rate': 7.72542372881356e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:24:26<4:22:25,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:24:29<4:19:12,  3.41s/it]                                                       {'loss': 0.011, 'grad_norm': 2.2551188468933105, 'learning_rate': 7.723728813559322e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:24:29<4:19:12,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:24:32<4:18:28,  3.40s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.8017852306365967, 'learning_rate': 7.722033898305085e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:24:32<4:18:28,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:24:36<4:17:41,  3.39s/it]                                                       {'loss': 0.0542, 'grad_norm': 10.794503211975098, 'learning_rate': 7.720338983050848e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:24:36<4:17:41,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:24:39<4:17:04,  3.39s/it]                                                       {'loss': 0.0321, 'grad_norm': 7.71164083480835, 'learning_rate': 7.718644067796612e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:24:39<4:17:04,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:24:42<4:15:49,  3.37s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.888920545578003, 'learning_rate': 7.716949152542373e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:24:42<4:15:49,  3.37s/it] 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:24:46<4:15:07,  3.36s/it]                                                       {'loss': 0.6521, 'grad_norm': 22.222734451293945, 'learning_rate': 7.715254237288136e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:24:46<4:15:07,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:24:49<4:15:04,  3.36s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.2902120351791382, 'learning_rate': 7.7135593220339e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:24:49<4:15:04,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:24:53<4:15:06,  3.36s/it]                                                       {'loss': 0.0607, 'grad_norm': 17.180667877197266, 'learning_rate': 7.711864406779663e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:24:53<4:15:06,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:24:56<4:15:01,  3.36s/it]                                                       {'loss': 0.05, 'grad_norm': 7.470559597015381, 'learning_rate': 7.710169491525425e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:24:56<4:15:01,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:24:59<4:15:53,  3.38s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.7706694006919861, 'learning_rate': 7.708474576271186e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:24:59<4:15:53,  3.38s/it] 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:03<4:14:51,  3.36s/it]                                                       {'loss': 0.2458, 'grad_norm': 16.08094596862793, 'learning_rate': 7.70677966101695e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:25:03<4:14:51,  3.36s/it] 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:06<4:14:11,  3.35s/it]                                                       {'loss': 0.1148, 'grad_norm': 10.512170791625977, 'learning_rate': 7.705084745762713e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1454/6000 [1:25:06<4:14:11,  3.35s/it] 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:09<4:14:07,  3.35s/it]                                                       {'loss': 0.0821, 'grad_norm': 7.138225078582764, 'learning_rate': 7.703389830508476e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1455/6000 [1:25:09<4:14:07,  3.35s/it] 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:13<4:17:18,  3.40s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.3627013564109802, 'learning_rate': 7.701694915254238e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1456/6000 [1:25:13<4:17:18,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:25:16<4:16:33,  3.39s/it]                                                       {'loss': 0.0418, 'grad_norm': 6.649265766143799, 'learning_rate': 7.7e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1457/6000 [1:25:16<4:16:33,  3.39s/it] 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:25:20<4:17:46,  3.41s/it]                                                       {'loss': 0.0482, 'grad_norm': 10.17134952545166, 'learning_rate': 7.698305084745762e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1458/6000 [1:25:20<4:17:46,  3.41s/it] 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:25:23<4:17:03,  3.40s/it]                                                       {'loss': 0.0934, 'grad_norm': 15.30399227142334, 'learning_rate': 7.696610169491526e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1459/6000 [1:25:23<4:17:03,  3.40s/it] 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:25:26<4:15:16,  3.37s/it]                                                       {'loss': 0.2322, 'grad_norm': 22.823570251464844, 'learning_rate': 7.694915254237289e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1460/6000 [1:25:26<4:15:16,  3.37s/it] 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:25:30<4:23:21,  3.48s/it]                                                       {'loss': 0.073, 'grad_norm': 8.51031494140625, 'learning_rate': 7.693220338983052e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1461/6000 [1:25:30<4:23:21,  3.48s/it] 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:25:33<4:21:05,  3.45s/it]                                                       {'loss': 0.038, 'grad_norm': 8.095467567443848, 'learning_rate': 7.691525423728814e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1462/6000 [1:25:33<4:21:05,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:25:37<4:20:49,  3.45s/it]                                                       {'loss': 0.0445, 'grad_norm': 6.608067989349365, 'learning_rate': 7.689830508474577e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1463/6000 [1:25:37<4:20:49,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:25:40<4:18:29,  3.42s/it]                                                       {'loss': 0.127, 'grad_norm': 17.717998504638672, 'learning_rate': 7.688135593220339e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1464/6000 [1:25:40<4:18:29,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:25:44<4:20:50,  3.45s/it]                                                       {'loss': 0.068, 'grad_norm': 9.097508430480957, 'learning_rate': 7.686440677966102e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1465/6000 [1:25:44<4:20:50,  3.45s/it] 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:25:47<4:18:08,  3.42s/it]                                                       {'loss': 0.0218, 'grad_norm': 3.7293341159820557, 'learning_rate': 7.684745762711865e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1466/6000 [1:25:47<4:18:08,  3.42s/it] 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:25:51<4:19:18,  3.43s/it]                                                       {'loss': 0.0505, 'grad_norm': 5.863219261169434, 'learning_rate': 7.683050847457628e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1467/6000 [1:25:51<4:19:18,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:25:54<4:19:13,  3.43s/it]                                                       {'loss': 0.3011, 'grad_norm': 19.51346778869629, 'learning_rate': 7.68135593220339e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1468/6000 [1:25:54<4:19:13,  3.43s/it] 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:25:58<4:27:15,  3.54s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.2638285160064697, 'learning_rate': 7.679661016949153e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1469/6000 [1:25:58<4:27:15,  3.54s/it] 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:01<4:26:23,  3.53s/it]                                                       {'loss': 0.2471, 'grad_norm': 16.301488876342773, 'learning_rate': 7.677966101694917e-06, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1470/6000 [1:26:01<4:26:23,  3.53s/it] 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:05<4:25:47,  3.52s/it]                                                       {'loss': 0.2269, 'grad_norm': 19.48250961303711, 'learning_rate': 7.67627118644068e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1471/6000 [1:26:05<4:25:47,  3.52s/it] 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:08<4:26:40,  3.53s/it]                                                       {'loss': 0.0455, 'grad_norm': 9.222431182861328, 'learning_rate': 7.674576271186441e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1472/6000 [1:26:08<4:26:40,  3.53s/it] 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:12<4:23:15,  3.49s/it]                                                       {'loss': 0.0157, 'grad_norm': 4.750158786773682, 'learning_rate': 7.672881355932203e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1473/6000 [1:26:12<4:23:15,  3.49s/it] 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:26:15<4:19:04,  3.43s/it]                                                       {'loss': 0.0252, 'grad_norm': 8.715702056884766, 'learning_rate': 7.671186440677966e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1474/6000 [1:26:15<4:19:04,  3.43s/it] 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:26:19<4:35:08,  3.65s/it]                                                       {'loss': 0.2104, 'grad_norm': 13.160128593444824, 'learning_rate': 7.66949152542373e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1475/6000 [1:26:19<4:35:08,  3.65s/it] 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:26:23<4:27:49,  3.55s/it]                                                       {'loss': 0.0326, 'grad_norm': 3.6448912620544434, 'learning_rate': 7.667796610169493e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1476/6000 [1:26:23<4:27:49,  3.55s/it] 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:26:26<4:22:15,  3.48s/it]                                                       {'loss': 0.1159, 'grad_norm': 12.13837718963623, 'learning_rate': 7.666101694915254e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1477/6000 [1:26:26<4:22:15,  3.48s/it] 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:26:29<4:20:18,  3.45s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.4980987012386322, 'learning_rate': 7.664406779661018e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1478/6000 [1:26:29<4:20:18,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:26:33<4:19:47,  3.45s/it]                                                       {'loss': 0.182, 'grad_norm': 15.858694076538086, 'learning_rate': 7.66271186440678e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1479/6000 [1:26:33<4:19:47,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:26:36<4:17:36,  3.42s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.7016685605049133, 'learning_rate': 7.661016949152543e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1480/6000 [1:26:36<4:17:36,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:26:39<4:15:56,  3.40s/it]                                                       {'loss': 0.1093, 'grad_norm': 13.698250770568848, 'learning_rate': 7.659322033898306e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1481/6000 [1:26:39<4:15:56,  3.40s/it] 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:26:43<4:17:09,  3.42s/it]                                                       {'loss': 0.0966, 'grad_norm': 8.275428771972656, 'learning_rate': 7.657627118644069e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1482/6000 [1:26:43<4:17:09,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:26:46<4:17:30,  3.42s/it]                                                       {'loss': 0.0607, 'grad_norm': 8.669294357299805, 'learning_rate': 7.65593220338983e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1483/6000 [1:26:46<4:17:30,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:26:50<4:17:03,  3.42s/it]                                                       {'loss': 0.0483, 'grad_norm': 9.407591819763184, 'learning_rate': 7.654237288135594e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1484/6000 [1:26:50<4:17:03,  3.42s/it] 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:26:53<4:18:25,  3.43s/it]                                                       {'loss': 0.2604, 'grad_norm': 14.656696319580078, 'learning_rate': 7.652542372881356e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1485/6000 [1:26:53<4:18:25,  3.43s/it] 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:26:57<4:19:02,  3.44s/it]                                                       {'loss': 0.0763, 'grad_norm': 18.887800216674805, 'learning_rate': 7.65084745762712e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1486/6000 [1:26:57<4:19:02,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:00<4:28:39,  3.57s/it]                                                       {'loss': 0.0749, 'grad_norm': 7.493829250335693, 'learning_rate': 7.649152542372882e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1487/6000 [1:27:00<4:28:39,  3.57s/it] 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:04<4:24:20,  3.52s/it]                                                       {'loss': 0.0749, 'grad_norm': 10.239995002746582, 'learning_rate': 7.647457627118645e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1488/6000 [1:27:04<4:24:20,  3.52s/it] 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:08<4:30:51,  3.60s/it]                                                       {'loss': 0.172, 'grad_norm': 17.785791397094727, 'learning_rate': 7.645762711864407e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1489/6000 [1:27:08<4:30:51,  3.60s/it] 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:11<4:30:44,  3.60s/it]                                                       {'loss': 0.0737, 'grad_norm': 7.111166477203369, 'learning_rate': 7.64406779661017e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1490/6000 [1:27:11<4:30:44,  3.60s/it] 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:27:15<4:27:40,  3.56s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.3092060089111328, 'learning_rate': 7.642372881355933e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1491/6000 [1:27:15<4:27:40,  3.56s/it] 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:27:19<4:36:08,  3.68s/it]                                                       {'loss': 0.0287, 'grad_norm': 4.065703868865967, 'learning_rate': 7.640677966101695e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1492/6000 [1:27:19<4:36:08,  3.68s/it] 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:27:22<4:28:47,  3.58s/it]                                                       {'loss': 0.0138, 'grad_norm': 3.272909164428711, 'learning_rate': 7.638983050847458e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1493/6000 [1:27:22<4:28:47,  3.58s/it] 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:27:25<4:24:03,  3.52s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.6201465129852295, 'learning_rate': 7.63728813559322e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1494/6000 [1:27:25<4:24:03,  3.52s/it] 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:27:29<4:20:30,  3.47s/it]                                                       {'loss': 0.1696, 'grad_norm': 16.604368209838867, 'learning_rate': 7.635593220338983e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1495/6000 [1:27:29<4:20:30,  3.47s/it] 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:27:32<4:18:48,  3.45s/it]                                                       {'loss': 0.1994, 'grad_norm': 15.7413330078125, 'learning_rate': 7.633898305084746e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1496/6000 [1:27:32<4:18:48,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:27:36<4:19:15,  3.45s/it]                                                       {'loss': 0.2368, 'grad_norm': 16.749359130859375, 'learning_rate': 7.63220338983051e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1497/6000 [1:27:36<4:19:15,  3.45s/it] 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:27:39<4:18:21,  3.44s/it]                                                       {'loss': 0.0751, 'grad_norm': 8.125164031982422, 'learning_rate': 7.630508474576271e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1498/6000 [1:27:39<4:18:21,  3.44s/it] 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:27:42<4:17:20,  3.43s/it]                                                       {'loss': 0.011, 'grad_norm': 2.4340453147888184, 'learning_rate': 7.628813559322035e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1499/6000 [1:27:42<4:17:20,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:27:46<4:17:07,  3.43s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.6872779130935669, 'learning_rate': 7.627118644067797e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1500/6000 [1:27:46<4:17:07,  3.43s/it][2025-11-07 00:18:55,866] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500
[2025-11-07 00:18:55,879] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:18:56,521] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:27:52<5:08:42,  4.12s/it]                                                       {'loss': 0.0875, 'grad_norm': 8.969141006469727, 'learning_rate': 7.62542372881356e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1501/6000 [1:27:52<5:08:42,  4.12s/it] 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:27:55<4:58:24,  3.98s/it]                                                       {'loss': 0.0756, 'grad_norm': 13.465522766113281, 'learning_rate': 7.623728813559323e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1502/6000 [1:27:55<4:58:24,  3.98s/it] 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:27:59<4:42:10,  3.76s/it]                                                       {'loss': 0.1288, 'grad_norm': 11.023686408996582, 'learning_rate': 7.622033898305086e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1503/6000 [1:27:59<4:42:10,  3.76s/it] 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:02<4:34:47,  3.67s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2836230397224426, 'learning_rate': 7.6203389830508476e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1504/6000 [1:28:02<4:34:47,  3.67s/it] 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:05<4:28:24,  3.58s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.37469273805618286, 'learning_rate': 7.618644067796611e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1505/6000 [1:28:05<4:28:24,  3.58s/it] 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:09<4:24:42,  3.53s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.6126010417938232, 'learning_rate': 7.616949152542373e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1506/6000 [1:28:09<4:24:42,  3.53s/it] 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:12<4:22:39,  3.51s/it]                                                       {'loss': 0.0843, 'grad_norm': 7.053711891174316, 'learning_rate': 7.6152542372881365e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1507/6000 [1:28:12<4:22:39,  3.51s/it] 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:28:16<4:23:03,  3.51s/it]                                                       {'loss': 0.0785, 'grad_norm': 10.483445167541504, 'learning_rate': 7.613559322033899e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1508/6000 [1:28:16<4:23:03,  3.51s/it] 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:28:19<4:21:34,  3.49s/it]                                                       {'loss': 0.0168, 'grad_norm': 3.3361268043518066, 'learning_rate': 7.611864406779662e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1509/6000 [1:28:19<4:21:34,  3.49s/it] 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:28:23<4:19:40,  3.47s/it]                                                       {'loss': 0.0674, 'grad_norm': 8.178470611572266, 'learning_rate': 7.610169491525425e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1510/6000 [1:28:23<4:19:40,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:28:26<4:19:46,  3.47s/it]                                                       {'loss': 0.0976, 'grad_norm': 16.496606826782227, 'learning_rate': 7.608474576271188e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1511/6000 [1:28:26<4:19:46,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:28:29<4:17:58,  3.45s/it]                                                       {'loss': 0.1314, 'grad_norm': 13.077686309814453, 'learning_rate': 7.6067796610169495e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1512/6000 [1:28:29<4:17:58,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:28:33<4:18:20,  3.45s/it]                                                       {'loss': 0.1302, 'grad_norm': 12.191638946533203, 'learning_rate': 7.605084745762712e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1513/6000 [1:28:33<4:18:20,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:28:36<4:16:05,  3.43s/it]                                                       {'loss': 0.0129, 'grad_norm': 3.2008049488067627, 'learning_rate': 7.603389830508475e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1514/6000 [1:28:36<4:16:05,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:28:40<4:15:45,  3.42s/it]                                                       {'loss': 0.0371, 'grad_norm': 6.254076957702637, 'learning_rate': 7.601694915254238e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1515/6000 [1:28:40<4:15:45,  3.42s/it] 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:28:43<4:15:34,  3.42s/it]                                                       {'loss': 0.0669, 'grad_norm': 7.985538005828857, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1516/6000 [1:28:43<4:15:34,  3.42s/it] 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:28:47<4:21:47,  3.50s/it]                                                       {'loss': 0.1097, 'grad_norm': 10.538494110107422, 'learning_rate': 7.5983050847457625e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1517/6000 [1:28:47<4:21:47,  3.50s/it] 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:28:50<4:18:56,  3.47s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.3089017868041992, 'learning_rate': 7.596610169491526e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1518/6000 [1:28:50<4:18:56,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:28:54<4:16:06,  3.43s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.0447461605072021, 'learning_rate': 7.594915254237288e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1519/6000 [1:28:54<4:16:06,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:28:57<4:19:26,  3.47s/it]                                                       {'loss': 0.1605, 'grad_norm': 12.761801719665527, 'learning_rate': 7.5932203389830515e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1520/6000 [1:28:57<4:19:26,  3.47s/it] 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:01<4:17:43,  3.45s/it]                                                       {'loss': 0.0079, 'grad_norm': 0.747251033782959, 'learning_rate': 7.591525423728814e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1521/6000 [1:29:01<4:17:43,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:04<4:17:05,  3.44s/it]                                                       {'loss': 0.1379, 'grad_norm': 10.400408744812012, 'learning_rate': 7.589830508474577e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1522/6000 [1:29:04<4:17:05,  3.44s/it] 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:07<4:16:01,  3.43s/it]                                                       {'loss': 0.0217, 'grad_norm': 4.013437271118164, 'learning_rate': 7.58813559322034e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1523/6000 [1:29:07<4:16:01,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:11<4:15:31,  3.43s/it]                                                       {'loss': 0.1795, 'grad_norm': 17.087135314941406, 'learning_rate': 7.586440677966103e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1524/6000 [1:29:11<4:15:31,  3.43s/it] 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:14<4:17:34,  3.45s/it]                                                       {'loss': 0.0667, 'grad_norm': 10.079991340637207, 'learning_rate': 7.5847457627118645e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1525/6000 [1:29:14<4:17:34,  3.45s/it] 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:29:18<4:18:14,  3.46s/it]                                                       {'loss': 0.0096, 'grad_norm': 1.89732027053833, 'learning_rate': 7.583050847457628e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1526/6000 [1:29:18<4:18:14,  3.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:29:22<4:26:24,  3.57s/it]                                                       {'loss': 0.0281, 'grad_norm': 5.6155548095703125, 'learning_rate': 7.58135593220339e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1527/6000 [1:29:22<4:26:24,  3.57s/it] 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:29:26<4:35:54,  3.70s/it]                                                       {'loss': 0.0076, 'grad_norm': 1.9642788171768188, 'learning_rate': 7.5796610169491534e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1528/6000 [1:29:26<4:35:54,  3.70s/it] 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:29:29<4:27:17,  3.59s/it]                                                       {'loss': 0.0175, 'grad_norm': 4.957900524139404, 'learning_rate': 7.577966101694916e-06, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1529/6000 [1:29:29<4:27:17,  3.59s/it] 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:29:33<4:33:40,  3.67s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.3260651230812073, 'learning_rate': 7.576271186440679e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1530/6000 [1:29:33<4:33:40,  3.67s/it] 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:29:36<4:28:44,  3.61s/it]                                                       {'loss': 0.0608, 'grad_norm': 9.684057235717773, 'learning_rate': 7.5745762711864416e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1531/6000 [1:29:36<4:28:44,  3.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:29:40<4:22:26,  3.52s/it]                                                       {'loss': 0.1517, 'grad_norm': 13.051800727844238, 'learning_rate': 7.572881355932205e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1532/6000 [1:29:40<4:22:26,  3.52s/it] 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:29:43<4:18:48,  3.48s/it]                                                       {'loss': 0.1227, 'grad_norm': 14.828930854797363, 'learning_rate': 7.571186440677966e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1533/6000 [1:29:43<4:18:48,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:29:46<4:15:09,  3.43s/it]                                                       {'loss': 0.0318, 'grad_norm': 6.300358772277832, 'learning_rate': 7.569491525423729e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1534/6000 [1:29:46<4:15:09,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:29:50<4:14:30,  3.42s/it]                                                       {'loss': 0.0707, 'grad_norm': 6.471803188323975, 'learning_rate': 7.567796610169492e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1535/6000 [1:29:50<4:14:30,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:29:53<4:12:25,  3.39s/it]                                                       {'loss': 0.0923, 'grad_norm': 13.055665016174316, 'learning_rate': 7.5661016949152545e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1536/6000 [1:29:53<4:12:25,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:29:57<4:15:04,  3.43s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.1131174564361572, 'learning_rate': 7.564406779661018e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1537/6000 [1:29:57<4:15:04,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:00<4:18:37,  3.48s/it]                                                       {'loss': 0.0527, 'grad_norm': 3.705618381500244, 'learning_rate': 7.56271186440678e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1538/6000 [1:30:00<4:18:37,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:04<4:17:11,  3.46s/it]                                                       {'loss': 0.001, 'grad_norm': 0.27699723839759827, 'learning_rate': 7.5610169491525435e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1539/6000 [1:30:04<4:17:11,  3.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:07<4:18:01,  3.47s/it]                                                       {'loss': 0.1383, 'grad_norm': 14.393290519714355, 'learning_rate': 7.559322033898305e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1540/6000 [1:30:07<4:18:01,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:11<4:22:13,  3.53s/it]                                                       {'loss': 0.1853, 'grad_norm': 14.571855545043945, 'learning_rate': 7.557627118644068e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1541/6000 [1:30:11<4:22:13,  3.53s/it] 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:14<4:18:24,  3.48s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.6261645555496216, 'learning_rate': 7.555932203389831e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1542/6000 [1:30:14<4:18:24,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:30:18<4:18:51,  3.48s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.048181917518377304, 'learning_rate': 7.554237288135594e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1543/6000 [1:30:18<4:18:51,  3.48s/it] 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:30:21<4:16:25,  3.45s/it]                                                       {'loss': 0.1666, 'grad_norm': 18.9951114654541, 'learning_rate': 7.5525423728813565e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1544/6000 [1:30:21<4:16:25,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:30:24<4:16:02,  3.45s/it]                                                       {'loss': 0.0776, 'grad_norm': 7.24189567565918, 'learning_rate': 7.55084745762712e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1545/6000 [1:30:24<4:16:02,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:30:28<4:21:38,  3.52s/it]                                                       {'loss': 0.0945, 'grad_norm': 14.012314796447754, 'learning_rate': 7.549152542372881e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1546/6000 [1:30:28<4:21:38,  3.52s/it] 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:30:31<4:17:13,  3.47s/it]                                                       {'loss': 0.0156, 'grad_norm': 5.3350372314453125, 'learning_rate': 7.5474576271186455e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1547/6000 [1:30:31<4:17:13,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:30:35<4:15:01,  3.44s/it]                                                       {'loss': 0.0422, 'grad_norm': 6.965474605560303, 'learning_rate': 7.545762711864407e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1548/6000 [1:30:35<4:15:01,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:30:38<4:15:36,  3.45s/it]                                                       {'loss': 0.0437, 'grad_norm': 13.418530464172363, 'learning_rate': 7.54406779661017e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1549/6000 [1:30:38<4:15:36,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:30:42<4:16:14,  3.45s/it]                                                       {'loss': 0.0202, 'grad_norm': 2.825080633163452, 'learning_rate': 7.542372881355933e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1550/6000 [1:30:42<4:16:14,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:30:45<4:14:43,  3.44s/it]                                                       {'loss': 0.0188, 'grad_norm': 1.4682321548461914, 'learning_rate': 7.540677966101696e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1551/6000 [1:30:45<4:14:43,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:30:48<4:13:58,  3.43s/it]                                                       {'loss': 0.0038, 'grad_norm': 1.0994291305541992, 'learning_rate': 7.5389830508474584e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1552/6000 [1:30:48<4:13:58,  3.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:30:52<4:10:35,  3.38s/it]                                                       {'loss': 0.0949, 'grad_norm': 8.405243873596191, 'learning_rate': 7.537288135593222e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1553/6000 [1:30:52<4:10:35,  3.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:30:55<4:11:15,  3.39s/it]                                                       {'loss': 0.0522, 'grad_norm': 9.46878433227539, 'learning_rate': 7.535593220338983e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1554/6000 [1:30:55<4:11:15,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:30:58<4:09:20,  3.37s/it]                                                       {'loss': 0.0779, 'grad_norm': 10.868218421936035, 'learning_rate': 7.533898305084746e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1555/6000 [1:30:58<4:09:20,  3.37s/it] 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:02<4:07:46,  3.35s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.4563133716583252, 'learning_rate': 7.532203389830509e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1556/6000 [1:31:02<4:07:46,  3.35s/it] 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:05<4:08:26,  3.36s/it]                                                       {'loss': 0.0811, 'grad_norm': 9.402376174926758, 'learning_rate': 7.5305084745762714e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1557/6000 [1:31:05<4:08:26,  3.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:09<4:08:40,  3.36s/it]                                                       {'loss': 0.0645, 'grad_norm': 8.917723655700684, 'learning_rate': 7.528813559322035e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1558/6000 [1:31:09<4:08:40,  3.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:12<4:20:06,  3.51s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2998214364051819, 'learning_rate': 7.527118644067797e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1559/6000 [1:31:12<4:20:06,  3.51s/it] 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:31:16<4:16:31,  3.47s/it]                                                       {'loss': 0.115, 'grad_norm': 11.699614524841309, 'learning_rate': 7.52542372881356e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1560/6000 [1:31:16<4:16:31,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:31:19<4:15:34,  3.45s/it]                                                       {'loss': 0.0771, 'grad_norm': 6.391420364379883, 'learning_rate': 7.523728813559322e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1561/6000 [1:31:19<4:15:34,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:31:23<4:16:23,  3.47s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.2980901002883911, 'learning_rate': 7.522033898305085e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1562/6000 [1:31:23<4:16:23,  3.47s/it] 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:31:26<4:14:07,  3.44s/it]                                                       {'loss': 0.0386, 'grad_norm': 8.719524383544922, 'learning_rate': 7.520338983050848e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1563/6000 [1:31:26<4:14:07,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:31:29<4:12:59,  3.42s/it]                                                       {'loss': 0.0529, 'grad_norm': 6.2459282875061035, 'learning_rate': 7.518644067796611e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1564/6000 [1:31:29<4:12:59,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:31:33<4:09:57,  3.38s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.14114095270633698, 'learning_rate': 7.516949152542373e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1565/6000 [1:31:33<4:09:57,  3.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:31:36<4:14:55,  3.45s/it]                                                       {'loss': 0.0157, 'grad_norm': 3.0046308040618896, 'learning_rate': 7.515254237288137e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1566/6000 [1:31:36<4:14:55,  3.45s/it] 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:31:40<4:12:49,  3.42s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11578121781349182, 'learning_rate': 7.513559322033899e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1567/6000 [1:31:40<4:12:49,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:31:43<4:10:35,  3.39s/it]                                                       {'loss': 0.0348, 'grad_norm': 7.174471378326416, 'learning_rate': 7.511864406779662e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1568/6000 [1:31:43<4:10:35,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:31:46<4:10:20,  3.39s/it]                                                       {'loss': 0.0824, 'grad_norm': 12.977493286132812, 'learning_rate': 7.510169491525424e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1569/6000 [1:31:46<4:10:20,  3.39s/it] 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:31:50<4:12:20,  3.42s/it]                                                       {'loss': 0.1505, 'grad_norm': 17.029830932617188, 'learning_rate': 7.508474576271187e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1570/6000 [1:31:50<4:12:20,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:31:53<4:14:00,  3.44s/it]                                                       {'loss': 0.0706, 'grad_norm': 5.431219100952148, 'learning_rate': 7.50677966101695e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1571/6000 [1:31:53<4:14:00,  3.44s/it] 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:31:57<4:12:29,  3.42s/it]                                                       {'loss': 0.023, 'grad_norm': 6.227608680725098, 'learning_rate': 7.505084745762713e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1572/6000 [1:31:57<4:12:29,  3.42s/it] 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:00<4:11:45,  3.41s/it]                                                       {'loss': 0.0186, 'grad_norm': 1.9808741807937622, 'learning_rate': 7.503389830508475e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1573/6000 [1:32:00<4:11:45,  3.41s/it] 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:04<4:13:54,  3.44s/it]                                                       {'loss': 0.0227, 'grad_norm': 6.454537868499756, 'learning_rate': 7.501694915254239e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1574/6000 [1:32:04<4:13:54,  3.44s/it] 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:07<4:12:24,  3.42s/it]                                                       {'loss': 0.0619, 'grad_norm': 12.402676582336426, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1575/6000 [1:32:07<4:12:24,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:11<4:14:40,  3.45s/it]                                                       {'loss': 0.017, 'grad_norm': 4.231413841247559, 'learning_rate': 7.498305084745763e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1576/6000 [1:32:11<4:14:40,  3.45s/it] 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:32:14<4:13:18,  3.44s/it]                                                       {'loss': 0.2407, 'grad_norm': 13.686964988708496, 'learning_rate': 7.496610169491526e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1577/6000 [1:32:14<4:13:18,  3.44s/it] 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:32:17<4:12:38,  3.43s/it]                                                       {'loss': 0.0185, 'grad_norm': 7.7653021812438965, 'learning_rate': 7.494915254237288e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1578/6000 [1:32:17<4:12:38,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:32:21<4:11:46,  3.42s/it]                                                       {'loss': 0.0176, 'grad_norm': 4.667445659637451, 'learning_rate': 7.493220338983052e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1579/6000 [1:32:21<4:11:46,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:32:24<4:10:07,  3.40s/it]                                                       {'loss': 0.1485, 'grad_norm': 9.353804588317871, 'learning_rate': 7.491525423728814e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1580/6000 [1:32:24<4:10:07,  3.40s/it] 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:32:28<4:22:07,  3.56s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3941161632537842, 'learning_rate': 7.489830508474577e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1581/6000 [1:32:28<4:22:07,  3.56s/it] 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:32:31<4:18:47,  3.51s/it]                                                       {'loss': 0.0859, 'grad_norm': 13.348638534545898, 'learning_rate': 7.488135593220339e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1582/6000 [1:32:31<4:18:47,  3.51s/it] 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:32:35<4:14:54,  3.46s/it]                                                       {'loss': 0.013, 'grad_norm': 2.4675939083099365, 'learning_rate': 7.486440677966102e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1583/6000 [1:32:35<4:14:54,  3.46s/it] 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:32:38<4:12:18,  3.43s/it]                                                       {'loss': 0.0979, 'grad_norm': 19.558988571166992, 'learning_rate': 7.4847457627118646e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1584/6000 [1:32:38<4:12:18,  3.43s/it] 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:32:42<4:11:39,  3.42s/it]                                                       {'loss': 0.0852, 'grad_norm': 12.875255584716797, 'learning_rate': 7.483050847457628e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1585/6000 [1:32:42<4:11:39,  3.42s/it] 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:32:45<4:16:11,  3.48s/it]                                                       {'loss': 0.0389, 'grad_norm': 6.5625152587890625, 'learning_rate': 7.48135593220339e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1586/6000 [1:32:45<4:16:11,  3.48s/it] 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:32:49<4:15:38,  3.48s/it]                                                       {'loss': 0.0173, 'grad_norm': 4.0830488204956055, 'learning_rate': 7.4796610169491535e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1587/6000 [1:32:49<4:15:38,  3.48s/it] 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:32:52<4:14:32,  3.46s/it]                                                       {'loss': 0.0368, 'grad_norm': 9.371366500854492, 'learning_rate': 7.477966101694916e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1588/6000 [1:32:52<4:14:32,  3.46s/it] 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:32:56<4:22:14,  3.57s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1893531084060669, 'learning_rate': 7.476271186440679e-06, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1589/6000 [1:32:56<4:22:14,  3.57s/it] 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:32:59<4:16:13,  3.49s/it]                                                       {'loss': 0.013, 'grad_norm': 4.0614447593688965, 'learning_rate': 7.474576271186441e-06, 'epoch': 0.27}
 26%|â–ˆâ–ˆâ–‹       | 1590/6000 [1:32:59<4:16:13,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:03<4:13:00,  3.44s/it]                                                       {'loss': 0.111, 'grad_norm': 13.931105613708496, 'learning_rate': 7.472881355932204e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1591/6000 [1:33:03<4:13:00,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:06<4:11:36,  3.42s/it]                                                       {'loss': 0.0391, 'grad_norm': 4.100627422332764, 'learning_rate': 7.4711864406779665e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1592/6000 [1:33:06<4:11:36,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:09<4:09:36,  3.40s/it]                                                       {'loss': 0.0045, 'grad_norm': 1.1017673015594482, 'learning_rate': 7.46949152542373e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1593/6000 [1:33:09<4:09:36,  3.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:33:13<4:08:06,  3.38s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.4953274726867676, 'learning_rate': 7.467796610169492e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1594/6000 [1:33:13<4:08:06,  3.38s/it] 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:33:16<4:10:09,  3.41s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.637814998626709, 'learning_rate': 7.4661016949152555e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1595/6000 [1:33:16<4:10:09,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:33:19<4:11:22,  3.42s/it]                                                       {'loss': 0.1165, 'grad_norm': 9.917181968688965, 'learning_rate': 7.464406779661018e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1596/6000 [1:33:20<4:11:22,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:33:23<4:12:00,  3.43s/it]                                                       {'loss': 0.0325, 'grad_norm': 5.692813396453857, 'learning_rate': 7.4627118644067795e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1597/6000 [1:33:23<4:12:00,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:33:26<4:12:04,  3.44s/it]                                                       {'loss': 0.2343, 'grad_norm': 15.325590133666992, 'learning_rate': 7.461016949152543e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1598/6000 [1:33:26<4:12:04,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:33:30<4:12:24,  3.44s/it]                                                       {'loss': 0.1478, 'grad_norm': 14.82404899597168, 'learning_rate': 7.459322033898305e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1599/6000 [1:33:30<4:12:24,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:33:33<4:16:41,  3.50s/it]                                                       {'loss': 0.0739, 'grad_norm': 6.938076019287109, 'learning_rate': 7.4576271186440685e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1600/6000 [1:33:33<4:16:41,  3.50s/it][2025-11-07 00:24:43,480] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600
[2025-11-07 00:24:43,492] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:24:44,238] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:33:39<5:06:55,  4.19s/it]                                                       {'loss': 0.0186, 'grad_norm': 5.218305587768555, 'learning_rate': 7.455932203389831e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1601/6000 [1:33:39<5:06:55,  4.19s/it] 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:33:43<5:00:24,  4.10s/it]                                                       {'loss': 0.067, 'grad_norm': 7.701645374298096, 'learning_rate': 7.454237288135594e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1602/6000 [1:33:43<5:00:24,  4.10s/it] 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:33:47<4:53:00,  4.00s/it]                                                       {'loss': 0.0184, 'grad_norm': 3.688336133956909, 'learning_rate': 7.452542372881356e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1603/6000 [1:33:47<4:53:00,  4.00s/it] 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:33:51<4:58:04,  4.07s/it]                                                       {'loss': 0.0228, 'grad_norm': 3.601632833480835, 'learning_rate': 7.45084745762712e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1604/6000 [1:33:51<4:58:04,  4.07s/it] 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:33:55<4:55:50,  4.04s/it]                                                       {'loss': 0.0468, 'grad_norm': 5.678010940551758, 'learning_rate': 7.4491525423728815e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1605/6000 [1:33:55<4:55:50,  4.04s/it] 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:33:58<4:39:13,  3.81s/it]                                                       {'loss': 0.0136, 'grad_norm': 2.998936891555786, 'learning_rate': 7.447457627118645e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1606/6000 [1:33:58<4:39:13,  3.81s/it] 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:02<4:30:03,  3.69s/it]                                                       {'loss': 0.0162, 'grad_norm': 3.2446446418762207, 'learning_rate': 7.445762711864407e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1607/6000 [1:34:02<4:30:03,  3.69s/it] 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:06<4:32:25,  3.72s/it]                                                       {'loss': 0.0398, 'grad_norm': 7.71509313583374, 'learning_rate': 7.4440677966101704e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1608/6000 [1:34:06<4:32:25,  3.72s/it] 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:09<4:24:05,  3.61s/it]                                                       {'loss': 0.0765, 'grad_norm': 14.486437797546387, 'learning_rate': 7.442372881355933e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1609/6000 [1:34:09<4:24:05,  3.61s/it] 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:12<4:19:35,  3.55s/it]                                                       {'loss': 0.0182, 'grad_norm': 5.881938457489014, 'learning_rate': 7.440677966101696e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1610/6000 [1:34:12<4:19:35,  3.55s/it] 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:34:16<4:16:37,  3.51s/it]                                                       {'loss': 0.0442, 'grad_norm': 6.33625602722168, 'learning_rate': 7.438983050847458e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1611/6000 [1:34:16<4:16:37,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:34:19<4:11:26,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07041708379983902, 'learning_rate': 7.437288135593221e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1612/6000 [1:34:19<4:11:26,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:34:22<4:09:11,  3.41s/it]                                                       {'loss': 0.1005, 'grad_norm': 16.575101852416992, 'learning_rate': 7.435593220338983e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1613/6000 [1:34:22<4:09:11,  3.41s/it] 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:34:26<4:11:41,  3.44s/it]                                                       {'loss': 0.1186, 'grad_norm': 13.328606605529785, 'learning_rate': 7.433898305084747e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1614/6000 [1:34:26<4:11:41,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:34:29<4:10:45,  3.43s/it]                                                       {'loss': 0.06, 'grad_norm': 9.027971267700195, 'learning_rate': 7.432203389830509e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1615/6000 [1:34:29<4:10:45,  3.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:34:33<4:13:14,  3.47s/it]                                                       {'loss': 0.0221, 'grad_norm': 2.841309070587158, 'learning_rate': 7.430508474576272e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1616/6000 [1:34:33<4:13:14,  3.47s/it] 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:34:36<4:11:38,  3.44s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.23041951656341553, 'learning_rate': 7.428813559322035e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1617/6000 [1:34:36<4:11:38,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:34:40<4:20:29,  3.57s/it]                                                       {'loss': 0.0353, 'grad_norm': 6.199464321136475, 'learning_rate': 7.427118644067796e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1618/6000 [1:34:40<4:20:29,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:34:44<4:20:26,  3.57s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.7255416512489319, 'learning_rate': 7.42542372881356e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1619/6000 [1:34:44<4:20:26,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:34:47<4:20:28,  3.57s/it]                                                       {'loss': 0.0218, 'grad_norm': 2.5277628898620605, 'learning_rate': 7.423728813559322e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1620/6000 [1:34:47<4:20:28,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:34:51<4:27:25,  3.66s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.9306819438934326, 'learning_rate': 7.422033898305085e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1621/6000 [1:34:51<4:27:25,  3.66s/it] 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:34:55<4:25:03,  3.63s/it]                                                       {'loss': 0.1208, 'grad_norm': 12.19130802154541, 'learning_rate': 7.420338983050848e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1622/6000 [1:34:55<4:25:03,  3.63s/it] 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:34:58<4:20:29,  3.57s/it]                                                       {'loss': 0.0785, 'grad_norm': 15.38012409210205, 'learning_rate': 7.418644067796611e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1623/6000 [1:34:58<4:20:29,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:02<4:20:17,  3.57s/it]                                                       {'loss': 0.1526, 'grad_norm': 12.844491958618164, 'learning_rate': 7.4169491525423735e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1624/6000 [1:35:02<4:20:17,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:05<4:20:10,  3.57s/it]                                                       {'loss': 0.053, 'grad_norm': 6.371025562286377, 'learning_rate': 7.415254237288137e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1625/6000 [1:35:05<4:20:10,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:09<4:18:02,  3.54s/it]                                                       {'loss': 0.015, 'grad_norm': 1.8488184213638306, 'learning_rate': 7.413559322033898e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1626/6000 [1:35:09<4:18:02,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:12<4:16:10,  3.51s/it]                                                       {'loss': 0.0477, 'grad_norm': 7.727520942687988, 'learning_rate': 7.411864406779662e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1627/6000 [1:35:12<4:16:10,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:35:16<4:17:58,  3.54s/it]                                                       {'loss': 0.045, 'grad_norm': 8.435797691345215, 'learning_rate': 7.410169491525424e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1628/6000 [1:35:16<4:17:58,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:35:19<4:16:37,  3.52s/it]                                                       {'loss': 0.0813, 'grad_norm': 13.361929893493652, 'learning_rate': 7.408474576271187e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1629/6000 [1:35:19<4:16:37,  3.52s/it] 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:35:23<4:17:30,  3.54s/it]                                                       {'loss': 0.2832, 'grad_norm': 16.95289421081543, 'learning_rate': 7.40677966101695e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1630/6000 [1:35:23<4:17:30,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:35:26<4:18:59,  3.56s/it]                                                       {'loss': 0.0973, 'grad_norm': 12.269906997680664, 'learning_rate': 7.405084745762713e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1631/6000 [1:35:26<4:18:59,  3.56s/it] 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:35:30<4:14:17,  3.49s/it]                                                       {'loss': 0.172, 'grad_norm': 18.35897445678711, 'learning_rate': 7.4033898305084754e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1632/6000 [1:35:30<4:14:17,  3.49s/it] 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:35:33<4:10:33,  3.44s/it]                                                       {'loss': 0.0797, 'grad_norm': 7.754310607910156, 'learning_rate': 7.401694915254239e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1633/6000 [1:35:33<4:10:33,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:35:36<4:08:33,  3.42s/it]                                                       {'loss': 0.1869, 'grad_norm': 12.599892616271973, 'learning_rate': 7.4e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1634/6000 [1:35:36<4:08:33,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:35:40<4:19:31,  3.57s/it]                                                       {'loss': 0.0918, 'grad_norm': 13.420190811157227, 'learning_rate': 7.3983050847457636e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1635/6000 [1:35:40<4:19:31,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:35:44<4:23:16,  3.62s/it]                                                       {'loss': 0.1393, 'grad_norm': 16.538280487060547, 'learning_rate': 7.396610169491526e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1636/6000 [1:35:44<4:23:16,  3.62s/it] 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:35:48<4:19:48,  3.57s/it]                                                       {'loss': 0.0647, 'grad_norm': 10.62962532043457, 'learning_rate': 7.394915254237289e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1637/6000 [1:35:48<4:19:48,  3.57s/it] 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:35:51<4:14:58,  3.51s/it]                                                       {'loss': 0.0559, 'grad_norm': 13.150005340576172, 'learning_rate': 7.393220338983052e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1638/6000 [1:35:51<4:14:58,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:35:54<4:12:09,  3.47s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.125556468963623, 'learning_rate': 7.391525423728813e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1639/6000 [1:35:54<4:12:09,  3.47s/it] 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:35:58<4:11:26,  3.46s/it]                                                       {'loss': 0.0611, 'grad_norm': 10.115168571472168, 'learning_rate': 7.3898305084745766e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1640/6000 [1:35:58<4:11:26,  3.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:01<4:17:04,  3.54s/it]                                                       {'loss': 0.1141, 'grad_norm': 9.99198055267334, 'learning_rate': 7.388135593220339e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1641/6000 [1:36:01<4:17:04,  3.54s/it] 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:05<4:14:57,  3.51s/it]                                                       {'loss': 0.0699, 'grad_norm': 11.644984245300293, 'learning_rate': 7.386440677966102e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1642/6000 [1:36:05<4:14:57,  3.51s/it] 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:08<4:12:37,  3.48s/it]                                                       {'loss': 0.1425, 'grad_norm': 15.201056480407715, 'learning_rate': 7.384745762711865e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1643/6000 [1:36:08<4:12:37,  3.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:12<4:09:28,  3.44s/it]                                                       {'loss': 0.0413, 'grad_norm': 6.361403942108154, 'learning_rate': 7.383050847457628e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1644/6000 [1:36:12<4:09:28,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:36:15<4:09:23,  3.44s/it]                                                       {'loss': 0.0403, 'grad_norm': 7.678175449371338, 'learning_rate': 7.38135593220339e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1645/6000 [1:36:15<4:09:23,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:36:18<4:07:59,  3.42s/it]                                                       {'loss': 0.3635, 'grad_norm': 20.013660430908203, 'learning_rate': 7.379661016949154e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1646/6000 [1:36:18<4:07:59,  3.42s/it] 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:36:22<4:09:50,  3.44s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.716200590133667, 'learning_rate': 7.377966101694915e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1647/6000 [1:36:22<4:09:50,  3.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:36:25<4:09:59,  3.45s/it]                                                       {'loss': 0.5008, 'grad_norm': 14.0216064453125, 'learning_rate': 7.3762711864406785e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1648/6000 [1:36:25<4:09:59,  3.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:36:29<4:09:25,  3.44s/it]                                                       {'loss': 0.1161, 'grad_norm': 9.690601348876953, 'learning_rate': 7.374576271186441e-06, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1649/6000 [1:36:29<4:09:25,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:36:32<4:09:45,  3.44s/it]                                                       {'loss': 0.1363, 'grad_norm': 13.017341613769531, 'learning_rate': 7.372881355932204e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1650/6000 [1:36:32<4:09:45,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:36:36<4:08:13,  3.42s/it]                                                       {'loss': 0.0462, 'grad_norm': 10.87120246887207, 'learning_rate': 7.371186440677967e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1651/6000 [1:36:36<4:08:13,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:36:40<4:22:51,  3.63s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06437039375305176, 'learning_rate': 7.36949152542373e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1652/6000 [1:36:40<4:22:51,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:36:43<4:19:15,  3.58s/it]                                                       {'loss': 0.1932, 'grad_norm': 18.731801986694336, 'learning_rate': 7.367796610169492e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1653/6000 [1:36:43<4:19:15,  3.58s/it] 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:36:47<4:15:39,  3.53s/it]                                                       {'loss': 0.0146, 'grad_norm': 4.488901138305664, 'learning_rate': 7.366101694915256e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1654/6000 [1:36:47<4:15:39,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:36:50<4:20:29,  3.60s/it]                                                       {'loss': 0.0218, 'grad_norm': 3.9094467163085938, 'learning_rate': 7.364406779661017e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1655/6000 [1:36:50<4:20:29,  3.60s/it] 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:36:54<4:18:40,  3.57s/it]                                                       {'loss': 0.0244, 'grad_norm': 4.78643274307251, 'learning_rate': 7.3627118644067805e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1656/6000 [1:36:54<4:18:40,  3.57s/it] 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:36:58<4:19:33,  3.59s/it]                                                       {'loss': 0.0144, 'grad_norm': 4.568550109863281, 'learning_rate': 7.361016949152543e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1657/6000 [1:36:58<4:19:33,  3.59s/it] 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:01<4:14:08,  3.51s/it]                                                       {'loss': 0.044, 'grad_norm': 4.877996921539307, 'learning_rate': 7.359322033898306e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1658/6000 [1:37:01<4:14:08,  3.51s/it] 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:06<4:38:44,  3.85s/it]                                                       {'loss': 0.0464, 'grad_norm': 12.520934104919434, 'learning_rate': 7.357627118644069e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1659/6000 [1:37:06<4:38:44,  3.85s/it] 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:09<4:35:38,  3.81s/it]                                                       {'loss': 0.0803, 'grad_norm': 11.470921516418457, 'learning_rate': 7.355932203389831e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1660/6000 [1:37:09<4:35:38,  3.81s/it] 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:37:13<4:26:29,  3.69s/it]                                                       {'loss': 0.0036, 'grad_norm': 1.1854197978973389, 'learning_rate': 7.354237288135594e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1661/6000 [1:37:13<4:26:29,  3.69s/it] 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:37:16<4:23:07,  3.64s/it]                                                       {'loss': 0.0559, 'grad_norm': 10.029518127441406, 'learning_rate': 7.352542372881356e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1662/6000 [1:37:16<4:23:07,  3.64s/it] 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:37:20<4:16:49,  3.55s/it]                                                       {'loss': 0.028, 'grad_norm': 12.398404121398926, 'learning_rate': 7.350847457627119e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1663/6000 [1:37:20<4:16:49,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:37:23<4:14:38,  3.52s/it]                                                       {'loss': 0.0935, 'grad_norm': 13.420649528503418, 'learning_rate': 7.3491525423728816e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1664/6000 [1:37:23<4:14:38,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:37:26<4:12:23,  3.49s/it]                                                       {'loss': 0.0803, 'grad_norm': 7.196661949157715, 'learning_rate': 7.347457627118645e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1665/6000 [1:37:26<4:12:23,  3.49s/it] 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:37:30<4:17:01,  3.56s/it]                                                       {'loss': 0.0366, 'grad_norm': 8.339334487915039, 'learning_rate': 7.345762711864407e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1666/6000 [1:37:30<4:17:01,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:37:34<4:23:12,  3.64s/it]                                                       {'loss': 0.0155, 'grad_norm': 4.931237697601318, 'learning_rate': 7.3440677966101705e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1667/6000 [1:37:34<4:23:12,  3.64s/it] 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:37:37<4:19:59,  3.60s/it]                                                       {'loss': 0.0914, 'grad_norm': 13.26512622833252, 'learning_rate': 7.342372881355932e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1668/6000 [1:37:37<4:19:59,  3.60s/it] 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:37:41<4:14:48,  3.53s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.850969910621643, 'learning_rate': 7.340677966101695e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1669/6000 [1:37:41<4:14:48,  3.53s/it] 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:37:45<4:19:32,  3.60s/it]                                                       {'loss': 0.1445, 'grad_norm': 13.611307144165039, 'learning_rate': 7.338983050847458e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1670/6000 [1:37:45<4:19:32,  3.60s/it] 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:37:48<4:13:44,  3.52s/it]                                                       {'loss': 0.0394, 'grad_norm': 4.512472629547119, 'learning_rate': 7.337288135593221e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1671/6000 [1:37:48<4:13:44,  3.52s/it] 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:37:52<4:16:36,  3.56s/it]                                                       {'loss': 0.1188, 'grad_norm': 14.943489074707031, 'learning_rate': 7.3355932203389835e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1672/6000 [1:37:52<4:16:36,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:37:55<4:12:51,  3.51s/it]                                                       {'loss': 0.0305, 'grad_norm': 5.782393932342529, 'learning_rate': 7.333898305084747e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1673/6000 [1:37:55<4:12:51,  3.51s/it] 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:37:58<4:11:06,  3.48s/it]                                                       {'loss': 0.0066, 'grad_norm': 2.2931149005889893, 'learning_rate': 7.332203389830509e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1674/6000 [1:37:58<4:11:06,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:02<4:10:02,  3.47s/it]                                                       {'loss': 0.0817, 'grad_norm': 8.80179500579834, 'learning_rate': 7.3305084745762725e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1675/6000 [1:38:02<4:10:02,  3.47s/it] 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:05<4:07:41,  3.44s/it]                                                       {'loss': 0.0112, 'grad_norm': 2.7631614208221436, 'learning_rate': 7.328813559322034e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1676/6000 [1:38:05<4:07:41,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:09<4:07:00,  3.43s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.8288054466247559, 'learning_rate': 7.327118644067797e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1677/6000 [1:38:09<4:07:00,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:12<4:04:39,  3.40s/it]                                                       {'loss': 0.0793, 'grad_norm': 11.795035362243652, 'learning_rate': 7.32542372881356e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1678/6000 [1:38:12<4:04:39,  3.40s/it] 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:38:16<4:23:17,  3.66s/it]                                                       {'loss': 0.0056, 'grad_norm': 2.582050085067749, 'learning_rate': 7.323728813559322e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1679/6000 [1:38:16<4:23:17,  3.66s/it] 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:38:20<4:16:48,  3.57s/it]                                                       {'loss': 0.0491, 'grad_norm': 9.143853187561035, 'learning_rate': 7.3220338983050855e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1680/6000 [1:38:20<4:16:48,  3.57s/it] 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:38:23<4:11:13,  3.49s/it]                                                       {'loss': 0.1449, 'grad_norm': 11.80846881866455, 'learning_rate': 7.320338983050848e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1681/6000 [1:38:23<4:11:13,  3.49s/it] 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:38:26<4:08:25,  3.45s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.5779389142990112, 'learning_rate': 7.318644067796611e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1682/6000 [1:38:26<4:08:25,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:38:30<4:05:16,  3.41s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.8883723020553589, 'learning_rate': 7.316949152542373e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1683/6000 [1:38:30<4:05:16,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:38:33<4:08:06,  3.45s/it]                                                       {'loss': 0.0095, 'grad_norm': 2.0938353538513184, 'learning_rate': 7.315254237288136e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1684/6000 [1:38:33<4:08:06,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:38:36<4:07:04,  3.44s/it]                                                       {'loss': 0.0444, 'grad_norm': 9.693581581115723, 'learning_rate': 7.3135593220338985e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1685/6000 [1:38:36<4:07:04,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:38:40<4:05:43,  3.42s/it]                                                       {'loss': 0.0104, 'grad_norm': 2.983001947402954, 'learning_rate': 7.311864406779662e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1686/6000 [1:38:40<4:05:43,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:38:44<4:23:29,  3.67s/it]                                                       {'loss': 0.0438, 'grad_norm': 8.422185897827148, 'learning_rate': 7.310169491525424e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1687/6000 [1:38:44<4:23:29,  3.67s/it] 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:38:48<4:20:06,  3.62s/it]                                                       {'loss': 0.1514, 'grad_norm': 12.379671096801758, 'learning_rate': 7.3084745762711874e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1688/6000 [1:38:48<4:20:06,  3.62s/it] 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:38:51<4:16:00,  3.56s/it]                                                       {'loss': 0.0174, 'grad_norm': 2.746870756149292, 'learning_rate': 7.30677966101695e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1689/6000 [1:38:51<4:16:00,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:38:55<4:15:52,  3.56s/it]                                                       {'loss': 0.2077, 'grad_norm': 14.95509147644043, 'learning_rate': 7.305084745762713e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1690/6000 [1:38:55<4:15:52,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:38:58<4:15:12,  3.55s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.9899768829345703, 'learning_rate': 7.303389830508475e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1691/6000 [1:38:58<4:15:12,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:02<4:16:35,  3.57s/it]                                                       {'loss': 0.0439, 'grad_norm': 6.533013820648193, 'learning_rate': 7.301694915254238e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1692/6000 [1:39:02<4:16:35,  3.57s/it] 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:05<4:20:13,  3.63s/it]                                                       {'loss': 0.157, 'grad_norm': 12.26103401184082, 'learning_rate': 7.3e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1693/6000 [1:39:05<4:20:13,  3.63s/it] 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:09<4:15:30,  3.56s/it]                                                       {'loss': 0.1005, 'grad_norm': 10.18470573425293, 'learning_rate': 7.298305084745764e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1694/6000 [1:39:09<4:15:30,  3.56s/it] 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:12<4:14:53,  3.55s/it]                                                       {'loss': 0.0202, 'grad_norm': 5.003068923950195, 'learning_rate': 7.296610169491526e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1695/6000 [1:39:12<4:14:53,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:39:16<4:09:51,  3.48s/it]                                                       {'loss': 0.117, 'grad_norm': 7.640214920043945, 'learning_rate': 7.294915254237289e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1696/6000 [1:39:16<4:09:51,  3.48s/it] 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:39:19<4:06:30,  3.44s/it]                                                       {'loss': 0.1189, 'grad_norm': 9.762887001037598, 'learning_rate': 7.293220338983051e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1697/6000 [1:39:19<4:06:30,  3.44s/it] 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:39:23<4:06:14,  3.43s/it]                                                       {'loss': 0.2265, 'grad_norm': 15.424310684204102, 'learning_rate': 7.291525423728815e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1698/6000 [1:39:23<4:06:14,  3.43s/it] 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:39:26<4:04:53,  3.42s/it]                                                       {'loss': 0.0776, 'grad_norm': 14.741621971130371, 'learning_rate': 7.289830508474577e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1699/6000 [1:39:26<4:04:53,  3.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:39:29<4:03:33,  3.40s/it]                                                       {'loss': 0.0621, 'grad_norm': 8.706548690795898, 'learning_rate': 7.288135593220339e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1700/6000 [1:39:29<4:03:33,  3.40s/it][2025-11-07 00:30:39,238] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700
[2025-11-07 00:30:39,256] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:30:39,936] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:39:35<4:52:18,  4.08s/it]                                                       {'loss': 0.2272, 'grad_norm': 13.790369987487793, 'learning_rate': 7.286440677966102e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1701/6000 [1:39:35<4:52:18,  4.08s/it] 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:39:38<4:36:42,  3.86s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.5294935703277588, 'learning_rate': 7.284745762711865e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1702/6000 [1:39:38<4:36:42,  3.86s/it] 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:39:42<4:31:54,  3.80s/it]                                                       {'loss': 0.2726, 'grad_norm': 15.049189567565918, 'learning_rate': 7.283050847457628e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1703/6000 [1:39:42<4:31:54,  3.80s/it] 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:39:45<4:22:11,  3.66s/it]                                                       {'loss': 0.4418, 'grad_norm': 14.6451416015625, 'learning_rate': 7.28135593220339e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1704/6000 [1:39:45<4:22:11,  3.66s/it] 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:39:49<4:13:48,  3.55s/it]                                                       {'loss': 0.0831, 'grad_norm': 8.057121276855469, 'learning_rate': 7.279661016949153e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1705/6000 [1:39:49<4:13:48,  3.55s/it] 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:39:52<4:09:37,  3.49s/it]                                                       {'loss': 0.0123, 'grad_norm': 3.0953996181488037, 'learning_rate': 7.277966101694915e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1706/6000 [1:39:52<4:09:37,  3.49s/it] 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:39:55<4:07:50,  3.46s/it]                                                       {'loss': 0.0105, 'grad_norm': 3.246326446533203, 'learning_rate': 7.276271186440679e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1707/6000 [1:39:55<4:07:50,  3.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:39:59<4:06:58,  3.45s/it]                                                       {'loss': 0.0096, 'grad_norm': 2.1748223304748535, 'learning_rate': 7.274576271186441e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1708/6000 [1:39:59<4:06:58,  3.45s/it] 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:02<4:03:38,  3.41s/it]                                                       {'loss': 0.0745, 'grad_norm': 9.162315368652344, 'learning_rate': 7.272881355932204e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1709/6000 [1:40:02<4:03:38,  3.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:05<4:03:54,  3.41s/it]                                                       {'loss': 0.0965, 'grad_norm': 14.539929389953613, 'learning_rate': 7.271186440677967e-06, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1710/6000 [1:40:05<4:03:54,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:09<4:05:10,  3.43s/it]                                                       {'loss': 0.0045, 'grad_norm': 1.2593942880630493, 'learning_rate': 7.26949152542373e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1711/6000 [1:40:09<4:05:10,  3.43s/it] 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:12<4:03:12,  3.40s/it]                                                       {'loss': 0.0604, 'grad_norm': 9.82935905456543, 'learning_rate': 7.267796610169492e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1712/6000 [1:40:12<4:03:12,  3.40s/it] 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:40:16<4:01:37,  3.38s/it]                                                       {'loss': 0.0087, 'grad_norm': 2.805015802383423, 'learning_rate': 7.266101694915255e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1713/6000 [1:40:16<4:01:37,  3.38s/it] 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:40:19<4:11:42,  3.52s/it]                                                       {'loss': 0.011, 'grad_norm': 1.7250778675079346, 'learning_rate': 7.264406779661017e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1714/6000 [1:40:19<4:11:42,  3.52s/it] 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:40:23<4:10:20,  3.51s/it]                                                       {'loss': 0.0111, 'grad_norm': 1.9406105279922485, 'learning_rate': 7.2627118644067806e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1715/6000 [1:40:23<4:10:20,  3.51s/it] 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:40:26<4:07:09,  3.46s/it]                                                       {'loss': 0.1128, 'grad_norm': 10.325925827026367, 'learning_rate': 7.261016949152543e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1716/6000 [1:40:26<4:07:09,  3.46s/it] 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:40:30<4:03:18,  3.41s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.23956231772899628, 'learning_rate': 7.259322033898306e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1717/6000 [1:40:30<4:03:18,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:40:33<4:00:42,  3.37s/it]                                                       {'loss': 0.0548, 'grad_norm': 3.99007511138916, 'learning_rate': 7.257627118644069e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1718/6000 [1:40:33<4:00:42,  3.37s/it] 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:40:36<4:02:12,  3.39s/it]                                                       {'loss': 0.0548, 'grad_norm': 19.086088180541992, 'learning_rate': 7.255932203389832e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1719/6000 [1:40:36<4:02:12,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:40:40<4:01:42,  3.39s/it]                                                       {'loss': 0.1227, 'grad_norm': 12.42790412902832, 'learning_rate': 7.2542372881355936e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1720/6000 [1:40:40<4:01:42,  3.39s/it] 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:40:43<4:03:40,  3.42s/it]                                                       {'loss': 0.0259, 'grad_norm': 6.814384937286377, 'learning_rate': 7.252542372881356e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1721/6000 [1:40:43<4:03:40,  3.42s/it] 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:40:47<4:02:56,  3.41s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.788983166217804, 'learning_rate': 7.250847457627119e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1722/6000 [1:40:47<4:02:56,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:40:50<4:02:51,  3.41s/it]                                                       {'loss': 0.0473, 'grad_norm': 8.440288543701172, 'learning_rate': 7.249152542372882e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1723/6000 [1:40:50<4:02:51,  3.41s/it] 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:40:53<4:05:32,  3.45s/it]                                                       {'loss': 0.0884, 'grad_norm': 5.9242777824401855, 'learning_rate': 7.247457627118645e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1724/6000 [1:40:53<4:05:32,  3.45s/it] 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:40:57<4:03:17,  3.41s/it]                                                       {'loss': 0.1016, 'grad_norm': 9.366235733032227, 'learning_rate': 7.2457627118644065e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1725/6000 [1:40:57<4:03:17,  3.41s/it] 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:00<4:04:45,  3.44s/it]                                                       {'loss': 0.0487, 'grad_norm': 12.617198944091797, 'learning_rate': 7.244067796610171e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1726/6000 [1:41:00<4:04:45,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:04<4:04:39,  3.44s/it]                                                       {'loss': 0.0217, 'grad_norm': 4.748099327087402, 'learning_rate': 7.242372881355932e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1727/6000 [1:41:04<4:04:39,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:07<4:04:14,  3.43s/it]                                                       {'loss': 0.0094, 'grad_norm': 2.2571513652801514, 'learning_rate': 7.2406779661016955e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1728/6000 [1:41:07<4:04:14,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:11<4:04:27,  3.43s/it]                                                       {'loss': 0.112, 'grad_norm': 9.915844917297363, 'learning_rate': 7.238983050847458e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1729/6000 [1:41:11<4:04:27,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:41:14<4:04:48,  3.44s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.9984768629074097, 'learning_rate': 7.237288135593221e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1730/6000 [1:41:14<4:04:48,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:41:17<4:03:01,  3.42s/it]                                                       {'loss': 0.023, 'grad_norm': 4.121241092681885, 'learning_rate': 7.235593220338984e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1731/6000 [1:41:17<4:03:01,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:41:21<4:04:06,  3.43s/it]                                                       {'loss': 0.003, 'grad_norm': 0.5107210278511047, 'learning_rate': 7.233898305084747e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1732/6000 [1:41:21<4:04:06,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:41:25<4:12:16,  3.55s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.7758897542953491, 'learning_rate': 7.2322033898305085e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1733/6000 [1:41:25<4:12:16,  3.55s/it] 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:41:28<4:08:57,  3.50s/it]                                                       {'loss': 0.2299, 'grad_norm': 17.245006561279297, 'learning_rate': 7.230508474576272e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1734/6000 [1:41:28<4:08:57,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:41:32<4:08:44,  3.50s/it]                                                       {'loss': 0.004, 'grad_norm': 0.9130429625511169, 'learning_rate': 7.228813559322034e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1735/6000 [1:41:32<4:08:44,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:41:35<4:08:29,  3.50s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.9070043563842773, 'learning_rate': 7.2271186440677975e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1736/6000 [1:41:35<4:08:29,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:41:39<4:08:07,  3.49s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.858083724975586, 'learning_rate': 7.22542372881356e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1737/6000 [1:41:39<4:08:07,  3.49s/it] 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:41:42<4:07:30,  3.48s/it]                                                       {'loss': 0.0174, 'grad_norm': 4.33034086227417, 'learning_rate': 7.223728813559323e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1738/6000 [1:41:42<4:07:30,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:41:46<4:14:49,  3.59s/it]                                                       {'loss': 0.1515, 'grad_norm': 13.76364803314209, 'learning_rate': 7.222033898305086e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1739/6000 [1:41:46<4:14:49,  3.59s/it] 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:41:50<4:20:12,  3.66s/it]                                                       {'loss': 0.0644, 'grad_norm': 11.690388679504395, 'learning_rate': 7.220338983050849e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1740/6000 [1:41:50<4:20:12,  3.66s/it] 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:41:53<4:14:28,  3.59s/it]                                                       {'loss': 0.0096, 'grad_norm': 4.251624584197998, 'learning_rate': 7.2186440677966104e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1741/6000 [1:41:53<4:14:28,  3.59s/it] 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:41:56<4:10:05,  3.52s/it]                                                       {'loss': 0.1395, 'grad_norm': 10.895120620727539, 'learning_rate': 7.216949152542373e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1742/6000 [1:41:56<4:10:05,  3.52s/it] 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:00<4:07:57,  3.49s/it]                                                       {'loss': 0.299, 'grad_norm': 19.887113571166992, 'learning_rate': 7.215254237288136e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1743/6000 [1:42:00<4:07:57,  3.49s/it] 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:03<4:06:02,  3.47s/it]                                                       {'loss': 0.0072, 'grad_norm': 2.5950963497161865, 'learning_rate': 7.2135593220338986e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1744/6000 [1:42:03<4:06:02,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:07<4:03:29,  3.43s/it]                                                       {'loss': 0.0602, 'grad_norm': 7.4663801193237305, 'learning_rate': 7.211864406779662e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1745/6000 [1:42:07<4:03:29,  3.43s/it] 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:10<4:00:51,  3.40s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.30103230476379395, 'learning_rate': 7.210169491525424e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1746/6000 [1:42:10<4:00:51,  3.40s/it] 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:42:13<4:00:26,  3.39s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.5766360759735107, 'learning_rate': 7.2084745762711875e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1747/6000 [1:42:13<4:00:26,  3.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:42:17<3:59:48,  3.38s/it]                                                       {'loss': 0.0439, 'grad_norm': 7.362667560577393, 'learning_rate': 7.206779661016949e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1748/6000 [1:42:17<3:59:48,  3.38s/it] 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:42:20<4:02:22,  3.42s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.281516432762146, 'learning_rate': 7.205084745762712e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1749/6000 [1:42:20<4:02:22,  3.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:42:24<4:12:50,  3.57s/it]                                                       {'loss': 0.0265, 'grad_norm': 6.074010372161865, 'learning_rate': 7.203389830508475e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1750/6000 [1:42:24<4:12:50,  3.57s/it] 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:42:28<4:14:06,  3.59s/it]                                                       {'loss': 0.0682, 'grad_norm': 13.652745246887207, 'learning_rate': 7.201694915254238e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1751/6000 [1:42:28<4:14:06,  3.59s/it] 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:42:31<4:11:08,  3.55s/it]                                                       {'loss': 0.1651, 'grad_norm': 17.722806930541992, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1752/6000 [1:42:31<4:11:08,  3.55s/it] 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:42:35<4:07:44,  3.50s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.200959324836731, 'learning_rate': 7.198305084745764e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1753/6000 [1:42:35<4:07:44,  3.50s/it] 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:42:38<4:11:56,  3.56s/it]                                                       {'loss': 0.0247, 'grad_norm': 5.302196502685547, 'learning_rate': 7.196610169491526e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1754/6000 [1:42:38<4:11:56,  3.56s/it] 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:42:42<4:16:47,  3.63s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.1946195363998413, 'learning_rate': 7.1949152542372895e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1755/6000 [1:42:42<4:16:47,  3.63s/it] 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:42:46<4:13:37,  3.59s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.721816897392273, 'learning_rate': 7.193220338983051e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1756/6000 [1:42:46<4:13:37,  3.59s/it] 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:42:49<4:08:05,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.07259377837181091, 'learning_rate': 7.191525423728814e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1757/6000 [1:42:49<4:08:05,  3.51s/it] 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:42:52<4:06:15,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.47422662377357483, 'learning_rate': 7.189830508474577e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1758/6000 [1:42:52<4:06:15,  3.48s/it] 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:42:56<4:06:21,  3.49s/it]                                                       {'loss': 0.1722, 'grad_norm': 20.463274002075195, 'learning_rate': 7.18813559322034e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1759/6000 [1:42:56<4:06:21,  3.49s/it] 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:42:59<4:04:55,  3.47s/it]                                                       {'loss': 0.1456, 'grad_norm': 16.243757247924805, 'learning_rate': 7.1864406779661025e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1760/6000 [1:42:59<4:04:55,  3.47s/it] 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:03<4:03:04,  3.44s/it]                                                       {'loss': 0.0246, 'grad_norm': 3.1244046688079834, 'learning_rate': 7.184745762711866e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1761/6000 [1:43:03<4:03:04,  3.44s/it] 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:07<4:15:02,  3.61s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.6859468221664429, 'learning_rate': 7.183050847457627e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1762/6000 [1:43:07<4:15:02,  3.61s/it] 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:10<4:10:27,  3.55s/it]                                                       {'loss': 0.0892, 'grad_norm': 10.887803077697754, 'learning_rate': 7.18135593220339e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1763/6000 [1:43:10<4:10:27,  3.55s/it] 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:43:14<4:28:22,  3.80s/it]                                                       {'loss': 0.2518, 'grad_norm': 16.941543579101562, 'learning_rate': 7.179661016949153e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1764/6000 [1:43:14<4:28:22,  3.80s/it] 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:43:19<4:42:57,  4.01s/it]                                                       {'loss': 0.1191, 'grad_norm': 15.01646900177002, 'learning_rate': 7.1779661016949155e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1765/6000 [1:43:19<4:42:57,  4.01s/it] 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:43:22<4:31:51,  3.85s/it]                                                       {'loss': 0.0268, 'grad_norm': 3.8213770389556885, 'learning_rate': 7.176271186440679e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1766/6000 [1:43:22<4:31:51,  3.85s/it] 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:43:26<4:25:59,  3.77s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.29722481966018677, 'learning_rate': 7.174576271186441e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1767/6000 [1:43:26<4:25:59,  3.77s/it] 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:43:30<4:34:56,  3.90s/it]                                                       {'loss': 0.0793, 'grad_norm': 11.121604919433594, 'learning_rate': 7.1728813559322044e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1768/6000 [1:43:30<4:34:56,  3.90s/it] 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:43:34<4:23:17,  3.73s/it]                                                       {'loss': 0.0307, 'grad_norm': 9.698738098144531, 'learning_rate': 7.171186440677966e-06, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1769/6000 [1:43:34<4:23:17,  3.73s/it] 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:43:37<4:20:01,  3.69s/it]                                                       {'loss': 0.0429, 'grad_norm': 7.759124279022217, 'learning_rate': 7.169491525423729e-06, 'epoch': 0.29}
 30%|â–ˆâ–ˆâ–‰       | 1770/6000 [1:43:37<4:20:01,  3.69s/it] 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:43:41<4:23:18,  3.74s/it]                                                       {'loss': 0.0176, 'grad_norm': 3.9958157539367676, 'learning_rate': 7.167796610169492e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1771/6000 [1:43:41<4:23:18,  3.74s/it] 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:43:44<4:14:55,  3.62s/it]                                                       {'loss': 0.2695, 'grad_norm': 19.321866989135742, 'learning_rate': 7.166101694915255e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1772/6000 [1:43:44<4:14:55,  3.62s/it] 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:43:48<4:08:27,  3.53s/it]                                                       {'loss': 0.0604, 'grad_norm': 7.288036346435547, 'learning_rate': 7.164406779661017e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1773/6000 [1:43:48<4:08:27,  3.53s/it] 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:43:51<4:05:46,  3.49s/it]                                                       {'loss': 0.0219, 'grad_norm': 3.3823187351226807, 'learning_rate': 7.162711864406781e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1774/6000 [1:43:51<4:05:46,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:43:54<4:05:13,  3.48s/it]                                                       {'loss': 0.1017, 'grad_norm': 14.175066947937012, 'learning_rate': 7.161016949152543e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1775/6000 [1:43:54<4:05:13,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:43:58<4:02:35,  3.45s/it]                                                       {'loss': 0.0498, 'grad_norm': 2.3177380561828613, 'learning_rate': 7.159322033898306e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1776/6000 [1:43:58<4:02:35,  3.45s/it] 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:01<4:01:49,  3.44s/it]                                                       {'loss': 0.0627, 'grad_norm': 8.737850189208984, 'learning_rate': 7.157627118644068e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1777/6000 [1:44:01<4:01:49,  3.44s/it] 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:05<4:05:06,  3.48s/it]                                                       {'loss': 0.1188, 'grad_norm': 14.345057487487793, 'learning_rate': 7.155932203389831e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1778/6000 [1:44:05<4:05:06,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:08<4:04:12,  3.47s/it]                                                       {'loss': 0.0279, 'grad_norm': 3.466596841812134, 'learning_rate': 7.154237288135594e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1779/6000 [1:44:08<4:04:12,  3.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:44:12<4:03:11,  3.46s/it]                                                       {'loss': 0.0436, 'grad_norm': 6.930490493774414, 'learning_rate': 7.152542372881357e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1780/6000 [1:44:12<4:03:11,  3.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:44:15<4:04:46,  3.48s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3791019022464752, 'learning_rate': 7.150847457627119e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1781/6000 [1:44:15<4:04:46,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:44:19<4:04:49,  3.48s/it]                                                       {'loss': 0.0356, 'grad_norm': 2.0450098514556885, 'learning_rate': 7.149152542372883e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1782/6000 [1:44:19<4:04:49,  3.48s/it] 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:44:22<4:08:24,  3.53s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.9757673740386963, 'learning_rate': 7.147457627118645e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1783/6000 [1:44:22<4:08:24,  3.53s/it] 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:44:26<4:07:10,  3.52s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3025638163089752, 'learning_rate': 7.145762711864407e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1784/6000 [1:44:26<4:07:10,  3.52s/it] 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:44:29<4:05:32,  3.50s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.35064825415611267, 'learning_rate': 7.14406779661017e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1785/6000 [1:44:29<4:05:32,  3.50s/it] 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:44:33<4:10:53,  3.57s/it]                                                       {'loss': 0.0581, 'grad_norm': 9.91633129119873, 'learning_rate': 7.142372881355932e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1786/6000 [1:44:33<4:10:53,  3.57s/it] 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:44:37<4:08:21,  3.54s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.6815817952156067, 'learning_rate': 7.140677966101696e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1787/6000 [1:44:37<4:08:21,  3.54s/it] 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:44:40<4:04:40,  3.49s/it]                                                       {'loss': 0.1074, 'grad_norm': 18.920225143432617, 'learning_rate': 7.138983050847458e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1788/6000 [1:44:40<4:04:40,  3.49s/it] 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:44:43<4:00:43,  3.43s/it]                                                       {'loss': 0.037, 'grad_norm': 6.106605052947998, 'learning_rate': 7.137288135593221e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1789/6000 [1:44:43<4:00:43,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:44:47<3:59:08,  3.41s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5592870116233826, 'learning_rate': 7.135593220338983e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1790/6000 [1:44:47<3:59:08,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:44:50<3:57:15,  3.38s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.2860724925994873, 'learning_rate': 7.133898305084746e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1791/6000 [1:44:50<3:57:15,  3.38s/it] 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:44:53<4:00:35,  3.43s/it]                                                       {'loss': 0.0996, 'grad_norm': 9.74413013458252, 'learning_rate': 7.132203389830509e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1792/6000 [1:44:53<4:00:35,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:44:57<4:00:17,  3.43s/it]                                                       {'loss': 0.0401, 'grad_norm': 8.147431373596191, 'learning_rate': 7.130508474576272e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1793/6000 [1:44:57<4:00:17,  3.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:00<3:57:49,  3.39s/it]                                                       {'loss': 0.0141, 'grad_norm': 5.203929901123047, 'learning_rate': 7.128813559322034e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1794/6000 [1:45:00<3:57:49,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:04<3:58:03,  3.40s/it]                                                       {'loss': 0.091, 'grad_norm': 12.647202491760254, 'learning_rate': 7.1271186440677976e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1795/6000 [1:45:04<3:58:03,  3.40s/it] 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:07<3:59:08,  3.41s/it]                                                       {'loss': 0.0121, 'grad_norm': 3.8925414085388184, 'learning_rate': 7.12542372881356e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1796/6000 [1:45:07<3:59:08,  3.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:10<3:57:37,  3.39s/it]                                                       {'loss': 0.0059, 'grad_norm': 0.878669261932373, 'learning_rate': 7.123728813559323e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1797/6000 [1:45:10<3:57:37,  3.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:45:14<3:56:09,  3.37s/it]                                                       {'loss': 0.0223, 'grad_norm': 4.676338195800781, 'learning_rate': 7.122033898305085e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1798/6000 [1:45:14<3:56:09,  3.37s/it] 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:45:17<3:55:49,  3.37s/it]                                                       {'loss': 0.0296, 'grad_norm': 3.9940946102142334, 'learning_rate': 7.120338983050848e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1799/6000 [1:45:17<3:55:49,  3.37s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:45:21<4:11:01,  3.59s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.1756141185760498, 'learning_rate': 7.1186440677966106e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1800/6000 [1:45:21<4:11:01,  3.59s/it][2025-11-07 00:36:31,128] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800
[2025-11-07 00:36:31,143] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:36:31,862] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:45:27<4:56:48,  4.24s/it]                                                       {'loss': 0.0731, 'grad_norm': 10.660350799560547, 'learning_rate': 7.116949152542374e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1801/6000 [1:45:27<4:56:48,  4.24s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:45:30<4:38:33,  3.98s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06427613645792007, 'learning_rate': 7.115254237288136e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1802/6000 [1:45:30<4:38:33,  3.98s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:45:34<4:26:40,  3.81s/it]                                                       {'loss': 0.063, 'grad_norm': 10.950174331665039, 'learning_rate': 7.1135593220338995e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1803/6000 [1:45:34<4:26:40,  3.81s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:45:37<4:18:12,  3.69s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1459178924560547, 'learning_rate': 7.111864406779662e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1804/6000 [1:45:37<4:18:12,  3.69s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:45:41<4:15:26,  3.65s/it]                                                       {'loss': 0.0704, 'grad_norm': 9.610806465148926, 'learning_rate': 7.1101694915254235e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1805/6000 [1:45:41<4:15:26,  3.65s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:45:44<4:09:56,  3.58s/it]                                                       {'loss': 0.0968, 'grad_norm': 13.119969367980957, 'learning_rate': 7.108474576271187e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1806/6000 [1:45:44<4:09:56,  3.58s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:45:47<4:06:13,  3.52s/it]                                                       {'loss': 0.1925, 'grad_norm': 13.04989242553711, 'learning_rate': 7.106779661016949e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1807/6000 [1:45:47<4:06:13,  3.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:45:51<4:04:53,  3.51s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2975323498249054, 'learning_rate': 7.1050847457627125e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1808/6000 [1:45:51<4:04:53,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:45:54<4:05:12,  3.51s/it]                                                       {'loss': 0.2232, 'grad_norm': 11.162798881530762, 'learning_rate': 7.103389830508475e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1809/6000 [1:45:54<4:05:12,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:45:58<4:11:18,  3.60s/it]                                                       {'loss': 0.0292, 'grad_norm': 7.131516456604004, 'learning_rate': 7.101694915254238e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1810/6000 [1:45:58<4:11:18,  3.60s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:02<4:05:42,  3.52s/it]                                                       {'loss': 0.0265, 'grad_norm': 6.773007869720459, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1811/6000 [1:46:02<4:05:42,  3.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:05<4:04:46,  3.51s/it]                                                       {'loss': 0.1627, 'grad_norm': 12.191500663757324, 'learning_rate': 7.098305084745764e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1812/6000 [1:46:05<4:04:46,  3.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:09<4:03:19,  3.49s/it]                                                       {'loss': 0.1569, 'grad_norm': 13.258670806884766, 'learning_rate': 7.0966101694915255e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1813/6000 [1:46:09<4:03:19,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:46:12<4:04:05,  3.50s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.7417913675308228, 'learning_rate': 7.094915254237289e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1814/6000 [1:46:12<4:04:05,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:46:15<4:02:53,  3.48s/it]                                                       {'loss': 0.0191, 'grad_norm': 5.1897501945495605, 'learning_rate': 7.093220338983051e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1815/6000 [1:46:15<4:02:53,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:46:19<4:02:57,  3.48s/it]                                                       {'loss': 0.2174, 'grad_norm': 18.38114356994629, 'learning_rate': 7.0915254237288145e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1816/6000 [1:46:19<4:02:57,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:46:22<4:01:27,  3.46s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.14758358895778656, 'learning_rate': 7.089830508474577e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1817/6000 [1:46:22<4:01:27,  3.46s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:46:26<4:00:41,  3.45s/it]                                                       {'loss': 0.0269, 'grad_norm': 6.009025573730469, 'learning_rate': 7.08813559322034e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1818/6000 [1:46:26<4:00:41,  3.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:46:30<4:07:07,  3.55s/it]                                                       {'loss': 0.2176, 'grad_norm': 16.39231300354004, 'learning_rate': 7.086440677966102e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1819/6000 [1:46:30<4:07:07,  3.55s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:46:33<4:06:06,  3.53s/it]                                                       {'loss': 0.0753, 'grad_norm': 6.091475009918213, 'learning_rate': 7.084745762711865e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1820/6000 [1:46:33<4:06:06,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:46:36<4:02:14,  3.48s/it]                                                       {'loss': 0.175, 'grad_norm': 15.712824821472168, 'learning_rate': 7.0830508474576274e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1821/6000 [1:46:36<4:02:14,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:46:40<4:02:39,  3.48s/it]                                                       {'loss': 0.0994, 'grad_norm': 14.28588581085205, 'learning_rate': 7.081355932203391e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1822/6000 [1:46:40<4:02:39,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:46:43<4:03:26,  3.50s/it]                                                       {'loss': 0.0287, 'grad_norm': 4.439858913421631, 'learning_rate': 7.079661016949153e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1823/6000 [1:46:43<4:03:26,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:46:47<4:02:14,  3.48s/it]                                                       {'loss': 0.1047, 'grad_norm': 12.648837089538574, 'learning_rate': 7.077966101694916e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1824/6000 [1:46:47<4:02:14,  3.48s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:46:51<4:05:28,  3.53s/it]                                                       {'loss': 0.0287, 'grad_norm': 3.775073766708374, 'learning_rate': 7.076271186440679e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1825/6000 [1:46:51<4:05:28,  3.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:46:54<4:05:02,  3.52s/it]                                                       {'loss': 0.0631, 'grad_norm': 10.71277904510498, 'learning_rate': 7.07457627118644e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1826/6000 [1:46:54<4:05:02,  3.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:46:58<4:06:37,  3.55s/it]                                                       {'loss': 0.038, 'grad_norm': 9.964067459106445, 'learning_rate': 7.072881355932204e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1827/6000 [1:46:58<4:06:37,  3.55s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:01<4:03:32,  3.50s/it]                                                       {'loss': 0.0809, 'grad_norm': 10.669500350952148, 'learning_rate': 7.071186440677966e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1828/6000 [1:47:01<4:03:32,  3.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:04<4:01:22,  3.47s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.373413562774658, 'learning_rate': 7.069491525423729e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1829/6000 [1:47:04<4:01:22,  3.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:08<4:10:33,  3.61s/it]                                                       {'loss': 0.0892, 'grad_norm': 11.721896171569824, 'learning_rate': 7.067796610169492e-06, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1830/6000 [1:47:08<4:10:33,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:12<4:06:48,  3.55s/it]                                                       {'loss': 0.0577, 'grad_norm': 13.27488899230957, 'learning_rate': 7.066101694915255e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1831/6000 [1:47:12<4:06:48,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:47:15<4:06:50,  3.55s/it]                                                       {'loss': 0.0738, 'grad_norm': 11.785971641540527, 'learning_rate': 7.0644067796610175e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1832/6000 [1:47:15<4:06:50,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:47:19<4:04:09,  3.52s/it]                                                       {'loss': 0.0603, 'grad_norm': 9.516749382019043, 'learning_rate': 7.062711864406781e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1833/6000 [1:47:19<4:04:09,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:47:22<3:59:32,  3.45s/it]                                                       {'loss': 0.03, 'grad_norm': 4.564717769622803, 'learning_rate': 7.061016949152542e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1834/6000 [1:47:22<3:59:32,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:47:25<3:58:14,  3.43s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.6591228246688843, 'learning_rate': 7.059322033898306e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1835/6000 [1:47:25<3:58:14,  3.43s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:47:29<4:01:36,  3.48s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.0416399240493774, 'learning_rate': 7.057627118644068e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1836/6000 [1:47:29<4:01:36,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:47:33<4:07:38,  3.57s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.304288625717163, 'learning_rate': 7.055932203389831e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1837/6000 [1:47:33<4:07:38,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:47:36<4:05:32,  3.54s/it]                                                       {'loss': 0.0128, 'grad_norm': 3.485741138458252, 'learning_rate': 7.054237288135594e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1838/6000 [1:47:36<4:05:32,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:47:40<4:04:08,  3.52s/it]                                                       {'loss': 0.0192, 'grad_norm': 3.8378055095672607, 'learning_rate': 7.052542372881357e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1839/6000 [1:47:40<4:04:08,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:47:44<4:11:32,  3.63s/it]                                                       {'loss': 0.0049, 'grad_norm': 1.5000715255737305, 'learning_rate': 7.0508474576271195e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1840/6000 [1:47:44<4:11:32,  3.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:47:47<4:06:43,  3.56s/it]                                                       {'loss': 0.3554, 'grad_norm': 17.147523880004883, 'learning_rate': 7.049152542372883e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1841/6000 [1:47:47<4:06:43,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:47:51<4:04:45,  3.53s/it]                                                       {'loss': 0.027, 'grad_norm': 2.7393407821655273, 'learning_rate': 7.047457627118644e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1842/6000 [1:47:51<4:04:45,  3.53s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:47:54<4:02:20,  3.50s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.8570173978805542, 'learning_rate': 7.045762711864408e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1843/6000 [1:47:54<4:02:20,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:47:57<3:59:11,  3.45s/it]                                                       {'loss': 0.0197, 'grad_norm': 4.576064109802246, 'learning_rate': 7.04406779661017e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1844/6000 [1:47:57<3:59:11,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:01<4:05:36,  3.55s/it]                                                       {'loss': 0.1209, 'grad_norm': 10.320686340332031, 'learning_rate': 7.042372881355933e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1845/6000 [1:48:01<4:05:36,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:05<4:05:32,  3.55s/it]                                                       {'loss': 0.0969, 'grad_norm': 11.497465133666992, 'learning_rate': 7.040677966101696e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1846/6000 [1:48:05<4:05:32,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:08<4:02:01,  3.50s/it]                                                       {'loss': 0.1401, 'grad_norm': 12.510912895202637, 'learning_rate': 7.038983050847457e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1847/6000 [1:48:08<4:02:01,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:11<4:00:29,  3.48s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.6963419318199158, 'learning_rate': 7.037288135593221e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1848/6000 [1:48:11<4:00:29,  3.48s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:48:15<4:01:37,  3.49s/it]                                                       {'loss': 0.0383, 'grad_norm': 6.626967906951904, 'learning_rate': 7.035593220338983e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1849/6000 [1:48:15<4:01:37,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:48:19<4:18:00,  3.73s/it]                                                       {'loss': 0.0924, 'grad_norm': 9.981820106506348, 'learning_rate': 7.033898305084746e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1850/6000 [1:48:19<4:18:00,  3.73s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:48:23<4:10:36,  3.62s/it]                                                       {'loss': 0.1687, 'grad_norm': 17.784448623657227, 'learning_rate': 7.032203389830509e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1851/6000 [1:48:23<4:10:36,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:48:26<4:06:11,  3.56s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.4211665391921997, 'learning_rate': 7.030508474576272e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1852/6000 [1:48:26<4:06:11,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:48:29<4:01:45,  3.50s/it]                                                       {'loss': 0.107, 'grad_norm': 5.935326099395752, 'learning_rate': 7.028813559322034e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1853/6000 [1:48:29<4:01:45,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:48:33<3:58:21,  3.45s/it]                                                       {'loss': 0.3494, 'grad_norm': 14.415523529052734, 'learning_rate': 7.027118644067798e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1854/6000 [1:48:33<3:58:21,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:48:36<3:56:49,  3.43s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.626412272453308, 'learning_rate': 7.025423728813559e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1855/6000 [1:48:36<3:56:49,  3.43s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:48:40<3:57:56,  3.45s/it]                                                       {'loss': 0.0097, 'grad_norm': 2.6433990001678467, 'learning_rate': 7.0237288135593225e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1856/6000 [1:48:40<3:57:56,  3.45s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:48:44<4:18:12,  3.74s/it]                                                       {'loss': 0.1136, 'grad_norm': 14.079474449157715, 'learning_rate': 7.022033898305085e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1857/6000 [1:48:44<4:18:12,  3.74s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:48:48<4:13:23,  3.67s/it]                                                       {'loss': 0.0356, 'grad_norm': 6.789343357086182, 'learning_rate': 7.020338983050848e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1858/6000 [1:48:48<4:13:23,  3.67s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:48:51<4:16:42,  3.72s/it]                                                       {'loss': 0.0091, 'grad_norm': 2.1706244945526123, 'learning_rate': 7.018644067796611e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1859/6000 [1:48:51<4:16:42,  3.72s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:48:55<4:10:04,  3.62s/it]                                                       {'loss': 0.0635, 'grad_norm': 9.547021865844727, 'learning_rate': 7.016949152542374e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1860/6000 [1:48:55<4:10:04,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:48:58<4:05:26,  3.56s/it]                                                       {'loss': 0.0283, 'grad_norm': 7.93961238861084, 'learning_rate': 7.015254237288136e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1861/6000 [1:48:58<4:05:26,  3.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:02<4:19:02,  3.76s/it]                                                       {'loss': 0.0206, 'grad_norm': 5.7546706199646, 'learning_rate': 7.0135593220339e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1862/6000 [1:49:02<4:19:02,  3.76s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:06<4:12:43,  3.67s/it]                                                       {'loss': 0.0138, 'grad_norm': 4.937994003295898, 'learning_rate': 7.011864406779661e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1863/6000 [1:49:06<4:12:43,  3.67s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:09<4:07:41,  3.59s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.4649806022644043, 'learning_rate': 7.0101694915254245e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1864/6000 [1:49:09<4:07:41,  3.59s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:49:13<4:04:06,  3.54s/it]                                                       {'loss': 0.2273, 'grad_norm': 6.699470520019531, 'learning_rate': 7.008474576271187e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1865/6000 [1:49:13<4:04:06,  3.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:49:16<4:06:14,  3.57s/it]                                                       {'loss': 0.0204, 'grad_norm': 3.6868021488189697, 'learning_rate': 7.006779661016949e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1866/6000 [1:49:16<4:06:14,  3.57s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:49:20<4:11:55,  3.66s/it]                                                       {'loss': 0.0669, 'grad_norm': 11.992173194885254, 'learning_rate': 7.005084745762713e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1867/6000 [1:49:20<4:11:55,  3.66s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:49:24<4:06:19,  3.58s/it]                                                       {'loss': 0.0747, 'grad_norm': 14.484941482543945, 'learning_rate': 7.003389830508475e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1868/6000 [1:49:24<4:06:19,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:49:27<4:04:29,  3.55s/it]                                                       {'loss': 0.0359, 'grad_norm': 4.54403829574585, 'learning_rate': 7.001694915254238e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1869/6000 [1:49:27<4:04:29,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:49:30<4:02:22,  3.52s/it]                                                       {'loss': 0.0732, 'grad_norm': 8.88693618774414, 'learning_rate': 7e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1870/6000 [1:49:31<4:02:22,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:49:34<4:01:11,  3.50s/it]                                                       {'loss': 0.2713, 'grad_norm': 18.702577590942383, 'learning_rate': 6.998305084745763e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1871/6000 [1:49:34<4:01:11,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:49:38<4:08:02,  3.61s/it]                                                       {'loss': 0.0707, 'grad_norm': 7.50597620010376, 'learning_rate': 6.996610169491526e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1872/6000 [1:49:38<4:08:02,  3.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:49:41<4:08:43,  3.62s/it]                                                       {'loss': 0.1592, 'grad_norm': 17.119966506958008, 'learning_rate': 6.994915254237289e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1873/6000 [1:49:41<4:08:43,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:49:45<4:06:26,  3.58s/it]                                                       {'loss': 0.0406, 'grad_norm': 5.618216514587402, 'learning_rate': 6.993220338983051e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1874/6000 [1:49:45<4:06:26,  3.58s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:49:48<4:01:34,  3.51s/it]                                                       {'loss': 0.0104, 'grad_norm': 1.9880800247192383, 'learning_rate': 6.9915254237288146e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1875/6000 [1:49:48<4:01:34,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:49:52<4:09:06,  3.62s/it]                                                       {'loss': 0.1601, 'grad_norm': 14.608718872070312, 'learning_rate': 6.989830508474576e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1876/6000 [1:49:52<4:09:06,  3.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:49:56<4:07:08,  3.60s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.078455924987793, 'learning_rate': 6.98813559322034e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1877/6000 [1:49:56<4:07:08,  3.60s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:49:59<4:02:06,  3.52s/it]                                                       {'loss': 0.0237, 'grad_norm': 5.113565921783447, 'learning_rate': 6.986440677966102e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1878/6000 [1:49:59<4:02:06,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:02<4:00:05,  3.50s/it]                                                       {'loss': 0.0375, 'grad_norm': 3.6450893878936768, 'learning_rate': 6.984745762711865e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1879/6000 [1:50:03<4:00:05,  3.50s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:06<4:00:59,  3.51s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.36331427097320557, 'learning_rate': 6.9830508474576275e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1880/6000 [1:50:06<4:00:59,  3.51s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:09<3:58:09,  3.47s/it]                                                       {'loss': 0.0404, 'grad_norm': 7.253842830657959, 'learning_rate': 6.981355932203391e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1881/6000 [1:50:09<3:58:09,  3.47s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:50:13<3:55:02,  3.42s/it]                                                       {'loss': 0.0204, 'grad_norm': 2.803746223449707, 'learning_rate': 6.979661016949153e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1882/6000 [1:50:13<3:55:02,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:50:16<3:54:29,  3.42s/it]                                                       {'loss': 0.0404, 'grad_norm': 7.780794143676758, 'learning_rate': 6.9779661016949165e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1883/6000 [1:50:16<3:54:29,  3.42s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:50:20<3:55:54,  3.44s/it]                                                       {'loss': 0.0287, 'grad_norm': 7.572129726409912, 'learning_rate': 6.976271186440678e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1884/6000 [1:50:20<3:55:54,  3.44s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:50:23<4:03:35,  3.55s/it]                                                       {'loss': 0.0253, 'grad_norm': 4.349631309509277, 'learning_rate': 6.974576271186441e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1885/6000 [1:50:23<4:03:35,  3.55s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:50:27<4:01:22,  3.52s/it]                                                       {'loss': 0.0083, 'grad_norm': 2.072298765182495, 'learning_rate': 6.972881355932204e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1886/6000 [1:50:27<4:01:22,  3.52s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:50:30<3:59:34,  3.49s/it]                                                       {'loss': 0.0575, 'grad_norm': 5.431467533111572, 'learning_rate': 6.971186440677966e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1887/6000 [1:50:30<3:59:34,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:50:34<3:59:07,  3.49s/it]                                                       {'loss': 0.0284, 'grad_norm': 8.024840354919434, 'learning_rate': 6.9694915254237295e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1888/6000 [1:50:34<3:59:07,  3.49s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:50:38<4:06:00,  3.59s/it]                                                       {'loss': 0.0824, 'grad_norm': 7.14361572265625, 'learning_rate': 6.967796610169492e-06, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1889/6000 [1:50:38<4:06:00,  3.59s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:50:41<4:03:54,  3.56s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.1812914609909058, 'learning_rate': 6.966101694915255e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1890/6000 [1:50:41<4:03:54,  3.56s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:50:45<4:04:38,  3.57s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.4557689428329468, 'learning_rate': 6.964406779661017e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1891/6000 [1:50:45<4:04:38,  3.57s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:50:48<4:01:39,  3.53s/it]                                                       {'loss': 0.019, 'grad_norm': 5.5425286293029785, 'learning_rate': 6.96271186440678e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1892/6000 [1:50:48<4:01:39,  3.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:50:52<3:58:12,  3.48s/it]                                                       {'loss': 0.0266, 'grad_norm': 9.854615211486816, 'learning_rate': 6.9610169491525425e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1893/6000 [1:50:52<3:58:12,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:50:55<3:59:33,  3.50s/it]                                                       {'loss': 0.0094, 'grad_norm': 2.0482983589172363, 'learning_rate': 6.959322033898306e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1894/6000 [1:50:55<3:59:33,  3.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:50:59<4:12:00,  3.68s/it]                                                       {'loss': 0.0205, 'grad_norm': 4.533283233642578, 'learning_rate': 6.957627118644068e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1895/6000 [1:50:59<4:12:00,  3.68s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:03<4:07:33,  3.62s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.39506009221076965, 'learning_rate': 6.9559322033898315e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1896/6000 [1:51:03<4:07:33,  3.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:06<4:02:05,  3.54s/it]                                                       {'loss': 0.0611, 'grad_norm': 11.166912078857422, 'learning_rate': 6.954237288135594e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1897/6000 [1:51:06<4:02:05,  3.54s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:09<3:56:52,  3.46s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.0137195587158203, 'learning_rate': 6.952542372881357e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1898/6000 [1:51:09<3:56:52,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:51:13<3:53:52,  3.42s/it]                                                       {'loss': 0.1313, 'grad_norm': 12.418055534362793, 'learning_rate': 6.950847457627119e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1899/6000 [1:51:13<3:53:52,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:51:16<3:52:29,  3.40s/it]                                                       {'loss': 0.1207, 'grad_norm': 12.178502082824707, 'learning_rate': 6.949152542372882e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1900/6000 [1:51:16<3:52:29,  3.40s/it][2025-11-07 00:42:25,959] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900
[2025-11-07 00:42:25,972] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:42:26,630] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:51:22<4:39:50,  4.10s/it]                                                       {'loss': 0.0118, 'grad_norm': 3.5249521732330322, 'learning_rate': 6.9474576271186444e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1901/6000 [1:51:22<4:39:50,  4.10s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:51:26<4:48:30,  4.22s/it]                                                       {'loss': 0.0213, 'grad_norm': 5.8383378982543945, 'learning_rate': 6.945762711864408e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1902/6000 [1:51:26<4:48:30,  4.22s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:51:30<4:31:06,  3.97s/it]                                                       {'loss': 0.0855, 'grad_norm': 3.7449164390563965, 'learning_rate': 6.94406779661017e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1903/6000 [1:51:30<4:31:06,  3.97s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:51:33<4:28:49,  3.94s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.9469779133796692, 'learning_rate': 6.942372881355933e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1904/6000 [1:51:33<4:28:49,  3.94s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:51:37<4:26:07,  3.90s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.8240346312522888, 'learning_rate': 6.940677966101696e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1905/6000 [1:51:37<4:26:07,  3.90s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:51:41<4:14:40,  3.73s/it]                                                       {'loss': 0.1163, 'grad_norm': 11.075014114379883, 'learning_rate': 6.938983050847459e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1906/6000 [1:51:41<4:14:40,  3.73s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:51:44<4:08:51,  3.65s/it]                                                       {'loss': 0.048, 'grad_norm': 10.48307991027832, 'learning_rate': 6.937288135593221e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1907/6000 [1:51:44<4:08:51,  3.65s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:51:47<4:02:07,  3.55s/it]                                                       {'loss': 0.0801, 'grad_norm': 10.269410133361816, 'learning_rate': 6.935593220338983e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1908/6000 [1:51:47<4:02:07,  3.55s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:51:51<3:57:06,  3.48s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.9226890802383423, 'learning_rate': 6.933898305084746e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1909/6000 [1:51:51<3:57:06,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:51:54<3:57:31,  3.48s/it]                                                       {'loss': 0.0196, 'grad_norm': 4.704107284545898, 'learning_rate': 6.932203389830509e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1910/6000 [1:51:54<3:57:31,  3.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:51:57<3:53:42,  3.43s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.7047756910324097, 'learning_rate': 6.930508474576272e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1911/6000 [1:51:57<3:53:42,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:52:01<3:53:20,  3.42s/it]                                                       {'loss': 0.1287, 'grad_norm': 15.955906867980957, 'learning_rate': 6.928813559322034e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1912/6000 [1:52:01<3:53:20,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:52:04<3:54:42,  3.45s/it]                                                       {'loss': 0.1364, 'grad_norm': 14.437090873718262, 'learning_rate': 6.927118644067797e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1913/6000 [1:52:04<3:54:42,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:52:08<3:53:29,  3.43s/it]                                                       {'loss': 0.0074, 'grad_norm': 2.868155002593994, 'learning_rate': 6.925423728813559e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1914/6000 [1:52:08<3:53:29,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:52:11<3:55:44,  3.46s/it]                                                       {'loss': 0.0482, 'grad_norm': 6.896573066711426, 'learning_rate': 6.923728813559323e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1915/6000 [1:52:11<3:55:44,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:52:15<3:57:27,  3.49s/it]                                                       {'loss': 0.0558, 'grad_norm': 11.893755912780762, 'learning_rate': 6.922033898305085e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1916/6000 [1:52:15<3:57:27,  3.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:52:18<3:54:46,  3.45s/it]                                                       {'loss': 0.0711, 'grad_norm': 13.515562057495117, 'learning_rate': 6.920338983050848e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1917/6000 [1:52:18<3:54:46,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:52:22<3:53:57,  3.44s/it]                                                       {'loss': 0.014, 'grad_norm': 3.9158248901367188, 'learning_rate': 6.918644067796611e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1918/6000 [1:52:22<3:53:57,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:52:25<3:59:10,  3.52s/it]                                                       {'loss': 0.1007, 'grad_norm': 3.980926990509033, 'learning_rate': 6.916949152542374e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1919/6000 [1:52:25<3:59:10,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:52:29<3:58:47,  3.51s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.8396961092948914, 'learning_rate': 6.915254237288136e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1920/6000 [1:52:29<3:58:47,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:52:32<4:00:12,  3.53s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.17649899423122406, 'learning_rate': 6.913559322033899e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1921/6000 [1:52:32<4:00:12,  3.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:52:36<3:55:13,  3.46s/it]                                                       {'loss': 0.2101, 'grad_norm': 10.998031616210938, 'learning_rate': 6.911864406779661e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1922/6000 [1:52:36<3:55:13,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:52:39<3:52:37,  3.42s/it]                                                       {'loss': 0.125, 'grad_norm': 6.173315525054932, 'learning_rate': 6.910169491525425e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1923/6000 [1:52:39<3:52:37,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:52:43<3:55:59,  3.47s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.08622871339321136, 'learning_rate': 6.908474576271187e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1924/6000 [1:52:43<3:55:59,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:52:46<3:54:14,  3.45s/it]                                                       {'loss': 0.0589, 'grad_norm': 8.604166030883789, 'learning_rate': 6.90677966101695e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1925/6000 [1:52:46<3:54:14,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:52:49<3:51:23,  3.41s/it]                                                       {'loss': 0.0624, 'grad_norm': 6.499859809875488, 'learning_rate': 6.905084745762713e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1926/6000 [1:52:49<3:51:23,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:52:53<3:53:54,  3.45s/it]                                                       {'loss': 0.0137, 'grad_norm': 4.222623825073242, 'learning_rate': 6.903389830508476e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1927/6000 [1:52:53<3:53:54,  3.45s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:52:56<3:52:08,  3.42s/it]                                                       {'loss': 0.0701, 'grad_norm': 7.609064102172852, 'learning_rate': 6.901694915254238e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1928/6000 [1:52:56<3:52:08,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:53:00<3:50:57,  3.40s/it]                                                       {'loss': 0.002, 'grad_norm': 0.41374459862709045, 'learning_rate': 6.9e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1929/6000 [1:53:00<3:50:57,  3.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:53:03<3:53:36,  3.44s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.3956966698169708, 'learning_rate': 6.898305084745763e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1930/6000 [1:53:03<3:53:36,  3.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:53:07<3:55:38,  3.47s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3272637128829956, 'learning_rate': 6.896610169491526e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1931/6000 [1:53:07<3:55:38,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:53:10<3:52:09,  3.42s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5054478049278259, 'learning_rate': 6.894915254237289e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1932/6000 [1:53:10<3:52:09,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:53:13<3:52:04,  3.42s/it]                                                       {'loss': 0.0323, 'grad_norm': 3.3292312622070312, 'learning_rate': 6.893220338983051e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1933/6000 [1:53:13<3:52:04,  3.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:53:17<3:49:43,  3.39s/it]                                                       {'loss': 0.0093, 'grad_norm': 3.648983955383301, 'learning_rate': 6.891525423728815e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1934/6000 [1:53:17<3:49:43,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:53:20<3:50:42,  3.41s/it]                                                       {'loss': 0.0485, 'grad_norm': 4.673857688903809, 'learning_rate': 6.889830508474576e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1935/6000 [1:53:20<3:50:42,  3.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:53:24<3:49:37,  3.39s/it]                                                       {'loss': 0.052, 'grad_norm': 8.990225791931152, 'learning_rate': 6.8881355932203395e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1936/6000 [1:53:24<3:49:37,  3.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:53:27<3:54:28,  3.46s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.9916072487831116, 'learning_rate': 6.886440677966102e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1937/6000 [1:53:27<3:54:28,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:53:31<4:03:59,  3.60s/it]                                                       {'loss': 0.0438, 'grad_norm': 9.002580642700195, 'learning_rate': 6.884745762711865e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1938/6000 [1:53:31<4:03:59,  3.60s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:53:34<3:58:27,  3.52s/it]                                                       {'loss': 0.0859, 'grad_norm': 10.144436836242676, 'learning_rate': 6.883050847457628e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1939/6000 [1:53:34<3:58:27,  3.52s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:53:38<3:57:13,  3.51s/it]                                                       {'loss': 0.0582, 'grad_norm': 9.840304374694824, 'learning_rate': 6.881355932203391e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1940/6000 [1:53:38<3:57:13,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:53:41<3:55:01,  3.47s/it]                                                       {'loss': 0.1712, 'grad_norm': 13.429997444152832, 'learning_rate': 6.8796610169491525e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1941/6000 [1:53:41<3:55:01,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:53:45<3:53:41,  3.46s/it]                                                       {'loss': 0.1147, 'grad_norm': 12.020106315612793, 'learning_rate': 6.877966101694916e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1942/6000 [1:53:45<3:53:41,  3.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:53:48<3:51:50,  3.43s/it]                                                       {'loss': 0.0212, 'grad_norm': 5.247618675231934, 'learning_rate': 6.876271186440678e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1943/6000 [1:53:48<3:51:50,  3.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:53:52<3:54:47,  3.47s/it]                                                       {'loss': 0.117, 'grad_norm': 15.00993824005127, 'learning_rate': 6.8745762711864415e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1944/6000 [1:53:52<3:54:47,  3.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:53:55<4:01:08,  3.57s/it]                                                       {'loss': 0.0422, 'grad_norm': 8.454261779785156, 'learning_rate': 6.872881355932204e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1945/6000 [1:53:55<4:01:08,  3.57s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:53:59<3:56:26,  3.50s/it]                                                       {'loss': 0.0152, 'grad_norm': 5.231722831726074, 'learning_rate': 6.871186440677967e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1946/6000 [1:53:59<3:56:26,  3.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:54:02<3:57:22,  3.51s/it]                                                       {'loss': 0.1196, 'grad_norm': 10.287477493286133, 'learning_rate': 6.86949152542373e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1947/6000 [1:54:02<3:57:22,  3.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:54:06<3:58:43,  3.53s/it]                                                       {'loss': 0.0103, 'grad_norm': 3.112083673477173, 'learning_rate': 6.867796610169493e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1948/6000 [1:54:06<3:58:43,  3.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:54:10<4:04:52,  3.63s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.4556944370269775, 'learning_rate': 6.8661016949152545e-06, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1949/6000 [1:54:10<4:04:52,  3.63s/it] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:54:13<3:59:04,  3.54s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.9452078342437744, 'learning_rate': 6.864406779661017e-06, 'epoch': 0.33}
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1950/6000 [1:54:13<3:59:04,  3.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:54:17<3:59:15,  3.55s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.19674965739250183, 'learning_rate': 6.86271186440678e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1951/6000 [1:54:17<3:59:15,  3.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:54:20<3:55:50,  3.50s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.5485779047012329, 'learning_rate': 6.861016949152543e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1952/6000 [1:54:20<3:55:50,  3.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:54:23<3:53:00,  3.45s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.1293081045150757, 'learning_rate': 6.859322033898306e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1953/6000 [1:54:23<3:53:00,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:54:27<3:52:25,  3.45s/it]                                                       {'loss': 0.0134, 'grad_norm': 3.9556725025177, 'learning_rate': 6.857627118644068e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1954/6000 [1:54:27<3:52:25,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:54:30<3:50:24,  3.42s/it]                                                       {'loss': 0.0353, 'grad_norm': 5.028968811035156, 'learning_rate': 6.8559322033898316e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1955/6000 [1:54:30<3:50:24,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:54:34<3:51:32,  3.44s/it]                                                       {'loss': 0.0238, 'grad_norm': 3.0554378032684326, 'learning_rate': 6.854237288135593e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1956/6000 [1:54:34<3:51:32,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:54:37<3:50:44,  3.42s/it]                                                       {'loss': 0.0607, 'grad_norm': 5.698619365692139, 'learning_rate': 6.852542372881356e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1957/6000 [1:54:37<3:50:44,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:54:40<3:49:13,  3.40s/it]                                                       {'loss': 0.0438, 'grad_norm': 5.759631633758545, 'learning_rate': 6.850847457627119e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1958/6000 [1:54:40<3:49:13,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:54:44<3:56:58,  3.52s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.20229952037334442, 'learning_rate': 6.849152542372882e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1959/6000 [1:54:44<3:56:58,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:54:48<3:55:13,  3.49s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.5144630670547485, 'learning_rate': 6.8474576271186445e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1960/6000 [1:54:48<3:55:13,  3.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:54:51<3:52:28,  3.45s/it]                                                       {'loss': 0.0029, 'grad_norm': 1.0914026498794556, 'learning_rate': 6.845762711864408e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1961/6000 [1:54:51<3:52:28,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:54:55<3:56:46,  3.52s/it]                                                       {'loss': 0.1622, 'grad_norm': 15.261754989624023, 'learning_rate': 6.84406779661017e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1962/6000 [1:54:55<3:56:46,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:54:58<3:53:06,  3.46s/it]                                                       {'loss': 0.0456, 'grad_norm': 6.21049165725708, 'learning_rate': 6.8423728813559335e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1963/6000 [1:54:58<3:53:06,  3.46s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:55:01<3:50:09,  3.42s/it]                                                       {'loss': 0.0514, 'grad_norm': 4.7530999183654785, 'learning_rate': 6.840677966101695e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1964/6000 [1:55:01<3:50:09,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:55:05<3:48:36,  3.40s/it]                                                       {'loss': 0.0452, 'grad_norm': 6.094815254211426, 'learning_rate': 6.838983050847458e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1965/6000 [1:55:05<3:48:36,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:55:09<4:01:37,  3.59s/it]                                                       {'loss': 0.014, 'grad_norm': 3.415151596069336, 'learning_rate': 6.837288135593221e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1966/6000 [1:55:09<4:01:37,  3.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:55:12<3:56:54,  3.52s/it]                                                       {'loss': 0.0428, 'grad_norm': 6.481398105621338, 'learning_rate': 6.835593220338984e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1967/6000 [1:55:12<3:56:54,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:55:16<3:56:25,  3.52s/it]                                                       {'loss': 0.0609, 'grad_norm': 11.005879402160645, 'learning_rate': 6.8338983050847465e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1968/6000 [1:55:16<3:56:25,  3.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:55:19<3:55:09,  3.50s/it]                                                       {'loss': 0.0397, 'grad_norm': 7.349546909332275, 'learning_rate': 6.83220338983051e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1969/6000 [1:55:19<3:55:09,  3.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:55:23<4:01:20,  3.59s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06686660647392273, 'learning_rate': 6.830508474576271e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1970/6000 [1:55:23<4:01:20,  3.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:55:26<3:57:31,  3.54s/it]                                                       {'loss': 0.0084, 'grad_norm': 1.4613971710205078, 'learning_rate': 6.828813559322034e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/6000 [1:55:26<3:57:31,  3.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:55:30<3:53:12,  3.47s/it]                                                       {'loss': 0.0279, 'grad_norm': 6.000926494598389, 'learning_rate': 6.827118644067797e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1972/6000 [1:55:30<3:53:12,  3.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:55:33<3:50:36,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07746084779500961, 'learning_rate': 6.8254237288135595e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1973/6000 [1:55:33<3:50:36,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:55:36<3:51:24,  3.45s/it]                                                       {'loss': 0.0125, 'grad_norm': 1.6506761312484741, 'learning_rate': 6.823728813559323e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1974/6000 [1:55:36<3:51:24,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:55:40<3:53:20,  3.48s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.17308814823627472, 'learning_rate': 6.822033898305085e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1975/6000 [1:55:40<3:53:20,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:55:43<3:49:35,  3.42s/it]                                                       {'loss': 0.0312, 'grad_norm': 7.158234119415283, 'learning_rate': 6.8203389830508485e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1976/6000 [1:55:43<3:49:35,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:55:47<3:50:07,  3.43s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.3109211921691895, 'learning_rate': 6.81864406779661e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1977/6000 [1:55:47<3:50:07,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:55:50<3:49:30,  3.42s/it]                                                       {'loss': 0.0096, 'grad_norm': 3.6454527378082275, 'learning_rate': 6.816949152542373e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1978/6000 [1:55:50<3:49:30,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:55:54<3:50:48,  3.44s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.8001527786254883, 'learning_rate': 6.815254237288136e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1979/6000 [1:55:54<3:50:48,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:55:57<3:50:14,  3.44s/it]                                                       {'loss': 0.0403, 'grad_norm': 4.825239658355713, 'learning_rate': 6.813559322033899e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1980/6000 [1:55:57<3:50:14,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:56:00<3:47:38,  3.40s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.1632691621780396, 'learning_rate': 6.8118644067796614e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1981/6000 [1:56:00<3:47:38,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:56:04<3:47:50,  3.40s/it]                                                       {'loss': 0.1212, 'grad_norm': 17.46985626220703, 'learning_rate': 6.810169491525425e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1982/6000 [1:56:04<3:47:50,  3.40s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:56:07<3:48:42,  3.42s/it]                                                       {'loss': 0.1325, 'grad_norm': 18.2657413482666, 'learning_rate': 6.808474576271187e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1983/6000 [1:56:07<3:48:42,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:56:11<3:52:55,  3.48s/it]                                                       {'loss': 0.0887, 'grad_norm': 11.598228454589844, 'learning_rate': 6.80677966101695e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1984/6000 [1:56:11<3:52:55,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:56:14<3:50:10,  3.44s/it]                                                       {'loss': 0.0233, 'grad_norm': 5.3717474937438965, 'learning_rate': 6.805084745762712e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1985/6000 [1:56:14<3:50:10,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:56:18<3:50:12,  3.44s/it]                                                       {'loss': 0.097, 'grad_norm': 17.34587287902832, 'learning_rate': 6.803389830508475e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1986/6000 [1:56:18<3:50:12,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:56:21<3:49:16,  3.43s/it]                                                       {'loss': 0.0174, 'grad_norm': 4.691455841064453, 'learning_rate': 6.801694915254238e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1987/6000 [1:56:21<3:49:16,  3.43s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:56:24<3:49:47,  3.44s/it]                                                       {'loss': 0.0776, 'grad_norm': 13.432794570922852, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1988/6000 [1:56:24<3:49:47,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:56:28<3:52:26,  3.48s/it]                                                       {'loss': 0.0334, 'grad_norm': 6.0886359214782715, 'learning_rate': 6.798305084745763e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1989/6000 [1:56:28<3:52:26,  3.48s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:56:31<3:50:33,  3.45s/it]                                                       {'loss': 0.141, 'grad_norm': 14.882322311401367, 'learning_rate': 6.796610169491527e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1990/6000 [1:56:31<3:50:33,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:56:35<3:48:48,  3.42s/it]                                                       {'loss': 0.0379, 'grad_norm': 3.755042552947998, 'learning_rate': 6.794915254237289e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1991/6000 [1:56:35<3:48:48,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:56:38<3:46:05,  3.38s/it]                                                       {'loss': 0.0496, 'grad_norm': 6.6681060791015625, 'learning_rate': 6.793220338983051e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1992/6000 [1:56:38<3:46:05,  3.38s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:56:41<3:46:32,  3.39s/it]                                                       {'loss': 0.0159, 'grad_norm': 4.722447872161865, 'learning_rate': 6.791525423728814e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1993/6000 [1:56:41<3:46:32,  3.39s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:56:45<3:45:33,  3.38s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.7403558492660522, 'learning_rate': 6.789830508474576e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1994/6000 [1:56:45<3:45:33,  3.38s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:56:48<3:49:24,  3.44s/it]                                                       {'loss': 0.1904, 'grad_norm': 13.53472900390625, 'learning_rate': 6.78813559322034e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1995/6000 [1:56:48<3:49:24,  3.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:56:52<3:48:30,  3.42s/it]                                                       {'loss': 0.0258, 'grad_norm': 3.247986078262329, 'learning_rate': 6.786440677966102e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1996/6000 [1:56:52<3:48:30,  3.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:56:55<3:50:29,  3.45s/it]                                                       {'loss': 0.0761, 'grad_norm': 12.468118667602539, 'learning_rate': 6.784745762711865e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1997/6000 [1:56:55<3:50:29,  3.45s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:56:59<3:51:09,  3.47s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.6112727522850037, 'learning_rate': 6.783050847457627e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1998/6000 [1:56:59<3:51:09,  3.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:57:03<3:58:58,  3.58s/it]                                                       {'loss': 0.0573, 'grad_norm': 10.38747787475586, 'learning_rate': 6.78135593220339e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1999/6000 [1:57:03<3:58:58,  3.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:57:07<4:05:54,  3.69s/it]                                                       {'loss': 0.0106, 'grad_norm': 2.670499563217163, 'learning_rate': 6.779661016949153e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/6000 [1:57:07<4:05:54,  3.69s/it][2025-11-07 00:48:16,582] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000
[2025-11-07 00:48:16,595] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:48:17,277] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:57:12<4:47:50,  4.32s/it]                                                       {'loss': 0.132, 'grad_norm': 15.392203330993652, 'learning_rate': 6.777966101694916e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2001/6000 [1:57:12<4:47:50,  4.32s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:57:16<4:27:51,  4.02s/it]                                                       {'loss': 0.0987, 'grad_norm': 14.023058891296387, 'learning_rate': 6.776271186440678e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2002/6000 [1:57:16<4:27:51,  4.02s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:57:19<4:17:43,  3.87s/it]                                                       {'loss': 0.0365, 'grad_norm': 6.792910099029541, 'learning_rate': 6.774576271186442e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2003/6000 [1:57:19<4:17:43,  3.87s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:57:23<4:08:46,  3.74s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04854678735136986, 'learning_rate': 6.772881355932204e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2004/6000 [1:57:23<4:08:46,  3.74s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:57:26<4:02:51,  3.65s/it]                                                       {'loss': 0.0083, 'grad_norm': 2.6730446815490723, 'learning_rate': 6.771186440677967e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2005/6000 [1:57:26<4:02:51,  3.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:57:30<4:04:57,  3.68s/it]                                                       {'loss': 0.0587, 'grad_norm': 5.5086517333984375, 'learning_rate': 6.769491525423729e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2006/6000 [1:57:30<4:04:57,  3.68s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:57:33<4:00:46,  3.62s/it]                                                       {'loss': 0.007, 'grad_norm': 2.70182466506958, 'learning_rate': 6.767796610169492e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2007/6000 [1:57:33<4:00:46,  3.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:57:37<3:56:02,  3.55s/it]                                                       {'loss': 0.1077, 'grad_norm': 7.994534492492676, 'learning_rate': 6.766101694915255e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2008/6000 [1:57:37<3:56:02,  3.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:57:40<3:51:59,  3.49s/it]                                                       {'loss': 0.02, 'grad_norm': 6.824184417724609, 'learning_rate': 6.764406779661018e-06, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2009/6000 [1:57:40<3:51:59,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:57:44<4:00:24,  3.62s/it]                                                       {'loss': 0.0963, 'grad_norm': 12.179447174072266, 'learning_rate': 6.76271186440678e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2010/6000 [1:57:44<4:00:24,  3.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:57:47<3:55:04,  3.54s/it]                                                       {'loss': 0.0563, 'grad_norm': 11.325716018676758, 'learning_rate': 6.7610169491525436e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2011/6000 [1:57:47<3:55:04,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:57:51<3:51:51,  3.49s/it]                                                       {'loss': 0.0088, 'grad_norm': 3.0555598735809326, 'learning_rate': 6.759322033898306e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2012/6000 [1:57:51<3:51:51,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:57:54<3:49:25,  3.45s/it]                                                       {'loss': 0.2868, 'grad_norm': 17.40412139892578, 'learning_rate': 6.7576271186440676e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2013/6000 [1:57:54<3:49:25,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:57:57<3:46:51,  3.41s/it]                                                       {'loss': 0.0401, 'grad_norm': 7.545709609985352, 'learning_rate': 6.755932203389831e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2014/6000 [1:57:57<3:46:51,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:58:01<3:45:31,  3.40s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.055946435779333115, 'learning_rate': 6.754237288135593e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2015/6000 [1:58:01<3:45:31,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:58:04<3:48:09,  3.44s/it]                                                       {'loss': 0.0709, 'grad_norm': 9.576005935668945, 'learning_rate': 6.7525423728813565e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2016/6000 [1:58:04<3:48:09,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:58:08<3:52:04,  3.50s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.4907506704330444, 'learning_rate': 6.750847457627119e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2017/6000 [1:58:08<3:52:04,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:58:11<3:50:11,  3.47s/it]                                                       {'loss': 0.0143, 'grad_norm': 10.024049758911133, 'learning_rate': 6.749152542372882e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2018/6000 [1:58:11<3:50:11,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:58:15<3:53:29,  3.52s/it]                                                       {'loss': 0.007, 'grad_norm': 2.1968181133270264, 'learning_rate': 6.747457627118645e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2019/6000 [1:58:15<3:53:29,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:58:19<3:58:53,  3.60s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1587502807378769, 'learning_rate': 6.745762711864408e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2020/6000 [1:58:19<3:58:53,  3.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:58:22<3:53:31,  3.52s/it]                                                       {'loss': 0.1484, 'grad_norm': 15.208953857421875, 'learning_rate': 6.7440677966101695e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2021/6000 [1:58:22<3:53:31,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:58:25<3:50:42,  3.48s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.20479746162891388, 'learning_rate': 6.742372881355933e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2022/6000 [1:58:25<3:50:42,  3.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:58:29<3:52:06,  3.50s/it]                                                       {'loss': 0.0255, 'grad_norm': 4.993452548980713, 'learning_rate': 6.740677966101695e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2023/6000 [1:58:29<3:52:06,  3.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:58:32<3:50:14,  3.47s/it]                                                       {'loss': 0.0033, 'grad_norm': 1.4680023193359375, 'learning_rate': 6.7389830508474585e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2024/6000 [1:58:32<3:50:14,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:58:36<3:48:27,  3.45s/it]                                                       {'loss': 0.0584, 'grad_norm': 9.232500076293945, 'learning_rate': 6.737288135593221e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2025/6000 [1:58:36<3:48:27,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:58:39<3:49:01,  3.46s/it]                                                       {'loss': 0.004, 'grad_norm': 0.7764450907707214, 'learning_rate': 6.735593220338984e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2026/6000 [1:58:39<3:49:01,  3.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:58:43<3:46:37,  3.42s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.4915765523910522, 'learning_rate': 6.733898305084746e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2027/6000 [1:58:43<3:46:37,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:58:46<3:45:16,  3.40s/it]                                                       {'loss': 0.0422, 'grad_norm': 5.541479110717773, 'learning_rate': 6.73220338983051e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2028/6000 [1:58:46<3:45:16,  3.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:58:50<3:48:28,  3.45s/it]                                                       {'loss': 0.104, 'grad_norm': 16.023963928222656, 'learning_rate': 6.7305084745762715e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2029/6000 [1:58:50<3:48:28,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:58:54<4:05:53,  3.72s/it]                                                       {'loss': 0.1832, 'grad_norm': 15.487768173217773, 'learning_rate': 6.728813559322035e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2030/6000 [1:58:54<4:05:53,  3.72s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:58:57<3:59:34,  3.62s/it]                                                       {'loss': 0.106, 'grad_norm': 12.094743728637695, 'learning_rate': 6.727118644067797e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2031/6000 [1:58:57<3:59:34,  3.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:59:01<3:56:12,  3.57s/it]                                                       {'loss': 0.013, 'grad_norm': 3.6615302562713623, 'learning_rate': 6.7254237288135604e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2032/6000 [1:59:01<3:56:12,  3.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:59:04<3:56:04,  3.57s/it]                                                       {'loss': 0.014, 'grad_norm': 3.6665847301483154, 'learning_rate': 6.723728813559323e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2033/6000 [1:59:04<3:56:04,  3.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:59:08<3:53:35,  3.53s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.2353603839874268, 'learning_rate': 6.7220338983050844e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2034/6000 [1:59:08<3:53:35,  3.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:59:12<3:59:41,  3.63s/it]                                                       {'loss': 0.0325, 'grad_norm': 6.196934223175049, 'learning_rate': 6.720338983050848e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2035/6000 [1:59:12<3:59:41,  3.63s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:59:15<3:54:58,  3.56s/it]                                                       {'loss': 0.1745, 'grad_norm': 14.608991622924805, 'learning_rate': 6.71864406779661e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2036/6000 [1:59:15<3:54:58,  3.56s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:59:18<3:50:46,  3.49s/it]                                                       {'loss': 0.0093, 'grad_norm': 3.205852746963501, 'learning_rate': 6.716949152542373e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2037/6000 [1:59:18<3:50:46,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:59:22<3:48:55,  3.47s/it]                                                       {'loss': 0.0095, 'grad_norm': 2.1261837482452393, 'learning_rate': 6.715254237288136e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2038/6000 [1:59:22<3:48:55,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:59:25<3:46:02,  3.42s/it]                                                       {'loss': 0.0353, 'grad_norm': 8.082204818725586, 'learning_rate': 6.713559322033899e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2039/6000 [1:59:25<3:46:02,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:59:29<3:52:03,  3.52s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.6251401901245117, 'learning_rate': 6.7118644067796615e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2040/6000 [1:59:29<3:52:03,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:59:32<3:47:06,  3.44s/it]                                                       {'loss': 0.0192, 'grad_norm': 4.508182525634766, 'learning_rate': 6.710169491525425e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2041/6000 [1:59:32<3:47:06,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:59:35<3:44:42,  3.41s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.2304714024066925, 'learning_rate': 6.708474576271186e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2042/6000 [1:59:35<3:44:42,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [1:59:39<3:44:36,  3.41s/it]                                                       {'loss': 0.0071, 'grad_norm': 2.102741241455078, 'learning_rate': 6.70677966101695e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2043/6000 [1:59:39<3:44:36,  3.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [1:59:42<3:45:30,  3.42s/it]                                                       {'loss': 0.0807, 'grad_norm': 11.700334548950195, 'learning_rate': 6.705084745762712e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2044/6000 [1:59:42<3:45:30,  3.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [1:59:46<3:42:27,  3.37s/it]                                                       {'loss': 0.0381, 'grad_norm': 4.075675964355469, 'learning_rate': 6.703389830508475e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2045/6000 [1:59:46<3:42:27,  3.37s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [1:59:49<3:46:12,  3.43s/it]                                                       {'loss': 0.0089, 'grad_norm': 3.0732877254486084, 'learning_rate': 6.701694915254238e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2046/6000 [1:59:49<3:46:12,  3.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [1:59:53<3:47:03,  3.45s/it]                                                       {'loss': 0.0289, 'grad_norm': 6.993289470672607, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2047/6000 [1:59:53<3:47:03,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [1:59:56<3:50:03,  3.49s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.0938057899475098, 'learning_rate': 6.6983050847457635e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2048/6000 [1:59:56<3:50:03,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:00:00<3:47:28,  3.45s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.7733367085456848, 'learning_rate': 6.696610169491527e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2049/6000 [2:00:00<3:47:28,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:00:03<3:47:05,  3.45s/it]                                                       {'loss': 0.228, 'grad_norm': 18.199827194213867, 'learning_rate': 6.694915254237288e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2050/6000 [2:00:03<3:47:05,  3.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:00:06<3:48:12,  3.47s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.6832380294799805, 'learning_rate': 6.693220338983052e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2051/6000 [2:00:06<3:48:12,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:00:10<3:51:44,  3.52s/it]                                                       {'loss': 0.2207, 'grad_norm': 13.510859489440918, 'learning_rate': 6.691525423728814e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2052/6000 [2:00:10<3:51:44,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:00:14<3:49:23,  3.49s/it]                                                       {'loss': 0.0179, 'grad_norm': 7.433222770690918, 'learning_rate': 6.6898305084745765e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2053/6000 [2:00:14<3:49:23,  3.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:00:17<3:48:20,  3.47s/it]                                                       {'loss': 0.0387, 'grad_norm': 6.483883857727051, 'learning_rate': 6.68813559322034e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2054/6000 [2:00:17<3:48:20,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:00:21<3:54:37,  3.57s/it]                                                       {'loss': 0.1982, 'grad_norm': 10.959939956665039, 'learning_rate': 6.686440677966101e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2055/6000 [2:00:21<3:54:37,  3.57s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:00:24<3:51:38,  3.52s/it]                                                       {'loss': 0.0181, 'grad_norm': 4.777538776397705, 'learning_rate': 6.6847457627118655e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2056/6000 [2:00:24<3:51:38,  3.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:00:28<4:05:44,  3.74s/it]                                                       {'loss': 0.0915, 'grad_norm': 12.007838249206543, 'learning_rate': 6.683050847457627e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2057/6000 [2:00:28<4:05:44,  3.74s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:00:32<3:58:18,  3.63s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.9023245573043823, 'learning_rate': 6.68135593220339e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2058/6000 [2:00:32<3:58:18,  3.63s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:00:35<3:53:27,  3.55s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.7618615627288818, 'learning_rate': 6.679661016949153e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2059/6000 [2:00:35<3:53:27,  3.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:00:39<3:51:35,  3.53s/it]                                                       {'loss': 0.0116, 'grad_norm': 3.7955892086029053, 'learning_rate': 6.677966101694916e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2060/6000 [2:00:39<3:51:35,  3.53s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:00:42<3:50:08,  3.51s/it]                                                       {'loss': 0.0181, 'grad_norm': 6.683154106140137, 'learning_rate': 6.6762711864406784e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2061/6000 [2:00:42<3:50:08,  3.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:00:45<3:47:26,  3.47s/it]                                                       {'loss': 0.1303, 'grad_norm': 9.818514823913574, 'learning_rate': 6.674576271186442e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2062/6000 [2:00:45<3:47:26,  3.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:00:49<3:45:29,  3.44s/it]                                                       {'loss': 0.0955, 'grad_norm': 12.130255699157715, 'learning_rate': 6.672881355932203e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2063/6000 [2:00:49<3:45:29,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:00:52<3:45:43,  3.44s/it]                                                       {'loss': 0.024, 'grad_norm': 3.820781946182251, 'learning_rate': 6.6711864406779666e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2064/6000 [2:00:52<3:45:43,  3.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:00:56<3:52:24,  3.54s/it]                                                       {'loss': 0.0369, 'grad_norm': 3.102844476699829, 'learning_rate': 6.669491525423729e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2065/6000 [2:00:56<3:52:24,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:01:00<4:01:05,  3.68s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06214277446269989, 'learning_rate': 6.667796610169492e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2066/6000 [2:01:00<4:01:05,  3.68s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:01:03<3:56:13,  3.60s/it]                                                       {'loss': 0.1532, 'grad_norm': 14.127416610717773, 'learning_rate': 6.666101694915255e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2067/6000 [2:01:03<3:56:13,  3.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:01:07<3:51:40,  3.54s/it]                                                       {'loss': 0.096, 'grad_norm': 14.605713844299316, 'learning_rate': 6.664406779661018e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2068/6000 [2:01:07<3:51:40,  3.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:01:11<4:06:32,  3.76s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.6213564872741699, 'learning_rate': 6.66271186440678e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2069/6000 [2:01:11<4:06:32,  3.76s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:01:15<4:00:11,  3.67s/it]                                                       {'loss': 0.298, 'grad_norm': 15.682729721069336, 'learning_rate': 6.661016949152544e-06, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 2070/6000 [2:01:15<4:00:11,  3.67s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:01:18<3:55:01,  3.59s/it]                                                       {'loss': 0.1145, 'grad_norm': 12.616747856140137, 'learning_rate': 6.659322033898305e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2071/6000 [2:01:18<3:55:01,  3.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:01:21<3:52:30,  3.55s/it]                                                       {'loss': 0.0851, 'grad_norm': 9.63448429107666, 'learning_rate': 6.6576271186440685e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2072/6000 [2:01:21<3:52:30,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:01:25<3:48:13,  3.49s/it]                                                       {'loss': 0.0515, 'grad_norm': 8.460287094116211, 'learning_rate': 6.655932203389831e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2073/6000 [2:01:25<3:48:13,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:01:29<3:52:24,  3.55s/it]                                                       {'loss': 0.0199, 'grad_norm': 4.319310665130615, 'learning_rate': 6.654237288135593e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2074/6000 [2:01:29<3:52:24,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:01:33<4:01:20,  3.69s/it]                                                       {'loss': 0.1137, 'grad_norm': 9.959586143493652, 'learning_rate': 6.652542372881357e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2075/6000 [2:01:33<4:01:20,  3.69s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:01:36<3:56:01,  3.61s/it]                                                       {'loss': 0.1206, 'grad_norm': 10.997405052185059, 'learning_rate': 6.650847457627119e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2076/6000 [2:01:36<3:56:01,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:01:39<3:53:00,  3.56s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.32599887251853943, 'learning_rate': 6.649152542372882e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2077/6000 [2:01:39<3:53:00,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:01:43<3:50:05,  3.52s/it]                                                       {'loss': 0.158, 'grad_norm': 10.84811019897461, 'learning_rate': 6.647457627118644e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2078/6000 [2:01:43<3:50:05,  3.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:01:46<3:46:50,  3.47s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.2012842893600464, 'learning_rate': 6.645762711864407e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2079/6000 [2:01:46<3:46:50,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:01:50<3:46:25,  3.47s/it]                                                       {'loss': 0.071, 'grad_norm': 16.688276290893555, 'learning_rate': 6.64406779661017e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2080/6000 [2:01:50<3:46:25,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:01:53<3:44:55,  3.44s/it]                                                       {'loss': 0.1726, 'grad_norm': 17.34153175354004, 'learning_rate': 6.642372881355933e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2081/6000 [2:01:53<3:44:55,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:01:57<3:45:47,  3.46s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.379922866821289, 'learning_rate': 6.640677966101695e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2082/6000 [2:01:57<3:45:47,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:02:00<3:42:34,  3.41s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.738061785697937, 'learning_rate': 6.638983050847459e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2083/6000 [2:02:00<3:42:34,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:02:03<3:41:15,  3.39s/it]                                                       {'loss': 0.0717, 'grad_norm': 13.140177726745605, 'learning_rate': 6.637288135593221e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2084/6000 [2:02:03<3:41:15,  3.39s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:02:07<3:43:57,  3.43s/it]                                                       {'loss': 0.0141, 'grad_norm': 3.3937203884124756, 'learning_rate': 6.635593220338984e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2085/6000 [2:02:07<3:43:57,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:02:10<3:50:01,  3.53s/it]                                                       {'loss': 0.0255, 'grad_norm': 7.996455669403076, 'learning_rate': 6.633898305084746e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2086/6000 [2:02:10<3:50:01,  3.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:02:14<3:55:28,  3.61s/it]                                                       {'loss': 0.0033, 'grad_norm': 1.2156966924667358, 'learning_rate': 6.632203389830509e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2087/6000 [2:02:14<3:55:28,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:02:18<3:50:25,  3.53s/it]                                                       {'loss': 0.1153, 'grad_norm': 12.226404190063477, 'learning_rate': 6.6305084745762716e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2088/6000 [2:02:18<3:50:25,  3.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:02:21<3:45:36,  3.46s/it]                                                       {'loss': 0.0933, 'grad_norm': 11.246484756469727, 'learning_rate': 6.628813559322035e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2089/6000 [2:02:21<3:45:36,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:02:24<3:43:12,  3.43s/it]                                                       {'loss': 0.091, 'grad_norm': 13.464537620544434, 'learning_rate': 6.627118644067797e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2090/6000 [2:02:24<3:43:12,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:02:28<3:42:16,  3.41s/it]                                                       {'loss': 0.0176, 'grad_norm': 3.30962872505188, 'learning_rate': 6.6254237288135605e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2091/6000 [2:02:28<3:42:16,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:02:31<3:41:36,  3.40s/it]                                                       {'loss': 0.0872, 'grad_norm': 11.072758674621582, 'learning_rate': 6.623728813559322e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2092/6000 [2:02:31<3:41:36,  3.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:02:34<3:42:16,  3.41s/it]                                                       {'loss': 0.0577, 'grad_norm': 9.519325256347656, 'learning_rate': 6.622033898305085e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2093/6000 [2:02:34<3:42:16,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:02:38<3:42:12,  3.41s/it]                                                       {'loss': 0.0086, 'grad_norm': 2.4992315769195557, 'learning_rate': 6.620338983050848e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2094/6000 [2:02:38<3:42:12,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:02:42<3:51:17,  3.55s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.9301378726959229, 'learning_rate': 6.61864406779661e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2095/6000 [2:02:42<3:51:17,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:02:45<3:47:47,  3.50s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.6772687435150146, 'learning_rate': 6.6169491525423735e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2096/6000 [2:02:45<3:47:47,  3.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:02:49<3:54:37,  3.61s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9887515902519226, 'learning_rate': 6.615254237288136e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2097/6000 [2:02:49<3:54:37,  3.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:02:53<3:56:31,  3.64s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.061610154807567596, 'learning_rate': 6.613559322033899e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2098/6000 [2:02:53<3:56:31,  3.64s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:02:56<3:58:00,  3.66s/it]                                                       {'loss': 0.0927, 'grad_norm': 13.841170310974121, 'learning_rate': 6.611864406779661e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 2099/6000 [2:02:56<3:58:00,  3.66s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:03:00<3:53:43,  3.60s/it]                                                       {'loss': 0.1355, 'grad_norm': 15.017125129699707, 'learning_rate': 6.610169491525424e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2100/6000 [2:03:00<3:53:43,  3.60s/it][2025-11-07 00:54:09,809] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100
[2025-11-07 00:54:09,822] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:54:10,587] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:03:06<4:35:50,  4.24s/it]                                                       {'loss': 0.0082, 'grad_norm': 2.694709300994873, 'learning_rate': 6.6084745762711865e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2101/6000 [2:03:06<4:35:50,  4.24s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:03:09<4:17:54,  3.97s/it]                                                       {'loss': 0.0224, 'grad_norm': 3.1289777755737305, 'learning_rate': 6.60677966101695e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2102/6000 [2:03:09<4:17:54,  3.97s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:03:12<4:05:01,  3.77s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.841630458831787, 'learning_rate': 6.605084745762712e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2103/6000 [2:03:12<4:05:01,  3.77s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:03:16<3:57:33,  3.66s/it]                                                       {'loss': 0.0602, 'grad_norm': 7.808176040649414, 'learning_rate': 6.6033898305084755e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2104/6000 [2:03:16<3:57:33,  3.66s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:03:19<3:53:57,  3.60s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.6967666745185852, 'learning_rate': 6.601694915254238e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2105/6000 [2:03:19<3:53:57,  3.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:03:22<3:47:32,  3.51s/it]                                                       {'loss': 0.1473, 'grad_norm': 18.90471076965332, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2106/6000 [2:03:22<3:47:32,  3.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:03:26<3:45:35,  3.48s/it]                                                       {'loss': 0.0175, 'grad_norm': 2.459409236907959, 'learning_rate': 6.598305084745763e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2107/6000 [2:03:26<3:45:35,  3.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:03:29<3:43:53,  3.45s/it]                                                       {'loss': 0.1694, 'grad_norm': 12.911029815673828, 'learning_rate': 6.596610169491526e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2108/6000 [2:03:29<3:43:53,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:03:33<3:44:37,  3.46s/it]                                                       {'loss': 0.2738, 'grad_norm': 14.228318214416504, 'learning_rate': 6.5949152542372885e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2109/6000 [2:03:33<3:44:37,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:03:37<3:54:29,  3.62s/it]                                                       {'loss': 0.0545, 'grad_norm': 11.528616905212402, 'learning_rate': 6.593220338983052e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2110/6000 [2:03:37<3:54:29,  3.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:03:40<3:50:26,  3.56s/it]                                                       {'loss': 0.0442, 'grad_norm': 8.394107818603516, 'learning_rate': 6.591525423728814e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2111/6000 [2:03:40<3:50:26,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:03:44<3:54:33,  3.62s/it]                                                       {'loss': 0.2777, 'grad_norm': 19.304780960083008, 'learning_rate': 6.5898305084745774e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2112/6000 [2:03:44<3:54:33,  3.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:03:47<3:50:51,  3.56s/it]                                                       {'loss': 0.0418, 'grad_norm': 5.505037307739258, 'learning_rate': 6.58813559322034e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2113/6000 [2:03:47<3:50:51,  3.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:03:51<3:46:00,  3.49s/it]                                                       {'loss': 0.0314, 'grad_norm': 5.6646013259887695, 'learning_rate': 6.586440677966103e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2114/6000 [2:03:51<3:46:00,  3.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:03:54<3:43:55,  3.46s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.5486633777618408, 'learning_rate': 6.584745762711865e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2115/6000 [2:03:54<3:43:55,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:03:57<3:44:23,  3.47s/it]                                                       {'loss': 0.0347, 'grad_norm': 8.328989028930664, 'learning_rate': 6.583050847457627e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2116/6000 [2:03:57<3:44:23,  3.47s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:04:01<3:44:02,  3.46s/it]                                                       {'loss': 0.3476, 'grad_norm': 16.034631729125977, 'learning_rate': 6.58135593220339e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2117/6000 [2:04:01<3:44:02,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:04:04<3:42:14,  3.44s/it]                                                       {'loss': 0.0582, 'grad_norm': 9.156394958496094, 'learning_rate': 6.579661016949153e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2118/6000 [2:04:04<3:42:14,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:04:08<3:43:35,  3.46s/it]                                                       {'loss': 0.0434, 'grad_norm': 8.072223663330078, 'learning_rate': 6.577966101694916e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2119/6000 [2:04:08<3:43:35,  3.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:04:11<3:42:01,  3.43s/it]                                                       {'loss': 0.0564, 'grad_norm': 11.238574981689453, 'learning_rate': 6.576271186440678e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2120/6000 [2:04:11<3:42:01,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:04:14<3:40:26,  3.41s/it]                                                       {'loss': 0.1201, 'grad_norm': 13.618976593017578, 'learning_rate': 6.574576271186441e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2121/6000 [2:04:15<3:40:26,  3.41s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:04:19<3:51:54,  3.59s/it]                                                       {'loss': 0.0153, 'grad_norm': 4.60725212097168, 'learning_rate': 6.572881355932203e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2122/6000 [2:04:19<3:51:54,  3.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:04:22<3:49:12,  3.55s/it]                                                       {'loss': 0.0723, 'grad_norm': 11.2877197265625, 'learning_rate': 6.571186440677967e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2123/6000 [2:04:22<3:49:12,  3.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:04:25<3:46:18,  3.50s/it]                                                       {'loss': 0.1339, 'grad_norm': 10.57022476196289, 'learning_rate': 6.569491525423729e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2124/6000 [2:04:25<3:46:18,  3.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:04:29<3:42:13,  3.44s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5849639177322388, 'learning_rate': 6.567796610169492e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2125/6000 [2:04:29<3:42:13,  3.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:04:32<3:41:13,  3.43s/it]                                                       {'loss': 0.0182, 'grad_norm': 4.340287685394287, 'learning_rate': 6.566101694915255e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2126/6000 [2:04:32<3:41:13,  3.43s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:04:36<3:42:50,  3.45s/it]                                                       {'loss': 0.0385, 'grad_norm': 4.158286094665527, 'learning_rate': 6.564406779661018e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2127/6000 [2:04:36<3:42:50,  3.45s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:04:39<3:40:41,  3.42s/it]                                                       {'loss': 0.2429, 'grad_norm': 13.570040702819824, 'learning_rate': 6.56271186440678e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2128/6000 [2:04:39<3:40:41,  3.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:04:42<3:40:29,  3.42s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5802842378616333, 'learning_rate': 6.561016949152543e-06, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2129/6000 [2:04:42<3:40:29,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:04:46<3:39:06,  3.40s/it]                                                       {'loss': 0.0405, 'grad_norm': 7.387199401855469, 'learning_rate': 6.559322033898305e-06, 'epoch': 0.35}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2130/6000 [2:04:46<3:39:06,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:04:49<3:39:16,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015595853328704834, 'learning_rate': 6.557627118644069e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2131/6000 [2:04:49<3:39:16,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:04:52<3:39:12,  3.40s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.4221090078353882, 'learning_rate': 6.555932203389831e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2132/6000 [2:04:52<3:39:12,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:04:56<3:48:53,  3.55s/it]                                                       {'loss': 0.173, 'grad_norm': 21.550703048706055, 'learning_rate': 6.554237288135594e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2133/6000 [2:04:56<3:48:53,  3.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:05:00<3:44:18,  3.48s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.6506131887435913, 'learning_rate': 6.552542372881357e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2134/6000 [2:05:00<3:44:18,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:05:03<3:41:24,  3.44s/it]                                                       {'loss': 0.012, 'grad_norm': 2.2785539627075195, 'learning_rate': 6.55084745762712e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2135/6000 [2:05:03<3:41:24,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:05:07<3:44:21,  3.48s/it]                                                       {'loss': 0.0181, 'grad_norm': 5.067666053771973, 'learning_rate': 6.549152542372882e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2136/6000 [2:05:07<3:44:21,  3.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:05:10<3:43:37,  3.47s/it]                                                       {'loss': 0.0062, 'grad_norm': 2.6419355869293213, 'learning_rate': 6.547457627118644e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2137/6000 [2:05:10<3:43:37,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:05:13<3:41:06,  3.44s/it]                                                       {'loss': 0.0168, 'grad_norm': 4.233220100402832, 'learning_rate': 6.545762711864407e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2138/6000 [2:05:13<3:41:06,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:05:17<3:39:21,  3.41s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.5345947742462158, 'learning_rate': 6.54406779661017e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2139/6000 [2:05:17<3:39:21,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:05:20<3:38:50,  3.40s/it]                                                       {'loss': 0.3423, 'grad_norm': 17.08225440979004, 'learning_rate': 6.542372881355933e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/6000 [2:05:20<3:38:50,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:05:24<3:39:29,  3.41s/it]                                                       {'loss': 0.0037, 'grad_norm': 1.361720085144043, 'learning_rate': 6.5406779661016954e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2141/6000 [2:05:24<3:39:29,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:05:27<3:41:05,  3.44s/it]                                                       {'loss': 0.008, 'grad_norm': 1.289701223373413, 'learning_rate': 6.538983050847459e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2142/6000 [2:05:27<3:41:05,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:05:31<3:47:30,  3.54s/it]                                                       {'loss': 0.011, 'grad_norm': 2.774383783340454, 'learning_rate': 6.53728813559322e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2143/6000 [2:05:31<3:47:30,  3.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:05:34<3:46:09,  3.52s/it]                                                       {'loss': 0.0806, 'grad_norm': 11.182320594787598, 'learning_rate': 6.5355932203389836e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2144/6000 [2:05:34<3:46:09,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:05:38<3:44:08,  3.49s/it]                                                       {'loss': 0.1316, 'grad_norm': 12.997923851013184, 'learning_rate': 6.533898305084746e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2145/6000 [2:05:38<3:44:08,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:05:41<3:41:50,  3.45s/it]                                                       {'loss': 0.0441, 'grad_norm': 13.878664016723633, 'learning_rate': 6.532203389830509e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2146/6000 [2:05:41<3:41:50,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:05:44<3:39:46,  3.42s/it]                                                       {'loss': 0.0331, 'grad_norm': 5.952885150909424, 'learning_rate': 6.530508474576272e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2147/6000 [2:05:44<3:39:46,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:05:48<3:40:30,  3.43s/it]                                                       {'loss': 0.3786, 'grad_norm': 19.04261589050293, 'learning_rate': 6.528813559322035e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2148/6000 [2:05:48<3:40:30,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:05:51<3:39:35,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.050454139709472656, 'learning_rate': 6.5271186440677965e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2149/6000 [2:05:51<3:39:35,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:05:55<3:38:10,  3.40s/it]                                                       {'loss': 0.2001, 'grad_norm': 14.752723693847656, 'learning_rate': 6.52542372881356e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2150/6000 [2:05:55<3:38:10,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:05:59<3:49:38,  3.58s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.5249065160751343, 'learning_rate': 6.523728813559322e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2151/6000 [2:05:59<3:49:38,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:06:02<3:47:25,  3.55s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.4445580840110779, 'learning_rate': 6.5220338983050855e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2152/6000 [2:06:02<3:47:25,  3.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:06:06<3:44:43,  3.51s/it]                                                       {'loss': 0.0146, 'grad_norm': 4.120419025421143, 'learning_rate': 6.520338983050848e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2153/6000 [2:06:06<3:44:43,  3.51s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:06:09<3:45:28,  3.52s/it]                                                       {'loss': 0.0048, 'grad_norm': 0.9504414796829224, 'learning_rate': 6.518644067796611e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2154/6000 [2:06:09<3:45:28,  3.52s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:06:13<3:44:13,  3.50s/it]                                                       {'loss': 0.0107, 'grad_norm': 2.3148691654205322, 'learning_rate': 6.516949152542374e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2155/6000 [2:06:13<3:44:13,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:06:16<3:42:16,  3.47s/it]                                                       {'loss': 0.1061, 'grad_norm': 13.171520233154297, 'learning_rate': 6.515254237288137e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2156/6000 [2:06:16<3:42:16,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:06:19<3:41:34,  3.46s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.2449601888656616, 'learning_rate': 6.5135593220338985e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2157/6000 [2:06:19<3:41:34,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:06:23<3:40:14,  3.44s/it]                                                       {'loss': 0.0441, 'grad_norm': 7.878970146179199, 'learning_rate': 6.511864406779661e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2158/6000 [2:06:23<3:40:14,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:06:26<3:41:33,  3.46s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3639748990535736, 'learning_rate': 6.510169491525424e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2159/6000 [2:06:26<3:41:33,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:06:30<3:40:02,  3.44s/it]                                                       {'loss': 0.0113, 'grad_norm': 2.088163137435913, 'learning_rate': 6.508474576271187e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2160/6000 [2:06:30<3:40:02,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:06:33<3:38:35,  3.42s/it]                                                       {'loss': 0.0831, 'grad_norm': 12.865694046020508, 'learning_rate': 6.50677966101695e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2161/6000 [2:06:33<3:38:35,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:06:36<3:36:08,  3.38s/it]                                                       {'loss': 0.1323, 'grad_norm': 14.615819931030273, 'learning_rate': 6.505084745762712e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2162/6000 [2:06:36<3:36:08,  3.38s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:06:40<3:45:33,  3.53s/it]                                                       {'loss': 0.0805, 'grad_norm': 12.99057388305664, 'learning_rate': 6.503389830508476e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2163/6000 [2:06:40<3:45:33,  3.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:06:43<3:40:38,  3.45s/it]                                                       {'loss': 0.0765, 'grad_norm': 8.521754264831543, 'learning_rate': 6.501694915254237e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2164/6000 [2:06:43<3:40:38,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:06:47<3:40:21,  3.45s/it]                                                       {'loss': 0.053, 'grad_norm': 8.515630722045898, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2165/6000 [2:06:47<3:40:21,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:06:50<3:38:49,  3.42s/it]                                                       {'loss': 0.1452, 'grad_norm': 20.490400314331055, 'learning_rate': 6.498305084745763e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2166/6000 [2:06:50<3:38:49,  3.42s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:06:54<3:39:07,  3.43s/it]                                                       {'loss': 0.0403, 'grad_norm': 11.971770286560059, 'learning_rate': 6.496610169491526e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2167/6000 [2:06:54<3:39:07,  3.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:06:57<3:39:24,  3.44s/it]                                                       {'loss': 0.0127, 'grad_norm': 2.3574304580688477, 'learning_rate': 6.4949152542372886e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2168/6000 [2:06:57<3:39:24,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:07:01<3:37:22,  3.40s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.7100093364715576, 'learning_rate': 6.493220338983052e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2169/6000 [2:07:01<3:37:22,  3.40s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:07:04<3:41:25,  3.47s/it]                                                       {'loss': 0.0432, 'grad_norm': 7.436863422393799, 'learning_rate': 6.491525423728814e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2170/6000 [2:07:04<3:41:25,  3.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:07:08<3:39:58,  3.45s/it]                                                       {'loss': 0.0646, 'grad_norm': 6.640970230102539, 'learning_rate': 6.4898305084745775e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2171/6000 [2:07:08<3:39:58,  3.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:07:11<3:43:31,  3.50s/it]                                                       {'loss': 0.0226, 'grad_norm': 3.815990686416626, 'learning_rate': 6.488135593220339e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2172/6000 [2:07:11<3:43:31,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:07:15<3:40:32,  3.46s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.6772189140319824, 'learning_rate': 6.486440677966102e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2173/6000 [2:07:15<3:40:32,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:07:18<3:42:49,  3.49s/it]                                                       {'loss': 0.0301, 'grad_norm': 5.8278093338012695, 'learning_rate': 6.484745762711865e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2174/6000 [2:07:18<3:42:49,  3.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:07:22<3:46:46,  3.56s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.13796262443065643, 'learning_rate': 6.483050847457628e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2175/6000 [2:07:22<3:46:46,  3.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:07:25<3:43:29,  3.51s/it]                                                       {'loss': 0.0759, 'grad_norm': 13.416988372802734, 'learning_rate': 6.4813559322033905e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2176/6000 [2:07:25<3:43:29,  3.51s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:07:29<3:40:37,  3.46s/it]                                                       {'loss': 0.0962, 'grad_norm': 14.061006546020508, 'learning_rate': 6.479661016949154e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2177/6000 [2:07:29<3:40:37,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:07:32<3:43:05,  3.50s/it]                                                       {'loss': 0.0295, 'grad_norm': 7.767535209655762, 'learning_rate': 6.477966101694915e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2178/6000 [2:07:32<3:43:05,  3.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:07:35<3:40:15,  3.46s/it]                                                       {'loss': 0.1103, 'grad_norm': 11.891748428344727, 'learning_rate': 6.476271186440678e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2179/6000 [2:07:36<3:40:15,  3.46s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:07:39<3:36:53,  3.41s/it]                                                       {'loss': 0.0375, 'grad_norm': 5.421514511108398, 'learning_rate': 6.474576271186441e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2180/6000 [2:07:39<3:36:53,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:07:42<3:37:00,  3.41s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.1647870540618896, 'learning_rate': 6.4728813559322035e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2181/6000 [2:07:42<3:37:00,  3.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:07:46<3:38:45,  3.44s/it]                                                       {'loss': 0.0159, 'grad_norm': 3.906841278076172, 'learning_rate': 6.471186440677967e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2182/6000 [2:07:46<3:38:45,  3.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:07:50<3:50:11,  3.62s/it]                                                       {'loss': 0.008, 'grad_norm': 1.8749792575836182, 'learning_rate': 6.469491525423729e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2183/6000 [2:07:50<3:50:11,  3.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:07:53<3:46:21,  3.56s/it]                                                       {'loss': 0.0654, 'grad_norm': 8.203970909118652, 'learning_rate': 6.4677966101694925e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2184/6000 [2:07:53<3:46:21,  3.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:07:57<3:43:27,  3.51s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3648430407047272, 'learning_rate': 6.466101694915254e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/6000 [2:07:57<3:43:27,  3.51s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:08:00<3:47:25,  3.58s/it]                                                       {'loss': 0.0488, 'grad_norm': 9.822283744812012, 'learning_rate': 6.464406779661017e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2186/6000 [2:08:00<3:47:25,  3.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:08:04<3:52:16,  3.65s/it]                                                       {'loss': 0.046, 'grad_norm': 12.411360740661621, 'learning_rate': 6.46271186440678e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2187/6000 [2:08:04<3:52:16,  3.65s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:08:08<3:49:08,  3.61s/it]                                                       {'loss': 0.145, 'grad_norm': 13.571308135986328, 'learning_rate': 6.461016949152543e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2188/6000 [2:08:08<3:49:08,  3.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:08:11<3:46:24,  3.56s/it]                                                       {'loss': 0.1178, 'grad_norm': 14.126029014587402, 'learning_rate': 6.4593220338983055e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2189/6000 [2:08:11<3:46:24,  3.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:08:15<3:43:23,  3.52s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.6863350868225098, 'learning_rate': 6.457627118644069e-06, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 2190/6000 [2:08:15<3:43:23,  3.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:08:18<3:40:21,  3.47s/it]                                                       {'loss': 0.1894, 'grad_norm': 13.339920997619629, 'learning_rate': 6.455932203389831e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2191/6000 [2:08:18<3:40:21,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:08:21<3:39:35,  3.46s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.09196168929338455, 'learning_rate': 6.4542372881355944e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2192/6000 [2:08:21<3:39:35,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:08:25<3:35:37,  3.40s/it]                                                       {'loss': 0.0239, 'grad_norm': 6.142341613769531, 'learning_rate': 6.452542372881356e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2193/6000 [2:08:25<3:35:37,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:08:28<3:39:16,  3.46s/it]                                                       {'loss': 0.0036, 'grad_norm': 1.3035603761672974, 'learning_rate': 6.450847457627119e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2194/6000 [2:08:28<3:39:16,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:08:32<3:38:07,  3.44s/it]                                                       {'loss': 0.051, 'grad_norm': 8.648355484008789, 'learning_rate': 6.449152542372882e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2195/6000 [2:08:32<3:38:07,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:08:35<3:39:31,  3.46s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.2323858737945557, 'learning_rate': 6.447457627118645e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2196/6000 [2:08:35<3:39:31,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:08:38<3:36:31,  3.42s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.8498409986495972, 'learning_rate': 6.445762711864407e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2197/6000 [2:08:38<3:36:31,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:08:42<3:35:27,  3.40s/it]                                                       {'loss': 0.0381, 'grad_norm': 6.851173400878906, 'learning_rate': 6.444067796610171e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2198/6000 [2:08:42<3:35:27,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:08:45<3:36:36,  3.42s/it]                                                       {'loss': 0.277, 'grad_norm': 21.027463912963867, 'learning_rate': 6.442372881355933e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2199/6000 [2:08:45<3:36:36,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:08:49<3:43:41,  3.53s/it]                                                       {'loss': 0.002, 'grad_norm': 0.5625913739204407, 'learning_rate': 6.440677966101695e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2200/6000 [2:08:49<3:43:41,  3.53s/it][2025-11-07 00:59:58,984] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200
[2025-11-07 00:59:58,997] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 00:59:59,666] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:08:55<4:25:46,  4.20s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.6678516864776611, 'learning_rate': 6.438983050847458e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2201/6000 [2:08:55<4:25:46,  4.20s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:08:58<4:10:30,  3.96s/it]                                                       {'loss': 0.0686, 'grad_norm': 4.381426811218262, 'learning_rate': 6.43728813559322e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2202/6000 [2:08:58<4:10:30,  3.96s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:09:02<4:01:58,  3.82s/it]                                                       {'loss': 0.0094, 'grad_norm': 2.034459352493286, 'learning_rate': 6.435593220338984e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2203/6000 [2:09:02<4:01:58,  3.82s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:09:05<3:54:25,  3.71s/it]                                                       {'loss': 0.0613, 'grad_norm': 10.935104370117188, 'learning_rate': 6.433898305084746e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2204/6000 [2:09:05<3:54:25,  3.71s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:09:08<3:48:06,  3.61s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.29144713282585144, 'learning_rate': 6.432203389830509e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2205/6000 [2:09:08<3:48:06,  3.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:09:13<4:02:29,  3.83s/it]                                                       {'loss': 0.0801, 'grad_norm': 8.389345169067383, 'learning_rate': 6.430508474576271e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2206/6000 [2:09:13<4:02:29,  3.83s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:09:16<3:54:31,  3.71s/it]                                                       {'loss': 0.0345, 'grad_norm': 7.823575973510742, 'learning_rate': 6.428813559322035e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2207/6000 [2:09:16<3:54:31,  3.71s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:09:20<3:51:01,  3.66s/it]                                                       {'loss': 0.4744, 'grad_norm': 20.441862106323242, 'learning_rate': 6.427118644067797e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2208/6000 [2:09:20<3:51:01,  3.66s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:09:23<3:47:17,  3.60s/it]                                                       {'loss': 0.025, 'grad_norm': 6.094795227050781, 'learning_rate': 6.42542372881356e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2209/6000 [2:09:23<3:47:17,  3.60s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:09:27<3:44:52,  3.56s/it]                                                       {'loss': 0.0235, 'grad_norm': 4.114222526550293, 'learning_rate': 6.423728813559322e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2210/6000 [2:09:27<3:44:52,  3.56s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:09:30<3:43:33,  3.54s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.5298190116882324, 'learning_rate': 6.422033898305086e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2211/6000 [2:09:30<3:43:33,  3.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:09:34<3:46:26,  3.59s/it]                                                       {'loss': 0.0155, 'grad_norm': 3.2003183364868164, 'learning_rate': 6.420338983050848e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2212/6000 [2:09:34<3:46:26,  3.59s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:09:37<3:43:08,  3.54s/it]                                                       {'loss': 0.1339, 'grad_norm': 16.14044952392578, 'learning_rate': 6.418644067796611e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2213/6000 [2:09:37<3:43:08,  3.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:09:41<3:39:40,  3.48s/it]                                                       {'loss': 0.0958, 'grad_norm': 13.564764976501465, 'learning_rate': 6.416949152542373e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2214/6000 [2:09:41<3:39:40,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:09:44<3:38:01,  3.46s/it]                                                       {'loss': 0.0515, 'grad_norm': 11.707746505737305, 'learning_rate': 6.415254237288136e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2215/6000 [2:09:44<3:38:01,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:09:48<3:41:30,  3.51s/it]                                                       {'loss': 0.1252, 'grad_norm': 13.556673049926758, 'learning_rate': 6.413559322033899e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2216/6000 [2:09:48<3:41:30,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:09:51<3:41:20,  3.51s/it]                                                       {'loss': 0.2653, 'grad_norm': 15.976883888244629, 'learning_rate': 6.411864406779662e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2217/6000 [2:09:51<3:41:20,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:09:55<3:40:09,  3.49s/it]                                                       {'loss': 0.1763, 'grad_norm': 19.129791259765625, 'learning_rate': 6.410169491525424e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2218/6000 [2:09:55<3:40:09,  3.49s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:09:58<3:39:25,  3.48s/it]                                                       {'loss': 0.025, 'grad_norm': 4.512526035308838, 'learning_rate': 6.408474576271188e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2219/6000 [2:09:58<3:39:25,  3.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:10:02<3:37:43,  3.46s/it]                                                       {'loss': 0.0167, 'grad_norm': 3.818546772003174, 'learning_rate': 6.40677966101695e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2220/6000 [2:10:02<3:37:43,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:10:05<3:38:44,  3.47s/it]                                                       {'loss': 0.005, 'grad_norm': 1.4318416118621826, 'learning_rate': 6.405084745762712e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2221/6000 [2:10:05<3:38:44,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:10:09<3:40:35,  3.50s/it]                                                       {'loss': 0.0262, 'grad_norm': 6.880951881408691, 'learning_rate': 6.403389830508475e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2222/6000 [2:10:09<3:40:35,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:10:12<3:42:40,  3.54s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4213904142379761, 'learning_rate': 6.401694915254237e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2223/6000 [2:10:12<3:42:40,  3.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:10:16<3:38:06,  3.47s/it]                                                       {'loss': 0.02, 'grad_norm': 4.5570502281188965, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2224/6000 [2:10:16<3:38:06,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:10:19<3:34:46,  3.41s/it]                                                       {'loss': 0.008, 'grad_norm': 1.5409835577011108, 'learning_rate': 6.398305084745763e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2225/6000 [2:10:19<3:34:46,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:10:22<3:32:25,  3.38s/it]                                                       {'loss': 0.2448, 'grad_norm': 19.181381225585938, 'learning_rate': 6.396610169491526e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2226/6000 [2:10:22<3:32:25,  3.38s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:10:26<3:33:08,  3.39s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.7740758657455444, 'learning_rate': 6.394915254237289e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2227/6000 [2:10:26<3:33:08,  3.39s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:10:29<3:36:14,  3.44s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.1819775104522705, 'learning_rate': 6.393220338983052e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2228/6000 [2:10:29<3:36:14,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:10:32<3:34:03,  3.41s/it]                                                       {'loss': 0.0172, 'grad_norm': 4.699915409088135, 'learning_rate': 6.3915254237288135e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2229/6000 [2:10:32<3:34:03,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:10:36<3:40:34,  3.51s/it]                                                       {'loss': 0.0862, 'grad_norm': 10.882471084594727, 'learning_rate': 6.389830508474577e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2230/6000 [2:10:36<3:40:34,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:10:40<3:39:59,  3.50s/it]                                                       {'loss': 0.0244, 'grad_norm': 3.888967990875244, 'learning_rate': 6.388135593220339e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2231/6000 [2:10:40<3:39:59,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:10:43<3:40:24,  3.51s/it]                                                       {'loss': 0.1922, 'grad_norm': 18.52896499633789, 'learning_rate': 6.3864406779661025e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2232/6000 [2:10:43<3:40:24,  3.51s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:10:46<3:36:33,  3.45s/it]                                                       {'loss': 0.0844, 'grad_norm': 13.030708312988281, 'learning_rate': 6.384745762711865e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/6000 [2:10:46<3:36:33,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:10:50<3:45:27,  3.59s/it]                                                       {'loss': 0.0215, 'grad_norm': 3.266200542449951, 'learning_rate': 6.383050847457628e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2234/6000 [2:10:50<3:45:27,  3.59s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:10:54<3:39:38,  3.50s/it]                                                       {'loss': 0.2077, 'grad_norm': 15.507597923278809, 'learning_rate': 6.381355932203391e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2235/6000 [2:10:54<3:39:38,  3.50s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:10:57<3:36:30,  3.45s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.3617866635322571, 'learning_rate': 6.379661016949154e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2236/6000 [2:10:57<3:36:30,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:11:01<3:37:25,  3.47s/it]                                                       {'loss': 0.1781, 'grad_norm': 12.620551109313965, 'learning_rate': 6.3779661016949155e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2237/6000 [2:11:01<3:37:25,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:11:04<3:35:40,  3.44s/it]                                                       {'loss': 0.0152, 'grad_norm': 4.1442341804504395, 'learning_rate': 6.376271186440679e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2238/6000 [2:11:04<3:35:40,  3.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:11:07<3:33:47,  3.41s/it]                                                       {'loss': 0.1574, 'grad_norm': 14.612726211547852, 'learning_rate': 6.374576271186441e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2239/6000 [2:11:07<3:33:47,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:11:11<3:33:23,  3.41s/it]                                                       {'loss': 0.0928, 'grad_norm': 11.955734252929688, 'learning_rate': 6.372881355932204e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2240/6000 [2:11:11<3:33:23,  3.41s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:11:14<3:33:18,  3.40s/it]                                                       {'loss': 0.0421, 'grad_norm': 9.443924903869629, 'learning_rate': 6.371186440677967e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2241/6000 [2:11:14<3:33:18,  3.40s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:11:18<3:40:53,  3.53s/it]                                                       {'loss': 0.0146, 'grad_norm': 5.32452917098999, 'learning_rate': 6.3694915254237285e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2242/6000 [2:11:18<3:40:53,  3.53s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:11:21<3:37:33,  3.47s/it]                                                       {'loss': 0.0238, 'grad_norm': 6.9903998374938965, 'learning_rate': 6.367796610169492e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2243/6000 [2:11:21<3:37:33,  3.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:11:25<3:36:28,  3.46s/it]                                                       {'loss': 0.1586, 'grad_norm': 12.419371604919434, 'learning_rate': 6.366101694915254e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2244/6000 [2:11:25<3:36:28,  3.46s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:11:28<3:36:05,  3.45s/it]                                                       {'loss': 0.0593, 'grad_norm': 10.02180290222168, 'learning_rate': 6.3644067796610174e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2245/6000 [2:11:28<3:36:05,  3.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:11:31<3:33:45,  3.42s/it]                                                       {'loss': 0.0229, 'grad_norm': 3.7223939895629883, 'learning_rate': 6.36271186440678e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2246/6000 [2:11:31<3:33:45,  3.42s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:11:35<3:31:40,  3.38s/it]                                                       {'loss': 0.0493, 'grad_norm': 10.268888473510742, 'learning_rate': 6.361016949152543e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2247/6000 [2:11:35<3:31:40,  3.38s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:11:38<3:30:56,  3.37s/it]                                                       {'loss': 0.064, 'grad_norm': 6.225120544433594, 'learning_rate': 6.3593220338983056e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2248/6000 [2:11:38<3:30:56,  3.37s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:11:42<3:39:44,  3.51s/it]                                                       {'loss': 0.0086, 'grad_norm': 3.338813543319702, 'learning_rate': 6.357627118644069e-06, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2249/6000 [2:11:42<3:39:44,  3.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:11:45<3:37:58,  3.49s/it]                                                       {'loss': 0.0263, 'grad_norm': 7.070925235748291, 'learning_rate': 6.3559322033898304e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2250/6000 [2:11:45<3:37:58,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:11:49<3:40:36,  3.53s/it]                                                       {'loss': 0.1106, 'grad_norm': 16.108335494995117, 'learning_rate': 6.354237288135594e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2251/6000 [2:11:49<3:40:36,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:11:52<3:36:34,  3.47s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.7466144561767578, 'learning_rate': 6.352542372881356e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/6000 [2:11:52<3:36:34,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:11:56<3:34:45,  3.44s/it]                                                       {'loss': 0.004, 'grad_norm': 0.9990134239196777, 'learning_rate': 6.350847457627119e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2253/6000 [2:11:56<3:34:45,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:12:00<3:55:36,  3.77s/it]                                                       {'loss': 0.036, 'grad_norm': 4.912926197052002, 'learning_rate': 6.349152542372882e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2254/6000 [2:12:00<3:55:36,  3.77s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:12:04<3:48:22,  3.66s/it]                                                       {'loss': 0.0722, 'grad_norm': 10.737887382507324, 'learning_rate': 6.347457627118645e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2255/6000 [2:12:04<3:48:22,  3.66s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:12:07<3:43:03,  3.57s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2732858657836914, 'learning_rate': 6.3457627118644075e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2256/6000 [2:12:07<3:43:03,  3.57s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:12:10<3:40:16,  3.53s/it]                                                       {'loss': 0.001, 'grad_norm': 0.24377532303333282, 'learning_rate': 6.344067796610171e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2257/6000 [2:12:10<3:40:16,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:12:14<3:36:52,  3.48s/it]                                                       {'loss': 0.0183, 'grad_norm': 4.584207534790039, 'learning_rate': 6.342372881355932e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2258/6000 [2:12:14<3:36:52,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:12:17<3:34:17,  3.44s/it]                                                       {'loss': 0.0687, 'grad_norm': 10.429632186889648, 'learning_rate': 6.340677966101696e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2259/6000 [2:12:17<3:34:17,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:12:20<3:32:50,  3.41s/it]                                                       {'loss': 0.1626, 'grad_norm': 15.277044296264648, 'learning_rate': 6.338983050847458e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2260/6000 [2:12:20<3:32:50,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:12:25<3:46:08,  3.63s/it]                                                       {'loss': 0.0338, 'grad_norm': 6.009159564971924, 'learning_rate': 6.3372881355932205e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2261/6000 [2:12:25<3:46:08,  3.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:12:28<3:42:48,  3.58s/it]                                                       {'loss': 0.1111, 'grad_norm': 8.688775062561035, 'learning_rate': 6.335593220338984e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2262/6000 [2:12:28<3:42:48,  3.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:12:32<3:43:26,  3.59s/it]                                                       {'loss': 0.2261, 'grad_norm': 14.953147888183594, 'learning_rate': 6.333898305084746e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2263/6000 [2:12:32<3:43:26,  3.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:12:36<3:48:36,  3.67s/it]                                                       {'loss': 0.0319, 'grad_norm': 12.090497970581055, 'learning_rate': 6.3322033898305095e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2264/6000 [2:12:36<3:48:36,  3.67s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:12:39<3:46:13,  3.63s/it]                                                       {'loss': 0.0452, 'grad_norm': 7.216754913330078, 'learning_rate': 6.330508474576271e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2265/6000 [2:12:39<3:46:13,  3.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:12:42<3:41:43,  3.56s/it]                                                       {'loss': 0.1042, 'grad_norm': 12.542736053466797, 'learning_rate': 6.328813559322034e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2266/6000 [2:12:42<3:41:43,  3.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:12:46<3:37:46,  3.50s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.21020294725894928, 'learning_rate': 6.327118644067797e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2267/6000 [2:12:46<3:37:46,  3.50s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:12:49<3:35:56,  3.47s/it]                                                       {'loss': 0.0432, 'grad_norm': 7.548311233520508, 'learning_rate': 6.32542372881356e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2268/6000 [2:12:49<3:35:56,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:12:53<3:34:38,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.06392155587673187, 'learning_rate': 6.3237288135593225e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2269/6000 [2:12:53<3:34:38,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:12:57<3:44:15,  3.61s/it]                                                       {'loss': 0.0267, 'grad_norm': 5.106870174407959, 'learning_rate': 6.322033898305086e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2270/6000 [2:12:57<3:44:15,  3.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:13:00<3:40:54,  3.55s/it]                                                       {'loss': 0.0266, 'grad_norm': 7.539952278137207, 'learning_rate': 6.320338983050847e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2271/6000 [2:13:00<3:40:54,  3.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:13:03<3:36:04,  3.48s/it]                                                       {'loss': 0.0168, 'grad_norm': 2.4491121768951416, 'learning_rate': 6.318644067796611e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2272/6000 [2:13:03<3:36:04,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:13:07<3:33:27,  3.44s/it]                                                       {'loss': 0.063, 'grad_norm': 9.1779146194458, 'learning_rate': 6.316949152542373e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2273/6000 [2:13:07<3:33:27,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:13:10<3:34:15,  3.45s/it]                                                       {'loss': 0.0439, 'grad_norm': 9.374751091003418, 'learning_rate': 6.315254237288136e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2274/6000 [2:13:10<3:34:15,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:13:14<3:34:06,  3.45s/it]                                                       {'loss': 0.0761, 'grad_norm': 10.052138328552246, 'learning_rate': 6.313559322033899e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2275/6000 [2:13:14<3:34:06,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:13:17<3:36:30,  3.49s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.17126919329166412, 'learning_rate': 6.311864406779662e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2276/6000 [2:13:17<3:36:30,  3.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:13:20<3:33:20,  3.44s/it]                                                       {'loss': 0.1842, 'grad_norm': 19.623525619506836, 'learning_rate': 6.310169491525424e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2277/6000 [2:13:21<3:33:20,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:13:24<3:30:40,  3.40s/it]                                                       {'loss': 0.0226, 'grad_norm': 4.754861831665039, 'learning_rate': 6.308474576271188e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2278/6000 [2:13:24<3:30:40,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:13:27<3:28:35,  3.36s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.0083415508270264, 'learning_rate': 6.306779661016949e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/6000 [2:13:27<3:28:35,  3.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:13:31<3:30:44,  3.40s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.829164445400238, 'learning_rate': 6.3050847457627125e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2280/6000 [2:13:31<3:30:44,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:13:34<3:30:18,  3.39s/it]                                                       {'loss': 0.1045, 'grad_norm': 14.403726577758789, 'learning_rate': 6.303389830508475e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2281/6000 [2:13:34<3:30:18,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:13:37<3:30:29,  3.40s/it]                                                       {'loss': 0.0155, 'grad_norm': 4.581091403961182, 'learning_rate': 6.301694915254237e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2282/6000 [2:13:37<3:30:29,  3.40s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:13:41<3:29:49,  3.39s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.6978956460952759, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2283/6000 [2:13:41<3:29:49,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:13:44<3:30:08,  3.39s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.5317907333374023, 'learning_rate': 6.298305084745763e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2284/6000 [2:13:44<3:30:08,  3.39s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:13:48<3:30:52,  3.41s/it]                                                       {'loss': 0.0857, 'grad_norm': 15.874977111816406, 'learning_rate': 6.296610169491526e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2285/6000 [2:13:48<3:30:52,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:13:51<3:31:16,  3.41s/it]                                                       {'loss': 0.0772, 'grad_norm': 17.6431884765625, 'learning_rate': 6.294915254237288e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2286/6000 [2:13:51<3:31:16,  3.41s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:13:55<3:35:18,  3.48s/it]                                                       {'loss': 0.0054, 'grad_norm': 2.3954360485076904, 'learning_rate': 6.293220338983051e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2287/6000 [2:13:55<3:35:18,  3.48s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:13:58<3:33:26,  3.45s/it]                                                       {'loss': 0.1346, 'grad_norm': 10.023978233337402, 'learning_rate': 6.291525423728814e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2288/6000 [2:13:58<3:33:26,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:14:01<3:31:27,  3.42s/it]                                                       {'loss': 0.1822, 'grad_norm': 10.195049285888672, 'learning_rate': 6.289830508474577e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2289/6000 [2:14:01<3:31:27,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:14:05<3:38:18,  3.53s/it]                                                       {'loss': 0.1256, 'grad_norm': 11.019268035888672, 'learning_rate': 6.288135593220339e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2290/6000 [2:14:05<3:38:18,  3.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:14:08<3:34:13,  3.47s/it]                                                       {'loss': 0.0245, 'grad_norm': 5.50778341293335, 'learning_rate': 6.286440677966103e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2291/6000 [2:14:08<3:34:13,  3.47s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:14:12<3:31:22,  3.42s/it]                                                       {'loss': 0.0123, 'grad_norm': 3.345611572265625, 'learning_rate': 6.284745762711865e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2292/6000 [2:14:12<3:31:22,  3.42s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:14:15<3:31:40,  3.43s/it]                                                       {'loss': 0.0894, 'grad_norm': 4.891499996185303, 'learning_rate': 6.283050847457628e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2293/6000 [2:14:15<3:31:40,  3.43s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:14:19<3:32:32,  3.44s/it]                                                       {'loss': 0.0171, 'grad_norm': 3.600316047668457, 'learning_rate': 6.28135593220339e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2294/6000 [2:14:19<3:32:32,  3.44s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:14:22<3:32:55,  3.45s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.569678544998169, 'learning_rate': 6.279661016949153e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2295/6000 [2:14:22<3:32:55,  3.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:14:26<3:37:14,  3.52s/it]                                                       {'loss': 0.1842, 'grad_norm': 14.311469078063965, 'learning_rate': 6.277966101694916e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2296/6000 [2:14:26<3:37:14,  3.52s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:14:30<3:43:20,  3.62s/it]                                                       {'loss': 0.0315, 'grad_norm': 5.149613857269287, 'learning_rate': 6.276271186440679e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2297/6000 [2:14:30<3:43:20,  3.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:14:34<3:56:59,  3.84s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.5874320268630981, 'learning_rate': 6.274576271186441e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2298/6000 [2:14:34<3:56:59,  3.84s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:14:37<3:49:22,  3.72s/it]                                                       {'loss': 0.0479, 'grad_norm': 7.239019870758057, 'learning_rate': 6.2728813559322046e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2299/6000 [2:14:37<3:49:22,  3.72s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:14:41<3:41:27,  3.59s/it]                                                       {'loss': 0.0465, 'grad_norm': 8.77901840209961, 'learning_rate': 6.271186440677966e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2300/6000 [2:14:41<3:41:27,  3.59s/it][2025-11-07 01:05:50,770] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300
[2025-11-07 01:05:50,784] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:05:51,481] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:14:47<4:25:34,  4.31s/it]                                                       {'loss': 0.002, 'grad_norm': 1.8297412395477295, 'learning_rate': 6.2694915254237294e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2301/6000 [2:14:47<4:25:34,  4.31s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:14:50<4:08:00,  4.02s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.820826530456543, 'learning_rate': 6.267796610169492e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2302/6000 [2:14:50<4:08:00,  4.02s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:14:53<3:55:09,  3.82s/it]                                                       {'loss': 0.092, 'grad_norm': 12.723980903625488, 'learning_rate': 6.266101694915254e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2303/6000 [2:14:53<3:55:09,  3.82s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:14:57<3:48:04,  3.70s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04545429348945618, 'learning_rate': 6.2644067796610176e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2304/6000 [2:14:57<3:48:04,  3.70s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:15:00<3:44:30,  3.65s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.8387917876243591, 'learning_rate': 6.26271186440678e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2305/6000 [2:15:00<3:44:30,  3.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:15:04<3:42:07,  3.61s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.5968126058578491, 'learning_rate': 6.261016949152543e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2306/6000 [2:15:04<3:42:07,  3.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:15:08<3:46:54,  3.69s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.3386846780776978, 'learning_rate': 6.259322033898305e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2307/6000 [2:15:08<3:46:54,  3.69s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:15:11<3:43:16,  3.63s/it]                                                       {'loss': 0.0402, 'grad_norm': 7.54054069519043, 'learning_rate': 6.257627118644068e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2308/6000 [2:15:11<3:43:16,  3.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:15:15<3:38:38,  3.55s/it]                                                       {'loss': 0.2274, 'grad_norm': 23.511028289794922, 'learning_rate': 6.2559322033898305e-06, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2309/6000 [2:15:15<3:38:38,  3.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:15:18<3:35:16,  3.50s/it]                                                       {'loss': 0.1591, 'grad_norm': 11.61761474609375, 'learning_rate': 6.254237288135594e-06, 'epoch': 0.39}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 2310/6000 [2:15:18<3:35:16,  3.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:15:21<3:32:40,  3.46s/it]                                                       {'loss': 0.0096, 'grad_norm': 2.2217142581939697, 'learning_rate': 6.252542372881356e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2311/6000 [2:15:21<3:32:40,  3.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:15:25<3:30:37,  3.43s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.6170572638511658, 'learning_rate': 6.2508474576271195e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2312/6000 [2:15:25<3:30:37,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:15:28<3:31:30,  3.44s/it]                                                       {'loss': 0.0273, 'grad_norm': 6.63269567489624, 'learning_rate': 6.249152542372882e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2313/6000 [2:15:28<3:31:30,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:15:32<3:31:30,  3.44s/it]                                                       {'loss': 0.0466, 'grad_norm': 7.170581340789795, 'learning_rate': 6.247457627118645e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2314/6000 [2:15:32<3:31:30,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:15:35<3:32:03,  3.45s/it]                                                       {'loss': 0.03, 'grad_norm': 5.934422492980957, 'learning_rate': 6.245762711864407e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2315/6000 [2:15:35<3:32:03,  3.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:15:38<3:30:08,  3.42s/it]                                                       {'loss': 0.028, 'grad_norm': 7.373743534088135, 'learning_rate': 6.24406779661017e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2316/6000 [2:15:39<3:30:08,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:15:42<3:27:52,  3.39s/it]                                                       {'loss': 0.2859, 'grad_norm': 17.463279724121094, 'learning_rate': 6.2423728813559325e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2317/6000 [2:15:42<3:27:52,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:15:45<3:26:29,  3.36s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9597112536430359, 'learning_rate': 6.240677966101696e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2318/6000 [2:15:45<3:26:29,  3.36s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:15:49<3:27:08,  3.38s/it]                                                       {'loss': 0.1466, 'grad_norm': 12.04080581665039, 'learning_rate': 6.238983050847458e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2319/6000 [2:15:49<3:27:08,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:15:52<3:29:00,  3.41s/it]                                                       {'loss': 0.0667, 'grad_norm': 10.764774322509766, 'learning_rate': 6.2372881355932215e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2320/6000 [2:15:52<3:29:00,  3.41s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:15:55<3:29:27,  3.42s/it]                                                       {'loss': 0.0807, 'grad_norm': 10.341781616210938, 'learning_rate': 6.235593220338984e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2321/6000 [2:15:55<3:29:27,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:15:59<3:27:29,  3.38s/it]                                                       {'loss': 0.046, 'grad_norm': 7.788122177124023, 'learning_rate': 6.233898305084747e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2322/6000 [2:15:59<3:27:29,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:16:02<3:30:01,  3.43s/it]                                                       {'loss': 0.1458, 'grad_norm': 15.956807136535645, 'learning_rate': 6.232203389830509e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2323/6000 [2:16:02<3:30:01,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:16:06<3:30:19,  3.43s/it]                                                       {'loss': 0.0258, 'grad_norm': 5.759153842926025, 'learning_rate': 6.230508474576271e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 2324/6000 [2:16:06<3:30:19,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:16:09<3:29:22,  3.42s/it]                                                       {'loss': 0.0429, 'grad_norm': 5.860109806060791, 'learning_rate': 6.2288135593220344e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2325/6000 [2:16:09<3:29:22,  3.42s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:16:12<3:28:52,  3.41s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.4784711599349976, 'learning_rate': 6.227118644067797e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2326/6000 [2:16:13<3:28:52,  3.41s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:16:16<3:27:32,  3.39s/it]                                                       {'loss': 0.1523, 'grad_norm': 13.70157527923584, 'learning_rate': 6.22542372881356e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2327/6000 [2:16:16<3:27:32,  3.39s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:16:19<3:27:01,  3.38s/it]                                                       {'loss': 0.4181, 'grad_norm': 24.430805206298828, 'learning_rate': 6.223728813559322e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2328/6000 [2:16:19<3:27:01,  3.38s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:16:24<3:58:06,  3.89s/it]                                                       {'loss': 0.1438, 'grad_norm': 17.066268920898438, 'learning_rate': 6.222033898305085e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2329/6000 [2:16:24<3:58:06,  3.89s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:16:28<3:51:14,  3.78s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.887805461883545, 'learning_rate': 6.2203389830508474e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/6000 [2:16:28<3:51:14,  3.78s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:16:31<3:44:27,  3.67s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2378539890050888, 'learning_rate': 6.218644067796611e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2331/6000 [2:16:31<3:44:27,  3.67s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:16:35<3:38:07,  3.57s/it]                                                       {'loss': 0.027, 'grad_norm': 4.012879848480225, 'learning_rate': 6.216949152542373e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2332/6000 [2:16:35<3:38:07,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:16:38<3:34:16,  3.51s/it]                                                       {'loss': 0.0303, 'grad_norm': 6.657470226287842, 'learning_rate': 6.215254237288136e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2333/6000 [2:16:38<3:34:16,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:16:41<3:32:05,  3.47s/it]                                                       {'loss': 0.0948, 'grad_norm': 11.908415794372559, 'learning_rate': 6.213559322033899e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2334/6000 [2:16:41<3:32:05,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:16:45<3:29:51,  3.44s/it]                                                       {'loss': 0.0063, 'grad_norm': 2.647547960281372, 'learning_rate': 6.211864406779662e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2335/6000 [2:16:45<3:29:51,  3.44s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:16:48<3:29:26,  3.43s/it]                                                       {'loss': 0.1868, 'grad_norm': 14.025127410888672, 'learning_rate': 6.210169491525424e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2336/6000 [2:16:48<3:29:26,  3.43s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:16:52<3:35:31,  3.53s/it]                                                       {'loss': 0.0557, 'grad_norm': 9.493329048156738, 'learning_rate': 6.208474576271187e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2337/6000 [2:16:52<3:35:31,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:16:56<3:42:31,  3.65s/it]                                                       {'loss': 0.1099, 'grad_norm': 12.673858642578125, 'learning_rate': 6.206779661016949e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2338/6000 [2:16:56<3:42:31,  3.65s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:16:59<3:37:09,  3.56s/it]                                                       {'loss': 0.0186, 'grad_norm': 3.9149763584136963, 'learning_rate': 6.205084745762713e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2339/6000 [2:16:59<3:37:09,  3.56s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:17:03<3:34:30,  3.52s/it]                                                       {'loss': 0.0597, 'grad_norm': 10.0368013381958, 'learning_rate': 6.203389830508475e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2340/6000 [2:17:03<3:34:30,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:17:06<3:31:45,  3.47s/it]                                                       {'loss': 0.1072, 'grad_norm': 16.250354766845703, 'learning_rate': 6.201694915254238e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2341/6000 [2:17:06<3:31:45,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:17:10<3:40:59,  3.62s/it]                                                       {'loss': 0.0183, 'grad_norm': 6.058619976043701, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2342/6000 [2:17:10<3:40:59,  3.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:17:13<3:37:15,  3.56s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3076709806919098, 'learning_rate': 6.198305084745764e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2343/6000 [2:17:13<3:37:15,  3.56s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:17:17<3:35:18,  3.53s/it]                                                       {'loss': 0.003, 'grad_norm': 1.2775462865829468, 'learning_rate': 6.196610169491526e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2344/6000 [2:17:17<3:35:18,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:17:20<3:34:06,  3.51s/it]                                                       {'loss': 0.0067, 'grad_norm': 2.011963367462158, 'learning_rate': 6.194915254237288e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2345/6000 [2:17:20<3:34:06,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:17:24<3:33:32,  3.51s/it]                                                       {'loss': 0.3492, 'grad_norm': 18.394317626953125, 'learning_rate': 6.193220338983051e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2346/6000 [2:17:24<3:33:32,  3.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:17:27<3:34:15,  3.52s/it]                                                       {'loss': 0.0183, 'grad_norm': 7.07509183883667, 'learning_rate': 6.191525423728814e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2347/6000 [2:17:27<3:34:15,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:17:31<3:31:07,  3.47s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.0649408102035522, 'learning_rate': 6.189830508474577e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2348/6000 [2:17:31<3:31:07,  3.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:17:34<3:36:04,  3.55s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.18255998194217682, 'learning_rate': 6.1881355932203395e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2349/6000 [2:17:34<3:36:04,  3.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:17:38<3:40:05,  3.62s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.626275360584259, 'learning_rate': 6.186440677966103e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2350/6000 [2:17:38<3:40:05,  3.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:17:42<3:37:29,  3.58s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9443084597587585, 'learning_rate': 6.184745762711864e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2351/6000 [2:17:42<3:37:29,  3.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:17:45<3:35:05,  3.54s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.17359484732151031, 'learning_rate': 6.183050847457628e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2352/6000 [2:17:45<3:35:05,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:17:49<3:40:39,  3.63s/it]                                                       {'loss': 0.1611, 'grad_norm': 17.196115493774414, 'learning_rate': 6.18135593220339e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2353/6000 [2:17:49<3:40:39,  3.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:17:52<3:38:47,  3.60s/it]                                                       {'loss': 0.1372, 'grad_norm': 14.44473648071289, 'learning_rate': 6.179661016949153e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2354/6000 [2:17:52<3:38:47,  3.60s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:17:56<3:45:04,  3.70s/it]                                                       {'loss': 0.0515, 'grad_norm': 7.296276569366455, 'learning_rate': 6.177966101694916e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2355/6000 [2:17:56<3:45:04,  3.70s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:18:00<3:47:12,  3.74s/it]                                                       {'loss': 0.0651, 'grad_norm': 16.52785301208496, 'learning_rate': 6.176271186440679e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2356/6000 [2:18:00<3:47:12,  3.74s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:18:04<3:42:16,  3.66s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.029676638543605804, 'learning_rate': 6.1745762711864406e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2357/6000 [2:18:04<3:42:16,  3.66s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:18:07<3:36:33,  3.57s/it]                                                       {'loss': 0.0165, 'grad_norm': 2.072967290878296, 'learning_rate': 6.172881355932205e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2358/6000 [2:18:07<3:36:33,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:18:10<3:34:31,  3.54s/it]                                                       {'loss': 0.0162, 'grad_norm': 5.793570518493652, 'learning_rate': 6.171186440677966e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2359/6000 [2:18:10<3:34:31,  3.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:18:14<3:37:05,  3.58s/it]                                                       {'loss': 0.1184, 'grad_norm': 14.563101768493652, 'learning_rate': 6.1694915254237295e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2360/6000 [2:18:14<3:37:05,  3.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:18:18<3:40:31,  3.64s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.12402492016553879, 'learning_rate': 6.167796610169492e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2361/6000 [2:18:18<3:40:31,  3.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:18:21<3:36:29,  3.57s/it]                                                       {'loss': 0.0326, 'grad_norm': 4.178907871246338, 'learning_rate': 6.166101694915255e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2362/6000 [2:18:21<3:36:29,  3.57s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:18:25<3:35:31,  3.56s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.3709683418273926, 'learning_rate': 6.164406779661018e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2363/6000 [2:18:25<3:35:31,  3.56s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:18:28<3:34:04,  3.53s/it]                                                       {'loss': 0.0859, 'grad_norm': 12.061098098754883, 'learning_rate': 6.162711864406781e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2364/6000 [2:18:28<3:34:04,  3.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:18:32<3:36:56,  3.58s/it]                                                       {'loss': 0.003, 'grad_norm': 0.8808820247650146, 'learning_rate': 6.1610169491525425e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2365/6000 [2:18:32<3:36:56,  3.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:18:35<3:33:21,  3.52s/it]                                                       {'loss': 0.1024, 'grad_norm': 12.726078987121582, 'learning_rate': 6.159322033898305e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2366/6000 [2:18:35<3:33:21,  3.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:18:39<3:31:16,  3.49s/it]                                                       {'loss': 0.0381, 'grad_norm': 5.736097812652588, 'learning_rate': 6.157627118644068e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2367/6000 [2:18:39<3:31:16,  3.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:18:42<3:30:52,  3.48s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.11824441701173782, 'learning_rate': 6.155932203389831e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2368/6000 [2:18:42<3:30:52,  3.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:18:46<3:30:54,  3.49s/it]                                                       {'loss': 0.009, 'grad_norm': 1.893117070198059, 'learning_rate': 6.154237288135594e-06, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 2369/6000 [2:18:46<3:30:54,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:18:49<3:28:15,  3.44s/it]                                                       {'loss': 0.003, 'grad_norm': 0.9117292165756226, 'learning_rate': 6.152542372881356e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2370/6000 [2:18:49<3:28:15,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:18:53<3:27:51,  3.44s/it]                                                       {'loss': 0.0443, 'grad_norm': 10.977486610412598, 'learning_rate': 6.15084745762712e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2371/6000 [2:18:53<3:27:51,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:18:56<3:27:33,  3.43s/it]                                                       {'loss': 0.2275, 'grad_norm': 20.613861083984375, 'learning_rate': 6.149152542372881e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2372/6000 [2:18:56<3:27:33,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:19:00<3:28:49,  3.45s/it]                                                       {'loss': 0.06, 'grad_norm': 6.345959663391113, 'learning_rate': 6.1474576271186445e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2373/6000 [2:19:00<3:28:49,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:19:03<3:26:34,  3.42s/it]                                                       {'loss': 0.0637, 'grad_norm': 10.7525634765625, 'learning_rate': 6.145762711864407e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2374/6000 [2:19:03<3:26:34,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:19:06<3:27:04,  3.43s/it]                                                       {'loss': 0.1494, 'grad_norm': 12.861824989318848, 'learning_rate': 6.14406779661017e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2375/6000 [2:19:06<3:27:04,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:19:10<3:27:21,  3.43s/it]                                                       {'loss': 0.0164, 'grad_norm': 3.211228847503662, 'learning_rate': 6.142372881355933e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2376/6000 [2:19:10<3:27:21,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:19:13<3:27:07,  3.43s/it]                                                       {'loss': 0.0058, 'grad_norm': 2.6690917015075684, 'learning_rate': 6.140677966101696e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2377/6000 [2:19:13<3:27:07,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:19:17<3:27:59,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.19442375004291534, 'learning_rate': 6.138983050847458e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2378/6000 [2:19:17<3:27:59,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:19:20<3:26:49,  3.43s/it]                                                       {'loss': 0.0426, 'grad_norm': 9.798920631408691, 'learning_rate': 6.1372881355932216e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/6000 [2:19:20<3:26:49,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:19:23<3:26:22,  3.42s/it]                                                       {'loss': 0.0369, 'grad_norm': 7.974171161651611, 'learning_rate': 6.135593220338983e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2380/6000 [2:19:23<3:26:22,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:19:27<3:24:52,  3.40s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.9586333632469177, 'learning_rate': 6.1338983050847464e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/6000 [2:19:27<3:24:52,  3.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:19:30<3:28:31,  3.46s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1115456148982048, 'learning_rate': 6.132203389830509e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2382/6000 [2:19:30<3:28:31,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:19:34<3:26:03,  3.42s/it]                                                       {'loss': 0.0203, 'grad_norm': 4.33128023147583, 'learning_rate': 6.130508474576272e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2383/6000 [2:19:34<3:26:03,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:19:37<3:24:27,  3.39s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.4452180862426758, 'learning_rate': 6.1288135593220346e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2384/6000 [2:19:37<3:24:27,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:19:40<3:24:13,  3.39s/it]                                                       {'loss': 0.1132, 'grad_norm': 14.527617454528809, 'learning_rate': 6.127118644067798e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2385/6000 [2:19:40<3:24:13,  3.39s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:19:44<3:24:35,  3.40s/it]                                                       {'loss': 0.0097, 'grad_norm': 3.144896984100342, 'learning_rate': 6.12542372881356e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2386/6000 [2:19:44<3:24:35,  3.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:19:47<3:28:57,  3.47s/it]                                                       {'loss': 0.1296, 'grad_norm': 13.91506576538086, 'learning_rate': 6.123728813559322e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2387/6000 [2:19:47<3:28:57,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:19:51<3:29:23,  3.48s/it]                                                       {'loss': 0.2566, 'grad_norm': 15.784038543701172, 'learning_rate': 6.122033898305085e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2388/6000 [2:19:51<3:29:23,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:19:54<3:26:36,  3.43s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.7268620729446411, 'learning_rate': 6.1203389830508475e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2389/6000 [2:19:54<3:26:36,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:19:58<3:28:16,  3.46s/it]                                                       {'loss': 0.0236, 'grad_norm': 5.373992443084717, 'learning_rate': 6.118644067796611e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2390/6000 [2:19:58<3:28:16,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:20:01<3:27:27,  3.45s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.7781513929367065, 'learning_rate': 6.116949152542373e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2391/6000 [2:20:01<3:27:27,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:20:05<3:26:56,  3.44s/it]                                                       {'loss': 0.0923, 'grad_norm': 9.6294584274292, 'learning_rate': 6.1152542372881365e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2392/6000 [2:20:05<3:26:56,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:20:08<3:25:27,  3.42s/it]                                                       {'loss': 0.0283, 'grad_norm': 7.675751209259033, 'learning_rate': 6.113559322033898e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2393/6000 [2:20:08<3:25:27,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:20:12<3:26:44,  3.44s/it]                                                       {'loss': 0.0437, 'grad_norm': 5.330069065093994, 'learning_rate': 6.111864406779661e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2394/6000 [2:20:12<3:26:44,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:20:15<3:24:54,  3.41s/it]                                                       {'loss': 0.0253, 'grad_norm': 7.416219234466553, 'learning_rate': 6.110169491525424e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2395/6000 [2:20:15<3:24:54,  3.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:20:19<3:29:50,  3.49s/it]                                                       {'loss': 0.0129, 'grad_norm': 2.3667125701904297, 'learning_rate': 6.108474576271187e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2396/6000 [2:20:19<3:29:50,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:20:22<3:29:49,  3.49s/it]                                                       {'loss': 0.0138, 'grad_norm': 2.850200653076172, 'learning_rate': 6.1067796610169495e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2397/6000 [2:20:22<3:29:49,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:20:25<3:28:15,  3.47s/it]                                                       {'loss': 0.002, 'grad_norm': 0.7375639081001282, 'learning_rate': 6.105084745762713e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2398/6000 [2:20:25<3:28:15,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:20:29<3:26:57,  3.45s/it]                                                       {'loss': 0.1078, 'grad_norm': 7.978880882263184, 'learning_rate': 6.103389830508475e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 2399/6000 [2:20:29<3:26:57,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:20:32<3:25:59,  3.43s/it]                                                       {'loss': 0.0287, 'grad_norm': 7.816426753997803, 'learning_rate': 6.1016949152542385e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2400/6000 [2:20:32<3:25:59,  3.43s/it][2025-11-07 01:11:42,245] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400
[2025-11-07 01:11:42,263] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:11:42,952] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:20:38<4:07:28,  4.13s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.2813185453414917, 'learning_rate': 6.1e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2401/6000 [2:20:38<4:07:28,  4.13s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:20:41<3:55:49,  3.93s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.10310531407594681, 'learning_rate': 6.098305084745763e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2402/6000 [2:20:41<3:55:49,  3.93s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:20:45<3:45:47,  3.77s/it]                                                       {'loss': 0.0345, 'grad_norm': 8.706864356994629, 'learning_rate': 6.096610169491526e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2403/6000 [2:20:45<3:45:47,  3.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:20:48<3:38:43,  3.65s/it]                                                       {'loss': 0.0243, 'grad_norm': 2.835505962371826, 'learning_rate': 6.094915254237289e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2404/6000 [2:20:48<3:38:43,  3.65s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:20:52<3:34:54,  3.59s/it]                                                       {'loss': 0.0466, 'grad_norm': 8.691139221191406, 'learning_rate': 6.0932203389830514e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2405/6000 [2:20:52<3:34:54,  3.59s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:20:55<3:32:29,  3.55s/it]                                                       {'loss': 0.1142, 'grad_norm': 13.43242073059082, 'learning_rate': 6.091525423728814e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2406/6000 [2:20:55<3:32:29,  3.55s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:20:58<3:29:02,  3.49s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.2471598386764526, 'learning_rate': 6.089830508474577e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2407/6000 [2:20:58<3:29:02,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:21:02<3:27:09,  3.46s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.7523125410079956, 'learning_rate': 6.088135593220339e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2408/6000 [2:21:02<3:27:09,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:21:05<3:25:07,  3.43s/it]                                                       {'loss': 0.0618, 'grad_norm': 12.390708923339844, 'learning_rate': 6.086440677966102e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2409/6000 [2:21:05<3:25:07,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:21:09<3:30:28,  3.52s/it]                                                       {'loss': 0.0557, 'grad_norm': 8.705009460449219, 'learning_rate': 6.084745762711864e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2410/6000 [2:21:09<3:30:28,  3.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:21:12<3:28:03,  3.48s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.979469895362854, 'learning_rate': 6.083050847457628e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2411/6000 [2:21:12<3:28:03,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:21:16<3:28:48,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.2276371568441391, 'learning_rate': 6.08135593220339e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2412/6000 [2:21:16<3:28:48,  3.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:21:19<3:26:37,  3.46s/it]                                                       {'loss': 0.1324, 'grad_norm': 15.029584884643555, 'learning_rate': 6.079661016949153e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2413/6000 [2:21:19<3:26:37,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:21:23<3:25:08,  3.43s/it]                                                       {'loss': 0.1562, 'grad_norm': 13.70678997039795, 'learning_rate': 6.077966101694916e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2414/6000 [2:21:23<3:25:08,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:21:26<3:25:42,  3.44s/it]                                                       {'loss': 0.1133, 'grad_norm': 14.293754577636719, 'learning_rate': 6.076271186440679e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2415/6000 [2:21:26<3:25:42,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:21:29<3:24:26,  3.42s/it]                                                       {'loss': 0.0268, 'grad_norm': 5.978216648101807, 'learning_rate': 6.074576271186441e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2416/6000 [2:21:29<3:24:26,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:21:33<3:24:40,  3.43s/it]                                                       {'loss': 0.0248, 'grad_norm': 4.8143205642700195, 'learning_rate': 6.072881355932204e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2417/6000 [2:21:33<3:24:40,  3.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:21:36<3:23:59,  3.42s/it]                                                       {'loss': 0.1641, 'grad_norm': 15.352921485900879, 'learning_rate': 6.071186440677966e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2418/6000 [2:21:36<3:23:59,  3.42s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:21:40<3:25:18,  3.44s/it]                                                       {'loss': 0.014, 'grad_norm': 3.7744553089141846, 'learning_rate': 6.06949152542373e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2419/6000 [2:21:40<3:25:18,  3.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:21:44<3:32:10,  3.56s/it]                                                       {'loss': 0.0156, 'grad_norm': 3.176056385040283, 'learning_rate': 6.067796610169492e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2420/6000 [2:21:44<3:32:10,  3.56s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:21:47<3:32:19,  3.56s/it]                                                       {'loss': 0.001, 'grad_norm': 0.22223854064941406, 'learning_rate': 6.066101694915255e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2421/6000 [2:21:47<3:32:19,  3.56s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:21:51<3:29:52,  3.52s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.631673574447632, 'learning_rate': 6.064406779661017e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2422/6000 [2:21:51<3:29:52,  3.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:21:54<3:27:42,  3.48s/it]                                                       {'loss': 0.1073, 'grad_norm': 13.973467826843262, 'learning_rate': 6.06271186440678e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2423/6000 [2:21:54<3:27:42,  3.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:21:57<3:25:25,  3.45s/it]                                                       {'loss': 0.1965, 'grad_norm': 20.00550651550293, 'learning_rate': 6.061016949152543e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2424/6000 [2:21:57<3:25:25,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:22:01<3:28:43,  3.50s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.536015272140503, 'learning_rate': 6.059322033898306e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2425/6000 [2:22:01<3:28:43,  3.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:22:04<3:26:13,  3.46s/it]                                                       {'loss': 0.05, 'grad_norm': 8.70107650756836, 'learning_rate': 6.057627118644068e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2426/6000 [2:22:04<3:26:13,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:22:08<3:25:47,  3.46s/it]                                                       {'loss': 0.0135, 'grad_norm': 5.346601486206055, 'learning_rate': 6.055932203389831e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2427/6000 [2:22:08<3:25:47,  3.46s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:22:11<3:25:23,  3.45s/it]                                                       {'loss': 0.0364, 'grad_norm': 4.562566757202148, 'learning_rate': 6.054237288135594e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2428/6000 [2:22:11<3:25:23,  3.45s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:22:15<3:26:21,  3.47s/it]                                                       {'loss': 0.0104, 'grad_norm': 3.317491292953491, 'learning_rate': 6.052542372881356e-06, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2429/6000 [2:22:15<3:26:21,  3.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:22:18<3:28:59,  3.51s/it]                                                       {'loss': 0.0201, 'grad_norm': 4.741504192352295, 'learning_rate': 6.050847457627119e-06, 'epoch': 0.41}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2430/6000 [2:22:18<3:28:59,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:22:22<3:30:10,  3.53s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.1246001124382019, 'learning_rate': 6.049152542372881e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2431/6000 [2:22:22<3:30:10,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:22:25<3:26:07,  3.47s/it]                                                       {'loss': 0.0421, 'grad_norm': 10.166449546813965, 'learning_rate': 6.047457627118645e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/6000 [2:22:25<3:26:07,  3.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:22:29<3:24:35,  3.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.05797712504863739, 'learning_rate': 6.045762711864407e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2433/6000 [2:22:29<3:24:35,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:22:32<3:30:09,  3.54s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.3300033807754517, 'learning_rate': 6.04406779661017e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2434/6000 [2:22:32<3:30:09,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:22:36<3:27:27,  3.49s/it]                                                       {'loss': 0.0323, 'grad_norm': 5.85588264465332, 'learning_rate': 6.042372881355933e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2435/6000 [2:22:36<3:27:27,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:22:39<3:25:23,  3.46s/it]                                                       {'loss': 0.0641, 'grad_norm': 8.127341270446777, 'learning_rate': 6.040677966101696e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2436/6000 [2:22:39<3:25:23,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:22:43<3:23:23,  3.43s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.32447975873947144, 'learning_rate': 6.0389830508474576e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2437/6000 [2:22:43<3:23:23,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:22:46<3:24:03,  3.44s/it]                                                       {'loss': 0.0822, 'grad_norm': 9.918655395507812, 'learning_rate': 6.037288135593221e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2438/6000 [2:22:46<3:24:03,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:22:50<3:30:43,  3.55s/it]                                                       {'loss': 0.0109, 'grad_norm': 4.085683822631836, 'learning_rate': 6.035593220338983e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2439/6000 [2:22:50<3:30:43,  3.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:22:53<3:26:52,  3.49s/it]                                                       {'loss': 0.02, 'grad_norm': 3.0641286373138428, 'learning_rate': 6.0338983050847465e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2440/6000 [2:22:53<3:26:52,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:22:57<3:32:56,  3.59s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.435437798500061, 'learning_rate': 6.032203389830509e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2441/6000 [2:22:57<3:32:56,  3.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:23:00<3:29:19,  3.53s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.6460685729980469, 'learning_rate': 6.030508474576272e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2442/6000 [2:23:00<3:29:19,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:23:04<3:28:05,  3.51s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.1887613534927368, 'learning_rate': 6.028813559322035e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2443/6000 [2:23:04<3:28:05,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:23:07<3:24:42,  3.45s/it]                                                       {'loss': 0.1715, 'grad_norm': 14.434298515319824, 'learning_rate': 6.027118644067798e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2444/6000 [2:23:07<3:24:42,  3.45s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:23:11<3:26:57,  3.49s/it]                                                       {'loss': 0.1371, 'grad_norm': 16.114917755126953, 'learning_rate': 6.0254237288135595e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2445/6000 [2:23:11<3:26:57,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:23:14<3:26:12,  3.48s/it]                                                       {'loss': 0.0103, 'grad_norm': 2.5674238204956055, 'learning_rate': 6.023728813559323e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2446/6000 [2:23:14<3:26:12,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:23:18<3:26:40,  3.49s/it]                                                       {'loss': 0.009, 'grad_norm': 2.592144250869751, 'learning_rate': 6.022033898305085e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2447/6000 [2:23:18<3:26:40,  3.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:23:21<3:31:54,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.055204618722200394, 'learning_rate': 6.020338983050848e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2448/6000 [2:23:21<3:31:54,  3.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:23:25<3:27:05,  3.50s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.12604476511478424, 'learning_rate': 6.018644067796611e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2449/6000 [2:23:25<3:27:05,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:23:28<3:24:31,  3.46s/it]                                                       {'loss': 0.0288, 'grad_norm': 6.04725456237793, 'learning_rate': 6.0169491525423725e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2450/6000 [2:23:28<3:24:31,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:23:32<3:22:41,  3.43s/it]                                                       {'loss': 0.0173, 'grad_norm': 3.9367778301239014, 'learning_rate': 6.015254237288136e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2451/6000 [2:23:32<3:22:41,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:23:35<3:23:15,  3.44s/it]                                                       {'loss': 0.0634, 'grad_norm': 9.173439979553223, 'learning_rate': 6.013559322033898e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2452/6000 [2:23:35<3:23:15,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:23:38<3:24:50,  3.46s/it]                                                       {'loss': 0.1658, 'grad_norm': 11.508923530578613, 'learning_rate': 6.0118644067796615e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2453/6000 [2:23:38<3:24:50,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:23:42<3:22:09,  3.42s/it]                                                       {'loss': 0.0154, 'grad_norm': 4.788666725158691, 'learning_rate': 6.010169491525424e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2454/6000 [2:23:42<3:22:09,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:23:45<3:20:47,  3.40s/it]                                                       {'loss': 0.0474, 'grad_norm': 6.804842472076416, 'learning_rate': 6.008474576271187e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2455/6000 [2:23:45<3:20:47,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:23:49<3:20:35,  3.40s/it]                                                       {'loss': 0.0071, 'grad_norm': 2.5127885341644287, 'learning_rate': 6.00677966101695e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2456/6000 [2:23:49<3:20:35,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:23:52<3:23:17,  3.44s/it]                                                       {'loss': 0.0754, 'grad_norm': 9.263529777526855, 'learning_rate': 6.005084745762713e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2457/6000 [2:23:52<3:23:17,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:23:56<3:24:06,  3.46s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07679200917482376, 'learning_rate': 6.0033898305084745e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2458/6000 [2:23:56<3:24:06,  3.46s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:24:00<3:32:23,  3.60s/it]                                                       {'loss': 0.0316, 'grad_norm': 7.637266635894775, 'learning_rate': 6.001694915254238e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2459/6000 [2:24:00<3:32:23,  3.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:24:03<3:29:05,  3.54s/it]                                                       {'loss': 0.123, 'grad_norm': 13.909869194030762, 'learning_rate': 6e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2460/6000 [2:24:03<3:29:05,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:24:07<3:32:00,  3.59s/it]                                                       {'loss': 0.0423, 'grad_norm': 4.534853935241699, 'learning_rate': 5.9983050847457634e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2461/6000 [2:24:07<3:32:00,  3.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:24:10<3:28:39,  3.54s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.7897613048553467, 'learning_rate': 5.996610169491526e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2462/6000 [2:24:10<3:28:39,  3.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:24:13<3:26:10,  3.50s/it]                                                       {'loss': 0.0556, 'grad_norm': 11.142621040344238, 'learning_rate': 5.994915254237289e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2463/6000 [2:24:13<3:26:10,  3.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:24:17<3:25:11,  3.48s/it]                                                       {'loss': 0.1974, 'grad_norm': 16.395112991333008, 'learning_rate': 5.9932203389830516e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2464/6000 [2:24:17<3:25:11,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:24:21<3:32:41,  3.61s/it]                                                       {'loss': 0.0316, 'grad_norm': 7.962088108062744, 'learning_rate': 5.991525423728815e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2465/6000 [2:24:21<3:32:41,  3.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:24:24<3:29:26,  3.56s/it]                                                       {'loss': 0.0064, 'grad_norm': 2.859175443649292, 'learning_rate': 5.989830508474576e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2466/6000 [2:24:24<3:29:26,  3.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:24:28<3:24:59,  3.48s/it]                                                       {'loss': 0.0288, 'grad_norm': 6.981434345245361, 'learning_rate': 5.98813559322034e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2467/6000 [2:24:28<3:24:59,  3.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:24:31<3:22:41,  3.44s/it]                                                       {'loss': 0.0415, 'grad_norm': 6.00309944152832, 'learning_rate': 5.986440677966102e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2468/6000 [2:24:31<3:22:41,  3.44s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:24:34<3:19:27,  3.39s/it]                                                       {'loss': 0.1343, 'grad_norm': 18.87615203857422, 'learning_rate': 5.9847457627118645e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2469/6000 [2:24:34<3:19:27,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:24:38<3:20:51,  3.41s/it]                                                       {'loss': 0.1991, 'grad_norm': 14.635156631469727, 'learning_rate': 5.983050847457628e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2470/6000 [2:24:38<3:20:51,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:24:41<3:21:13,  3.42s/it]                                                       {'loss': 0.0565, 'grad_norm': 9.361480712890625, 'learning_rate': 5.98135593220339e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2471/6000 [2:24:41<3:21:13,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:24:45<3:21:38,  3.43s/it]                                                       {'loss': 0.2542, 'grad_norm': 50.883113861083984, 'learning_rate': 5.9796610169491535e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2472/6000 [2:24:45<3:21:38,  3.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:24:48<3:19:45,  3.40s/it]                                                       {'loss': 0.1863, 'grad_norm': 14.522181510925293, 'learning_rate': 5.977966101694915e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2473/6000 [2:24:48<3:19:45,  3.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:24:51<3:20:29,  3.41s/it]                                                       {'loss': 0.1996, 'grad_norm': 18.920700073242188, 'learning_rate': 5.976271186440678e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2474/6000 [2:24:51<3:20:29,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:24:55<3:20:25,  3.41s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.8426494002342224, 'learning_rate': 5.974576271186441e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2475/6000 [2:24:55<3:20:25,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:24:58<3:21:08,  3.42s/it]                                                       {'loss': 0.13, 'grad_norm': 20.041549682617188, 'learning_rate': 5.972881355932204e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2476/6000 [2:24:58<3:21:08,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:25:02<3:20:25,  3.41s/it]                                                       {'loss': 0.2094, 'grad_norm': 20.589078903198242, 'learning_rate': 5.9711864406779665e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2477/6000 [2:25:02<3:20:25,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:25:05<3:20:06,  3.41s/it]                                                       {'loss': 0.0206, 'grad_norm': 5.866809844970703, 'learning_rate': 5.96949152542373e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2478/6000 [2:25:05<3:20:06,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:25:08<3:20:18,  3.41s/it]                                                       {'loss': 0.0213, 'grad_norm': 6.869786739349365, 'learning_rate': 5.967796610169491e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2479/6000 [2:25:08<3:20:18,  3.41s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:25:12<3:20:48,  3.42s/it]                                                       {'loss': 0.0058, 'grad_norm': 9.767611503601074, 'learning_rate': 5.9661016949152555e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2480/6000 [2:25:12<3:20:48,  3.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:25:15<3:18:39,  3.39s/it]                                                       {'loss': 0.0049, 'grad_norm': 1.1506036520004272, 'learning_rate': 5.964406779661017e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/6000 [2:25:15<3:18:39,  3.39s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:25:18<3:17:08,  3.36s/it]                                                       {'loss': 0.0092, 'grad_norm': 2.88641357421875, 'learning_rate': 5.96271186440678e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2482/6000 [2:25:18<3:17:08,  3.36s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:25:22<3:26:51,  3.53s/it]                                                       {'loss': 0.0902, 'grad_norm': 16.943462371826172, 'learning_rate': 5.961016949152543e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2483/6000 [2:25:22<3:26:51,  3.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:25:26<3:32:19,  3.62s/it]                                                       {'loss': 0.3356, 'grad_norm': 18.124465942382812, 'learning_rate': 5.959322033898306e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2484/6000 [2:25:26<3:32:19,  3.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:25:30<3:30:21,  3.59s/it]                                                       {'loss': 0.0383, 'grad_norm': 10.87724781036377, 'learning_rate': 5.9576271186440684e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2485/6000 [2:25:30<3:30:21,  3.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:25:33<3:27:53,  3.55s/it]                                                       {'loss': 0.0278, 'grad_norm': 7.7305989265441895, 'learning_rate': 5.955932203389832e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2486/6000 [2:25:33<3:27:53,  3.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:25:37<3:25:28,  3.51s/it]                                                       {'loss': 0.0237, 'grad_norm': 4.348599910736084, 'learning_rate': 5.954237288135593e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2487/6000 [2:25:37<3:25:28,  3.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:25:40<3:25:46,  3.52s/it]                                                       {'loss': 0.001, 'grad_norm': 0.24272507429122925, 'learning_rate': 5.9525423728813566e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2488/6000 [2:25:40<3:25:46,  3.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:25:43<3:23:07,  3.47s/it]                                                       {'loss': 0.0122, 'grad_norm': 3.2743775844573975, 'learning_rate': 5.950847457627119e-06, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2489/6000 [2:25:43<3:23:07,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:25:47<3:27:57,  3.55s/it]                                                       {'loss': 0.0264, 'grad_norm': 4.378188610076904, 'learning_rate': 5.949152542372881e-06, 'epoch': 0.41}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2490/6000 [2:25:47<3:27:57,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:25:50<3:22:56,  3.47s/it]                                                       {'loss': 0.0073, 'grad_norm': 2.14345121383667, 'learning_rate': 5.947457627118645e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2491/6000 [2:25:50<3:22:56,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:25:54<3:21:53,  3.45s/it]                                                       {'loss': 0.0889, 'grad_norm': 14.632588386535645, 'learning_rate': 5.945762711864407e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2492/6000 [2:25:54<3:21:53,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:25:57<3:20:10,  3.42s/it]                                                       {'loss': 0.2126, 'grad_norm': 14.881299018859863, 'learning_rate': 5.94406779661017e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2493/6000 [2:25:57<3:20:10,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:26:01<3:19:44,  3.42s/it]                                                       {'loss': 0.2695, 'grad_norm': 19.957109451293945, 'learning_rate': 5.942372881355932e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2494/6000 [2:26:01<3:19:44,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:26:04<3:25:06,  3.51s/it]                                                       {'loss': 0.0932, 'grad_norm': 10.531631469726562, 'learning_rate': 5.940677966101695e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2495/6000 [2:26:04<3:25:06,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:26:08<3:29:05,  3.58s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.146101713180542, 'learning_rate': 5.938983050847458e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2496/6000 [2:26:08<3:29:05,  3.58s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:26:12<3:27:36,  3.56s/it]                                                       {'loss': 0.0095, 'grad_norm': 4.348999500274658, 'learning_rate': 5.937288135593221e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2497/6000 [2:26:12<3:27:36,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:26:15<3:31:12,  3.62s/it]                                                       {'loss': 0.1114, 'grad_norm': 12.909838676452637, 'learning_rate': 5.935593220338983e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2498/6000 [2:26:15<3:31:12,  3.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:26:19<3:26:17,  3.54s/it]                                                       {'loss': 0.0348, 'grad_norm': 8.409135818481445, 'learning_rate': 5.933898305084747e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2499/6000 [2:26:19<3:26:17,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:26:22<3:24:38,  3.51s/it]                                                       {'loss': 0.047, 'grad_norm': 18.797462463378906, 'learning_rate': 5.932203389830509e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2500/6000 [2:26:22<3:24:38,  3.51s/it][2025-11-07 01:17:32,175] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500
[2025-11-07 01:17:32,189] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:17:32,863] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:26:28<4:03:17,  4.17s/it]                                                       {'loss': 0.0758, 'grad_norm': 10.947632789611816, 'learning_rate': 5.930508474576272e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2501/6000 [2:26:28<4:03:17,  4.17s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:26:31<3:48:42,  3.92s/it]                                                       {'loss': 0.2899, 'grad_norm': 16.266878128051758, 'learning_rate': 5.928813559322034e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2502/6000 [2:26:31<3:48:42,  3.92s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:26:35<3:37:51,  3.74s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05762812867760658, 'learning_rate': 5.927118644067797e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2503/6000 [2:26:35<3:37:51,  3.74s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:26:38<3:31:02,  3.62s/it]                                                       {'loss': 0.298, 'grad_norm': 21.40349006652832, 'learning_rate': 5.92542372881356e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2504/6000 [2:26:38<3:31:02,  3.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:26:41<3:26:36,  3.55s/it]                                                       {'loss': 0.064, 'grad_norm': 13.94591999053955, 'learning_rate': 5.923728813559323e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2505/6000 [2:26:41<3:26:36,  3.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:26:45<3:27:33,  3.56s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.5119903683662415, 'learning_rate': 5.922033898305085e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2506/6000 [2:26:45<3:27:33,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:26:48<3:24:49,  3.52s/it]                                                       {'loss': 0.0261, 'grad_norm': 4.050581932067871, 'learning_rate': 5.920338983050849e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2507/6000 [2:26:48<3:24:49,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:26:52<3:20:41,  3.45s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.03237264230847359, 'learning_rate': 5.91864406779661e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2508/6000 [2:26:52<3:20:41,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:26:55<3:18:53,  3.42s/it]                                                       {'loss': 0.178, 'grad_norm': 16.785734176635742, 'learning_rate': 5.916949152542374e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2509/6000 [2:26:55<3:18:53,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:26:58<3:21:16,  3.46s/it]                                                       {'loss': 0.002, 'grad_norm': 0.47976118326187134, 'learning_rate': 5.915254237288136e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2510/6000 [2:26:58<3:21:16,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:27:02<3:27:27,  3.57s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.2567524015903473, 'learning_rate': 5.913559322033898e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2511/6000 [2:27:02<3:27:27,  3.57s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:27:06<3:24:20,  3.52s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.6355501413345337, 'learning_rate': 5.911864406779662e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2512/6000 [2:27:06<3:24:20,  3.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:27:09<3:21:48,  3.47s/it]                                                       {'loss': 0.0119, 'grad_norm': 3.5411274433135986, 'learning_rate': 5.910169491525424e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2513/6000 [2:27:09<3:21:48,  3.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:27:12<3:20:39,  3.45s/it]                                                       {'loss': 0.12, 'grad_norm': 13.25799560546875, 'learning_rate': 5.908474576271187e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2514/6000 [2:27:12<3:20:39,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:27:16<3:22:04,  3.48s/it]                                                       {'loss': 0.3507, 'grad_norm': 24.299978256225586, 'learning_rate': 5.906779661016949e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2515/6000 [2:27:16<3:22:04,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:27:19<3:20:54,  3.46s/it]                                                       {'loss': 0.2357, 'grad_norm': 18.999897003173828, 'learning_rate': 5.905084745762712e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2516/6000 [2:27:19<3:20:54,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:27:23<3:25:29,  3.54s/it]                                                       {'loss': 0.1, 'grad_norm': 16.417694091796875, 'learning_rate': 5.9033898305084746e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2517/6000 [2:27:23<3:25:29,  3.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:27:27<3:22:22,  3.49s/it]                                                       {'loss': 0.1603, 'grad_norm': 19.099796295166016, 'learning_rate': 5.901694915254238e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2518/6000 [2:27:27<3:22:22,  3.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:27:30<3:20:10,  3.45s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06165945529937744, 'learning_rate': 5.9e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2519/6000 [2:27:30<3:20:10,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:27:33<3:18:25,  3.42s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.2832372486591339, 'learning_rate': 5.8983050847457635e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2520/6000 [2:27:33<3:18:25,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:27:37<3:18:17,  3.42s/it]                                                       {'loss': 0.0599, 'grad_norm': 15.950701713562012, 'learning_rate': 5.896610169491526e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2521/6000 [2:27:37<3:18:17,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:27:41<3:26:21,  3.56s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.7288562059402466, 'learning_rate': 5.894915254237289e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2522/6000 [2:27:41<3:26:21,  3.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:27:44<3:23:15,  3.51s/it]                                                       {'loss': 0.1934, 'grad_norm': 14.439178466796875, 'learning_rate': 5.893220338983051e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2523/6000 [2:27:44<3:23:15,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:27:47<3:20:09,  3.45s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.9189969301223755, 'learning_rate': 5.891525423728814e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2524/6000 [2:27:47<3:20:09,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:27:51<3:19:57,  3.45s/it]                                                       {'loss': 0.3179, 'grad_norm': 35.02485656738281, 'learning_rate': 5.8898305084745765e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2525/6000 [2:27:51<3:19:57,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:27:55<3:29:30,  3.62s/it]                                                       {'loss': 0.0142, 'grad_norm': 2.7177062034606934, 'learning_rate': 5.88813559322034e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2526/6000 [2:27:55<3:29:30,  3.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:27:59<3:34:18,  3.70s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.2211333513259888, 'learning_rate': 5.886440677966102e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2527/6000 [2:27:59<3:34:18,  3.70s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:28:02<3:29:35,  3.62s/it]                                                       {'loss': 0.154, 'grad_norm': 8.6943998336792, 'learning_rate': 5.8847457627118655e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2528/6000 [2:28:02<3:29:35,  3.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:28:05<3:24:15,  3.53s/it]                                                       {'loss': 0.005, 'grad_norm': 1.1894363164901733, 'learning_rate': 5.883050847457628e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2529/6000 [2:28:05<3:24:15,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:28:09<3:24:05,  3.53s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.6880732178688049, 'learning_rate': 5.881355932203391e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2530/6000 [2:28:09<3:24:05,  3.53s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:28:12<3:22:41,  3.51s/it]                                                       {'loss': 0.074, 'grad_norm': 8.624034881591797, 'learning_rate': 5.879661016949153e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2531/6000 [2:28:12<3:22:41,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:28:16<3:21:09,  3.48s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1876148283481598, 'learning_rate': 5.877966101694915e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/6000 [2:28:16<3:21:09,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:28:19<3:21:15,  3.48s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.33512017130851746, 'learning_rate': 5.8762711864406785e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2533/6000 [2:28:19<3:21:15,  3.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:28:23<3:19:50,  3.46s/it]                                                       {'loss': 0.0215, 'grad_norm': 6.909658908843994, 'learning_rate': 5.874576271186441e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2534/6000 [2:28:23<3:19:50,  3.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:28:26<3:19:06,  3.45s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.41210079193115234, 'learning_rate': 5.872881355932204e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2535/6000 [2:28:26<3:19:06,  3.45s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:28:29<3:18:17,  3.43s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.8899250030517578, 'learning_rate': 5.871186440677966e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2536/6000 [2:28:29<3:18:17,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:28:33<3:18:27,  3.44s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.3962222635746002, 'learning_rate': 5.86949152542373e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2537/6000 [2:28:33<3:18:27,  3.44s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:28:36<3:17:31,  3.42s/it]                                                       {'loss': 0.0418, 'grad_norm': 8.038057327270508, 'learning_rate': 5.8677966101694915e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2538/6000 [2:28:36<3:17:31,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:28:40<3:16:25,  3.41s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8474498391151428, 'learning_rate': 5.866101694915255e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2539/6000 [2:28:40<3:16:25,  3.41s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:28:43<3:17:19,  3.42s/it]                                                       {'loss': 0.0772, 'grad_norm': 13.659597396850586, 'learning_rate': 5.864406779661017e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2540/6000 [2:28:43<3:17:19,  3.42s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:28:46<3:16:00,  3.40s/it]                                                       {'loss': 0.0546, 'grad_norm': 10.546581268310547, 'learning_rate': 5.8627118644067804e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2541/6000 [2:28:46<3:16:00,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:28:50<3:14:08,  3.37s/it]                                                       {'loss': 0.0035, 'grad_norm': 1.0810638666152954, 'learning_rate': 5.861016949152543e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2542/6000 [2:28:50<3:14:08,  3.37s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:28:53<3:14:11,  3.37s/it]                                                       {'loss': 0.0165, 'grad_norm': 3.603846788406372, 'learning_rate': 5.859322033898306e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2543/6000 [2:28:53<3:14:11,  3.37s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:28:57<3:15:52,  3.40s/it]                                                       {'loss': 0.0446, 'grad_norm': 8.645212173461914, 'learning_rate': 5.857627118644068e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2544/6000 [2:28:57<3:15:52,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:29:00<3:15:55,  3.40s/it]                                                       {'loss': 0.0675, 'grad_norm': 9.585665702819824, 'learning_rate': 5.855932203389831e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2545/6000 [2:29:00<3:15:55,  3.40s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:29:04<3:17:28,  3.43s/it]                                                       {'loss': 0.0701, 'grad_norm': 7.226640224456787, 'learning_rate': 5.854237288135593e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2546/6000 [2:29:04<3:17:28,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:29:07<3:17:17,  3.43s/it]                                                       {'loss': 0.008, 'grad_norm': 1.683566689491272, 'learning_rate': 5.852542372881357e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2547/6000 [2:29:07<3:17:17,  3.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:29:11<3:21:43,  3.51s/it]                                                       {'loss': 0.2753, 'grad_norm': 17.671110153198242, 'learning_rate': 5.850847457627119e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2548/6000 [2:29:11<3:21:43,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:29:14<3:21:43,  3.51s/it]                                                       {'loss': 0.0207, 'grad_norm': 6.205306529998779, 'learning_rate': 5.849152542372882e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2549/6000 [2:29:14<3:21:43,  3.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:29:18<3:20:35,  3.49s/it]                                                       {'loss': 0.0934, 'grad_norm': 8.179129600524902, 'learning_rate': 5.847457627118645e-06, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2550/6000 [2:29:18<3:20:35,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:29:21<3:18:43,  3.46s/it]                                                       {'loss': 0.2824, 'grad_norm': 22.353471755981445, 'learning_rate': 5.845762711864408e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2551/6000 [2:29:21<3:18:43,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:29:24<3:17:47,  3.44s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.7157502174377441, 'learning_rate': 5.84406779661017e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2552/6000 [2:29:24<3:17:47,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:29:28<3:15:27,  3.40s/it]                                                       {'loss': 0.0319, 'grad_norm': 6.8253865242004395, 'learning_rate': 5.842372881355932e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2553/6000 [2:29:28<3:15:27,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:29:32<3:23:03,  3.54s/it]                                                       {'loss': 0.025, 'grad_norm': 5.590821266174316, 'learning_rate': 5.840677966101695e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2554/6000 [2:29:32<3:23:03,  3.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:29:35<3:20:14,  3.49s/it]                                                       {'loss': 0.0086, 'grad_norm': 3.7821874618530273, 'learning_rate': 5.838983050847458e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2555/6000 [2:29:35<3:20:14,  3.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:29:38<3:18:11,  3.45s/it]                                                       {'loss': 0.132, 'grad_norm': 13.519176483154297, 'learning_rate': 5.837288135593221e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2556/6000 [2:29:38<3:18:11,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:29:42<3:17:21,  3.44s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.2974354922771454, 'learning_rate': 5.8355932203389835e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2557/6000 [2:29:42<3:17:21,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:29:45<3:17:20,  3.44s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.8112910985946655, 'learning_rate': 5.833898305084747e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2558/6000 [2:29:45<3:17:20,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:29:49<3:16:41,  3.43s/it]                                                       {'loss': 0.1161, 'grad_norm': 12.8722562789917, 'learning_rate': 5.832203389830508e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2559/6000 [2:29:49<3:16:41,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:29:52<3:17:40,  3.45s/it]                                                       {'loss': 0.0611, 'grad_norm': 12.590271949768066, 'learning_rate': 5.830508474576272e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2560/6000 [2:29:52<3:17:40,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:29:55<3:17:50,  3.45s/it]                                                       {'loss': 0.0579, 'grad_norm': 9.846163749694824, 'learning_rate': 5.828813559322034e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2561/6000 [2:29:55<3:17:50,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:29:59<3:18:13,  3.46s/it]                                                       {'loss': 0.0883, 'grad_norm': 9.141380310058594, 'learning_rate': 5.827118644067797e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2562/6000 [2:29:59<3:18:13,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:30:02<3:15:17,  3.41s/it]                                                       {'loss': 0.2298, 'grad_norm': 15.0438232421875, 'learning_rate': 5.82542372881356e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2563/6000 [2:30:02<3:15:17,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:30:06<3:19:23,  3.48s/it]                                                       {'loss': 0.0269, 'grad_norm': 5.2964043617248535, 'learning_rate': 5.823728813559323e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2564/6000 [2:30:06<3:19:23,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:30:09<3:17:07,  3.44s/it]                                                       {'loss': 0.0124, 'grad_norm': 3.5258190631866455, 'learning_rate': 5.8220338983050854e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2565/6000 [2:30:09<3:17:07,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:30:13<3:16:18,  3.43s/it]                                                       {'loss': 0.2138, 'grad_norm': 15.38827133178711, 'learning_rate': 5.820338983050849e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2566/6000 [2:30:13<3:16:18,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:30:16<3:21:56,  3.53s/it]                                                       {'loss': 0.0414, 'grad_norm': 12.858589172363281, 'learning_rate': 5.81864406779661e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2567/6000 [2:30:16<3:21:56,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:30:20<3:24:40,  3.58s/it]                                                       {'loss': 0.013, 'grad_norm': 3.6058735847473145, 'learning_rate': 5.8169491525423736e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2568/6000 [2:30:20<3:24:40,  3.58s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:30:24<3:22:42,  3.54s/it]                                                       {'loss': 0.1674, 'grad_norm': 21.105520248413086, 'learning_rate': 5.815254237288136e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2569/6000 [2:30:24<3:22:42,  3.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:30:27<3:21:29,  3.52s/it]                                                       {'loss': 0.1014, 'grad_norm': 10.416266441345215, 'learning_rate': 5.813559322033899e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2570/6000 [2:30:27<3:21:29,  3.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:30:30<3:18:16,  3.47s/it]                                                       {'loss': 0.0181, 'grad_norm': 3.3524935245513916, 'learning_rate': 5.811864406779662e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2571/6000 [2:30:30<3:18:16,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:30:34<3:16:49,  3.44s/it]                                                       {'loss': 0.0077, 'grad_norm': 2.5117108821868896, 'learning_rate': 5.810169491525425e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2572/6000 [2:30:34<3:16:49,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:30:37<3:15:27,  3.42s/it]                                                       {'loss': 0.0222, 'grad_norm': 4.892141342163086, 'learning_rate': 5.8084745762711865e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2573/6000 [2:30:37<3:15:27,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:30:41<3:16:16,  3.44s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.8680288791656494, 'learning_rate': 5.806779661016949e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2574/6000 [2:30:41<3:16:16,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:30:44<3:17:52,  3.47s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.3207567632198334, 'learning_rate': 5.805084745762712e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2575/6000 [2:30:44<3:17:52,  3.47s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:30:48<3:15:56,  3.43s/it]                                                       {'loss': 0.1196, 'grad_norm': 17.904794692993164, 'learning_rate': 5.803389830508475e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2576/6000 [2:30:48<3:15:56,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:30:51<3:15:00,  3.42s/it]                                                       {'loss': 0.0585, 'grad_norm': 10.044954299926758, 'learning_rate': 5.801694915254238e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2577/6000 [2:30:51<3:15:00,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:30:54<3:14:41,  3.41s/it]                                                       {'loss': 0.0892, 'grad_norm': 15.246657371520996, 'learning_rate': 5.8e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2578/6000 [2:30:54<3:14:41,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:30:58<3:13:47,  3.40s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.5979965925216675, 'learning_rate': 5.798305084745764e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2579/6000 [2:30:58<3:13:47,  3.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:31:01<3:14:55,  3.42s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.44300517439842224, 'learning_rate': 5.796610169491525e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2580/6000 [2:31:01<3:14:55,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:31:05<3:16:36,  3.45s/it]                                                       {'loss': 0.0454, 'grad_norm': 8.723007202148438, 'learning_rate': 5.7949152542372885e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2581/6000 [2:31:05<3:16:36,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:31:08<3:22:47,  3.56s/it]                                                       {'loss': 0.3229, 'grad_norm': 24.326332092285156, 'learning_rate': 5.793220338983051e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2582/6000 [2:31:08<3:22:47,  3.56s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:31:12<3:20:14,  3.52s/it]                                                       {'loss': 0.3361, 'grad_norm': 16.060148239135742, 'learning_rate': 5.791525423728814e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2583/6000 [2:31:12<3:20:14,  3.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:31:15<3:16:44,  3.46s/it]                                                       {'loss': 0.1913, 'grad_norm': 12.921175956726074, 'learning_rate': 5.789830508474577e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2584/6000 [2:31:15<3:16:44,  3.46s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:31:19<3:15:34,  3.44s/it]                                                       {'loss': 0.1076, 'grad_norm': 6.0882673263549805, 'learning_rate': 5.78813559322034e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2585/6000 [2:31:19<3:15:34,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:31:22<3:14:21,  3.42s/it]                                                       {'loss': 0.2138, 'grad_norm': 11.101791381835938, 'learning_rate': 5.786440677966102e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2586/6000 [2:31:22<3:14:21,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:31:25<3:12:50,  3.39s/it]                                                       {'loss': 0.0666, 'grad_norm': 10.850476264953613, 'learning_rate': 5.784745762711866e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2587/6000 [2:31:25<3:12:50,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:31:29<3:20:58,  3.53s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.18535317480564117, 'learning_rate': 5.783050847457627e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2588/6000 [2:31:29<3:20:58,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:31:33<3:22:54,  3.57s/it]                                                       {'loss': 0.0094, 'grad_norm': 2.359936475753784, 'learning_rate': 5.7813559322033905e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2589/6000 [2:31:33<3:22:54,  3.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:31:36<3:20:44,  3.53s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.0980703830718994, 'learning_rate': 5.779661016949153e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2590/6000 [2:31:36<3:20:44,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:31:40<3:17:32,  3.48s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.43730485439300537, 'learning_rate': 5.777966101694916e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2591/6000 [2:31:40<3:17:32,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:31:43<3:14:51,  3.43s/it]                                                       {'loss': 0.1979, 'grad_norm': 24.89008140563965, 'learning_rate': 5.776271186440679e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2592/6000 [2:31:43<3:14:51,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:31:46<3:13:39,  3.41s/it]                                                       {'loss': 0.0131, 'grad_norm': 4.7130584716796875, 'learning_rate': 5.774576271186441e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2593/6000 [2:31:46<3:13:39,  3.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:31:50<3:12:25,  3.39s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.8176013231277466, 'learning_rate': 5.772881355932204e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2594/6000 [2:31:50<3:12:25,  3.39s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:31:53<3:15:27,  3.44s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.24431051313877106, 'learning_rate': 5.771186440677966e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2595/6000 [2:31:53<3:15:27,  3.44s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:31:57<3:17:13,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.23987509310245514, 'learning_rate': 5.769491525423729e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2596/6000 [2:31:57<3:17:13,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:32:00<3:15:53,  3.45s/it]                                                       {'loss': 0.1124, 'grad_norm': 11.962349891662598, 'learning_rate': 5.7677966101694916e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2597/6000 [2:32:00<3:15:53,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:32:04<3:14:13,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07552527636289597, 'learning_rate': 5.766101694915255e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2598/6000 [2:32:04<3:14:13,  3.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:32:07<3:13:54,  3.42s/it]                                                       {'loss': 0.0076, 'grad_norm': 2.2797532081604004, 'learning_rate': 5.764406779661017e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2599/6000 [2:32:07<3:13:54,  3.42s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:32:10<3:13:10,  3.41s/it]                                                       {'loss': 0.005, 'grad_norm': 1.7973339557647705, 'learning_rate': 5.7627118644067805e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2600/6000 [2:32:10<3:13:10,  3.41s/it][2025-11-07 01:23:20,310] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600
[2025-11-07 01:23:20,324] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:23:20,997] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:32:16<3:57:22,  4.19s/it]                                                       {'loss': 0.2272, 'grad_norm': 17.094860076904297, 'learning_rate': 5.761016949152542e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2601/6000 [2:32:16<3:57:22,  4.19s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:32:20<3:43:21,  3.94s/it]                                                       {'loss': 0.0289, 'grad_norm': 6.030241966247559, 'learning_rate': 5.759322033898305e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2602/6000 [2:32:20<3:43:21,  3.94s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:32:23<3:34:13,  3.78s/it]                                                       {'loss': 0.0984, 'grad_norm': 8.366290092468262, 'learning_rate': 5.757627118644068e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2603/6000 [2:32:23<3:34:13,  3.78s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:32:27<3:28:13,  3.68s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5307856798171997, 'learning_rate': 5.755932203389831e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/6000 [2:32:27<3:28:13,  3.68s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:32:30<3:23:40,  3.60s/it]                                                       {'loss': 0.0522, 'grad_norm': 3.472599506378174, 'learning_rate': 5.7542372881355935e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2605/6000 [2:32:30<3:23:40,  3.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:32:33<3:19:42,  3.53s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.696239471435547, 'learning_rate': 5.752542372881357e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2606/6000 [2:32:33<3:19:42,  3.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:32:37<3:16:34,  3.48s/it]                                                       {'loss': 0.0278, 'grad_norm': 7.341517925262451, 'learning_rate': 5.750847457627119e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2607/6000 [2:32:37<3:16:34,  3.48s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:32:40<3:15:07,  3.45s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.3228975534439087, 'learning_rate': 5.7491525423728825e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2608/6000 [2:32:40<3:15:07,  3.45s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:32:43<3:14:12,  3.44s/it]                                                       {'loss': 0.0351, 'grad_norm': 10.057108879089355, 'learning_rate': 5.747457627118644e-06, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2609/6000 [2:32:43<3:14:12,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:32:47<3:13:32,  3.43s/it]                                                       {'loss': 0.0146, 'grad_norm': 4.1002583503723145, 'learning_rate': 5.745762711864407e-06, 'epoch': 0.43}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2610/6000 [2:32:47<3:13:32,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:32:50<3:14:14,  3.44s/it]                                                       {'loss': 0.1541, 'grad_norm': 10.19158935546875, 'learning_rate': 5.74406779661017e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2611/6000 [2:32:50<3:14:14,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:32:54<3:11:36,  3.39s/it]                                                       {'loss': 0.0, 'grad_norm': 0.007836231030523777, 'learning_rate': 5.742372881355933e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2612/6000 [2:32:54<3:11:36,  3.39s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:32:57<3:17:27,  3.50s/it]                                                       {'loss': 0.0619, 'grad_norm': 7.6785888671875, 'learning_rate': 5.7406779661016955e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2613/6000 [2:32:57<3:17:27,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:33:01<3:15:03,  3.46s/it]                                                       {'loss': 0.0394, 'grad_norm': 5.692783832550049, 'learning_rate': 5.738983050847458e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2614/6000 [2:33:01<3:15:03,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:33:04<3:13:45,  3.43s/it]                                                       {'loss': 0.0567, 'grad_norm': 8.441411972045898, 'learning_rate': 5.737288135593221e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2615/6000 [2:33:04<3:13:45,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:33:08<3:12:56,  3.42s/it]                                                       {'loss': 0.2038, 'grad_norm': 11.861159324645996, 'learning_rate': 5.735593220338983e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2616/6000 [2:33:08<3:12:56,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:33:11<3:11:10,  3.39s/it]                                                       {'loss': 0.0703, 'grad_norm': 14.939315795898438, 'learning_rate': 5.733898305084746e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2617/6000 [2:33:11<3:11:10,  3.39s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:33:14<3:11:31,  3.40s/it]                                                       {'loss': 0.1048, 'grad_norm': 15.651022911071777, 'learning_rate': 5.7322033898305084e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2618/6000 [2:33:14<3:11:31,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:33:18<3:19:35,  3.54s/it]                                                       {'loss': 0.0264, 'grad_norm': 6.497940540313721, 'learning_rate': 5.730508474576272e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2619/6000 [2:33:18<3:19:35,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:33:22<3:22:58,  3.60s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.1188324689865112, 'learning_rate': 5.728813559322034e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2620/6000 [2:33:22<3:22:58,  3.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:33:25<3:23:04,  3.61s/it]                                                       {'loss': 0.0526, 'grad_norm': 9.109872817993164, 'learning_rate': 5.727118644067797e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2621/6000 [2:33:25<3:23:04,  3.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:33:29<3:21:05,  3.57s/it]                                                       {'loss': 0.0696, 'grad_norm': 7.596648693084717, 'learning_rate': 5.72542372881356e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2622/6000 [2:33:29<3:21:05,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:33:32<3:18:04,  3.52s/it]                                                       {'loss': 0.0085, 'grad_norm': 2.255661964416504, 'learning_rate': 5.723728813559323e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2623/6000 [2:33:32<3:18:04,  3.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:33:36<3:16:39,  3.50s/it]                                                       {'loss': 0.0176, 'grad_norm': 5.616505146026611, 'learning_rate': 5.722033898305085e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2624/6000 [2:33:36<3:16:39,  3.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:33:39<3:16:17,  3.49s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.9440791606903076, 'learning_rate': 5.720338983050848e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2625/6000 [2:33:39<3:16:17,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:33:43<3:18:24,  3.53s/it]                                                       {'loss': 0.0941, 'grad_norm': 12.77236270904541, 'learning_rate': 5.71864406779661e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2626/6000 [2:33:43<3:18:24,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:33:46<3:18:21,  3.53s/it]                                                       {'loss': 0.1113, 'grad_norm': 9.18964672088623, 'learning_rate': 5.716949152542374e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2627/6000 [2:33:46<3:18:21,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:33:50<3:16:23,  3.49s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015595274977385998, 'learning_rate': 5.715254237288136e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2628/6000 [2:33:50<3:16:23,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:33:53<3:15:18,  3.48s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.9804503321647644, 'learning_rate': 5.713559322033899e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2629/6000 [2:33:53<3:15:18,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:33:57<3:13:45,  3.45s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04103058949112892, 'learning_rate': 5.711864406779661e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2630/6000 [2:33:57<3:13:45,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:34:00<3:11:34,  3.41s/it]                                                       {'loss': 0.0145, 'grad_norm': 2.969423532485962, 'learning_rate': 5.710169491525425e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2631/6000 [2:34:00<3:11:34,  3.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:34:03<3:10:42,  3.40s/it]                                                       {'loss': 0.1487, 'grad_norm': 12.709060668945312, 'learning_rate': 5.708474576271187e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2632/6000 [2:34:03<3:10:42,  3.40s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:34:07<3:09:58,  3.39s/it]                                                       {'loss': 0.003, 'grad_norm': 0.7006343603134155, 'learning_rate': 5.70677966101695e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2633/6000 [2:34:07<3:09:58,  3.39s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:34:10<3:12:03,  3.42s/it]                                                       {'loss': 0.0123, 'grad_norm': 4.1821608543396, 'learning_rate': 5.705084745762712e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2634/6000 [2:34:10<3:12:03,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:34:14<3:13:13,  3.45s/it]                                                       {'loss': 0.0282, 'grad_norm': 7.359250545501709, 'learning_rate': 5.703389830508475e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2635/6000 [2:34:14<3:13:13,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:34:18<3:27:31,  3.70s/it]                                                       {'loss': 0.057, 'grad_norm': 7.43747615814209, 'learning_rate': 5.701694915254238e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2636/6000 [2:34:18<3:27:31,  3.70s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:34:22<3:24:43,  3.65s/it]                                                       {'loss': 0.1582, 'grad_norm': 11.380605697631836, 'learning_rate': 5.7e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2637/6000 [2:34:22<3:24:43,  3.65s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:34:25<3:21:23,  3.59s/it]                                                       {'loss': 0.1044, 'grad_norm': 9.700592994689941, 'learning_rate': 5.698305084745763e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2638/6000 [2:34:25<3:21:23,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:34:28<3:18:33,  3.54s/it]                                                       {'loss': 0.0319, 'grad_norm': 6.484498500823975, 'learning_rate': 5.696610169491525e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2639/6000 [2:34:28<3:18:33,  3.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:34:32<3:19:47,  3.57s/it]                                                       {'loss': 0.1495, 'grad_norm': 14.679059982299805, 'learning_rate': 5.694915254237289e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2640/6000 [2:34:32<3:19:47,  3.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:34:36<3:26:15,  3.68s/it]                                                       {'loss': 0.1212, 'grad_norm': 14.61391830444336, 'learning_rate': 5.693220338983051e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2641/6000 [2:34:36<3:26:15,  3.68s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:34:39<3:20:43,  3.59s/it]                                                       {'loss': 0.013, 'grad_norm': 4.507014274597168, 'learning_rate': 5.691525423728814e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2642/6000 [2:34:39<3:20:43,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:34:43<3:17:23,  3.53s/it]                                                       {'loss': 0.0221, 'grad_norm': 6.001445770263672, 'learning_rate': 5.689830508474577e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2643/6000 [2:34:43<3:17:23,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:34:46<3:13:51,  3.47s/it]                                                       {'loss': 0.1911, 'grad_norm': 18.799293518066406, 'learning_rate': 5.68813559322034e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2644/6000 [2:34:46<3:13:51,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:34:50<3:13:27,  3.46s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.414630651473999, 'learning_rate': 5.686440677966102e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2645/6000 [2:34:50<3:13:27,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:34:53<3:11:18,  3.42s/it]                                                       {'loss': 0.0149, 'grad_norm': 3.0714662075042725, 'learning_rate': 5.684745762711865e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2646/6000 [2:34:53<3:11:18,  3.42s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:34:56<3:14:23,  3.48s/it]                                                       {'loss': 0.0414, 'grad_norm': 6.862728595733643, 'learning_rate': 5.683050847457627e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2647/6000 [2:34:56<3:14:23,  3.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:35:00<3:12:06,  3.44s/it]                                                       {'loss': 0.2186, 'grad_norm': 16.99671745300293, 'learning_rate': 5.6813559322033906e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2648/6000 [2:35:00<3:12:06,  3.44s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:35:03<3:13:43,  3.47s/it]                                                       {'loss': 0.1012, 'grad_norm': 12.170977592468262, 'learning_rate': 5.679661016949153e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2649/6000 [2:35:03<3:13:43,  3.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:35:07<3:12:54,  3.46s/it]                                                       {'loss': 0.0044, 'grad_norm': 0.726269006729126, 'learning_rate': 5.677966101694916e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2650/6000 [2:35:07<3:12:54,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:35:10<3:10:19,  3.41s/it]                                                       {'loss': 0.0236, 'grad_norm': 7.150852203369141, 'learning_rate': 5.676271186440679e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2651/6000 [2:35:10<3:10:19,  3.41s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:35:14<3:12:23,  3.45s/it]                                                       {'loss': 0.0711, 'grad_norm': 10.961858749389648, 'learning_rate': 5.674576271186442e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2652/6000 [2:35:14<3:12:23,  3.45s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:35:18<3:19:37,  3.58s/it]                                                       {'loss': 0.0823, 'grad_norm': 6.513218879699707, 'learning_rate': 5.6728813559322035e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2653/6000 [2:35:18<3:19:37,  3.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:35:21<3:17:03,  3.53s/it]                                                       {'loss': 0.0307, 'grad_norm': 4.639518737792969, 'learning_rate': 5.671186440677967e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/6000 [2:35:21<3:17:03,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:35:24<3:14:32,  3.49s/it]                                                       {'loss': 0.0598, 'grad_norm': 9.882100105285645, 'learning_rate': 5.669491525423729e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2655/6000 [2:35:24<3:14:32,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:35:28<3:11:11,  3.43s/it]                                                       {'loss': 0.001, 'grad_norm': 0.4017302393913269, 'learning_rate': 5.667796610169492e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2656/6000 [2:35:28<3:11:11,  3.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:35:32<3:20:32,  3.60s/it]                                                       {'loss': 0.1819, 'grad_norm': 13.072888374328613, 'learning_rate': 5.666101694915255e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2657/6000 [2:35:32<3:20:32,  3.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:35:35<3:16:19,  3.52s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4710257649421692, 'learning_rate': 5.6644067796610165e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2658/6000 [2:35:35<3:16:19,  3.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:35:39<3:21:35,  3.62s/it]                                                       {'loss': 0.063, 'grad_norm': 8.265000343322754, 'learning_rate': 5.662711864406781e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2659/6000 [2:35:39<3:21:35,  3.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:35:43<3:24:26,  3.67s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.4805842638015747, 'learning_rate': 5.661016949152542e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2660/6000 [2:35:43<3:24:26,  3.67s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:35:46<3:19:45,  3.59s/it]                                                       {'loss': 0.0687, 'grad_norm': 12.418513298034668, 'learning_rate': 5.6593220338983055e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2661/6000 [2:35:46<3:19:45,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:35:49<3:16:27,  3.53s/it]                                                       {'loss': 0.0164, 'grad_norm': 3.6677093505859375, 'learning_rate': 5.657627118644068e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2662/6000 [2:35:49<3:16:27,  3.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:35:53<3:14:00,  3.49s/it]                                                       {'loss': 0.0943, 'grad_norm': 10.110101699829102, 'learning_rate': 5.655932203389831e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2663/6000 [2:35:53<3:14:00,  3.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:35:56<3:12:08,  3.46s/it]                                                       {'loss': 0.0195, 'grad_norm': 5.420547008514404, 'learning_rate': 5.654237288135594e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2664/6000 [2:35:56<3:12:08,  3.46s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:36:00<3:15:41,  3.52s/it]                                                       {'loss': 0.0613, 'grad_norm': 7.62955904006958, 'learning_rate': 5.652542372881357e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2665/6000 [2:36:00<3:15:41,  3.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:36:03<3:15:15,  3.51s/it]                                                       {'loss': 0.0737, 'grad_norm': 9.466743469238281, 'learning_rate': 5.6508474576271185e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2666/6000 [2:36:03<3:15:15,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:36:07<3:15:08,  3.51s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03643641620874405, 'learning_rate': 5.649152542372882e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2667/6000 [2:36:07<3:15:08,  3.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:36:11<3:19:24,  3.59s/it]                                                       {'loss': 0.0622, 'grad_norm': 14.104764938354492, 'learning_rate': 5.647457627118644e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2668/6000 [2:36:11<3:19:24,  3.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:36:14<3:16:50,  3.55s/it]                                                       {'loss': 0.0134, 'grad_norm': 4.653900623321533, 'learning_rate': 5.6457627118644075e-06, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2669/6000 [2:36:14<3:16:50,  3.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:36:17<3:12:58,  3.48s/it]                                                       {'loss': 0.1007, 'grad_norm': 10.27764892578125, 'learning_rate': 5.64406779661017e-06, 'epoch': 0.45}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2670/6000 [2:36:17<3:12:58,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:36:21<3:12:09,  3.46s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.6506779193878174, 'learning_rate': 5.642372881355933e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2671/6000 [2:36:21<3:12:09,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:36:24<3:12:13,  3.47s/it]                                                       {'loss': 0.0455, 'grad_norm': 7.283166408538818, 'learning_rate': 5.640677966101696e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2672/6000 [2:36:24<3:12:13,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:36:28<3:13:24,  3.49s/it]                                                       {'loss': 0.0034, 'grad_norm': 1.1315321922302246, 'learning_rate': 5.638983050847459e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2673/6000 [2:36:28<3:13:24,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:36:31<3:12:07,  3.47s/it]                                                       {'loss': 0.0352, 'grad_norm': 6.324519634246826, 'learning_rate': 5.6372881355932204e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2674/6000 [2:36:31<3:12:07,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:36:35<3:17:08,  3.56s/it]                                                       {'loss': 0.0992, 'grad_norm': 10.440348625183105, 'learning_rate': 5.635593220338984e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2675/6000 [2:36:35<3:17:08,  3.56s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:36:38<3:13:19,  3.49s/it]                                                       {'loss': 0.0354, 'grad_norm': 5.3164801597595215, 'learning_rate': 5.633898305084746e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2676/6000 [2:36:38<3:13:19,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:36:42<3:13:42,  3.50s/it]                                                       {'loss': 0.0216, 'grad_norm': 3.964714288711548, 'learning_rate': 5.6322033898305086e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2677/6000 [2:36:42<3:13:42,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:36:45<3:13:06,  3.49s/it]                                                       {'loss': 0.0764, 'grad_norm': 12.46446418762207, 'learning_rate': 5.630508474576272e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2678/6000 [2:36:45<3:13:06,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:36:49<3:10:26,  3.44s/it]                                                       {'loss': 0.0788, 'grad_norm': 16.115909576416016, 'learning_rate': 5.628813559322034e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2679/6000 [2:36:49<3:10:26,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:36:52<3:12:38,  3.48s/it]                                                       {'loss': 0.0088, 'grad_norm': 2.5716984272003174, 'learning_rate': 5.6271186440677975e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2680/6000 [2:36:52<3:12:38,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:36:56<3:11:30,  3.46s/it]                                                       {'loss': 0.003, 'grad_norm': 0.4645713269710541, 'learning_rate': 5.625423728813559e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2681/6000 [2:36:56<3:11:30,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:36:59<3:09:59,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06497795879840851, 'learning_rate': 5.623728813559322e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2682/6000 [2:36:59<3:09:59,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:37:02<3:08:53,  3.42s/it]                                                       {'loss': 0.113, 'grad_norm': 18.641202926635742, 'learning_rate': 5.622033898305085e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2683/6000 [2:37:02<3:08:53,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:37:06<3:07:55,  3.40s/it]                                                       {'loss': 0.398, 'grad_norm': 21.28363800048828, 'learning_rate': 5.620338983050848e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2684/6000 [2:37:06<3:07:55,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:37:09<3:07:19,  3.39s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.7235006093978882, 'learning_rate': 5.6186440677966105e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2685/6000 [2:37:09<3:07:19,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:37:13<3:08:33,  3.41s/it]                                                       {'loss': 0.1304, 'grad_norm': 6.059354305267334, 'learning_rate': 5.616949152542374e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2686/6000 [2:37:13<3:08:33,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:37:16<3:08:24,  3.41s/it]                                                       {'loss': 0.0132, 'grad_norm': 3.146108865737915, 'learning_rate': 5.615254237288136e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2687/6000 [2:37:16<3:08:24,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:37:19<3:08:38,  3.42s/it]                                                       {'loss': 0.0475, 'grad_norm': 7.131163120269775, 'learning_rate': 5.6135593220338995e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2688/6000 [2:37:19<3:08:38,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:37:23<3:08:16,  3.41s/it]                                                       {'loss': 0.0301, 'grad_norm': 9.050765991210938, 'learning_rate': 5.611864406779661e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2689/6000 [2:37:23<3:08:16,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:37:26<3:07:12,  3.39s/it]                                                       {'loss': 0.2411, 'grad_norm': 14.823684692382812, 'learning_rate': 5.610169491525424e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2690/6000 [2:37:26<3:07:12,  3.39s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:37:30<3:07:30,  3.40s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.45204660296440125, 'learning_rate': 5.608474576271187e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2691/6000 [2:37:30<3:07:30,  3.40s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:37:33<3:07:47,  3.41s/it]                                                       {'loss': 0.0339, 'grad_norm': 7.706723690032959, 'learning_rate': 5.60677966101695e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2692/6000 [2:37:33<3:07:47,  3.41s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:37:36<3:08:36,  3.42s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.367099791765213, 'learning_rate': 5.6050847457627125e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2693/6000 [2:37:36<3:08:36,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:37:40<3:14:21,  3.53s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.044641949236392975, 'learning_rate': 5.603389830508476e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2694/6000 [2:37:40<3:14:21,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:37:44<3:15:58,  3.56s/it]                                                       {'loss': 0.0048, 'grad_norm': 2.210207462310791, 'learning_rate': 5.601694915254237e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2695/6000 [2:37:44<3:15:58,  3.56s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:37:47<3:14:26,  3.53s/it]                                                       {'loss': 0.1464, 'grad_norm': 17.42233657836914, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2696/6000 [2:37:47<3:14:26,  3.53s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:37:51<3:13:57,  3.52s/it]                                                       {'loss': 0.0385, 'grad_norm': 6.9395599365234375, 'learning_rate': 5.598305084745763e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2697/6000 [2:37:51<3:13:57,  3.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:37:54<3:11:45,  3.48s/it]                                                       {'loss': 0.0433, 'grad_norm': 3.546332359313965, 'learning_rate': 5.5966101694915254e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2698/6000 [2:37:54<3:11:45,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:37:58<3:09:26,  3.44s/it]                                                       {'loss': 0.0126, 'grad_norm': 3.133746385574341, 'learning_rate': 5.594915254237289e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2699/6000 [2:37:58<3:09:26,  3.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:38:01<3:08:45,  3.43s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.260340690612793, 'learning_rate': 5.593220338983051e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2700/6000 [2:38:01<3:08:45,  3.43s/it][2025-11-07 01:29:10,979] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700
[2025-11-07 01:29:10,996] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:29:11,735] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:38:07<3:57:19,  4.32s/it]                                                       {'loss': 0.1521, 'grad_norm': 10.726634979248047, 'learning_rate': 5.591525423728814e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2701/6000 [2:38:07<3:57:19,  4.32s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:38:11<3:49:07,  4.17s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.43434980511665344, 'learning_rate': 5.589830508474576e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2702/6000 [2:38:11<3:49:07,  4.17s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:38:15<3:37:33,  3.96s/it]                                                       {'loss': 0.0087, 'grad_norm': 2.4617791175842285, 'learning_rate': 5.588135593220339e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2703/6000 [2:38:15<3:37:33,  3.96s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:38:18<3:29:29,  3.81s/it]                                                       {'loss': 0.2072, 'grad_norm': 15.242840766906738, 'learning_rate': 5.586440677966102e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2704/6000 [2:38:18<3:29:29,  3.81s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:38:22<3:24:56,  3.73s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.6479768753051758, 'learning_rate': 5.584745762711865e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/6000 [2:38:22<3:24:56,  3.73s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:38:25<3:18:41,  3.62s/it]                                                       {'loss': 0.2315, 'grad_norm': 26.061479568481445, 'learning_rate': 5.583050847457627e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2706/6000 [2:38:25<3:18:41,  3.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:38:28<3:15:49,  3.57s/it]                                                       {'loss': 0.0289, 'grad_norm': 6.236100196838379, 'learning_rate': 5.581355932203391e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2707/6000 [2:38:28<3:15:49,  3.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:38:32<3:19:35,  3.64s/it]                                                       {'loss': 0.0227, 'grad_norm': 5.500180244445801, 'learning_rate': 5.579661016949153e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2708/6000 [2:38:32<3:19:35,  3.64s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:38:36<3:19:03,  3.63s/it]                                                       {'loss': 0.1077, 'grad_norm': 14.990093231201172, 'learning_rate': 5.577966101694916e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2709/6000 [2:38:36<3:19:03,  3.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:38:39<3:17:22,  3.60s/it]                                                       {'loss': 0.0229, 'grad_norm': 3.006206512451172, 'learning_rate': 5.576271186440678e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2710/6000 [2:38:39<3:17:22,  3.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:38:43<3:14:16,  3.54s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.168182834982872, 'learning_rate': 5.574576271186441e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2711/6000 [2:38:43<3:14:16,  3.54s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:38:46<3:14:08,  3.54s/it]                                                       {'loss': 0.0083, 'grad_norm': 2.891887664794922, 'learning_rate': 5.572881355932204e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2712/6000 [2:38:46<3:14:08,  3.54s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:38:50<3:11:25,  3.49s/it]                                                       {'loss': 0.0158, 'grad_norm': 2.980229377746582, 'learning_rate': 5.571186440677967e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2713/6000 [2:38:50<3:11:25,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:38:53<3:09:20,  3.46s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.8056679964065552, 'learning_rate': 5.569491525423729e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2714/6000 [2:38:53<3:09:20,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:38:57<3:10:38,  3.48s/it]                                                       {'loss': 0.0374, 'grad_norm': 7.48711633682251, 'learning_rate': 5.567796610169493e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2715/6000 [2:38:57<3:10:38,  3.48s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:39:00<3:12:08,  3.51s/it]                                                       {'loss': 0.2118, 'grad_norm': 17.3924503326416, 'learning_rate': 5.566101694915255e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2716/6000 [2:39:00<3:12:08,  3.51s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:39:04<3:09:00,  3.45s/it]                                                       {'loss': 0.0236, 'grad_norm': 3.4752085208892822, 'learning_rate': 5.564406779661018e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2717/6000 [2:39:04<3:09:00,  3.45s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:39:07<3:06:57,  3.42s/it]                                                       {'loss': 0.0841, 'grad_norm': 10.872138977050781, 'learning_rate': 5.56271186440678e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2718/6000 [2:39:07<3:06:57,  3.42s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:39:10<3:07:22,  3.43s/it]                                                       {'loss': 0.1304, 'grad_norm': 10.769177436828613, 'learning_rate': 5.561016949152542e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2719/6000 [2:39:10<3:07:22,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:39:14<3:10:36,  3.49s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.8396475315093994, 'learning_rate': 5.559322033898306e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2720/6000 [2:39:14<3:10:36,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:39:17<3:09:37,  3.47s/it]                                                       {'loss': 0.0339, 'grad_norm': 7.106360912322998, 'learning_rate': 5.557627118644068e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2721/6000 [2:39:17<3:09:37,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:39:21<3:09:32,  3.47s/it]                                                       {'loss': 0.0882, 'grad_norm': 11.225627899169922, 'learning_rate': 5.555932203389831e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2722/6000 [2:39:21<3:09:32,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:39:24<3:07:32,  3.43s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.022482115775346756, 'learning_rate': 5.554237288135593e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2723/6000 [2:39:24<3:07:32,  3.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:39:28<3:10:42,  3.49s/it]                                                       {'loss': 0.0346, 'grad_norm': 4.5622687339782715, 'learning_rate': 5.552542372881356e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2724/6000 [2:39:28<3:10:42,  3.49s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:39:31<3:11:09,  3.50s/it]                                                       {'loss': 0.0859, 'grad_norm': 13.536385536193848, 'learning_rate': 5.550847457627119e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2725/6000 [2:39:31<3:11:09,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:39:35<3:10:42,  3.50s/it]                                                       {'loss': 0.0192, 'grad_norm': 6.338489532470703, 'learning_rate': 5.549152542372882e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2726/6000 [2:39:35<3:10:42,  3.50s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:39:38<3:09:11,  3.47s/it]                                                       {'loss': 0.1036, 'grad_norm': 16.10491943359375, 'learning_rate': 5.547457627118644e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2727/6000 [2:39:38<3:09:11,  3.47s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:39:42<3:08:26,  3.46s/it]                                                       {'loss': 0.0313, 'grad_norm': 4.446895599365234, 'learning_rate': 5.5457627118644076e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2728/6000 [2:39:42<3:08:26,  3.46s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:39:45<3:08:50,  3.46s/it]                                                       {'loss': 0.0525, 'grad_norm': 8.669565200805664, 'learning_rate': 5.54406779661017e-06, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2729/6000 [2:39:45<3:08:50,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:39:48<3:06:16,  3.42s/it]                                                       {'loss': 0.006, 'grad_norm': 1.8528523445129395, 'learning_rate': 5.542372881355933e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2730/6000 [2:39:48<3:06:16,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:39:52<3:06:44,  3.43s/it]                                                       {'loss': 0.006, 'grad_norm': 2.1832163333892822, 'learning_rate': 5.540677966101695e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2731/6000 [2:39:52<3:06:44,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:39:55<3:07:39,  3.45s/it]                                                       {'loss': 0.028, 'grad_norm': 7.105621337890625, 'learning_rate': 5.538983050847458e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2732/6000 [2:39:55<3:07:39,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:39:59<3:06:23,  3.42s/it]                                                       {'loss': 0.2538, 'grad_norm': 18.883203506469727, 'learning_rate': 5.5372881355932205e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2733/6000 [2:39:59<3:06:23,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:40:03<3:12:42,  3.54s/it]                                                       {'loss': 0.0226, 'grad_norm': 9.422933578491211, 'learning_rate': 5.535593220338984e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2734/6000 [2:40:03<3:12:42,  3.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:40:06<3:11:39,  3.52s/it]                                                       {'loss': 0.0324, 'grad_norm': 7.586888313293457, 'learning_rate': 5.533898305084746e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2735/6000 [2:40:06<3:11:39,  3.52s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:40:10<3:14:37,  3.58s/it]                                                       {'loss': 0.0274, 'grad_norm': 3.9381637573242188, 'learning_rate': 5.5322033898305095e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2736/6000 [2:40:10<3:14:37,  3.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:40:13<3:12:53,  3.55s/it]                                                       {'loss': 0.0848, 'grad_norm': 12.30167293548584, 'learning_rate': 5.530508474576272e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2737/6000 [2:40:13<3:12:53,  3.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:40:17<3:10:13,  3.50s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06458112597465515, 'learning_rate': 5.528813559322035e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2738/6000 [2:40:17<3:10:13,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:40:20<3:10:08,  3.50s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.7975689172744751, 'learning_rate': 5.527118644067797e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2739/6000 [2:40:20<3:10:08,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:40:23<3:07:33,  3.45s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5590888261795044, 'learning_rate': 5.525423728813559e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2740/6000 [2:40:23<3:07:33,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:40:27<3:08:02,  3.46s/it]                                                       {'loss': 0.0083, 'grad_norm': 2.1748595237731934, 'learning_rate': 5.5237288135593225e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2741/6000 [2:40:27<3:08:02,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:40:30<3:05:10,  3.41s/it]                                                       {'loss': 0.0956, 'grad_norm': 11.863393783569336, 'learning_rate': 5.522033898305085e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2742/6000 [2:40:30<3:05:10,  3.41s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:40:34<3:03:34,  3.38s/it]                                                       {'loss': 0.0367, 'grad_norm': 5.561450481414795, 'learning_rate': 5.520338983050848e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2743/6000 [2:40:34<3:03:34,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:40:37<3:01:24,  3.34s/it]                                                       {'loss': 0.0409, 'grad_norm': 6.505405426025391, 'learning_rate': 5.518644067796611e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2744/6000 [2:40:37<3:01:24,  3.34s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:40:40<3:04:31,  3.40s/it]                                                       {'loss': 0.0242, 'grad_norm': 7.746568202972412, 'learning_rate': 5.516949152542374e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2745/6000 [2:40:40<3:04:31,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:40:44<3:12:05,  3.54s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.4073436260223389, 'learning_rate': 5.5152542372881355e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2746/6000 [2:40:44<3:12:05,  3.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:40:48<3:17:11,  3.64s/it]                                                       {'loss': 0.107, 'grad_norm': 11.983275413513184, 'learning_rate': 5.513559322033899e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2747/6000 [2:40:48<3:17:11,  3.64s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:40:51<3:13:02,  3.56s/it]                                                       {'loss': 0.196, 'grad_norm': 9.422184944152832, 'learning_rate': 5.511864406779661e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2748/6000 [2:40:51<3:13:02,  3.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:40:55<3:09:28,  3.50s/it]                                                       {'loss': 0.0253, 'grad_norm': 4.367100238800049, 'learning_rate': 5.5101694915254245e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2749/6000 [2:40:55<3:09:28,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:40:58<3:06:08,  3.44s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.8335290551185608, 'learning_rate': 5.508474576271187e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2750/6000 [2:40:58<3:06:08,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:41:02<3:05:47,  3.43s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.1226029247045517, 'learning_rate': 5.50677966101695e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2751/6000 [2:41:02<3:05:47,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:41:05<3:06:10,  3.44s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.4840153455734253, 'learning_rate': 5.505084745762712e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2752/6000 [2:41:05<3:06:10,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:41:08<3:05:20,  3.42s/it]                                                       {'loss': 0.1458, 'grad_norm': 12.950475692749023, 'learning_rate': 5.503389830508475e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2753/6000 [2:41:08<3:05:20,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:41:12<3:12:56,  3.57s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2914980351924896, 'learning_rate': 5.5016949152542374e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2754/6000 [2:41:12<3:12:56,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:41:16<3:13:04,  3.57s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.8127143979072571, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/6000 [2:41:16<3:13:04,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:41:20<3:14:50,  3.60s/it]                                                       {'loss': 0.0174, 'grad_norm': 4.065112590789795, 'learning_rate': 5.498305084745763e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2756/6000 [2:41:20<3:14:50,  3.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:41:23<3:15:05,  3.61s/it]                                                       {'loss': 0.1024, 'grad_norm': 13.084598541259766, 'learning_rate': 5.496610169491526e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2757/6000 [2:41:23<3:15:05,  3.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:41:27<3:10:46,  3.53s/it]                                                       {'loss': 0.016, 'grad_norm': 2.97851824760437, 'learning_rate': 5.494915254237289e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2758/6000 [2:41:27<3:10:46,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:41:30<3:12:48,  3.57s/it]                                                       {'loss': 0.1397, 'grad_norm': 13.576876640319824, 'learning_rate': 5.493220338983052e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2759/6000 [2:41:30<3:12:48,  3.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:41:34<3:09:43,  3.51s/it]                                                       {'loss': 0.0609, 'grad_norm': 5.3968825340271, 'learning_rate': 5.491525423728814e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2760/6000 [2:41:34<3:09:43,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:41:37<3:08:53,  3.50s/it]                                                       {'loss': 0.2005, 'grad_norm': 13.868529319763184, 'learning_rate': 5.489830508474576e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2761/6000 [2:41:37<3:08:53,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:41:40<3:07:17,  3.47s/it]                                                       {'loss': 0.208, 'grad_norm': 18.61573028564453, 'learning_rate': 5.488135593220339e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2762/6000 [2:41:40<3:07:17,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:41:44<3:05:16,  3.43s/it]                                                       {'loss': 0.1883, 'grad_norm': 13.654895782470703, 'learning_rate': 5.486440677966102e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2763/6000 [2:41:44<3:05:16,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:41:47<3:05:38,  3.44s/it]                                                       {'loss': 0.026, 'grad_norm': 6.493517875671387, 'learning_rate': 5.484745762711865e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2764/6000 [2:41:47<3:05:38,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:41:51<3:06:51,  3.47s/it]                                                       {'loss': 0.0059, 'grad_norm': 2.11211895942688, 'learning_rate': 5.4830508474576275e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2765/6000 [2:41:51<3:06:51,  3.47s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:41:54<3:04:19,  3.42s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.21164734661579132, 'learning_rate': 5.481355932203391e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2766/6000 [2:41:54<3:04:19,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:41:58<3:06:27,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.08092798292636871, 'learning_rate': 5.479661016949152e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2767/6000 [2:41:58<3:06:27,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:42:01<3:04:45,  3.43s/it]                                                       {'loss': 0.0155, 'grad_norm': 3.1388094425201416, 'learning_rate': 5.477966101694916e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2768/6000 [2:42:01<3:04:45,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:42:04<3:05:38,  3.45s/it]                                                       {'loss': 0.2331, 'grad_norm': 15.412867546081543, 'learning_rate': 5.476271186440678e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2769/6000 [2:42:04<3:05:38,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:42:08<3:04:26,  3.43s/it]                                                       {'loss': 0.0259, 'grad_norm': 6.309975624084473, 'learning_rate': 5.474576271186441e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2770/6000 [2:42:08<3:04:26,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:42:11<3:04:45,  3.43s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.5087424516677856, 'learning_rate': 5.472881355932204e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2771/6000 [2:42:11<3:04:45,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:42:15<3:03:54,  3.42s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.5279717445373535, 'learning_rate': 5.471186440677967e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2772/6000 [2:42:15<3:03:54,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:42:19<3:12:27,  3.58s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.09374132752418518, 'learning_rate': 5.4694915254237295e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2773/6000 [2:42:19<3:12:27,  3.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:42:22<3:08:13,  3.50s/it]                                                       {'loss': 0.0131, 'grad_norm': 1.4234837293624878, 'learning_rate': 5.467796610169493e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2774/6000 [2:42:22<3:08:13,  3.50s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:42:25<3:05:30,  3.45s/it]                                                       {'loss': 0.1678, 'grad_norm': 9.632304191589355, 'learning_rate': 5.466101694915254e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2775/6000 [2:42:25<3:05:30,  3.45s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:42:29<3:07:09,  3.48s/it]                                                       {'loss': 0.0606, 'grad_norm': 5.958073139190674, 'learning_rate': 5.464406779661018e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2776/6000 [2:42:29<3:07:09,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:42:32<3:04:49,  3.44s/it]                                                       {'loss': 0.0052, 'grad_norm': 0.9614795446395874, 'learning_rate': 5.46271186440678e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2777/6000 [2:42:32<3:04:49,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:42:36<3:05:32,  3.46s/it]                                                       {'loss': 0.1992, 'grad_norm': 14.706706047058105, 'learning_rate': 5.461016949152543e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2778/6000 [2:42:36<3:05:32,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:42:39<3:04:29,  3.44s/it]                                                       {'loss': 0.028, 'grad_norm': 5.036256790161133, 'learning_rate': 5.459322033898306e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2779/6000 [2:42:39<3:04:29,  3.44s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:42:42<3:02:39,  3.40s/it]                                                       {'loss': 0.0235, 'grad_norm': 5.596835136413574, 'learning_rate': 5.457627118644067e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2780/6000 [2:42:42<3:02:39,  3.40s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:42:46<3:05:26,  3.46s/it]                                                       {'loss': 0.0926, 'grad_norm': 10.949199676513672, 'learning_rate': 5.4559322033898306e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2781/6000 [2:42:46<3:05:26,  3.46s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:42:49<3:03:26,  3.42s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.6452921628952026, 'learning_rate': 5.454237288135593e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2782/6000 [2:42:49<3:03:26,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:42:53<3:01:17,  3.38s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2567285895347595, 'learning_rate': 5.452542372881356e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2783/6000 [2:42:53<3:01:17,  3.38s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:42:56<3:03:46,  3.43s/it]                                                       {'loss': 0.0178, 'grad_norm': 1.9801284074783325, 'learning_rate': 5.450847457627119e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2784/6000 [2:42:56<3:03:46,  3.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:43:00<3:08:56,  3.53s/it]                                                       {'loss': 0.0327, 'grad_norm': 8.075241088867188, 'learning_rate': 5.449152542372882e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2785/6000 [2:43:00<3:08:56,  3.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:43:03<3:09:46,  3.54s/it]                                                       {'loss': 0.0511, 'grad_norm': 10.613727569580078, 'learning_rate': 5.447457627118644e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2786/6000 [2:43:03<3:09:46,  3.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:43:07<3:07:53,  3.51s/it]                                                       {'loss': 0.0926, 'grad_norm': 11.040244102478027, 'learning_rate': 5.445762711864408e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2787/6000 [2:43:07<3:07:53,  3.51s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:43:10<3:06:09,  3.48s/it]                                                       {'loss': 0.1974, 'grad_norm': 9.879199981689453, 'learning_rate': 5.444067796610169e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2788/6000 [2:43:10<3:06:09,  3.48s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:43:14<3:02:48,  3.42s/it]                                                       {'loss': 0.1185, 'grad_norm': 13.265828132629395, 'learning_rate': 5.4423728813559325e-06, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2789/6000 [2:43:14<3:02:48,  3.42s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:43:17<3:01:33,  3.39s/it]                                                       {'loss': 0.0085, 'grad_norm': 2.3522703647613525, 'learning_rate': 5.440677966101695e-06, 'epoch': 0.47}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2790/6000 [2:43:17<3:01:33,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:43:20<3:01:42,  3.40s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.4947872161865234, 'learning_rate': 5.438983050847458e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2791/6000 [2:43:20<3:01:42,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:43:24<3:01:10,  3.39s/it]                                                       {'loss': 0.1165, 'grad_norm': 10.890433311462402, 'learning_rate': 5.437288135593221e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2792/6000 [2:43:24<3:01:10,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:43:27<3:01:46,  3.40s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.9381729364395142, 'learning_rate': 5.435593220338984e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2793/6000 [2:43:27<3:01:46,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:43:31<3:09:14,  3.54s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.25145423412323, 'learning_rate': 5.433898305084746e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2794/6000 [2:43:31<3:09:14,  3.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:43:34<3:07:17,  3.51s/it]                                                       {'loss': 0.0769, 'grad_norm': 11.280793190002441, 'learning_rate': 5.43220338983051e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2795/6000 [2:43:34<3:07:17,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:43:38<3:04:05,  3.45s/it]                                                       {'loss': 0.3325, 'grad_norm': 19.62940216064453, 'learning_rate': 5.430508474576271e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2796/6000 [2:43:38<3:04:05,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:43:41<3:04:35,  3.46s/it]                                                       {'loss': 0.0289, 'grad_norm': 5.289881229400635, 'learning_rate': 5.4288135593220345e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2797/6000 [2:43:41<3:04:35,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:43:45<3:04:05,  3.45s/it]                                                       {'loss': 0.1104, 'grad_norm': 7.319476127624512, 'learning_rate': 5.427118644067797e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2798/6000 [2:43:45<3:04:05,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:43:48<3:04:47,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.21190887689590454, 'learning_rate': 5.42542372881356e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2799/6000 [2:43:48<3:04:47,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:43:51<3:02:49,  3.43s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.9370693564414978, 'learning_rate': 5.423728813559323e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2800/6000 [2:43:51<3:02:49,  3.43s/it][2025-11-07 01:35:01,488] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800
[2025-11-07 01:35:01,508] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:35:02,207] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:43:57<3:41:33,  4.16s/it]                                                       {'loss': 0.094, 'grad_norm': 8.98604965209961, 'learning_rate': 5.422033898305085e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2801/6000 [2:43:57<3:41:33,  4.16s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:44:01<3:29:14,  3.93s/it]                                                       {'loss': 0.0419, 'grad_norm': 6.881135940551758, 'learning_rate': 5.420338983050848e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2802/6000 [2:44:01<3:29:14,  3.93s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:44:04<3:23:57,  3.83s/it]                                                       {'loss': 0.0185, 'grad_norm': 3.394143581390381, 'learning_rate': 5.41864406779661e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2803/6000 [2:44:04<3:23:57,  3.83s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:44:08<3:16:44,  3.69s/it]                                                       {'loss': 0.1326, 'grad_norm': 12.173460960388184, 'learning_rate': 5.416949152542373e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2804/6000 [2:44:08<3:16:44,  3.69s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:44:11<3:16:47,  3.70s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03554986044764519, 'learning_rate': 5.415254237288136e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2805/6000 [2:44:11<3:16:47,  3.70s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:44:15<3:11:56,  3.61s/it]                                                       {'loss': 0.0719, 'grad_norm': 9.648009300231934, 'learning_rate': 5.413559322033899e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/6000 [2:44:15<3:11:56,  3.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:44:18<3:09:10,  3.55s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.036764368414878845, 'learning_rate': 5.411864406779661e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2807/6000 [2:44:18<3:09:10,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:44:22<3:05:09,  3.48s/it]                                                       {'loss': 0.0408, 'grad_norm': 3.1942574977874756, 'learning_rate': 5.4101694915254246e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2808/6000 [2:44:22<3:05:09,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:44:25<3:03:39,  3.45s/it]                                                       {'loss': 0.1282, 'grad_norm': 14.024956703186035, 'learning_rate': 5.408474576271186e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2809/6000 [2:44:25<3:03:39,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:44:29<3:13:00,  3.63s/it]                                                       {'loss': 0.0085, 'grad_norm': 2.2867255210876465, 'learning_rate': 5.40677966101695e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2810/6000 [2:44:29<3:13:00,  3.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:44:33<3:12:22,  3.62s/it]                                                       {'loss': 0.1239, 'grad_norm': 15.656778335571289, 'learning_rate': 5.405084745762712e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2811/6000 [2:44:33<3:12:22,  3.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:44:36<3:07:56,  3.54s/it]                                                       {'loss': 0.0131, 'grad_norm': 3.6255125999450684, 'learning_rate': 5.403389830508475e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2812/6000 [2:44:36<3:07:56,  3.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:44:39<3:05:04,  3.48s/it]                                                       {'loss': 0.0441, 'grad_norm': 9.067551612854004, 'learning_rate': 5.4016949152542375e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2813/6000 [2:44:39<3:05:04,  3.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:44:43<3:02:53,  3.44s/it]                                                       {'loss': 0.1409, 'grad_norm': 12.197738647460938, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2814/6000 [2:44:43<3:02:53,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:44:46<3:02:15,  3.43s/it]                                                       {'loss': 0.0064, 'grad_norm': 2.2119228839874268, 'learning_rate': 5.398305084745763e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2815/6000 [2:44:46<3:02:15,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:44:49<3:01:50,  3.43s/it]                                                       {'loss': 0.048, 'grad_norm': 7.272737503051758, 'learning_rate': 5.3966101694915265e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2816/6000 [2:44:49<3:01:50,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:44:53<3:06:10,  3.51s/it]                                                       {'loss': 0.1062, 'grad_norm': 13.366122245788574, 'learning_rate': 5.394915254237288e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2817/6000 [2:44:53<3:06:10,  3.51s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:44:57<3:06:28,  3.52s/it]                                                       {'loss': 0.2628, 'grad_norm': 17.80352783203125, 'learning_rate': 5.393220338983051e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2818/6000 [2:44:57<3:06:28,  3.52s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:45:00<3:05:13,  3.49s/it]                                                       {'loss': 0.0237, 'grad_norm': 5.308541297912598, 'learning_rate': 5.391525423728814e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2819/6000 [2:45:00<3:05:13,  3.49s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:45:04<3:16:26,  3.71s/it]                                                       {'loss': 0.0127, 'grad_norm': 2.6148290634155273, 'learning_rate': 5.389830508474577e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2820/6000 [2:45:04<3:16:26,  3.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:45:08<3:12:21,  3.63s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.8357059359550476, 'learning_rate': 5.3881355932203395e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2821/6000 [2:45:08<3:12:21,  3.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:45:11<3:06:58,  3.53s/it]                                                       {'loss': 0.0916, 'grad_norm': 7.776285171508789, 'learning_rate': 5.386440677966102e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2822/6000 [2:45:11<3:06:58,  3.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:45:14<3:03:57,  3.47s/it]                                                       {'loss': 0.1038, 'grad_norm': 10.417387962341309, 'learning_rate': 5.384745762711865e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2823/6000 [2:45:14<3:03:57,  3.47s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:45:18<3:02:23,  3.45s/it]                                                       {'loss': 0.0122, 'grad_norm': 3.7457520961761475, 'learning_rate': 5.383050847457627e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2824/6000 [2:45:18<3:02:23,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:45:21<3:02:22,  3.45s/it]                                                       {'loss': 0.0664, 'grad_norm': 11.92551040649414, 'learning_rate': 5.38135593220339e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2825/6000 [2:45:21<3:02:22,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:45:25<3:02:05,  3.44s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.29594653844833374, 'learning_rate': 5.3796610169491525e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2826/6000 [2:45:25<3:02:05,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:45:28<3:02:32,  3.45s/it]                                                       {'loss': 0.0963, 'grad_norm': 12.380220413208008, 'learning_rate': 5.377966101694916e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2827/6000 [2:45:28<3:02:32,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:45:32<3:02:08,  3.45s/it]                                                       {'loss': 0.0085, 'grad_norm': 2.6210989952087402, 'learning_rate': 5.376271186440678e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2828/6000 [2:45:32<3:02:08,  3.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:45:35<3:01:15,  3.43s/it]                                                       {'loss': 0.188, 'grad_norm': 20.18609046936035, 'learning_rate': 5.3745762711864414e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2829/6000 [2:45:35<3:01:15,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:45:38<3:01:52,  3.44s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2298000156879425, 'learning_rate': 5.372881355932204e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2830/6000 [2:45:38<3:01:52,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:45:42<3:01:01,  3.43s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1306082159280777, 'learning_rate': 5.371186440677967e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2831/6000 [2:45:42<3:01:01,  3.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:45:45<2:58:44,  3.39s/it]                                                       {'loss': 0.0125, 'grad_norm': 2.108320951461792, 'learning_rate': 5.369491525423729e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2832/6000 [2:45:45<2:58:44,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:45:49<2:58:59,  3.39s/it]                                                       {'loss': 0.0111, 'grad_norm': 2.2905807495117188, 'learning_rate': 5.367796610169492e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2833/6000 [2:45:49<2:58:59,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:45:52<2:58:53,  3.39s/it]                                                       {'loss': 0.0625, 'grad_norm': 9.130949974060059, 'learning_rate': 5.3661016949152544e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2834/6000 [2:45:52<2:58:53,  3.39s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:45:55<3:00:07,  3.41s/it]                                                       {'loss': 0.1496, 'grad_norm': 26.306856155395508, 'learning_rate': 5.364406779661018e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2835/6000 [2:45:55<3:00:07,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:45:59<2:59:49,  3.41s/it]                                                       {'loss': 0.0034, 'grad_norm': 1.6508710384368896, 'learning_rate': 5.36271186440678e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2836/6000 [2:45:59<2:59:49,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:46:02<2:59:10,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.22050350904464722, 'learning_rate': 5.361016949152543e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2837/6000 [2:46:02<2:59:10,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:46:06<2:59:08,  3.40s/it]                                                       {'loss': 0.0399, 'grad_norm': 7.581596374511719, 'learning_rate': 5.359322033898306e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2838/6000 [2:46:06<2:59:08,  3.40s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:46:09<2:59:49,  3.41s/it]                                                       {'loss': 0.0068, 'grad_norm': 2.217233896255493, 'learning_rate': 5.357627118644069e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2839/6000 [2:46:09<2:59:49,  3.41s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:46:13<3:01:09,  3.44s/it]                                                       {'loss': 0.0801, 'grad_norm': 10.814062118530273, 'learning_rate': 5.355932203389831e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2840/6000 [2:46:13<3:01:09,  3.44s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:46:16<3:02:16,  3.46s/it]                                                       {'loss': 0.1127, 'grad_norm': 14.52920913696289, 'learning_rate': 5.354237288135594e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2841/6000 [2:46:16<3:02:16,  3.46s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:46:20<3:11:48,  3.64s/it]                                                       {'loss': 0.0315, 'grad_norm': 4.062599182128906, 'learning_rate': 5.352542372881356e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2842/6000 [2:46:20<3:11:48,  3.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:46:24<3:14:33,  3.70s/it]                                                       {'loss': 0.0065, 'grad_norm': 1.1403632164001465, 'learning_rate': 5.350847457627119e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2843/6000 [2:46:24<3:14:33,  3.70s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:46:27<3:08:44,  3.59s/it]                                                       {'loss': 0.1124, 'grad_norm': 9.946626663208008, 'learning_rate': 5.349152542372882e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2844/6000 [2:46:27<3:08:44,  3.59s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:46:31<3:06:27,  3.55s/it]                                                       {'loss': 0.0902, 'grad_norm': 11.219477653503418, 'learning_rate': 5.347457627118644e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2845/6000 [2:46:31<3:06:27,  3.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:46:35<3:13:00,  3.67s/it]                                                       {'loss': 0.1696, 'grad_norm': 12.503905296325684, 'learning_rate': 5.345762711864407e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2846/6000 [2:46:35<3:13:00,  3.67s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:46:38<3:13:58,  3.69s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.12400972843170166, 'learning_rate': 5.344067796610169e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2847/6000 [2:46:38<3:13:58,  3.69s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:46:42<3:15:50,  3.73s/it]                                                       {'loss': 0.0089, 'grad_norm': 1.6348673105239868, 'learning_rate': 5.342372881355933e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2848/6000 [2:46:42<3:15:50,  3.73s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:46:46<3:12:57,  3.67s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.27110186219215393, 'learning_rate': 5.340677966101695e-06, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2849/6000 [2:46:46<3:12:57,  3.67s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:46:49<3:07:16,  3.57s/it]                                                       {'loss': 0.0153, 'grad_norm': 4.332948684692383, 'learning_rate': 5.338983050847458e-06, 'epoch': 0.47}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2850/6000 [2:46:49<3:07:16,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:46:53<3:05:24,  3.53s/it]                                                       {'loss': 0.0186, 'grad_norm': 5.590199947357178, 'learning_rate': 5.337288135593221e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2851/6000 [2:46:53<3:05:24,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:46:56<3:04:48,  3.52s/it]                                                       {'loss': 0.1606, 'grad_norm': 10.221259117126465, 'learning_rate': 5.335593220338984e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2852/6000 [2:46:56<3:04:48,  3.52s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:46:59<3:01:57,  3.47s/it]                                                       {'loss': 0.0767, 'grad_norm': 10.698892593383789, 'learning_rate': 5.333898305084746e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2853/6000 [2:46:59<3:01:57,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:47:03<3:06:28,  3.56s/it]                                                       {'loss': 0.0292, 'grad_norm': 5.3568315505981445, 'learning_rate': 5.332203389830509e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2854/6000 [2:47:03<3:06:28,  3.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:47:06<3:03:03,  3.49s/it]                                                       {'loss': 0.087, 'grad_norm': 11.81869888305664, 'learning_rate': 5.330508474576271e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2855/6000 [2:47:06<3:03:03,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:47:10<3:01:32,  3.46s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.6034021377563477, 'learning_rate': 5.328813559322035e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2856/6000 [2:47:10<3:01:32,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:47:13<3:00:00,  3.44s/it]                                                       {'loss': 0.2961, 'grad_norm': 17.434368133544922, 'learning_rate': 5.327118644067797e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2857/6000 [2:47:13<3:00:00,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:47:17<2:59:48,  3.43s/it]                                                       {'loss': 0.0264, 'grad_norm': 4.512146949768066, 'learning_rate': 5.32542372881356e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2858/6000 [2:47:17<2:59:48,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:47:20<3:00:56,  3.46s/it]                                                       {'loss': 0.1224, 'grad_norm': 14.24688720703125, 'learning_rate': 5.323728813559323e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2859/6000 [2:47:20<3:00:56,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:47:24<3:00:58,  3.46s/it]                                                       {'loss': 0.042, 'grad_norm': 4.120854377746582, 'learning_rate': 5.322033898305086e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2860/6000 [2:47:24<3:00:58,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:47:27<3:01:01,  3.46s/it]                                                       {'loss': 0.0173, 'grad_norm': 5.307351112365723, 'learning_rate': 5.3203389830508476e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2861/6000 [2:47:27<3:01:01,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:47:31<3:00:31,  3.45s/it]                                                       {'loss': 0.1914, 'grad_norm': 13.373656272888184, 'learning_rate': 5.318644067796611e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2862/6000 [2:47:31<3:00:31,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:47:34<3:00:54,  3.46s/it]                                                       {'loss': 0.0396, 'grad_norm': 6.546421051025391, 'learning_rate': 5.316949152542373e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2863/6000 [2:47:34<3:00:54,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:47:37<2:59:03,  3.43s/it]                                                       {'loss': 0.0178, 'grad_norm': 3.6056416034698486, 'learning_rate': 5.315254237288136e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2864/6000 [2:47:37<2:59:03,  3.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:47:41<2:59:44,  3.44s/it]                                                       {'loss': 0.005, 'grad_norm': 1.4248201847076416, 'learning_rate': 5.313559322033899e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2865/6000 [2:47:41<2:59:44,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:47:44<2:59:33,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06459701806306839, 'learning_rate': 5.311864406779661e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2866/6000 [2:47:44<2:59:33,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:47:48<3:00:49,  3.46s/it]                                                       {'loss': 0.0088, 'grad_norm': 2.6321022510528564, 'learning_rate': 5.310169491525425e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2867/6000 [2:47:48<3:00:49,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:47:51<3:03:00,  3.51s/it]                                                       {'loss': 0.009, 'grad_norm': 1.8895543813705444, 'learning_rate': 5.308474576271186e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2868/6000 [2:47:51<3:03:00,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:47:55<3:07:30,  3.59s/it]                                                       {'loss': 0.0903, 'grad_norm': 11.63703441619873, 'learning_rate': 5.3067796610169495e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2869/6000 [2:47:55<3:07:30,  3.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:47:59<3:04:11,  3.53s/it]                                                       {'loss': 0.0087, 'grad_norm': 1.9851243495941162, 'learning_rate': 5.305084745762712e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2870/6000 [2:47:59<3:04:11,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:48:02<3:03:10,  3.51s/it]                                                       {'loss': 0.1052, 'grad_norm': 11.778197288513184, 'learning_rate': 5.303389830508475e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2871/6000 [2:48:02<3:03:10,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:48:05<3:01:46,  3.49s/it]                                                       {'loss': 0.054, 'grad_norm': 10.135421752929688, 'learning_rate': 5.301694915254238e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2872/6000 [2:48:05<3:01:46,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:48:09<3:00:35,  3.47s/it]                                                       {'loss': 0.1325, 'grad_norm': 13.704090118408203, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2873/6000 [2:48:09<3:00:35,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:48:12<3:00:47,  3.47s/it]                                                       {'loss': 0.0403, 'grad_norm': 10.565417289733887, 'learning_rate': 5.2983050847457625e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2874/6000 [2:48:12<3:00:47,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:48:16<2:59:01,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.41181784868240356, 'learning_rate': 5.296610169491526e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2875/6000 [2:48:16<2:59:01,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:48:19<3:00:43,  3.47s/it]                                                       {'loss': 0.0323, 'grad_norm': 9.58682918548584, 'learning_rate': 5.294915254237288e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2876/6000 [2:48:19<3:00:43,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:48:23<3:01:11,  3.48s/it]                                                       {'loss': 0.0666, 'grad_norm': 10.916027069091797, 'learning_rate': 5.2932203389830515e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/6000 [2:48:23<3:01:11,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:48:26<3:00:36,  3.47s/it]                                                       {'loss': 0.0624, 'grad_norm': 9.504703521728516, 'learning_rate': 5.291525423728814e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2878/6000 [2:48:26<3:00:36,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:48:30<2:59:25,  3.45s/it]                                                       {'loss': 0.1142, 'grad_norm': 8.855229377746582, 'learning_rate': 5.289830508474577e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2879/6000 [2:48:30<2:59:25,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:48:34<3:05:52,  3.57s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5775957703590393, 'learning_rate': 5.28813559322034e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2880/6000 [2:48:34<3:05:52,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:48:37<3:02:33,  3.51s/it]                                                       {'loss': 0.0398, 'grad_norm': 7.385052680969238, 'learning_rate': 5.286440677966103e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2881/6000 [2:48:37<3:02:33,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:48:40<3:00:11,  3.47s/it]                                                       {'loss': 0.0045, 'grad_norm': 0.9452520608901978, 'learning_rate': 5.2847457627118645e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2882/6000 [2:48:40<3:00:11,  3.47s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:48:44<2:58:36,  3.44s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.231217622756958, 'learning_rate': 5.283050847457628e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2883/6000 [2:48:44<2:58:36,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:48:47<2:59:14,  3.45s/it]                                                       {'loss': 0.0141, 'grad_norm': 3.612454414367676, 'learning_rate': 5.28135593220339e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2884/6000 [2:48:47<2:59:14,  3.45s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:48:51<3:13:32,  3.73s/it]                                                       {'loss': 0.0334, 'grad_norm': 5.570138931274414, 'learning_rate': 5.279661016949153e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2885/6000 [2:48:51<3:13:32,  3.73s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:48:55<3:07:47,  3.62s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.962695837020874, 'learning_rate': 5.277966101694916e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2886/6000 [2:48:55<3:07:47,  3.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:48:58<3:04:59,  3.57s/it]                                                       {'loss': 0.0639, 'grad_norm': 8.22497844696045, 'learning_rate': 5.276271186440678e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2887/6000 [2:48:58<3:04:59,  3.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:49:02<3:03:23,  3.54s/it]                                                       {'loss': 0.0835, 'grad_norm': 9.760750770568848, 'learning_rate': 5.2745762711864416e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2888/6000 [2:49:02<3:03:23,  3.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:49:05<3:02:16,  3.52s/it]                                                       {'loss': 0.0047, 'grad_norm': 2.0745511054992676, 'learning_rate': 5.272881355932203e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2889/6000 [2:49:05<3:02:16,  3.52s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:49:09<3:01:09,  3.49s/it]                                                       {'loss': 0.013, 'grad_norm': 3.143599033355713, 'learning_rate': 5.271186440677966e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2890/6000 [2:49:09<3:01:09,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:49:12<3:03:16,  3.54s/it]                                                       {'loss': 0.122, 'grad_norm': 11.265266418457031, 'learning_rate': 5.269491525423729e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2891/6000 [2:49:12<3:03:16,  3.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:49:16<3:01:36,  3.51s/it]                                                       {'loss': 0.5287, 'grad_norm': 15.17712688446045, 'learning_rate': 5.267796610169492e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2892/6000 [2:49:16<3:01:36,  3.51s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:49:19<3:02:19,  3.52s/it]                                                       {'loss': 0.2209, 'grad_norm': 22.5865535736084, 'learning_rate': 5.2661016949152545e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2893/6000 [2:49:19<3:02:19,  3.52s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:49:23<3:00:08,  3.48s/it]                                                       {'loss': 0.0602, 'grad_norm': 8.77935791015625, 'learning_rate': 5.264406779661018e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2894/6000 [2:49:23<3:00:08,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:49:26<2:59:00,  3.46s/it]                                                       {'loss': 0.0112, 'grad_norm': 3.4336369037628174, 'learning_rate': 5.26271186440678e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2895/6000 [2:49:26<2:59:00,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [2:49:30<3:02:25,  3.53s/it]                                                       {'loss': 0.0787, 'grad_norm': 8.030802726745605, 'learning_rate': 5.2610169491525435e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2896/6000 [2:49:30<3:02:25,  3.53s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [2:49:33<3:00:30,  3.49s/it]                                                       {'loss': 0.0147, 'grad_norm': 2.6515822410583496, 'learning_rate': 5.259322033898305e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2897/6000 [2:49:33<3:00:30,  3.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [2:49:37<2:58:48,  3.46s/it]                                                       {'loss': 0.1801, 'grad_norm': 13.573745727539062, 'learning_rate': 5.257627118644068e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2898/6000 [2:49:37<2:58:48,  3.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [2:49:40<2:56:11,  3.41s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.2952222228050232, 'learning_rate': 5.255932203389831e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2899/6000 [2:49:40<2:56:11,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [2:49:43<2:55:31,  3.40s/it]                                                       {'loss': 0.1039, 'grad_norm': 15.263016700744629, 'learning_rate': 5.254237288135594e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2900/6000 [2:49:43<2:55:31,  3.40s/it][2025-11-07 01:40:53,209] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2900
[2025-11-07 01:40:53,221] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:40:53,871] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-2900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [2:49:49<3:37:32,  4.21s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.2080801725387573, 'learning_rate': 5.2525423728813565e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2901/6000 [2:49:49<3:37:32,  4.21s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [2:49:53<3:27:17,  4.01s/it]                                                       {'loss': 0.2557, 'grad_norm': 14.253013610839844, 'learning_rate': 5.25084745762712e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2902/6000 [2:49:53<3:27:17,  4.01s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [2:49:56<3:16:55,  3.82s/it]                                                       {'loss': 0.0307, 'grad_norm': 6.656040668487549, 'learning_rate': 5.249152542372881e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2903/6000 [2:49:56<3:16:55,  3.82s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [2:50:00<3:09:02,  3.66s/it]                                                       {'loss': 0.0151, 'grad_norm': 5.075042247772217, 'learning_rate': 5.247457627118645e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2904/6000 [2:50:00<3:09:02,  3.66s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [2:50:03<3:03:10,  3.55s/it]                                                       {'loss': 0.0204, 'grad_norm': 3.4373064041137695, 'learning_rate': 5.245762711864407e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2905/6000 [2:50:03<3:03:10,  3.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [2:50:06<2:59:37,  3.48s/it]                                                       {'loss': 0.0636, 'grad_norm': 8.49348258972168, 'learning_rate': 5.2440677966101695e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2906/6000 [2:50:06<2:59:37,  3.48s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [2:50:09<2:57:12,  3.44s/it]                                                       {'loss': 0.0664, 'grad_norm': 10.677139282226562, 'learning_rate': 5.242372881355933e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2907/6000 [2:50:09<2:57:12,  3.44s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [2:50:13<2:55:56,  3.41s/it]                                                       {'loss': 0.0223, 'grad_norm': 2.7499866485595703, 'learning_rate': 5.240677966101695e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2908/6000 [2:50:13<2:55:56,  3.41s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [2:50:16<2:54:34,  3.39s/it]                                                       {'loss': 0.1486, 'grad_norm': 13.084888458251953, 'learning_rate': 5.2389830508474584e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2909/6000 [2:50:16<2:54:34,  3.39s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [2:50:20<2:55:14,  3.40s/it]                                                       {'loss': 0.2313, 'grad_norm': 16.38970375061035, 'learning_rate': 5.23728813559322e-06, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2910/6000 [2:50:20<2:55:14,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [2:50:23<2:54:55,  3.40s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.6877126097679138, 'learning_rate': 5.235593220338983e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2911/6000 [2:50:23<2:54:55,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [2:50:26<2:54:00,  3.38s/it]                                                       {'loss': 0.0646, 'grad_norm': 14.791281700134277, 'learning_rate': 5.233898305084746e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2912/6000 [2:50:26<2:54:00,  3.38s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [2:50:30<2:54:16,  3.39s/it]                                                       {'loss': 0.1228, 'grad_norm': 5.53860330581665, 'learning_rate': 5.232203389830509e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2913/6000 [2:50:30<2:54:16,  3.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [2:50:33<2:54:11,  3.39s/it]                                                       {'loss': 0.0475, 'grad_norm': 3.7329161167144775, 'learning_rate': 5.2305084745762714e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2914/6000 [2:50:33<2:54:11,  3.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [2:50:37<2:55:37,  3.42s/it]                                                       {'loss': 0.4677, 'grad_norm': 18.813819885253906, 'learning_rate': 5.228813559322035e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2915/6000 [2:50:37<2:55:37,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [2:50:41<3:07:13,  3.64s/it]                                                       {'loss': 0.0322, 'grad_norm': 6.186017036437988, 'learning_rate': 5.227118644067797e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2916/6000 [2:50:41<3:07:13,  3.64s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [2:50:44<3:02:35,  3.55s/it]                                                       {'loss': 0.1283, 'grad_norm': 8.53669548034668, 'learning_rate': 5.22542372881356e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2917/6000 [2:50:44<3:02:35,  3.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [2:50:48<3:01:46,  3.54s/it]                                                       {'loss': 0.0213, 'grad_norm': 5.594685077667236, 'learning_rate': 5.223728813559322e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2918/6000 [2:50:48<3:01:46,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [2:50:51<3:01:30,  3.53s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.1771401166915894, 'learning_rate': 5.222033898305085e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2919/6000 [2:50:51<3:01:30,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [2:50:55<3:01:11,  3.53s/it]                                                       {'loss': 0.0853, 'grad_norm': 9.961835861206055, 'learning_rate': 5.220338983050848e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2920/6000 [2:50:55<3:01:11,  3.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [2:50:58<2:59:27,  3.50s/it]                                                       {'loss': 0.0281, 'grad_norm': 4.042813777923584, 'learning_rate': 5.218644067796611e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2921/6000 [2:50:58<2:59:27,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [2:51:01<2:57:36,  3.46s/it]                                                       {'loss': 0.0456, 'grad_norm': 9.295389175415039, 'learning_rate': 5.216949152542373e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2922/6000 [2:51:01<2:57:36,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [2:51:07<3:27:24,  4.04s/it]                                                       {'loss': 0.0899, 'grad_norm': 7.721388339996338, 'learning_rate': 5.215254237288137e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2923/6000 [2:51:07<3:27:24,  4.04s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [2:51:11<3:27:43,  4.05s/it]                                                       {'loss': 0.0501, 'grad_norm': 4.985787391662598, 'learning_rate': 5.213559322033899e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2924/6000 [2:51:11<3:27:43,  4.05s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [2:51:14<3:17:41,  3.86s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.9530220627784729, 'learning_rate': 5.211864406779662e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2925/6000 [2:51:14<3:17:41,  3.86s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [2:51:18<3:09:20,  3.70s/it]                                                       {'loss': 0.0071, 'grad_norm': 1.5148307085037231, 'learning_rate': 5.210169491525424e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2926/6000 [2:51:18<3:09:20,  3.70s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [2:51:21<3:05:21,  3.62s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.5428770780563354, 'learning_rate': 5.208474576271186e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2927/6000 [2:51:21<3:05:21,  3.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [2:51:25<3:03:57,  3.59s/it]                                                       {'loss': 0.0741, 'grad_norm': 7.791807651519775, 'learning_rate': 5.20677966101695e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2928/6000 [2:51:25<3:03:57,  3.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [2:51:28<3:07:24,  3.66s/it]                                                       {'loss': 0.1488, 'grad_norm': 17.90950584411621, 'learning_rate': 5.205084745762712e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2929/6000 [2:51:28<3:07:24,  3.66s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [2:51:32<3:03:10,  3.58s/it]                                                       {'loss': 0.0663, 'grad_norm': 13.86204719543457, 'learning_rate': 5.203389830508475e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/6000 [2:51:32<3:03:10,  3.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [2:51:35<3:00:18,  3.52s/it]                                                       {'loss': 0.0917, 'grad_norm': 13.28536605834961, 'learning_rate': 5.201694915254237e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2931/6000 [2:51:35<3:00:18,  3.52s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [2:51:39<2:59:08,  3.50s/it]                                                       {'loss': 0.1047, 'grad_norm': 13.528850555419922, 'learning_rate': 5.2e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2932/6000 [2:51:39<2:59:08,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [2:51:42<3:00:01,  3.52s/it]                                                       {'loss': 0.1726, 'grad_norm': 13.339608192443848, 'learning_rate': 5.198305084745763e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2933/6000 [2:51:42<3:00:01,  3.52s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [2:51:46<2:56:37,  3.46s/it]                                                       {'loss': 0.0891, 'grad_norm': 11.890337944030762, 'learning_rate': 5.196610169491526e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2934/6000 [2:51:46<2:56:37,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [2:51:49<2:55:45,  3.44s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.4094783067703247, 'learning_rate': 5.194915254237288e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2935/6000 [2:51:49<2:55:45,  3.44s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [2:51:52<2:56:55,  3.46s/it]                                                       {'loss': 0.0394, 'grad_norm': 7.072383403778076, 'learning_rate': 5.193220338983052e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2936/6000 [2:51:53<2:56:55,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [2:51:56<3:01:22,  3.55s/it]                                                       {'loss': 0.0107, 'grad_norm': 2.476006507873535, 'learning_rate': 5.191525423728814e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2937/6000 [2:51:56<3:01:22,  3.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [2:52:00<2:58:18,  3.49s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.42718690633773804, 'learning_rate': 5.189830508474577e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2938/6000 [2:52:00<2:58:18,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [2:52:03<2:57:58,  3.49s/it]                                                       {'loss': 0.0464, 'grad_norm': 6.3628129959106445, 'learning_rate': 5.188135593220339e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2939/6000 [2:52:03<2:57:58,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [2:52:07<2:57:03,  3.47s/it]                                                       {'loss': 0.131, 'grad_norm': 10.806249618530273, 'learning_rate': 5.186440677966102e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2940/6000 [2:52:07<2:57:03,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [2:52:10<2:54:40,  3.43s/it]                                                       {'loss': 0.0846, 'grad_norm': 10.732525825500488, 'learning_rate': 5.1847457627118646e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2941/6000 [2:52:10<2:54:40,  3.43s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [2:52:14<3:00:12,  3.54s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.21244987845420837, 'learning_rate': 5.183050847457628e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2942/6000 [2:52:14<3:00:12,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [2:52:17<2:59:25,  3.52s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.0233039855957031, 'learning_rate': 5.18135593220339e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2943/6000 [2:52:17<2:59:25,  3.52s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [2:52:21<2:57:25,  3.48s/it]                                                       {'loss': 0.0779, 'grad_norm': 12.128467559814453, 'learning_rate': 5.1796610169491535e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2944/6000 [2:52:21<2:57:25,  3.48s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [2:52:24<2:56:32,  3.47s/it]                                                       {'loss': 0.3581, 'grad_norm': 20.22089195251465, 'learning_rate': 5.177966101694916e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2945/6000 [2:52:24<2:56:32,  3.47s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [2:52:27<2:53:40,  3.41s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08318264782428741, 'learning_rate': 5.176271186440679e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2946/6000 [2:52:27<2:53:40,  3.41s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [2:52:31<2:55:30,  3.45s/it]                                                       {'loss': 0.0672, 'grad_norm': 8.143698692321777, 'learning_rate': 5.174576271186441e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2947/6000 [2:52:31<2:55:30,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [2:52:34<2:56:07,  3.46s/it]                                                       {'loss': 0.0123, 'grad_norm': 3.1679649353027344, 'learning_rate': 5.172881355932203e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2948/6000 [2:52:34<2:56:07,  3.46s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [2:52:38<2:54:10,  3.43s/it]                                                       {'loss': 0.058, 'grad_norm': 9.280817985534668, 'learning_rate': 5.1711864406779665e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2949/6000 [2:52:38<2:54:10,  3.43s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [2:52:41<2:54:06,  3.42s/it]                                                       {'loss': 0.0183, 'grad_norm': 2.4394054412841797, 'learning_rate': 5.169491525423729e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2950/6000 [2:52:41<2:54:06,  3.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [2:52:44<2:52:02,  3.39s/it]                                                       {'loss': 0.0304, 'grad_norm': 4.469745635986328, 'learning_rate': 5.167796610169492e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2951/6000 [2:52:44<2:52:02,  3.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [2:52:48<2:53:10,  3.41s/it]                                                       {'loss': 0.0582, 'grad_norm': 9.249859809875488, 'learning_rate': 5.166101694915255e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2952/6000 [2:52:48<2:53:10,  3.41s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [2:52:51<2:52:53,  3.40s/it]                                                       {'loss': 0.0625, 'grad_norm': 9.002108573913574, 'learning_rate': 5.164406779661018e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2953/6000 [2:52:51<2:52:53,  3.40s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [2:52:55<2:52:00,  3.39s/it]                                                       {'loss': 0.0234, 'grad_norm': 5.432945728302002, 'learning_rate': 5.1627118644067795e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2954/6000 [2:52:55<2:52:00,  3.39s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [2:52:58<2:51:02,  3.37s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.39749884605407715, 'learning_rate': 5.161016949152543e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2955/6000 [2:52:58<2:51:02,  3.37s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [2:53:01<2:50:22,  3.36s/it]                                                       {'loss': 0.0249, 'grad_norm': 2.706496238708496, 'learning_rate': 5.159322033898305e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2956/6000 [2:53:01<2:50:22,  3.36s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [2:53:05<2:51:15,  3.38s/it]                                                       {'loss': 0.01, 'grad_norm': 1.7289921045303345, 'learning_rate': 5.1576271186440685e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2957/6000 [2:53:05<2:51:15,  3.38s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [2:53:08<2:51:14,  3.38s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.26099953055381775, 'learning_rate': 5.155932203389831e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2958/6000 [2:53:08<2:51:14,  3.38s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [2:53:12<2:55:00,  3.45s/it]                                                       {'loss': 0.0675, 'grad_norm': 14.56850528717041, 'learning_rate': 5.154237288135594e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2959/6000 [2:53:12<2:55:00,  3.45s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [2:53:15<2:57:51,  3.51s/it]                                                       {'loss': 0.0769, 'grad_norm': 11.24506664276123, 'learning_rate': 5.152542372881356e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2960/6000 [2:53:15<2:57:51,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [2:53:19<2:56:51,  3.49s/it]                                                       {'loss': 0.3521, 'grad_norm': 19.130340576171875, 'learning_rate': 5.15084745762712e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2961/6000 [2:53:19<2:56:51,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [2:53:22<2:59:06,  3.54s/it]                                                       {'loss': 0.0609, 'grad_norm': 9.407541275024414, 'learning_rate': 5.1491525423728815e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2962/6000 [2:53:22<2:59:06,  3.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [2:53:26<3:00:15,  3.56s/it]                                                       {'loss': 0.04, 'grad_norm': 5.9446845054626465, 'learning_rate': 5.147457627118645e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2963/6000 [2:53:26<3:00:15,  3.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [2:53:29<2:57:23,  3.51s/it]                                                       {'loss': 0.1358, 'grad_norm': 9.939043998718262, 'learning_rate': 5.145762711864407e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2964/6000 [2:53:29<2:57:23,  3.51s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [2:53:33<2:56:53,  3.50s/it]                                                       {'loss': 0.0191, 'grad_norm': 1.4821093082427979, 'learning_rate': 5.1440677966101704e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2965/6000 [2:53:33<2:56:53,  3.50s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [2:53:36<2:56:17,  3.49s/it]                                                       {'loss': 0.1027, 'grad_norm': 11.854801177978516, 'learning_rate': 5.142372881355933e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2966/6000 [2:53:36<2:56:17,  3.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [2:53:40<2:53:54,  3.44s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1956891417503357, 'learning_rate': 5.1406779661016944e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2967/6000 [2:53:40<2:53:54,  3.44s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [2:53:43<2:52:24,  3.41s/it]                                                       {'loss': 0.0295, 'grad_norm': 5.379780292510986, 'learning_rate': 5.138983050847458e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2968/6000 [2:53:43<2:52:24,  3.41s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [2:53:47<2:54:22,  3.45s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.12140634655952454, 'learning_rate': 5.13728813559322e-06, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2969/6000 [2:53:47<2:54:22,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [2:53:50<2:51:33,  3.40s/it]                                                       {'loss': 0.002, 'grad_norm': 0.75373774766922, 'learning_rate': 5.135593220338983e-06, 'epoch': 0.49}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2970/6000 [2:53:50<2:51:33,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [2:53:53<2:52:22,  3.41s/it]                                                       {'loss': 0.1533, 'grad_norm': 18.098873138427734, 'learning_rate': 5.133898305084746e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2971/6000 [2:53:53<2:52:22,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [2:53:57<2:53:14,  3.43s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08378706872463226, 'learning_rate': 5.132203389830509e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2972/6000 [2:53:57<2:53:14,  3.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [2:54:00<2:55:00,  3.47s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.9607701301574707, 'learning_rate': 5.1305084745762715e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2973/6000 [2:54:00<2:55:00,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [2:54:04<2:55:05,  3.47s/it]                                                       {'loss': 0.019, 'grad_norm': 5.813796520233154, 'learning_rate': 5.128813559322035e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2974/6000 [2:54:04<2:55:05,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [2:54:07<2:57:18,  3.52s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.13113199174404144, 'learning_rate': 5.127118644067796e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2975/6000 [2:54:07<2:57:18,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [2:54:11<2:57:39,  3.52s/it]                                                       {'loss': 0.0373, 'grad_norm': 8.483607292175293, 'learning_rate': 5.12542372881356e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2976/6000 [2:54:11<2:57:39,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [2:54:15<3:01:49,  3.61s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.20847000181674957, 'learning_rate': 5.123728813559322e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2977/6000 [2:54:15<3:01:49,  3.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [2:54:18<2:57:18,  3.52s/it]                                                       {'loss': 0.0451, 'grad_norm': 5.618985652923584, 'learning_rate': 5.122033898305085e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2978/6000 [2:54:18<2:57:18,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [2:54:21<2:55:53,  3.49s/it]                                                       {'loss': 0.1672, 'grad_norm': 14.715957641601562, 'learning_rate': 5.120338983050848e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2979/6000 [2:54:21<2:55:53,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [2:54:25<3:02:05,  3.62s/it]                                                       {'loss': 0.061, 'grad_norm': 6.418718338012695, 'learning_rate': 5.118644067796611e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2980/6000 [2:54:25<3:02:05,  3.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [2:54:29<2:59:14,  3.56s/it]                                                       {'loss': 0.002, 'grad_norm': 0.4893648028373718, 'learning_rate': 5.1169491525423735e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2981/6000 [2:54:29<2:59:14,  3.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [2:54:32<3:00:27,  3.59s/it]                                                       {'loss': 0.0449, 'grad_norm': 7.842201232910156, 'learning_rate': 5.115254237288137e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2982/6000 [2:54:32<3:00:27,  3.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [2:54:36<2:57:25,  3.53s/it]                                                       {'loss': 0.016, 'grad_norm': 3.4447433948516846, 'learning_rate': 5.113559322033898e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2983/6000 [2:54:36<2:57:25,  3.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [2:54:39<2:53:35,  3.45s/it]                                                       {'loss': 0.0056, 'grad_norm': 2.037734031677246, 'learning_rate': 5.111864406779662e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2984/6000 [2:54:39<2:53:35,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [2:54:42<2:51:58,  3.42s/it]                                                       {'loss': 0.0037, 'grad_norm': 1.2003412246704102, 'learning_rate': 5.110169491525424e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2985/6000 [2:54:42<2:51:58,  3.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [2:54:46<2:56:37,  3.52s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.0218631029129028, 'learning_rate': 5.108474576271187e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2986/6000 [2:54:46<2:56:37,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [2:54:50<2:55:20,  3.49s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.5992166996002197, 'learning_rate': 5.10677966101695e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2987/6000 [2:54:50<2:55:20,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [2:54:53<2:59:37,  3.58s/it]                                                       {'loss': 0.0938, 'grad_norm': 12.207613945007324, 'learning_rate': 5.105084745762711e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2988/6000 [2:54:53<2:59:37,  3.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [2:54:57<2:55:46,  3.50s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.37982556223869324, 'learning_rate': 5.1033898305084754e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2989/6000 [2:54:57<2:55:46,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [2:55:01<3:05:17,  3.69s/it]                                                       {'loss': 0.0248, 'grad_norm': 5.2095561027526855, 'learning_rate': 5.101694915254237e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2990/6000 [2:55:01<3:05:17,  3.69s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [2:55:04<2:59:30,  3.58s/it]                                                       {'loss': 0.0674, 'grad_norm': 5.641531944274902, 'learning_rate': 5.1e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2991/6000 [2:55:04<2:59:30,  3.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [2:55:08<2:56:43,  3.52s/it]                                                       {'loss': 0.2021, 'grad_norm': 15.078609466552734, 'learning_rate': 5.098305084745763e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2992/6000 [2:55:08<2:56:43,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [2:55:11<2:53:20,  3.46s/it]                                                       {'loss': 0.1325, 'grad_norm': 18.002243041992188, 'learning_rate': 5.096610169491526e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2993/6000 [2:55:11<2:53:20,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [2:55:14<2:50:46,  3.41s/it]                                                       {'loss': 0.2311, 'grad_norm': 21.931241989135742, 'learning_rate': 5.0949152542372884e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2994/6000 [2:55:14<2:50:46,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [2:55:18<2:50:16,  3.40s/it]                                                       {'loss': 0.4129, 'grad_norm': 23.676374435424805, 'learning_rate': 5.093220338983052e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2995/6000 [2:55:18<2:50:16,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [2:55:21<2:53:27,  3.46s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.0623677968978882, 'learning_rate': 5.091525423728813e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2996/6000 [2:55:21<2:53:27,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [2:55:25<2:53:01,  3.46s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.8502715826034546, 'learning_rate': 5.0898305084745766e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2997/6000 [2:55:25<2:53:01,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [2:55:28<2:53:28,  3.47s/it]                                                       {'loss': 0.3332, 'grad_norm': 22.441303253173828, 'learning_rate': 5.088135593220339e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2998/6000 [2:55:28<2:53:28,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [2:55:32<2:59:37,  3.59s/it]                                                       {'loss': 0.1077, 'grad_norm': 9.916115760803223, 'learning_rate': 5.086440677966102e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2999/6000 [2:55:32<2:59:37,  3.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [2:55:35<2:57:59,  3.56s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.805572509765625, 'learning_rate': 5.084745762711865e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/6000 [2:55:35<2:57:59,  3.56s/it][2025-11-07 01:46:45,460] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3000
[2025-11-07 01:46:45,478] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:46:46,157] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [2:55:42<3:37:59,  4.36s/it]                                                       {'loss': 0.1298, 'grad_norm': 15.180949211120605, 'learning_rate': 5.083050847457628e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3001/6000 [2:55:42<3:37:59,  4.36s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [2:55:45<3:22:44,  4.06s/it]                                                       {'loss': 0.0995, 'grad_norm': 10.397080421447754, 'learning_rate': 5.08135593220339e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3002/6000 [2:55:45<3:22:44,  4.06s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [2:55:49<3:21:14,  4.03s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.245346188545227, 'learning_rate': 5.079661016949154e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3003/6000 [2:55:49<3:21:14,  4.03s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [2:55:52<3:12:00,  3.85s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.1690940856933594, 'learning_rate': 5.077966101694915e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3004/6000 [2:55:52<3:12:00,  3.85s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [2:55:56<3:08:30,  3.78s/it]                                                       {'loss': 0.0482, 'grad_norm': 8.8372802734375, 'learning_rate': 5.0762711864406785e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3005/6000 [2:55:56<3:08:30,  3.78s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [2:56:00<3:05:07,  3.71s/it]                                                       {'loss': 0.0334, 'grad_norm': 4.557738304138184, 'learning_rate': 5.074576271186441e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3006/6000 [2:56:00<3:05:07,  3.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [2:56:03<3:05:54,  3.73s/it]                                                       {'loss': 0.0269, 'grad_norm': 3.9183363914489746, 'learning_rate': 5.072881355932204e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3007/6000 [2:56:04<3:05:54,  3.73s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [2:56:07<3:03:38,  3.68s/it]                                                       {'loss': 0.1452, 'grad_norm': 17.232067108154297, 'learning_rate': 5.071186440677967e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3008/6000 [2:56:07<3:03:38,  3.68s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [2:56:10<3:00:56,  3.63s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5053467750549316, 'learning_rate': 5.069491525423729e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3009/6000 [2:56:10<3:00:56,  3.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [2:56:14<2:56:30,  3.54s/it]                                                       {'loss': 0.2254, 'grad_norm': 13.906290054321289, 'learning_rate': 5.067796610169492e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3010/6000 [2:56:14<2:56:30,  3.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [2:56:17<2:53:16,  3.48s/it]                                                       {'loss': 0.0095, 'grad_norm': 2.3009703159332275, 'learning_rate': 5.066101694915254e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3011/6000 [2:56:17<2:53:16,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [2:56:21<2:52:28,  3.46s/it]                                                       {'loss': 0.2914, 'grad_norm': 16.65011215209961, 'learning_rate': 5.064406779661017e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3012/6000 [2:56:21<2:52:28,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [2:56:24<2:52:47,  3.47s/it]                                                       {'loss': 0.017, 'grad_norm': 3.1359024047851562, 'learning_rate': 5.06271186440678e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3013/6000 [2:56:24<2:52:47,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [2:56:28<2:52:48,  3.47s/it]                                                       {'loss': 0.0038, 'grad_norm': 1.063485860824585, 'learning_rate': 5.061016949152543e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3014/6000 [2:56:28<2:52:48,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [2:56:31<2:51:17,  3.44s/it]                                                       {'loss': 0.1509, 'grad_norm': 15.1303129196167, 'learning_rate': 5.059322033898305e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3015/6000 [2:56:31<2:51:17,  3.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [2:56:34<2:52:51,  3.48s/it]                                                       {'loss': 0.0697, 'grad_norm': 10.129093170166016, 'learning_rate': 5.057627118644069e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3016/6000 [2:56:34<2:52:51,  3.48s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [2:56:38<2:52:33,  3.47s/it]                                                       {'loss': 0.1248, 'grad_norm': 16.075410842895508, 'learning_rate': 5.055932203389831e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3017/6000 [2:56:38<2:52:33,  3.47s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [2:56:41<2:51:47,  3.46s/it]                                                       {'loss': 0.0351, 'grad_norm': 7.7595415115356445, 'learning_rate': 5.054237288135594e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3018/6000 [2:56:41<2:51:47,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [2:56:45<2:51:42,  3.46s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.27120307087898254, 'learning_rate': 5.052542372881356e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3019/6000 [2:56:45<2:51:42,  3.46s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [2:56:48<2:49:12,  3.41s/it]                                                       {'loss': 0.1679, 'grad_norm': 13.213521003723145, 'learning_rate': 5.050847457627119e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3020/6000 [2:56:48<2:49:12,  3.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [2:56:51<2:48:38,  3.40s/it]                                                       {'loss': 0.0722, 'grad_norm': 8.99276065826416, 'learning_rate': 5.0491525423728816e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3021/6000 [2:56:51<2:48:38,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [2:56:55<2:48:36,  3.40s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.11163706332445145, 'learning_rate': 5.047457627118645e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3022/6000 [2:56:55<2:48:36,  3.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [2:56:59<2:54:39,  3.52s/it]                                                       {'loss': 0.0952, 'grad_norm': 12.281514167785645, 'learning_rate': 5.045762711864407e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3023/6000 [2:56:59<2:54:39,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [2:57:02<2:54:04,  3.51s/it]                                                       {'loss': 0.256, 'grad_norm': 11.801663398742676, 'learning_rate': 5.0440677966101705e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3024/6000 [2:57:02<2:54:04,  3.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [2:57:06<2:54:46,  3.52s/it]                                                       {'loss': 0.1827, 'grad_norm': 14.591052055358887, 'learning_rate': 5.042372881355932e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3025/6000 [2:57:06<2:54:46,  3.52s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [2:57:09<2:56:08,  3.55s/it]                                                       {'loss': 0.0383, 'grad_norm': 6.954475402832031, 'learning_rate': 5.040677966101695e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3026/6000 [2:57:09<2:56:08,  3.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [2:57:13<2:53:05,  3.49s/it]                                                       {'loss': 0.1401, 'grad_norm': 11.586755752563477, 'learning_rate': 5.038983050847458e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3027/6000 [2:57:13<2:53:05,  3.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [2:57:16<2:55:00,  3.53s/it]                                                       {'loss': 0.0438, 'grad_norm': 8.537644386291504, 'learning_rate': 5.037288135593221e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3028/6000 [2:57:16<2:55:00,  3.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [2:57:20<2:53:03,  3.50s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.8320401310920715, 'learning_rate': 5.0355932203389835e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3029/6000 [2:57:20<2:53:03,  3.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [2:57:23<2:51:07,  3.46s/it]                                                       {'loss': 0.0183, 'grad_norm': 3.387338399887085, 'learning_rate': 5.033898305084746e-06, 'epoch': 0.51}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3030/6000 [2:57:23<2:51:07,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [2:57:27<2:51:11,  3.46s/it]                                                       {'loss': 0.0257, 'grad_norm': 2.8341989517211914, 'learning_rate': 5.032203389830509e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3031/6000 [2:57:27<2:51:11,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [2:57:30<2:51:34,  3.47s/it]                                                       {'loss': 0.0265, 'grad_norm': 7.2516703605651855, 'learning_rate': 5.030508474576271e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3032/6000 [2:57:30<2:51:34,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [2:57:33<2:51:03,  3.46s/it]                                                       {'loss': 0.24, 'grad_norm': 13.10234260559082, 'learning_rate': 5.028813559322034e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3033/6000 [2:57:33<2:51:03,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [2:57:37<2:51:13,  3.46s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.968472421169281, 'learning_rate': 5.0271186440677965e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3034/6000 [2:57:37<2:51:13,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [2:57:41<2:54:28,  3.53s/it]                                                       {'loss': 0.0543, 'grad_norm': 7.503343105316162, 'learning_rate': 5.02542372881356e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3035/6000 [2:57:41<2:54:28,  3.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [2:57:44<2:51:49,  3.48s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.024437926709651947, 'learning_rate': 5.023728813559322e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3036/6000 [2:57:44<2:51:49,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [2:57:47<2:51:19,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.034359004348516464, 'learning_rate': 5.0220338983050855e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3037/6000 [2:57:47<2:51:19,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [2:57:51<2:49:35,  3.44s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3580404222011566, 'learning_rate': 5.020338983050848e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3038/6000 [2:57:51<2:49:35,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [2:57:54<2:52:16,  3.49s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.21582378447055817, 'learning_rate': 5.018644067796611e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3039/6000 [2:57:54<2:52:16,  3.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [2:57:58<2:50:51,  3.46s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.8440206050872803, 'learning_rate': 5.016949152542373e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3040/6000 [2:57:58<2:50:51,  3.46s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [2:58:01<2:49:58,  3.45s/it]                                                       {'loss': 0.0334, 'grad_norm': 3.3434715270996094, 'learning_rate': 5.015254237288136e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3041/6000 [2:58:01<2:49:58,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [2:58:05<2:47:43,  3.40s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.9543352127075195, 'learning_rate': 5.0135593220338985e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3042/6000 [2:58:05<2:47:43,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [2:58:08<2:48:15,  3.41s/it]                                                       {'loss': 0.1469, 'grad_norm': 15.937217712402344, 'learning_rate': 5.011864406779662e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3043/6000 [2:58:08<2:48:15,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [2:58:11<2:48:33,  3.42s/it]                                                       {'loss': 0.013, 'grad_norm': 1.6568975448608398, 'learning_rate': 5.010169491525424e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3044/6000 [2:58:11<2:48:33,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [2:58:15<2:48:18,  3.42s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1112901046872139, 'learning_rate': 5.0084745762711874e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3045/6000 [2:58:15<2:48:18,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [2:58:18<2:50:39,  3.47s/it]                                                       {'loss': 0.1568, 'grad_norm': 14.454248428344727, 'learning_rate': 5.00677966101695e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3046/6000 [2:58:18<2:50:39,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [2:58:22<2:49:07,  3.44s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.0187175273895264, 'learning_rate': 5.005084745762713e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/6000 [2:58:22<2:49:07,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [2:58:25<2:51:59,  3.50s/it]                                                       {'loss': 0.0758, 'grad_norm': 7.366703510284424, 'learning_rate': 5.003389830508475e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3048/6000 [2:58:25<2:51:59,  3.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [2:58:29<2:56:33,  3.59s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.7459042072296143, 'learning_rate': 5.001694915254238e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3049/6000 [2:58:29<2:56:33,  3.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [2:58:33<2:56:18,  3.59s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.14802615344524384, 'learning_rate': 5e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3050/6000 [2:58:33<2:56:18,  3.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [2:58:37<3:01:48,  3.70s/it]                                                       {'loss': 0.3641, 'grad_norm': 20.259170532226562, 'learning_rate': 4.998305084745763e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3051/6000 [2:58:37<3:01:48,  3.70s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [2:58:40<3:02:42,  3.72s/it]                                                       {'loss': 0.0672, 'grad_norm': 8.844015121459961, 'learning_rate': 4.996610169491526e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3052/6000 [2:58:40<3:02:42,  3.72s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [2:58:44<2:56:15,  3.59s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.6415584087371826, 'learning_rate': 4.9949152542372885e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3053/6000 [2:58:44<2:56:15,  3.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [2:58:47<2:53:02,  3.52s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.4561525285243988, 'learning_rate': 4.993220338983051e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3054/6000 [2:58:47<2:53:02,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [2:58:51<2:51:42,  3.50s/it]                                                       {'loss': 0.0826, 'grad_norm': 11.864377975463867, 'learning_rate': 4.991525423728814e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3055/6000 [2:58:51<2:51:42,  3.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [2:58:54<2:52:08,  3.51s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.5503597259521484, 'learning_rate': 4.989830508474577e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3056/6000 [2:58:54<2:52:08,  3.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [2:58:58<2:51:00,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.7903008460998535, 'learning_rate': 4.98813559322034e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3057/6000 [2:58:58<2:51:00,  3.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [2:59:01<2:49:10,  3.45s/it]                                                       {'loss': 0.0435, 'grad_norm': 7.726216793060303, 'learning_rate': 4.986440677966102e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3058/6000 [2:59:01<2:49:10,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [2:59:05<2:57:44,  3.63s/it]                                                       {'loss': 0.0138, 'grad_norm': 3.3177430629730225, 'learning_rate': 4.984745762711865e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3059/6000 [2:59:05<2:57:44,  3.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [2:59:09<2:57:08,  3.61s/it]                                                       {'loss': 0.0142, 'grad_norm': 3.595855712890625, 'learning_rate': 4.983050847457628e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3060/6000 [2:59:09<2:57:08,  3.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [2:59:12<2:53:42,  3.55s/it]                                                       {'loss': 0.0382, 'grad_norm': 6.795632362365723, 'learning_rate': 4.98135593220339e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3061/6000 [2:59:12<2:53:42,  3.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [2:59:15<2:50:40,  3.49s/it]                                                       {'loss': 0.014, 'grad_norm': 2.147702217102051, 'learning_rate': 4.979661016949153e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3062/6000 [2:59:15<2:50:40,  3.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [2:59:19<2:48:58,  3.45s/it]                                                       {'loss': 0.0454, 'grad_norm': 8.046609878540039, 'learning_rate': 4.977966101694915e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3063/6000 [2:59:19<2:48:58,  3.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [2:59:23<2:54:54,  3.57s/it]                                                       {'loss': 0.0094, 'grad_norm': 3.499774694442749, 'learning_rate': 4.976271186440678e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3064/6000 [2:59:23<2:54:54,  3.57s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [2:59:26<2:51:59,  3.52s/it]                                                       {'loss': 0.2409, 'grad_norm': 15.05384635925293, 'learning_rate': 4.974576271186441e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3065/6000 [2:59:26<2:51:59,  3.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [2:59:29<2:49:31,  3.47s/it]                                                       {'loss': 0.014, 'grad_norm': 4.384941577911377, 'learning_rate': 4.9728813559322035e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3066/6000 [2:59:29<2:49:31,  3.47s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [2:59:33<2:47:29,  3.43s/it]                                                       {'loss': 0.003, 'grad_norm': 0.9339092969894409, 'learning_rate': 4.971186440677967e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3067/6000 [2:59:33<2:47:29,  3.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [2:59:36<2:48:06,  3.44s/it]                                                       {'loss': 0.017, 'grad_norm': 3.38569974899292, 'learning_rate': 4.969491525423729e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3068/6000 [2:59:36<2:48:06,  3.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [2:59:39<2:47:00,  3.42s/it]                                                       {'loss': 0.1445, 'grad_norm': 13.918371200561523, 'learning_rate': 4.967796610169492e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3069/6000 [2:59:39<2:47:00,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [2:59:43<2:46:14,  3.40s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3889816105365753, 'learning_rate': 4.966101694915255e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3070/6000 [2:59:43<2:46:14,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [2:59:46<2:46:05,  3.40s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.2231833934783936, 'learning_rate': 4.964406779661017e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3071/6000 [2:59:46<2:46:05,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [2:59:50<2:45:23,  3.39s/it]                                                       {'loss': 0.0328, 'grad_norm': 6.887514591217041, 'learning_rate': 4.96271186440678e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3072/6000 [2:59:50<2:45:23,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [2:59:53<2:51:24,  3.51s/it]                                                       {'loss': 0.001, 'grad_norm': 0.4357454776763916, 'learning_rate': 4.961016949152543e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3073/6000 [2:59:53<2:51:24,  3.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [2:59:57<2:52:03,  3.53s/it]                                                       {'loss': 0.3936, 'grad_norm': 18.111774444580078, 'learning_rate': 4.9593220338983054e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3074/6000 [2:59:57<2:52:03,  3.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [3:00:00<2:49:43,  3.48s/it]                                                       {'loss': 0.1771, 'grad_norm': 9.898355484008789, 'learning_rate': 4.957627118644069e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3075/6000 [3:00:00<2:49:43,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [3:00:04<2:52:50,  3.55s/it]                                                       {'loss': 0.1169, 'grad_norm': 9.680506706237793, 'learning_rate': 4.955932203389831e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3076/6000 [3:00:04<2:52:50,  3.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [3:00:07<2:49:31,  3.48s/it]                                                       {'loss': 0.0097, 'grad_norm': 2.3375842571258545, 'learning_rate': 4.9542372881355936e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3077/6000 [3:00:07<2:49:31,  3.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [3:00:11<2:46:39,  3.42s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.9992485046386719, 'learning_rate': 4.952542372881357e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3078/6000 [3:00:11<2:46:39,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [3:00:14<2:45:37,  3.40s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.7130553722381592, 'learning_rate': 4.950847457627119e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3079/6000 [3:00:14<2:45:37,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [3:00:17<2:44:54,  3.39s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.6957491040229797, 'learning_rate': 4.949152542372882e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3080/6000 [3:00:17<2:44:54,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [3:00:21<2:45:20,  3.40s/it]                                                       {'loss': 0.0636, 'grad_norm': 9.748054504394531, 'learning_rate': 4.947457627118645e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3081/6000 [3:00:21<2:45:20,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [3:00:24<2:45:27,  3.40s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.5183064341545105, 'learning_rate': 4.9457627118644065e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3082/6000 [3:00:24<2:45:27,  3.40s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [3:00:28<2:46:23,  3.42s/it]                                                       {'loss': 0.0225, 'grad_norm': 3.08644437789917, 'learning_rate': 4.94406779661017e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3083/6000 [3:00:28<2:46:23,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [3:00:31<2:46:19,  3.42s/it]                                                       {'loss': 0.0997, 'grad_norm': 13.246236801147461, 'learning_rate': 4.942372881355932e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3084/6000 [3:00:31<2:46:19,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [3:00:34<2:46:00,  3.42s/it]                                                       {'loss': 0.0706, 'grad_norm': 13.107595443725586, 'learning_rate': 4.9406779661016955e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3085/6000 [3:00:34<2:46:00,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [3:00:38<2:45:54,  3.42s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.110666513442993, 'learning_rate': 4.938983050847458e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3086/6000 [3:00:38<2:45:54,  3.42s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [3:00:41<2:44:33,  3.39s/it]                                                       {'loss': 0.0668, 'grad_norm': 8.467883110046387, 'learning_rate': 4.93728813559322e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3087/6000 [3:00:41<2:44:33,  3.39s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [3:00:45<2:45:42,  3.41s/it]                                                       {'loss': 0.1906, 'grad_norm': 19.115245819091797, 'learning_rate': 4.935593220338984e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3088/6000 [3:00:45<2:45:42,  3.41s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [3:00:48<2:45:15,  3.41s/it]                                                       {'loss': 0.1682, 'grad_norm': 16.707284927368164, 'learning_rate': 4.933898305084746e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3089/6000 [3:00:48<2:45:15,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [3:00:52<2:47:42,  3.46s/it]                                                       {'loss': 0.0439, 'grad_norm': 10.043492317199707, 'learning_rate': 4.9322033898305085e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3090/6000 [3:00:52<2:47:42,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [3:00:55<2:45:59,  3.42s/it]                                                       {'loss': 0.2715, 'grad_norm': 15.293106079101562, 'learning_rate': 4.930508474576272e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3091/6000 [3:00:55<2:45:59,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [3:00:59<2:48:43,  3.48s/it]                                                       {'loss': 0.2131, 'grad_norm': 16.19757080078125, 'learning_rate': 4.928813559322034e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3092/6000 [3:00:59<2:48:43,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [3:01:02<2:47:05,  3.45s/it]                                                       {'loss': 0.0333, 'grad_norm': 6.121057510375977, 'learning_rate': 4.9271186440677975e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3093/6000 [3:01:02<2:47:05,  3.45s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [3:01:06<2:54:16,  3.60s/it]                                                       {'loss': 0.0091, 'grad_norm': 3.001117467880249, 'learning_rate': 4.92542372881356e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3094/6000 [3:01:06<2:54:16,  3.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [3:01:09<2:51:15,  3.54s/it]                                                       {'loss': 0.0296, 'grad_norm': 8.184981346130371, 'learning_rate': 4.923728813559322e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/6000 [3:01:09<2:51:15,  3.54s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [3:01:13<2:48:03,  3.47s/it]                                                       {'loss': 0.0328, 'grad_norm': 3.7438321113586426, 'learning_rate': 4.922033898305086e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3096/6000 [3:01:13<2:48:03,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [3:01:16<2:46:35,  3.44s/it]                                                       {'loss': 0.1666, 'grad_norm': 16.955753326416016, 'learning_rate': 4.920338983050848e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3097/6000 [3:01:16<2:46:35,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [3:01:19<2:45:41,  3.43s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.910433530807495, 'learning_rate': 4.9186440677966104e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3098/6000 [3:01:19<2:45:41,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [3:01:23<2:44:18,  3.40s/it]                                                       {'loss': 0.0352, 'grad_norm': 4.8060150146484375, 'learning_rate': 4.916949152542374e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3099/6000 [3:01:23<2:44:18,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [3:01:26<2:44:10,  3.40s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.611305832862854, 'learning_rate': 4.915254237288136e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3100/6000 [3:01:26<2:44:10,  3.40s/it][2025-11-07 01:52:36,083] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3100
[2025-11-07 01:52:36,097] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:52:36,797] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [3:01:32<3:18:50,  4.12s/it]                                                       {'loss': 0.0449, 'grad_norm': 3.92480206489563, 'learning_rate': 4.9135593220338986e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3101/6000 [3:01:32<3:18:50,  4.12s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [3:01:35<3:08:45,  3.91s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.05063029006123543, 'learning_rate': 4.911864406779661e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3102/6000 [3:01:35<3:08:45,  3.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [3:01:39<3:00:51,  3.75s/it]                                                       {'loss': 0.2475, 'grad_norm': 18.88568878173828, 'learning_rate': 4.910169491525424e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3103/6000 [3:01:39<3:00:51,  3.75s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [3:01:42<2:54:48,  3.62s/it]                                                       {'loss': 0.1492, 'grad_norm': 8.417634010314941, 'learning_rate': 4.908474576271187e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3104/6000 [3:01:42<2:54:48,  3.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [3:01:45<2:52:09,  3.57s/it]                                                       {'loss': 0.0973, 'grad_norm': 8.70083999633789, 'learning_rate': 4.906779661016949e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3105/6000 [3:01:45<2:52:09,  3.57s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [3:01:49<2:57:30,  3.68s/it]                                                       {'loss': 0.0379, 'grad_norm': 7.017038345336914, 'learning_rate': 4.905084745762712e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3106/6000 [3:01:49<2:57:30,  3.68s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [3:01:53<2:53:01,  3.59s/it]                                                       {'loss': 0.0908, 'grad_norm': 14.617349624633789, 'learning_rate': 4.903389830508475e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3107/6000 [3:01:53<2:53:01,  3.59s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [3:01:56<2:50:18,  3.53s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.2993395328521729, 'learning_rate': 4.901694915254237e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3108/6000 [3:01:56<2:50:18,  3.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [3:02:00<2:48:09,  3.49s/it]                                                       {'loss': 0.0213, 'grad_norm': 6.269554138183594, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3109/6000 [3:02:00<2:48:09,  3.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [3:02:03<2:48:53,  3.51s/it]                                                       {'loss': 0.043, 'grad_norm': 9.869462966918945, 'learning_rate': 4.898305084745763e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3110/6000 [3:02:03<2:48:53,  3.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [3:02:07<2:47:44,  3.48s/it]                                                       {'loss': 0.041, 'grad_norm': 11.7735013961792, 'learning_rate': 4.896610169491525e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3111/6000 [3:02:07<2:47:44,  3.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [3:02:10<2:49:24,  3.52s/it]                                                       {'loss': 0.0533, 'grad_norm': 10.254315376281738, 'learning_rate': 4.894915254237289e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3112/6000 [3:02:10<2:49:24,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [3:02:13<2:46:35,  3.46s/it]                                                       {'loss': 0.0132, 'grad_norm': 3.317662000656128, 'learning_rate': 4.893220338983051e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3113/6000 [3:02:13<2:46:35,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [3:02:17<2:45:32,  3.44s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.3692820370197296, 'learning_rate': 4.891525423728814e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3114/6000 [3:02:17<2:45:32,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [3:02:20<2:46:37,  3.47s/it]                                                       {'loss': 0.2142, 'grad_norm': 14.224535942077637, 'learning_rate': 4.889830508474577e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3115/6000 [3:02:20<2:46:37,  3.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [3:02:24<2:52:52,  3.60s/it]                                                       {'loss': 0.0237, 'grad_norm': 4.472790718078613, 'learning_rate': 4.888135593220339e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3116/6000 [3:02:24<2:52:52,  3.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [3:02:28<2:51:01,  3.56s/it]                                                       {'loss': 0.0732, 'grad_norm': 11.894952774047852, 'learning_rate': 4.8864406779661025e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3117/6000 [3:02:28<2:51:01,  3.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [3:02:32<2:55:17,  3.65s/it]                                                       {'loss': 0.0161, 'grad_norm': 2.729853868484497, 'learning_rate': 4.884745762711865e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3118/6000 [3:02:32<2:55:17,  3.65s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [3:02:35<2:57:34,  3.70s/it]                                                       {'loss': 0.0157, 'grad_norm': 4.623867034912109, 'learning_rate': 4.883050847457627e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3119/6000 [3:02:35<2:57:34,  3.70s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [3:02:39<2:53:39,  3.62s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.3737951517105103, 'learning_rate': 4.881355932203391e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3120/6000 [3:02:39<2:53:39,  3.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [3:02:42<2:51:16,  3.57s/it]                                                       {'loss': 0.0213, 'grad_norm': 5.489009857177734, 'learning_rate': 4.879661016949153e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3121/6000 [3:02:42<2:51:16,  3.57s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [3:02:46<2:49:45,  3.54s/it]                                                       {'loss': 0.0099, 'grad_norm': 2.5733940601348877, 'learning_rate': 4.877966101694916e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3122/6000 [3:02:46<2:49:45,  3.54s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [3:02:49<2:50:10,  3.55s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2345612794160843, 'learning_rate': 4.876271186440678e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3123/6000 [3:02:49<2:50:10,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [3:02:53<2:50:22,  3.55s/it]                                                       {'loss': 0.043, 'grad_norm': 10.000802993774414, 'learning_rate': 4.874576271186441e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3124/6000 [3:02:53<2:50:22,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [3:02:56<2:47:00,  3.49s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.9746297597885132, 'learning_rate': 4.872881355932204e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3125/6000 [3:02:56<2:47:00,  3.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [3:03:00<2:44:52,  3.44s/it]                                                       {'loss': 0.2099, 'grad_norm': 12.699441909790039, 'learning_rate': 4.871186440677966e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3126/6000 [3:03:00<2:44:52,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [3:03:03<2:44:51,  3.44s/it]                                                       {'loss': 0.0544, 'grad_norm': 12.531054496765137, 'learning_rate': 4.869491525423729e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3127/6000 [3:03:03<2:44:51,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [3:03:06<2:44:46,  3.44s/it]                                                       {'loss': 0.0266, 'grad_norm': 3.863236665725708, 'learning_rate': 4.867796610169492e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3128/6000 [3:03:06<2:44:46,  3.44s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [3:03:10<2:50:00,  3.55s/it]                                                       {'loss': 0.0718, 'grad_norm': 12.90059757232666, 'learning_rate': 4.866101694915254e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3129/6000 [3:03:10<2:50:00,  3.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [3:03:14<2:46:54,  3.49s/it]                                                       {'loss': 0.1451, 'grad_norm': 16.91812515258789, 'learning_rate': 4.864406779661017e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3130/6000 [3:03:14<2:46:54,  3.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [3:03:17<2:45:35,  3.46s/it]                                                       {'loss': 0.0263, 'grad_norm': 8.95665168762207, 'learning_rate': 4.86271186440678e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3131/6000 [3:03:17<2:45:35,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [3:03:20<2:42:46,  3.41s/it]                                                       {'loss': 0.0083, 'grad_norm': 2.329914093017578, 'learning_rate': 4.861016949152543e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3132/6000 [3:03:20<2:42:46,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [3:03:24<2:42:29,  3.40s/it]                                                       {'loss': 0.004, 'grad_norm': 0.85010826587677, 'learning_rate': 4.8593220338983055e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3133/6000 [3:03:24<2:42:29,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [3:03:28<2:48:26,  3.53s/it]                                                       {'loss': 0.1096, 'grad_norm': 11.400450706481934, 'learning_rate': 4.857627118644068e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3134/6000 [3:03:28<2:48:26,  3.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [3:03:31<2:49:04,  3.54s/it]                                                       {'loss': 0.0696, 'grad_norm': 9.058802604675293, 'learning_rate': 4.855932203389831e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3135/6000 [3:03:31<2:49:04,  3.54s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [3:03:35<2:48:14,  3.52s/it]                                                       {'loss': 0.2748, 'grad_norm': 11.389988899230957, 'learning_rate': 4.854237288135594e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3136/6000 [3:03:35<2:48:14,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [3:03:38<2:48:12,  3.52s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1942395269870758, 'learning_rate': 4.852542372881356e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3137/6000 [3:03:38<2:48:12,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [3:03:42<2:49:34,  3.56s/it]                                                       {'loss': 0.0404, 'grad_norm': 8.60390853881836, 'learning_rate': 4.850847457627119e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3138/6000 [3:03:42<2:49:34,  3.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [3:03:45<2:47:43,  3.52s/it]                                                       {'loss': 0.011, 'grad_norm': 2.3319053649902344, 'learning_rate': 4.849152542372882e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3139/6000 [3:03:45<2:47:43,  3.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [3:03:48<2:44:59,  3.46s/it]                                                       {'loss': 0.0196, 'grad_norm': 2.2223808765411377, 'learning_rate': 4.847457627118645e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3140/6000 [3:03:48<2:44:59,  3.46s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [3:03:52<2:44:15,  3.45s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.270267367362976, 'learning_rate': 4.8457627118644075e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3141/6000 [3:03:52<2:44:15,  3.45s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [3:03:55<2:43:27,  3.43s/it]                                                       {'loss': 0.0202, 'grad_norm': 2.3810675144195557, 'learning_rate': 4.84406779661017e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3142/6000 [3:03:55<2:43:27,  3.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [3:03:59<2:42:12,  3.41s/it]                                                       {'loss': 0.1408, 'grad_norm': 12.80056095123291, 'learning_rate': 4.842372881355933e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3143/6000 [3:03:59<2:42:12,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [3:04:02<2:42:02,  3.40s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.245085671544075, 'learning_rate': 4.840677966101695e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3144/6000 [3:04:02<2:42:02,  3.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [3:04:05<2:42:08,  3.41s/it]                                                       {'loss': 0.0788, 'grad_norm': 13.29427433013916, 'learning_rate': 4.838983050847458e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3145/6000 [3:04:05<2:42:08,  3.41s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [3:04:09<2:41:15,  3.39s/it]                                                       {'loss': 0.0148, 'grad_norm': 3.055115222930908, 'learning_rate': 4.8372881355932205e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3146/6000 [3:04:09<2:41:15,  3.39s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [3:04:12<2:40:11,  3.37s/it]                                                       {'loss': 0.0707, 'grad_norm': 11.803454399108887, 'learning_rate': 4.835593220338983e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3147/6000 [3:04:12<2:40:11,  3.37s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [3:04:15<2:40:16,  3.37s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3442363440990448, 'learning_rate': 4.833898305084746e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3148/6000 [3:04:16<2:40:16,  3.37s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [3:04:19<2:42:19,  3.42s/it]                                                       {'loss': 0.0848, 'grad_norm': 11.142271995544434, 'learning_rate': 4.832203389830509e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3149/6000 [3:04:19<2:42:19,  3.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [3:04:22<2:41:12,  3.39s/it]                                                       {'loss': 0.0927, 'grad_norm': 10.74303913116455, 'learning_rate': 4.830508474576272e-06, 'epoch': 0.53}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3150/6000 [3:04:22<2:41:12,  3.39s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [3:04:26<2:42:54,  3.43s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.37335479259490967, 'learning_rate': 4.828813559322034e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3151/6000 [3:04:26<2:42:54,  3.43s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [3:04:29<2:41:20,  3.40s/it]                                                       {'loss': 0.0819, 'grad_norm': 11.913939476013184, 'learning_rate': 4.827118644067797e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3152/6000 [3:04:29<2:41:20,  3.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [3:04:33<2:40:06,  3.37s/it]                                                       {'loss': 0.0193, 'grad_norm': 4.125097751617432, 'learning_rate': 4.82542372881356e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3153/6000 [3:04:33<2:40:06,  3.37s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [3:04:36<2:40:33,  3.39s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.8923826813697815, 'learning_rate': 4.823728813559322e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3154/6000 [3:04:36<2:40:33,  3.39s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [3:04:39<2:41:06,  3.40s/it]                                                       {'loss': 0.1421, 'grad_norm': 10.1533203125, 'learning_rate': 4.822033898305085e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3155/6000 [3:04:39<2:41:06,  3.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [3:04:43<2:40:49,  3.39s/it]                                                       {'loss': 0.0907, 'grad_norm': 16.059356689453125, 'learning_rate': 4.820338983050848e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3156/6000 [3:04:43<2:40:49,  3.39s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [3:04:46<2:43:00,  3.44s/it]                                                       {'loss': 0.0848, 'grad_norm': 6.388935565948486, 'learning_rate': 4.8186440677966105e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3157/6000 [3:04:46<2:43:00,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [3:04:50<2:42:49,  3.44s/it]                                                       {'loss': 0.0097, 'grad_norm': 3.1614913940429688, 'learning_rate': 4.816949152542373e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3158/6000 [3:04:50<2:42:49,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [3:04:53<2:43:11,  3.45s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.210197925567627, 'learning_rate': 4.815254237288136e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3159/6000 [3:04:53<2:43:11,  3.45s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [3:04:57<2:47:05,  3.53s/it]                                                       {'loss': 0.0309, 'grad_norm': 9.101167678833008, 'learning_rate': 4.813559322033899e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3160/6000 [3:04:57<2:47:05,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [3:05:01<2:48:44,  3.57s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.48686325550079346, 'learning_rate': 4.811864406779662e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3161/6000 [3:05:01<2:48:44,  3.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [3:05:04<2:46:55,  3.53s/it]                                                       {'loss': 0.0944, 'grad_norm': 14.458988189697266, 'learning_rate': 4.810169491525424e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3162/6000 [3:05:04<2:46:55,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [3:05:07<2:45:54,  3.51s/it]                                                       {'loss': 0.0111, 'grad_norm': 3.5134775638580322, 'learning_rate': 4.808474576271187e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3163/6000 [3:05:07<2:45:54,  3.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [3:05:11<2:50:23,  3.60s/it]                                                       {'loss': 0.0056, 'grad_norm': 2.2900760173797607, 'learning_rate': 4.80677966101695e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3164/6000 [3:05:11<2:50:23,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [3:05:15<2:47:38,  3.55s/it]                                                       {'loss': 0.0741, 'grad_norm': 9.066192626953125, 'learning_rate': 4.805084745762712e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3165/6000 [3:05:15<2:47:38,  3.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [3:05:18<2:49:03,  3.58s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.8159608840942383, 'learning_rate': 4.803389830508475e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3166/6000 [3:05:18<2:49:03,  3.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [3:05:22<2:45:45,  3.51s/it]                                                       {'loss': 0.2319, 'grad_norm': 15.388284683227539, 'learning_rate': 4.801694915254237e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3167/6000 [3:05:22<2:45:45,  3.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [3:05:25<2:48:01,  3.56s/it]                                                       {'loss': 0.2053, 'grad_norm': 20.747217178344727, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3168/6000 [3:05:25<2:48:01,  3.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [3:05:29<2:45:52,  3.52s/it]                                                       {'loss': 0.0806, 'grad_norm': 7.688350200653076, 'learning_rate': 4.798305084745763e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3169/6000 [3:05:29<2:45:52,  3.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [3:05:32<2:45:02,  3.50s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.1231249570846558, 'learning_rate': 4.7966101694915255e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3170/6000 [3:05:32<2:45:02,  3.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [3:05:36<2:48:42,  3.58s/it]                                                       {'loss': 0.0227, 'grad_norm': 5.233449935913086, 'learning_rate': 4.794915254237289e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3171/6000 [3:05:36<2:48:42,  3.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [3:05:40<2:52:37,  3.66s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.8629670143127441, 'learning_rate': 4.793220338983051e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3172/6000 [3:05:40<2:52:37,  3.66s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [3:05:44<2:53:37,  3.69s/it]                                                       {'loss': 0.0335, 'grad_norm': 4.004134654998779, 'learning_rate': 4.791525423728814e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3173/6000 [3:05:44<2:53:37,  3.69s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [3:05:47<2:50:24,  3.62s/it]                                                       {'loss': 0.2294, 'grad_norm': 12.366153717041016, 'learning_rate': 4.789830508474577e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3174/6000 [3:05:47<2:50:24,  3.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [3:05:51<2:49:05,  3.59s/it]                                                       {'loss': 0.0105, 'grad_norm': 2.2454023361206055, 'learning_rate': 4.788135593220339e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3175/6000 [3:05:51<2:49:05,  3.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [3:05:54<2:49:33,  3.60s/it]                                                       {'loss': 0.0235, 'grad_norm': 6.980250358581543, 'learning_rate': 4.786440677966102e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3176/6000 [3:05:54<2:49:33,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [3:05:58<2:47:00,  3.55s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.3784850537776947, 'learning_rate': 4.784745762711865e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3177/6000 [3:05:58<2:47:00,  3.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [3:06:01<2:49:05,  3.60s/it]                                                       {'loss': 0.0649, 'grad_norm': 8.884099960327148, 'learning_rate': 4.7830508474576274e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3178/6000 [3:06:01<2:49:05,  3.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [3:06:05<2:46:05,  3.53s/it]                                                       {'loss': 0.0397, 'grad_norm': 7.173266410827637, 'learning_rate': 4.781355932203391e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3179/6000 [3:06:05<2:46:05,  3.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [3:06:08<2:45:26,  3.52s/it]                                                       {'loss': 0.1008, 'grad_norm': 10.717134475708008, 'learning_rate': 4.779661016949153e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3180/6000 [3:06:08<2:45:26,  3.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [3:06:12<2:43:13,  3.47s/it]                                                       {'loss': 0.0559, 'grad_norm': 10.5877685546875, 'learning_rate': 4.7779661016949156e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3181/6000 [3:06:12<2:43:13,  3.47s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [3:06:15<2:42:00,  3.45s/it]                                                       {'loss': 0.157, 'grad_norm': 17.084388732910156, 'learning_rate': 4.776271186440679e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3182/6000 [3:06:15<2:42:00,  3.45s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [3:06:18<2:40:43,  3.42s/it]                                                       {'loss': 0.092, 'grad_norm': 13.199468612670898, 'learning_rate': 4.774576271186441e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3183/6000 [3:06:18<2:40:43,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [3:06:22<2:45:17,  3.52s/it]                                                       {'loss': 0.042, 'grad_norm': 5.277705192565918, 'learning_rate': 4.772881355932204e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3184/6000 [3:06:22<2:45:17,  3.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [3:06:25<2:42:30,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1179148405790329, 'learning_rate': 4.771186440677967e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3185/6000 [3:06:25<2:42:30,  3.46s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [3:06:29<2:40:29,  3.42s/it]                                                       {'loss': 0.0181, 'grad_norm': 4.601932525634766, 'learning_rate': 4.7694915254237285e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3186/6000 [3:06:29<2:40:29,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [3:06:32<2:39:32,  3.40s/it]                                                       {'loss': 0.025, 'grad_norm': 6.266357898712158, 'learning_rate': 4.767796610169492e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3187/6000 [3:06:32<2:39:32,  3.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [3:06:36<2:39:40,  3.41s/it]                                                       {'loss': 0.0958, 'grad_norm': 11.507085800170898, 'learning_rate': 4.766101694915254e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3188/6000 [3:06:36<2:39:40,  3.41s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [3:06:39<2:40:15,  3.42s/it]                                                       {'loss': 0.0576, 'grad_norm': 12.39654541015625, 'learning_rate': 4.7644067796610175e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3189/6000 [3:06:39<2:40:15,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [3:06:43<2:49:27,  3.62s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.5744867324829102, 'learning_rate': 4.76271186440678e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/6000 [3:06:43<2:49:27,  3.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [3:06:47<2:46:46,  3.56s/it]                                                       {'loss': 0.0192, 'grad_norm': 3.371424436569214, 'learning_rate': 4.761016949152542e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3191/6000 [3:06:47<2:46:46,  3.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [3:06:50<2:42:45,  3.48s/it]                                                       {'loss': 0.0592, 'grad_norm': 8.812314987182617, 'learning_rate': 4.759322033898306e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3192/6000 [3:06:50<2:42:45,  3.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [3:06:53<2:41:09,  3.44s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.8703129887580872, 'learning_rate': 4.757627118644068e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3193/6000 [3:06:53<2:41:09,  3.44s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [3:06:57<2:39:54,  3.42s/it]                                                       {'loss': 0.095, 'grad_norm': 11.991475105285645, 'learning_rate': 4.7559322033898305e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3194/6000 [3:06:57<2:39:54,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [3:07:00<2:38:34,  3.39s/it]                                                       {'loss': 0.024, 'grad_norm': 6.27669095993042, 'learning_rate': 4.754237288135594e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/6000 [3:07:00<2:38:34,  3.39s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [3:07:03<2:36:56,  3.36s/it]                                                       {'loss': 0.1042, 'grad_norm': 11.386932373046875, 'learning_rate': 4.752542372881356e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3196/6000 [3:07:03<2:36:56,  3.36s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [3:07:07<2:37:27,  3.37s/it]                                                       {'loss': 0.1149, 'grad_norm': 13.159250259399414, 'learning_rate': 4.7508474576271195e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3197/6000 [3:07:07<2:37:27,  3.37s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [3:07:10<2:37:57,  3.38s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.3929254412651062, 'learning_rate': 4.749152542372882e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3198/6000 [3:07:10<2:37:57,  3.38s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [3:07:13<2:39:31,  3.42s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.1538000106811523, 'learning_rate': 4.747457627118644e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3199/6000 [3:07:13<2:39:31,  3.42s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [3:07:17<2:39:10,  3.41s/it]                                                       {'loss': 0.012, 'grad_norm': 4.033820152282715, 'learning_rate': 4.745762711864408e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3200/6000 [3:07:17<2:39:10,  3.41s/it][2025-11-07 01:58:26,825] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3200
[2025-11-07 01:58:27,181] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 01:58:27,863] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [3:07:23<3:15:56,  4.20s/it]                                                       {'loss': 0.02, 'grad_norm': 3.103681802749634, 'learning_rate': 4.74406779661017e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3201/6000 [3:07:23<3:15:56,  4.20s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [3:07:26<3:03:49,  3.94s/it]                                                       {'loss': 0.0722, 'grad_norm': 9.25905990600586, 'learning_rate': 4.7423728813559325e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3202/6000 [3:07:26<3:03:49,  3.94s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [3:07:30<2:54:58,  3.75s/it]                                                       {'loss': 0.05, 'grad_norm': 8.08223819732666, 'learning_rate': 4.740677966101696e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3203/6000 [3:07:30<2:54:58,  3.75s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [3:07:33<2:49:08,  3.63s/it]                                                       {'loss': 0.0551, 'grad_norm': 6.845877170562744, 'learning_rate': 4.738983050847458e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3204/6000 [3:07:33<2:49:08,  3.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [3:07:36<2:46:14,  3.57s/it]                                                       {'loss': 0.0237, 'grad_norm': 1.9183586835861206, 'learning_rate': 4.737288135593221e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3205/6000 [3:07:36<2:46:14,  3.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [3:07:40<2:53:41,  3.73s/it]                                                       {'loss': 0.0873, 'grad_norm': 6.471154689788818, 'learning_rate': 4.735593220338983e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3206/6000 [3:07:40<2:53:41,  3.73s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [3:07:44<2:49:33,  3.64s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.4167168140411377, 'learning_rate': 4.733898305084746e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3207/6000 [3:07:44<2:49:33,  3.64s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [3:07:47<2:48:42,  3.63s/it]                                                       {'loss': 0.0054, 'grad_norm': 0.8954951763153076, 'learning_rate': 4.732203389830509e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3208/6000 [3:07:47<2:48:42,  3.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [3:07:51<2:46:34,  3.58s/it]                                                       {'loss': 0.1107, 'grad_norm': 12.079065322875977, 'learning_rate': 4.730508474576271e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3209/6000 [3:07:51<2:46:34,  3.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [3:07:54<2:44:46,  3.54s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.4720476865768433, 'learning_rate': 4.728813559322034e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3210/6000 [3:07:54<2:44:46,  3.54s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [3:07:58<2:43:30,  3.52s/it]                                                       {'loss': 0.0102, 'grad_norm': 3.120506763458252, 'learning_rate': 4.727118644067797e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3211/6000 [3:07:58<2:43:30,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [3:08:01<2:41:53,  3.48s/it]                                                       {'loss': 0.0047, 'grad_norm': 1.0387756824493408, 'learning_rate': 4.725423728813559e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3212/6000 [3:08:01<2:41:53,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [3:08:05<2:44:25,  3.54s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.8481435775756836, 'learning_rate': 4.7237288135593225e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3213/6000 [3:08:05<2:44:25,  3.54s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [3:08:08<2:43:08,  3.51s/it]                                                       {'loss': 0.0482, 'grad_norm': 2.1231157779693604, 'learning_rate': 4.722033898305085e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3214/6000 [3:08:08<2:43:08,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [3:08:12<2:47:17,  3.60s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.7850215435028076, 'learning_rate': 4.720338983050848e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3215/6000 [3:08:12<2:47:17,  3.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [3:08:16<2:43:38,  3.53s/it]                                                       {'loss': 0.1114, 'grad_norm': 15.907674789428711, 'learning_rate': 4.718644067796611e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3216/6000 [3:08:16<2:43:38,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [3:08:19<2:43:42,  3.53s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.7863951921463013, 'learning_rate': 4.716949152542373e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3217/6000 [3:08:19<2:43:42,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [3:08:22<2:42:14,  3.50s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.40309157967567444, 'learning_rate': 4.715254237288136e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3218/6000 [3:08:22<2:42:14,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [3:08:26<2:41:15,  3.48s/it]                                                       {'loss': 0.0251, 'grad_norm': 5.204052925109863, 'learning_rate': 4.713559322033899e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3219/6000 [3:08:26<2:41:15,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [3:08:29<2:39:02,  3.43s/it]                                                       {'loss': 0.1014, 'grad_norm': 12.658825874328613, 'learning_rate': 4.711864406779661e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3220/6000 [3:08:29<2:39:02,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [3:08:33<2:37:27,  3.40s/it]                                                       {'loss': 0.0097, 'grad_norm': 1.9083901643753052, 'learning_rate': 4.7101694915254245e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3221/6000 [3:08:33<2:37:27,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [3:08:36<2:37:15,  3.40s/it]                                                       {'loss': 0.0264, 'grad_norm': 3.968592405319214, 'learning_rate': 4.708474576271187e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3222/6000 [3:08:36<2:37:15,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [3:08:39<2:36:59,  3.39s/it]                                                       {'loss': 0.0818, 'grad_norm': 12.65101432800293, 'learning_rate': 4.706779661016949e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3223/6000 [3:08:39<2:36:59,  3.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [3:08:43<2:39:07,  3.44s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07546727359294891, 'learning_rate': 4.705084745762713e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3224/6000 [3:08:43<2:39:07,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [3:08:46<2:37:49,  3.41s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.7272042036056519, 'learning_rate': 4.703389830508475e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3225/6000 [3:08:46<2:37:49,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [3:08:50<2:38:29,  3.43s/it]                                                       {'loss': 0.0735, 'grad_norm': 10.389204025268555, 'learning_rate': 4.701694915254238e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3226/6000 [3:08:50<2:38:29,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [3:08:53<2:37:52,  3.42s/it]                                                       {'loss': 0.0095, 'grad_norm': 1.724690318107605, 'learning_rate': 4.7e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3227/6000 [3:08:53<2:37:52,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [3:08:57<2:38:57,  3.44s/it]                                                       {'loss': 0.2639, 'grad_norm': 17.14410400390625, 'learning_rate': 4.698305084745763e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3228/6000 [3:08:57<2:38:57,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [3:09:00<2:37:57,  3.42s/it]                                                       {'loss': 0.0293, 'grad_norm': 7.180837631225586, 'learning_rate': 4.696610169491526e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3229/6000 [3:09:00<2:37:57,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [3:09:03<2:38:13,  3.43s/it]                                                       {'loss': 0.0083, 'grad_norm': 4.110899448394775, 'learning_rate': 4.694915254237288e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3230/6000 [3:09:03<2:38:13,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [3:09:07<2:36:47,  3.40s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.10317403823137283, 'learning_rate': 4.693220338983051e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3231/6000 [3:09:07<2:36:47,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [3:09:10<2:38:15,  3.43s/it]                                                       {'loss': 0.0147, 'grad_norm': 3.5310897827148438, 'learning_rate': 4.691525423728814e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3232/6000 [3:09:10<2:38:15,  3.43s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [3:09:14<2:36:29,  3.39s/it]                                                       {'loss': 0.0344, 'grad_norm': 9.562841415405273, 'learning_rate': 4.689830508474576e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3233/6000 [3:09:14<2:36:29,  3.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [3:09:17<2:35:53,  3.38s/it]                                                       {'loss': 0.004, 'grad_norm': 0.48119214177131653, 'learning_rate': 4.688135593220339e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3234/6000 [3:09:17<2:35:53,  3.38s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [3:09:20<2:35:28,  3.37s/it]                                                       {'loss': 0.4288, 'grad_norm': 17.15341567993164, 'learning_rate': 4.686440677966102e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3235/6000 [3:09:20<2:35:28,  3.37s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [3:09:24<2:37:41,  3.42s/it]                                                       {'loss': 0.1635, 'grad_norm': 10.327126502990723, 'learning_rate': 4.684745762711865e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3236/6000 [3:09:24<2:37:41,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [3:09:27<2:36:44,  3.40s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.9806031584739685, 'learning_rate': 4.6830508474576275e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3237/6000 [3:09:27<2:36:44,  3.40s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [3:09:31<2:41:47,  3.51s/it]                                                       {'loss': 0.0278, 'grad_norm': 3.4927632808685303, 'learning_rate': 4.68135593220339e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3238/6000 [3:09:31<2:41:47,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [3:09:34<2:42:21,  3.53s/it]                                                       {'loss': 0.0255, 'grad_norm': 7.464949607849121, 'learning_rate': 4.679661016949153e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3239/6000 [3:09:34<2:42:21,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [3:09:38<2:40:05,  3.48s/it]                                                       {'loss': 0.0123, 'grad_norm': 2.2199289798736572, 'learning_rate': 4.677966101694916e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3240/6000 [3:09:38<2:40:05,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [3:09:41<2:39:28,  3.47s/it]                                                       {'loss': 0.0588, 'grad_norm': 11.430683135986328, 'learning_rate': 4.676271186440678e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3241/6000 [3:09:41<2:39:28,  3.47s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [3:09:45<2:40:54,  3.50s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.1302441358566284, 'learning_rate': 4.674576271186441e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3242/6000 [3:09:45<2:40:54,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [3:09:48<2:40:40,  3.50s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.3035370409488678, 'learning_rate': 4.672881355932204e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3243/6000 [3:09:48<2:40:40,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [3:09:53<2:53:37,  3.78s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.8574217557907104, 'learning_rate': 4.671186440677967e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3244/6000 [3:09:53<2:53:37,  3.78s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [3:09:56<2:52:16,  3.75s/it]                                                       {'loss': 0.0282, 'grad_norm': 3.280665397644043, 'learning_rate': 4.6694915254237295e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/6000 [3:09:56<2:52:16,  3.75s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [3:10:00<2:48:11,  3.66s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.7675365209579468, 'learning_rate': 4.667796610169492e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3246/6000 [3:10:00<2:48:11,  3.66s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [3:10:03<2:43:20,  3.56s/it]                                                       {'loss': 0.0676, 'grad_norm': 10.255583763122559, 'learning_rate': 4.666101694915255e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3247/6000 [3:10:03<2:43:20,  3.56s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [3:10:07<2:41:51,  3.53s/it]                                                       {'loss': 0.129, 'grad_norm': 15.663474082946777, 'learning_rate': 4.664406779661017e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3248/6000 [3:10:07<2:41:51,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [3:10:10<2:40:48,  3.51s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.21225044131278992, 'learning_rate': 4.66271186440678e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3249/6000 [3:10:10<2:40:48,  3.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [3:10:14<2:39:13,  3.47s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.6374236345291138, 'learning_rate': 4.6610169491525425e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3250/6000 [3:10:14<2:39:13,  3.47s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [3:10:17<2:41:08,  3.52s/it]                                                       {'loss': 0.0344, 'grad_norm': 5.652810096740723, 'learning_rate': 4.659322033898305e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3251/6000 [3:10:17<2:41:08,  3.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [3:10:21<2:40:23,  3.50s/it]                                                       {'loss': 0.0091, 'grad_norm': 3.1660358905792236, 'learning_rate': 4.657627118644068e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3252/6000 [3:10:21<2:40:23,  3.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [3:10:24<2:39:13,  3.48s/it]                                                       {'loss': 0.0546, 'grad_norm': 10.331177711486816, 'learning_rate': 4.655932203389831e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3253/6000 [3:10:24<2:39:13,  3.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [3:10:27<2:37:48,  3.45s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.4142179489135742, 'learning_rate': 4.654237288135594e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3254/6000 [3:10:27<2:37:48,  3.45s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [3:10:31<2:37:48,  3.45s/it]                                                       {'loss': 0.0568, 'grad_norm': 7.5565619468688965, 'learning_rate': 4.652542372881356e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/6000 [3:10:31<2:37:48,  3.45s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [3:10:34<2:36:31,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.046755269169807434, 'learning_rate': 4.650847457627119e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3256/6000 [3:10:34<2:36:31,  3.42s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [3:10:38<2:43:29,  3.58s/it]                                                       {'loss': 0.0669, 'grad_norm': 7.441847324371338, 'learning_rate': 4.649152542372882e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3257/6000 [3:10:38<2:43:29,  3.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [3:10:42<2:41:34,  3.54s/it]                                                       {'loss': 0.0155, 'grad_norm': 3.5866940021514893, 'learning_rate': 4.6474576271186444e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3258/6000 [3:10:42<2:41:34,  3.54s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [3:10:45<2:41:13,  3.53s/it]                                                       {'loss': 0.0283, 'grad_norm': 7.413354396820068, 'learning_rate': 4.645762711864407e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3259/6000 [3:10:45<2:41:13,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [3:10:49<2:47:10,  3.66s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.1933311223983765, 'learning_rate': 4.64406779661017e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3260/6000 [3:10:49<2:47:10,  3.66s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [3:10:52<2:43:28,  3.58s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.834338366985321, 'learning_rate': 4.6423728813559326e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3261/6000 [3:10:53<2:43:28,  3.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [3:10:56<2:41:10,  3.53s/it]                                                       {'loss': 0.0927, 'grad_norm': 5.109960079193115, 'learning_rate': 4.640677966101695e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3262/6000 [3:10:56<2:41:10,  3.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [3:10:59<2:38:05,  3.47s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.5806713700294495, 'learning_rate': 4.638983050847458e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3263/6000 [3:10:59<2:38:05,  3.47s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [3:11:03<2:36:41,  3.44s/it]                                                       {'loss': 0.0339, 'grad_norm': 7.002555847167969, 'learning_rate': 4.637288135593221e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3264/6000 [3:11:03<2:36:41,  3.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [3:11:06<2:35:21,  3.41s/it]                                                       {'loss': 0.0561, 'grad_norm': 9.201759338378906, 'learning_rate': 4.635593220338984e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3265/6000 [3:11:06<2:35:21,  3.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [3:11:09<2:34:25,  3.39s/it]                                                       {'loss': 0.0352, 'grad_norm': 10.275032043457031, 'learning_rate': 4.633898305084746e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3266/6000 [3:11:09<2:34:25,  3.39s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [3:11:13<2:32:39,  3.35s/it]                                                       {'loss': 0.028, 'grad_norm': 5.743243217468262, 'learning_rate': 4.632203389830509e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3267/6000 [3:11:13<2:32:39,  3.35s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [3:11:16<2:32:39,  3.35s/it]                                                       {'loss': 0.3878, 'grad_norm': 21.938793182373047, 'learning_rate': 4.630508474576272e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3268/6000 [3:11:16<2:32:39,  3.35s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [3:11:19<2:32:33,  3.35s/it]                                                       {'loss': 0.1105, 'grad_norm': 12.196271896362305, 'learning_rate': 4.628813559322034e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3269/6000 [3:11:19<2:32:33,  3.35s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [3:11:23<2:32:38,  3.35s/it]                                                       {'loss': 0.1096, 'grad_norm': 13.610381126403809, 'learning_rate': 4.627118644067797e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3270/6000 [3:11:23<2:32:38,  3.35s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [3:11:26<2:32:59,  3.36s/it]                                                       {'loss': 0.0466, 'grad_norm': 8.738890647888184, 'learning_rate': 4.625423728813559e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3271/6000 [3:11:26<2:32:59,  3.36s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [3:11:29<2:33:30,  3.38s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.34003493189811707, 'learning_rate': 4.623728813559323e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3272/6000 [3:11:29<2:33:30,  3.38s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [3:11:33<2:40:15,  3.53s/it]                                                       {'loss': 0.0628, 'grad_norm': 5.8269429206848145, 'learning_rate': 4.622033898305085e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3273/6000 [3:11:33<2:40:15,  3.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [3:11:37<2:41:49,  3.56s/it]                                                       {'loss': 0.029, 'grad_norm': 5.3117804527282715, 'learning_rate': 4.6203389830508475e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3274/6000 [3:11:37<2:41:49,  3.56s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [3:11:41<2:45:13,  3.64s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.6166825890541077, 'learning_rate': 4.618644067796611e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3275/6000 [3:11:41<2:45:13,  3.64s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [3:11:44<2:41:52,  3.57s/it]                                                       {'loss': 0.0029, 'grad_norm': 1.0564066171646118, 'learning_rate': 4.616949152542373e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3276/6000 [3:11:44<2:41:52,  3.57s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [3:11:48<2:39:24,  3.51s/it]                                                       {'loss': 0.08, 'grad_norm': 10.487984657287598, 'learning_rate': 4.615254237288136e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3277/6000 [3:11:48<2:39:24,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [3:11:51<2:37:40,  3.48s/it]                                                       {'loss': 0.0775, 'grad_norm': 3.8770978450775146, 'learning_rate': 4.613559322033899e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3278/6000 [3:11:51<2:37:40,  3.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [3:11:55<2:44:05,  3.62s/it]                                                       {'loss': 0.0064, 'grad_norm': 0.8766751885414124, 'learning_rate': 4.611864406779661e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3279/6000 [3:11:55<2:44:05,  3.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [3:11:58<2:41:00,  3.55s/it]                                                       {'loss': 0.0356, 'grad_norm': 10.653998374938965, 'learning_rate': 4.610169491525424e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3280/6000 [3:11:58<2:41:00,  3.55s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [3:12:02<2:39:30,  3.52s/it]                                                       {'loss': 0.0511, 'grad_norm': 9.166946411132812, 'learning_rate': 4.608474576271187e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3281/6000 [3:12:02<2:39:30,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [3:12:05<2:40:27,  3.54s/it]                                                       {'loss': 0.1483, 'grad_norm': 12.710700035095215, 'learning_rate': 4.6067796610169495e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3282/6000 [3:12:05<2:40:27,  3.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [3:12:09<2:39:30,  3.52s/it]                                                       {'loss': 0.2342, 'grad_norm': 21.632829666137695, 'learning_rate': 4.605084745762713e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3283/6000 [3:12:09<2:39:30,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [3:12:12<2:38:19,  3.50s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.82565975189209, 'learning_rate': 4.603389830508475e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3284/6000 [3:12:12<2:38:19,  3.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [3:12:16<2:35:36,  3.44s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5781305432319641, 'learning_rate': 4.601694915254238e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3285/6000 [3:12:16<2:35:36,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [3:12:19<2:40:02,  3.54s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.2683831453323364, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3286/6000 [3:12:19<2:40:02,  3.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [3:12:23<2:38:37,  3.51s/it]                                                       {'loss': 0.0912, 'grad_norm': 7.723344326019287, 'learning_rate': 4.598305084745763e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3287/6000 [3:12:23<2:38:37,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [3:12:26<2:35:48,  3.45s/it]                                                       {'loss': 0.0474, 'grad_norm': 8.858630180358887, 'learning_rate': 4.596610169491526e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3288/6000 [3:12:26<2:35:48,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [3:12:29<2:33:27,  3.40s/it]                                                       {'loss': 0.0239, 'grad_norm': 6.405116081237793, 'learning_rate': 4.594915254237288e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3289/6000 [3:12:29<2:33:27,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [3:12:33<2:33:11,  3.39s/it]                                                       {'loss': 0.1599, 'grad_norm': 8.867819786071777, 'learning_rate': 4.5932203389830506e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3290/6000 [3:12:33<2:33:11,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [3:12:36<2:35:49,  3.45s/it]                                                       {'loss': 0.0862, 'grad_norm': 13.161715507507324, 'learning_rate': 4.591525423728814e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3291/6000 [3:12:36<2:35:49,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [3:12:40<2:35:43,  3.45s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.7620214223861694, 'learning_rate': 4.589830508474576e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3292/6000 [3:12:40<2:35:43,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [3:12:43<2:35:33,  3.45s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.7323658466339111, 'learning_rate': 4.5881355932203395e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3293/6000 [3:12:43<2:35:33,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [3:12:47<2:34:45,  3.43s/it]                                                       {'loss': 0.0309, 'grad_norm': 2.7030558586120605, 'learning_rate': 4.586440677966102e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3294/6000 [3:12:47<2:34:45,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [3:12:50<2:35:55,  3.46s/it]                                                       {'loss': 0.0079, 'grad_norm': 1.1559725999832153, 'learning_rate': 4.584745762711864e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3295/6000 [3:12:50<2:35:55,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [3:12:53<2:34:28,  3.43s/it]                                                       {'loss': 0.008, 'grad_norm': 1.636155605316162, 'learning_rate': 4.583050847457628e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3296/6000 [3:12:53<2:34:28,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [3:12:57<2:37:08,  3.49s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09694036841392517, 'learning_rate': 4.58135593220339e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3297/6000 [3:12:57<2:37:08,  3.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [3:13:01<2:39:15,  3.54s/it]                                                       {'loss': 0.0578, 'grad_norm': 9.956201553344727, 'learning_rate': 4.5796610169491525e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3298/6000 [3:13:01<2:39:15,  3.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [3:13:04<2:37:13,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.07440924644470215, 'learning_rate': 4.577966101694916e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3299/6000 [3:13:04<2:37:13,  3.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [3:13:08<2:35:58,  3.47s/it]                                                       {'loss': 0.1637, 'grad_norm': 16.001293182373047, 'learning_rate': 4.576271186440678e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3300/6000 [3:13:08<2:35:58,  3.47s/it][2025-11-07 02:04:17,506] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3300
[2025-11-07 02:04:17,521] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:04:18,253] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [3:13:13<3:08:29,  4.19s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.49450448155403137, 'learning_rate': 4.5745762711864415e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3301/6000 [3:13:13<3:08:29,  4.19s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [3:13:17<2:56:49,  3.93s/it]                                                       {'loss': 0.1247, 'grad_norm': 10.777472496032715, 'learning_rate': 4.572881355932204e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3302/6000 [3:13:17<2:56:49,  3.93s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [3:13:20<2:49:30,  3.77s/it]                                                       {'loss': 0.0491, 'grad_norm': 9.1686429977417, 'learning_rate': 4.571186440677966e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3303/6000 [3:13:20<2:49:30,  3.77s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [3:13:23<2:42:34,  3.62s/it]                                                       {'loss': 0.0571, 'grad_norm': 10.865711212158203, 'learning_rate': 4.56949152542373e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3304/6000 [3:13:23<2:42:34,  3.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [3:13:27<2:38:01,  3.52s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07230369001626968, 'learning_rate': 4.567796610169492e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3305/6000 [3:13:27<2:38:01,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [3:13:30<2:35:52,  3.47s/it]                                                       {'loss': 0.3189, 'grad_norm': 20.393205642700195, 'learning_rate': 4.5661016949152545e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3306/6000 [3:13:30<2:35:52,  3.47s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [3:13:33<2:33:29,  3.42s/it]                                                       {'loss': 0.2075, 'grad_norm': 13.543549537658691, 'learning_rate': 4.564406779661018e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3307/6000 [3:13:33<2:33:29,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [3:13:37<2:31:22,  3.37s/it]                                                       {'loss': 0.0045, 'grad_norm': 1.1607543230056763, 'learning_rate': 4.56271186440678e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3308/6000 [3:13:37<2:31:22,  3.37s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [3:13:40<2:32:19,  3.40s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1614859402179718, 'learning_rate': 4.561016949152543e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3309/6000 [3:13:40<2:32:19,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [3:13:43<2:31:53,  3.39s/it]                                                       {'loss': 0.0039, 'grad_norm': 0.8912067413330078, 'learning_rate': 4.559322033898305e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3310/6000 [3:13:43<2:31:53,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [3:13:47<2:33:27,  3.42s/it]                                                       {'loss': 0.1035, 'grad_norm': 7.083319187164307, 'learning_rate': 4.557627118644068e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3311/6000 [3:13:47<2:33:27,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [3:13:50<2:34:03,  3.44s/it]                                                       {'loss': 0.0845, 'grad_norm': 8.830488204956055, 'learning_rate': 4.555932203389831e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3312/6000 [3:13:50<2:34:03,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [3:13:54<2:32:00,  3.39s/it]                                                       {'loss': 0.027, 'grad_norm': 6.919577121734619, 'learning_rate': 4.554237288135593e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3313/6000 [3:13:54<2:32:00,  3.39s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [3:13:58<2:37:40,  3.52s/it]                                                       {'loss': 0.0234, 'grad_norm': 5.058036804199219, 'learning_rate': 4.552542372881356e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3314/6000 [3:13:58<2:37:40,  3.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [3:14:01<2:37:07,  3.51s/it]                                                       {'loss': 0.0202, 'grad_norm': 5.223773002624512, 'learning_rate': 4.550847457627119e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3315/6000 [3:14:01<2:37:07,  3.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [3:14:04<2:34:14,  3.45s/it]                                                       {'loss': 0.0783, 'grad_norm': 12.075446128845215, 'learning_rate': 4.549152542372881e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3316/6000 [3:14:04<2:34:14,  3.45s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [3:14:08<2:32:11,  3.40s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.32772570848464966, 'learning_rate': 4.5474576271186445e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3317/6000 [3:14:08<2:32:11,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [3:14:11<2:32:09,  3.40s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.0140684843063354, 'learning_rate': 4.545762711864407e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3318/6000 [3:14:11<2:32:09,  3.40s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [3:14:15<2:33:29,  3.44s/it]                                                       {'loss': 0.1096, 'grad_norm': 13.12547779083252, 'learning_rate': 4.54406779661017e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3319/6000 [3:14:15<2:33:29,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [3:14:18<2:33:52,  3.44s/it]                                                       {'loss': 0.4373, 'grad_norm': 25.173248291015625, 'learning_rate': 4.542372881355933e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3320/6000 [3:14:18<2:33:52,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [3:14:21<2:33:07,  3.43s/it]                                                       {'loss': 0.2769, 'grad_norm': 20.156099319458008, 'learning_rate': 4.540677966101695e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3321/6000 [3:14:21<2:33:07,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [3:14:25<2:33:25,  3.44s/it]                                                       {'loss': 0.013, 'grad_norm': 4.107507228851318, 'learning_rate': 4.538983050847458e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3322/6000 [3:14:25<2:33:25,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [3:14:28<2:33:23,  3.44s/it]                                                       {'loss': 0.0025, 'grad_norm': 1.4659684896469116, 'learning_rate': 4.537288135593221e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3323/6000 [3:14:28<2:33:23,  3.44s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [3:14:32<2:32:39,  3.42s/it]                                                       {'loss': 0.0914, 'grad_norm': 14.268362998962402, 'learning_rate': 4.535593220338983e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3324/6000 [3:14:32<2:32:39,  3.42s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [3:14:35<2:33:06,  3.43s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.261539340019226, 'learning_rate': 4.5338983050847465e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3325/6000 [3:14:35<2:33:06,  3.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [3:14:39<2:34:23,  3.46s/it]                                                       {'loss': 0.0022, 'grad_norm': 0.5114607214927673, 'learning_rate': 4.532203389830509e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3326/6000 [3:14:39<2:34:23,  3.46s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [3:14:43<2:45:15,  3.71s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.1842492818832397, 'learning_rate': 4.530508474576271e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3327/6000 [3:14:43<2:45:15,  3.71s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [3:14:46<2:39:29,  3.58s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.2787821888923645, 'learning_rate': 4.528813559322035e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3328/6000 [3:14:46<2:39:29,  3.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [3:14:50<2:37:32,  3.54s/it]                                                       {'loss': 0.0378, 'grad_norm': 6.6781511306762695, 'learning_rate': 4.527118644067797e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3329/6000 [3:14:50<2:37:32,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [3:14:53<2:36:49,  3.52s/it]                                                       {'loss': 0.0219, 'grad_norm': 4.762576103210449, 'learning_rate': 4.52542372881356e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3330/6000 [3:14:53<2:36:49,  3.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [3:14:56<2:34:30,  3.47s/it]                                                       {'loss': 0.0239, 'grad_norm': 6.234440803527832, 'learning_rate': 4.523728813559322e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3331/6000 [3:14:56<2:34:30,  3.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [3:15:00<2:31:57,  3.42s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.1020805835723877, 'learning_rate': 4.522033898305085e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3332/6000 [3:15:00<2:31:57,  3.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [3:15:03<2:31:23,  3.41s/it]                                                       {'loss': 0.0616, 'grad_norm': 4.122951984405518, 'learning_rate': 4.520338983050848e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3333/6000 [3:15:03<2:31:23,  3.41s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [3:15:07<2:31:13,  3.40s/it]                                                       {'loss': 0.0546, 'grad_norm': 8.052075386047363, 'learning_rate': 4.51864406779661e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3334/6000 [3:15:07<2:31:13,  3.40s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [3:15:10<2:36:49,  3.53s/it]                                                       {'loss': 0.0952, 'grad_norm': 5.618589878082275, 'learning_rate': 4.516949152542373e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3335/6000 [3:15:10<2:36:49,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [3:15:14<2:41:55,  3.65s/it]                                                       {'loss': 0.055, 'grad_norm': 9.003477096557617, 'learning_rate': 4.515254237288136e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3336/6000 [3:15:14<2:41:55,  3.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [3:15:18<2:39:28,  3.59s/it]                                                       {'loss': 0.011, 'grad_norm': 2.118795871734619, 'learning_rate': 4.513559322033898e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3337/6000 [3:15:18<2:39:28,  3.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [3:15:21<2:35:44,  3.51s/it]                                                       {'loss': 0.0118, 'grad_norm': 2.2702372074127197, 'learning_rate': 4.5118644067796614e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3338/6000 [3:15:21<2:35:44,  3.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [3:15:24<2:33:22,  3.46s/it]                                                       {'loss': 0.0329, 'grad_norm': 7.7076005935668945, 'learning_rate': 4.510169491525424e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3339/6000 [3:15:24<2:33:22,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [3:15:28<2:32:30,  3.44s/it]                                                       {'loss': 0.0177, 'grad_norm': 6.8983964920043945, 'learning_rate': 4.508474576271187e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3340/6000 [3:15:28<2:32:30,  3.44s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [3:15:31<2:30:15,  3.39s/it]                                                       {'loss': 0.0187, 'grad_norm': 3.269551992416382, 'learning_rate': 4.5067796610169496e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3341/6000 [3:15:31<2:30:15,  3.39s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [3:15:34<2:28:35,  3.35s/it]                                                       {'loss': 0.0706, 'grad_norm': 9.168410301208496, 'learning_rate': 4.505084745762712e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3342/6000 [3:15:34<2:28:35,  3.35s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [3:15:38<2:28:35,  3.36s/it]                                                       {'loss': 0.0501, 'grad_norm': 5.9606099128723145, 'learning_rate': 4.503389830508475e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3343/6000 [3:15:38<2:28:35,  3.36s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [3:15:41<2:29:48,  3.38s/it]                                                       {'loss': 0.0032, 'grad_norm': 1.067901372909546, 'learning_rate': 4.501694915254238e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3344/6000 [3:15:41<2:29:48,  3.38s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [3:15:45<2:33:01,  3.46s/it]                                                       {'loss': 0.0442, 'grad_norm': 9.907052040100098, 'learning_rate': 4.5e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3345/6000 [3:15:45<2:33:01,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [3:15:49<2:38:00,  3.57s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.019721269607544, 'learning_rate': 4.498305084745763e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3346/6000 [3:15:49<2:38:00,  3.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [3:15:53<2:42:14,  3.67s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.24833975732326508, 'learning_rate': 4.496610169491526e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/6000 [3:15:53<2:42:14,  3.67s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [3:15:56<2:37:20,  3.56s/it]                                                       {'loss': 0.1576, 'grad_norm': 10.167146682739258, 'learning_rate': 4.494915254237289e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3348/6000 [3:15:56<2:37:20,  3.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [3:15:59<2:34:42,  3.50s/it]                                                       {'loss': 0.2802, 'grad_norm': 16.1927433013916, 'learning_rate': 4.4932203389830515e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3349/6000 [3:15:59<2:34:42,  3.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [3:16:03<2:33:36,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1898956447839737, 'learning_rate': 4.491525423728814e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3350/6000 [3:16:03<2:33:36,  3.48s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [3:16:06<2:37:34,  3.57s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.5028846263885498, 'learning_rate': 4.489830508474577e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3351/6000 [3:16:06<2:37:34,  3.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [3:16:10<2:36:17,  3.54s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.424876093864441, 'learning_rate': 4.488135593220339e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3352/6000 [3:16:10<2:36:17,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [3:16:13<2:36:05,  3.54s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.28948894143104553, 'learning_rate': 4.486440677966102e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3353/6000 [3:16:13<2:36:05,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [3:16:17<2:33:59,  3.49s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.5258737802505493, 'learning_rate': 4.4847457627118645e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3354/6000 [3:16:17<2:33:59,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [3:16:20<2:32:43,  3.46s/it]                                                       {'loss': 0.0104, 'grad_norm': 2.3471179008483887, 'learning_rate': 4.483050847457627e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3355/6000 [3:16:20<2:32:43,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [3:16:24<2:32:29,  3.46s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.4701164960861206, 'learning_rate': 4.48135593220339e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3356/6000 [3:16:24<2:32:29,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [3:16:27<2:36:45,  3.56s/it]                                                       {'loss': 0.0935, 'grad_norm': 11.444703102111816, 'learning_rate': 4.479661016949153e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3357/6000 [3:16:27<2:36:45,  3.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [3:16:31<2:35:45,  3.54s/it]                                                       {'loss': 0.007, 'grad_norm': 1.5407694578170776, 'learning_rate': 4.477966101694916e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3358/6000 [3:16:31<2:35:45,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [3:16:34<2:35:14,  3.53s/it]                                                       {'loss': 0.1035, 'grad_norm': 10.689351081848145, 'learning_rate': 4.476271186440678e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3359/6000 [3:16:34<2:35:14,  3.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [3:16:38<2:33:35,  3.49s/it]                                                       {'loss': 0.0306, 'grad_norm': 8.240450859069824, 'learning_rate': 4.474576271186441e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3360/6000 [3:16:38<2:33:35,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [3:16:41<2:32:18,  3.46s/it]                                                       {'loss': 0.0091, 'grad_norm': 1.885453224182129, 'learning_rate': 4.472881355932204e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3361/6000 [3:16:41<2:32:18,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [3:16:45<2:30:57,  3.43s/it]                                                       {'loss': 0.061, 'grad_norm': 4.460301876068115, 'learning_rate': 4.4711864406779664e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3362/6000 [3:16:45<2:30:57,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [3:16:48<2:32:00,  3.46s/it]                                                       {'loss': 0.1378, 'grad_norm': 14.159893989562988, 'learning_rate': 4.469491525423729e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3363/6000 [3:16:48<2:32:00,  3.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [3:16:51<2:30:39,  3.43s/it]                                                       {'loss': 0.1572, 'grad_norm': 17.51322364807129, 'learning_rate': 4.467796610169492e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3364/6000 [3:16:51<2:30:39,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [3:16:55<2:30:47,  3.43s/it]                                                       {'loss': 0.2987, 'grad_norm': 17.158899307250977, 'learning_rate': 4.4661016949152546e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3365/6000 [3:16:55<2:30:47,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [3:16:58<2:31:20,  3.45s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.31580090522766113, 'learning_rate': 4.464406779661018e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3366/6000 [3:16:58<2:31:20,  3.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [3:17:02<2:30:38,  3.43s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.6929415464401245, 'learning_rate': 4.46271186440678e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3367/6000 [3:17:02<2:30:38,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [3:17:05<2:30:17,  3.43s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.5800720453262329, 'learning_rate': 4.461016949152543e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3368/6000 [3:17:05<2:30:17,  3.43s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [3:17:09<2:28:28,  3.39s/it]                                                       {'loss': 0.1012, 'grad_norm': 13.014425277709961, 'learning_rate': 4.459322033898306e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3369/6000 [3:17:09<2:28:28,  3.39s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [3:17:12<2:30:36,  3.44s/it]                                                       {'loss': 0.018, 'grad_norm': 4.5420684814453125, 'learning_rate': 4.457627118644068e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3370/6000 [3:17:12<2:30:36,  3.44s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [3:17:17<2:44:44,  3.76s/it]                                                       {'loss': 0.1761, 'grad_norm': 14.999509811401367, 'learning_rate': 4.455932203389831e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3371/6000 [3:17:17<2:44:44,  3.76s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [3:17:20<2:41:11,  3.68s/it]                                                       {'loss': 0.0924, 'grad_norm': 5.995444297790527, 'learning_rate': 4.454237288135594e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3372/6000 [3:17:20<2:41:11,  3.68s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [3:17:24<2:38:33,  3.62s/it]                                                       {'loss': 0.0721, 'grad_norm': 8.27550220489502, 'learning_rate': 4.452542372881356e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3373/6000 [3:17:24<2:38:33,  3.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [3:17:27<2:35:25,  3.55s/it]                                                       {'loss': 0.0092, 'grad_norm': 3.605659008026123, 'learning_rate': 4.450847457627119e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3374/6000 [3:17:27<2:35:25,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [3:17:30<2:34:58,  3.54s/it]                                                       {'loss': 0.0157, 'grad_norm': 3.9037065505981445, 'learning_rate': 4.449152542372881e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3375/6000 [3:17:30<2:34:58,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [3:17:34<2:32:27,  3.49s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.3995743989944458, 'learning_rate': 4.447457627118645e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3376/6000 [3:17:34<2:32:27,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [3:17:37<2:33:03,  3.50s/it]                                                       {'loss': 0.0736, 'grad_norm': 10.47197151184082, 'learning_rate': 4.445762711864407e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3377/6000 [3:17:37<2:33:03,  3.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [3:17:42<2:44:06,  3.76s/it]                                                       {'loss': 0.0365, 'grad_norm': 6.485793113708496, 'learning_rate': 4.4440677966101695e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3378/6000 [3:17:42<2:44:06,  3.76s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [3:17:45<2:38:02,  3.62s/it]                                                       {'loss': 0.0907, 'grad_norm': 11.731651306152344, 'learning_rate': 4.442372881355933e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3379/6000 [3:17:45<2:38:02,  3.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [3:17:48<2:34:40,  3.54s/it]                                                       {'loss': 0.1214, 'grad_norm': 12.188165664672852, 'learning_rate': 4.440677966101695e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3380/6000 [3:17:48<2:34:40,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [3:17:52<2:34:32,  3.54s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.1256804466247559, 'learning_rate': 4.438983050847458e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3381/6000 [3:17:52<2:34:32,  3.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [3:17:56<2:42:18,  3.72s/it]                                                       {'loss': 0.006, 'grad_norm': 1.3146854639053345, 'learning_rate': 4.437288135593221e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3382/6000 [3:17:56<2:42:18,  3.72s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [3:17:59<2:38:28,  3.63s/it]                                                       {'loss': 0.1578, 'grad_norm': 16.893918991088867, 'learning_rate': 4.435593220338983e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3383/6000 [3:17:59<2:38:28,  3.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [3:18:03<2:34:49,  3.55s/it]                                                       {'loss': 0.001, 'grad_norm': 0.22379469871520996, 'learning_rate': 4.433898305084746e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3384/6000 [3:18:03<2:34:49,  3.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [3:18:06<2:35:16,  3.56s/it]                                                       {'loss': 0.0189, 'grad_norm': 5.858551502227783, 'learning_rate': 4.432203389830509e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3385/6000 [3:18:06<2:35:16,  3.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [3:18:10<2:31:54,  3.49s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.18674379587173462, 'learning_rate': 4.4305084745762715e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3386/6000 [3:18:10<2:31:54,  3.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [3:18:13<2:32:15,  3.50s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03656521812081337, 'learning_rate': 4.428813559322035e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3387/6000 [3:18:13<2:32:15,  3.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [3:18:17<2:30:51,  3.47s/it]                                                       {'loss': 0.2407, 'grad_norm': 13.382930755615234, 'learning_rate': 4.427118644067797e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3388/6000 [3:18:17<2:30:51,  3.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [3:18:20<2:30:11,  3.45s/it]                                                       {'loss': 0.0031, 'grad_norm': 1.8806166648864746, 'learning_rate': 4.42542372881356e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3389/6000 [3:18:20<2:30:11,  3.45s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [3:18:23<2:29:10,  3.43s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.14576514065265656, 'learning_rate': 4.423728813559323e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3390/6000 [3:18:23<2:29:10,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [3:18:27<2:33:59,  3.54s/it]                                                       {'loss': 0.1458, 'grad_norm': 15.606545448303223, 'learning_rate': 4.422033898305085e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3391/6000 [3:18:27<2:33:59,  3.54s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [3:18:31<2:33:05,  3.52s/it]                                                       {'loss': 0.1619, 'grad_norm': 13.085225105285645, 'learning_rate': 4.420338983050848e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3392/6000 [3:18:31<2:33:05,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [3:18:34<2:31:23,  3.48s/it]                                                       {'loss': 0.09, 'grad_norm': 13.368220329284668, 'learning_rate': 4.41864406779661e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3393/6000 [3:18:34<2:31:23,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [3:18:37<2:28:51,  3.43s/it]                                                       {'loss': 0.0115, 'grad_norm': 3.6444618701934814, 'learning_rate': 4.416949152542373e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3394/6000 [3:18:37<2:28:51,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [3:18:42<2:39:35,  3.68s/it]                                                       {'loss': 0.041, 'grad_norm': 1.0692750215530396, 'learning_rate': 4.415254237288136e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3395/6000 [3:18:42<2:39:35,  3.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [3:18:45<2:35:29,  3.58s/it]                                                       {'loss': 0.0567, 'grad_norm': 9.931787490844727, 'learning_rate': 4.413559322033898e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3396/6000 [3:18:45<2:35:29,  3.58s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [3:18:48<2:32:31,  3.52s/it]                                                       {'loss': 0.1354, 'grad_norm': 13.139360427856445, 'learning_rate': 4.4118644067796615e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3397/6000 [3:18:48<2:32:31,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [3:18:52<2:31:07,  3.48s/it]                                                       {'loss': 0.0855, 'grad_norm': 12.087711334228516, 'learning_rate': 4.410169491525424e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3398/6000 [3:18:52<2:31:07,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [3:18:55<2:30:53,  3.48s/it]                                                       {'loss': 0.047, 'grad_norm': 9.8976469039917, 'learning_rate': 4.408474576271186e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3399/6000 [3:18:55<2:30:53,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [3:18:59<2:36:35,  3.61s/it]                                                       {'loss': 0.023, 'grad_norm': 7.659757137298584, 'learning_rate': 4.40677966101695e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3400/6000 [3:18:59<2:36:35,  3.61s/it][2025-11-07 02:10:09,186] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3400
[2025-11-07 02:10:09,245] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:10:09,934] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [3:19:05<3:06:03,  4.30s/it]                                                       {'loss': 0.3376, 'grad_norm': 17.158023834228516, 'learning_rate': 4.405084745762712e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3401/6000 [3:19:05<3:06:03,  4.30s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [3:19:09<2:56:06,  4.07s/it]                                                       {'loss': 0.1217, 'grad_norm': 15.699933052062988, 'learning_rate': 4.4033898305084745e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3402/6000 [3:19:09<2:56:06,  4.07s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [3:19:12<2:47:02,  3.86s/it]                                                       {'loss': 0.1099, 'grad_norm': 14.113365173339844, 'learning_rate': 4.401694915254238e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3403/6000 [3:19:12<2:47:02,  3.86s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [3:19:16<2:42:48,  3.76s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.23733989894390106, 'learning_rate': 4.4e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3404/6000 [3:19:16<2:42:48,  3.76s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [3:19:19<2:37:22,  3.64s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.49558672308921814, 'learning_rate': 4.3983050847457635e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3405/6000 [3:19:19<2:37:22,  3.64s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [3:19:22<2:33:28,  3.55s/it]                                                       {'loss': 0.0203, 'grad_norm': 5.737863063812256, 'learning_rate': 4.396610169491526e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3406/6000 [3:19:22<2:33:28,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [3:19:26<2:32:25,  3.53s/it]                                                       {'loss': 0.1504, 'grad_norm': 10.864468574523926, 'learning_rate': 4.394915254237288e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3407/6000 [3:19:26<2:32:25,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [3:19:30<2:44:17,  3.80s/it]                                                       {'loss': 0.0154, 'grad_norm': 3.531641960144043, 'learning_rate': 4.393220338983052e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3408/6000 [3:19:30<2:44:17,  3.80s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [3:19:34<2:39:57,  3.70s/it]                                                       {'loss': 0.2182, 'grad_norm': 17.300304412841797, 'learning_rate': 4.391525423728814e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3409/6000 [3:19:34<2:39:57,  3.70s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [3:19:37<2:35:45,  3.61s/it]                                                       {'loss': 0.0179, 'grad_norm': 4.881153106689453, 'learning_rate': 4.3898305084745765e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3410/6000 [3:19:37<2:35:45,  3.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [3:19:40<2:33:15,  3.55s/it]                                                       {'loss': 0.0365, 'grad_norm': 7.579237937927246, 'learning_rate': 4.38813559322034e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3411/6000 [3:19:40<2:33:15,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [3:19:44<2:32:59,  3.55s/it]                                                       {'loss': 0.107, 'grad_norm': 9.31259536743164, 'learning_rate': 4.386440677966102e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3412/6000 [3:19:44<2:32:59,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [3:19:47<2:30:24,  3.49s/it]                                                       {'loss': 0.037, 'grad_norm': 10.615889549255371, 'learning_rate': 4.384745762711865e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3413/6000 [3:19:47<2:30:24,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [3:19:51<2:27:59,  3.43s/it]                                                       {'loss': 0.0828, 'grad_norm': 13.188862800598145, 'learning_rate': 4.383050847457627e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3414/6000 [3:19:51<2:27:59,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [3:19:54<2:29:22,  3.47s/it]                                                       {'loss': 0.0482, 'grad_norm': 6.616913795471191, 'learning_rate': 4.38135593220339e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3415/6000 [3:19:54<2:29:22,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [3:19:58<2:29:51,  3.48s/it]                                                       {'loss': 0.1983, 'grad_norm': 15.735240936279297, 'learning_rate': 4.379661016949153e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3416/6000 [3:19:58<2:29:51,  3.48s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [3:20:01<2:31:15,  3.51s/it]                                                       {'loss': 0.0438, 'grad_norm': 7.718163013458252, 'learning_rate': 4.377966101694915e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/6000 [3:20:01<2:31:15,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [3:20:05<2:30:02,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.3537447452545166, 'learning_rate': 4.3762711864406784e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3418/6000 [3:20:05<2:30:02,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [3:20:08<2:30:49,  3.51s/it]                                                       {'loss': 0.0173, 'grad_norm': 5.411990642547607, 'learning_rate': 4.374576271186441e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3419/6000 [3:20:08<2:30:49,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [3:20:12<2:29:08,  3.47s/it]                                                       {'loss': 0.0466, 'grad_norm': 9.753540992736816, 'learning_rate': 4.372881355932203e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3420/6000 [3:20:12<2:29:08,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [3:20:15<2:30:31,  3.50s/it]                                                       {'loss': 0.0729, 'grad_norm': 10.846612930297852, 'learning_rate': 4.3711864406779666e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3421/6000 [3:20:15<2:30:31,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [3:20:19<2:29:15,  3.47s/it]                                                       {'loss': 0.0436, 'grad_norm': 8.78071117401123, 'learning_rate': 4.369491525423729e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3422/6000 [3:20:19<2:29:15,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [3:20:23<2:35:28,  3.62s/it]                                                       {'loss': 0.1577, 'grad_norm': 13.776119232177734, 'learning_rate': 4.367796610169492e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3423/6000 [3:20:23<2:35:28,  3.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [3:20:26<2:34:28,  3.60s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8751938939094543, 'learning_rate': 4.366101694915255e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3424/6000 [3:20:26<2:34:28,  3.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [3:20:30<2:32:08,  3.55s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.40064573287963867, 'learning_rate': 4.364406779661017e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3425/6000 [3:20:30<2:32:08,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [3:20:33<2:30:49,  3.52s/it]                                                       {'loss': 0.0712, 'grad_norm': 12.782777786254883, 'learning_rate': 4.36271186440678e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3426/6000 [3:20:33<2:30:49,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [3:20:36<2:29:41,  3.49s/it]                                                       {'loss': 0.038, 'grad_norm': 5.625053405761719, 'learning_rate': 4.361016949152543e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3427/6000 [3:20:36<2:29:41,  3.49s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [3:20:40<2:27:54,  3.45s/it]                                                       {'loss': 0.198, 'grad_norm': 16.422161102294922, 'learning_rate': 4.359322033898305e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3428/6000 [3:20:40<2:27:54,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [3:20:43<2:30:26,  3.51s/it]                                                       {'loss': 0.0275, 'grad_norm': 5.659406661987305, 'learning_rate': 4.3576271186440685e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3429/6000 [3:20:43<2:30:26,  3.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [3:20:47<2:27:40,  3.45s/it]                                                       {'loss': 0.3094, 'grad_norm': 15.485160827636719, 'learning_rate': 4.355932203389831e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3430/6000 [3:20:47<2:27:40,  3.45s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [3:20:51<2:34:51,  3.62s/it]                                                       {'loss': 0.0239, 'grad_norm': 4.171934127807617, 'learning_rate': 4.354237288135593e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3431/6000 [3:20:51<2:34:51,  3.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [3:20:54<2:36:08,  3.65s/it]                                                       {'loss': 0.0952, 'grad_norm': 8.160907745361328, 'learning_rate': 4.352542372881357e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3432/6000 [3:20:54<2:36:08,  3.65s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [3:20:58<2:34:54,  3.62s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.6169077157974243, 'learning_rate': 4.350847457627119e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3433/6000 [3:20:58<2:34:54,  3.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [3:21:01<2:32:47,  3.57s/it]                                                       {'loss': 0.0111, 'grad_norm': 3.3718013763427734, 'learning_rate': 4.349152542372882e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3434/6000 [3:21:01<2:32:47,  3.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [3:21:05<2:30:53,  3.53s/it]                                                       {'loss': 0.015, 'grad_norm': 2.085798501968384, 'learning_rate': 4.347457627118644e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3435/6000 [3:21:05<2:30:53,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [3:21:08<2:29:37,  3.50s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.4814353883266449, 'learning_rate': 4.345762711864407e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3436/6000 [3:21:08<2:29:37,  3.50s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [3:21:12<2:34:42,  3.62s/it]                                                       {'loss': 0.063, 'grad_norm': 9.741146087646484, 'learning_rate': 4.34406779661017e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3437/6000 [3:21:12<2:34:42,  3.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [3:21:16<2:32:38,  3.57s/it]                                                       {'loss': 0.0066, 'grad_norm': 2.2435545921325684, 'learning_rate': 4.342372881355932e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3438/6000 [3:21:16<2:32:38,  3.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [3:21:20<2:38:15,  3.71s/it]                                                       {'loss': 0.0552, 'grad_norm': 8.539050102233887, 'learning_rate': 4.340677966101695e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3439/6000 [3:21:20<2:38:15,  3.71s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [3:21:23<2:34:21,  3.62s/it]                                                       {'loss': 0.0971, 'grad_norm': 12.867342948913574, 'learning_rate': 4.338983050847458e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3440/6000 [3:21:23<2:34:21,  3.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [3:21:27<2:33:31,  3.60s/it]                                                       {'loss': 0.0107, 'grad_norm': 2.41220760345459, 'learning_rate': 4.33728813559322e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3441/6000 [3:21:27<2:33:31,  3.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [3:21:30<2:31:17,  3.55s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.6265590786933899, 'learning_rate': 4.3355932203389834e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3442/6000 [3:21:30<2:31:17,  3.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [3:21:34<2:30:05,  3.52s/it]                                                       {'loss': 0.0535, 'grad_norm': 10.368724822998047, 'learning_rate': 4.333898305084746e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3443/6000 [3:21:34<2:30:05,  3.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [3:21:37<2:27:52,  3.47s/it]                                                       {'loss': 0.0639, 'grad_norm': 12.556739807128906, 'learning_rate': 4.332203389830509e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3444/6000 [3:21:37<2:27:52,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [3:21:40<2:26:24,  3.44s/it]                                                       {'loss': 0.0392, 'grad_norm': 6.895759105682373, 'learning_rate': 4.3305084745762716e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3445/6000 [3:21:40<2:26:24,  3.44s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [3:21:44<2:30:23,  3.53s/it]                                                       {'loss': 0.0352, 'grad_norm': 5.979403018951416, 'learning_rate': 4.328813559322034e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3446/6000 [3:21:44<2:30:23,  3.53s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [3:21:47<2:27:42,  3.47s/it]                                                       {'loss': 0.0468, 'grad_norm': 4.181110382080078, 'learning_rate': 4.327118644067797e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3447/6000 [3:21:47<2:27:42,  3.47s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [3:21:51<2:25:58,  3.43s/it]                                                       {'loss': 0.0246, 'grad_norm': 5.737542629241943, 'learning_rate': 4.32542372881356e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3448/6000 [3:21:51<2:25:58,  3.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [3:21:54<2:25:07,  3.41s/it]                                                       {'loss': 0.0283, 'grad_norm': 5.869802474975586, 'learning_rate': 4.323728813559322e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3449/6000 [3:21:54<2:25:07,  3.41s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [3:21:58<2:30:24,  3.54s/it]                                                       {'loss': 0.0181, 'grad_norm': 7.854541301727295, 'learning_rate': 4.322033898305085e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3450/6000 [3:21:58<2:30:24,  3.54s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [3:22:01<2:29:12,  3.51s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.572856068611145, 'learning_rate': 4.320338983050848e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3451/6000 [3:22:01<2:29:12,  3.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [3:22:05<2:33:12,  3.61s/it]                                                       {'loss': 0.0178, 'grad_norm': 6.086270332336426, 'learning_rate': 4.318644067796611e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3452/6000 [3:22:05<2:33:12,  3.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [3:22:09<2:31:28,  3.57s/it]                                                       {'loss': 0.1158, 'grad_norm': 10.934456825256348, 'learning_rate': 4.3169491525423735e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3453/6000 [3:22:09<2:31:28,  3.57s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [3:22:12<2:29:30,  3.52s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.1439080238342285, 'learning_rate': 4.315254237288136e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3454/6000 [3:22:12<2:29:30,  3.52s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [3:22:16<2:34:18,  3.64s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1468520611524582, 'learning_rate': 4.313559322033899e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3455/6000 [3:22:16<2:34:18,  3.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [3:22:19<2:31:43,  3.58s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11755798012018204, 'learning_rate': 4.311864406779661e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3456/6000 [3:22:19<2:31:43,  3.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [3:22:23<2:28:32,  3.50s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.16462665796279907, 'learning_rate': 4.310169491525424e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3457/6000 [3:22:23<2:28:32,  3.50s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [3:22:26<2:26:34,  3.46s/it]                                                       {'loss': 0.0053, 'grad_norm': 2.7708325386047363, 'learning_rate': 4.3084745762711865e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3458/6000 [3:22:26<2:26:34,  3.46s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [3:22:30<2:26:12,  3.45s/it]                                                       {'loss': 0.0324, 'grad_norm': 6.233838081359863, 'learning_rate': 4.306779661016949e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3459/6000 [3:22:30<2:26:12,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [3:22:33<2:23:58,  3.40s/it]                                                       {'loss': 0.0644, 'grad_norm': 14.187525749206543, 'learning_rate': 4.305084745762712e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3460/6000 [3:22:33<2:23:58,  3.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [3:22:36<2:23:43,  3.40s/it]                                                       {'loss': 0.3192, 'grad_norm': 16.522319793701172, 'learning_rate': 4.303389830508475e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3461/6000 [3:22:36<2:23:43,  3.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [3:22:40<2:23:26,  3.39s/it]                                                       {'loss': 0.0127, 'grad_norm': 3.4486515522003174, 'learning_rate': 4.301694915254238e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3462/6000 [3:22:40<2:23:26,  3.39s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [3:22:43<2:24:15,  3.41s/it]                                                       {'loss': 0.0131, 'grad_norm': 3.162585735321045, 'learning_rate': 4.3e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3463/6000 [3:22:43<2:24:15,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [3:22:46<2:24:01,  3.41s/it]                                                       {'loss': 0.0356, 'grad_norm': 8.530293464660645, 'learning_rate': 4.298305084745763e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3464/6000 [3:22:46<2:24:01,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [3:22:50<2:24:02,  3.41s/it]                                                       {'loss': 0.0292, 'grad_norm': 8.777854919433594, 'learning_rate': 4.296610169491526e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3465/6000 [3:22:50<2:24:02,  3.41s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [3:22:53<2:23:33,  3.40s/it]                                                       {'loss': 0.0236, 'grad_norm': 6.817573070526123, 'learning_rate': 4.2949152542372885e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/6000 [3:22:53<2:23:33,  3.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [3:22:57<2:22:51,  3.38s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.9404844045639038, 'learning_rate': 4.293220338983051e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3467/6000 [3:22:57<2:22:51,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [3:23:00<2:24:25,  3.42s/it]                                                       {'loss': 0.0049, 'grad_norm': 1.915688157081604, 'learning_rate': 4.291525423728814e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3468/6000 [3:23:00<2:24:25,  3.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [3:23:04<2:28:42,  3.53s/it]                                                       {'loss': 0.1802, 'grad_norm': 14.932281494140625, 'learning_rate': 4.289830508474577e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3469/6000 [3:23:04<2:28:42,  3.53s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [3:23:07<2:28:34,  3.52s/it]                                                       {'loss': 0.0217, 'grad_norm': 5.323921203613281, 'learning_rate': 4.28813559322034e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3470/6000 [3:23:07<2:28:34,  3.52s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [3:23:11<2:26:36,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.3230464458465576, 'learning_rate': 4.286440677966102e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3471/6000 [3:23:11<2:26:36,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [3:23:14<2:24:58,  3.44s/it]                                                       {'loss': 0.0464, 'grad_norm': 9.747078895568848, 'learning_rate': 4.284745762711865e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3472/6000 [3:23:14<2:24:58,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [3:23:18<2:26:02,  3.47s/it]                                                       {'loss': 0.0027, 'grad_norm': 1.3545396327972412, 'learning_rate': 4.283050847457628e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3473/6000 [3:23:18<2:26:02,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [3:23:21<2:25:21,  3.45s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.7207505702972412, 'learning_rate': 4.28135593220339e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3474/6000 [3:23:21<2:25:21,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [3:23:24<2:24:40,  3.44s/it]                                                       {'loss': 0.0976, 'grad_norm': 13.570158004760742, 'learning_rate': 4.279661016949153e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3475/6000 [3:23:24<2:24:40,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [3:23:28<2:25:19,  3.45s/it]                                                       {'loss': 0.0085, 'grad_norm': 2.4957966804504395, 'learning_rate': 4.277966101694915e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3476/6000 [3:23:28<2:25:19,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [3:23:32<2:27:00,  3.50s/it]                                                       {'loss': 0.0752, 'grad_norm': 10.822733879089355, 'learning_rate': 4.276271186440678e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3477/6000 [3:23:32<2:27:00,  3.50s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [3:23:35<2:25:43,  3.47s/it]                                                       {'loss': 0.01, 'grad_norm': 3.3595688343048096, 'learning_rate': 4.274576271186441e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3478/6000 [3:23:35<2:25:43,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [3:23:39<2:26:41,  3.49s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4144054055213928, 'learning_rate': 4.272881355932203e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3479/6000 [3:23:39<2:26:41,  3.49s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [3:23:42<2:30:49,  3.59s/it]                                                       {'loss': 0.3472, 'grad_norm': 14.902999877929688, 'learning_rate': 4.271186440677967e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3480/6000 [3:23:42<2:30:49,  3.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [3:23:46<2:27:38,  3.52s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.5100319385528564, 'learning_rate': 4.269491525423729e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3481/6000 [3:23:46<2:27:38,  3.52s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [3:23:49<2:25:25,  3.47s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.5461810231208801, 'learning_rate': 4.2677966101694915e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3482/6000 [3:23:49<2:25:25,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [3:23:52<2:25:25,  3.47s/it]                                                       {'loss': 0.012, 'grad_norm': 2.9806907176971436, 'learning_rate': 4.266101694915255e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3483/6000 [3:23:52<2:25:25,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [3:23:56<2:24:11,  3.44s/it]                                                       {'loss': 0.0509, 'grad_norm': 8.899125099182129, 'learning_rate': 4.264406779661017e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3484/6000 [3:23:56<2:24:11,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [3:23:59<2:24:45,  3.45s/it]                                                       {'loss': 0.0367, 'grad_norm': 7.923490524291992, 'learning_rate': 4.26271186440678e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3485/6000 [3:23:59<2:24:45,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [3:24:03<2:24:14,  3.44s/it]                                                       {'loss': 0.1372, 'grad_norm': 15.594406127929688, 'learning_rate': 4.261016949152543e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3486/6000 [3:24:03<2:24:14,  3.44s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [3:24:06<2:24:34,  3.45s/it]                                                       {'loss': 0.0571, 'grad_norm': 10.744325637817383, 'learning_rate': 4.259322033898305e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3487/6000 [3:24:06<2:24:34,  3.45s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [3:24:10<2:25:13,  3.47s/it]                                                       {'loss': 0.008, 'grad_norm': 1.5960451364517212, 'learning_rate': 4.257627118644068e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3488/6000 [3:24:10<2:25:13,  3.47s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [3:24:13<2:23:05,  3.42s/it]                                                       {'loss': 0.0953, 'grad_norm': 15.306031227111816, 'learning_rate': 4.255932203389831e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3489/6000 [3:24:13<2:23:05,  3.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [3:24:16<2:21:59,  3.39s/it]                                                       {'loss': 0.1004, 'grad_norm': 6.71290397644043, 'learning_rate': 4.2542372881355935e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3490/6000 [3:24:16<2:21:59,  3.39s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [3:24:20<2:21:32,  3.38s/it]                                                       {'loss': 0.0047, 'grad_norm': 0.8790731430053711, 'learning_rate': 4.252542372881357e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3491/6000 [3:24:20<2:21:32,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [3:24:23<2:20:51,  3.37s/it]                                                       {'loss': 0.0045, 'grad_norm': 1.6169490814208984, 'learning_rate': 4.250847457627119e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3492/6000 [3:24:23<2:20:51,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [3:24:26<2:20:36,  3.37s/it]                                                       {'loss': 0.0353, 'grad_norm': 6.78907585144043, 'learning_rate': 4.249152542372882e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3493/6000 [3:24:26<2:20:36,  3.37s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [3:24:30<2:21:19,  3.38s/it]                                                       {'loss': 0.0114, 'grad_norm': 2.2837650775909424, 'learning_rate': 4.247457627118645e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3494/6000 [3:24:30<2:21:19,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [3:24:33<2:21:52,  3.40s/it]                                                       {'loss': 0.068, 'grad_norm': 9.555533409118652, 'learning_rate': 4.245762711864407e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3495/6000 [3:24:33<2:21:52,  3.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [3:24:37<2:21:14,  3.38s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5458106994628906, 'learning_rate': 4.24406779661017e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3496/6000 [3:24:37<2:21:14,  3.38s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [3:24:40<2:20:20,  3.36s/it]                                                       {'loss': 0.0171, 'grad_norm': 4.300806999206543, 'learning_rate': 4.242372881355932e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3497/6000 [3:24:40<2:20:20,  3.36s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [3:24:44<2:25:10,  3.48s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.2694421708583832, 'learning_rate': 4.2406779661016954e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3498/6000 [3:24:44<2:25:10,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [3:24:47<2:25:10,  3.48s/it]                                                       {'loss': 0.0765, 'grad_norm': 9.868420600891113, 'learning_rate': 4.238983050847458e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3499/6000 [3:24:47<2:25:10,  3.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [3:24:51<2:24:32,  3.47s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08248333632946014, 'learning_rate': 4.23728813559322e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3500/6000 [3:24:51<2:24:32,  3.47s/it][2025-11-07 02:16:00,632] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3500
[2025-11-07 02:16:00,645] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:16:01,345] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [3:24:57<2:54:56,  4.20s/it]                                                       {'loss': 0.009, 'grad_norm': 2.0280675888061523, 'learning_rate': 4.2355932203389836e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3501/6000 [3:24:57<2:54:56,  4.20s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [3:25:00<2:44:14,  3.94s/it]                                                       {'loss': 0.0581, 'grad_norm': 11.148653984069824, 'learning_rate': 4.233898305084746e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3502/6000 [3:25:00<2:44:14,  3.94s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [3:25:03<2:38:39,  3.81s/it]                                                       {'loss': 0.0232, 'grad_norm': 4.265528202056885, 'learning_rate': 4.232203389830508e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3503/6000 [3:25:03<2:38:39,  3.81s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [3:25:07<2:32:50,  3.67s/it]                                                       {'loss': 0.0081, 'grad_norm': 2.4551005363464355, 'learning_rate': 4.230508474576272e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3504/6000 [3:25:07<2:32:50,  3.67s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [3:25:10<2:30:04,  3.61s/it]                                                       {'loss': 0.0436, 'grad_norm': 7.682549476623535, 'learning_rate': 4.228813559322034e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3505/6000 [3:25:10<2:30:04,  3.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [3:25:14<2:29:15,  3.59s/it]                                                       {'loss': 0.0244, 'grad_norm': 5.578003406524658, 'learning_rate': 4.2271186440677965e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3506/6000 [3:25:14<2:29:15,  3.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [3:25:17<2:28:14,  3.57s/it]                                                       {'loss': 0.0981, 'grad_norm': 13.750286102294922, 'learning_rate': 4.22542372881356e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3507/6000 [3:25:17<2:28:14,  3.57s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [3:25:21<2:28:10,  3.57s/it]                                                       {'loss': 0.0517, 'grad_norm': 4.8062262535095215, 'learning_rate': 4.223728813559322e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3508/6000 [3:25:21<2:28:10,  3.57s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [3:25:24<2:25:00,  3.49s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.1940402388572693, 'learning_rate': 4.2220338983050855e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3509/6000 [3:25:24<2:25:00,  3.49s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [3:25:28<2:24:34,  3.48s/it]                                                       {'loss': 0.0186, 'grad_norm': 6.856730937957764, 'learning_rate': 4.220338983050848e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3510/6000 [3:25:28<2:24:34,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [3:25:31<2:26:00,  3.52s/it]                                                       {'loss': 0.0242, 'grad_norm': 4.01476526260376, 'learning_rate': 4.21864406779661e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3511/6000 [3:25:31<2:26:00,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [3:25:35<2:24:38,  3.49s/it]                                                       {'loss': 0.0624, 'grad_norm': 11.601622581481934, 'learning_rate': 4.216949152542374e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3512/6000 [3:25:35<2:24:38,  3.49s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [3:25:38<2:28:14,  3.58s/it]                                                       {'loss': 0.1622, 'grad_norm': 15.872264862060547, 'learning_rate': 4.215254237288136e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3513/6000 [3:25:38<2:28:14,  3.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [3:25:42<2:27:26,  3.56s/it]                                                       {'loss': 0.0075, 'grad_norm': 2.2821319103240967, 'learning_rate': 4.2135593220338985e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3514/6000 [3:25:42<2:27:26,  3.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [3:25:45<2:25:47,  3.52s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.3801660537719727, 'learning_rate': 4.211864406779662e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3515/6000 [3:25:45<2:25:47,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [3:25:49<2:25:22,  3.51s/it]                                                       {'loss': 0.0148, 'grad_norm': 3.409029722213745, 'learning_rate': 4.210169491525424e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3516/6000 [3:25:49<2:25:22,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [3:25:52<2:24:54,  3.50s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.7942726612091064, 'learning_rate': 4.2084745762711875e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3517/6000 [3:25:52<2:24:54,  3.50s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [3:25:56<2:22:27,  3.44s/it]                                                       {'loss': 0.5965, 'grad_norm': 20.186260223388672, 'learning_rate': 4.206779661016949e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3518/6000 [3:25:56<2:22:27,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [3:25:59<2:25:16,  3.51s/it]                                                       {'loss': 0.2673, 'grad_norm': 13.39078426361084, 'learning_rate': 4.205084745762712e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3519/6000 [3:25:59<2:25:16,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [3:26:03<2:25:57,  3.53s/it]                                                       {'loss': 0.17, 'grad_norm': 13.561610221862793, 'learning_rate': 4.203389830508475e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3520/6000 [3:26:03<2:25:57,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [3:26:06<2:24:34,  3.50s/it]                                                       {'loss': 0.2572, 'grad_norm': 13.6439790725708, 'learning_rate': 4.201694915254237e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3521/6000 [3:26:06<2:24:34,  3.50s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [3:26:10<2:32:30,  3.69s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.7650809288024902, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3522/6000 [3:26:10<2:32:30,  3.69s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [3:26:14<2:30:57,  3.66s/it]                                                       {'loss': 0.0033, 'grad_norm': 2.91656756401062, 'learning_rate': 4.198305084745763e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3523/6000 [3:26:14<2:30:57,  3.66s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [3:26:17<2:28:08,  3.59s/it]                                                       {'loss': 0.0476, 'grad_norm': 4.56294059753418, 'learning_rate': 4.196610169491525e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3524/6000 [3:26:17<2:28:08,  3.59s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [3:26:21<2:26:08,  3.54s/it]                                                       {'loss': 0.1684, 'grad_norm': 14.17648983001709, 'learning_rate': 4.1949152542372886e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3525/6000 [3:26:21<2:26:08,  3.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [3:26:24<2:24:38,  3.51s/it]                                                       {'loss': 0.1412, 'grad_norm': 15.082236289978027, 'learning_rate': 4.193220338983051e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3526/6000 [3:26:24<2:24:38,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [3:26:28<2:22:44,  3.46s/it]                                                       {'loss': 0.0225, 'grad_norm': 2.6671998500823975, 'learning_rate': 4.191525423728814e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3527/6000 [3:26:28<2:22:44,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [3:26:31<2:20:47,  3.42s/it]                                                       {'loss': 0.0465, 'grad_norm': 4.4033684730529785, 'learning_rate': 4.189830508474577e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3528/6000 [3:26:31<2:20:47,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [3:26:34<2:21:21,  3.43s/it]                                                       {'loss': 0.0557, 'grad_norm': 5.822910308837891, 'learning_rate': 4.188135593220339e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3529/6000 [3:26:34<2:21:21,  3.43s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [3:26:38<2:20:28,  3.41s/it]                                                       {'loss': 0.1366, 'grad_norm': 16.760408401489258, 'learning_rate': 4.186440677966102e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3530/6000 [3:26:38<2:20:28,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [3:26:41<2:20:00,  3.40s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.6576560735702515, 'learning_rate': 4.184745762711865e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3531/6000 [3:26:41<2:20:00,  3.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [3:26:45<2:19:00,  3.38s/it]                                                       {'loss': 0.0219, 'grad_norm': 3.23909068107605, 'learning_rate': 4.183050847457627e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3532/6000 [3:26:45<2:19:00,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [3:26:48<2:19:09,  3.38s/it]                                                       {'loss': 0.1133, 'grad_norm': 12.964553833007812, 'learning_rate': 4.1813559322033905e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3533/6000 [3:26:48<2:19:09,  3.38s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [3:26:51<2:20:05,  3.41s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.9911003708839417, 'learning_rate': 4.179661016949153e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3534/6000 [3:26:51<2:20:05,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [3:26:55<2:20:31,  3.42s/it]                                                       {'loss': 0.0429, 'grad_norm': 5.233635425567627, 'learning_rate': 4.177966101694915e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3535/6000 [3:26:55<2:20:31,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [3:26:58<2:21:11,  3.44s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5265041589736938, 'learning_rate': 4.176271186440679e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3536/6000 [3:26:58<2:21:11,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [3:27:02<2:20:16,  3.42s/it]                                                       {'loss': 0.221, 'grad_norm': 17.552064895629883, 'learning_rate': 4.174576271186441e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3537/6000 [3:27:02<2:20:16,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [3:27:05<2:20:12,  3.42s/it]                                                       {'loss': 0.4086, 'grad_norm': 18.073843002319336, 'learning_rate': 4.172881355932204e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3538/6000 [3:27:05<2:20:12,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [3:27:09<2:19:55,  3.41s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.6267577409744263, 'learning_rate': 4.171186440677966e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3539/6000 [3:27:09<2:19:55,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [3:27:12<2:20:21,  3.42s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.36546799540519714, 'learning_rate': 4.169491525423729e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3540/6000 [3:27:12<2:20:21,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [3:27:15<2:20:03,  3.42s/it]                                                       {'loss': 0.3189, 'grad_norm': 15.52454662322998, 'learning_rate': 4.167796610169492e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3541/6000 [3:27:15<2:20:03,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [3:27:19<2:20:03,  3.42s/it]                                                       {'loss': 0.1959, 'grad_norm': 13.48250961303711, 'learning_rate': 4.166101694915254e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3542/6000 [3:27:19<2:20:03,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [3:27:22<2:21:18,  3.45s/it]                                                       {'loss': 0.0121, 'grad_norm': 2.73171067237854, 'learning_rate': 4.164406779661017e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3543/6000 [3:27:22<2:21:18,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [3:27:26<2:21:37,  3.46s/it]                                                       {'loss': 0.2883, 'grad_norm': 16.49848747253418, 'learning_rate': 4.16271186440678e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3544/6000 [3:27:26<2:21:37,  3.46s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [3:27:29<2:20:51,  3.44s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.3068417310714722, 'learning_rate': 4.161016949152543e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3545/6000 [3:27:29<2:20:51,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [3:27:33<2:26:00,  3.57s/it]                                                       {'loss': 0.0581, 'grad_norm': 8.998138427734375, 'learning_rate': 4.1593220338983055e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3546/6000 [3:27:33<2:26:00,  3.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [3:27:37<2:25:04,  3.55s/it]                                                       {'loss': 0.2013, 'grad_norm': 15.6107177734375, 'learning_rate': 4.157627118644068e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3547/6000 [3:27:37<2:25:04,  3.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [3:27:40<2:24:04,  3.53s/it]                                                       {'loss': 0.002, 'grad_norm': 0.678094744682312, 'learning_rate': 4.155932203389831e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3548/6000 [3:27:40<2:24:04,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [3:27:43<2:22:16,  3.48s/it]                                                       {'loss': 0.008, 'grad_norm': 2.5806026458740234, 'learning_rate': 4.154237288135594e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3549/6000 [3:27:43<2:22:16,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [3:27:47<2:20:54,  3.45s/it]                                                       {'loss': 0.0318, 'grad_norm': 3.0716795921325684, 'learning_rate': 4.152542372881356e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3550/6000 [3:27:47<2:20:54,  3.45s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [3:27:51<2:33:29,  3.76s/it]                                                       {'loss': 0.0308, 'grad_norm': 4.8803935050964355, 'learning_rate': 4.150847457627119e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3551/6000 [3:27:51<2:33:29,  3.76s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [3:27:55<2:33:51,  3.77s/it]                                                       {'loss': 0.0364, 'grad_norm': 5.584954738616943, 'learning_rate': 4.149152542372882e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3552/6000 [3:27:55<2:33:51,  3.77s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [3:27:59<2:31:29,  3.71s/it]                                                       {'loss': 0.0271, 'grad_norm': 7.682153701782227, 'learning_rate': 4.147457627118644e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3553/6000 [3:27:59<2:31:29,  3.71s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [3:28:02<2:27:17,  3.61s/it]                                                       {'loss': 0.0268, 'grad_norm': 4.106851577758789, 'learning_rate': 4.145762711864407e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3554/6000 [3:28:02<2:27:17,  3.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [3:28:05<2:25:04,  3.56s/it]                                                       {'loss': 0.1543, 'grad_norm': 14.451367378234863, 'learning_rate': 4.14406779661017e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3555/6000 [3:28:05<2:25:04,  3.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [3:28:09<2:23:40,  3.53s/it]                                                       {'loss': 0.0715, 'grad_norm': 9.571577072143555, 'learning_rate': 4.142372881355933e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3556/6000 [3:28:09<2:23:40,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [3:28:12<2:23:46,  3.53s/it]                                                       {'loss': 0.0166, 'grad_norm': 5.0923943519592285, 'learning_rate': 4.1406779661016955e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3557/6000 [3:28:12<2:23:46,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [3:28:16<2:22:57,  3.51s/it]                                                       {'loss': 0.0, 'grad_norm': 0.011798505671322346, 'learning_rate': 4.138983050847458e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3558/6000 [3:28:16<2:22:57,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [3:28:19<2:21:44,  3.48s/it]                                                       {'loss': 0.156, 'grad_norm': 11.725019454956055, 'learning_rate': 4.13728813559322e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3559/6000 [3:28:19<2:21:44,  3.48s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [3:28:23<2:19:50,  3.44s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.7556512951850891, 'learning_rate': 4.135593220338983e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3560/6000 [3:28:23<2:19:50,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [3:28:26<2:19:09,  3.42s/it]                                                       {'loss': 0.0296, 'grad_norm': 8.24940299987793, 'learning_rate': 4.133898305084746e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3561/6000 [3:28:26<2:19:09,  3.42s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [3:28:29<2:18:22,  3.41s/it]                                                       {'loss': 0.0153, 'grad_norm': 2.0123116970062256, 'learning_rate': 4.1322033898305085e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3562/6000 [3:28:29<2:18:22,  3.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [3:28:33<2:19:50,  3.44s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.15329395234584808, 'learning_rate': 4.130508474576271e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3563/6000 [3:28:33<2:19:50,  3.44s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [3:28:37<2:24:17,  3.55s/it]                                                       {'loss': 0.0076, 'grad_norm': 2.194193124771118, 'learning_rate': 4.128813559322034e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3564/6000 [3:28:37<2:24:17,  3.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [3:28:40<2:22:36,  3.51s/it]                                                       {'loss': 0.0052, 'grad_norm': 1.0322736501693726, 'learning_rate': 4.127118644067797e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3565/6000 [3:28:40<2:22:36,  3.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [3:28:44<2:25:02,  3.58s/it]                                                       {'loss': 0.0295, 'grad_norm': 6.6791672706604, 'learning_rate': 4.12542372881356e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3566/6000 [3:28:44<2:25:02,  3.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [3:28:47<2:23:13,  3.53s/it]                                                       {'loss': 0.001, 'grad_norm': 0.21023719012737274, 'learning_rate': 4.123728813559322e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3567/6000 [3:28:47<2:23:13,  3.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [3:28:51<2:22:52,  3.52s/it]                                                       {'loss': 0.1414, 'grad_norm': 7.935987949371338, 'learning_rate': 4.122033898305085e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/6000 [3:28:51<2:22:52,  3.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [3:28:54<2:22:17,  3.51s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3279704749584198, 'learning_rate': 4.120338983050848e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3569/6000 [3:28:54<2:22:17,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [3:28:58<2:20:34,  3.47s/it]                                                       {'loss': 0.0156, 'grad_norm': 3.0088846683502197, 'learning_rate': 4.1186440677966105e-06, 'epoch': 0.59}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3570/6000 [3:28:58<2:20:34,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [3:29:01<2:19:15,  3.44s/it]                                                       {'loss': 0.053, 'grad_norm': 3.5594065189361572, 'learning_rate': 4.116949152542373e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3571/6000 [3:29:01<2:19:15,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [3:29:05<2:20:39,  3.48s/it]                                                       {'loss': 0.0362, 'grad_norm': 5.94130277633667, 'learning_rate': 4.115254237288136e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3572/6000 [3:29:05<2:20:39,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [3:29:08<2:19:57,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.22576217353343964, 'learning_rate': 4.113559322033899e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3573/6000 [3:29:08<2:19:57,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [3:29:12<2:25:07,  3.59s/it]                                                       {'loss': 0.004, 'grad_norm': 1.4886943101882935, 'learning_rate': 4.111864406779662e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3574/6000 [3:29:12<2:25:07,  3.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [3:29:16<2:32:15,  3.77s/it]                                                       {'loss': 0.008, 'grad_norm': 2.496896982192993, 'learning_rate': 4.110169491525424e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3575/6000 [3:29:16<2:32:15,  3.77s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [3:29:20<2:27:58,  3.66s/it]                                                       {'loss': 0.012, 'grad_norm': 1.5742348432540894, 'learning_rate': 4.108474576271187e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3576/6000 [3:29:20<2:27:58,  3.66s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [3:29:23<2:27:49,  3.66s/it]                                                       {'loss': 0.0225, 'grad_norm': 3.605253219604492, 'learning_rate': 4.10677966101695e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3577/6000 [3:29:23<2:27:49,  3.66s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [3:29:27<2:23:32,  3.56s/it]                                                       {'loss': 0.0167, 'grad_norm': 4.534815788269043, 'learning_rate': 4.1050847457627124e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3578/6000 [3:29:27<2:23:32,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [3:29:30<2:20:30,  3.48s/it]                                                       {'loss': 0.0076, 'grad_norm': 2.368377923965454, 'learning_rate': 4.103389830508475e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3579/6000 [3:29:30<2:20:30,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [3:29:33<2:20:20,  3.48s/it]                                                       {'loss': 0.0095, 'grad_norm': 2.6293962001800537, 'learning_rate': 4.101694915254237e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3580/6000 [3:29:33<2:20:20,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [3:29:37<2:24:41,  3.59s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.32397904992103577, 'learning_rate': 4.1e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3581/6000 [3:29:37<2:24:41,  3.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [3:29:41<2:23:38,  3.56s/it]                                                       {'loss': 0.1413, 'grad_norm': 11.169190406799316, 'learning_rate': 4.098305084745763e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3582/6000 [3:29:41<2:23:38,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [3:29:44<2:26:22,  3.63s/it]                                                       {'loss': 0.1839, 'grad_norm': 15.057019233703613, 'learning_rate': 4.096610169491525e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3583/6000 [3:29:44<2:26:22,  3.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [3:29:48<2:23:43,  3.57s/it]                                                       {'loss': 0.08, 'grad_norm': 12.739030838012695, 'learning_rate': 4.094915254237289e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3584/6000 [3:29:48<2:23:43,  3.57s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [3:29:51<2:21:14,  3.51s/it]                                                       {'loss': 0.082, 'grad_norm': 10.459393501281738, 'learning_rate': 4.093220338983051e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3585/6000 [3:29:51<2:21:14,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [3:29:55<2:19:22,  3.46s/it]                                                       {'loss': 0.1486, 'grad_norm': 11.959227561950684, 'learning_rate': 4.0915254237288135e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3586/6000 [3:29:55<2:19:22,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [3:29:58<2:20:05,  3.48s/it]                                                       {'loss': 0.0533, 'grad_norm': 9.509551048278809, 'learning_rate': 4.089830508474577e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3587/6000 [3:29:58<2:20:05,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [3:30:02<2:19:17,  3.46s/it]                                                       {'loss': 0.1159, 'grad_norm': 12.258259773254395, 'learning_rate': 4.088135593220339e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3588/6000 [3:30:02<2:19:17,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [3:30:05<2:18:51,  3.46s/it]                                                       {'loss': 0.1501, 'grad_norm': 8.742240905761719, 'learning_rate': 4.086440677966102e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3589/6000 [3:30:05<2:18:51,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [3:30:08<2:18:06,  3.44s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.7351975440979004, 'learning_rate': 4.084745762711865e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3590/6000 [3:30:08<2:18:06,  3.44s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [3:30:12<2:16:59,  3.41s/it]                                                       {'loss': 0.1363, 'grad_norm': 11.26966381072998, 'learning_rate': 4.083050847457627e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3591/6000 [3:30:12<2:16:59,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [3:30:15<2:16:32,  3.40s/it]                                                       {'loss': 0.0081, 'grad_norm': 1.9093981981277466, 'learning_rate': 4.081355932203391e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3592/6000 [3:30:15<2:16:32,  3.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [3:30:18<2:16:17,  3.40s/it]                                                       {'loss': 0.2178, 'grad_norm': 12.58625602722168, 'learning_rate': 4.079661016949153e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3593/6000 [3:30:18<2:16:17,  3.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [3:30:22<2:22:52,  3.56s/it]                                                       {'loss': 0.1273, 'grad_norm': 11.28023910522461, 'learning_rate': 4.0779661016949155e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3594/6000 [3:30:22<2:22:52,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [3:30:26<2:22:04,  3.54s/it]                                                       {'loss': 0.1316, 'grad_norm': 6.736570835113525, 'learning_rate': 4.076271186440679e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3595/6000 [3:30:26<2:22:04,  3.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [3:30:29<2:19:46,  3.49s/it]                                                       {'loss': 0.0102, 'grad_norm': 1.758484959602356, 'learning_rate': 4.074576271186441e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3596/6000 [3:30:29<2:19:46,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [3:30:33<2:19:14,  3.48s/it]                                                       {'loss': 0.0311, 'grad_norm': 9.12657356262207, 'learning_rate': 4.072881355932204e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3597/6000 [3:30:33<2:19:14,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [3:30:36<2:21:22,  3.53s/it]                                                       {'loss': 0.2307, 'grad_norm': 18.7503604888916, 'learning_rate': 4.071186440677967e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3598/6000 [3:30:36<2:21:22,  3.53s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [3:30:40<2:19:07,  3.48s/it]                                                       {'loss': 0.0112, 'grad_norm': 3.5637989044189453, 'learning_rate': 4.069491525423729e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3599/6000 [3:30:40<2:19:07,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [3:30:43<2:17:16,  3.43s/it]                                                       {'loss': 0.0262, 'grad_norm': 6.753470420837402, 'learning_rate': 4.067796610169492e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3600/6000 [3:30:43<2:17:16,  3.43s/it][2025-11-07 02:21:53,078] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3600
[2025-11-07 02:21:53,095] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:21:53,785] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [3:30:49<2:50:32,  4.27s/it]                                                       {'loss': 0.0933, 'grad_norm': 9.89905834197998, 'learning_rate': 4.066101694915254e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3601/6000 [3:30:49<2:50:32,  4.27s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [3:30:53<2:40:20,  4.01s/it]                                                       {'loss': 0.159, 'grad_norm': 17.42140007019043, 'learning_rate': 4.0644067796610174e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3602/6000 [3:30:53<2:40:20,  4.01s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [3:30:56<2:33:54,  3.85s/it]                                                       {'loss': 0.0929, 'grad_norm': 13.157012939453125, 'learning_rate': 4.06271186440678e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3603/6000 [3:30:56<2:33:54,  3.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [3:31:00<2:28:10,  3.71s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.858576774597168, 'learning_rate': 4.061016949152542e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3604/6000 [3:31:00<2:28:10,  3.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [3:31:03<2:23:51,  3.60s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04513179883360863, 'learning_rate': 4.0593220338983056e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3605/6000 [3:31:03<2:23:51,  3.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [3:31:06<2:22:11,  3.56s/it]                                                       {'loss': 0.0735, 'grad_norm': 4.387216091156006, 'learning_rate': 4.057627118644068e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3606/6000 [3:31:06<2:22:11,  3.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [3:31:10<2:20:46,  3.53s/it]                                                       {'loss': 0.1073, 'grad_norm': 14.571796417236328, 'learning_rate': 4.0559322033898304e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3607/6000 [3:31:10<2:20:46,  3.53s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [3:31:13<2:20:26,  3.52s/it]                                                       {'loss': 0.1727, 'grad_norm': 13.620816230773926, 'learning_rate': 4.054237288135594e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3608/6000 [3:31:13<2:20:26,  3.52s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [3:31:18<2:29:25,  3.75s/it]                                                       {'loss': 0.0049, 'grad_norm': 1.7739206552505493, 'learning_rate': 4.052542372881356e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3609/6000 [3:31:18<2:29:25,  3.75s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [3:31:22<2:36:27,  3.93s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.7555517554283142, 'learning_rate': 4.0508474576271186e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3610/6000 [3:31:22<2:36:27,  3.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [3:31:25<2:30:09,  3.77s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2694033682346344, 'learning_rate': 4.049152542372882e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3611/6000 [3:31:25<2:30:09,  3.77s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [3:31:29<2:27:37,  3.71s/it]                                                       {'loss': 0.1542, 'grad_norm': 15.226125717163086, 'learning_rate': 4.047457627118644e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3612/6000 [3:31:29<2:27:37,  3.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [3:31:32<2:23:42,  3.61s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.25301048159599304, 'learning_rate': 4.0457627118644075e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3613/6000 [3:31:32<2:23:42,  3.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [3:31:36<2:25:15,  3.65s/it]                                                       {'loss': 0.1378, 'grad_norm': 12.766687393188477, 'learning_rate': 4.04406779661017e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3614/6000 [3:31:36<2:25:15,  3.65s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [3:31:40<2:22:34,  3.59s/it]                                                       {'loss': 0.2816, 'grad_norm': 12.681440353393555, 'learning_rate': 4.042372881355932e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3615/6000 [3:31:40<2:22:34,  3.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [3:31:43<2:20:56,  3.55s/it]                                                       {'loss': 0.2209, 'grad_norm': 17.29010772705078, 'learning_rate': 4.040677966101696e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3616/6000 [3:31:43<2:20:56,  3.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [3:31:46<2:19:06,  3.50s/it]                                                       {'loss': 0.0076, 'grad_norm': 2.0654428005218506, 'learning_rate': 4.038983050847458e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3617/6000 [3:31:46<2:19:06,  3.50s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [3:31:50<2:18:15,  3.48s/it]                                                       {'loss': 0.0212, 'grad_norm': 4.0857462882995605, 'learning_rate': 4.0372881355932205e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3618/6000 [3:31:50<2:18:15,  3.48s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [3:31:53<2:18:48,  3.50s/it]                                                       {'loss': 0.1777, 'grad_norm': 15.000752449035645, 'learning_rate': 4.035593220338984e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/6000 [3:31:53<2:18:48,  3.50s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [3:31:57<2:17:25,  3.46s/it]                                                       {'loss': 0.0188, 'grad_norm': 5.112320423126221, 'learning_rate': 4.033898305084746e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3620/6000 [3:31:57<2:17:25,  3.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [3:32:00<2:19:13,  3.51s/it]                                                       {'loss': 0.1294, 'grad_norm': 14.512483596801758, 'learning_rate': 4.0322033898305095e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3621/6000 [3:32:00<2:19:13,  3.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [3:32:04<2:17:28,  3.47s/it]                                                       {'loss': 0.1959, 'grad_norm': 12.732592582702637, 'learning_rate': 4.030508474576271e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3622/6000 [3:32:04<2:17:28,  3.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [3:32:07<2:15:47,  3.43s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.31005915999412537, 'learning_rate': 4.028813559322034e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3623/6000 [3:32:07<2:15:47,  3.43s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [3:32:10<2:14:54,  3.41s/it]                                                       {'loss': 0.1776, 'grad_norm': 12.625123023986816, 'learning_rate': 4.027118644067797e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3624/6000 [3:32:10<2:14:54,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [3:32:14<2:14:52,  3.41s/it]                                                       {'loss': 0.2388, 'grad_norm': 17.245399475097656, 'learning_rate': 4.025423728813559e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3625/6000 [3:32:14<2:14:52,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [3:32:17<2:15:02,  3.41s/it]                                                       {'loss': 0.0906, 'grad_norm': 15.178278923034668, 'learning_rate': 4.0237288135593225e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3626/6000 [3:32:17<2:15:02,  3.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [3:32:21<2:15:04,  3.42s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.218258336186409, 'learning_rate': 4.022033898305085e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3627/6000 [3:32:21<2:15:04,  3.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [3:32:24<2:13:19,  3.37s/it]                                                       {'loss': 0.0195, 'grad_norm': 5.679116249084473, 'learning_rate': 4.020338983050847e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3628/6000 [3:32:24<2:13:19,  3.37s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [3:32:28<2:17:48,  3.49s/it]                                                       {'loss': 0.0234, 'grad_norm': 5.129665374755859, 'learning_rate': 4.018644067796611e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3629/6000 [3:32:28<2:17:48,  3.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [3:32:31<2:16:11,  3.45s/it]                                                       {'loss': 0.2607, 'grad_norm': 14.480464935302734, 'learning_rate': 4.016949152542373e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3630/6000 [3:32:31<2:16:11,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [3:32:34<2:15:58,  3.44s/it]                                                       {'loss': 0.0674, 'grad_norm': 10.597163200378418, 'learning_rate': 4.015254237288136e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3631/6000 [3:32:34<2:15:58,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [3:32:38<2:15:21,  3.43s/it]                                                       {'loss': 0.0233, 'grad_norm': 4.380737781524658, 'learning_rate': 4.013559322033899e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3632/6000 [3:32:38<2:15:21,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [3:32:42<2:25:42,  3.69s/it]                                                       {'loss': 0.2466, 'grad_norm': 15.361376762390137, 'learning_rate': 4.011864406779661e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3633/6000 [3:32:42<2:25:42,  3.69s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [3:32:46<2:21:29,  3.59s/it]                                                       {'loss': 0.0707, 'grad_norm': 10.325143814086914, 'learning_rate': 4.010169491525424e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3634/6000 [3:32:46<2:21:29,  3.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [3:32:49<2:18:26,  3.51s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.378347784280777, 'learning_rate': 4.008474576271187e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3635/6000 [3:32:49<2:18:26,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [3:32:52<2:17:33,  3.49s/it]                                                       {'loss': 0.0157, 'grad_norm': 4.1530537605285645, 'learning_rate': 4.006779661016949e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3636/6000 [3:32:52<2:17:33,  3.49s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [3:32:56<2:18:36,  3.52s/it]                                                       {'loss': 0.0591, 'grad_norm': 7.167182445526123, 'learning_rate': 4.0050847457627125e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3637/6000 [3:32:56<2:18:36,  3.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [3:32:59<2:17:51,  3.50s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.24658727645874023, 'learning_rate': 4.003389830508475e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3638/6000 [3:32:59<2:17:51,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [3:33:03<2:16:25,  3.47s/it]                                                       {'loss': 0.1002, 'grad_norm': 14.396946907043457, 'learning_rate': 4.001694915254237e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3639/6000 [3:33:03<2:16:25,  3.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [3:33:06<2:16:14,  3.46s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.8982511162757874, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3640/6000 [3:33:06<2:16:14,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [3:33:10<2:15:30,  3.45s/it]                                                       {'loss': 0.0507, 'grad_norm': 9.808762550354004, 'learning_rate': 3.998305084745763e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3641/6000 [3:33:10<2:15:30,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [3:33:13<2:15:08,  3.44s/it]                                                       {'loss': 0.0967, 'grad_norm': 9.132036209106445, 'learning_rate': 3.996610169491526e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3642/6000 [3:33:13<2:15:08,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [3:33:17<2:20:05,  3.57s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.09170923382043839, 'learning_rate': 3.994915254237288e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3643/6000 [3:33:17<2:20:05,  3.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [3:33:20<2:16:35,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.2915531098842621, 'learning_rate': 3.993220338983051e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3644/6000 [3:33:20<2:16:35,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [3:33:24<2:16:31,  3.48s/it]                                                       {'loss': 0.2788, 'grad_norm': 21.07688331604004, 'learning_rate': 3.991525423728814e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3645/6000 [3:33:24<2:16:31,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [3:33:27<2:15:41,  3.46s/it]                                                       {'loss': 0.2133, 'grad_norm': 15.14875316619873, 'learning_rate': 3.989830508474576e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3646/6000 [3:33:27<2:15:41,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [3:33:30<2:14:46,  3.44s/it]                                                       {'loss': 0.0799, 'grad_norm': 9.143095016479492, 'learning_rate': 3.988135593220339e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3647/6000 [3:33:30<2:14:46,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [3:33:34<2:14:22,  3.43s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.3330360651016235, 'learning_rate': 3.986440677966102e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3648/6000 [3:33:34<2:14:22,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [3:33:37<2:14:38,  3.44s/it]                                                       {'loss': 0.0254, 'grad_norm': 2.893986225128174, 'learning_rate': 3.984745762711865e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3649/6000 [3:33:37<2:14:38,  3.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [3:33:41<2:13:03,  3.40s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.0055471658706665, 'learning_rate': 3.9830508474576275e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3650/6000 [3:33:41<2:13:03,  3.40s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [3:33:44<2:15:25,  3.46s/it]                                                       {'loss': 0.0162, 'grad_norm': 4.780610084533691, 'learning_rate': 3.98135593220339e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3651/6000 [3:33:44<2:15:25,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [3:33:48<2:15:32,  3.46s/it]                                                       {'loss': 0.0238, 'grad_norm': 4.25781774520874, 'learning_rate': 3.979661016949153e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3652/6000 [3:33:48<2:15:32,  3.46s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [3:33:51<2:14:52,  3.45s/it]                                                       {'loss': 0.0458, 'grad_norm': 6.831996917724609, 'learning_rate': 3.977966101694916e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3653/6000 [3:33:51<2:14:52,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [3:33:54<2:13:27,  3.41s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.14857414364814758, 'learning_rate': 3.976271186440678e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3654/6000 [3:33:54<2:13:27,  3.41s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [3:33:58<2:13:31,  3.42s/it]                                                       {'loss': 0.1845, 'grad_norm': 14.814449310302734, 'learning_rate': 3.974576271186441e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3655/6000 [3:33:58<2:13:31,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [3:34:01<2:12:02,  3.38s/it]                                                       {'loss': 0.2868, 'grad_norm': 18.673763275146484, 'learning_rate': 3.972881355932204e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3656/6000 [3:34:01<2:12:02,  3.38s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [3:34:05<2:12:10,  3.38s/it]                                                       {'loss': 0.0546, 'grad_norm': 9.147656440734863, 'learning_rate': 3.971186440677966e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3657/6000 [3:34:05<2:12:10,  3.38s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [3:34:08<2:13:31,  3.42s/it]                                                       {'loss': 0.0216, 'grad_norm': 4.245204925537109, 'learning_rate': 3.9694915254237294e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3658/6000 [3:34:08<2:13:31,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [3:34:12<2:17:01,  3.51s/it]                                                       {'loss': 0.006, 'grad_norm': 1.4973273277282715, 'learning_rate': 3.967796610169492e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3659/6000 [3:34:12<2:17:01,  3.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [3:34:15<2:16:27,  3.50s/it]                                                       {'loss': 0.1476, 'grad_norm': 15.10481071472168, 'learning_rate': 3.966101694915255e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3660/6000 [3:34:15<2:16:27,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [3:34:19<2:15:30,  3.48s/it]                                                       {'loss': 0.0162, 'grad_norm': 4.7284674644470215, 'learning_rate': 3.9644067796610176e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3661/6000 [3:34:19<2:15:30,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [3:34:22<2:13:21,  3.42s/it]                                                       {'loss': 0.0218, 'grad_norm': 5.740547180175781, 'learning_rate': 3.96271186440678e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3662/6000 [3:34:22<2:13:21,  3.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [3:34:25<2:13:31,  3.43s/it]                                                       {'loss': 0.0878, 'grad_norm': 11.297388076782227, 'learning_rate': 3.961016949152542e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3663/6000 [3:34:25<2:13:31,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [3:34:29<2:12:18,  3.40s/it]                                                       {'loss': 0.0246, 'grad_norm': 3.1003143787384033, 'learning_rate': 3.959322033898305e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3664/6000 [3:34:29<2:12:18,  3.40s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [3:34:33<2:19:29,  3.58s/it]                                                       {'loss': 0.0137, 'grad_norm': 3.0877554416656494, 'learning_rate': 3.957627118644068e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3665/6000 [3:34:33<2:19:29,  3.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [3:34:37<2:24:32,  3.72s/it]                                                       {'loss': 0.0926, 'grad_norm': 7.128937721252441, 'learning_rate': 3.9559322033898305e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3666/6000 [3:34:37<2:24:32,  3.72s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [3:34:40<2:22:53,  3.67s/it]                                                       {'loss': 0.0372, 'grad_norm': 5.227889537811279, 'learning_rate': 3.954237288135593e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3667/6000 [3:34:40<2:22:53,  3.67s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [3:34:44<2:19:31,  3.59s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.8281384110450745, 'learning_rate': 3.952542372881356e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3668/6000 [3:34:44<2:19:31,  3.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [3:34:47<2:17:55,  3.55s/it]                                                       {'loss': 0.1248, 'grad_norm': 12.717270851135254, 'learning_rate': 3.950847457627119e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3669/6000 [3:34:47<2:17:55,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [3:34:51<2:20:41,  3.62s/it]                                                       {'loss': 0.1101, 'grad_norm': 13.43010425567627, 'learning_rate': 3.949152542372882e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3670/6000 [3:34:51<2:20:41,  3.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [3:34:54<2:16:45,  3.52s/it]                                                       {'loss': 0.0127, 'grad_norm': 2.5764312744140625, 'learning_rate': 3.947457627118644e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3671/6000 [3:34:54<2:16:45,  3.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [3:34:58<2:14:57,  3.48s/it]                                                       {'loss': 0.1297, 'grad_norm': 11.922035217285156, 'learning_rate': 3.945762711864407e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3672/6000 [3:34:58<2:14:57,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [3:35:01<2:13:45,  3.45s/it]                                                       {'loss': 0.1933, 'grad_norm': 14.97404670715332, 'learning_rate': 3.94406779661017e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3673/6000 [3:35:01<2:13:45,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [3:35:05<2:17:45,  3.55s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.16680414974689484, 'learning_rate': 3.9423728813559325e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3674/6000 [3:35:05<2:17:45,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [3:35:08<2:17:38,  3.55s/it]                                                       {'loss': 0.0402, 'grad_norm': 7.387211322784424, 'learning_rate': 3.940677966101695e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3675/6000 [3:35:08<2:17:38,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [3:35:12<2:17:08,  3.54s/it]                                                       {'loss': 0.04, 'grad_norm': 10.895939826965332, 'learning_rate': 3.938983050847458e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3676/6000 [3:35:12<2:17:08,  3.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [3:35:15<2:15:35,  3.50s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5650259256362915, 'learning_rate': 3.937288135593221e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3677/6000 [3:35:15<2:15:35,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [3:35:19<2:13:30,  3.45s/it]                                                       {'loss': 0.0509, 'grad_norm': 3.8657052516937256, 'learning_rate': 3.935593220338984e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3678/6000 [3:35:19<2:13:30,  3.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [3:35:22<2:12:42,  3.43s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.261307030916214, 'learning_rate': 3.933898305084746e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3679/6000 [3:35:22<2:12:42,  3.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [3:35:26<2:14:36,  3.48s/it]                                                       {'loss': 0.0804, 'grad_norm': 14.003687858581543, 'learning_rate': 3.932203389830509e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3680/6000 [3:35:26<2:14:36,  3.48s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [3:35:29<2:15:21,  3.50s/it]                                                       {'loss': 0.0674, 'grad_norm': 9.050909996032715, 'learning_rate': 3.930508474576272e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3681/6000 [3:35:29<2:15:21,  3.50s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [3:35:33<2:16:57,  3.55s/it]                                                       {'loss': 0.0945, 'grad_norm': 10.382601737976074, 'learning_rate': 3.9288135593220344e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3682/6000 [3:35:33<2:16:57,  3.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [3:35:37<2:20:41,  3.64s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.0932459607720375, 'learning_rate': 3.927118644067797e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3683/6000 [3:35:37<2:20:41,  3.64s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [3:35:40<2:17:14,  3.56s/it]                                                       {'loss': 0.0649, 'grad_norm': 11.315086364746094, 'learning_rate': 3.925423728813559e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3684/6000 [3:35:40<2:17:14,  3.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [3:35:44<2:19:07,  3.61s/it]                                                       {'loss': 0.0278, 'grad_norm': 4.713855743408203, 'learning_rate': 3.923728813559322e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3685/6000 [3:35:44<2:19:07,  3.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [3:35:47<2:17:45,  3.57s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.16596420109272003, 'learning_rate': 3.922033898305085e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3686/6000 [3:35:47<2:17:45,  3.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [3:35:51<2:19:55,  3.63s/it]                                                       {'loss': 0.1734, 'grad_norm': 18.69008445739746, 'learning_rate': 3.920338983050847e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3687/6000 [3:35:51<2:19:55,  3.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [3:35:54<2:17:20,  3.56s/it]                                                       {'loss': 0.0159, 'grad_norm': 4.197475433349609, 'learning_rate': 3.918644067796611e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3688/6000 [3:35:54<2:17:20,  3.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [3:35:58<2:15:33,  3.52s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.825614333152771, 'learning_rate': 3.916949152542373e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3689/6000 [3:35:58<2:15:33,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [3:36:01<2:15:44,  3.53s/it]                                                       {'loss': 0.0262, 'grad_norm': 5.040769577026367, 'learning_rate': 3.9152542372881355e-06, 'epoch': 0.61}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3690/6000 [3:36:01<2:15:44,  3.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [3:36:05<2:13:01,  3.46s/it]                                                       {'loss': 0.0515, 'grad_norm': 5.46382474899292, 'learning_rate': 3.913559322033899e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3691/6000 [3:36:05<2:13:01,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [3:36:08<2:13:50,  3.48s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.4958631992340088, 'learning_rate': 3.911864406779661e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3692/6000 [3:36:08<2:13:50,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [3:36:12<2:13:07,  3.46s/it]                                                       {'loss': 0.0333, 'grad_norm': 6.11700439453125, 'learning_rate': 3.910169491525424e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3693/6000 [3:36:12<2:13:07,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [3:36:15<2:15:10,  3.52s/it]                                                       {'loss': 0.0305, 'grad_norm': 6.80732536315918, 'learning_rate': 3.908474576271187e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3694/6000 [3:36:15<2:15:10,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [3:36:19<2:14:47,  3.51s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.1543463468551636, 'learning_rate': 3.906779661016949e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3695/6000 [3:36:19<2:14:47,  3.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [3:36:22<2:13:47,  3.48s/it]                                                       {'loss': 0.0053, 'grad_norm': 0.8107261657714844, 'learning_rate': 3.905084745762713e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3696/6000 [3:36:22<2:13:47,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [3:36:26<2:13:27,  3.48s/it]                                                       {'loss': 0.0228, 'grad_norm': 5.548122882843018, 'learning_rate': 3.903389830508475e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3697/6000 [3:36:26<2:13:27,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [3:36:30<2:22:27,  3.71s/it]                                                       {'loss': 0.0038, 'grad_norm': 1.2078819274902344, 'learning_rate': 3.9016949152542375e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3698/6000 [3:36:30<2:22:27,  3.71s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [3:36:34<2:22:42,  3.72s/it]                                                       {'loss': 0.0074, 'grad_norm': 1.0111374855041504, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3699/6000 [3:36:34<2:22:42,  3.72s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [3:36:37<2:22:57,  3.73s/it]                                                       {'loss': 0.0769, 'grad_norm': 15.818012237548828, 'learning_rate': 3.898305084745763e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3700/6000 [3:36:37<2:22:57,  3.73s/it][2025-11-07 02:27:47,404] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3700
[2025-11-07 02:27:47,417] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:27:48,077] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [3:36:43<2:46:23,  4.34s/it]                                                       {'loss': 0.0655, 'grad_norm': 7.095799446105957, 'learning_rate': 3.896610169491526e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3701/6000 [3:36:43<2:46:23,  4.34s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [3:36:46<2:34:26,  4.03s/it]                                                       {'loss': 0.0236, 'grad_norm': 6.16481351852417, 'learning_rate': 3.894915254237289e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3702/6000 [3:36:46<2:34:26,  4.03s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [3:36:50<2:26:37,  3.83s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.15936103463172913, 'learning_rate': 3.893220338983051e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3703/6000 [3:36:50<2:26:37,  3.83s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [3:36:53<2:21:37,  3.70s/it]                                                       {'loss': 0.0141, 'grad_norm': 4.958131313323975, 'learning_rate': 3.891525423728814e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3704/6000 [3:36:53<2:21:37,  3.70s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [3:36:57<2:18:53,  3.63s/it]                                                       {'loss': 0.0118, 'grad_norm': 2.6547579765319824, 'learning_rate': 3.889830508474576e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3705/6000 [3:36:57<2:18:53,  3.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [3:37:01<2:21:17,  3.70s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.9579728841781616, 'learning_rate': 3.8881355932203395e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3706/6000 [3:37:01<2:21:17,  3.70s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [3:37:04<2:17:03,  3.59s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.03733375668525696, 'learning_rate': 3.886440677966102e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3707/6000 [3:37:04<2:17:03,  3.59s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [3:37:07<2:14:20,  3.52s/it]                                                       {'loss': 0.0252, 'grad_norm': 6.880042552947998, 'learning_rate': 3.884745762711864e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3708/6000 [3:37:07<2:14:20,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [3:37:11<2:11:58,  3.46s/it]                                                       {'loss': 0.0203, 'grad_norm': 5.917501926422119, 'learning_rate': 3.883050847457628e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3709/6000 [3:37:11<2:11:58,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [3:37:14<2:11:29,  3.45s/it]                                                       {'loss': 0.0643, 'grad_norm': 6.365179061889648, 'learning_rate': 3.88135593220339e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3710/6000 [3:37:14<2:11:29,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [3:37:17<2:10:18,  3.42s/it]                                                       {'loss': 0.2338, 'grad_norm': 13.505252838134766, 'learning_rate': 3.8796610169491524e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3711/6000 [3:37:17<2:10:18,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [3:37:21<2:09:43,  3.40s/it]                                                       {'loss': 0.0448, 'grad_norm': 10.260096549987793, 'learning_rate': 3.877966101694916e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3712/6000 [3:37:21<2:09:43,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [3:37:24<2:10:24,  3.42s/it]                                                       {'loss': 0.093, 'grad_norm': 9.878140449523926, 'learning_rate': 3.876271186440678e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3713/6000 [3:37:24<2:10:24,  3.42s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [3:37:28<2:11:31,  3.45s/it]                                                       {'loss': 0.1288, 'grad_norm': 6.206408500671387, 'learning_rate': 3.8745762711864406e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3714/6000 [3:37:28<2:11:31,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [3:37:31<2:12:27,  3.48s/it]                                                       {'loss': 0.0177, 'grad_norm': 5.721127986907959, 'learning_rate': 3.872881355932204e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3715/6000 [3:37:31<2:12:27,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [3:37:35<2:11:15,  3.45s/it]                                                       {'loss': 0.023, 'grad_norm': 5.761046886444092, 'learning_rate': 3.871186440677966e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3716/6000 [3:37:35<2:11:15,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [3:37:38<2:10:42,  3.44s/it]                                                       {'loss': 0.1038, 'grad_norm': 10.764166831970215, 'learning_rate': 3.8694915254237295e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3717/6000 [3:37:38<2:10:42,  3.44s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [3:37:41<2:10:29,  3.43s/it]                                                       {'loss': 0.0326, 'grad_norm': 4.862100124359131, 'learning_rate': 3.867796610169492e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3718/6000 [3:37:41<2:10:29,  3.43s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [3:37:45<2:12:28,  3.48s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.5330544710159302, 'learning_rate': 3.866101694915254e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3719/6000 [3:37:45<2:12:28,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [3:37:48<2:11:18,  3.46s/it]                                                       {'loss': 0.1133, 'grad_norm': 11.723594665527344, 'learning_rate': 3.864406779661018e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3720/6000 [3:37:48<2:11:18,  3.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [3:37:52<2:11:03,  3.45s/it]                                                       {'loss': 0.0848, 'grad_norm': 15.613306045532227, 'learning_rate': 3.86271186440678e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3721/6000 [3:37:52<2:11:03,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [3:37:56<2:15:09,  3.56s/it]                                                       {'loss': 0.0058, 'grad_norm': 2.360158920288086, 'learning_rate': 3.8610169491525425e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/6000 [3:37:56<2:15:09,  3.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [3:37:59<2:12:12,  3.48s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.27224862575531, 'learning_rate': 3.859322033898306e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3723/6000 [3:37:59<2:12:12,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [3:38:03<2:17:14,  3.62s/it]                                                       {'loss': 0.0064, 'grad_norm': 2.2347257137298584, 'learning_rate': 3.857627118644068e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3724/6000 [3:38:03<2:17:14,  3.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [3:38:06<2:15:23,  3.57s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.07897462695837021, 'learning_rate': 3.8559322033898315e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3725/6000 [3:38:06<2:15:23,  3.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [3:38:10<2:17:36,  3.63s/it]                                                       {'loss': 0.2513, 'grad_norm': 13.169163703918457, 'learning_rate': 3.854237288135593e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3726/6000 [3:38:10<2:17:36,  3.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [3:38:14<2:14:57,  3.56s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.029400883242487907, 'learning_rate': 3.852542372881356e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3727/6000 [3:38:14<2:14:57,  3.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [3:38:17<2:12:04,  3.49s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.5610063076019287, 'learning_rate': 3.850847457627119e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3728/6000 [3:38:17<2:12:04,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [3:38:20<2:10:35,  3.45s/it]                                                       {'loss': 0.038, 'grad_norm': 10.584779739379883, 'learning_rate': 3.849152542372881e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3729/6000 [3:38:20<2:10:35,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [3:38:24<2:16:34,  3.61s/it]                                                       {'loss': 0.0261, 'grad_norm': 4.401708126068115, 'learning_rate': 3.8474576271186445e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3730/6000 [3:38:24<2:16:34,  3.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [3:38:28<2:14:35,  3.56s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.11179664731025696, 'learning_rate': 3.845762711864407e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3731/6000 [3:38:28<2:14:35,  3.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [3:38:31<2:13:24,  3.53s/it]                                                       {'loss': 0.0184, 'grad_norm': 6.852376461029053, 'learning_rate': 3.844067796610169e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3732/6000 [3:38:31<2:13:24,  3.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [3:38:35<2:17:05,  3.63s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03458439186215401, 'learning_rate': 3.842372881355933e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3733/6000 [3:38:35<2:17:05,  3.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [3:38:38<2:15:38,  3.59s/it]                                                       {'loss': 0.0202, 'grad_norm': 4.747332572937012, 'learning_rate': 3.840677966101695e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3734/6000 [3:38:38<2:15:38,  3.59s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [3:38:42<2:14:18,  3.56s/it]                                                       {'loss': 0.1429, 'grad_norm': 8.419957160949707, 'learning_rate': 3.838983050847458e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3735/6000 [3:38:42<2:14:18,  3.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [3:38:45<2:12:42,  3.52s/it]                                                       {'loss': 0.0459, 'grad_norm': 2.4115095138549805, 'learning_rate': 3.837288135593221e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3736/6000 [3:38:45<2:12:42,  3.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [3:38:49<2:11:22,  3.48s/it]                                                       {'loss': 0.0653, 'grad_norm': 10.615439414978027, 'learning_rate': 3.835593220338983e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3737/6000 [3:38:49<2:11:22,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [3:38:52<2:11:05,  3.48s/it]                                                       {'loss': 0.0776, 'grad_norm': 8.691624641418457, 'learning_rate': 3.8338983050847464e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3738/6000 [3:38:52<2:11:05,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [3:38:56<2:09:57,  3.45s/it]                                                       {'loss': 0.0969, 'grad_norm': 11.811147689819336, 'learning_rate': 3.832203389830509e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3739/6000 [3:38:56<2:09:57,  3.45s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [3:38:59<2:07:50,  3.39s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.05360442399978638, 'learning_rate': 3.830508474576271e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3740/6000 [3:38:59<2:07:50,  3.39s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [3:39:02<2:08:16,  3.41s/it]                                                       {'loss': 0.1466, 'grad_norm': 10.718170166015625, 'learning_rate': 3.8288135593220346e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3741/6000 [3:39:02<2:08:16,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [3:39:06<2:08:22,  3.41s/it]                                                       {'loss': 0.3351, 'grad_norm': 26.2006778717041, 'learning_rate': 3.827118644067797e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3742/6000 [3:39:06<2:08:22,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [3:39:09<2:08:17,  3.41s/it]                                                       {'loss': 0.0145, 'grad_norm': 3.4449212551116943, 'learning_rate': 3.82542372881356e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3743/6000 [3:39:09<2:08:17,  3.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [3:39:13<2:07:52,  3.40s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.8603024482727051, 'learning_rate': 3.823728813559323e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3744/6000 [3:39:13<2:07:52,  3.40s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [3:39:16<2:10:48,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.38133877515792847, 'learning_rate': 3.822033898305085e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3745/6000 [3:39:16<2:10:48,  3.48s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [3:39:20<2:14:43,  3.59s/it]                                                       {'loss': 0.0037, 'grad_norm': 1.032045841217041, 'learning_rate': 3.8203389830508475e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3746/6000 [3:39:20<2:14:43,  3.59s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [3:39:23<2:12:35,  3.53s/it]                                                       {'loss': 0.0083, 'grad_norm': 3.1057138442993164, 'learning_rate': 3.81864406779661e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3747/6000 [3:39:23<2:12:35,  3.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [3:39:27<2:11:08,  3.49s/it]                                                       {'loss': 0.0171, 'grad_norm': 5.7352776527404785, 'learning_rate': 3.816949152542373e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3748/6000 [3:39:27<2:11:08,  3.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [3:39:30<2:08:52,  3.44s/it]                                                       {'loss': 0.037, 'grad_norm': 5.921700477600098, 'learning_rate': 3.815254237288136e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3749/6000 [3:39:30<2:08:52,  3.44s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [3:39:34<2:09:08,  3.44s/it]                                                       {'loss': 0.0208, 'grad_norm': 5.672679901123047, 'learning_rate': 3.8135593220338985e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3750/6000 [3:39:34<2:09:08,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [3:39:37<2:07:32,  3.40s/it]                                                       {'loss': 0.0125, 'grad_norm': 4.056987285614014, 'learning_rate': 3.8118644067796614e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3751/6000 [3:39:37<2:07:32,  3.40s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [3:39:40<2:07:04,  3.39s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.3158773183822632, 'learning_rate': 3.8101694915254238e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3752/6000 [3:39:40<2:07:04,  3.39s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [3:39:44<2:05:53,  3.36s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.227150321006775, 'learning_rate': 3.8084745762711866e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3753/6000 [3:39:44<2:05:53,  3.36s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [3:39:47<2:06:26,  3.38s/it]                                                       {'loss': 0.0528, 'grad_norm': 8.261576652526855, 'learning_rate': 3.8067796610169495e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3754/6000 [3:39:47<2:06:26,  3.38s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [3:39:51<2:07:57,  3.42s/it]                                                       {'loss': 0.011, 'grad_norm': 3.937760353088379, 'learning_rate': 3.8050847457627123e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3755/6000 [3:39:51<2:07:57,  3.42s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [3:39:54<2:07:09,  3.40s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.3685781955718994, 'learning_rate': 3.8033898305084748e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3756/6000 [3:39:54<2:07:09,  3.40s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [3:39:58<2:10:04,  3.48s/it]                                                       {'loss': 0.0468, 'grad_norm': 5.761050224304199, 'learning_rate': 3.8016949152542376e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3757/6000 [3:39:58<2:10:04,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [3:40:01<2:10:16,  3.49s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.9730377793312073, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3758/6000 [3:40:01<2:10:16,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [3:40:05<2:10:42,  3.50s/it]                                                       {'loss': 0.0242, 'grad_norm': 4.073340892791748, 'learning_rate': 3.798305084745763e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3759/6000 [3:40:05<2:10:42,  3.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [3:40:08<2:09:36,  3.47s/it]                                                       {'loss': 0.278, 'grad_norm': 16.778644561767578, 'learning_rate': 3.7966101694915257e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3760/6000 [3:40:08<2:09:36,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [3:40:11<2:08:58,  3.46s/it]                                                       {'loss': 0.0652, 'grad_norm': 6.65704870223999, 'learning_rate': 3.7949152542372886e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3761/6000 [3:40:11<2:08:58,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [3:40:15<2:09:57,  3.48s/it]                                                       {'loss': 0.0571, 'grad_norm': 7.854751110076904, 'learning_rate': 3.7932203389830514e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3762/6000 [3:40:15<2:09:57,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [3:40:18<2:09:00,  3.46s/it]                                                       {'loss': 0.0161, 'grad_norm': 5.071994304656982, 'learning_rate': 3.791525423728814e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3763/6000 [3:40:18<2:09:00,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [3:40:22<2:08:18,  3.44s/it]                                                       {'loss': 0.0253, 'grad_norm': 4.817449569702148, 'learning_rate': 3.7898305084745767e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3764/6000 [3:40:22<2:08:18,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [3:40:25<2:08:00,  3.44s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.4123353958129883, 'learning_rate': 3.7881355932203396e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3765/6000 [3:40:25<2:08:00,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [3:40:29<2:12:21,  3.55s/it]                                                       {'loss': 0.0582, 'grad_norm': 10.351387023925781, 'learning_rate': 3.7864406779661024e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3766/6000 [3:40:29<2:12:21,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [3:40:32<2:10:58,  3.52s/it]                                                       {'loss': 0.0161, 'grad_norm': 4.38991117477417, 'learning_rate': 3.7847457627118644e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3767/6000 [3:40:32<2:10:58,  3.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [3:40:36<2:09:55,  3.49s/it]                                                       {'loss': 0.0058, 'grad_norm': 1.703814148902893, 'learning_rate': 3.7830508474576273e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/6000 [3:40:36<2:09:55,  3.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [3:40:39<2:08:24,  3.45s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.958725094795227, 'learning_rate': 3.78135593220339e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3769/6000 [3:40:39<2:08:24,  3.45s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [3:40:43<2:07:58,  3.44s/it]                                                       {'loss': 0.1048, 'grad_norm': 13.712162971496582, 'learning_rate': 3.7796610169491525e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3770/6000 [3:40:43<2:07:58,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [3:40:46<2:09:55,  3.50s/it]                                                       {'loss': 0.1038, 'grad_norm': 13.640953063964844, 'learning_rate': 3.7779661016949154e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3771/6000 [3:40:46<2:09:55,  3.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [3:40:50<2:12:49,  3.58s/it]                                                       {'loss': 0.1446, 'grad_norm': 10.07806396484375, 'learning_rate': 3.7762711864406782e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3772/6000 [3:40:50<2:12:49,  3.58s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [3:40:53<2:11:19,  3.54s/it]                                                       {'loss': 0.0274, 'grad_norm': 2.0500175952911377, 'learning_rate': 3.7745762711864407e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3773/6000 [3:40:53<2:11:19,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [3:40:58<2:19:55,  3.77s/it]                                                       {'loss': 0.0302, 'grad_norm': 6.571265697479248, 'learning_rate': 3.7728813559322035e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3774/6000 [3:40:58<2:19:55,  3.77s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [3:41:01<2:16:50,  3.69s/it]                                                       {'loss': 0.0548, 'grad_norm': 12.692172050476074, 'learning_rate': 3.7711864406779664e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3775/6000 [3:41:01<2:16:50,  3.69s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [3:41:05<2:14:09,  3.62s/it]                                                       {'loss': 0.0619, 'grad_norm': 10.068867683410645, 'learning_rate': 3.7694915254237292e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3776/6000 [3:41:05<2:14:09,  3.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [3:41:08<2:11:08,  3.54s/it]                                                       {'loss': 0.1296, 'grad_norm': 16.58026695251465, 'learning_rate': 3.7677966101694917e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3777/6000 [3:41:08<2:11:08,  3.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [3:41:11<2:09:01,  3.48s/it]                                                       {'loss': 0.0651, 'grad_norm': 8.210040092468262, 'learning_rate': 3.7661016949152545e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3778/6000 [3:41:11<2:09:01,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [3:41:15<2:08:09,  3.46s/it]                                                       {'loss': 0.0314, 'grad_norm': 4.822741985321045, 'learning_rate': 3.7644067796610174e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3779/6000 [3:41:15<2:08:09,  3.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [3:41:18<2:06:18,  3.41s/it]                                                       {'loss': 0.0487, 'grad_norm': 7.676013469696045, 'learning_rate': 3.76271186440678e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3780/6000 [3:41:18<2:06:18,  3.41s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [3:41:22<2:07:10,  3.44s/it]                                                       {'loss': 0.022, 'grad_norm': 4.198617458343506, 'learning_rate': 3.7610169491525426e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3781/6000 [3:41:22<2:07:10,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [3:41:25<2:07:01,  3.44s/it]                                                       {'loss': 0.0069, 'grad_norm': 2.6292991638183594, 'learning_rate': 3.7593220338983055e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3782/6000 [3:41:25<2:07:01,  3.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [3:41:29<2:06:37,  3.43s/it]                                                       {'loss': 0.01, 'grad_norm': 2.185412645339966, 'learning_rate': 3.7576271186440683e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3783/6000 [3:41:29<2:06:37,  3.43s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [3:41:32<2:04:56,  3.38s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.020579848438501358, 'learning_rate': 3.755932203389831e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3784/6000 [3:41:32<2:04:56,  3.38s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [3:41:36<2:10:13,  3.53s/it]                                                       {'loss': 0.0256, 'grad_norm': 5.905601501464844, 'learning_rate': 3.7542372881355936e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3785/6000 [3:41:36<2:10:13,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [3:41:39<2:10:49,  3.55s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.6170454025268555, 'learning_rate': 3.7525423728813565e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3786/6000 [3:41:39<2:10:49,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [3:41:43<2:15:05,  3.66s/it]                                                       {'loss': 0.0397, 'grad_norm': 10.357131004333496, 'learning_rate': 3.7508474576271193e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3787/6000 [3:41:43<2:15:05,  3.66s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [3:41:47<2:13:12,  3.61s/it]                                                       {'loss': 0.1585, 'grad_norm': 12.484898567199707, 'learning_rate': 3.7491525423728813e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3788/6000 [3:41:47<2:13:12,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [3:41:50<2:13:00,  3.61s/it]                                                       {'loss': 0.0433, 'grad_norm': 6.846653938293457, 'learning_rate': 3.747457627118644e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3789/6000 [3:41:50<2:13:00,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [3:41:54<2:13:45,  3.63s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.03512668237090111, 'learning_rate': 3.745762711864407e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3790/6000 [3:41:54<2:13:45,  3.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [3:41:58<2:20:07,  3.81s/it]                                                       {'loss': 0.2052, 'grad_norm': 18.058137893676758, 'learning_rate': 3.7440677966101694e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3791/6000 [3:41:58<2:20:07,  3.81s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [3:42:02<2:20:26,  3.82s/it]                                                       {'loss': 0.095, 'grad_norm': 9.437612533569336, 'learning_rate': 3.7423728813559323e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3792/6000 [3:42:02<2:20:26,  3.82s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [3:42:05<2:15:29,  3.68s/it]                                                       {'loss': 0.0439, 'grad_norm': 6.407609462738037, 'learning_rate': 3.740677966101695e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3793/6000 [3:42:05<2:15:29,  3.68s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [3:42:09<2:12:05,  3.59s/it]                                                       {'loss': 0.0321, 'grad_norm': 6.602260112762451, 'learning_rate': 3.738983050847458e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3794/6000 [3:42:09<2:12:05,  3.59s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [3:42:12<2:09:40,  3.53s/it]                                                       {'loss': 0.1005, 'grad_norm': 8.333922386169434, 'learning_rate': 3.7372881355932204e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3795/6000 [3:42:12<2:09:40,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [3:42:16<2:12:47,  3.61s/it]                                                       {'loss': 0.0122, 'grad_norm': 3.8822593688964844, 'learning_rate': 3.7355932203389833e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3796/6000 [3:42:16<2:12:47,  3.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [3:42:19<2:10:18,  3.55s/it]                                                       {'loss': 0.011, 'grad_norm': 2.6547882556915283, 'learning_rate': 3.733898305084746e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/6000 [3:42:19<2:10:18,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [3:42:23<2:09:05,  3.52s/it]                                                       {'loss': 0.1053, 'grad_norm': 19.266647338867188, 'learning_rate': 3.732203389830509e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3798/6000 [3:42:23<2:09:05,  3.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [3:42:26<2:07:35,  3.48s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.8800024390220642, 'learning_rate': 3.7305084745762714e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3799/6000 [3:42:26<2:07:35,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [3:42:29<2:05:30,  3.42s/it]                                                       {'loss': 0.0854, 'grad_norm': 11.849717140197754, 'learning_rate': 3.7288135593220342e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3800/6000 [3:42:29<2:05:30,  3.42s/it][2025-11-07 02:33:39,468] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3800
[2025-11-07 02:33:39,482] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:33:40,214] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [3:42:35<2:32:23,  4.16s/it]                                                       {'loss': 0.0295, 'grad_norm': 4.895441055297852, 'learning_rate': 3.727118644067797e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3801/6000 [3:42:35<2:32:23,  4.16s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [3:42:39<2:24:06,  3.93s/it]                                                       {'loss': 0.11, 'grad_norm': 11.589693069458008, 'learning_rate': 3.72542372881356e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3802/6000 [3:42:39<2:24:06,  3.93s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [3:42:42<2:18:04,  3.77s/it]                                                       {'loss': 0.0131, 'grad_norm': 3.8077404499053955, 'learning_rate': 3.7237288135593224e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3803/6000 [3:42:42<2:18:04,  3.77s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [3:42:45<2:13:19,  3.64s/it]                                                       {'loss': 0.0744, 'grad_norm': 9.609691619873047, 'learning_rate': 3.7220338983050852e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3804/6000 [3:42:45<2:13:19,  3.64s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [3:42:49<2:09:52,  3.55s/it]                                                       {'loss': 0.016, 'grad_norm': 5.357716083526611, 'learning_rate': 3.720338983050848e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3805/6000 [3:42:49<2:09:52,  3.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [3:42:52<2:09:07,  3.53s/it]                                                       {'loss': 0.0655, 'grad_norm': 5.686370849609375, 'learning_rate': 3.7186440677966105e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3806/6000 [3:42:52<2:09:07,  3.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [3:42:56<2:07:01,  3.48s/it]                                                       {'loss': 0.1119, 'grad_norm': 10.244906425476074, 'learning_rate': 3.7169491525423733e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3807/6000 [3:42:56<2:07:01,  3.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [3:42:59<2:06:41,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.018358558416366577, 'learning_rate': 3.715254237288136e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3808/6000 [3:42:59<2:06:41,  3.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [3:43:03<2:12:58,  3.64s/it]                                                       {'loss': 0.0557, 'grad_norm': 15.403099060058594, 'learning_rate': 3.713559322033898e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3809/6000 [3:43:03<2:12:58,  3.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [3:43:07<2:09:41,  3.55s/it]                                                       {'loss': 0.142, 'grad_norm': 12.626113891601562, 'learning_rate': 3.711864406779661e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3810/6000 [3:43:07<2:09:41,  3.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [3:43:10<2:08:06,  3.51s/it]                                                       {'loss': 0.0829, 'grad_norm': 12.379652976989746, 'learning_rate': 3.710169491525424e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3811/6000 [3:43:10<2:08:06,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [3:43:14<2:08:51,  3.53s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.4707809388637543, 'learning_rate': 3.7084745762711867e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3812/6000 [3:43:14<2:08:51,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [3:43:17<2:11:17,  3.60s/it]                                                       {'loss': 0.0364, 'grad_norm': 7.088655471801758, 'learning_rate': 3.706779661016949e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3813/6000 [3:43:17<2:11:17,  3.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [3:43:21<2:10:09,  3.57s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.43619441986084, 'learning_rate': 3.705084745762712e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3814/6000 [3:43:21<2:10:09,  3.57s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [3:43:24<2:08:20,  3.52s/it]                                                       {'loss': 0.0158, 'grad_norm': 5.6357879638671875, 'learning_rate': 3.703389830508475e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3815/6000 [3:43:24<2:08:20,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [3:43:28<2:06:18,  3.47s/it]                                                       {'loss': 0.0999, 'grad_norm': 13.201773643493652, 'learning_rate': 3.7016949152542377e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3816/6000 [3:43:28<2:06:18,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [3:43:31<2:06:24,  3.47s/it]                                                       {'loss': 0.113, 'grad_norm': 16.30793571472168, 'learning_rate': 3.7e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3817/6000 [3:43:31<2:06:24,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [3:43:34<2:05:54,  3.46s/it]                                                       {'loss': 0.0314, 'grad_norm': 5.653916835784912, 'learning_rate': 3.698305084745763e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3818/6000 [3:43:34<2:05:54,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [3:43:38<2:05:40,  3.46s/it]                                                       {'loss': 0.0317, 'grad_norm': 6.803696155548096, 'learning_rate': 3.696610169491526e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3819/6000 [3:43:38<2:05:40,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [3:43:41<2:04:35,  3.43s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06458757817745209, 'learning_rate': 3.6949152542372883e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3820/6000 [3:43:41<2:04:35,  3.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [3:43:45<2:03:58,  3.41s/it]                                                       {'loss': 0.0434, 'grad_norm': 2.5824697017669678, 'learning_rate': 3.693220338983051e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3821/6000 [3:43:45<2:03:58,  3.41s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [3:43:48<2:04:44,  3.44s/it]                                                       {'loss': 0.1351, 'grad_norm': 7.861324787139893, 'learning_rate': 3.691525423728814e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3822/6000 [3:43:48<2:04:44,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [3:43:52<2:08:04,  3.53s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1407146155834198, 'learning_rate': 3.689830508474577e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3823/6000 [3:43:52<2:08:04,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [3:43:55<2:07:22,  3.51s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2519809305667877, 'learning_rate': 3.6881355932203393e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3824/6000 [3:43:55<2:07:22,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [3:43:59<2:08:16,  3.54s/it]                                                       {'loss': 0.0848, 'grad_norm': 8.987845420837402, 'learning_rate': 3.686440677966102e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3825/6000 [3:43:59<2:08:16,  3.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [3:44:02<2:06:33,  3.49s/it]                                                       {'loss': 0.109, 'grad_norm': 12.53434944152832, 'learning_rate': 3.684745762711865e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3826/6000 [3:44:02<2:06:33,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [3:44:06<2:05:58,  3.48s/it]                                                       {'loss': 0.0941, 'grad_norm': 10.6019926071167, 'learning_rate': 3.683050847457628e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3827/6000 [3:44:06<2:05:58,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [3:44:09<2:05:05,  3.46s/it]                                                       {'loss': 0.0271, 'grad_norm': 4.786279678344727, 'learning_rate': 3.6813559322033902e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3828/6000 [3:44:09<2:05:05,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [3:44:13<2:04:42,  3.45s/it]                                                       {'loss': 0.1149, 'grad_norm': 9.737480163574219, 'learning_rate': 3.679661016949153e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3829/6000 [3:44:13<2:04:42,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [3:44:16<2:05:13,  3.46s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.6605896353721619, 'learning_rate': 3.6779661016949155e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3830/6000 [3:44:16<2:05:13,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [3:44:20<2:05:45,  3.48s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.2055388242006302, 'learning_rate': 3.676271186440678e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3831/6000 [3:44:20<2:05:45,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [3:44:23<2:06:12,  3.49s/it]                                                       {'loss': 0.1554, 'grad_norm': 25.926057815551758, 'learning_rate': 3.6745762711864408e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3832/6000 [3:44:23<2:06:12,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [3:44:27<2:09:38,  3.59s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.001189947128296, 'learning_rate': 3.6728813559322036e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3833/6000 [3:44:27<2:09:38,  3.59s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [3:44:30<2:07:09,  3.52s/it]                                                       {'loss': 0.1312, 'grad_norm': 14.014192581176758, 'learning_rate': 3.671186440677966e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3834/6000 [3:44:30<2:07:09,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [3:44:34<2:10:23,  3.61s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8343400955200195, 'learning_rate': 3.669491525423729e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3835/6000 [3:44:34<2:10:23,  3.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [3:44:38<2:07:44,  3.54s/it]                                                       {'loss': 0.0445, 'grad_norm': 7.76283597946167, 'learning_rate': 3.6677966101694918e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3836/6000 [3:44:38<2:07:44,  3.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [3:44:41<2:05:37,  3.48s/it]                                                       {'loss': 0.2085, 'grad_norm': 13.977056503295898, 'learning_rate': 3.6661016949152546e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3837/6000 [3:44:41<2:05:37,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [3:44:44<2:03:56,  3.44s/it]                                                       {'loss': 0.0306, 'grad_norm': 8.612491607666016, 'learning_rate': 3.664406779661017e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3838/6000 [3:44:44<2:03:56,  3.44s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [3:44:48<2:07:12,  3.53s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.237693428993225, 'learning_rate': 3.66271186440678e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3839/6000 [3:44:48<2:07:12,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [3:44:51<2:05:01,  3.47s/it]                                                       {'loss': 0.0944, 'grad_norm': 9.117634773254395, 'learning_rate': 3.6610169491525427e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3840/6000 [3:44:51<2:05:01,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [3:44:55<2:10:53,  3.64s/it]                                                       {'loss': 0.2013, 'grad_norm': 19.138460159301758, 'learning_rate': 3.6593220338983056e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3841/6000 [3:44:55<2:10:53,  3.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [3:44:59<2:10:57,  3.64s/it]                                                       {'loss': 0.1716, 'grad_norm': 17.23184585571289, 'learning_rate': 3.657627118644068e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3842/6000 [3:44:59<2:10:57,  3.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [3:45:02<2:07:45,  3.55s/it]                                                       {'loss': 0.0907, 'grad_norm': 9.947093963623047, 'learning_rate': 3.655932203389831e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3843/6000 [3:45:02<2:07:45,  3.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [3:45:06<2:08:10,  3.57s/it]                                                       {'loss': 0.2378, 'grad_norm': 14.553027153015137, 'learning_rate': 3.6542372881355937e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3844/6000 [3:45:06<2:08:10,  3.57s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [3:45:10<2:08:40,  3.58s/it]                                                       {'loss': 0.0155, 'grad_norm': 3.697859287261963, 'learning_rate': 3.6525423728813566e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3845/6000 [3:45:10<2:08:40,  3.58s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [3:45:13<2:12:08,  3.68s/it]                                                       {'loss': 0.1868, 'grad_norm': 17.40060806274414, 'learning_rate': 3.650847457627119e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3846/6000 [3:45:13<2:12:08,  3.68s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [3:45:17<2:09:53,  3.62s/it]                                                       {'loss': 0.0678, 'grad_norm': 9.003263473510742, 'learning_rate': 3.649152542372882e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3847/6000 [3:45:17<2:09:53,  3.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [3:45:20<2:06:35,  3.53s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.2533258199691772, 'learning_rate': 3.6474576271186447e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3848/6000 [3:45:20<2:06:35,  3.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [3:45:24<2:04:17,  3.47s/it]                                                       {'loss': 0.0027, 'grad_norm': 1.1259043216705322, 'learning_rate': 3.6457627118644075e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/6000 [3:45:24<2:04:17,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [3:45:27<2:07:43,  3.56s/it]                                                       {'loss': 0.096, 'grad_norm': 8.3427152633667, 'learning_rate': 3.6440677966101695e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3850/6000 [3:45:27<2:07:43,  3.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [3:45:31<2:06:55,  3.54s/it]                                                       {'loss': 0.0209, 'grad_norm': 5.133110046386719, 'learning_rate': 3.6423728813559324e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3851/6000 [3:45:31<2:06:55,  3.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [3:45:34<2:05:28,  3.50s/it]                                                       {'loss': 0.0203, 'grad_norm': 3.476658582687378, 'learning_rate': 3.640677966101695e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3852/6000 [3:45:34<2:05:28,  3.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [3:45:38<2:04:39,  3.48s/it]                                                       {'loss': 0.0058, 'grad_norm': 2.091505289077759, 'learning_rate': 3.6389830508474577e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3853/6000 [3:45:38<2:04:39,  3.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [3:45:41<2:04:01,  3.47s/it]                                                       {'loss': 0.0141, 'grad_norm': 6.619927883148193, 'learning_rate': 3.6372881355932205e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3854/6000 [3:45:41<2:04:01,  3.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [3:45:45<2:05:52,  3.52s/it]                                                       {'loss': 0.0073, 'grad_norm': 2.385140895843506, 'learning_rate': 3.6355932203389834e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3855/6000 [3:45:45<2:05:52,  3.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [3:45:48<2:05:18,  3.51s/it]                                                       {'loss': 0.2416, 'grad_norm': 18.913209915161133, 'learning_rate': 3.633898305084746e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3856/6000 [3:45:48<2:05:18,  3.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [3:45:52<2:03:21,  3.45s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.11806053668260574, 'learning_rate': 3.6322033898305086e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3857/6000 [3:45:52<2:03:21,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [3:45:55<2:02:04,  3.42s/it]                                                       {'loss': 0.0742, 'grad_norm': 6.8564605712890625, 'learning_rate': 3.6305084745762715e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3858/6000 [3:45:55<2:02:04,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [3:45:58<2:02:11,  3.42s/it]                                                       {'loss': 0.0457, 'grad_norm': 3.782923936843872, 'learning_rate': 3.6288135593220343e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3859/6000 [3:45:58<2:02:11,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [3:46:02<2:00:59,  3.39s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3466204106807709, 'learning_rate': 3.6271186440677968e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3860/6000 [3:46:02<2:00:59,  3.39s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [3:46:05<2:01:57,  3.42s/it]                                                       {'loss': 0.2424, 'grad_norm': 13.97508430480957, 'learning_rate': 3.6254237288135596e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3861/6000 [3:46:05<2:01:57,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [3:46:09<2:01:59,  3.42s/it]                                                       {'loss': 0.2278, 'grad_norm': 15.262896537780762, 'learning_rate': 3.6237288135593225e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3862/6000 [3:46:09<2:01:59,  3.42s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [3:46:12<2:03:20,  3.46s/it]                                                       {'loss': 0.0691, 'grad_norm': 11.501365661621094, 'learning_rate': 3.6220338983050853e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3863/6000 [3:46:12<2:03:20,  3.46s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [3:46:16<2:04:21,  3.49s/it]                                                       {'loss': 0.1184, 'grad_norm': 12.192437171936035, 'learning_rate': 3.6203389830508478e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3864/6000 [3:46:16<2:04:21,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [3:46:19<2:02:52,  3.45s/it]                                                       {'loss': 0.0108, 'grad_norm': 2.7709808349609375, 'learning_rate': 3.6186440677966106e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3865/6000 [3:46:19<2:02:52,  3.45s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [3:46:23<2:04:06,  3.49s/it]                                                       {'loss': 0.097, 'grad_norm': 10.04520034790039, 'learning_rate': 3.6169491525423735e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3866/6000 [3:46:23<2:04:06,  3.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [3:46:28<2:21:20,  3.98s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.335614562034607, 'learning_rate': 3.615254237288136e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3867/6000 [3:46:28<2:21:20,  3.98s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [3:46:31<2:16:05,  3.83s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.92612886428833, 'learning_rate': 3.6135593220338987e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3868/6000 [3:46:31<2:16:05,  3.83s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [3:46:35<2:12:22,  3.73s/it]                                                       {'loss': 0.0257, 'grad_norm': 5.12730598449707, 'learning_rate': 3.6118644067796616e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3869/6000 [3:46:35<2:12:22,  3.73s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [3:46:38<2:09:07,  3.64s/it]                                                       {'loss': 0.0169, 'grad_norm': 2.2665579319000244, 'learning_rate': 3.6101694915254244e-06, 'epoch': 0.65}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3870/6000 [3:46:38<2:09:07,  3.64s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [3:46:42<2:06:49,  3.57s/it]                                                       {'loss': 0.0125, 'grad_norm': 3.067525863647461, 'learning_rate': 3.6084745762711864e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3871/6000 [3:46:42<2:06:49,  3.57s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [3:46:45<2:04:37,  3.51s/it]                                                       {'loss': 0.0296, 'grad_norm': 7.974249362945557, 'learning_rate': 3.6067796610169493e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3872/6000 [3:46:45<2:04:37,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [3:46:48<2:03:59,  3.50s/it]                                                       {'loss': 0.0458, 'grad_norm': 6.115988731384277, 'learning_rate': 3.605084745762712e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3873/6000 [3:46:48<2:03:59,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [3:46:52<2:01:53,  3.44s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.4251350164413452, 'learning_rate': 3.6033898305084746e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3874/6000 [3:46:52<2:01:53,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [3:46:55<2:01:30,  3.43s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.6354634165763855, 'learning_rate': 3.6016949152542374e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3875/6000 [3:46:55<2:01:30,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [3:46:59<2:01:00,  3.42s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.8094196319580078, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3876/6000 [3:46:59<2:01:00,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [3:47:02<2:00:21,  3.40s/it]                                                       {'loss': 0.1019, 'grad_norm': 13.238324165344238, 'learning_rate': 3.598305084745763e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3877/6000 [3:47:02<2:00:21,  3.40s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [3:47:06<2:05:18,  3.54s/it]                                                       {'loss': 0.0224, 'grad_norm': 6.561365604400635, 'learning_rate': 3.5966101694915255e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3878/6000 [3:47:06<2:05:18,  3.54s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [3:47:09<2:03:51,  3.50s/it]                                                       {'loss': 0.0201, 'grad_norm': 2.8377814292907715, 'learning_rate': 3.5949152542372884e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3879/6000 [3:47:09<2:03:51,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [3:47:13<2:02:26,  3.47s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07098880410194397, 'learning_rate': 3.5932203389830512e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3880/6000 [3:47:13<2:02:26,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [3:47:16<2:03:39,  3.50s/it]                                                       {'loss': 0.2473, 'grad_norm': 15.095553398132324, 'learning_rate': 3.5915254237288137e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3881/6000 [3:47:16<2:03:39,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [3:47:19<2:01:13,  3.43s/it]                                                       {'loss': 0.0215, 'grad_norm': 6.449362277984619, 'learning_rate': 3.5898305084745765e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3882/6000 [3:47:19<2:01:13,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [3:47:23<2:03:28,  3.50s/it]                                                       {'loss': 0.1498, 'grad_norm': 12.015724182128906, 'learning_rate': 3.5881355932203394e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3883/6000 [3:47:23<2:03:28,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [3:47:26<2:02:26,  3.47s/it]                                                       {'loss': 0.0191, 'grad_norm': 4.044899940490723, 'learning_rate': 3.5864406779661022e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3884/6000 [3:47:26<2:02:26,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [3:47:30<2:02:56,  3.49s/it]                                                       {'loss': 0.0166, 'grad_norm': 2.161261558532715, 'learning_rate': 3.5847457627118646e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3885/6000 [3:47:30<2:02:56,  3.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [3:47:33<2:01:10,  3.44s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1641479730606079, 'learning_rate': 3.5830508474576275e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3886/6000 [3:47:33<2:01:10,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [3:47:37<2:03:28,  3.51s/it]                                                       {'loss': 0.1775, 'grad_norm': 18.35077667236328, 'learning_rate': 3.5813559322033903e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3887/6000 [3:47:37<2:03:28,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [3:47:41<2:08:07,  3.64s/it]                                                       {'loss': 0.1478, 'grad_norm': 14.378349304199219, 'learning_rate': 3.579661016949153e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3888/6000 [3:47:41<2:08:07,  3.64s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [3:47:44<2:05:26,  3.57s/it]                                                       {'loss': 0.1047, 'grad_norm': 10.717300415039062, 'learning_rate': 3.5779661016949156e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3889/6000 [3:47:44<2:05:26,  3.57s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [3:47:48<2:04:20,  3.54s/it]                                                       {'loss': 0.0086, 'grad_norm': 2.9285004138946533, 'learning_rate': 3.5762711864406785e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3890/6000 [3:47:48<2:04:20,  3.54s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [3:47:51<2:03:29,  3.51s/it]                                                       {'loss': 0.0215, 'grad_norm': 5.069635391235352, 'learning_rate': 3.5745762711864413e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3891/6000 [3:47:51<2:03:29,  3.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [3:47:55<2:02:14,  3.48s/it]                                                       {'loss': 0.1028, 'grad_norm': 12.950335502624512, 'learning_rate': 3.5728813559322033e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3892/6000 [3:47:55<2:02:14,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [3:47:58<2:05:52,  3.58s/it]                                                       {'loss': 0.0088, 'grad_norm': 1.3898626565933228, 'learning_rate': 3.571186440677966e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3893/6000 [3:47:58<2:05:52,  3.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [3:48:02<2:04:11,  3.54s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.9577823281288147, 'learning_rate': 3.569491525423729e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3894/6000 [3:48:02<2:04:11,  3.54s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [3:48:05<2:02:10,  3.48s/it]                                                       {'loss': 0.0072, 'grad_norm': 2.2440671920776367, 'learning_rate': 3.5677966101694914e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3895/6000 [3:48:05<2:02:10,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [3:48:09<2:01:39,  3.47s/it]                                                       {'loss': 0.012, 'grad_norm': 3.340043306350708, 'learning_rate': 3.5661016949152543e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3896/6000 [3:48:09<2:01:39,  3.47s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [3:48:12<1:59:43,  3.42s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.75570148229599, 'learning_rate': 3.564406779661017e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3897/6000 [3:48:12<1:59:43,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [3:48:15<1:59:33,  3.41s/it]                                                       {'loss': 0.0203, 'grad_norm': 4.170255661010742, 'learning_rate': 3.56271186440678e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3898/6000 [3:48:15<1:59:33,  3.41s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [3:48:19<1:58:46,  3.39s/it]                                                       {'loss': 0.1864, 'grad_norm': 14.30666732788086, 'learning_rate': 3.5610169491525424e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3899/6000 [3:48:19<1:58:46,  3.39s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [3:48:22<1:59:42,  3.42s/it]                                                       {'loss': 0.0493, 'grad_norm': 6.357229232788086, 'learning_rate': 3.5593220338983053e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3900/6000 [3:48:22<1:59:42,  3.42s/it][2025-11-07 02:39:32,211] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3900
[2025-11-07 02:39:32,224] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:39:32,916] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-3900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [3:48:28<2:24:50,  4.14s/it]                                                       {'loss': 0.3727, 'grad_norm': 19.227523803710938, 'learning_rate': 3.557627118644068e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3901/6000 [3:48:28<2:24:50,  4.14s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [3:48:31<2:16:57,  3.92s/it]                                                       {'loss': 0.0268, 'grad_norm': 8.031599044799805, 'learning_rate': 3.555932203389831e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/6000 [3:48:31<2:16:57,  3.92s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [3:48:35<2:11:44,  3.77s/it]                                                       {'loss': 0.2183, 'grad_norm': 14.75228214263916, 'learning_rate': 3.5542372881355934e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3903/6000 [3:48:35<2:11:44,  3.77s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [3:48:38<2:08:16,  3.67s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.32956111431121826, 'learning_rate': 3.5525423728813563e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3904/6000 [3:48:38<2:08:16,  3.67s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [3:48:42<2:04:19,  3.56s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5637769103050232, 'learning_rate': 3.550847457627119e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3905/6000 [3:48:42<2:04:19,  3.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [3:48:45<2:06:22,  3.62s/it]                                                       {'loss': 0.0508, 'grad_norm': 7.557313442230225, 'learning_rate': 3.549152542372882e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3906/6000 [3:48:45<2:06:22,  3.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [3:48:49<2:04:42,  3.58s/it]                                                       {'loss': 0.0724, 'grad_norm': 10.382560729980469, 'learning_rate': 3.5474576271186444e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3907/6000 [3:48:49<2:04:42,  3.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [3:48:52<2:02:00,  3.50s/it]                                                       {'loss': 0.1233, 'grad_norm': 12.489344596862793, 'learning_rate': 3.5457627118644072e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3908/6000 [3:48:52<2:02:00,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [3:48:56<2:00:38,  3.46s/it]                                                       {'loss': 0.0992, 'grad_norm': 10.388788223266602, 'learning_rate': 3.54406779661017e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3909/6000 [3:48:56<2:00:38,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [3:48:59<1:59:00,  3.42s/it]                                                       {'loss': 0.0514, 'grad_norm': 9.27344036102295, 'learning_rate': 3.5423728813559325e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3910/6000 [3:48:59<1:59:00,  3.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [3:49:02<1:58:27,  3.40s/it]                                                       {'loss': 0.0496, 'grad_norm': 4.426455020904541, 'learning_rate': 3.5406779661016954e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3911/6000 [3:49:02<1:58:27,  3.40s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [3:49:06<1:59:57,  3.45s/it]                                                       {'loss': 0.1114, 'grad_norm': 14.135396957397461, 'learning_rate': 3.538983050847458e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3912/6000 [3:49:06<1:59:57,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [3:49:09<1:59:13,  3.43s/it]                                                       {'loss': 0.0444, 'grad_norm': 7.812184810638428, 'learning_rate': 3.53728813559322e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3913/6000 [3:49:09<1:59:13,  3.43s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [3:49:12<1:57:28,  3.38s/it]                                                       {'loss': 0.0453, 'grad_norm': 7.633610248565674, 'learning_rate': 3.535593220338983e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3914/6000 [3:49:12<1:57:28,  3.38s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [3:49:16<2:02:10,  3.52s/it]                                                       {'loss': 0.0963, 'grad_norm': 12.01340103149414, 'learning_rate': 3.533898305084746e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3915/6000 [3:49:16<2:02:10,  3.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [3:49:20<2:00:59,  3.48s/it]                                                       {'loss': 0.0105, 'grad_norm': 3.63883113861084, 'learning_rate': 3.5322033898305088e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3916/6000 [3:49:20<2:00:59,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [3:49:23<2:00:06,  3.46s/it]                                                       {'loss': 0.0035, 'grad_norm': 1.0130819082260132, 'learning_rate': 3.530508474576271e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3917/6000 [3:49:23<2:00:06,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [3:49:27<2:00:04,  3.46s/it]                                                       {'loss': 0.0139, 'grad_norm': 4.203006267547607, 'learning_rate': 3.528813559322034e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3918/6000 [3:49:27<2:00:04,  3.46s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [3:49:30<1:59:16,  3.44s/it]                                                       {'loss': 0.1533, 'grad_norm': 13.048521995544434, 'learning_rate': 3.527118644067797e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3919/6000 [3:49:30<1:59:16,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [3:49:33<1:59:18,  3.44s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.13528446853160858, 'learning_rate': 3.5254237288135597e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3920/6000 [3:49:33<1:59:18,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [3:49:37<1:59:14,  3.44s/it]                                                       {'loss': 0.0572, 'grad_norm': 5.9415507316589355, 'learning_rate': 3.523728813559322e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3921/6000 [3:49:37<1:59:14,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [3:49:40<1:59:29,  3.45s/it]                                                       {'loss': 0.0564, 'grad_norm': 8.071590423583984, 'learning_rate': 3.522033898305085e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3922/6000 [3:49:40<1:59:29,  3.45s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [3:49:44<2:00:27,  3.48s/it]                                                       {'loss': 0.0172, 'grad_norm': 4.027615070343018, 'learning_rate': 3.520338983050848e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3923/6000 [3:49:44<2:00:27,  3.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [3:49:47<1:59:08,  3.44s/it]                                                       {'loss': 0.0322, 'grad_norm': 5.017792701721191, 'learning_rate': 3.5186440677966103e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3924/6000 [3:49:47<1:59:08,  3.44s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [3:49:51<2:02:37,  3.55s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.4016400873661041, 'learning_rate': 3.516949152542373e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3925/6000 [3:49:51<2:02:37,  3.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [3:49:55<2:04:39,  3.61s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.021340854465961456, 'learning_rate': 3.515254237288136e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3926/6000 [3:49:55<2:04:39,  3.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [3:49:58<2:02:32,  3.55s/it]                                                       {'loss': 0.0732, 'grad_norm': 8.590167045593262, 'learning_rate': 3.513559322033899e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3927/6000 [3:49:58<2:02:32,  3.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [3:50:02<2:00:53,  3.50s/it]                                                       {'loss': 0.0034, 'grad_norm': 1.2293211221694946, 'learning_rate': 3.5118644067796613e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3928/6000 [3:50:02<2:00:53,  3.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [3:50:05<2:02:51,  3.56s/it]                                                       {'loss': 0.0772, 'grad_norm': 9.33867073059082, 'learning_rate': 3.510169491525424e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3929/6000 [3:50:05<2:02:51,  3.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [3:50:09<2:00:35,  3.50s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.0493425130844116, 'learning_rate': 3.508474576271187e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3930/6000 [3:50:09<2:00:35,  3.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [3:50:12<1:59:57,  3.48s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.8530327677726746, 'learning_rate': 3.50677966101695e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3931/6000 [3:50:12<1:59:57,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [3:50:16<2:03:48,  3.59s/it]                                                       {'loss': 0.0956, 'grad_norm': 9.525869369506836, 'learning_rate': 3.5050847457627122e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3932/6000 [3:50:16<2:03:48,  3.59s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [3:50:19<2:02:26,  3.55s/it]                                                       {'loss': 0.0069, 'grad_norm': 1.134757399559021, 'learning_rate': 3.5033898305084747e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3933/6000 [3:50:20<2:02:26,  3.55s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [3:50:23<2:03:34,  3.59s/it]                                                       {'loss': 0.1499, 'grad_norm': 16.123394012451172, 'learning_rate': 3.5016949152542375e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3934/6000 [3:50:23<2:03:34,  3.59s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [3:50:26<2:01:56,  3.54s/it]                                                       {'loss': 0.0322, 'grad_norm': 6.012810230255127, 'learning_rate': 3.5e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3935/6000 [3:50:26<2:01:56,  3.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [3:50:30<2:00:18,  3.50s/it]                                                       {'loss': 0.0097, 'grad_norm': 2.6637179851531982, 'learning_rate': 3.498305084745763e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3936/6000 [3:50:30<2:00:18,  3.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [3:50:33<2:00:11,  3.50s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.8800020217895508, 'learning_rate': 3.4966101694915256e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3937/6000 [3:50:33<2:00:11,  3.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [3:50:37<1:59:09,  3.47s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.027648886665701866, 'learning_rate': 3.494915254237288e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3938/6000 [3:50:37<1:59:09,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [3:50:40<1:58:44,  3.46s/it]                                                       {'loss': 0.0494, 'grad_norm': 11.378766059875488, 'learning_rate': 3.493220338983051e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3939/6000 [3:50:40<1:58:44,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [3:50:43<1:57:26,  3.42s/it]                                                       {'loss': 0.0719, 'grad_norm': 9.887908935546875, 'learning_rate': 3.4915254237288138e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3940/6000 [3:50:43<1:57:26,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [3:50:47<1:57:19,  3.42s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.49850228428840637, 'learning_rate': 3.4898305084745766e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3941/6000 [3:50:47<1:57:19,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [3:50:50<1:57:10,  3.42s/it]                                                       {'loss': 0.2321, 'grad_norm': 17.147119522094727, 'learning_rate': 3.488135593220339e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3942/6000 [3:50:50<1:57:10,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [3:50:54<1:58:06,  3.44s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.01095280796289444, 'learning_rate': 3.486440677966102e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3943/6000 [3:50:54<1:58:06,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [3:50:57<1:57:16,  3.42s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.1582863330841064, 'learning_rate': 3.4847457627118648e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3944/6000 [3:50:57<1:57:16,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [3:51:00<1:56:00,  3.39s/it]                                                       {'loss': 0.1422, 'grad_norm': 15.294666290283203, 'learning_rate': 3.4830508474576276e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3945/6000 [3:51:00<1:56:00,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [3:51:04<1:56:19,  3.40s/it]                                                       {'loss': 0.1108, 'grad_norm': 12.86182689666748, 'learning_rate': 3.48135593220339e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3946/6000 [3:51:04<1:56:19,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [3:51:07<1:55:26,  3.37s/it]                                                       {'loss': 0.0279, 'grad_norm': 7.568127632141113, 'learning_rate': 3.479661016949153e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3947/6000 [3:51:07<1:55:26,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [3:51:11<1:54:31,  3.35s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.3138391971588135, 'learning_rate': 3.4779661016949157e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3948/6000 [3:51:11<1:54:31,  3.35s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [3:51:14<1:56:00,  3.39s/it]                                                       {'loss': 0.0711, 'grad_norm': 8.669580459594727, 'learning_rate': 3.4762711864406786e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3949/6000 [3:51:14<1:56:00,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [3:51:17<1:55:59,  3.39s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.1726393699645996, 'learning_rate': 3.474576271186441e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3950/6000 [3:51:17<1:55:59,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [3:51:21<1:56:03,  3.40s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.3247607946395874, 'learning_rate': 3.472881355932204e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3951/6000 [3:51:21<1:56:03,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [3:51:24<1:55:20,  3.38s/it]                                                       {'loss': 0.0597, 'grad_norm': 11.445572853088379, 'learning_rate': 3.4711864406779667e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3952/6000 [3:51:24<1:55:20,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [3:51:28<1:55:47,  3.39s/it]                                                       {'loss': 0.0288, 'grad_norm': 5.0913987159729, 'learning_rate': 3.4694915254237296e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3953/6000 [3:51:28<1:55:47,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [3:51:31<1:56:03,  3.40s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.3536032438278198, 'learning_rate': 3.4677966101694916e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3954/6000 [3:51:31<1:56:03,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [3:51:34<1:55:27,  3.39s/it]                                                       {'loss': 0.0868, 'grad_norm': 11.39603042602539, 'learning_rate': 3.4661016949152544e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3955/6000 [3:51:34<1:55:27,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [3:51:38<1:58:14,  3.47s/it]                                                       {'loss': 0.0112, 'grad_norm': 1.968248963356018, 'learning_rate': 3.464406779661017e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3956/6000 [3:51:38<1:58:14,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [3:51:42<1:59:38,  3.51s/it]                                                       {'loss': 0.0083, 'grad_norm': 1.973185420036316, 'learning_rate': 3.4627118644067797e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3957/6000 [3:51:42<1:59:38,  3.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [3:51:45<1:58:46,  3.49s/it]                                                       {'loss': 0.0389, 'grad_norm': 2.7530901432037354, 'learning_rate': 3.4610169491525425e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3958/6000 [3:51:45<1:58:46,  3.49s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [3:51:48<1:57:36,  3.46s/it]                                                       {'loss': 0.0222, 'grad_norm': 6.384729385375977, 'learning_rate': 3.4593220338983054e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3959/6000 [3:51:48<1:57:36,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [3:51:52<1:57:23,  3.45s/it]                                                       {'loss': 0.0038, 'grad_norm': 1.1448864936828613, 'learning_rate': 3.457627118644068e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3960/6000 [3:51:52<1:57:23,  3.45s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [3:51:55<1:56:05,  3.42s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.4238450527191162, 'learning_rate': 3.4559322033898307e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3961/6000 [3:51:55<1:56:05,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [3:51:59<1:56:00,  3.42s/it]                                                       {'loss': 0.1666, 'grad_norm': 17.853363037109375, 'learning_rate': 3.4542372881355935e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3962/6000 [3:51:59<1:56:00,  3.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [3:52:02<1:55:07,  3.39s/it]                                                       {'loss': 0.1158, 'grad_norm': 11.52497386932373, 'learning_rate': 3.4525423728813564e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3963/6000 [3:52:02<1:55:07,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [3:52:05<1:54:35,  3.38s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.2519794702529907, 'learning_rate': 3.450847457627119e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3964/6000 [3:52:05<1:54:35,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [3:52:09<1:55:01,  3.39s/it]                                                       {'loss': 0.1, 'grad_norm': 12.908975601196289, 'learning_rate': 3.4491525423728816e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3965/6000 [3:52:09<1:55:01,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [3:52:12<1:54:44,  3.38s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.40491995215415955, 'learning_rate': 3.4474576271186445e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3966/6000 [3:52:12<1:54:44,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [3:52:15<1:53:37,  3.35s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.08944016695022583, 'learning_rate': 3.4457627118644073e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3967/6000 [3:52:15<1:53:37,  3.35s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [3:52:19<1:57:10,  3.46s/it]                                                       {'loss': 0.0723, 'grad_norm': 7.4743428230285645, 'learning_rate': 3.4440677966101698e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3968/6000 [3:52:19<1:57:10,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [3:52:22<1:56:16,  3.44s/it]                                                       {'loss': 0.4534, 'grad_norm': 15.484896659851074, 'learning_rate': 3.4423728813559326e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3969/6000 [3:52:22<1:56:16,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [3:52:26<1:57:28,  3.47s/it]                                                       {'loss': 0.4601, 'grad_norm': 15.891045570373535, 'learning_rate': 3.4406779661016955e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3970/6000 [3:52:26<1:57:28,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [3:52:29<1:57:20,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.09034276008605957, 'learning_rate': 3.438983050847458e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3971/6000 [3:52:29<1:57:20,  3.47s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [3:52:33<1:56:17,  3.44s/it]                                                       {'loss': 0.0359, 'grad_norm': 3.7260499000549316, 'learning_rate': 3.4372881355932207e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3972/6000 [3:52:33<1:56:17,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [3:52:36<1:58:06,  3.50s/it]                                                       {'loss': 0.0676, 'grad_norm': 9.964635848999023, 'learning_rate': 3.4355932203389836e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3973/6000 [3:52:36<1:58:06,  3.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [3:52:40<1:55:53,  3.43s/it]                                                       {'loss': 0.0207, 'grad_norm': 3.4895076751708984, 'learning_rate': 3.4338983050847464e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3974/6000 [3:52:40<1:55:53,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [3:52:43<1:56:38,  3.46s/it]                                                       {'loss': 0.0904, 'grad_norm': 11.578802108764648, 'learning_rate': 3.4322033898305084e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/6000 [3:52:43<1:56:38,  3.46s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [3:52:47<1:55:43,  3.43s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.20883865654468536, 'learning_rate': 3.4305084745762713e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3976/6000 [3:52:47<1:55:43,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [3:52:50<1:55:45,  3.43s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.13630513846874237, 'learning_rate': 3.428813559322034e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3977/6000 [3:52:50<1:55:45,  3.43s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [3:52:53<1:54:30,  3.40s/it]                                                       {'loss': 0.001, 'grad_norm': 0.22649483382701874, 'learning_rate': 3.4271186440677966e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3978/6000 [3:52:53<1:54:30,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [3:52:57<1:53:46,  3.38s/it]                                                       {'loss': 0.0646, 'grad_norm': 8.281259536743164, 'learning_rate': 3.4254237288135594e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3979/6000 [3:52:57<1:53:46,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [3:53:00<1:53:29,  3.37s/it]                                                       {'loss': 0.1124, 'grad_norm': 10.634093284606934, 'learning_rate': 3.4237288135593223e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3980/6000 [3:53:00<1:53:29,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [3:53:03<1:53:26,  3.37s/it]                                                       {'loss': 0.0268, 'grad_norm': 4.229300022125244, 'learning_rate': 3.422033898305085e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3981/6000 [3:53:03<1:53:26,  3.37s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [3:53:07<1:52:53,  3.36s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.7022509574890137, 'learning_rate': 3.4203389830508476e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3982/6000 [3:53:07<1:52:53,  3.36s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [3:53:10<1:54:04,  3.39s/it]                                                       {'loss': 0.0169, 'grad_norm': 4.212023735046387, 'learning_rate': 3.4186440677966104e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3983/6000 [3:53:10<1:54:04,  3.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [3:53:14<1:53:43,  3.38s/it]                                                       {'loss': 0.0851, 'grad_norm': 7.224335670471191, 'learning_rate': 3.4169491525423733e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3984/6000 [3:53:14<1:53:43,  3.38s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [3:53:17<1:54:14,  3.40s/it]                                                       {'loss': 0.0037, 'grad_norm': 1.1835612058639526, 'learning_rate': 3.4152542372881357e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3985/6000 [3:53:17<1:54:14,  3.40s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [3:53:21<1:54:37,  3.41s/it]                                                       {'loss': 0.0422, 'grad_norm': 2.4264049530029297, 'learning_rate': 3.4135593220338985e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3986/6000 [3:53:21<1:54:37,  3.41s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [3:53:24<1:56:37,  3.48s/it]                                                       {'loss': 0.0317, 'grad_norm': 5.216313362121582, 'learning_rate': 3.4118644067796614e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3987/6000 [3:53:24<1:56:37,  3.48s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [3:53:27<1:55:19,  3.44s/it]                                                       {'loss': 0.1608, 'grad_norm': 8.943153381347656, 'learning_rate': 3.4101694915254242e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3988/6000 [3:53:28<1:55:19,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [3:53:31<1:55:26,  3.44s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.48851922154426575, 'learning_rate': 3.4084745762711867e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3989/6000 [3:53:31<1:55:26,  3.44s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [3:53:34<1:55:08,  3.44s/it]                                                       {'loss': 0.0164, 'grad_norm': 2.1516716480255127, 'learning_rate': 3.4067796610169495e-06, 'epoch': 0.67}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3990/6000 [3:53:34<1:55:08,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [3:53:38<1:54:13,  3.41s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.17731142044067383, 'learning_rate': 3.4050847457627124e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3991/6000 [3:53:38<1:54:13,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [3:53:41<1:54:31,  3.42s/it]                                                       {'loss': 0.0147, 'grad_norm': 3.409280300140381, 'learning_rate': 3.403389830508475e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3992/6000 [3:53:41<1:54:31,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [3:53:45<1:54:43,  3.43s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.6735682487487793, 'learning_rate': 3.4016949152542376e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3993/6000 [3:53:45<1:54:43,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [3:53:49<2:03:31,  3.69s/it]                                                       {'loss': 0.0104, 'grad_norm': 3.8557040691375732, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3994/6000 [3:53:49<2:03:31,  3.69s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [3:53:52<2:01:42,  3.64s/it]                                                       {'loss': 0.044, 'grad_norm': 7.517840385437012, 'learning_rate': 3.3983050847457633e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3995/6000 [3:53:52<2:01:42,  3.64s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [3:53:56<1:58:35,  3.55s/it]                                                       {'loss': 0.0483, 'grad_norm': 3.6622042655944824, 'learning_rate': 3.3966101694915253e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3996/6000 [3:53:56<1:58:35,  3.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [3:53:59<1:56:44,  3.50s/it]                                                       {'loss': 0.003, 'grad_norm': 0.4561030864715576, 'learning_rate': 3.394915254237288e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3997/6000 [3:53:59<1:56:44,  3.50s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [3:54:02<1:54:58,  3.45s/it]                                                       {'loss': 0.0157, 'grad_norm': 4.673087120056152, 'learning_rate': 3.393220338983051e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3998/6000 [3:54:02<1:54:58,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [3:54:06<1:55:02,  3.45s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1629616767168045, 'learning_rate': 3.3915254237288135e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3999/6000 [3:54:06<1:55:02,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [3:54:09<1:55:23,  3.46s/it]                                                       {'loss': 0.1099, 'grad_norm': 12.856762886047363, 'learning_rate': 3.3898305084745763e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4000/6000 [3:54:09<1:55:23,  3.46s/it][2025-11-07 02:45:19,430] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4000
[2025-11-07 02:45:19,445] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:45:20,128] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4000/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [3:54:15<2:17:45,  4.13s/it]                                                       {'loss': 0.0045, 'grad_norm': 1.1273301839828491, 'learning_rate': 3.388135593220339e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4001/6000 [3:54:15<2:17:45,  4.13s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [3:54:19<2:10:30,  3.92s/it]                                                       {'loss': 0.0107, 'grad_norm': 1.4939100742340088, 'learning_rate': 3.386440677966102e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4002/6000 [3:54:19<2:10:30,  3.92s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [3:54:22<2:05:27,  3.77s/it]                                                       {'loss': 0.0873, 'grad_norm': 9.736639976501465, 'learning_rate': 3.3847457627118644e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4003/6000 [3:54:22<2:05:27,  3.77s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [3:54:25<2:02:14,  3.67s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.15060125291347504, 'learning_rate': 3.3830508474576273e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4004/6000 [3:54:25<2:02:14,  3.67s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [3:54:29<1:58:41,  3.57s/it]                                                       {'loss': 0.0893, 'grad_norm': 7.594225883483887, 'learning_rate': 3.38135593220339e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4005/6000 [3:54:29<1:58:41,  3.57s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [3:54:32<1:56:37,  3.51s/it]                                                       {'loss': 0.0136, 'grad_norm': 2.3298592567443848, 'learning_rate': 3.379661016949153e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4006/6000 [3:54:32<1:56:37,  3.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [3:54:36<1:55:57,  3.49s/it]                                                       {'loss': 0.0297, 'grad_norm': 3.7836556434631348, 'learning_rate': 3.3779661016949154e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4007/6000 [3:54:36<1:55:57,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [3:54:39<1:53:33,  3.42s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.9221779704093933, 'learning_rate': 3.3762711864406783e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4008/6000 [3:54:39<1:53:33,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [3:54:42<1:52:36,  3.39s/it]                                                       {'loss': 0.1883, 'grad_norm': 16.196102142333984, 'learning_rate': 3.374576271186441e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4009/6000 [3:54:42<1:52:36,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [3:54:46<1:52:26,  3.39s/it]                                                       {'loss': 0.0128, 'grad_norm': 4.27983283996582, 'learning_rate': 3.372881355932204e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4010/6000 [3:54:46<1:52:26,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [3:54:49<1:53:26,  3.42s/it]                                                       {'loss': 0.0057, 'grad_norm': 1.670011281967163, 'learning_rate': 3.3711864406779664e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4011/6000 [3:54:49<1:53:26,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [3:54:52<1:53:05,  3.41s/it]                                                       {'loss': 0.001, 'grad_norm': 0.22791975736618042, 'learning_rate': 3.3694915254237292e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4012/6000 [3:54:52<1:53:05,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [3:54:56<1:52:27,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.07949941605329514, 'learning_rate': 3.367796610169492e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4013/6000 [3:54:56<1:52:27,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [3:54:59<1:51:28,  3.37s/it]                                                       {'loss': 0.2232, 'grad_norm': 19.206707000732422, 'learning_rate': 3.366101694915255e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4014/6000 [3:54:59<1:51:28,  3.37s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [3:55:03<1:52:20,  3.40s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.4337116479873657, 'learning_rate': 3.3644067796610174e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4015/6000 [3:55:03<1:52:20,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [3:55:06<1:53:19,  3.43s/it]                                                       {'loss': 0.0998, 'grad_norm': 10.895812034606934, 'learning_rate': 3.3627118644067802e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4016/6000 [3:55:06<1:53:19,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [3:55:09<1:53:00,  3.42s/it]                                                       {'loss': 0.0164, 'grad_norm': 3.2949187755584717, 'learning_rate': 3.3610169491525422e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4017/6000 [3:55:09<1:53:00,  3.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [3:55:13<1:54:20,  3.46s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.49298951029777527, 'learning_rate': 3.359322033898305e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4018/6000 [3:55:13<1:54:20,  3.46s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [3:55:16<1:54:02,  3.45s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.4195428490638733, 'learning_rate': 3.357627118644068e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4019/6000 [3:55:16<1:54:02,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [3:55:20<1:53:23,  3.44s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.7656406164169312, 'learning_rate': 3.3559322033898308e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4020/6000 [3:55:20<1:53:23,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [3:55:23<1:52:24,  3.41s/it]                                                       {'loss': 0.0661, 'grad_norm': 13.768499374389648, 'learning_rate': 3.354237288135593e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4021/6000 [3:55:23<1:52:24,  3.41s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [3:55:28<2:01:27,  3.68s/it]                                                       {'loss': 0.0061, 'grad_norm': 1.218285083770752, 'learning_rate': 3.352542372881356e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4022/6000 [3:55:28<2:01:27,  3.68s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [3:55:31<1:59:23,  3.62s/it]                                                       {'loss': 0.098, 'grad_norm': 12.48449420928955, 'learning_rate': 3.350847457627119e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4023/6000 [3:55:31<1:59:23,  3.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [3:55:35<2:05:00,  3.80s/it]                                                       {'loss': 0.0233, 'grad_norm': 3.35787034034729, 'learning_rate': 3.3491525423728817e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4024/6000 [3:55:35<2:05:00,  3.80s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [3:55:39<2:00:59,  3.68s/it]                                                       {'loss': 0.4209, 'grad_norm': 16.382747650146484, 'learning_rate': 3.347457627118644e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4025/6000 [3:55:39<2:00:59,  3.68s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [3:55:42<1:58:25,  3.60s/it]                                                       {'loss': 0.0126, 'grad_norm': 2.798865795135498, 'learning_rate': 3.345762711864407e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4026/6000 [3:55:42<1:58:25,  3.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [3:55:46<2:03:09,  3.75s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.4621017873287201, 'learning_rate': 3.34406779661017e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4027/6000 [3:55:46<2:03:09,  3.75s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [3:55:50<2:00:08,  3.66s/it]                                                       {'loss': 0.072, 'grad_norm': 10.130572319030762, 'learning_rate': 3.3423728813559327e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4028/6000 [3:55:50<2:00:08,  3.66s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [3:55:53<1:58:15,  3.60s/it]                                                       {'loss': 0.2197, 'grad_norm': 13.845874786376953, 'learning_rate': 3.340677966101695e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4029/6000 [3:55:53<1:58:15,  3.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [3:55:56<1:56:46,  3.56s/it]                                                       {'loss': 0.1189, 'grad_norm': 14.197389602661133, 'learning_rate': 3.338983050847458e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4030/6000 [3:55:56<1:56:46,  3.56s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [3:56:00<1:54:42,  3.50s/it]                                                       {'loss': 0.0548, 'grad_norm': 4.571390151977539, 'learning_rate': 3.337288135593221e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4031/6000 [3:56:00<1:54:42,  3.50s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [3:56:03<1:54:22,  3.49s/it]                                                       {'loss': 0.0167, 'grad_norm': 3.7713441848754883, 'learning_rate': 3.3355932203389833e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4032/6000 [3:56:03<1:54:22,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [3:56:07<1:54:17,  3.49s/it]                                                       {'loss': 0.0226, 'grad_norm': 4.182389259338379, 'learning_rate': 3.333898305084746e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4033/6000 [3:56:07<1:54:17,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [3:56:10<1:52:50,  3.44s/it]                                                       {'loss': 0.0154, 'grad_norm': 3.0071959495544434, 'learning_rate': 3.332203389830509e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4034/6000 [3:56:10<1:52:50,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [3:56:14<1:52:32,  3.44s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.3631317615509033, 'learning_rate': 3.330508474576272e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4035/6000 [3:56:14<1:52:32,  3.44s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [3:56:17<1:51:10,  3.40s/it]                                                       {'loss': 0.054, 'grad_norm': 9.030710220336914, 'learning_rate': 3.3288135593220343e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4036/6000 [3:56:17<1:51:10,  3.40s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [3:56:20<1:50:47,  3.39s/it]                                                       {'loss': 0.0735, 'grad_norm': 4.746531963348389, 'learning_rate': 3.3271186440677967e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4037/6000 [3:56:20<1:50:47,  3.39s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [3:56:24<1:52:18,  3.43s/it]                                                       {'loss': 0.0743, 'grad_norm': 11.523843765258789, 'learning_rate': 3.3254237288135595e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4038/6000 [3:56:24<1:52:18,  3.43s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [3:56:27<1:52:45,  3.45s/it]                                                       {'loss': 0.0159, 'grad_norm': 3.3886489868164062, 'learning_rate': 3.323728813559322e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4039/6000 [3:56:27<1:52:45,  3.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [3:56:31<1:53:14,  3.47s/it]                                                       {'loss': 0.0081, 'grad_norm': 0.9864681363105774, 'learning_rate': 3.322033898305085e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4040/6000 [3:56:31<1:53:14,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [3:56:35<1:56:45,  3.58s/it]                                                       {'loss': 0.1762, 'grad_norm': 14.822659492492676, 'learning_rate': 3.3203389830508477e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4041/6000 [3:56:35<1:56:45,  3.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [3:56:38<1:54:44,  3.52s/it]                                                       {'loss': 0.1031, 'grad_norm': 15.545953750610352, 'learning_rate': 3.3186440677966105e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4042/6000 [3:56:38<1:54:44,  3.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [3:56:42<1:57:41,  3.61s/it]                                                       {'loss': 0.105, 'grad_norm': 15.407731056213379, 'learning_rate': 3.316949152542373e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4043/6000 [3:56:42<1:57:41,  3.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [3:56:45<1:55:23,  3.54s/it]                                                       {'loss': 0.0106, 'grad_norm': 1.5505009889602661, 'learning_rate': 3.3152542372881358e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4044/6000 [3:56:45<1:55:23,  3.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [3:56:49<1:54:15,  3.51s/it]                                                       {'loss': 0.0196, 'grad_norm': 4.3616719245910645, 'learning_rate': 3.3135593220338986e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4045/6000 [3:56:49<1:54:15,  3.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [3:56:52<1:52:56,  3.47s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.863246738910675, 'learning_rate': 3.311864406779661e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4046/6000 [3:56:52<1:52:56,  3.47s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [3:56:56<1:54:07,  3.51s/it]                                                       {'loss': 0.1441, 'grad_norm': 15.174635887145996, 'learning_rate': 3.310169491525424e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4047/6000 [3:56:56<1:54:07,  3.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [3:56:59<1:53:27,  3.49s/it]                                                       {'loss': 0.043, 'grad_norm': 6.3808488845825195, 'learning_rate': 3.3084745762711868e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4048/6000 [3:56:59<1:53:27,  3.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [3:57:02<1:51:58,  3.44s/it]                                                       {'loss': 0.1536, 'grad_norm': 11.45551872253418, 'learning_rate': 3.3067796610169496e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4049/6000 [3:57:02<1:51:58,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [3:57:06<1:53:02,  3.48s/it]                                                       {'loss': 0.2447, 'grad_norm': 15.547022819519043, 'learning_rate': 3.305084745762712e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4050/6000 [3:57:06<1:53:02,  3.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [3:57:09<1:51:52,  3.44s/it]                                                       {'loss': 0.2901, 'grad_norm': 14.749314308166504, 'learning_rate': 3.303389830508475e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4051/6000 [3:57:09<1:51:52,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [3:57:13<1:51:21,  3.43s/it]                                                       {'loss': 0.0745, 'grad_norm': 7.6357951164245605, 'learning_rate': 3.3016949152542377e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4052/6000 [3:57:13<1:51:21,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [3:57:16<1:54:14,  3.52s/it]                                                       {'loss': 0.0044, 'grad_norm': 1.0095856189727783, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4053/6000 [3:57:16<1:54:14,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [3:57:20<1:54:19,  3.53s/it]                                                       {'loss': 0.1329, 'grad_norm': 13.83780574798584, 'learning_rate': 3.298305084745763e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4054/6000 [3:57:20<1:54:19,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [3:57:23<1:54:17,  3.53s/it]                                                       {'loss': 0.0759, 'grad_norm': 8.41576862335205, 'learning_rate': 3.296610169491526e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4055/6000 [3:57:23<1:54:17,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [3:57:27<1:56:18,  3.59s/it]                                                       {'loss': 0.1768, 'grad_norm': 13.126849174499512, 'learning_rate': 3.2949152542372887e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4056/6000 [3:57:27<1:56:18,  3.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [3:57:30<1:53:22,  3.50s/it]                                                       {'loss': 0.0151, 'grad_norm': 3.788334369659424, 'learning_rate': 3.2932203389830516e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4057/6000 [3:57:30<1:53:22,  3.50s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [3:57:34<1:51:58,  3.46s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.344728946685791, 'learning_rate': 3.2915254237288136e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4058/6000 [3:57:34<1:51:58,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [3:57:37<1:50:52,  3.43s/it]                                                       {'loss': 0.0062, 'grad_norm': 2.178875207901001, 'learning_rate': 3.2898305084745764e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4059/6000 [3:57:37<1:50:52,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [3:57:41<1:50:07,  3.41s/it]                                                       {'loss': 0.1859, 'grad_norm': 13.915752410888672, 'learning_rate': 3.288135593220339e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4060/6000 [3:57:41<1:50:07,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [3:57:44<1:50:36,  3.42s/it]                                                       {'loss': 0.1712, 'grad_norm': 18.468605041503906, 'learning_rate': 3.2864406779661017e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4061/6000 [3:57:44<1:50:36,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [3:57:48<1:51:41,  3.46s/it]                                                       {'loss': 0.1477, 'grad_norm': 16.616933822631836, 'learning_rate': 3.2847457627118645e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4062/6000 [3:57:48<1:51:41,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [3:57:52<1:57:42,  3.65s/it]                                                       {'loss': 0.003, 'grad_norm': 1.0148742198944092, 'learning_rate': 3.2830508474576274e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4063/6000 [3:57:52<1:57:42,  3.65s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [3:57:55<1:55:06,  3.57s/it]                                                       {'loss': 0.0528, 'grad_norm': 10.012831687927246, 'learning_rate': 3.28135593220339e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4064/6000 [3:57:55<1:55:06,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [3:57:59<1:58:42,  3.68s/it]                                                       {'loss': 0.0051, 'grad_norm': 0.9997650384902954, 'learning_rate': 3.2796610169491527e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4065/6000 [3:57:59<1:58:42,  3.68s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [3:58:02<1:55:14,  3.58s/it]                                                       {'loss': 0.0638, 'grad_norm': 10.64913558959961, 'learning_rate': 3.2779661016949155e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4066/6000 [3:58:02<1:55:14,  3.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [3:58:06<1:53:46,  3.53s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.4819680154323578, 'learning_rate': 3.2762711864406784e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4067/6000 [3:58:06<1:53:46,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [3:58:09<1:51:59,  3.48s/it]                                                       {'loss': 0.0496, 'grad_norm': 8.02004337310791, 'learning_rate': 3.274576271186441e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4068/6000 [3:58:09<1:51:59,  3.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [3:58:12<1:50:56,  3.45s/it]                                                       {'loss': 0.0112, 'grad_norm': 3.783820152282715, 'learning_rate': 3.2728813559322037e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4069/6000 [3:58:12<1:50:56,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [3:58:16<1:49:53,  3.42s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.4597904682159424, 'learning_rate': 3.2711864406779665e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4070/6000 [3:58:16<1:49:53,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [3:58:19<1:49:53,  3.42s/it]                                                       {'loss': 0.0387, 'grad_norm': 8.806805610656738, 'learning_rate': 3.2694915254237294e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/6000 [3:58:19<1:49:53,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [3:58:23<1:51:08,  3.46s/it]                                                       {'loss': 0.0119, 'grad_norm': 3.537909507751465, 'learning_rate': 3.2677966101694918e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4072/6000 [3:58:23<1:51:08,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [3:58:27<1:53:49,  3.54s/it]                                                       {'loss': 0.015, 'grad_norm': 4.017609119415283, 'learning_rate': 3.2661016949152546e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4073/6000 [3:58:27<1:53:49,  3.54s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [3:58:30<1:52:23,  3.50s/it]                                                       {'loss': 0.2547, 'grad_norm': 15.728271484375, 'learning_rate': 3.2644067796610175e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4074/6000 [3:58:30<1:52:23,  3.50s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [3:58:33<1:50:35,  3.45s/it]                                                       {'loss': 0.095, 'grad_norm': 9.385542869567871, 'learning_rate': 3.26271186440678e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4075/6000 [3:58:33<1:50:35,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [3:58:37<1:53:12,  3.53s/it]                                                       {'loss': 0.0021, 'grad_norm': 0.4714588522911072, 'learning_rate': 3.2610169491525428e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4076/6000 [3:58:37<1:53:12,  3.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [3:58:40<1:52:07,  3.50s/it]                                                       {'loss': 0.0033, 'grad_norm': 1.127431035041809, 'learning_rate': 3.2593220338983056e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4077/6000 [3:58:40<1:52:07,  3.50s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [3:58:44<1:52:33,  3.51s/it]                                                       {'loss': 0.1075, 'grad_norm': 14.607085227966309, 'learning_rate': 3.2576271186440685e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4078/6000 [3:58:44<1:52:33,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [3:58:47<1:51:26,  3.48s/it]                                                       {'loss': 0.1536, 'grad_norm': 10.639374732971191, 'learning_rate': 3.2559322033898305e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4079/6000 [3:58:47<1:51:26,  3.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [3:58:51<1:50:32,  3.45s/it]                                                       {'loss': 0.1061, 'grad_norm': 14.269360542297363, 'learning_rate': 3.2542372881355933e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4080/6000 [3:58:51<1:50:32,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [3:58:54<1:53:08,  3.54s/it]                                                       {'loss': 0.004, 'grad_norm': 0.8331251740455627, 'learning_rate': 3.252542372881356e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4081/6000 [3:58:54<1:53:08,  3.54s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [3:58:58<1:51:28,  3.49s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.14637541770935059, 'learning_rate': 3.2508474576271186e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4082/6000 [3:58:58<1:51:28,  3.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [3:59:01<1:50:20,  3.45s/it]                                                       {'loss': 0.0671, 'grad_norm': 7.799350261688232, 'learning_rate': 3.2491525423728814e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4083/6000 [3:59:01<1:50:20,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [3:59:05<1:53:52,  3.57s/it]                                                       {'loss': 0.055, 'grad_norm': 10.10244083404541, 'learning_rate': 3.2474576271186443e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4084/6000 [3:59:05<1:53:52,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [3:59:08<1:51:57,  3.51s/it]                                                       {'loss': 0.0576, 'grad_norm': 7.669319152832031, 'learning_rate': 3.245762711864407e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4085/6000 [3:59:08<1:51:57,  3.51s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [3:59:12<1:50:31,  3.46s/it]                                                       {'loss': 0.0442, 'grad_norm': 11.714457511901855, 'learning_rate': 3.2440677966101696e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4086/6000 [3:59:12<1:50:31,  3.46s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [3:59:15<1:50:47,  3.47s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05440397560596466, 'learning_rate': 3.2423728813559324e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4087/6000 [3:59:15<1:50:47,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [3:59:19<1:53:55,  3.57s/it]                                                       {'loss': 0.0137, 'grad_norm': 2.6331048011779785, 'learning_rate': 3.2406779661016953e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4088/6000 [3:59:19<1:53:55,  3.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [3:59:22<1:52:03,  3.52s/it]                                                       {'loss': 0.0049, 'grad_norm': 0.9457656741142273, 'learning_rate': 3.2389830508474577e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4089/6000 [3:59:22<1:52:03,  3.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [3:59:26<1:50:52,  3.48s/it]                                                       {'loss': 0.0305, 'grad_norm': 4.515323638916016, 'learning_rate': 3.2372881355932205e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4090/6000 [3:59:26<1:50:52,  3.48s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [3:59:29<1:49:51,  3.45s/it]                                                       {'loss': 0.0036, 'grad_norm': 1.2645833492279053, 'learning_rate': 3.2355932203389834e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4091/6000 [3:59:29<1:49:51,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [3:59:33<1:48:53,  3.42s/it]                                                       {'loss': 0.0181, 'grad_norm': 6.535340785980225, 'learning_rate': 3.2338983050847462e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4092/6000 [3:59:33<1:48:53,  3.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [3:59:36<1:48:22,  3.41s/it]                                                       {'loss': 0.0358, 'grad_norm': 6.732180118560791, 'learning_rate': 3.2322033898305087e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4093/6000 [3:59:36<1:48:22,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [3:59:39<1:48:12,  3.41s/it]                                                       {'loss': 0.0771, 'grad_norm': 21.188695907592773, 'learning_rate': 3.2305084745762715e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4094/6000 [3:59:39<1:48:12,  3.41s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [3:59:43<1:48:58,  3.43s/it]                                                       {'loss': 0.1415, 'grad_norm': 16.048629760742188, 'learning_rate': 3.2288135593220344e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4095/6000 [3:59:43<1:48:58,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [3:59:46<1:49:08,  3.44s/it]                                                       {'loss': 0.0534, 'grad_norm': 5.462550640106201, 'learning_rate': 3.2271186440677972e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4096/6000 [3:59:46<1:49:08,  3.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [3:59:50<1:48:44,  3.43s/it]                                                       {'loss': 0.0401, 'grad_norm': 9.084700584411621, 'learning_rate': 3.2254237288135596e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4097/6000 [3:59:50<1:48:44,  3.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [3:59:53<1:49:55,  3.47s/it]                                                       {'loss': 0.1126, 'grad_norm': 17.870149612426758, 'learning_rate': 3.2237288135593225e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4098/6000 [3:59:53<1:49:55,  3.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [3:59:57<1:49:09,  3.45s/it]                                                       {'loss': 0.0952, 'grad_norm': 13.324467658996582, 'learning_rate': 3.2220338983050853e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4099/6000 [3:59:57<1:49:09,  3.45s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [4:00:01<1:53:44,  3.59s/it]                                                       {'loss': 0.0103, 'grad_norm': 2.1773886680603027, 'learning_rate': 3.2203389830508473e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4100/6000 [4:00:01<1:53:44,  3.59s/it][2025-11-07 02:51:10,620] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4100
[2025-11-07 02:51:10,632] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:51:11,335] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4100/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [4:00:06<2:13:59,  4.23s/it]                                                       {'loss': 0.101, 'grad_norm': 9.402141571044922, 'learning_rate': 3.21864406779661e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4101/6000 [4:00:07<2:13:59,  4.23s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [4:00:10<2:09:14,  4.09s/it]                                                       {'loss': 0.0354, 'grad_norm': 10.945899963378906, 'learning_rate': 3.216949152542373e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4102/6000 [4:00:10<2:09:14,  4.09s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [4:00:14<2:06:24,  4.00s/it]                                                       {'loss': 0.0244, 'grad_norm': 6.164486408233643, 'learning_rate': 3.2152542372881355e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4103/6000 [4:00:14<2:06:24,  4.00s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [4:00:18<2:04:45,  3.95s/it]                                                       {'loss': 0.0147, 'grad_norm': 5.15596342086792, 'learning_rate': 3.2135593220338983e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4104/6000 [4:00:18<2:04:45,  3.95s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [4:00:21<1:59:51,  3.80s/it]                                                       {'loss': 0.0257, 'grad_norm': 6.656085014343262, 'learning_rate': 3.211864406779661e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4105/6000 [4:00:21<1:59:51,  3.80s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [4:00:25<2:00:02,  3.80s/it]                                                       {'loss': 0.013, 'grad_norm': 4.331663131713867, 'learning_rate': 3.210169491525424e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4106/6000 [4:00:25<2:00:02,  3.80s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [4:00:28<1:56:19,  3.69s/it]                                                       {'loss': 0.0886, 'grad_norm': 11.299759864807129, 'learning_rate': 3.2084745762711865e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4107/6000 [4:00:28<1:56:19,  3.69s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [4:00:32<1:52:53,  3.58s/it]                                                       {'loss': 0.0994, 'grad_norm': 12.506878852844238, 'learning_rate': 3.2067796610169493e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4108/6000 [4:00:32<1:52:53,  3.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [4:00:36<1:56:26,  3.69s/it]                                                       {'loss': 0.0326, 'grad_norm': 6.069063663482666, 'learning_rate': 3.205084745762712e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4109/6000 [4:00:36<1:56:26,  3.69s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [4:00:39<1:53:30,  3.60s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.1478826403617859, 'learning_rate': 3.203389830508475e-06, 'epoch': 0.69}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4110/6000 [4:00:39<1:53:30,  3.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [4:00:43<1:51:58,  3.56s/it]                                                       {'loss': 0.0487, 'grad_norm': 11.661141395568848, 'learning_rate': 3.2016949152542374e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4111/6000 [4:00:43<1:51:58,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [4:00:46<1:49:54,  3.49s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.5219714641571045, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4112/6000 [4:00:46<1:49:54,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [4:00:50<1:54:11,  3.63s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.020768919959664345, 'learning_rate': 3.198305084745763e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4113/6000 [4:00:50<1:54:11,  3.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [4:00:53<1:51:36,  3.55s/it]                                                       {'loss': 0.0291, 'grad_norm': 5.30007266998291, 'learning_rate': 3.196610169491526e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4114/6000 [4:00:53<1:51:36,  3.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [4:00:57<1:50:04,  3.50s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.39244675636291504, 'learning_rate': 3.1949152542372884e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4115/6000 [4:00:57<1:50:04,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [4:01:00<1:48:45,  3.46s/it]                                                       {'loss': 0.05, 'grad_norm': 8.374161720275879, 'learning_rate': 3.1932203389830513e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4116/6000 [4:01:00<1:48:45,  3.46s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [4:01:04<1:52:02,  3.57s/it]                                                       {'loss': 0.012, 'grad_norm': 1.8568693399429321, 'learning_rate': 3.191525423728814e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4117/6000 [4:01:04<1:52:02,  3.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [4:01:07<1:49:14,  3.48s/it]                                                       {'loss': 0.1135, 'grad_norm': 11.948220252990723, 'learning_rate': 3.189830508474577e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4118/6000 [4:01:07<1:49:14,  3.48s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [4:01:11<1:49:23,  3.49s/it]                                                       {'loss': 0.0519, 'grad_norm': 8.835549354553223, 'learning_rate': 3.1881355932203394e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4119/6000 [4:01:11<1:49:23,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [4:01:14<1:48:36,  3.47s/it]                                                       {'loss': 0.006, 'grad_norm': 1.5909076929092407, 'learning_rate': 3.186440677966102e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4120/6000 [4:01:14<1:48:36,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [4:01:17<1:48:04,  3.45s/it]                                                       {'loss': 0.2082, 'grad_norm': 19.38785171508789, 'learning_rate': 3.1847457627118642e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4121/6000 [4:01:17<1:48:04,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [4:01:21<1:48:33,  3.47s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.05447699874639511, 'learning_rate': 3.183050847457627e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4122/6000 [4:01:21<1:48:33,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [4:01:24<1:48:38,  3.47s/it]                                                       {'loss': 0.0135, 'grad_norm': 2.9730093479156494, 'learning_rate': 3.18135593220339e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4123/6000 [4:01:24<1:48:38,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [4:01:28<1:47:04,  3.42s/it]                                                       {'loss': 0.0152, 'grad_norm': 2.8768935203552246, 'learning_rate': 3.1796610169491528e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4124/6000 [4:01:28<1:47:04,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [4:01:31<1:46:29,  3.41s/it]                                                       {'loss': 0.0099, 'grad_norm': 1.9495052099227905, 'learning_rate': 3.1779661016949152e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4125/6000 [4:01:31<1:46:29,  3.41s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [4:01:34<1:45:52,  3.39s/it]                                                       {'loss': 0.0696, 'grad_norm': 10.365921020507812, 'learning_rate': 3.176271186440678e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4126/6000 [4:01:34<1:45:52,  3.39s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [4:01:38<1:46:02,  3.40s/it]                                                       {'loss': 0.1519, 'grad_norm': 15.08630084991455, 'learning_rate': 3.174576271186441e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4127/6000 [4:01:38<1:46:02,  3.40s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [4:01:41<1:47:58,  3.46s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.3219093084335327, 'learning_rate': 3.1728813559322038e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4128/6000 [4:01:41<1:47:58,  3.46s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [4:01:45<1:46:50,  3.43s/it]                                                       {'loss': 0.2759, 'grad_norm': 15.330331802368164, 'learning_rate': 3.171186440677966e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4129/6000 [4:01:45<1:46:50,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [4:01:48<1:47:27,  3.45s/it]                                                       {'loss': 0.1227, 'grad_norm': 14.441067695617676, 'learning_rate': 3.169491525423729e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4130/6000 [4:01:48<1:47:27,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [4:01:52<1:48:08,  3.47s/it]                                                       {'loss': 0.0, 'grad_norm': 0.006372484844177961, 'learning_rate': 3.167796610169492e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4131/6000 [4:01:52<1:48:08,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [4:01:55<1:46:48,  3.43s/it]                                                       {'loss': 0.0203, 'grad_norm': 5.327603816986084, 'learning_rate': 3.1661016949152547e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4132/6000 [4:01:55<1:46:48,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [4:01:59<1:53:49,  3.66s/it]                                                       {'loss': 0.034, 'grad_norm': 6.8737945556640625, 'learning_rate': 3.164406779661017e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4133/6000 [4:01:59<1:53:49,  3.66s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [4:02:03<1:51:14,  3.58s/it]                                                       {'loss': 0.3632, 'grad_norm': 19.3414363861084, 'learning_rate': 3.16271186440678e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4134/6000 [4:02:03<1:51:14,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [4:02:06<1:48:47,  3.50s/it]                                                       {'loss': 0.0205, 'grad_norm': 5.446117401123047, 'learning_rate': 3.161016949152543e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4135/6000 [4:02:06<1:48:47,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [4:02:10<1:52:09,  3.61s/it]                                                       {'loss': 0.0446, 'grad_norm': 11.44321060180664, 'learning_rate': 3.1593220338983053e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4136/6000 [4:02:10<1:52:09,  3.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [4:02:14<1:56:04,  3.74s/it]                                                       {'loss': 0.0226, 'grad_norm': 2.243525743484497, 'learning_rate': 3.157627118644068e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4137/6000 [4:02:14<1:56:04,  3.74s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [4:02:17<1:53:47,  3.67s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.6618815064430237, 'learning_rate': 3.155932203389831e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4138/6000 [4:02:17<1:53:47,  3.67s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [4:02:21<1:51:04,  3.58s/it]                                                       {'loss': 0.1843, 'grad_norm': 14.801764488220215, 'learning_rate': 3.154237288135594e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4139/6000 [4:02:21<1:51:04,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [4:02:24<1:50:53,  3.58s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3812224864959717, 'learning_rate': 3.1525423728813563e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4140/6000 [4:02:24<1:50:53,  3.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [4:02:28<1:49:36,  3.54s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2624644339084625, 'learning_rate': 3.1508474576271187e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4141/6000 [4:02:28<1:49:36,  3.54s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [4:02:31<1:50:39,  3.57s/it]                                                       {'loss': 0.0144, 'grad_norm': 4.085387229919434, 'learning_rate': 3.1491525423728815e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4142/6000 [4:02:31<1:50:39,  3.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [4:02:35<1:50:04,  3.56s/it]                                                       {'loss': 0.2125, 'grad_norm': 21.867429733276367, 'learning_rate': 3.147457627118644e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4143/6000 [4:02:35<1:50:04,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [4:02:39<1:49:56,  3.55s/it]                                                       {'loss': 0.0029, 'grad_norm': 1.0793921947479248, 'learning_rate': 3.145762711864407e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4144/6000 [4:02:39<1:49:56,  3.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [4:02:42<1:48:06,  3.50s/it]                                                       {'loss': 0.0575, 'grad_norm': 7.434523105621338, 'learning_rate': 3.1440677966101697e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4145/6000 [4:02:42<1:48:06,  3.50s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [4:02:46<1:49:03,  3.53s/it]                                                       {'loss': 0.0335, 'grad_norm': 7.174711227416992, 'learning_rate': 3.1423728813559325e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4146/6000 [4:02:46<1:49:03,  3.53s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [4:02:49<1:48:16,  3.51s/it]                                                       {'loss': 0.0032, 'grad_norm': 1.0953978300094604, 'learning_rate': 3.140677966101695e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4147/6000 [4:02:49<1:48:16,  3.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [4:02:52<1:46:08,  3.44s/it]                                                       {'loss': 0.0838, 'grad_norm': 11.704276084899902, 'learning_rate': 3.138983050847458e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4148/6000 [4:02:52<1:46:08,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [4:02:56<1:45:35,  3.42s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.1964663416147232, 'learning_rate': 3.1372881355932207e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4149/6000 [4:02:56<1:45:35,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [4:02:59<1:44:28,  3.39s/it]                                                       {'loss': 0.0937, 'grad_norm': 9.562394142150879, 'learning_rate': 3.135593220338983e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4150/6000 [4:02:59<1:44:28,  3.39s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [4:03:02<1:44:02,  3.38s/it]                                                       {'loss': 0.0146, 'grad_norm': 4.273898601531982, 'learning_rate': 3.133898305084746e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4151/6000 [4:03:02<1:44:02,  3.38s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [4:03:06<1:43:47,  3.37s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.37328118085861206, 'learning_rate': 3.1322033898305088e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4152/6000 [4:03:06<1:43:47,  3.37s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [4:03:09<1:43:27,  3.36s/it]                                                       {'loss': 0.0176, 'grad_norm': 3.393986463546753, 'learning_rate': 3.1305084745762716e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4153/6000 [4:03:09<1:43:27,  3.36s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [4:03:13<1:49:12,  3.55s/it]                                                       {'loss': 0.1144, 'grad_norm': 16.13238525390625, 'learning_rate': 3.128813559322034e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4154/6000 [4:03:13<1:49:12,  3.55s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [4:03:16<1:48:16,  3.52s/it]                                                       {'loss': 0.0095, 'grad_norm': 3.099292755126953, 'learning_rate': 3.127118644067797e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4155/6000 [4:03:16<1:48:16,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [4:03:20<1:48:06,  3.52s/it]                                                       {'loss': 0.012, 'grad_norm': 2.7361209392547607, 'learning_rate': 3.1254237288135598e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4156/6000 [4:03:20<1:48:06,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [4:03:23<1:48:13,  3.52s/it]                                                       {'loss': 0.1679, 'grad_norm': 14.51984691619873, 'learning_rate': 3.1237288135593226e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4157/6000 [4:03:23<1:48:13,  3.52s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [4:03:27<1:50:18,  3.59s/it]                                                       {'loss': 0.1208, 'grad_norm': 14.90861988067627, 'learning_rate': 3.122033898305085e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4158/6000 [4:03:27<1:50:18,  3.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [4:03:31<1:49:13,  3.56s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.5182601809501648, 'learning_rate': 3.120338983050848e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4159/6000 [4:03:31<1:49:13,  3.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [4:03:34<1:47:08,  3.49s/it]                                                       {'loss': 0.0912, 'grad_norm': 11.401093482971191, 'learning_rate': 3.1186440677966107e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4160/6000 [4:03:34<1:47:08,  3.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [4:03:37<1:45:46,  3.45s/it]                                                       {'loss': 0.0382, 'grad_norm': 5.881661891937256, 'learning_rate': 3.1169491525423736e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4161/6000 [4:03:37<1:45:46,  3.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [4:03:41<1:45:18,  3.44s/it]                                                       {'loss': 0.1008, 'grad_norm': 10.84499454498291, 'learning_rate': 3.1152542372881356e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4162/6000 [4:03:41<1:45:18,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [4:03:44<1:44:42,  3.42s/it]                                                       {'loss': 0.0505, 'grad_norm': 6.511422157287598, 'learning_rate': 3.1135593220338984e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4163/6000 [4:03:44<1:44:42,  3.42s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [4:03:48<1:45:04,  3.43s/it]                                                       {'loss': 0.0027, 'grad_norm': 1.0344278812408447, 'learning_rate': 3.111864406779661e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4164/6000 [4:03:48<1:45:04,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [4:03:51<1:45:03,  3.44s/it]                                                       {'loss': 0.0155, 'grad_norm': 3.210033655166626, 'learning_rate': 3.1101694915254237e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4165/6000 [4:03:51<1:45:03,  3.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [4:03:55<1:44:55,  3.43s/it]                                                       {'loss': 0.1148, 'grad_norm': 10.995610237121582, 'learning_rate': 3.1084745762711866e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4166/6000 [4:03:55<1:44:55,  3.43s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [4:03:58<1:45:40,  3.46s/it]                                                       {'loss': 0.0534, 'grad_norm': 9.461402893066406, 'learning_rate': 3.1067796610169494e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4167/6000 [4:03:58<1:45:40,  3.46s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [4:04:02<1:45:51,  3.47s/it]                                                       {'loss': 0.1125, 'grad_norm': 11.183146476745605, 'learning_rate': 3.105084745762712e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4168/6000 [4:04:02<1:45:51,  3.47s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [4:04:06<1:51:36,  3.66s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.2104287147521973, 'learning_rate': 3.1033898305084747e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4169/6000 [4:04:06<1:51:36,  3.66s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [4:04:09<1:49:18,  3.58s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.42366698384284973, 'learning_rate': 3.1016949152542375e-06, 'epoch': 0.69}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4170/6000 [4:04:09<1:49:18,  3.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [4:04:13<1:52:11,  3.68s/it]                                                       {'loss': 0.2152, 'grad_norm': 17.757253646850586, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/6000 [4:04:13<1:52:11,  3.68s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [4:04:16<1:49:58,  3.61s/it]                                                       {'loss': 0.2404, 'grad_norm': 14.688570976257324, 'learning_rate': 3.098305084745763e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4172/6000 [4:04:16<1:49:58,  3.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [4:04:20<1:49:19,  3.59s/it]                                                       {'loss': 0.0751, 'grad_norm': 8.502184867858887, 'learning_rate': 3.0966101694915257e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4173/6000 [4:04:20<1:49:19,  3.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [4:04:23<1:47:59,  3.55s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.419846773147583, 'learning_rate': 3.0949152542372885e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4174/6000 [4:04:23<1:47:59,  3.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [4:04:27<1:47:54,  3.55s/it]                                                       {'loss': 0.0358, 'grad_norm': 6.488317489624023, 'learning_rate': 3.0932203389830514e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4175/6000 [4:04:27<1:47:54,  3.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [4:04:30<1:46:19,  3.50s/it]                                                       {'loss': 0.1103, 'grad_norm': 9.27657699584961, 'learning_rate': 3.091525423728814e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4176/6000 [4:04:30<1:46:19,  3.50s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [4:04:34<1:45:11,  3.46s/it]                                                       {'loss': 0.0657, 'grad_norm': 15.117439270019531, 'learning_rate': 3.0898305084745766e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4177/6000 [4:04:34<1:45:11,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [4:04:37<1:44:05,  3.43s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.887944221496582, 'learning_rate': 3.0881355932203395e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4178/6000 [4:04:37<1:44:05,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [4:04:40<1:43:53,  3.42s/it]                                                       {'loss': 0.2324, 'grad_norm': 15.341200828552246, 'learning_rate': 3.0864406779661023e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4179/6000 [4:04:40<1:43:53,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [4:04:44<1:42:54,  3.39s/it]                                                       {'loss': 0.0209, 'grad_norm': 7.134637832641602, 'learning_rate': 3.0847457627118648e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4180/6000 [4:04:44<1:42:54,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [4:04:47<1:42:03,  3.37s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.517049252986908, 'learning_rate': 3.0830508474576276e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4181/6000 [4:04:47<1:42:03,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [4:04:50<1:41:05,  3.34s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1693575084209442, 'learning_rate': 3.0813559322033905e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4182/6000 [4:04:50<1:41:05,  3.34s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [4:04:54<1:41:53,  3.36s/it]                                                       {'loss': 0.004, 'grad_norm': 0.8548001646995544, 'learning_rate': 3.0796610169491525e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4183/6000 [4:04:54<1:41:53,  3.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [4:04:57<1:42:50,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.019426869228482246, 'learning_rate': 3.0779661016949153e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4184/6000 [4:04:57<1:42:50,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [4:05:01<1:42:51,  3.40s/it]                                                       {'loss': 0.3551, 'grad_norm': 12.265420913696289, 'learning_rate': 3.076271186440678e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4185/6000 [4:05:01<1:42:51,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [4:05:04<1:44:06,  3.44s/it]                                                       {'loss': 0.0113, 'grad_norm': 1.6692856550216675, 'learning_rate': 3.0745762711864406e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4186/6000 [4:05:04<1:44:06,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [4:05:08<1:44:07,  3.45s/it]                                                       {'loss': 0.0285, 'grad_norm': 5.807291507720947, 'learning_rate': 3.0728813559322034e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4187/6000 [4:05:08<1:44:07,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [4:05:11<1:44:05,  3.45s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.19103088974952698, 'learning_rate': 3.0711864406779663e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4188/6000 [4:05:11<1:44:05,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [4:05:15<1:45:26,  3.49s/it]                                                       {'loss': 0.0196, 'grad_norm': 5.240070343017578, 'learning_rate': 3.069491525423729e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4189/6000 [4:05:15<1:45:26,  3.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [4:05:18<1:44:44,  3.47s/it]                                                       {'loss': 0.1467, 'grad_norm': 15.46793270111084, 'learning_rate': 3.0677966101694916e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4190/6000 [4:05:18<1:44:44,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [4:05:22<1:44:06,  3.45s/it]                                                       {'loss': 0.0326, 'grad_norm': 8.449519157409668, 'learning_rate': 3.0661016949152544e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4191/6000 [4:05:22<1:44:06,  3.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [4:05:25<1:44:17,  3.46s/it]                                                       {'loss': 0.0038, 'grad_norm': 0.8938402533531189, 'learning_rate': 3.0644067796610173e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4192/6000 [4:05:25<1:44:17,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [4:05:29<1:44:26,  3.47s/it]                                                       {'loss': 0.0401, 'grad_norm': 7.649647235870361, 'learning_rate': 3.06271186440678e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4193/6000 [4:05:29<1:44:26,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [4:05:32<1:44:24,  3.47s/it]                                                       {'loss': 0.1059, 'grad_norm': 14.54305362701416, 'learning_rate': 3.0610169491525426e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4194/6000 [4:05:32<1:44:24,  3.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [4:05:35<1:44:06,  3.46s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.5221632719039917, 'learning_rate': 3.0593220338983054e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4195/6000 [4:05:35<1:44:06,  3.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [4:05:39<1:43:34,  3.44s/it]                                                       {'loss': 0.0583, 'grad_norm': 2.5954065322875977, 'learning_rate': 3.0576271186440683e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4196/6000 [4:05:39<1:43:34,  3.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [4:05:42<1:42:37,  3.42s/it]                                                       {'loss': 0.0846, 'grad_norm': 11.719228744506836, 'learning_rate': 3.0559322033898307e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4197/6000 [4:05:42<1:42:37,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [4:05:46<1:42:20,  3.41s/it]                                                       {'loss': 0.2075, 'grad_norm': 15.73680591583252, 'learning_rate': 3.0542372881355935e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4198/6000 [4:05:46<1:42:20,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [4:05:49<1:42:02,  3.40s/it]                                                       {'loss': 0.0768, 'grad_norm': 15.741229057312012, 'learning_rate': 3.0525423728813564e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4199/6000 [4:05:49<1:42:02,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [4:05:52<1:42:08,  3.40s/it]                                                       {'loss': 0.0315, 'grad_norm': 10.20176887512207, 'learning_rate': 3.0508474576271192e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4200/6000 [4:05:52<1:42:08,  3.40s/it][2025-11-07 02:57:02,351] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4200
[2025-11-07 02:57:02,370] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 02:57:03,061] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4200/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [4:05:58<2:03:14,  4.11s/it]                                                       {'loss': 0.007, 'grad_norm': 1.5948160886764526, 'learning_rate': 3.0491525423728817e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4201/6000 [4:05:58<2:03:14,  4.11s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [4:06:02<1:57:23,  3.92s/it]                                                       {'loss': 0.015, 'grad_norm': 4.981373310089111, 'learning_rate': 3.0474576271186445e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4202/6000 [4:06:02<1:57:23,  3.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [4:06:05<1:52:28,  3.76s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.8805683851242065, 'learning_rate': 3.045762711864407e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4203/6000 [4:06:05<1:52:28,  3.76s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [4:06:08<1:49:41,  3.66s/it]                                                       {'loss': 0.0392, 'grad_norm': 3.548260450363159, 'learning_rate': 3.0440677966101694e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4204/6000 [4:06:08<1:49:41,  3.66s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [4:06:12<1:47:44,  3.60s/it]                                                       {'loss': 0.0594, 'grad_norm': 7.121622562408447, 'learning_rate': 3.042372881355932e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4205/6000 [4:06:12<1:47:44,  3.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [4:06:15<1:45:48,  3.54s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5345264077186584, 'learning_rate': 3.040677966101695e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4206/6000 [4:06:15<1:45:48,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [4:06:19<1:43:58,  3.48s/it]                                                       {'loss': 0.0861, 'grad_norm': 13.877167701721191, 'learning_rate': 3.038983050847458e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4207/6000 [4:06:19<1:43:58,  3.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [4:06:22<1:42:34,  3.43s/it]                                                       {'loss': 0.143, 'grad_norm': 13.01287841796875, 'learning_rate': 3.0372881355932203e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4208/6000 [4:06:22<1:42:34,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [4:06:25<1:41:57,  3.42s/it]                                                       {'loss': 0.0276, 'grad_norm': 5.581417083740234, 'learning_rate': 3.035593220338983e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4209/6000 [4:06:25<1:41:57,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [4:06:29<1:40:33,  3.37s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.5374638438224792, 'learning_rate': 3.033898305084746e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4210/6000 [4:06:29<1:40:33,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [4:06:32<1:40:31,  3.37s/it]                                                       {'loss': 0.0862, 'grad_norm': 12.988277435302734, 'learning_rate': 3.0322033898305085e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4211/6000 [4:06:32<1:40:31,  3.37s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [4:06:35<1:41:02,  3.39s/it]                                                       {'loss': 0.0027, 'grad_norm': 1.1561506986618042, 'learning_rate': 3.0305084745762713e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4212/6000 [4:06:35<1:41:02,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [4:06:39<1:41:13,  3.40s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.7046278119087219, 'learning_rate': 3.028813559322034e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4213/6000 [4:06:39<1:41:13,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [4:06:42<1:40:09,  3.36s/it]                                                       {'loss': 0.0435, 'grad_norm': 3.5764529705047607, 'learning_rate': 3.027118644067797e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4214/6000 [4:06:42<1:40:09,  3.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [4:06:46<1:41:38,  3.42s/it]                                                       {'loss': 0.0031, 'grad_norm': 0.9773486852645874, 'learning_rate': 3.0254237288135594e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4215/6000 [4:06:46<1:41:38,  3.42s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [4:06:49<1:40:47,  3.39s/it]                                                       {'loss': 0.3334, 'grad_norm': 15.590320587158203, 'learning_rate': 3.0237288135593223e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4216/6000 [4:06:49<1:40:47,  3.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [4:06:52<1:42:01,  3.43s/it]                                                       {'loss': 0.0294, 'grad_norm': 5.718991279602051, 'learning_rate': 3.022033898305085e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4217/6000 [4:06:52<1:42:01,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [4:06:56<1:41:45,  3.43s/it]                                                       {'loss': 0.0638, 'grad_norm': 10.475361824035645, 'learning_rate': 3.020338983050848e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4218/6000 [4:06:56<1:41:45,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [4:07:00<1:43:33,  3.49s/it]                                                       {'loss': 0.0037, 'grad_norm': 0.6586505770683289, 'learning_rate': 3.0186440677966104e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4219/6000 [4:07:00<1:43:33,  3.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [4:07:03<1:41:42,  3.43s/it]                                                       {'loss': 0.0298, 'grad_norm': 5.028536796569824, 'learning_rate': 3.0169491525423733e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/6000 [4:07:03<1:41:42,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [4:07:06<1:41:06,  3.41s/it]                                                       {'loss': 0.0901, 'grad_norm': 11.896333694458008, 'learning_rate': 3.015254237288136e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4221/6000 [4:07:06<1:41:06,  3.41s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [4:07:10<1:44:51,  3.54s/it]                                                       {'loss': 0.0823, 'grad_norm': 9.724780082702637, 'learning_rate': 3.013559322033899e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4222/6000 [4:07:10<1:44:51,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [4:07:14<1:44:56,  3.54s/it]                                                       {'loss': 0.0486, 'grad_norm': 8.850188255310059, 'learning_rate': 3.0118644067796614e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4223/6000 [4:07:14<1:44:56,  3.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [4:07:17<1:46:29,  3.60s/it]                                                       {'loss': 0.1245, 'grad_norm': 12.793978691101074, 'learning_rate': 3.010169491525424e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4224/6000 [4:07:17<1:46:29,  3.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [4:07:21<1:50:45,  3.74s/it]                                                       {'loss': 0.1154, 'grad_norm': 11.683627128601074, 'learning_rate': 3.0084745762711862e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4225/6000 [4:07:21<1:50:45,  3.74s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [4:07:26<1:57:33,  3.98s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.7661422491073608, 'learning_rate': 3.006779661016949e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4226/6000 [4:07:26<1:57:33,  3.98s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [4:07:29<1:52:24,  3.80s/it]                                                       {'loss': 0.0431, 'grad_norm': 8.390695571899414, 'learning_rate': 3.005084745762712e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4227/6000 [4:07:29<1:52:24,  3.80s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [4:07:33<1:50:09,  3.73s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.531737208366394, 'learning_rate': 3.003389830508475e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4228/6000 [4:07:33<1:50:09,  3.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [4:07:36<1:46:41,  3.61s/it]                                                       {'loss': 0.0041, 'grad_norm': 0.7915521860122681, 'learning_rate': 3.0016949152542372e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4229/6000 [4:07:36<1:46:41,  3.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [4:07:40<1:48:23,  3.67s/it]                                                       {'loss': 0.0397, 'grad_norm': 7.284866809844971, 'learning_rate': 3e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4230/6000 [4:07:40<1:48:23,  3.67s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [4:07:44<1:48:49,  3.69s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.7513204216957092, 'learning_rate': 2.998305084745763e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4231/6000 [4:07:44<1:48:49,  3.69s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [4:07:47<1:46:21,  3.61s/it]                                                       {'loss': 0.03, 'grad_norm': 6.856269836425781, 'learning_rate': 2.9966101694915258e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4232/6000 [4:07:47<1:46:21,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [4:07:51<1:44:19,  3.54s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.6936607956886292, 'learning_rate': 2.994915254237288e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4233/6000 [4:07:51<1:44:19,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [4:07:54<1:42:49,  3.49s/it]                                                       {'loss': 0.0275, 'grad_norm': 5.147633075714111, 'learning_rate': 2.993220338983051e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4234/6000 [4:07:54<1:42:49,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [4:07:57<1:41:29,  3.45s/it]                                                       {'loss': 0.0231, 'grad_norm': 4.904159069061279, 'learning_rate': 2.991525423728814e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4235/6000 [4:07:57<1:41:29,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [4:08:01<1:40:47,  3.43s/it]                                                       {'loss': 0.0521, 'grad_norm': 10.24372673034668, 'learning_rate': 2.9898305084745768e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4236/6000 [4:08:01<1:40:47,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [4:08:05<1:44:57,  3.57s/it]                                                       {'loss': 0.0277, 'grad_norm': 6.815337181091309, 'learning_rate': 2.988135593220339e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4237/6000 [4:08:05<1:44:57,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [4:08:08<1:43:12,  3.51s/it]                                                       {'loss': 0.0567, 'grad_norm': 9.60558795928955, 'learning_rate': 2.986440677966102e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4238/6000 [4:08:08<1:43:12,  3.51s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [4:08:11<1:42:12,  3.48s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.4949842393398285, 'learning_rate': 2.984745762711865e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4239/6000 [4:08:11<1:42:12,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [4:08:15<1:41:06,  3.45s/it]                                                       {'loss': 0.0268, 'grad_norm': 2.552445650100708, 'learning_rate': 2.9830508474576277e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4240/6000 [4:08:15<1:41:06,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [4:08:18<1:40:39,  3.43s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.40881285071372986, 'learning_rate': 2.98135593220339e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4241/6000 [4:08:18<1:40:39,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [4:08:22<1:40:50,  3.44s/it]                                                       {'loss': 0.0058, 'grad_norm': 0.8516690731048584, 'learning_rate': 2.979661016949153e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4242/6000 [4:08:22<1:40:50,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [4:08:25<1:44:57,  3.58s/it]                                                       {'loss': 0.0941, 'grad_norm': 7.922375679016113, 'learning_rate': 2.977966101694916e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4243/6000 [4:08:25<1:44:57,  3.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [4:08:30<1:49:37,  3.75s/it]                                                       {'loss': 0.0034, 'grad_norm': 0.7417927384376526, 'learning_rate': 2.9762711864406783e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4244/6000 [4:08:30<1:49:37,  3.75s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [4:08:33<1:46:51,  3.65s/it]                                                       {'loss': 0.0911, 'grad_norm': 12.187687873840332, 'learning_rate': 2.9745762711864407e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4245/6000 [4:08:33<1:46:51,  3.65s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [4:08:37<1:47:52,  3.69s/it]                                                       {'loss': 0.0148, 'grad_norm': 5.525459289550781, 'learning_rate': 2.9728813559322036e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4246/6000 [4:08:37<1:47:52,  3.69s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [4:08:40<1:46:04,  3.63s/it]                                                       {'loss': 0.0896, 'grad_norm': 9.828657150268555, 'learning_rate': 2.971186440677966e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4247/6000 [4:08:40<1:46:04,  3.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [4:08:44<1:44:25,  3.58s/it]                                                       {'loss': 0.0183, 'grad_norm': 5.668237209320068, 'learning_rate': 2.969491525423729e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4248/6000 [4:08:44<1:44:25,  3.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [4:08:47<1:42:45,  3.52s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.32961490750312805, 'learning_rate': 2.9677966101694917e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4249/6000 [4:08:47<1:42:45,  3.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [4:08:51<1:43:07,  3.54s/it]                                                       {'loss': 0.1197, 'grad_norm': 14.191186904907227, 'learning_rate': 2.9661016949152545e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4250/6000 [4:08:51<1:43:07,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [4:08:54<1:41:45,  3.49s/it]                                                       {'loss': 0.035, 'grad_norm': 2.8149802684783936, 'learning_rate': 2.964406779661017e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4251/6000 [4:08:54<1:41:45,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [4:08:58<1:41:44,  3.49s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07147803157567978, 'learning_rate': 2.96271186440678e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4252/6000 [4:08:58<1:41:44,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [4:09:01<1:44:22,  3.58s/it]                                                       {'loss': 0.0484, 'grad_norm': 8.703314781188965, 'learning_rate': 2.9610169491525427e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4253/6000 [4:09:01<1:44:22,  3.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [4:09:05<1:42:37,  3.53s/it]                                                       {'loss': 0.0747, 'grad_norm': 4.901399612426758, 'learning_rate': 2.959322033898305e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4254/6000 [4:09:05<1:42:37,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [4:09:08<1:40:28,  3.45s/it]                                                       {'loss': 0.047, 'grad_norm': 5.502057075500488, 'learning_rate': 2.957627118644068e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4255/6000 [4:09:08<1:40:28,  3.45s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [4:09:11<1:39:52,  3.44s/it]                                                       {'loss': 0.0389, 'grad_norm': 6.823945045471191, 'learning_rate': 2.955932203389831e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4256/6000 [4:09:11<1:39:52,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [4:09:15<1:39:21,  3.42s/it]                                                       {'loss': 0.003, 'grad_norm': 1.098994255065918, 'learning_rate': 2.9542372881355936e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4257/6000 [4:09:15<1:39:21,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [4:09:18<1:38:54,  3.41s/it]                                                       {'loss': 0.0572, 'grad_norm': 7.021113395690918, 'learning_rate': 2.952542372881356e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4258/6000 [4:09:18<1:38:54,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [4:09:22<1:38:19,  3.39s/it]                                                       {'loss': 0.049, 'grad_norm': 7.063534259796143, 'learning_rate': 2.950847457627119e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4259/6000 [4:09:22<1:38:19,  3.39s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [4:09:25<1:38:03,  3.38s/it]                                                       {'loss': 0.016, 'grad_norm': 3.70882248878479, 'learning_rate': 2.9491525423728818e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4260/6000 [4:09:25<1:38:03,  3.38s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [4:09:28<1:39:21,  3.43s/it]                                                       {'loss': 0.2275, 'grad_norm': 14.070326805114746, 'learning_rate': 2.9474576271186446e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4261/6000 [4:09:28<1:39:21,  3.43s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [4:09:32<1:38:30,  3.40s/it]                                                       {'loss': 0.0472, 'grad_norm': 7.660802841186523, 'learning_rate': 2.945762711864407e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4262/6000 [4:09:32<1:38:30,  3.40s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [4:09:36<1:42:44,  3.55s/it]                                                       {'loss': 0.1787, 'grad_norm': 15.000743865966797, 'learning_rate': 2.94406779661017e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4263/6000 [4:09:36<1:42:44,  3.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [4:09:39<1:42:04,  3.53s/it]                                                       {'loss': 0.0483, 'grad_norm': 7.433037757873535, 'learning_rate': 2.9423728813559327e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4264/6000 [4:09:39<1:42:04,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [4:09:43<1:40:44,  3.48s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.5802589654922485, 'learning_rate': 2.9406779661016956e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4265/6000 [4:09:43<1:40:44,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [4:09:46<1:38:48,  3.42s/it]                                                       {'loss': 0.1223, 'grad_norm': 13.665081977844238, 'learning_rate': 2.9389830508474576e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4266/6000 [4:09:46<1:38:48,  3.42s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [4:09:49<1:39:20,  3.44s/it]                                                       {'loss': 0.0243, 'grad_norm': 5.0493059158325195, 'learning_rate': 2.9372881355932204e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4267/6000 [4:09:49<1:39:20,  3.44s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [4:09:53<1:38:25,  3.41s/it]                                                       {'loss': 0.0033, 'grad_norm': 1.292177438735962, 'learning_rate': 2.935593220338983e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4268/6000 [4:09:53<1:38:25,  3.41s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [4:09:56<1:40:44,  3.49s/it]                                                       {'loss': 0.0568, 'grad_norm': 8.717686653137207, 'learning_rate': 2.9338983050847457e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4269/6000 [4:09:56<1:40:44,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [4:10:00<1:42:21,  3.55s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.40832117199897766, 'learning_rate': 2.9322033898305086e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4270/6000 [4:10:00<1:42:21,  3.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [4:10:04<1:44:40,  3.63s/it]                                                       {'loss': 0.0471, 'grad_norm': 6.517880916595459, 'learning_rate': 2.9305084745762714e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4271/6000 [4:10:04<1:44:40,  3.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [4:10:07<1:42:47,  3.57s/it]                                                       {'loss': 0.019, 'grad_norm': 5.081037998199463, 'learning_rate': 2.928813559322034e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4272/6000 [4:10:07<1:42:47,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [4:10:11<1:41:29,  3.53s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.059316959232091904, 'learning_rate': 2.9271186440677967e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4273/6000 [4:10:11<1:41:29,  3.53s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [4:10:14<1:39:31,  3.46s/it]                                                       {'loss': 0.0098, 'grad_norm': 4.232940196990967, 'learning_rate': 2.9254237288135596e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4274/6000 [4:10:14<1:39:31,  3.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [4:10:18<1:40:04,  3.48s/it]                                                       {'loss': 0.1236, 'grad_norm': 8.774188041687012, 'learning_rate': 2.9237288135593224e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4275/6000 [4:10:18<1:40:04,  3.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [4:10:21<1:39:46,  3.47s/it]                                                       {'loss': 0.0444, 'grad_norm': 8.948234558105469, 'learning_rate': 2.922033898305085e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4276/6000 [4:10:21<1:39:46,  3.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [4:10:25<1:45:00,  3.66s/it]                                                       {'loss': 0.02, 'grad_norm': 3.514251232147217, 'learning_rate': 2.9203389830508477e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4277/6000 [4:10:25<1:45:00,  3.66s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [4:10:29<1:46:19,  3.70s/it]                                                       {'loss': 0.1678, 'grad_norm': 18.911489486694336, 'learning_rate': 2.9186440677966105e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4278/6000 [4:10:29<1:46:19,  3.70s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [4:10:32<1:43:09,  3.60s/it]                                                       {'loss': 0.0839, 'grad_norm': 12.322364807128906, 'learning_rate': 2.9169491525423734e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4279/6000 [4:10:32<1:43:09,  3.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [4:10:36<1:42:13,  3.57s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.26987016201019287, 'learning_rate': 2.915254237288136e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4280/6000 [4:10:36<1:42:13,  3.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [4:10:39<1:40:20,  3.50s/it]                                                       {'loss': 0.1574, 'grad_norm': 16.983112335205078, 'learning_rate': 2.9135593220338987e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4281/6000 [4:10:39<1:40:20,  3.50s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [4:10:42<1:39:12,  3.46s/it]                                                       {'loss': 0.0129, 'grad_norm': 3.8009579181671143, 'learning_rate': 2.9118644067796615e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4282/6000 [4:10:42<1:39:12,  3.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [4:10:46<1:39:14,  3.47s/it]                                                       {'loss': 0.0322, 'grad_norm': 7.252187252044678, 'learning_rate': 2.9101694915254244e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4283/6000 [4:10:46<1:39:14,  3.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [4:10:50<1:43:17,  3.61s/it]                                                       {'loss': 0.1474, 'grad_norm': 13.189379692077637, 'learning_rate': 2.9084745762711868e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4284/6000 [4:10:50<1:43:17,  3.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [4:10:53<1:40:38,  3.52s/it]                                                       {'loss': 0.0086, 'grad_norm': 2.044475793838501, 'learning_rate': 2.9067796610169496e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4285/6000 [4:10:53<1:40:38,  3.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [4:10:57<1:41:13,  3.54s/it]                                                       {'loss': 0.0142, 'grad_norm': 3.274156093597412, 'learning_rate': 2.9050847457627125e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4286/6000 [4:10:57<1:41:13,  3.54s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [4:11:00<1:39:40,  3.49s/it]                                                       {'loss': 0.0309, 'grad_norm': 7.751239776611328, 'learning_rate': 2.9033898305084745e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4287/6000 [4:11:00<1:39:40,  3.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [4:11:04<1:38:44,  3.46s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.28277042508125305, 'learning_rate': 2.9016949152542373e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4288/6000 [4:11:04<1:38:44,  3.46s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [4:11:07<1:37:42,  3.43s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.21146810054779053, 'learning_rate': 2.9e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4289/6000 [4:11:07<1:37:42,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [4:11:10<1:36:35,  3.39s/it]                                                       {'loss': 0.0685, 'grad_norm': 11.676572799682617, 'learning_rate': 2.8983050847457626e-06, 'epoch': 0.71}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4290/6000 [4:11:10<1:36:35,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [4:11:14<1:36:44,  3.40s/it]                                                       {'loss': 0.0269, 'grad_norm': 3.887667179107666, 'learning_rate': 2.8966101694915255e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4291/6000 [4:11:14<1:36:44,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [4:11:17<1:36:12,  3.38s/it]                                                       {'loss': 0.0031, 'grad_norm': 1.0658482313156128, 'learning_rate': 2.8949152542372883e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4292/6000 [4:11:17<1:36:12,  3.38s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [4:11:20<1:36:24,  3.39s/it]                                                       {'loss': 0.0651, 'grad_norm': 11.96653938293457, 'learning_rate': 2.893220338983051e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4293/6000 [4:11:20<1:36:24,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [4:11:24<1:36:15,  3.39s/it]                                                       {'loss': 0.0265, 'grad_norm': 7.890181541442871, 'learning_rate': 2.8915254237288136e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4294/6000 [4:11:24<1:36:15,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [4:11:27<1:36:12,  3.39s/it]                                                       {'loss': 0.0796, 'grad_norm': 11.247115135192871, 'learning_rate': 2.8898305084745764e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4295/6000 [4:11:27<1:36:12,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [4:11:31<1:39:29,  3.50s/it]                                                       {'loss': 0.2937, 'grad_norm': 15.98416519165039, 'learning_rate': 2.8881355932203393e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4296/6000 [4:11:31<1:39:29,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [4:11:34<1:38:47,  3.48s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.2762930691242218, 'learning_rate': 2.886440677966102e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4297/6000 [4:11:34<1:38:47,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [4:11:38<1:42:42,  3.62s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.4584088325500488, 'learning_rate': 2.8847457627118646e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4298/6000 [4:11:38<1:42:42,  3.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [4:11:42<1:40:17,  3.54s/it]                                                       {'loss': 0.0205, 'grad_norm': 4.0705060958862305, 'learning_rate': 2.8830508474576274e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4299/6000 [4:11:42<1:40:17,  3.54s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [4:11:45<1:38:52,  3.49s/it]                                                       {'loss': 0.032, 'grad_norm': 3.514188051223755, 'learning_rate': 2.8813559322033903e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4300/6000 [4:11:45<1:38:52,  3.49s/it][2025-11-07 03:02:55,012] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4300
[2025-11-07 03:02:55,026] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:02:56,052] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4300/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [4:11:51<2:01:08,  4.28s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.47018134593963623, 'learning_rate': 2.8796610169491527e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4301/6000 [4:11:51<2:01:08,  4.28s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [4:11:55<1:53:24,  4.01s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.2076980024576187, 'learning_rate': 2.8779661016949155e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4302/6000 [4:11:55<1:53:24,  4.01s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [4:11:58<1:47:22,  3.80s/it]                                                       {'loss': 0.0061, 'grad_norm': 2.0198447704315186, 'learning_rate': 2.8762711864406784e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4303/6000 [4:11:58<1:47:22,  3.80s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [4:12:02<1:47:14,  3.79s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.6036939024925232, 'learning_rate': 2.8745762711864412e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4304/6000 [4:12:02<1:47:14,  3.79s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [4:12:05<1:44:04,  3.68s/it]                                                       {'loss': 0.1995, 'grad_norm': 15.475448608398438, 'learning_rate': 2.8728813559322037e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4305/6000 [4:12:05<1:44:04,  3.68s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [4:12:09<1:45:51,  3.75s/it]                                                       {'loss': 0.0216, 'grad_norm': 5.978724002838135, 'learning_rate': 2.8711864406779665e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4306/6000 [4:12:09<1:45:51,  3.75s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [4:12:12<1:42:20,  3.63s/it]                                                       {'loss': 0.0565, 'grad_norm': 8.265109062194824, 'learning_rate': 2.869491525423729e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4307/6000 [4:12:12<1:42:20,  3.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [4:12:16<1:40:50,  3.58s/it]                                                       {'loss': 0.0075, 'grad_norm': 1.07550847530365, 'learning_rate': 2.8677966101694914e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4308/6000 [4:12:16<1:40:50,  3.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [4:12:19<1:38:06,  3.48s/it]                                                       {'loss': 0.1066, 'grad_norm': 9.492374420166016, 'learning_rate': 2.8661016949152542e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4309/6000 [4:12:19<1:38:06,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [4:12:22<1:36:27,  3.42s/it]                                                       {'loss': 0.0116, 'grad_norm': 2.2209420204162598, 'learning_rate': 2.864406779661017e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4310/6000 [4:12:22<1:36:27,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [4:12:26<1:36:53,  3.44s/it]                                                       {'loss': 0.4153, 'grad_norm': 17.31418228149414, 'learning_rate': 2.86271186440678e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4311/6000 [4:12:26<1:36:53,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [4:12:29<1:38:48,  3.51s/it]                                                       {'loss': 0.0109, 'grad_norm': 2.823117256164551, 'learning_rate': 2.8610169491525424e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4312/6000 [4:12:29<1:38:48,  3.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [4:12:33<1:37:38,  3.47s/it]                                                       {'loss': 0.0246, 'grad_norm': 5.851914405822754, 'learning_rate': 2.859322033898305e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4313/6000 [4:12:33<1:37:38,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [4:12:36<1:36:19,  3.43s/it]                                                       {'loss': 0.1161, 'grad_norm': 13.4624605178833, 'learning_rate': 2.857627118644068e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4314/6000 [4:12:36<1:36:19,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [4:12:40<1:41:15,  3.61s/it]                                                       {'loss': 0.1188, 'grad_norm': 12.720563888549805, 'learning_rate': 2.8559322033898305e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4315/6000 [4:12:40<1:41:15,  3.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [4:12:44<1:41:36,  3.62s/it]                                                       {'loss': 0.0848, 'grad_norm': 7.261957168579102, 'learning_rate': 2.8542372881355933e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4316/6000 [4:12:44<1:41:36,  3.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [4:12:47<1:39:54,  3.56s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.5273883938789368, 'learning_rate': 2.852542372881356e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4317/6000 [4:12:47<1:39:54,  3.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [4:12:51<1:38:45,  3.52s/it]                                                       {'loss': 0.0138, 'grad_norm': 3.7315738201141357, 'learning_rate': 2.850847457627119e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/6000 [4:12:51<1:38:45,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [4:12:54<1:38:00,  3.50s/it]                                                       {'loss': 0.186, 'grad_norm': 15.882631301879883, 'learning_rate': 2.8491525423728815e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4319/6000 [4:12:54<1:38:00,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [4:12:58<1:37:08,  3.47s/it]                                                       {'loss': 0.1852, 'grad_norm': 12.756394386291504, 'learning_rate': 2.8474576271186443e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4320/6000 [4:12:58<1:37:08,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [4:13:01<1:38:27,  3.52s/it]                                                       {'loss': 0.2739, 'grad_norm': 17.27334213256836, 'learning_rate': 2.845762711864407e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4321/6000 [4:13:01<1:38:27,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [4:13:05<1:37:54,  3.50s/it]                                                       {'loss': 0.114, 'grad_norm': 10.070609092712402, 'learning_rate': 2.84406779661017e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4322/6000 [4:13:05<1:37:54,  3.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [4:13:08<1:36:35,  3.46s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.83835369348526, 'learning_rate': 2.8423728813559324e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4323/6000 [4:13:08<1:36:35,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [4:13:11<1:35:34,  3.42s/it]                                                       {'loss': 0.019, 'grad_norm': 5.500241279602051, 'learning_rate': 2.8406779661016953e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4324/6000 [4:13:11<1:35:34,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [4:13:15<1:36:43,  3.46s/it]                                                       {'loss': 0.0397, 'grad_norm': 7.838232040405273, 'learning_rate': 2.838983050847458e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4325/6000 [4:13:15<1:36:43,  3.46s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [4:13:19<1:39:03,  3.55s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.358064740896225, 'learning_rate': 2.837288135593221e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4326/6000 [4:13:19<1:39:03,  3.55s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [4:13:22<1:38:10,  3.52s/it]                                                       {'loss': 0.0942, 'grad_norm': 8.115756034851074, 'learning_rate': 2.8355932203389834e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4327/6000 [4:13:22<1:38:10,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [4:13:25<1:36:12,  3.45s/it]                                                       {'loss': 0.0086, 'grad_norm': 1.4554028511047363, 'learning_rate': 2.833898305084746e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4328/6000 [4:13:25<1:36:12,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [4:13:29<1:35:13,  3.42s/it]                                                       {'loss': 0.1348, 'grad_norm': 8.01357364654541, 'learning_rate': 2.8322033898305083e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4329/6000 [4:13:29<1:35:13,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [4:13:32<1:34:38,  3.40s/it]                                                       {'loss': 0.0191, 'grad_norm': 3.547429084777832, 'learning_rate': 2.830508474576271e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4330/6000 [4:13:32<1:34:38,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [4:13:36<1:38:02,  3.52s/it]                                                       {'loss': 0.0408, 'grad_norm': 7.106726169586182, 'learning_rate': 2.828813559322034e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4331/6000 [4:13:36<1:38:02,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [4:13:39<1:36:37,  3.48s/it]                                                       {'loss': 0.0564, 'grad_norm': 7.79335880279541, 'learning_rate': 2.827118644067797e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4332/6000 [4:13:39<1:36:37,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [4:13:43<1:37:47,  3.52s/it]                                                       {'loss': 0.0238, 'grad_norm': 4.34542989730835, 'learning_rate': 2.8254237288135592e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4333/6000 [4:13:43<1:37:47,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [4:13:46<1:36:39,  3.48s/it]                                                       {'loss': 0.0138, 'grad_norm': 2.5073883533477783, 'learning_rate': 2.823728813559322e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4334/6000 [4:13:46<1:36:39,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [4:13:50<1:36:12,  3.47s/it]                                                       {'loss': 0.0181, 'grad_norm': 3.6923282146453857, 'learning_rate': 2.822033898305085e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4335/6000 [4:13:50<1:36:12,  3.47s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [4:13:53<1:35:38,  3.45s/it]                                                       {'loss': 0.01, 'grad_norm': 1.8495134115219116, 'learning_rate': 2.820338983050848e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4336/6000 [4:13:53<1:35:38,  3.45s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [4:13:56<1:34:26,  3.41s/it]                                                       {'loss': 0.0228, 'grad_norm': 3.398883581161499, 'learning_rate': 2.8186440677966102e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4337/6000 [4:13:56<1:34:26,  3.41s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [4:14:00<1:33:32,  3.38s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.14756456017494202, 'learning_rate': 2.816949152542373e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4338/6000 [4:14:00<1:33:32,  3.38s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [4:14:03<1:32:58,  3.36s/it]                                                       {'loss': 0.097, 'grad_norm': 10.810454368591309, 'learning_rate': 2.815254237288136e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4339/6000 [4:14:03<1:32:58,  3.36s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [4:14:06<1:33:05,  3.36s/it]                                                       {'loss': 0.0128, 'grad_norm': 3.6730144023895264, 'learning_rate': 2.8135593220338988e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4340/6000 [4:14:06<1:33:05,  3.36s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [4:14:10<1:33:30,  3.38s/it]                                                       {'loss': 0.0085, 'grad_norm': 1.8641124963760376, 'learning_rate': 2.811864406779661e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4341/6000 [4:14:10<1:33:30,  3.38s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [4:14:13<1:33:48,  3.39s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0807899460196495, 'learning_rate': 2.810169491525424e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4342/6000 [4:14:13<1:33:48,  3.39s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [4:14:17<1:34:21,  3.42s/it]                                                       {'loss': 0.0273, 'grad_norm': 7.545764923095703, 'learning_rate': 2.808474576271187e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4343/6000 [4:14:17<1:34:21,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [4:14:20<1:34:16,  3.42s/it]                                                       {'loss': 0.1207, 'grad_norm': 9.342835426330566, 'learning_rate': 2.8067796610169497e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4344/6000 [4:14:20<1:34:16,  3.42s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [4:14:24<1:34:59,  3.44s/it]                                                       {'loss': 0.1607, 'grad_norm': 15.75479507446289, 'learning_rate': 2.805084745762712e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4345/6000 [4:14:24<1:34:59,  3.44s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [4:14:27<1:34:25,  3.43s/it]                                                       {'loss': 0.1736, 'grad_norm': 18.359102249145508, 'learning_rate': 2.803389830508475e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4346/6000 [4:14:27<1:34:25,  3.43s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [4:14:30<1:33:40,  3.40s/it]                                                       {'loss': 0.0205, 'grad_norm': 5.086117744445801, 'learning_rate': 2.801694915254238e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4347/6000 [4:14:30<1:33:40,  3.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [4:14:34<1:36:56,  3.52s/it]                                                       {'loss': 0.0146, 'grad_norm': 4.643838882446289, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4348/6000 [4:14:34<1:36:56,  3.52s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [4:14:38<1:35:42,  3.48s/it]                                                       {'loss': 0.0285, 'grad_norm': 5.280295372009277, 'learning_rate': 2.7983050847457627e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4349/6000 [4:14:38<1:35:42,  3.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [4:14:41<1:35:32,  3.47s/it]                                                       {'loss': 0.0364, 'grad_norm': 5.69910192489624, 'learning_rate': 2.7966101694915256e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4350/6000 [4:14:41<1:35:32,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [4:14:44<1:35:04,  3.46s/it]                                                       {'loss': 0.0565, 'grad_norm': 11.247365951538086, 'learning_rate': 2.794915254237288e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4351/6000 [4:14:44<1:35:04,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [4:14:48<1:35:27,  3.48s/it]                                                       {'loss': 0.0405, 'grad_norm': 7.589136600494385, 'learning_rate': 2.793220338983051e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4352/6000 [4:14:48<1:35:27,  3.48s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [4:14:52<1:36:14,  3.51s/it]                                                       {'loss': 0.0066, 'grad_norm': 2.609182834625244, 'learning_rate': 2.7915254237288137e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4353/6000 [4:14:52<1:36:14,  3.51s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [4:14:55<1:35:14,  3.47s/it]                                                       {'loss': 0.0203, 'grad_norm': 2.8114142417907715, 'learning_rate': 2.7898305084745766e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4354/6000 [4:14:55<1:35:14,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [4:14:58<1:34:21,  3.44s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.187240719795227, 'learning_rate': 2.788135593220339e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4355/6000 [4:14:58<1:34:21,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [4:15:02<1:37:37,  3.56s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.22691431641578674, 'learning_rate': 2.786440677966102e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4356/6000 [4:15:02<1:37:37,  3.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [4:15:06<1:36:34,  3.53s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.10394179075956345, 'learning_rate': 2.7847457627118647e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4357/6000 [4:15:06<1:36:34,  3.53s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [4:15:09<1:35:34,  3.49s/it]                                                       {'loss': 0.3676, 'grad_norm': 10.982063293457031, 'learning_rate': 2.7830508474576275e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4358/6000 [4:15:09<1:35:34,  3.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [4:15:12<1:33:54,  3.43s/it]                                                       {'loss': 0.0215, 'grad_norm': 4.774240016937256, 'learning_rate': 2.78135593220339e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4359/6000 [4:15:12<1:33:54,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [4:15:16<1:34:35,  3.46s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.6463823318481445, 'learning_rate': 2.779661016949153e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4360/6000 [4:15:16<1:34:35,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [4:15:19<1:33:44,  3.43s/it]                                                       {'loss': 0.0815, 'grad_norm': 11.573244094848633, 'learning_rate': 2.7779661016949157e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4361/6000 [4:15:19<1:33:44,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [4:15:23<1:33:04,  3.41s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.11997117847204208, 'learning_rate': 2.776271186440678e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4362/6000 [4:15:23<1:33:04,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [4:15:26<1:34:23,  3.46s/it]                                                       {'loss': 0.0657, 'grad_norm': 7.2094526290893555, 'learning_rate': 2.774576271186441e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4363/6000 [4:15:26<1:34:23,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [4:15:30<1:34:26,  3.46s/it]                                                       {'loss': 0.002, 'grad_norm': 1.0534940958023071, 'learning_rate': 2.7728813559322038e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4364/6000 [4:15:30<1:34:26,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [4:15:33<1:34:08,  3.45s/it]                                                       {'loss': 0.021, 'grad_norm': 5.247344017028809, 'learning_rate': 2.7711864406779666e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4365/6000 [4:15:33<1:34:08,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [4:15:36<1:33:49,  3.45s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.8788202404975891, 'learning_rate': 2.769491525423729e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4366/6000 [4:15:36<1:33:49,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [4:15:40<1:33:20,  3.43s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.4546974897384644, 'learning_rate': 2.767796610169492e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4367/6000 [4:15:40<1:33:20,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [4:15:43<1:32:31,  3.40s/it]                                                       {'loss': 0.0321, 'grad_norm': 8.319194793701172, 'learning_rate': 2.7661016949152548e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4368/6000 [4:15:43<1:32:31,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [4:15:47<1:32:26,  3.40s/it]                                                       {'loss': 0.1405, 'grad_norm': 11.278693199157715, 'learning_rate': 2.7644067796610176e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/6000 [4:15:47<1:32:26,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [4:15:50<1:32:36,  3.41s/it]                                                       {'loss': 0.1676, 'grad_norm': 14.281868934631348, 'learning_rate': 2.7627118644067796e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4370/6000 [4:15:50<1:32:36,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [4:15:53<1:32:54,  3.42s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07147528231143951, 'learning_rate': 2.7610169491525425e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4371/6000 [4:15:53<1:32:54,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [4:15:57<1:32:45,  3.42s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.4756399691104889, 'learning_rate': 2.7593220338983053e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4372/6000 [4:15:57<1:32:45,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [4:16:00<1:34:00,  3.47s/it]                                                       {'loss': 0.0185, 'grad_norm': 2.8712806701660156, 'learning_rate': 2.7576271186440677e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4373/6000 [4:16:00<1:34:00,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [4:16:04<1:33:44,  3.46s/it]                                                       {'loss': 0.0159, 'grad_norm': 2.6721668243408203, 'learning_rate': 2.7559322033898306e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4374/6000 [4:16:04<1:33:44,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [4:16:07<1:32:50,  3.43s/it]                                                       {'loss': 0.0377, 'grad_norm': 6.70404052734375, 'learning_rate': 2.7542372881355934e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4375/6000 [4:16:07<1:32:50,  3.43s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [4:16:11<1:33:51,  3.47s/it]                                                       {'loss': 0.0387, 'grad_norm': 3.9409587383270264, 'learning_rate': 2.752542372881356e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4376/6000 [4:16:11<1:33:51,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [4:16:14<1:33:49,  3.47s/it]                                                       {'loss': 0.0283, 'grad_norm': 4.7999091148376465, 'learning_rate': 2.7508474576271187e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4377/6000 [4:16:14<1:33:49,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [4:16:18<1:33:44,  3.47s/it]                                                       {'loss': 0.0122, 'grad_norm': 2.9697999954223633, 'learning_rate': 2.7491525423728816e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4378/6000 [4:16:18<1:33:44,  3.47s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [4:16:21<1:33:29,  3.46s/it]                                                       {'loss': 0.0329, 'grad_norm': 4.206523895263672, 'learning_rate': 2.7474576271186444e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4379/6000 [4:16:21<1:33:29,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [4:16:24<1:31:55,  3.40s/it]                                                       {'loss': 0.0101, 'grad_norm': 2.8477060794830322, 'learning_rate': 2.745762711864407e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4380/6000 [4:16:24<1:31:55,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [4:16:28<1:33:09,  3.45s/it]                                                       {'loss': 0.0394, 'grad_norm': 7.313256740570068, 'learning_rate': 2.7440677966101697e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4381/6000 [4:16:28<1:33:09,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [4:16:31<1:32:02,  3.41s/it]                                                       {'loss': 0.1947, 'grad_norm': 13.872919082641602, 'learning_rate': 2.7423728813559325e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4382/6000 [4:16:31<1:32:02,  3.41s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [4:16:35<1:32:52,  3.45s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.3906329572200775, 'learning_rate': 2.7406779661016954e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4383/6000 [4:16:35<1:32:52,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [4:16:38<1:32:03,  3.42s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.0866554975509644, 'learning_rate': 2.738983050847458e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4384/6000 [4:16:38<1:32:03,  3.42s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [4:16:42<1:31:28,  3.40s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02063288912177086, 'learning_rate': 2.7372881355932207e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/6000 [4:16:42<1:31:28,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [4:16:46<1:37:05,  3.61s/it]                                                       {'loss': 0.121, 'grad_norm': 21.30031967163086, 'learning_rate': 2.7355932203389835e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4386/6000 [4:16:46<1:37:05,  3.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [4:16:49<1:35:20,  3.55s/it]                                                       {'loss': 0.0332, 'grad_norm': 6.299863815307617, 'learning_rate': 2.7338983050847464e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4387/6000 [4:16:49<1:35:20,  3.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [4:16:53<1:35:00,  3.54s/it]                                                       {'loss': 0.0195, 'grad_norm': 5.321997165679932, 'learning_rate': 2.732203389830509e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4388/6000 [4:16:53<1:35:00,  3.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [4:16:56<1:37:56,  3.65s/it]                                                       {'loss': 0.0066, 'grad_norm': 1.161219596862793, 'learning_rate': 2.7305084745762716e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4389/6000 [4:16:56<1:37:56,  3.65s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [4:17:00<1:36:51,  3.61s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08092818409204483, 'learning_rate': 2.7288135593220336e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4390/6000 [4:17:00<1:36:51,  3.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [4:17:04<1:36:25,  3.60s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012262081727385521, 'learning_rate': 2.7271186440677965e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4391/6000 [4:17:04<1:36:25,  3.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [4:17:07<1:35:40,  3.57s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.22626802325248718, 'learning_rate': 2.7254237288135593e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4392/6000 [4:17:07<1:35:40,  3.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [4:17:10<1:33:42,  3.50s/it]                                                       {'loss': 0.0059, 'grad_norm': 1.1466984748840332, 'learning_rate': 2.723728813559322e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4393/6000 [4:17:10<1:33:42,  3.50s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [4:17:14<1:32:37,  3.46s/it]                                                       {'loss': 0.2039, 'grad_norm': 15.038130760192871, 'learning_rate': 2.7220338983050846e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4394/6000 [4:17:14<1:32:37,  3.46s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [4:17:17<1:31:00,  3.40s/it]                                                       {'loss': 0.2355, 'grad_norm': 17.068401336669922, 'learning_rate': 2.7203389830508475e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4395/6000 [4:17:17<1:31:00,  3.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [4:17:20<1:30:14,  3.38s/it]                                                       {'loss': 0.0167, 'grad_norm': 2.4934113025665283, 'learning_rate': 2.7186440677966103e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4396/6000 [4:17:20<1:30:14,  3.38s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [4:17:24<1:34:08,  3.52s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.6951638460159302, 'learning_rate': 2.716949152542373e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4397/6000 [4:17:24<1:34:08,  3.52s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [4:17:28<1:32:14,  3.45s/it]                                                       {'loss': 0.0936, 'grad_norm': 7.762680530548096, 'learning_rate': 2.7152542372881356e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4398/6000 [4:17:28<1:32:14,  3.45s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [4:17:31<1:31:46,  3.44s/it]                                                       {'loss': 0.2361, 'grad_norm': 17.189632415771484, 'learning_rate': 2.7135593220338985e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4399/6000 [4:17:31<1:31:46,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [4:17:34<1:31:16,  3.42s/it]                                                       {'loss': 0.001, 'grad_norm': 0.2416403442621231, 'learning_rate': 2.7118644067796613e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4400/6000 [4:17:34<1:31:16,  3.42s/it][2025-11-07 03:08:44,309] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4400
[2025-11-07 03:08:44,323] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:08:44,964] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4400/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [4:17:40<1:49:04,  4.09s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.42104074358940125, 'learning_rate': 2.710169491525424e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4401/6000 [4:17:40<1:49:04,  4.09s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [4:17:43<1:43:24,  3.88s/it]                                                       {'loss': 0.0534, 'grad_norm': 7.355954647064209, 'learning_rate': 2.7084745762711866e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4402/6000 [4:17:43<1:43:24,  3.88s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [4:17:47<1:39:53,  3.75s/it]                                                       {'loss': 0.044, 'grad_norm': 5.8128461837768555, 'learning_rate': 2.7067796610169494e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4403/6000 [4:17:47<1:39:53,  3.75s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [4:17:50<1:37:59,  3.68s/it]                                                       {'loss': 0.0387, 'grad_norm': 5.927413463592529, 'learning_rate': 2.7050847457627123e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4404/6000 [4:17:50<1:37:59,  3.68s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [4:17:54<1:36:09,  3.62s/it]                                                       {'loss': 0.0193, 'grad_norm': 4.605554103851318, 'learning_rate': 2.703389830508475e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4405/6000 [4:17:54<1:36:09,  3.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [4:17:57<1:34:04,  3.54s/it]                                                       {'loss': 0.0125, 'grad_norm': 3.811284303665161, 'learning_rate': 2.7016949152542376e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4406/6000 [4:17:57<1:34:04,  3.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [4:18:01<1:32:49,  3.50s/it]                                                       {'loss': 0.0055, 'grad_norm': 1.3224526643753052, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4407/6000 [4:18:01<1:32:49,  3.50s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [4:18:04<1:31:16,  3.44s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.12724444270133972, 'learning_rate': 2.6983050847457633e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4408/6000 [4:18:04<1:31:16,  3.44s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [4:18:07<1:30:19,  3.41s/it]                                                       {'loss': 0.0216, 'grad_norm': 5.352802753448486, 'learning_rate': 2.6966101694915257e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4409/6000 [4:18:07<1:30:19,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [4:18:10<1:29:20,  3.37s/it]                                                       {'loss': 0.1101, 'grad_norm': 12.93508529663086, 'learning_rate': 2.6949152542372885e-06, 'epoch': 0.73}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4410/6000 [4:18:10<1:29:20,  3.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [4:18:14<1:28:51,  3.36s/it]                                                       {'loss': 0.0036, 'grad_norm': 0.902794361114502, 'learning_rate': 2.693220338983051e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4411/6000 [4:18:14<1:28:51,  3.36s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [4:18:17<1:28:20,  3.34s/it]                                                       {'loss': 0.0652, 'grad_norm': 7.846073627471924, 'learning_rate': 2.6915254237288134e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4412/6000 [4:18:17<1:28:20,  3.34s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [4:18:21<1:28:53,  3.36s/it]                                                       {'loss': 0.0614, 'grad_norm': 9.682884216308594, 'learning_rate': 2.6898305084745762e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4413/6000 [4:18:21<1:28:53,  3.36s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [4:18:24<1:29:54,  3.40s/it]                                                       {'loss': 0.0642, 'grad_norm': 12.368317604064941, 'learning_rate': 2.688135593220339e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4414/6000 [4:18:24<1:29:54,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [4:18:27<1:29:41,  3.40s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.127908855676651, 'learning_rate': 2.686440677966102e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4415/6000 [4:18:27<1:29:41,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [4:18:31<1:29:52,  3.40s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5513495802879333, 'learning_rate': 2.6847457627118644e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4416/6000 [4:18:31<1:29:52,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [4:18:35<1:32:26,  3.50s/it]                                                       {'loss': 0.3473, 'grad_norm': 21.97724151611328, 'learning_rate': 2.6830508474576272e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4417/6000 [4:18:35<1:32:26,  3.50s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [4:18:38<1:31:37,  3.47s/it]                                                       {'loss': 0.1354, 'grad_norm': 17.347009658813477, 'learning_rate': 2.68135593220339e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4418/6000 [4:18:38<1:31:37,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [4:18:41<1:30:34,  3.44s/it]                                                       {'loss': 0.0032, 'grad_norm': 0.5058462023735046, 'learning_rate': 2.679661016949153e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4419/6000 [4:18:41<1:30:34,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [4:18:45<1:29:48,  3.41s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.06579650193452835, 'learning_rate': 2.6779661016949153e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4420/6000 [4:18:45<1:29:48,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [4:18:48<1:28:43,  3.37s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.8494789600372314, 'learning_rate': 2.676271186440678e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4421/6000 [4:18:48<1:28:43,  3.37s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [4:18:51<1:29:08,  3.39s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.8209199905395508, 'learning_rate': 2.674576271186441e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4422/6000 [4:18:51<1:29:08,  3.39s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [4:18:55<1:28:15,  3.36s/it]                                                       {'loss': 0.0915, 'grad_norm': 13.104388236999512, 'learning_rate': 2.6728813559322035e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4423/6000 [4:18:55<1:28:15,  3.36s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [4:18:59<1:32:45,  3.53s/it]                                                       {'loss': 0.0, 'grad_norm': 0.009956986643373966, 'learning_rate': 2.6711864406779663e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4424/6000 [4:18:59<1:32:45,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [4:19:02<1:31:03,  3.47s/it]                                                       {'loss': 0.2724, 'grad_norm': 12.16264533996582, 'learning_rate': 2.669491525423729e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4425/6000 [4:19:02<1:31:03,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [4:19:05<1:29:49,  3.42s/it]                                                       {'loss': 0.0278, 'grad_norm': 6.884969234466553, 'learning_rate': 2.667796610169492e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4426/6000 [4:19:05<1:29:49,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [4:19:09<1:30:31,  3.45s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.027201926335692406, 'learning_rate': 2.6661016949152544e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4427/6000 [4:19:09<1:30:31,  3.45s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [4:19:12<1:29:36,  3.42s/it]                                                       {'loss': 0.0211, 'grad_norm': 3.5843069553375244, 'learning_rate': 2.6644067796610173e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4428/6000 [4:19:12<1:29:36,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [4:19:15<1:29:15,  3.41s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.4511982202529907, 'learning_rate': 2.66271186440678e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4429/6000 [4:19:15<1:29:15,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [4:19:19<1:28:23,  3.38s/it]                                                       {'loss': 0.0053, 'grad_norm': 1.1851799488067627, 'learning_rate': 2.661016949152543e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4430/6000 [4:19:19<1:28:23,  3.38s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [4:19:22<1:29:48,  3.43s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0655498132109642, 'learning_rate': 2.6593220338983054e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4431/6000 [4:19:22<1:29:48,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [4:19:26<1:28:49,  3.40s/it]                                                       {'loss': 0.031, 'grad_norm': 5.254816055297852, 'learning_rate': 2.657627118644068e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4432/6000 [4:19:26<1:28:49,  3.40s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [4:19:29<1:29:06,  3.41s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.563704252243042, 'learning_rate': 2.6559322033898307e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4433/6000 [4:19:29<1:29:06,  3.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [4:19:33<1:29:30,  3.43s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.1422622203826904, 'learning_rate': 2.654237288135593e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4434/6000 [4:19:33<1:29:30,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [4:19:36<1:30:33,  3.47s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.088198184967041, 'learning_rate': 2.652542372881356e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4435/6000 [4:19:36<1:30:33,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [4:19:39<1:29:34,  3.44s/it]                                                       {'loss': 0.0129, 'grad_norm': 1.7170683145523071, 'learning_rate': 2.650847457627119e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4436/6000 [4:19:39<1:29:34,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [4:19:43<1:30:11,  3.46s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.6853625774383545, 'learning_rate': 2.6491525423728813e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4437/6000 [4:19:43<1:30:11,  3.46s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [4:19:46<1:29:04,  3.42s/it]                                                       {'loss': 0.026, 'grad_norm': 4.141108989715576, 'learning_rate': 2.647457627118644e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4438/6000 [4:19:46<1:29:04,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [4:19:50<1:31:53,  3.53s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.3921486735343933, 'learning_rate': 2.645762711864407e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4439/6000 [4:19:50<1:31:53,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [4:19:54<1:30:40,  3.49s/it]                                                       {'loss': 0.1491, 'grad_norm': 13.631104469299316, 'learning_rate': 2.64406779661017e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4440/6000 [4:19:54<1:30:40,  3.49s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [4:19:57<1:29:41,  3.45s/it]                                                       {'loss': 0.1237, 'grad_norm': 13.105053901672363, 'learning_rate': 2.6423728813559322e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4441/6000 [4:19:57<1:29:41,  3.45s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [4:20:00<1:29:45,  3.46s/it]                                                       {'loss': 0.0273, 'grad_norm': 6.547554016113281, 'learning_rate': 2.640677966101695e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4442/6000 [4:20:00<1:29:45,  3.46s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [4:20:04<1:30:12,  3.48s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.5085514783859253, 'learning_rate': 2.638983050847458e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4443/6000 [4:20:04<1:30:12,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [4:20:07<1:29:19,  3.44s/it]                                                       {'loss': 0.0649, 'grad_norm': 9.96660041809082, 'learning_rate': 2.6372881355932208e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4444/6000 [4:20:07<1:29:19,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [4:20:11<1:28:35,  3.42s/it]                                                       {'loss': 0.0771, 'grad_norm': 10.424582481384277, 'learning_rate': 2.635593220338983e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4445/6000 [4:20:11<1:28:35,  3.42s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [4:20:14<1:31:05,  3.52s/it]                                                       {'loss': 0.0128, 'grad_norm': 3.1470625400543213, 'learning_rate': 2.633898305084746e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4446/6000 [4:20:14<1:31:05,  3.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [4:20:18<1:29:56,  3.48s/it]                                                       {'loss': 0.0238, 'grad_norm': 8.349502563476562, 'learning_rate': 2.632203389830509e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4447/6000 [4:20:18<1:29:56,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [4:20:21<1:28:53,  3.44s/it]                                                       {'loss': 0.0562, 'grad_norm': 2.7035322189331055, 'learning_rate': 2.6305084745762718e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4448/6000 [4:20:21<1:28:53,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [4:20:24<1:28:37,  3.43s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.6528806686401367, 'learning_rate': 2.628813559322034e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4449/6000 [4:20:24<1:28:37,  3.43s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [4:20:28<1:29:35,  3.47s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.1024885177612305, 'learning_rate': 2.627118644067797e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4450/6000 [4:20:28<1:29:35,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [4:20:32<1:35:54,  3.72s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.38580453395843506, 'learning_rate': 2.62542372881356e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4451/6000 [4:20:32<1:35:54,  3.72s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [4:20:36<1:33:30,  3.62s/it]                                                       {'loss': 0.3199, 'grad_norm': 20.374780654907227, 'learning_rate': 2.6237288135593223e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4452/6000 [4:20:36<1:33:30,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [4:20:40<1:35:02,  3.69s/it]                                                       {'loss': 0.0217, 'grad_norm': 7.321291923522949, 'learning_rate': 2.6220338983050847e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4453/6000 [4:20:40<1:35:02,  3.69s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [4:20:43<1:32:33,  3.59s/it]                                                       {'loss': 0.0561, 'grad_norm': 7.805245399475098, 'learning_rate': 2.6203389830508476e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4454/6000 [4:20:43<1:32:33,  3.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [4:20:46<1:30:40,  3.52s/it]                                                       {'loss': 0.038, 'grad_norm': 5.615217208862305, 'learning_rate': 2.61864406779661e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4455/6000 [4:20:46<1:30:40,  3.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [4:20:50<1:29:47,  3.49s/it]                                                       {'loss': 0.001, 'grad_norm': 0.3099558651447296, 'learning_rate': 2.616949152542373e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4456/6000 [4:20:50<1:29:47,  3.49s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [4:20:53<1:29:22,  3.48s/it]                                                       {'loss': 0.0266, 'grad_norm': 2.290942668914795, 'learning_rate': 2.6152542372881357e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4457/6000 [4:20:53<1:29:22,  3.48s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [4:20:57<1:28:30,  3.44s/it]                                                       {'loss': 0.0119, 'grad_norm': 2.744309425354004, 'learning_rate': 2.6135593220338986e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4458/6000 [4:20:57<1:28:30,  3.44s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [4:21:01<1:33:48,  3.65s/it]                                                       {'loss': 0.0395, 'grad_norm': 11.264792442321777, 'learning_rate': 2.611864406779661e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4459/6000 [4:21:01<1:33:48,  3.65s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [4:21:04<1:31:09,  3.55s/it]                                                       {'loss': 0.0175, 'grad_norm': 4.830052852630615, 'learning_rate': 2.610169491525424e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4460/6000 [4:21:04<1:31:09,  3.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [4:21:08<1:33:38,  3.65s/it]                                                       {'loss': 0.0871, 'grad_norm': 10.207467079162598, 'learning_rate': 2.6084745762711867e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4461/6000 [4:21:08<1:33:38,  3.65s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [4:21:11<1:31:42,  3.58s/it]                                                       {'loss': 0.0554, 'grad_norm': 8.578835487365723, 'learning_rate': 2.6067796610169495e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4462/6000 [4:21:11<1:31:42,  3.58s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [4:21:15<1:32:48,  3.62s/it]                                                       {'loss': 0.1363, 'grad_norm': 14.330595970153809, 'learning_rate': 2.605084745762712e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4463/6000 [4:21:15<1:32:48,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [4:21:18<1:31:30,  3.57s/it]                                                       {'loss': 0.0033, 'grad_norm': 1.1992653608322144, 'learning_rate': 2.603389830508475e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4464/6000 [4:21:18<1:31:30,  3.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [4:21:22<1:30:17,  3.53s/it]                                                       {'loss': 0.0704, 'grad_norm': 11.65268611907959, 'learning_rate': 2.6016949152542377e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4465/6000 [4:21:22<1:30:17,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [4:21:25<1:29:42,  3.51s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.6858242750167847, 'learning_rate': 2.6e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4466/6000 [4:21:25<1:29:42,  3.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [4:21:29<1:32:25,  3.62s/it]                                                       {'loss': 0.1416, 'grad_norm': 20.6445255279541, 'learning_rate': 2.598305084745763e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4467/6000 [4:21:29<1:32:25,  3.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [4:21:33<1:30:13,  3.53s/it]                                                       {'loss': 0.0029, 'grad_norm': 0.706689178943634, 'learning_rate': 2.596610169491526e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4468/6000 [4:21:33<1:30:13,  3.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [4:21:36<1:28:26,  3.47s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.12949377298355103, 'learning_rate': 2.5949152542372886e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4469/6000 [4:21:36<1:28:26,  3.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [4:21:39<1:27:11,  3.42s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.9917898178100586, 'learning_rate': 2.593220338983051e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4470/6000 [4:21:39<1:27:11,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [4:21:43<1:27:16,  3.43s/it]                                                       {'loss': 0.073, 'grad_norm': 12.308815956115723, 'learning_rate': 2.591525423728814e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4471/6000 [4:21:43<1:27:16,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [4:21:46<1:27:01,  3.42s/it]                                                       {'loss': 0.023, 'grad_norm': 5.174230575561523, 'learning_rate': 2.5898305084745768e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4472/6000 [4:21:46<1:27:01,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [4:21:49<1:27:07,  3.42s/it]                                                       {'loss': 0.0672, 'grad_norm': 13.197480201721191, 'learning_rate': 2.5881355932203396e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4473/6000 [4:21:49<1:27:07,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [4:21:53<1:27:02,  3.42s/it]                                                       {'loss': 0.3092, 'grad_norm': 20.90199089050293, 'learning_rate': 2.5864406779661016e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4474/6000 [4:21:53<1:27:02,  3.42s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [4:21:56<1:26:34,  3.41s/it]                                                       {'loss': 0.1392, 'grad_norm': 12.57106876373291, 'learning_rate': 2.5847457627118645e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4475/6000 [4:21:56<1:26:34,  3.41s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [4:22:00<1:29:45,  3.53s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.0500378608703613, 'learning_rate': 2.5830508474576273e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4476/6000 [4:22:00<1:29:45,  3.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [4:22:04<1:29:15,  3.52s/it]                                                       {'loss': 0.2338, 'grad_norm': 15.045210838317871, 'learning_rate': 2.5813559322033898e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4477/6000 [4:22:04<1:29:15,  3.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [4:22:07<1:29:51,  3.54s/it]                                                       {'loss': 0.075, 'grad_norm': 15.883413314819336, 'learning_rate': 2.5796610169491526e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4478/6000 [4:22:07<1:29:51,  3.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [4:22:11<1:35:30,  3.77s/it]                                                       {'loss': 0.1348, 'grad_norm': 11.698507308959961, 'learning_rate': 2.5779661016949155e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4479/6000 [4:22:11<1:35:30,  3.77s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [4:22:15<1:32:03,  3.63s/it]                                                       {'loss': 0.0153, 'grad_norm': 4.602453708648682, 'learning_rate': 2.576271186440678e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4480/6000 [4:22:15<1:32:03,  3.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [4:22:18<1:29:45,  3.55s/it]                                                       {'loss': 0.0166, 'grad_norm': 3.6709702014923096, 'learning_rate': 2.5745762711864407e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4481/6000 [4:22:18<1:29:45,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [4:22:22<1:29:56,  3.55s/it]                                                       {'loss': 0.0161, 'grad_norm': 4.693418502807617, 'learning_rate': 2.5728813559322036e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4482/6000 [4:22:22<1:29:56,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [4:22:25<1:28:25,  3.50s/it]                                                       {'loss': 0.1971, 'grad_norm': 10.894671440124512, 'learning_rate': 2.5711864406779664e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4483/6000 [4:22:25<1:28:25,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [4:22:29<1:28:02,  3.48s/it]                                                       {'loss': 0.0176, 'grad_norm': 6.29139518737793, 'learning_rate': 2.569491525423729e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4484/6000 [4:22:29<1:28:02,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [4:22:32<1:30:15,  3.57s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.06180020049214363, 'learning_rate': 2.5677966101694917e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4485/6000 [4:22:32<1:30:15,  3.57s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [4:22:36<1:28:10,  3.49s/it]                                                       {'loss': 0.0088, 'grad_norm': 2.1938893795013428, 'learning_rate': 2.5661016949152546e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4486/6000 [4:22:36<1:28:10,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [4:22:39<1:27:56,  3.49s/it]                                                       {'loss': 0.2168, 'grad_norm': 14.368233680725098, 'learning_rate': 2.5644067796610174e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4487/6000 [4:22:39<1:27:56,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [4:22:42<1:27:17,  3.46s/it]                                                       {'loss': 0.0327, 'grad_norm': 5.064611911773682, 'learning_rate': 2.56271186440678e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4488/6000 [4:22:42<1:27:17,  3.46s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [4:22:46<1:29:55,  3.57s/it]                                                       {'loss': 0.0972, 'grad_norm': 8.004716873168945, 'learning_rate': 2.5610169491525427e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4489/6000 [4:22:46<1:29:55,  3.57s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [4:22:50<1:28:18,  3.51s/it]                                                       {'loss': 0.1175, 'grad_norm': 17.87993812561035, 'learning_rate': 2.5593220338983055e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4490/6000 [4:22:50<1:28:18,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [4:22:53<1:30:31,  3.60s/it]                                                       {'loss': 0.0, 'grad_norm': 0.006483821198344231, 'learning_rate': 2.5576271186440684e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4491/6000 [4:22:53<1:30:31,  3.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [4:22:57<1:29:01,  3.54s/it]                                                       {'loss': 0.0067, 'grad_norm': 1.7134617567062378, 'learning_rate': 2.555932203389831e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4492/6000 [4:22:57<1:29:01,  3.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [4:23:00<1:27:49,  3.50s/it]                                                       {'loss': 0.0617, 'grad_norm': 9.4177827835083, 'learning_rate': 2.5542372881355937e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4493/6000 [4:23:00<1:27:49,  3.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [4:23:04<1:27:40,  3.49s/it]                                                       {'loss': 0.0733, 'grad_norm': 9.874483108520508, 'learning_rate': 2.5525423728813557e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4494/6000 [4:23:04<1:27:40,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [4:23:07<1:25:59,  3.43s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.33064723014831543, 'learning_rate': 2.5508474576271185e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4495/6000 [4:23:07<1:25:59,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [4:23:10<1:26:00,  3.43s/it]                                                       {'loss': 0.0839, 'grad_norm': 7.952023029327393, 'learning_rate': 2.5491525423728814e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4496/6000 [4:23:10<1:26:00,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [4:23:14<1:25:16,  3.40s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.2212471961975098, 'learning_rate': 2.5474576271186442e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4497/6000 [4:23:14<1:25:16,  3.40s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [4:23:17<1:24:37,  3.38s/it]                                                       {'loss': 0.0545, 'grad_norm': 8.946409225463867, 'learning_rate': 2.5457627118644066e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4498/6000 [4:23:17<1:24:37,  3.38s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [4:23:21<1:24:31,  3.38s/it]                                                       {'loss': 0.1487, 'grad_norm': 10.534687995910645, 'learning_rate': 2.5440677966101695e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4499/6000 [4:23:21<1:24:31,  3.38s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [4:23:24<1:24:26,  3.38s/it]                                                       {'loss': 0.1117, 'grad_norm': 13.278696060180664, 'learning_rate': 2.5423728813559323e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4500/6000 [4:23:24<1:24:26,  3.38s/it][2025-11-07 03:14:33,884] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4500
[2025-11-07 03:14:33,901] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:14:34,608] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4500/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [4:23:30<1:42:23,  4.10s/it]                                                       {'loss': 0.0184, 'grad_norm': 2.9968600273132324, 'learning_rate': 2.540677966101695e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4501/6000 [4:23:30<1:42:23,  4.10s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [4:23:33<1:39:41,  3.99s/it]                                                       {'loss': 0.1693, 'grad_norm': 17.173038482666016, 'learning_rate': 2.5389830508474576e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4502/6000 [4:23:33<1:39:41,  3.99s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [4:23:37<1:35:38,  3.83s/it]                                                       {'loss': 0.1408, 'grad_norm': 14.100014686584473, 'learning_rate': 2.5372881355932205e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4503/6000 [4:23:37<1:35:38,  3.83s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [4:23:40<1:32:05,  3.69s/it]                                                       {'loss': 0.001, 'grad_norm': 0.16084639728069305, 'learning_rate': 2.5355932203389833e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4504/6000 [4:23:40<1:32:05,  3.69s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [4:23:44<1:29:26,  3.59s/it]                                                       {'loss': 0.0813, 'grad_norm': 12.54609203338623, 'learning_rate': 2.533898305084746e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4505/6000 [4:23:44<1:29:26,  3.59s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [4:23:47<1:28:24,  3.55s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.0822641849517822, 'learning_rate': 2.5322033898305086e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4506/6000 [4:23:47<1:28:24,  3.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [4:23:50<1:27:16,  3.51s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.18102918565273285, 'learning_rate': 2.5305084745762714e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4507/6000 [4:23:50<1:27:16,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [4:23:54<1:27:23,  3.51s/it]                                                       {'loss': 0.1052, 'grad_norm': 13.477293968200684, 'learning_rate': 2.5288135593220343e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4508/6000 [4:23:54<1:27:23,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [4:23:57<1:27:13,  3.51s/it]                                                       {'loss': 0.3081, 'grad_norm': 12.096150398254395, 'learning_rate': 2.527118644067797e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4509/6000 [4:23:57<1:27:13,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [4:24:01<1:26:26,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.6616296768188477, 'learning_rate': 2.5254237288135596e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4510/6000 [4:24:01<1:26:26,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [4:24:04<1:25:50,  3.46s/it]                                                       {'loss': 0.013, 'grad_norm': 3.5549373626708984, 'learning_rate': 2.5237288135593224e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4511/6000 [4:24:04<1:25:50,  3.46s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [4:24:08<1:25:05,  3.43s/it]                                                       {'loss': 0.0376, 'grad_norm': 8.75963020324707, 'learning_rate': 2.5220338983050853e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4512/6000 [4:24:08<1:25:05,  3.43s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [4:24:12<1:28:31,  3.57s/it]                                                       {'loss': 0.023, 'grad_norm': 4.845824241638184, 'learning_rate': 2.5203389830508477e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4513/6000 [4:24:12<1:28:31,  3.57s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [4:24:15<1:26:27,  3.49s/it]                                                       {'loss': 0.0322, 'grad_norm': 5.604491233825684, 'learning_rate': 2.5186440677966105e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4514/6000 [4:24:15<1:26:27,  3.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [4:24:19<1:29:24,  3.61s/it]                                                       {'loss': 0.016, 'grad_norm': 5.2462477684021, 'learning_rate': 2.516949152542373e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4515/6000 [4:24:19<1:29:24,  3.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [4:24:22<1:26:53,  3.51s/it]                                                       {'loss': 0.0826, 'grad_norm': 14.666964530944824, 'learning_rate': 2.5152542372881354e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4516/6000 [4:24:22<1:26:53,  3.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [4:24:25<1:25:57,  3.48s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.0802493691444397, 'learning_rate': 2.5135593220338983e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4517/6000 [4:24:25<1:25:57,  3.48s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [4:24:29<1:28:07,  3.57s/it]                                                       {'loss': 0.028, 'grad_norm': 6.281808853149414, 'learning_rate': 2.511864406779661e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4518/6000 [4:24:29<1:28:07,  3.57s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [4:24:33<1:27:54,  3.56s/it]                                                       {'loss': 0.2042, 'grad_norm': 12.211494445800781, 'learning_rate': 2.510169491525424e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4519/6000 [4:24:33<1:27:54,  3.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [4:24:37<1:31:03,  3.69s/it]                                                       {'loss': 0.0196, 'grad_norm': 7.341054916381836, 'learning_rate': 2.5084745762711864e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4520/6000 [4:24:37<1:31:03,  3.69s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [4:24:40<1:28:15,  3.58s/it]                                                       {'loss': 0.3665, 'grad_norm': 15.371792793273926, 'learning_rate': 2.5067796610169492e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4521/6000 [4:24:40<1:28:15,  3.58s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [4:24:44<1:32:06,  3.74s/it]                                                       {'loss': 0.021, 'grad_norm': 5.974232196807861, 'learning_rate': 2.505084745762712e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/6000 [4:24:44<1:32:06,  3.74s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [4:24:48<1:30:01,  3.66s/it]                                                       {'loss': 0.0096, 'grad_norm': 3.900557279586792, 'learning_rate': 2.503389830508475e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4523/6000 [4:24:48<1:30:01,  3.66s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [4:24:52<1:37:04,  3.95s/it]                                                       {'loss': 0.11, 'grad_norm': 7.12891149520874, 'learning_rate': 2.5016949152542374e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4524/6000 [4:24:52<1:37:04,  3.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [4:24:56<1:33:36,  3.81s/it]                                                       {'loss': 0.0722, 'grad_norm': 5.836115837097168, 'learning_rate': 2.5e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4525/6000 [4:24:56<1:33:36,  3.81s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [4:24:59<1:31:36,  3.73s/it]                                                       {'loss': 0.0105, 'grad_norm': 3.142333984375, 'learning_rate': 2.498305084745763e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4526/6000 [4:24:59<1:31:36,  3.73s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [4:25:04<1:38:38,  4.02s/it]                                                       {'loss': 0.1395, 'grad_norm': 12.627126693725586, 'learning_rate': 2.4966101694915255e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4527/6000 [4:25:04<1:38:38,  4.02s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [4:25:08<1:35:14,  3.88s/it]                                                       {'loss': 0.3526, 'grad_norm': 15.091931343078613, 'learning_rate': 2.4949152542372883e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4528/6000 [4:25:08<1:35:14,  3.88s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [4:25:11<1:31:31,  3.73s/it]                                                       {'loss': 0.27, 'grad_norm': 17.098512649536133, 'learning_rate': 2.493220338983051e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4529/6000 [4:25:11<1:31:31,  3.73s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [4:25:14<1:28:44,  3.62s/it]                                                       {'loss': 0.0547, 'grad_norm': 9.11058235168457, 'learning_rate': 2.491525423728814e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4530/6000 [4:25:14<1:28:44,  3.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [4:25:18<1:27:34,  3.58s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.0262324810028076, 'learning_rate': 2.4898305084745765e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4531/6000 [4:25:18<1:27:34,  3.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [4:25:21<1:26:29,  3.53s/it]                                                       {'loss': 0.0234, 'grad_norm': 5.07138204574585, 'learning_rate': 2.488135593220339e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4532/6000 [4:25:21<1:26:29,  3.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [4:25:25<1:24:40,  3.46s/it]                                                       {'loss': 0.0426, 'grad_norm': 10.064322471618652, 'learning_rate': 2.4864406779661017e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4533/6000 [4:25:25<1:24:40,  3.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [4:25:28<1:26:53,  3.56s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.0312669612467289, 'learning_rate': 2.4847457627118646e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4534/6000 [4:25:28<1:26:53,  3.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [4:25:32<1:27:08,  3.57s/it]                                                       {'loss': 0.1435, 'grad_norm': 13.816579818725586, 'learning_rate': 2.4830508474576274e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4535/6000 [4:25:32<1:27:08,  3.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [4:25:36<1:29:05,  3.65s/it]                                                       {'loss': 0.041, 'grad_norm': 6.929159164428711, 'learning_rate': 2.48135593220339e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4536/6000 [4:25:36<1:29:05,  3.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [4:25:39<1:27:49,  3.60s/it]                                                       {'loss': 0.0826, 'grad_norm': 10.51071834564209, 'learning_rate': 2.4796610169491527e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4537/6000 [4:25:39<1:27:49,  3.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [4:25:43<1:26:23,  3.55s/it]                                                       {'loss': 0.0115, 'grad_norm': 3.745734453201294, 'learning_rate': 2.4779661016949156e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4538/6000 [4:25:43<1:26:23,  3.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [4:25:46<1:27:40,  3.60s/it]                                                       {'loss': 0.0632, 'grad_norm': 7.087026119232178, 'learning_rate': 2.4762711864406784e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4539/6000 [4:25:46<1:27:40,  3.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [4:25:50<1:27:01,  3.58s/it]                                                       {'loss': 0.0274, 'grad_norm': 6.3479743003845215, 'learning_rate': 2.474576271186441e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4540/6000 [4:25:50<1:27:01,  3.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [4:25:54<1:31:23,  3.76s/it]                                                       {'loss': 0.0137, 'grad_norm': 3.571983814239502, 'learning_rate': 2.4728813559322033e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4541/6000 [4:25:54<1:31:23,  3.76s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [4:25:57<1:28:01,  3.62s/it]                                                       {'loss': 0.0684, 'grad_norm': 8.438735008239746, 'learning_rate': 2.471186440677966e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4542/6000 [4:25:57<1:28:01,  3.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [4:26:01<1:27:04,  3.59s/it]                                                       {'loss': 0.0548, 'grad_norm': 10.033421516418457, 'learning_rate': 2.469491525423729e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4543/6000 [4:26:01<1:27:04,  3.59s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [4:26:04<1:25:23,  3.52s/it]                                                       {'loss': 0.0099, 'grad_norm': 2.4279465675354004, 'learning_rate': 2.467796610169492e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4544/6000 [4:26:04<1:25:23,  3.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [4:26:08<1:24:23,  3.48s/it]                                                       {'loss': 0.0365, 'grad_norm': 2.99129056930542, 'learning_rate': 2.4661016949152542e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4545/6000 [4:26:08<1:24:23,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [4:26:11<1:25:50,  3.54s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.06376670300960541, 'learning_rate': 2.464406779661017e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4546/6000 [4:26:11<1:25:50,  3.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [4:26:15<1:25:07,  3.52s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.39231881499290466, 'learning_rate': 2.46271186440678e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4547/6000 [4:26:15<1:25:07,  3.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [4:26:18<1:24:13,  3.48s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.2095866203308105, 'learning_rate': 2.461016949152543e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4548/6000 [4:26:18<1:24:13,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [4:26:21<1:22:36,  3.42s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.42035356163978577, 'learning_rate': 2.4593220338983052e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4549/6000 [4:26:21<1:22:36,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [4:26:25<1:22:55,  3.43s/it]                                                       {'loss': 0.0088, 'grad_norm': 2.530796527862549, 'learning_rate': 2.457627118644068e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4550/6000 [4:26:25<1:22:55,  3.43s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [4:26:28<1:22:44,  3.43s/it]                                                       {'loss': 0.1383, 'grad_norm': 12.915915489196777, 'learning_rate': 2.4559322033898305e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4551/6000 [4:26:28<1:22:44,  3.43s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [4:26:32<1:21:38,  3.38s/it]                                                       {'loss': 0.0147, 'grad_norm': 4.308842658996582, 'learning_rate': 2.4542372881355933e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4552/6000 [4:26:32<1:21:38,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [4:26:35<1:21:31,  3.38s/it]                                                       {'loss': 0.0017, 'grad_norm': 0.5665073394775391, 'learning_rate': 2.452542372881356e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4553/6000 [4:26:35<1:21:31,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [4:26:39<1:24:26,  3.50s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.2126338928937912, 'learning_rate': 2.4508474576271186e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4554/6000 [4:26:39<1:24:26,  3.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [4:26:42<1:23:52,  3.48s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.44688400626182556, 'learning_rate': 2.4491525423728815e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4555/6000 [4:26:42<1:23:52,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [4:26:46<1:23:02,  3.45s/it]                                                       {'loss': 0.0553, 'grad_norm': 7.435585975646973, 'learning_rate': 2.4474576271186443e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4556/6000 [4:26:46<1:23:02,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [4:26:50<1:29:19,  3.71s/it]                                                       {'loss': 0.0027, 'grad_norm': 0.4885934889316559, 'learning_rate': 2.445762711864407e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4557/6000 [4:26:50<1:29:19,  3.71s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [4:26:53<1:27:58,  3.66s/it]                                                       {'loss': 0.3004, 'grad_norm': 11.412117004394531, 'learning_rate': 2.4440677966101696e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4558/6000 [4:26:53<1:27:58,  3.66s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [4:26:57<1:26:11,  3.59s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2419710010290146, 'learning_rate': 2.4423728813559324e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4559/6000 [4:26:57<1:26:11,  3.59s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [4:27:00<1:24:22,  3.52s/it]                                                       {'loss': 0.0586, 'grad_norm': 6.679741382598877, 'learning_rate': 2.4406779661016953e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4560/6000 [4:27:00<1:24:22,  3.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [4:27:04<1:23:22,  3.48s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.6880574822425842, 'learning_rate': 2.438983050847458e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4561/6000 [4:27:04<1:23:22,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [4:27:07<1:22:26,  3.44s/it]                                                       {'loss': 0.0663, 'grad_norm': 13.680904388427734, 'learning_rate': 2.4372881355932206e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4562/6000 [4:27:07<1:22:26,  3.44s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [4:27:10<1:22:27,  3.44s/it]                                                       {'loss': 0.0257, 'grad_norm': 7.251223564147949, 'learning_rate': 2.435593220338983e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4563/6000 [4:27:10<1:22:27,  3.44s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [4:27:14<1:22:39,  3.45s/it]                                                       {'loss': 0.005, 'grad_norm': 1.0724432468414307, 'learning_rate': 2.433898305084746e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4564/6000 [4:27:14<1:22:39,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [4:27:17<1:21:44,  3.42s/it]                                                       {'loss': 0.028, 'grad_norm': 2.4593255519866943, 'learning_rate': 2.4322033898305087e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4565/6000 [4:27:17<1:21:44,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [4:27:21<1:21:31,  3.41s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.1796441078186035, 'learning_rate': 2.4305084745762716e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4566/6000 [4:27:21<1:21:31,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [4:27:24<1:22:18,  3.45s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.439415216445923, 'learning_rate': 2.428813559322034e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4567/6000 [4:27:24<1:22:18,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [4:27:28<1:22:15,  3.45s/it]                                                       {'loss': 0.082, 'grad_norm': 11.509498596191406, 'learning_rate': 2.427118644067797e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4568/6000 [4:27:28<1:22:15,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [4:27:31<1:21:03,  3.40s/it]                                                       {'loss': 0.0522, 'grad_norm': 10.768603324890137, 'learning_rate': 2.4254237288135597e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4569/6000 [4:27:31<1:21:03,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [4:27:34<1:20:23,  3.37s/it]                                                       {'loss': 0.0266, 'grad_norm': 5.180274486541748, 'learning_rate': 2.4237288135593225e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4570/6000 [4:27:34<1:20:23,  3.37s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [4:27:38<1:19:57,  3.36s/it]                                                       {'loss': 0.004, 'grad_norm': 1.2421257495880127, 'learning_rate': 2.422033898305085e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4571/6000 [4:27:38<1:19:57,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [4:27:41<1:20:03,  3.36s/it]                                                       {'loss': 0.1848, 'grad_norm': 11.217507362365723, 'learning_rate': 2.4203389830508474e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4572/6000 [4:27:41<1:20:03,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [4:27:44<1:19:43,  3.35s/it]                                                       {'loss': 0.0077, 'grad_norm': 1.7201282978057861, 'learning_rate': 2.4186440677966102e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4573/6000 [4:27:44<1:19:43,  3.35s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [4:27:48<1:19:50,  3.36s/it]                                                       {'loss': 0.3342, 'grad_norm': 12.58736515045166, 'learning_rate': 2.416949152542373e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4574/6000 [4:27:48<1:19:50,  3.36s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [4:27:51<1:20:31,  3.39s/it]                                                       {'loss': 0.0091, 'grad_norm': 3.0413830280303955, 'learning_rate': 2.415254237288136e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4575/6000 [4:27:51<1:20:31,  3.39s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [4:27:54<1:20:40,  3.40s/it]                                                       {'loss': 0.1349, 'grad_norm': 11.587101936340332, 'learning_rate': 2.4135593220338984e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4576/6000 [4:27:54<1:20:40,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [4:27:58<1:20:34,  3.40s/it]                                                       {'loss': 0.0063, 'grad_norm': 2.3526148796081543, 'learning_rate': 2.411864406779661e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4577/6000 [4:27:58<1:20:34,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [4:28:01<1:21:07,  3.42s/it]                                                       {'loss': 0.1105, 'grad_norm': 12.592180252075195, 'learning_rate': 2.410169491525424e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4578/6000 [4:28:01<1:21:07,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [4:28:05<1:20:56,  3.42s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.9086235761642456, 'learning_rate': 2.4084745762711865e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4579/6000 [4:28:05<1:20:56,  3.42s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [4:28:08<1:20:43,  3.41s/it]                                                       {'loss': 0.0109, 'grad_norm': 2.497743844985962, 'learning_rate': 2.4067796610169493e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4580/6000 [4:28:08<1:20:43,  3.41s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [4:28:11<1:19:54,  3.38s/it]                                                       {'loss': 0.0254, 'grad_norm': 5.8832244873046875, 'learning_rate': 2.405084745762712e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4581/6000 [4:28:11<1:19:54,  3.38s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [4:28:15<1:19:34,  3.37s/it]                                                       {'loss': 0.1332, 'grad_norm': 16.109439849853516, 'learning_rate': 2.403389830508475e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4582/6000 [4:28:15<1:19:34,  3.37s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [4:28:18<1:20:21,  3.40s/it]                                                       {'loss': 0.0875, 'grad_norm': 9.43679141998291, 'learning_rate': 2.4016949152542375e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4583/6000 [4:28:18<1:20:21,  3.40s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [4:28:22<1:24:22,  3.57s/it]                                                       {'loss': 0.0666, 'grad_norm': 7.082995891571045, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4584/6000 [4:28:22<1:24:22,  3.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [4:28:26<1:23:11,  3.53s/it]                                                       {'loss': 0.2144, 'grad_norm': 15.595962524414062, 'learning_rate': 2.3983050847457627e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4585/6000 [4:28:26<1:23:11,  3.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [4:28:29<1:21:55,  3.48s/it]                                                       {'loss': 0.0041, 'grad_norm': 1.3904238939285278, 'learning_rate': 2.3966101694915256e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4586/6000 [4:28:29<1:21:55,  3.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [4:28:33<1:22:35,  3.51s/it]                                                       {'loss': 0.004, 'grad_norm': 1.0429331064224243, 'learning_rate': 2.3949152542372884e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4587/6000 [4:28:33<1:22:35,  3.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [4:28:36<1:21:11,  3.45s/it]                                                       {'loss': 0.121, 'grad_norm': 12.792930603027344, 'learning_rate': 2.393220338983051e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4588/6000 [4:28:36<1:21:11,  3.45s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [4:28:39<1:20:37,  3.43s/it]                                                       {'loss': 0.1923, 'grad_norm': 9.75026798248291, 'learning_rate': 2.3915254237288137e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4589/6000 [4:28:39<1:20:37,  3.43s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [4:28:43<1:19:58,  3.40s/it]                                                       {'loss': 0.0031, 'grad_norm': 1.1950377225875854, 'learning_rate': 2.3898305084745766e-06, 'epoch': 0.77}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4590/6000 [4:28:43<1:19:58,  3.40s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [4:28:46<1:20:34,  3.43s/it]                                                       {'loss': 0.0245, 'grad_norm': 4.827414512634277, 'learning_rate': 2.3881355932203394e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4591/6000 [4:28:46<1:20:34,  3.43s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [4:28:50<1:21:24,  3.47s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.3533269166946411, 'learning_rate': 2.386440677966102e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4592/6000 [4:28:50<1:21:24,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [4:28:53<1:23:16,  3.55s/it]                                                       {'loss': 0.0369, 'grad_norm': 8.697470664978027, 'learning_rate': 2.3847457627118643e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4593/6000 [4:28:53<1:23:16,  3.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [4:28:57<1:22:15,  3.51s/it]                                                       {'loss': 0.0186, 'grad_norm': 4.250825881958008, 'learning_rate': 2.383050847457627e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4594/6000 [4:28:57<1:22:15,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [4:29:00<1:21:19,  3.47s/it]                                                       {'loss': 0.0136, 'grad_norm': 1.981858253479004, 'learning_rate': 2.38135593220339e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4595/6000 [4:29:00<1:21:19,  3.47s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [4:29:04<1:20:34,  3.44s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.4441766738891602, 'learning_rate': 2.379661016949153e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4596/6000 [4:29:04<1:20:34,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [4:29:08<1:25:04,  3.64s/it]                                                       {'loss': 0.0124, 'grad_norm': 3.365515947341919, 'learning_rate': 2.3779661016949152e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4597/6000 [4:29:08<1:25:04,  3.64s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [4:29:11<1:23:30,  3.57s/it]                                                       {'loss': 0.1248, 'grad_norm': 11.473418235778809, 'learning_rate': 2.376271186440678e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4598/6000 [4:29:11<1:23:30,  3.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [4:29:14<1:22:00,  3.51s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.5251479148864746, 'learning_rate': 2.374576271186441e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4599/6000 [4:29:15<1:22:00,  3.51s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [4:29:18<1:21:13,  3.48s/it]                                                       {'loss': 0.0592, 'grad_norm': 5.668649673461914, 'learning_rate': 2.372881355932204e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4600/6000 [4:29:18<1:21:13,  3.48s/it][2025-11-07 03:20:27,897] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4600
[2025-11-07 03:20:27,911] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:20:28,796] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4600/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [4:29:24<1:38:45,  4.24s/it]                                                       {'loss': 0.0123, 'grad_norm': 1.324288010597229, 'learning_rate': 2.3711864406779662e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4601/6000 [4:29:24<1:38:45,  4.24s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [4:29:28<1:34:54,  4.07s/it]                                                       {'loss': 0.1345, 'grad_norm': 15.952681541442871, 'learning_rate': 2.369491525423729e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4602/6000 [4:29:28<1:34:54,  4.07s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [4:29:31<1:30:16,  3.88s/it]                                                       {'loss': 0.0056, 'grad_norm': 1.0589509010314941, 'learning_rate': 2.3677966101694915e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4603/6000 [4:29:31<1:30:16,  3.88s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [4:29:34<1:26:52,  3.73s/it]                                                       {'loss': 0.0222, 'grad_norm': 5.623043537139893, 'learning_rate': 2.3661016949152544e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4604/6000 [4:29:34<1:26:52,  3.73s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [4:29:38<1:24:30,  3.63s/it]                                                       {'loss': 0.0026, 'grad_norm': 0.7551819086074829, 'learning_rate': 2.364406779661017e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4605/6000 [4:29:38<1:24:30,  3.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [4:29:41<1:22:39,  3.56s/it]                                                       {'loss': 0.0705, 'grad_norm': 9.242006301879883, 'learning_rate': 2.3627118644067796e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4606/6000 [4:29:41<1:22:39,  3.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [4:29:45<1:21:11,  3.50s/it]                                                       {'loss': 0.0207, 'grad_norm': 6.776089668273926, 'learning_rate': 2.3610169491525425e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4607/6000 [4:29:45<1:21:11,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [4:29:48<1:19:55,  3.45s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.2535804212093353, 'learning_rate': 2.3593220338983053e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4608/6000 [4:29:48<1:19:55,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [4:29:53<1:28:30,  3.82s/it]                                                       {'loss': 0.0804, 'grad_norm': 13.396747589111328, 'learning_rate': 2.357627118644068e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4609/6000 [4:29:53<1:28:30,  3.82s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [4:29:56<1:26:13,  3.72s/it]                                                       {'loss': 0.0108, 'grad_norm': 3.047884941101074, 'learning_rate': 2.3559322033898306e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4610/6000 [4:29:56<1:26:13,  3.72s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [4:30:00<1:29:41,  3.87s/it]                                                       {'loss': 0.0039, 'grad_norm': 1.1975210905075073, 'learning_rate': 2.3542372881355935e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4611/6000 [4:30:00<1:29:41,  3.87s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [4:30:04<1:26:05,  3.72s/it]                                                       {'loss': 0.0082, 'grad_norm': 1.7838231325149536, 'learning_rate': 2.3525423728813563e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4612/6000 [4:30:04<1:26:05,  3.72s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [4:30:08<1:27:10,  3.77s/it]                                                       {'loss': 0.1123, 'grad_norm': 11.44918441772461, 'learning_rate': 2.350847457627119e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4613/6000 [4:30:08<1:27:10,  3.77s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [4:30:11<1:23:53,  3.63s/it]                                                       {'loss': 0.0142, 'grad_norm': 3.428074598312378, 'learning_rate': 2.3491525423728816e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4614/6000 [4:30:11<1:23:53,  3.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [4:30:14<1:23:30,  3.62s/it]                                                       {'loss': 0.0224, 'grad_norm': 3.830390691757202, 'learning_rate': 2.347457627118644e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4615/6000 [4:30:14<1:23:30,  3.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [4:30:18<1:21:32,  3.54s/it]                                                       {'loss': 0.0348, 'grad_norm': 5.453880310058594, 'learning_rate': 2.345762711864407e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4616/6000 [4:30:18<1:21:32,  3.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [4:30:21<1:20:29,  3.49s/it]                                                       {'loss': 0.0278, 'grad_norm': 6.48906135559082, 'learning_rate': 2.3440677966101697e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4617/6000 [4:30:21<1:20:29,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [4:30:25<1:19:20,  3.44s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.2308717966079712, 'learning_rate': 2.3423728813559326e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4618/6000 [4:30:25<1:19:20,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [4:30:28<1:20:12,  3.48s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.35430124402046204, 'learning_rate': 2.340677966101695e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4619/6000 [4:30:28<1:20:12,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [4:30:31<1:19:35,  3.46s/it]                                                       {'loss': 0.0055, 'grad_norm': 0.9940224289894104, 'learning_rate': 2.338983050847458e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4620/6000 [4:30:31<1:19:35,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [4:30:35<1:18:58,  3.44s/it]                                                       {'loss': 0.1844, 'grad_norm': 10.22508716583252, 'learning_rate': 2.3372881355932207e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4621/6000 [4:30:35<1:18:58,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [4:30:38<1:19:22,  3.46s/it]                                                       {'loss': 0.0827, 'grad_norm': 14.030832290649414, 'learning_rate': 2.3355932203389835e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4622/6000 [4:30:38<1:19:22,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [4:30:42<1:20:52,  3.52s/it]                                                       {'loss': 0.0125, 'grad_norm': 3.0551185607910156, 'learning_rate': 2.333898305084746e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4623/6000 [4:30:42<1:20:52,  3.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [4:30:45<1:20:05,  3.49s/it]                                                       {'loss': 0.1627, 'grad_norm': 13.482738494873047, 'learning_rate': 2.3322033898305084e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4624/6000 [4:30:45<1:20:05,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [4:30:49<1:19:18,  3.46s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07504887878894806, 'learning_rate': 2.3305084745762712e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4625/6000 [4:30:49<1:19:18,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [4:30:52<1:18:19,  3.42s/it]                                                       {'loss': 0.0378, 'grad_norm': 7.550147533416748, 'learning_rate': 2.328813559322034e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4626/6000 [4:30:52<1:18:19,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [4:30:56<1:17:46,  3.40s/it]                                                       {'loss': 0.0613, 'grad_norm': 6.461971759796143, 'learning_rate': 2.327118644067797e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4627/6000 [4:30:56<1:17:46,  3.40s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [4:30:59<1:18:03,  3.41s/it]                                                       {'loss': 0.0175, 'grad_norm': 3.571320056915283, 'learning_rate': 2.3254237288135594e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4628/6000 [4:30:59<1:18:03,  3.41s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [4:31:02<1:18:34,  3.44s/it]                                                       {'loss': 0.0192, 'grad_norm': 2.780778646469116, 'learning_rate': 2.3237288135593222e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4629/6000 [4:31:02<1:18:34,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [4:31:06<1:21:30,  3.57s/it]                                                       {'loss': 0.0098, 'grad_norm': 2.7247800827026367, 'learning_rate': 2.322033898305085e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4630/6000 [4:31:06<1:21:30,  3.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [4:31:10<1:20:56,  3.55s/it]                                                       {'loss': 0.1856, 'grad_norm': 8.904820442199707, 'learning_rate': 2.3203389830508475e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4631/6000 [4:31:10<1:20:56,  3.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [4:31:13<1:19:42,  3.50s/it]                                                       {'loss': 0.2825, 'grad_norm': 20.678804397583008, 'learning_rate': 2.3186440677966103e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4632/6000 [4:31:13<1:19:42,  3.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [4:31:17<1:18:23,  3.44s/it]                                                       {'loss': 0.0681, 'grad_norm': 8.51155948638916, 'learning_rate': 2.316949152542373e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4633/6000 [4:31:17<1:18:23,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [4:31:20<1:18:36,  3.45s/it]                                                       {'loss': 0.1517, 'grad_norm': 13.09251594543457, 'learning_rate': 2.315254237288136e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4634/6000 [4:31:20<1:18:36,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [4:31:23<1:18:07,  3.43s/it]                                                       {'loss': 0.0844, 'grad_norm': 8.9740571975708, 'learning_rate': 2.3135593220338985e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4635/6000 [4:31:23<1:18:07,  3.43s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [4:31:27<1:17:49,  3.42s/it]                                                       {'loss': 0.0284, 'grad_norm': 4.841601371765137, 'learning_rate': 2.3118644067796613e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4636/6000 [4:31:27<1:17:49,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [4:31:30<1:18:04,  3.44s/it]                                                       {'loss': 0.0057, 'grad_norm': 3.867790937423706, 'learning_rate': 2.3101694915254237e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4637/6000 [4:31:30<1:18:04,  3.44s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [4:31:34<1:22:01,  3.61s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1076245903968811, 'learning_rate': 2.3084745762711866e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4638/6000 [4:31:34<1:22:01,  3.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [4:31:38<1:20:12,  3.54s/it]                                                       {'loss': 0.0618, 'grad_norm': 10.436681747436523, 'learning_rate': 2.3067796610169494e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4639/6000 [4:31:38<1:20:12,  3.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [4:31:41<1:19:00,  3.49s/it]                                                       {'loss': 0.0091, 'grad_norm': 2.2031443119049072, 'learning_rate': 2.305084745762712e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4640/6000 [4:31:41<1:19:00,  3.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [4:31:45<1:19:42,  3.52s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.1383238434791565, 'learning_rate': 2.3033898305084747e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4641/6000 [4:31:45<1:19:42,  3.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [4:31:48<1:18:04,  3.45s/it]                                                       {'loss': 0.0035, 'grad_norm': 0.8274003863334656, 'learning_rate': 2.3016949152542376e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4642/6000 [4:31:48<1:18:04,  3.45s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [4:31:52<1:20:49,  3.57s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.18406330049037933, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4643/6000 [4:31:52<1:20:49,  3.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [4:31:55<1:19:41,  3.53s/it]                                                       {'loss': 0.0572, 'grad_norm': 7.736288070678711, 'learning_rate': 2.298305084745763e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4644/6000 [4:31:55<1:19:41,  3.53s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [4:31:59<1:18:29,  3.48s/it]                                                       {'loss': 0.0665, 'grad_norm': 10.205411911010742, 'learning_rate': 2.2966101694915253e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4645/6000 [4:31:59<1:18:29,  3.48s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [4:32:02<1:17:10,  3.42s/it]                                                       {'loss': 0.0126, 'grad_norm': 2.9479269981384277, 'learning_rate': 2.294915254237288e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4646/6000 [4:32:02<1:17:10,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [4:32:05<1:17:06,  3.42s/it]                                                       {'loss': 0.0203, 'grad_norm': 5.001357078552246, 'learning_rate': 2.293220338983051e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4647/6000 [4:32:05<1:17:06,  3.42s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [4:32:09<1:17:57,  3.46s/it]                                                       {'loss': 0.0354, 'grad_norm': 7.350124359130859, 'learning_rate': 2.291525423728814e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4648/6000 [4:32:09<1:17:57,  3.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [4:32:12<1:18:16,  3.48s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2713211476802826, 'learning_rate': 2.2898305084745763e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4649/6000 [4:32:12<1:18:16,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [4:32:16<1:17:51,  3.46s/it]                                                       {'loss': 0.1395, 'grad_norm': 13.012659072875977, 'learning_rate': 2.288135593220339e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4650/6000 [4:32:16<1:17:51,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [4:32:19<1:17:32,  3.45s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.11145300418138504, 'learning_rate': 2.286440677966102e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4651/6000 [4:32:19<1:17:32,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [4:32:23<1:19:15,  3.53s/it]                                                       {'loss': 0.024, 'grad_norm': 3.0153636932373047, 'learning_rate': 2.284745762711865e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4652/6000 [4:32:23<1:19:15,  3.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [4:32:26<1:17:54,  3.47s/it]                                                       {'loss': 0.0976, 'grad_norm': 16.559659957885742, 'learning_rate': 2.2830508474576272e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4653/6000 [4:32:26<1:17:54,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [4:32:30<1:17:42,  3.46s/it]                                                       {'loss': 0.0295, 'grad_norm': 5.905846118927002, 'learning_rate': 2.28135593220339e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4654/6000 [4:32:30<1:17:42,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [4:32:33<1:16:41,  3.42s/it]                                                       {'loss': 0.0231, 'grad_norm': 3.6079235076904297, 'learning_rate': 2.2796610169491525e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4655/6000 [4:32:33<1:16:41,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [4:32:37<1:17:54,  3.48s/it]                                                       {'loss': 0.0247, 'grad_norm': 7.543189525604248, 'learning_rate': 2.2779661016949154e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4656/6000 [4:32:37<1:17:54,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [4:32:40<1:16:42,  3.43s/it]                                                       {'loss': 0.1071, 'grad_norm': 12.95180606842041, 'learning_rate': 2.276271186440678e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4657/6000 [4:32:40<1:16:42,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [4:32:43<1:16:47,  3.43s/it]                                                       {'loss': 0.1593, 'grad_norm': 15.68662166595459, 'learning_rate': 2.2745762711864406e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4658/6000 [4:32:43<1:16:47,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [4:32:47<1:16:09,  3.41s/it]                                                       {'loss': 0.0213, 'grad_norm': 3.3782739639282227, 'learning_rate': 2.2728813559322035e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4659/6000 [4:32:47<1:16:09,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [4:32:50<1:16:18,  3.42s/it]                                                       {'loss': 0.0211, 'grad_norm': 5.905002593994141, 'learning_rate': 2.2711864406779663e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4660/6000 [4:32:50<1:16:18,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [4:32:54<1:16:02,  3.41s/it]                                                       {'loss': 0.0061, 'grad_norm': 0.9497987031936646, 'learning_rate': 2.269491525423729e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4661/6000 [4:32:54<1:16:02,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [4:32:57<1:16:15,  3.42s/it]                                                       {'loss': 0.0256, 'grad_norm': 6.120202541351318, 'learning_rate': 2.2677966101694916e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4662/6000 [4:32:57<1:16:15,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [4:33:00<1:16:00,  3.41s/it]                                                       {'loss': 0.054, 'grad_norm': 9.055573463439941, 'learning_rate': 2.2661016949152545e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4663/6000 [4:33:00<1:16:00,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [4:33:04<1:15:39,  3.40s/it]                                                       {'loss': 0.0979, 'grad_norm': 13.160277366638184, 'learning_rate': 2.2644067796610173e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4664/6000 [4:33:04<1:15:39,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [4:33:07<1:15:04,  3.37s/it]                                                       {'loss': 0.1489, 'grad_norm': 8.104143142700195, 'learning_rate': 2.26271186440678e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4665/6000 [4:33:07<1:15:04,  3.37s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [4:33:10<1:14:40,  3.36s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.08057041466236115, 'learning_rate': 2.2610169491525426e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4666/6000 [4:33:10<1:14:40,  3.36s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [4:33:14<1:14:59,  3.38s/it]                                                       {'loss': 0.0842, 'grad_norm': 11.51016616821289, 'learning_rate': 2.259322033898305e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4667/6000 [4:33:14<1:14:59,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [4:33:17<1:15:07,  3.38s/it]                                                       {'loss': 0.0089, 'grad_norm': 4.097372055053711, 'learning_rate': 2.257627118644068e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4668/6000 [4:33:17<1:15:07,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [4:33:21<1:14:46,  3.37s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.29941919445991516, 'learning_rate': 2.2559322033898307e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4669/6000 [4:33:21<1:14:46,  3.37s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [4:33:24<1:14:32,  3.36s/it]                                                       {'loss': 0.0209, 'grad_norm': 4.33189582824707, 'learning_rate': 2.2542372881355936e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4670/6000 [4:33:24<1:14:32,  3.36s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [4:33:27<1:14:55,  3.38s/it]                                                       {'loss': 0.1451, 'grad_norm': 11.74352741241455, 'learning_rate': 2.252542372881356e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4671/6000 [4:33:27<1:14:55,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [4:33:31<1:16:15,  3.45s/it]                                                       {'loss': 0.3894, 'grad_norm': 20.307851791381836, 'learning_rate': 2.250847457627119e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4672/6000 [4:33:31<1:16:15,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [4:33:34<1:16:17,  3.45s/it]                                                       {'loss': 0.0171, 'grad_norm': 6.053072452545166, 'learning_rate': 2.2491525423728817e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4673/6000 [4:33:34<1:16:17,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [4:33:38<1:15:40,  3.42s/it]                                                       {'loss': 0.0671, 'grad_norm': 11.252236366271973, 'learning_rate': 2.2474576271186445e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4674/6000 [4:33:38<1:15:40,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [4:33:41<1:15:06,  3.40s/it]                                                       {'loss': 0.0018, 'grad_norm': 0.4672481417655945, 'learning_rate': 2.245762711864407e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4675/6000 [4:33:41<1:15:06,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [4:33:44<1:14:58,  3.40s/it]                                                       {'loss': 0.0176, 'grad_norm': 5.158631324768066, 'learning_rate': 2.2440677966101694e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/6000 [4:33:44<1:14:58,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [4:33:48<1:14:36,  3.38s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.2926659882068634, 'learning_rate': 2.2423728813559322e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4677/6000 [4:33:48<1:14:36,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [4:33:51<1:14:47,  3.39s/it]                                                       {'loss': 0.08, 'grad_norm': 12.09936237335205, 'learning_rate': 2.240677966101695e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4678/6000 [4:33:51<1:14:47,  3.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [4:33:55<1:15:00,  3.41s/it]                                                       {'loss': 0.0338, 'grad_norm': 9.20784854888916, 'learning_rate': 2.238983050847458e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4679/6000 [4:33:55<1:15:00,  3.41s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [4:33:58<1:14:18,  3.38s/it]                                                       {'loss': 0.0305, 'grad_norm': 8.507579803466797, 'learning_rate': 2.2372881355932204e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4680/6000 [4:33:58<1:14:18,  3.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [4:34:01<1:13:56,  3.36s/it]                                                       {'loss': 0.1154, 'grad_norm': 12.252251625061035, 'learning_rate': 2.2355932203389832e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4681/6000 [4:34:01<1:13:56,  3.36s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [4:34:05<1:14:35,  3.40s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.04813307151198387, 'learning_rate': 2.233898305084746e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4682/6000 [4:34:05<1:14:35,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [4:34:08<1:14:42,  3.40s/it]                                                       {'loss': 0.0496, 'grad_norm': 12.161224365234375, 'learning_rate': 2.232203389830509e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4683/6000 [4:34:08<1:14:42,  3.40s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [4:34:12<1:15:59,  3.46s/it]                                                       {'loss': 0.0127, 'grad_norm': 3.8994433879852295, 'learning_rate': 2.2305084745762714e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4684/6000 [4:34:12<1:15:59,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [4:34:15<1:15:57,  3.47s/it]                                                       {'loss': 0.1288, 'grad_norm': 10.591435432434082, 'learning_rate': 2.228813559322034e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4685/6000 [4:34:15<1:15:57,  3.47s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [4:34:19<1:16:59,  3.52s/it]                                                       {'loss': 0.0456, 'grad_norm': 7.178289413452148, 'learning_rate': 2.227118644067797e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4686/6000 [4:34:19<1:16:59,  3.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [4:34:22<1:15:45,  3.46s/it]                                                       {'loss': 0.113, 'grad_norm': 8.976387977600098, 'learning_rate': 2.2254237288135595e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4687/6000 [4:34:22<1:15:45,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [4:34:26<1:15:23,  3.45s/it]                                                       {'loss': 0.0547, 'grad_norm': 9.759109497070312, 'learning_rate': 2.2237288135593223e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4688/6000 [4:34:26<1:15:23,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [4:34:29<1:17:25,  3.54s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.878069519996643, 'learning_rate': 2.2220338983050848e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4689/6000 [4:34:29<1:17:25,  3.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [4:34:33<1:16:46,  3.52s/it]                                                       {'loss': 0.0793, 'grad_norm': 12.33957290649414, 'learning_rate': 2.2203389830508476e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4690/6000 [4:34:33<1:16:46,  3.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [4:34:36<1:15:59,  3.48s/it]                                                       {'loss': 0.2514, 'grad_norm': 13.809574127197266, 'learning_rate': 2.2186440677966105e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4691/6000 [4:34:36<1:15:59,  3.48s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [4:34:40<1:14:46,  3.43s/it]                                                       {'loss': 0.0659, 'grad_norm': 2.921747922897339, 'learning_rate': 2.216949152542373e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4692/6000 [4:34:40<1:14:46,  3.43s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [4:34:43<1:15:16,  3.46s/it]                                                       {'loss': 0.0573, 'grad_norm': 11.323871612548828, 'learning_rate': 2.2152542372881357e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4693/6000 [4:34:43<1:15:16,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [4:34:47<1:15:06,  3.45s/it]                                                       {'loss': 0.002, 'grad_norm': 0.6028794646263123, 'learning_rate': 2.2135593220338986e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4694/6000 [4:34:47<1:15:06,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [4:34:50<1:16:44,  3.53s/it]                                                       {'loss': 0.0185, 'grad_norm': 5.693308353424072, 'learning_rate': 2.2118644067796614e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4695/6000 [4:34:50<1:16:44,  3.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [4:34:54<1:15:44,  3.49s/it]                                                       {'loss': 0.0365, 'grad_norm': 5.460797309875488, 'learning_rate': 2.210169491525424e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4696/6000 [4:34:54<1:15:44,  3.49s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [4:34:57<1:16:35,  3.53s/it]                                                       {'loss': 0.0547, 'grad_norm': 6.820648670196533, 'learning_rate': 2.2084745762711867e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4697/6000 [4:34:57<1:16:35,  3.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [4:35:01<1:15:10,  3.46s/it]                                                       {'loss': 0.0103, 'grad_norm': 2.1638684272766113, 'learning_rate': 2.206779661016949e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4698/6000 [4:35:01<1:15:10,  3.46s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [4:35:04<1:14:32,  3.44s/it]                                                       {'loss': 0.0141, 'grad_norm': 3.3295347690582275, 'learning_rate': 2.205084745762712e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4699/6000 [4:35:04<1:14:32,  3.44s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [4:35:07<1:14:30,  3.44s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.8479872941970825, 'learning_rate': 2.203389830508475e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4700/6000 [4:35:07<1:14:30,  3.44s/it][2025-11-07 03:26:17,385] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4700
[2025-11-07 03:26:17,400] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:26:18,084] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4700/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [4:35:13<1:29:39,  4.14s/it]                                                       {'loss': 0.0809, 'grad_norm': 11.030445098876953, 'learning_rate': 2.2016949152542373e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4701/6000 [4:35:13<1:29:39,  4.14s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [4:35:17<1:25:41,  3.96s/it]                                                       {'loss': 0.0709, 'grad_norm': 8.858041763305664, 'learning_rate': 2.2e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4702/6000 [4:35:17<1:25:41,  3.96s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [4:35:20<1:22:13,  3.80s/it]                                                       {'loss': 0.0279, 'grad_norm': 4.99536657333374, 'learning_rate': 2.198305084745763e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4703/6000 [4:35:20<1:22:13,  3.80s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [4:35:24<1:19:34,  3.68s/it]                                                       {'loss': 0.1751, 'grad_norm': 13.63325309753418, 'learning_rate': 2.196610169491526e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4704/6000 [4:35:24<1:19:34,  3.68s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [4:35:27<1:18:02,  3.62s/it]                                                       {'loss': 0.0634, 'grad_norm': 10.163473129272461, 'learning_rate': 2.1949152542372882e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4705/6000 [4:35:27<1:18:02,  3.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [4:35:30<1:16:48,  3.56s/it]                                                       {'loss': 0.2694, 'grad_norm': 14.264707565307617, 'learning_rate': 2.193220338983051e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4706/6000 [4:35:30<1:16:48,  3.56s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [4:35:34<1:15:32,  3.51s/it]                                                       {'loss': 0.0188, 'grad_norm': 2.6942098140716553, 'learning_rate': 2.1915254237288135e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4707/6000 [4:35:34<1:15:32,  3.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [4:35:37<1:14:20,  3.45s/it]                                                       {'loss': 0.0107, 'grad_norm': 2.7826743125915527, 'learning_rate': 2.1898305084745764e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4708/6000 [4:35:37<1:14:20,  3.45s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [4:35:40<1:13:28,  3.42s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.017262417823076248, 'learning_rate': 2.1881355932203392e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4709/6000 [4:35:40<1:13:28,  3.42s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [4:35:44<1:13:16,  3.41s/it]                                                       {'loss': 0.0148, 'grad_norm': 2.1280415058135986, 'learning_rate': 2.1864406779661016e-06, 'epoch': 0.79}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4710/6000 [4:35:44<1:13:16,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [4:35:47<1:12:42,  3.38s/it]                                                       {'loss': 0.0769, 'grad_norm': 5.611674785614014, 'learning_rate': 2.1847457627118645e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4711/6000 [4:35:47<1:12:42,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [4:35:51<1:14:57,  3.49s/it]                                                       {'loss': 0.0629, 'grad_norm': 5.136313438415527, 'learning_rate': 2.1830508474576273e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4712/6000 [4:35:51<1:14:57,  3.49s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [4:35:54<1:13:49,  3.44s/it]                                                       {'loss': 0.0014, 'grad_norm': 0.5013898015022278, 'learning_rate': 2.18135593220339e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4713/6000 [4:35:54<1:13:49,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [4:35:58<1:16:20,  3.56s/it]                                                       {'loss': 0.3169, 'grad_norm': 11.739209175109863, 'learning_rate': 2.1796610169491526e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4714/6000 [4:35:58<1:16:20,  3.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [4:36:01<1:14:31,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.44487953186035156, 'learning_rate': 2.1779661016949155e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4715/6000 [4:36:01<1:14:31,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [4:36:05<1:13:40,  3.44s/it]                                                       {'loss': 0.006, 'grad_norm': 0.9089984893798828, 'learning_rate': 2.1762711864406783e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4716/6000 [4:36:05<1:13:40,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [4:36:08<1:13:26,  3.43s/it]                                                       {'loss': 0.0134, 'grad_norm': 2.420271873474121, 'learning_rate': 2.174576271186441e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4717/6000 [4:36:08<1:13:26,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [4:36:12<1:15:08,  3.52s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.4965620040893555, 'learning_rate': 2.1728813559322036e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4718/6000 [4:36:12<1:15:08,  3.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [4:36:15<1:14:54,  3.51s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.07505268603563309, 'learning_rate': 2.171186440677966e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4719/6000 [4:36:15<1:14:54,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [4:36:19<1:14:16,  3.48s/it]                                                       {'loss': 0.0807, 'grad_norm': 12.962799072265625, 'learning_rate': 2.169491525423729e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4720/6000 [4:36:19<1:14:16,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [4:36:22<1:12:28,  3.40s/it]                                                       {'loss': 0.0798, 'grad_norm': 11.389556884765625, 'learning_rate': 2.1677966101694917e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4721/6000 [4:36:22<1:12:28,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [4:36:25<1:11:59,  3.38s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.7407968640327454, 'learning_rate': 2.1661016949152546e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4722/6000 [4:36:25<1:11:59,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [4:36:29<1:12:04,  3.39s/it]                                                       {'loss': 0.0657, 'grad_norm': 12.772027969360352, 'learning_rate': 2.164406779661017e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4723/6000 [4:36:29<1:12:04,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [4:36:32<1:12:04,  3.39s/it]                                                       {'loss': 0.0046, 'grad_norm': 1.4860897064208984, 'learning_rate': 2.16271186440678e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4724/6000 [4:36:32<1:12:04,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [4:36:36<1:12:41,  3.42s/it]                                                       {'loss': 0.0444, 'grad_norm': 7.069375038146973, 'learning_rate': 2.1610169491525427e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4725/6000 [4:36:36<1:12:41,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [4:36:39<1:15:11,  3.54s/it]                                                       {'loss': 0.1452, 'grad_norm': 14.574799537658691, 'learning_rate': 2.1593220338983056e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4726/6000 [4:36:39<1:15:11,  3.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [4:36:43<1:17:17,  3.64s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.34341055154800415, 'learning_rate': 2.157627118644068e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4727/6000 [4:36:43<1:17:17,  3.64s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [4:36:47<1:15:46,  3.57s/it]                                                       {'loss': 0.0351, 'grad_norm': 6.4549241065979, 'learning_rate': 2.1559322033898304e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/6000 [4:36:47<1:15:46,  3.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [4:36:50<1:14:47,  3.53s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.11561436206102371, 'learning_rate': 2.1542372881355933e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4729/6000 [4:36:50<1:14:47,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [4:36:54<1:14:14,  3.51s/it]                                                       {'loss': 0.044, 'grad_norm': 3.3469204902648926, 'learning_rate': 2.152542372881356e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4730/6000 [4:36:54<1:14:14,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [4:36:57<1:13:22,  3.47s/it]                                                       {'loss': 0.003, 'grad_norm': 1.1556415557861328, 'learning_rate': 2.150847457627119e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4731/6000 [4:36:57<1:13:22,  3.47s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [4:37:00<1:12:12,  3.42s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.06407784670591354, 'learning_rate': 2.1491525423728814e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4732/6000 [4:37:00<1:12:12,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [4:37:04<1:14:37,  3.53s/it]                                                       {'loss': 0.1567, 'grad_norm': 10.362663269042969, 'learning_rate': 2.1474576271186442e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4733/6000 [4:37:04<1:14:37,  3.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [4:37:08<1:14:43,  3.54s/it]                                                       {'loss': 0.0556, 'grad_norm': 10.344334602355957, 'learning_rate': 2.145762711864407e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4734/6000 [4:37:08<1:14:43,  3.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [4:37:11<1:13:46,  3.50s/it]                                                       {'loss': 0.0164, 'grad_norm': 5.453804016113281, 'learning_rate': 2.14406779661017e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4735/6000 [4:37:11<1:13:46,  3.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [4:37:14<1:12:56,  3.46s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1327885389328003, 'learning_rate': 2.1423728813559324e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4736/6000 [4:37:14<1:12:56,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [4:37:18<1:12:23,  3.44s/it]                                                       {'loss': 0.0051, 'grad_norm': 1.068153738975525, 'learning_rate': 2.140677966101695e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4737/6000 [4:37:18<1:12:23,  3.44s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [4:37:22<1:14:51,  3.56s/it]                                                       {'loss': 0.0703, 'grad_norm': 4.200763702392578, 'learning_rate': 2.1389830508474576e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4738/6000 [4:37:22<1:14:51,  3.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [4:37:25<1:14:05,  3.52s/it]                                                       {'loss': 0.0092, 'grad_norm': 2.512859344482422, 'learning_rate': 2.1372881355932205e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4739/6000 [4:37:25<1:14:05,  3.52s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [4:37:29<1:13:42,  3.51s/it]                                                       {'loss': 0.1131, 'grad_norm': 7.163400650024414, 'learning_rate': 2.1355932203389833e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4740/6000 [4:37:29<1:13:42,  3.51s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [4:37:32<1:12:36,  3.46s/it]                                                       {'loss': 0.2585, 'grad_norm': 24.399234771728516, 'learning_rate': 2.1338983050847458e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4741/6000 [4:37:32<1:12:36,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [4:37:35<1:12:54,  3.48s/it]                                                       {'loss': 0.0105, 'grad_norm': 3.955317974090576, 'learning_rate': 2.1322033898305086e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4742/6000 [4:37:35<1:12:54,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [4:37:39<1:12:16,  3.45s/it]                                                       {'loss': 0.1183, 'grad_norm': 11.059532165527344, 'learning_rate': 2.1305084745762715e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4743/6000 [4:37:39<1:12:16,  3.45s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [4:37:42<1:11:37,  3.42s/it]                                                       {'loss': 0.0551, 'grad_norm': 18.68850326538086, 'learning_rate': 2.128813559322034e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4744/6000 [4:37:42<1:11:37,  3.42s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [4:37:45<1:10:51,  3.39s/it]                                                       {'loss': 0.0884, 'grad_norm': 9.105982780456543, 'learning_rate': 2.1271186440677967e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4745/6000 [4:37:45<1:10:51,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [4:37:49<1:10:49,  3.39s/it]                                                       {'loss': 0.0877, 'grad_norm': 10.20961856842041, 'learning_rate': 2.1254237288135596e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4746/6000 [4:37:49<1:10:49,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [4:37:53<1:12:17,  3.46s/it]                                                       {'loss': 0.1205, 'grad_norm': 22.36092758178711, 'learning_rate': 2.1237288135593224e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4747/6000 [4:37:53<1:12:17,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [4:37:56<1:11:37,  3.43s/it]                                                       {'loss': 0.002, 'grad_norm': 0.5728915333747864, 'learning_rate': 2.122033898305085e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4748/6000 [4:37:56<1:11:37,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [4:37:59<1:10:59,  3.40s/it]                                                       {'loss': 0.0518, 'grad_norm': 10.153287887573242, 'learning_rate': 2.1203389830508477e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4749/6000 [4:37:59<1:10:59,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [4:38:03<1:10:32,  3.39s/it]                                                       {'loss': 0.0142, 'grad_norm': 3.8228235244750977, 'learning_rate': 2.11864406779661e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4750/6000 [4:38:03<1:10:32,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [4:38:06<1:10:50,  3.40s/it]                                                       {'loss': 0.0173, 'grad_norm': 3.520879030227661, 'learning_rate': 2.116949152542373e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4751/6000 [4:38:06<1:10:50,  3.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [4:38:09<1:11:18,  3.43s/it]                                                       {'loss': 0.0775, 'grad_norm': 14.839548110961914, 'learning_rate': 2.115254237288136e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4752/6000 [4:38:09<1:11:18,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [4:38:13<1:10:49,  3.41s/it]                                                       {'loss': 0.0062, 'grad_norm': 1.3104907274246216, 'learning_rate': 2.1135593220338983e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4753/6000 [4:38:13<1:10:49,  3.41s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [4:38:16<1:10:12,  3.38s/it]                                                       {'loss': 0.0109, 'grad_norm': 2.717759132385254, 'learning_rate': 2.111864406779661e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4754/6000 [4:38:16<1:10:12,  3.38s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [4:38:20<1:10:00,  3.37s/it]                                                       {'loss': 0.0095, 'grad_norm': 2.5334632396698, 'learning_rate': 2.110169491525424e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4755/6000 [4:38:20<1:10:00,  3.37s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [4:38:23<1:09:43,  3.36s/it]                                                       {'loss': 0.0352, 'grad_norm': 6.350229263305664, 'learning_rate': 2.108474576271187e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4756/6000 [4:38:23<1:09:43,  3.36s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [4:38:26<1:09:10,  3.34s/it]                                                       {'loss': 0.0503, 'grad_norm': 12.228403091430664, 'learning_rate': 2.1067796610169492e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4757/6000 [4:38:26<1:09:10,  3.34s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [4:38:30<1:09:28,  3.36s/it]                                                       {'loss': 0.0459, 'grad_norm': 8.494187355041504, 'learning_rate': 2.105084745762712e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4758/6000 [4:38:30<1:09:28,  3.36s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [4:38:33<1:09:31,  3.36s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.3634690046310425, 'learning_rate': 2.1033898305084745e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4759/6000 [4:38:33<1:09:31,  3.36s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [4:38:36<1:09:18,  3.35s/it]                                                       {'loss': 0.164, 'grad_norm': 14.407506942749023, 'learning_rate': 2.1016949152542374e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4760/6000 [4:38:36<1:09:18,  3.35s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [4:38:40<1:09:30,  3.37s/it]                                                       {'loss': 0.0042, 'grad_norm': 0.9143475890159607, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4761/6000 [4:38:40<1:09:30,  3.37s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [4:38:43<1:09:36,  3.37s/it]                                                       {'loss': 0.0054, 'grad_norm': 1.2037185430526733, 'learning_rate': 2.0983050847457626e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4762/6000 [4:38:43<1:09:36,  3.37s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [4:38:46<1:09:18,  3.36s/it]                                                       {'loss': 0.2423, 'grad_norm': 14.868399620056152, 'learning_rate': 2.0966101694915255e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4763/6000 [4:38:46<1:09:18,  3.36s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [4:38:50<1:11:43,  3.48s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.6057729125022888, 'learning_rate': 2.0949152542372883e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4764/6000 [4:38:50<1:11:43,  3.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [4:38:54<1:11:12,  3.46s/it]                                                       {'loss': 0.1053, 'grad_norm': 9.197122573852539, 'learning_rate': 2.093220338983051e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4765/6000 [4:38:54<1:11:12,  3.46s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [4:38:57<1:10:28,  3.43s/it]                                                       {'loss': 0.0127, 'grad_norm': 4.309499263763428, 'learning_rate': 2.0915254237288136e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4766/6000 [4:38:57<1:10:28,  3.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [4:39:00<1:09:44,  3.39s/it]                                                       {'loss': 0.1166, 'grad_norm': 14.459108352661133, 'learning_rate': 2.0898305084745765e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4767/6000 [4:39:00<1:09:44,  3.39s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [4:39:04<1:09:09,  3.37s/it]                                                       {'loss': 0.0575, 'grad_norm': 10.144548416137695, 'learning_rate': 2.0881355932203393e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4768/6000 [4:39:04<1:09:09,  3.37s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [4:39:07<1:10:37,  3.44s/it]                                                       {'loss': 0.2026, 'grad_norm': 18.84251594543457, 'learning_rate': 2.086440677966102e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4769/6000 [4:39:07<1:10:37,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [4:39:11<1:10:26,  3.44s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.19291377067565918, 'learning_rate': 2.0847457627118646e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4770/6000 [4:39:11<1:10:26,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [4:39:14<1:11:03,  3.47s/it]                                                       {'loss': 0.0102, 'grad_norm': 3.0694119930267334, 'learning_rate': 2.083050847457627e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4771/6000 [4:39:14<1:11:03,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [4:39:17<1:09:57,  3.42s/it]                                                       {'loss': 0.0946, 'grad_norm': 12.828022956848145, 'learning_rate': 2.08135593220339e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4772/6000 [4:39:17<1:09:57,  3.42s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [4:39:21<1:11:07,  3.48s/it]                                                       {'loss': 0.0163, 'grad_norm': 3.960151195526123, 'learning_rate': 2.0796610169491527e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4773/6000 [4:39:21<1:11:07,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [4:39:25<1:11:34,  3.50s/it]                                                       {'loss': 0.1166, 'grad_norm': 8.177230834960938, 'learning_rate': 2.0779661016949156e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4774/6000 [4:39:25<1:11:34,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [4:39:28<1:11:37,  3.51s/it]                                                       {'loss': 0.3586, 'grad_norm': 20.48705291748047, 'learning_rate': 2.076271186440678e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4775/6000 [4:39:28<1:11:37,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [4:39:32<1:11:10,  3.49s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.6295417547225952, 'learning_rate': 2.074576271186441e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4776/6000 [4:39:32<1:11:10,  3.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [4:39:35<1:10:14,  3.45s/it]                                                       {'loss': 0.0355, 'grad_norm': 4.89741325378418, 'learning_rate': 2.0728813559322037e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4777/6000 [4:39:35<1:10:14,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [4:39:39<1:11:18,  3.50s/it]                                                       {'loss': 0.0013, 'grad_norm': 0.30098724365234375, 'learning_rate': 2.0711864406779666e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4778/6000 [4:39:39<1:11:18,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [4:39:43<1:15:00,  3.69s/it]                                                       {'loss': 0.1367, 'grad_norm': 14.260567665100098, 'learning_rate': 2.069491525423729e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4779/6000 [4:39:43<1:15:00,  3.69s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [4:39:46<1:13:01,  3.59s/it]                                                       {'loss': 0.0134, 'grad_norm': 3.509596824645996, 'learning_rate': 2.0677966101694914e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4780/6000 [4:39:46<1:13:01,  3.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [4:39:50<1:13:17,  3.61s/it]                                                       {'loss': 0.0908, 'grad_norm': 11.093198776245117, 'learning_rate': 2.0661016949152543e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4781/6000 [4:39:50<1:13:17,  3.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [4:39:53<1:11:30,  3.52s/it]                                                       {'loss': 0.0064, 'grad_norm': 2.046684503555298, 'learning_rate': 2.064406779661017e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4782/6000 [4:39:53<1:11:30,  3.52s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [4:39:56<1:10:22,  3.47s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.1440916657447815, 'learning_rate': 2.06271186440678e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4783/6000 [4:39:56<1:10:22,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [4:40:00<1:12:30,  3.58s/it]                                                       {'loss': 0.2198, 'grad_norm': 17.017297744750977, 'learning_rate': 2.0610169491525424e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4784/6000 [4:40:00<1:12:30,  3.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [4:40:03<1:10:50,  3.50s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.17008401453495026, 'learning_rate': 2.0593220338983052e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4785/6000 [4:40:03<1:10:50,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [4:40:07<1:09:54,  3.46s/it]                                                       {'loss': 0.0072, 'grad_norm': 1.5221837759017944, 'learning_rate': 2.057627118644068e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4786/6000 [4:40:07<1:09:54,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [4:40:11<1:11:46,  3.55s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.10816332697868347, 'learning_rate': 2.055932203389831e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4787/6000 [4:40:11<1:11:46,  3.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [4:40:14<1:13:06,  3.62s/it]                                                       {'loss': 0.0063, 'grad_norm': 1.1600534915924072, 'learning_rate': 2.0542372881355934e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4788/6000 [4:40:14<1:13:06,  3.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [4:40:18<1:11:46,  3.56s/it]                                                       {'loss': 0.0136, 'grad_norm': 3.1680080890655518, 'learning_rate': 2.0525423728813562e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4789/6000 [4:40:18<1:11:46,  3.56s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [4:40:21<1:10:52,  3.51s/it]                                                       {'loss': 0.0008, 'grad_norm': 0.19539795815944672, 'learning_rate': 2.0508474576271186e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4790/6000 [4:40:21<1:10:52,  3.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [4:40:25<1:09:39,  3.46s/it]                                                       {'loss': 0.0105, 'grad_norm': 1.9008145332336426, 'learning_rate': 2.0491525423728815e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4791/6000 [4:40:25<1:09:39,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [4:40:28<1:10:49,  3.52s/it]                                                       {'loss': 0.0117, 'grad_norm': 2.9440696239471436, 'learning_rate': 2.0474576271186443e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4792/6000 [4:40:28<1:10:49,  3.52s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [4:40:32<1:09:55,  3.48s/it]                                                       {'loss': 0.0843, 'grad_norm': 13.820862770080566, 'learning_rate': 2.0457627118644068e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4793/6000 [4:40:32<1:09:55,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [4:40:35<1:09:44,  3.47s/it]                                                       {'loss': 0.029, 'grad_norm': 6.0109124183654785, 'learning_rate': 2.0440677966101696e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4794/6000 [4:40:35<1:09:44,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [4:40:38<1:09:15,  3.45s/it]                                                       {'loss': 0.0521, 'grad_norm': 9.536903381347656, 'learning_rate': 2.0423728813559325e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4795/6000 [4:40:38<1:09:15,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [4:40:42<1:09:24,  3.46s/it]                                                       {'loss': 0.1116, 'grad_norm': 14.896364212036133, 'learning_rate': 2.0406779661016953e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4796/6000 [4:40:42<1:09:24,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [4:40:45<1:09:14,  3.45s/it]                                                       {'loss': 0.0119, 'grad_norm': 4.657186508178711, 'learning_rate': 2.0389830508474577e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4797/6000 [4:40:45<1:09:14,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [4:40:49<1:08:01,  3.40s/it]                                                       {'loss': 0.0504, 'grad_norm': 9.25272274017334, 'learning_rate': 2.0372881355932206e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4798/6000 [4:40:49<1:08:01,  3.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [4:40:52<1:10:04,  3.50s/it]                                                       {'loss': 0.0028, 'grad_norm': 0.7491887211799622, 'learning_rate': 2.0355932203389834e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4799/6000 [4:40:52<1:10:04,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [4:40:56<1:09:04,  3.45s/it]                                                       {'loss': 0.1068, 'grad_norm': 7.501399993896484, 'learning_rate': 2.033898305084746e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4800/6000 [4:40:56<1:09:04,  3.45s/it][2025-11-07 03:32:05,681] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4800
[2025-11-07 03:32:05,695] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:32:06,368] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4800/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [4:41:01<1:22:18,  4.12s/it]                                                       {'loss': 0.0109, 'grad_norm': 3.091862678527832, 'learning_rate': 2.0322033898305087e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4801/6000 [4:41:01<1:22:18,  4.12s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [4:41:05<1:22:14,  4.12s/it]                                                       {'loss': 0.0024, 'grad_norm': 0.8353184461593628, 'learning_rate': 2.030508474576271e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4802/6000 [4:41:05<1:22:14,  4.12s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [4:41:09<1:18:42,  3.94s/it]                                                       {'loss': 0.0263, 'grad_norm': 7.211456775665283, 'learning_rate': 2.028813559322034e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4803/6000 [4:41:09<1:18:42,  3.94s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [4:41:12<1:15:34,  3.79s/it]                                                       {'loss': 0.0423, 'grad_norm': 2.497565507888794, 'learning_rate': 2.027118644067797e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4804/6000 [4:41:12<1:15:34,  3.79s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [4:41:16<1:14:52,  3.76s/it]                                                       {'loss': 0.1645, 'grad_norm': 10.397825241088867, 'learning_rate': 2.0254237288135593e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4805/6000 [4:41:16<1:14:52,  3.76s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [4:41:19<1:12:25,  3.64s/it]                                                       {'loss': 0.0206, 'grad_norm': 5.910821437835693, 'learning_rate': 2.023728813559322e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4806/6000 [4:41:19<1:12:25,  3.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [4:41:23<1:11:15,  3.58s/it]                                                       {'loss': 0.0088, 'grad_norm': 2.7359113693237305, 'learning_rate': 2.022033898305085e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4807/6000 [4:41:23<1:11:15,  3.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [4:41:26<1:09:50,  3.52s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.2121439278125763, 'learning_rate': 2.020338983050848e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4808/6000 [4:41:26<1:09:50,  3.52s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [4:41:30<1:08:49,  3.47s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.9427391290664673, 'learning_rate': 2.0186440677966103e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4809/6000 [4:41:30<1:08:49,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [4:41:33<1:07:56,  3.43s/it]                                                       {'loss': 0.1337, 'grad_norm': 9.252029418945312, 'learning_rate': 2.016949152542373e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4810/6000 [4:41:33<1:07:56,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [4:41:36<1:07:51,  3.42s/it]                                                       {'loss': 0.01, 'grad_norm': 1.061842918395996, 'learning_rate': 2.0152542372881355e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4811/6000 [4:41:36<1:07:51,  3.42s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [4:41:40<1:08:36,  3.46s/it]                                                       {'loss': 0.0376, 'grad_norm': 8.575806617736816, 'learning_rate': 2.0135593220338984e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4812/6000 [4:41:40<1:08:36,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [4:41:43<1:08:05,  3.44s/it]                                                       {'loss': 0.0154, 'grad_norm': 3.907634973526001, 'learning_rate': 2.0118644067796612e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4813/6000 [4:41:43<1:08:05,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [4:41:48<1:12:18,  3.66s/it]                                                       {'loss': 0.0043, 'grad_norm': 0.7664596438407898, 'learning_rate': 2.0101694915254237e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4814/6000 [4:41:48<1:12:18,  3.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [4:41:51<1:10:29,  3.57s/it]                                                       {'loss': 0.0079, 'grad_norm': 2.9197442531585693, 'learning_rate': 2.0084745762711865e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4815/6000 [4:41:51<1:10:29,  3.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [4:41:54<1:09:08,  3.50s/it]                                                       {'loss': 0.1708, 'grad_norm': 15.628002166748047, 'learning_rate': 2.0067796610169494e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4816/6000 [4:41:54<1:09:08,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [4:41:58<1:08:24,  3.47s/it]                                                       {'loss': 0.0736, 'grad_norm': 11.17341423034668, 'learning_rate': 2.005084745762712e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4817/6000 [4:41:58<1:08:24,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [4:42:02<1:10:58,  3.60s/it]                                                       {'loss': 0.033, 'grad_norm': 6.143922328948975, 'learning_rate': 2.0033898305084746e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4818/6000 [4:42:02<1:10:58,  3.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [4:42:05<1:10:13,  3.57s/it]                                                       {'loss': 0.0493, 'grad_norm': 9.733746528625488, 'learning_rate': 2.0016949152542375e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4819/6000 [4:42:05<1:10:13,  3.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [4:42:08<1:09:07,  3.52s/it]                                                       {'loss': 0.0102, 'grad_norm': 2.8311522006988525, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4820/6000 [4:42:08<1:09:07,  3.52s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [4:42:12<1:08:06,  3.47s/it]                                                       {'loss': 0.0007, 'grad_norm': 0.1612422615289688, 'learning_rate': 1.998305084745763e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4821/6000 [4:42:12<1:08:06,  3.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [4:42:15<1:08:42,  3.50s/it]                                                       {'loss': 0.0153, 'grad_norm': 3.0031356811523438, 'learning_rate': 1.9966101694915256e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4822/6000 [4:42:15<1:08:42,  3.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [4:42:19<1:07:54,  3.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.027520358562469482, 'learning_rate': 1.994915254237288e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4823/6000 [4:42:19<1:07:54,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [4:42:22<1:07:15,  3.43s/it]                                                       {'loss': 0.1289, 'grad_norm': 12.389455795288086, 'learning_rate': 1.993220338983051e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4824/6000 [4:42:22<1:07:15,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [4:42:26<1:09:16,  3.54s/it]                                                       {'loss': 0.0193, 'grad_norm': 4.458551406860352, 'learning_rate': 1.9915254237288137e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4825/6000 [4:42:26<1:09:16,  3.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [4:42:29<1:07:59,  3.48s/it]                                                       {'loss': 0.1229, 'grad_norm': 15.17707633972168, 'learning_rate': 1.9898305084745766e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4826/6000 [4:42:29<1:07:59,  3.48s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [4:42:33<1:07:38,  3.46s/it]                                                       {'loss': 0.3501, 'grad_norm': 17.875324249267578, 'learning_rate': 1.988135593220339e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4827/6000 [4:42:33<1:07:38,  3.46s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [4:42:36<1:07:16,  3.44s/it]                                                       {'loss': 0.0148, 'grad_norm': 4.140469074249268, 'learning_rate': 1.986440677966102e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4828/6000 [4:42:36<1:07:16,  3.44s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [4:42:39<1:07:19,  3.45s/it]                                                       {'loss': 0.1763, 'grad_norm': 14.607542037963867, 'learning_rate': 1.9847457627118647e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4829/6000 [4:42:39<1:07:19,  3.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [4:42:44<1:15:16,  3.86s/it]                                                       {'loss': 0.004, 'grad_norm': 0.5581457018852234, 'learning_rate': 1.9830508474576276e-06, 'epoch': 0.81}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4830/6000 [4:42:44<1:15:16,  3.86s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [4:42:48<1:13:56,  3.79s/it]                                                       {'loss': 0.0101, 'grad_norm': 1.3026927709579468, 'learning_rate': 1.98135593220339e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4831/6000 [4:42:48<1:13:56,  3.79s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [4:42:51<1:11:28,  3.67s/it]                                                       {'loss': 0.0297, 'grad_norm': 2.0896921157836914, 'learning_rate': 1.9796610169491524e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4832/6000 [4:42:51<1:11:28,  3.67s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [4:42:55<1:12:48,  3.74s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.2768798768520355, 'learning_rate': 1.9779661016949153e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4833/6000 [4:42:55<1:12:48,  3.74s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [4:42:59<1:10:27,  3.63s/it]                                                       {'loss': 0.015, 'grad_norm': 4.536969184875488, 'learning_rate': 1.976271186440678e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4834/6000 [4:42:59<1:10:27,  3.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [4:43:03<1:13:44,  3.80s/it]                                                       {'loss': 0.0411, 'grad_norm': 6.865330219268799, 'learning_rate': 1.974576271186441e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4835/6000 [4:43:03<1:13:44,  3.80s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [4:43:06<1:11:51,  3.70s/it]                                                       {'loss': 0.0603, 'grad_norm': 8.816521644592285, 'learning_rate': 1.9728813559322034e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4836/6000 [4:43:06<1:11:51,  3.70s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [4:43:10<1:10:05,  3.62s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.16605184972286224, 'learning_rate': 1.9711864406779662e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4837/6000 [4:43:10<1:10:05,  3.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [4:43:14<1:11:26,  3.69s/it]                                                       {'loss': 0.085, 'grad_norm': 7.295488357543945, 'learning_rate': 1.969491525423729e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4838/6000 [4:43:14<1:11:26,  3.69s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [4:43:18<1:16:13,  3.94s/it]                                                       {'loss': 0.0519, 'grad_norm': 8.887029647827148, 'learning_rate': 1.967796610169492e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4839/6000 [4:43:18<1:16:13,  3.94s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [4:43:21<1:13:03,  3.78s/it]                                                       {'loss': 0.2119, 'grad_norm': 9.587170600891113, 'learning_rate': 1.9661016949152544e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4840/6000 [4:43:21<1:13:03,  3.78s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [4:43:25<1:10:57,  3.67s/it]                                                       {'loss': 0.0194, 'grad_norm': 3.367943286895752, 'learning_rate': 1.9644067796610172e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4841/6000 [4:43:25<1:10:57,  3.67s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [4:43:28<1:09:31,  3.60s/it]                                                       {'loss': 0.0093, 'grad_norm': 3.069016933441162, 'learning_rate': 1.9627118644067796e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4842/6000 [4:43:28<1:09:31,  3.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [4:43:32<1:10:29,  3.66s/it]                                                       {'loss': 0.2062, 'grad_norm': 18.47418975830078, 'learning_rate': 1.9610169491525425e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4843/6000 [4:43:32<1:10:29,  3.66s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [4:43:36<1:09:59,  3.63s/it]                                                       {'loss': 0.0034, 'grad_norm': 1.3634625673294067, 'learning_rate': 1.9593220338983053e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4844/6000 [4:43:36<1:09:59,  3.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [4:43:39<1:08:34,  3.56s/it]                                                       {'loss': 0.2749, 'grad_norm': 15.54328441619873, 'learning_rate': 1.9576271186440678e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4845/6000 [4:43:39<1:08:34,  3.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [4:43:42<1:06:50,  3.48s/it]                                                       {'loss': 0.0523, 'grad_norm': 2.7685394287109375, 'learning_rate': 1.9559322033898306e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4846/6000 [4:43:42<1:06:50,  3.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [4:43:46<1:06:21,  3.45s/it]                                                       {'loss': 0.0146, 'grad_norm': 3.1312592029571533, 'learning_rate': 1.9542372881355935e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4847/6000 [4:43:46<1:06:21,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [4:43:49<1:05:50,  3.43s/it]                                                       {'loss': 0.0073, 'grad_norm': 1.8230513334274292, 'learning_rate': 1.9525423728813563e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4848/6000 [4:43:49<1:05:50,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [4:43:53<1:06:29,  3.47s/it]                                                       {'loss': 0.0151, 'grad_norm': 3.801290512084961, 'learning_rate': 1.9508474576271188e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4849/6000 [4:43:53<1:06:29,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [4:43:56<1:06:20,  3.46s/it]                                                       {'loss': 0.0513, 'grad_norm': 7.9828619956970215, 'learning_rate': 1.9491525423728816e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4850/6000 [4:43:56<1:06:20,  3.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [4:44:00<1:06:50,  3.49s/it]                                                       {'loss': 0.154, 'grad_norm': 14.297822952270508, 'learning_rate': 1.9474576271186445e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4851/6000 [4:44:00<1:06:50,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [4:44:03<1:05:55,  3.45s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.09010705351829529, 'learning_rate': 1.945762711864407e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4852/6000 [4:44:03<1:05:55,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [4:44:06<1:04:56,  3.40s/it]                                                       {'loss': 0.0005, 'grad_norm': 0.2112555354833603, 'learning_rate': 1.9440677966101697e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4853/6000 [4:44:06<1:04:56,  3.40s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [4:44:10<1:06:06,  3.46s/it]                                                       {'loss': 0.2273, 'grad_norm': 12.29848575592041, 'learning_rate': 1.942372881355932e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4854/6000 [4:44:10<1:06:06,  3.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [4:44:14<1:07:31,  3.54s/it]                                                       {'loss': 0.1132, 'grad_norm': 12.54773235321045, 'learning_rate': 1.940677966101695e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4855/6000 [4:44:14<1:07:31,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [4:44:17<1:05:57,  3.46s/it]                                                       {'loss': 0.0543, 'grad_norm': 10.350885391235352, 'learning_rate': 1.938983050847458e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4856/6000 [4:44:17<1:05:57,  3.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [4:44:20<1:05:17,  3.43s/it]                                                       {'loss': 0.0025, 'grad_norm': 0.6793596148490906, 'learning_rate': 1.9372881355932203e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4857/6000 [4:44:20<1:05:17,  3.43s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [4:44:24<1:07:16,  3.53s/it]                                                       {'loss': 0.3077, 'grad_norm': 16.557680130004883, 'learning_rate': 1.935593220338983e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4858/6000 [4:44:24<1:07:16,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [4:44:28<1:08:59,  3.63s/it]                                                       {'loss': 0.0194, 'grad_norm': 2.969107151031494, 'learning_rate': 1.933898305084746e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4859/6000 [4:44:28<1:08:59,  3.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [4:44:31<1:07:14,  3.54s/it]                                                       {'loss': 0.0269, 'grad_norm': 6.146634101867676, 'learning_rate': 1.932203389830509e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4860/6000 [4:44:31<1:07:14,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [4:44:35<1:06:22,  3.50s/it]                                                       {'loss': 0.0132, 'grad_norm': 4.381824493408203, 'learning_rate': 1.9305084745762713e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4861/6000 [4:44:35<1:06:22,  3.50s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [4:44:38<1:05:43,  3.47s/it]                                                       {'loss': 0.0535, 'grad_norm': 9.189472198486328, 'learning_rate': 1.928813559322034e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4862/6000 [4:44:38<1:05:43,  3.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [4:44:41<1:05:14,  3.44s/it]                                                       {'loss': 0.0515, 'grad_norm': 13.964159965515137, 'learning_rate': 1.9271186440677965e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4863/6000 [4:44:41<1:05:14,  3.44s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [4:44:45<1:07:15,  3.55s/it]                                                       {'loss': 0.0998, 'grad_norm': 8.855491638183594, 'learning_rate': 1.9254237288135594e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4864/6000 [4:44:45<1:07:15,  3.55s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [4:44:49<1:07:28,  3.57s/it]                                                       {'loss': 0.0099, 'grad_norm': 2.8434348106384277, 'learning_rate': 1.9237288135593222e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4865/6000 [4:44:49<1:07:28,  3.57s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [4:44:52<1:06:38,  3.53s/it]                                                       {'loss': 0.1017, 'grad_norm': 11.660809516906738, 'learning_rate': 1.9220338983050847e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4866/6000 [4:44:52<1:06:38,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [4:44:56<1:05:45,  3.48s/it]                                                       {'loss': 0.0064, 'grad_norm': 1.550877332687378, 'learning_rate': 1.9203389830508475e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4867/6000 [4:44:56<1:05:45,  3.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [4:44:59<1:05:33,  3.48s/it]                                                       {'loss': 0.0004, 'grad_norm': 0.08352862298488617, 'learning_rate': 1.9186440677966104e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4868/6000 [4:44:59<1:05:33,  3.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [4:45:03<1:05:03,  3.45s/it]                                                       {'loss': 0.0236, 'grad_norm': 6.688927173614502, 'learning_rate': 1.9169491525423732e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4869/6000 [4:45:03<1:05:03,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [4:45:06<1:04:29,  3.42s/it]                                                       {'loss': 0.003, 'grad_norm': 0.6250015497207642, 'learning_rate': 1.9152542372881356e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4870/6000 [4:45:06<1:04:29,  3.42s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [4:45:10<1:07:20,  3.58s/it]                                                       {'loss': 0.0625, 'grad_norm': 9.484467506408691, 'learning_rate': 1.9135593220338985e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4871/6000 [4:45:10<1:07:20,  3.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [4:45:13<1:07:00,  3.56s/it]                                                       {'loss': 0.0756, 'grad_norm': 4.273570537567139, 'learning_rate': 1.9118644067796613e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4872/6000 [4:45:13<1:07:00,  3.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [4:45:17<1:06:19,  3.53s/it]                                                       {'loss': 0.0103, 'grad_norm': 2.0693047046661377, 'learning_rate': 1.9101694915254238e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4873/6000 [4:45:17<1:06:19,  3.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [4:45:20<1:06:30,  3.54s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.7650553584098816, 'learning_rate': 1.9084745762711866e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4874/6000 [4:45:20<1:06:30,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [4:45:24<1:05:28,  3.49s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5149832963943481, 'learning_rate': 1.9067796610169493e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4875/6000 [4:45:24<1:05:28,  3.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [4:45:28<1:07:35,  3.61s/it]                                                       {'loss': 0.0031, 'grad_norm': 1.1270869970321655, 'learning_rate': 1.9050847457627119e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4876/6000 [4:45:28<1:07:35,  3.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [4:45:31<1:06:58,  3.58s/it]                                                       {'loss': 0.2003, 'grad_norm': 15.2494478225708, 'learning_rate': 1.9033898305084747e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4877/6000 [4:45:31<1:06:58,  3.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [4:45:35<1:06:07,  3.54s/it]                                                       {'loss': 0.0385, 'grad_norm': 8.615241050720215, 'learning_rate': 1.9016949152542374e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4878/6000 [4:45:35<1:06:07,  3.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [4:45:38<1:05:35,  3.51s/it]                                                       {'loss': 0.001, 'grad_norm': 0.23821164667606354, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4879/6000 [4:45:38<1:05:35,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [4:45:42<1:05:36,  3.51s/it]                                                       {'loss': 0.009, 'grad_norm': 2.3711977005004883, 'learning_rate': 1.8983050847457629e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4880/6000 [4:45:42<1:05:36,  3.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [4:45:45<1:04:20,  3.45s/it]                                                       {'loss': 0.0087, 'grad_norm': 2.7373836040496826, 'learning_rate': 1.8966101694915257e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4881/6000 [4:45:45<1:04:20,  3.45s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [4:45:48<1:03:32,  3.41s/it]                                                       {'loss': 0.0646, 'grad_norm': 6.450902462005615, 'learning_rate': 1.8949152542372884e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4882/6000 [4:45:48<1:03:32,  3.41s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [4:45:51<1:02:48,  3.37s/it]                                                       {'loss': 0.1095, 'grad_norm': 9.219609260559082, 'learning_rate': 1.8932203389830512e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4883/6000 [4:45:51<1:02:48,  3.37s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [4:45:55<1:02:52,  3.38s/it]                                                       {'loss': 0.2703, 'grad_norm': 12.181122779846191, 'learning_rate': 1.8915254237288136e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4884/6000 [4:45:55<1:02:52,  3.38s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [4:45:58<1:03:33,  3.42s/it]                                                       {'loss': 0.2405, 'grad_norm': 18.90656089782715, 'learning_rate': 1.8898305084745763e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4885/6000 [4:45:58<1:03:33,  3.42s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [4:46:02<1:03:21,  3.41s/it]                                                       {'loss': 0.0607, 'grad_norm': 10.429542541503906, 'learning_rate': 1.8881355932203391e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4886/6000 [4:46:02<1:03:21,  3.41s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [4:46:05<1:03:29,  3.42s/it]                                                       {'loss': 0.0084, 'grad_norm': 2.164360761642456, 'learning_rate': 1.8864406779661018e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4887/6000 [4:46:05<1:03:29,  3.42s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [4:46:09<1:03:00,  3.40s/it]                                                       {'loss': 0.008, 'grad_norm': 2.0983922481536865, 'learning_rate': 1.8847457627118646e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4888/6000 [4:46:09<1:03:00,  3.40s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [4:46:12<1:02:34,  3.38s/it]                                                       {'loss': 0.0266, 'grad_norm': 5.840975761413574, 'learning_rate': 1.8830508474576273e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4889/6000 [4:46:12<1:02:34,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [4:46:15<1:02:04,  3.36s/it]                                                       {'loss': 0.2423, 'grad_norm': 21.56593132019043, 'learning_rate': 1.88135593220339e-06, 'epoch': 0.81}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4890/6000 [4:46:15<1:02:04,  3.36s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [4:46:19<1:02:00,  3.35s/it]                                                       {'loss': 0.2109, 'grad_norm': 13.996384620666504, 'learning_rate': 1.8796610169491527e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4891/6000 [4:46:19<1:02:00,  3.35s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [4:46:22<1:02:06,  3.36s/it]                                                       {'loss': 0.1383, 'grad_norm': 15.2010498046875, 'learning_rate': 1.8779661016949156e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4892/6000 [4:46:22<1:02:06,  3.36s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [4:46:25<1:02:32,  3.39s/it]                                                       {'loss': 0.0376, 'grad_norm': 8.500210762023926, 'learning_rate': 1.8762711864406782e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4893/6000 [4:46:25<1:02:32,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [4:46:29<1:02:20,  3.38s/it]                                                       {'loss': 0.1257, 'grad_norm': 21.436004638671875, 'learning_rate': 1.8745762711864407e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4894/6000 [4:46:29<1:02:20,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [4:46:32<1:02:41,  3.40s/it]                                                       {'loss': 0.0212, 'grad_norm': 3.4184558391571045, 'learning_rate': 1.8728813559322035e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4895/6000 [4:46:32<1:02:41,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [4:46:35<1:02:10,  3.38s/it]                                                       {'loss': 0.0458, 'grad_norm': 6.746636390686035, 'learning_rate': 1.8711864406779661e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4896/6000 [4:46:35<1:02:10,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [4:46:39<1:02:09,  3.38s/it]                                                       {'loss': 0.0963, 'grad_norm': 7.30562162399292, 'learning_rate': 1.869491525423729e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4897/6000 [4:46:39<1:02:09,  3.38s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [4:46:42<1:02:28,  3.40s/it]                                                       {'loss': 0.1905, 'grad_norm': 7.966952800750732, 'learning_rate': 1.8677966101694916e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4898/6000 [4:46:42<1:02:28,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [4:46:46<1:02:59,  3.43s/it]                                                       {'loss': 0.0842, 'grad_norm': 11.047600746154785, 'learning_rate': 1.8661016949152545e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4899/6000 [4:46:46<1:02:59,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [4:46:50<1:05:07,  3.55s/it]                                                       {'loss': 0.0137, 'grad_norm': 3.445941686630249, 'learning_rate': 1.8644067796610171e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4900/6000 [4:46:50<1:05:07,  3.55s/it][2025-11-07 03:37:59,660] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4900
[2025-11-07 03:37:59,678] INFO [src.utils:19] Detected wrapper â€” saving only LoRA model (encoder.base).
[2025-11-07 03:38:00,382] INFO [src.utils:19] Saved tail token to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/checkpoint-4900/tail_token.pt
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [4:46:55<1:17:11,  4.21s/it]                                                       {'loss': 0.0529, 'grad_norm': 6.441168308258057, 'learning_rate': 1.86271186440678e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4901/6000 [4:46:55<1:17:11,  4.21s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [4:46:59<1:12:27,  3.96s/it]                                                       {'loss': 0.0481, 'grad_norm': 5.900271892547607, 'learning_rate': 1.8610169491525426e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4902/6000 [4:46:59<1:12:27,  3.96s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [4:47:02<1:09:47,  3.82s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.1982965469360352, 'learning_rate': 1.8593220338983052e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4903/6000 [4:47:02<1:09:47,  3.82s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [4:47:06<1:07:16,  3.68s/it]                                                       {'loss': 0.0016, 'grad_norm': 0.35370054841041565, 'learning_rate': 1.857627118644068e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4904/6000 [4:47:06<1:07:16,  3.68s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [4:47:09<1:06:28,  3.64s/it]                                                       {'loss': 0.0144, 'grad_norm': 2.3965625762939453, 'learning_rate': 1.8559322033898305e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4905/6000 [4:47:09<1:06:28,  3.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [4:47:12<1:04:27,  3.54s/it]                                                       {'loss': 0.1424, 'grad_norm': 12.69946002960205, 'learning_rate': 1.8542372881355934e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4906/6000 [4:47:12<1:04:27,  3.54s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [4:47:16<1:03:56,  3.51s/it]                                                       {'loss': 0.002, 'grad_norm': 0.6204965114593506, 'learning_rate': 1.852542372881356e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4907/6000 [4:47:16<1:03:56,  3.51s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [4:47:19<1:03:19,  3.48s/it]                                                       {'loss': 0.2004, 'grad_norm': 17.266376495361328, 'learning_rate': 1.8508474576271189e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/6000 [4:47:19<1:03:19,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [4:47:23<1:02:48,  3.45s/it]                                                       {'loss': 0.0023, 'grad_norm': 0.539210319519043, 'learning_rate': 1.8491525423728815e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4909/6000 [4:47:23<1:02:48,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [4:47:26<1:02:46,  3.46s/it]                                                       {'loss': 0.1315, 'grad_norm': 8.881194114685059, 'learning_rate': 1.8474576271186441e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4910/6000 [4:47:26<1:02:46,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [4:47:29<1:01:48,  3.41s/it]                                                       {'loss': 0.1678, 'grad_norm': 15.34738826751709, 'learning_rate': 1.845762711864407e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4911/6000 [4:47:29<1:01:48,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [4:47:33<1:01:31,  3.39s/it]                                                       {'loss': 0.101, 'grad_norm': 6.168213844299316, 'learning_rate': 1.8440677966101696e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4912/6000 [4:47:33<1:01:31,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [4:47:36<1:01:30,  3.40s/it]                                                       {'loss': 0.0027, 'grad_norm': 1.0978915691375732, 'learning_rate': 1.8423728813559325e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4913/6000 [4:47:36<1:01:30,  3.40s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [4:47:40<1:01:23,  3.39s/it]                                                       {'loss': 0.0145, 'grad_norm': 2.380497455596924, 'learning_rate': 1.8406779661016951e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4914/6000 [4:47:40<1:01:23,  3.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [4:47:43<1:02:05,  3.43s/it]                                                       {'loss': 0.0321, 'grad_norm': 5.52146053314209, 'learning_rate': 1.8389830508474578e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4915/6000 [4:47:43<1:02:05,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [4:47:47<1:02:04,  3.44s/it]                                                       {'loss': 0.0225, 'grad_norm': 4.848780632019043, 'learning_rate': 1.8372881355932204e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4916/6000 [4:47:47<1:02:04,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [4:47:50<1:02:03,  3.44s/it]                                                       {'loss': 0.028, 'grad_norm': 5.2350921630859375, 'learning_rate': 1.835593220338983e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4917/6000 [4:47:50<1:02:03,  3.44s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [4:47:54<1:02:50,  3.49s/it]                                                       {'loss': 0.0342, 'grad_norm': 3.0125439167022705, 'learning_rate': 1.8338983050847459e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4918/6000 [4:47:54<1:02:50,  3.49s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [4:47:57<1:02:37,  3.48s/it]                                                       {'loss': 0.1334, 'grad_norm': 15.819185256958008, 'learning_rate': 1.8322033898305085e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4919/6000 [4:47:57<1:02:37,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [4:48:01<1:02:12,  3.46s/it]                                                       {'loss': 0.0131, 'grad_norm': 3.4374442100524902, 'learning_rate': 1.8305084745762714e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4920/6000 [4:48:01<1:02:12,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [4:48:04<1:02:03,  3.45s/it]                                                       {'loss': 0.02, 'grad_norm': 3.732914924621582, 'learning_rate': 1.828813559322034e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4921/6000 [4:48:04<1:02:03,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [4:48:08<1:04:39,  3.60s/it]                                                       {'loss': 0.0274, 'grad_norm': 4.839365482330322, 'learning_rate': 1.8271186440677969e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4922/6000 [4:48:08<1:04:39,  3.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [4:48:11<1:03:53,  3.56s/it]                                                       {'loss': 0.0651, 'grad_norm': 5.628202438354492, 'learning_rate': 1.8254237288135595e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4923/6000 [4:48:11<1:03:53,  3.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [4:48:15<1:02:28,  3.48s/it]                                                       {'loss': 0.053, 'grad_norm': 6.918141841888428, 'learning_rate': 1.8237288135593223e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4924/6000 [4:48:15<1:02:28,  3.48s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [4:48:18<1:03:56,  3.57s/it]                                                       {'loss': 0.0411, 'grad_norm': 4.8563055992126465, 'learning_rate': 1.8220338983050848e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4925/6000 [4:48:18<1:03:56,  3.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [4:48:22<1:03:02,  3.52s/it]                                                       {'loss': 0.0093, 'grad_norm': 1.5743787288665771, 'learning_rate': 1.8203389830508474e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4926/6000 [4:48:22<1:03:02,  3.52s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [4:48:25<1:02:05,  3.47s/it]                                                       {'loss': 0.0156, 'grad_norm': 4.026310443878174, 'learning_rate': 1.8186440677966103e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4927/6000 [4:48:25<1:02:05,  3.47s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [4:48:29<1:01:16,  3.43s/it]                                                       {'loss': 0.2519, 'grad_norm': 18.012344360351562, 'learning_rate': 1.816949152542373e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4928/6000 [4:48:29<1:01:16,  3.43s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [4:48:32<1:01:49,  3.46s/it]                                                       {'loss': 0.0124, 'grad_norm': 2.5407283306121826, 'learning_rate': 1.8152542372881357e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4929/6000 [4:48:32<1:01:49,  3.46s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [4:48:35<1:01:02,  3.42s/it]                                                       {'loss': 0.0174, 'grad_norm': 4.310117244720459, 'learning_rate': 1.8135593220338984e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4930/6000 [4:48:35<1:01:02,  3.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [4:48:39<1:02:13,  3.49s/it]                                                       {'loss': 0.0015, 'grad_norm': 0.5250775218009949, 'learning_rate': 1.8118644067796612e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4931/6000 [4:48:39<1:02:13,  3.49s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [4:48:42<1:01:29,  3.45s/it]                                                       {'loss': 0.1979, 'grad_norm': 12.92883586883545, 'learning_rate': 1.8101694915254239e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4932/6000 [4:48:42<1:01:29,  3.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [4:48:46<1:00:40,  3.41s/it]                                                       {'loss': 0.267, 'grad_norm': 17.126773834228516, 'learning_rate': 1.8084745762711867e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4933/6000 [4:48:46<1:00:40,  3.41s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [4:48:49<1:00:45,  3.42s/it]                                                       {'loss': 0.0224, 'grad_norm': 5.063475131988525, 'learning_rate': 1.8067796610169494e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4934/6000 [4:48:49<1:00:45,  3.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [4:48:53<1:00:46,  3.42s/it]                                                       {'loss': 0.0464, 'grad_norm': 10.106224060058594, 'learning_rate': 1.8050847457627122e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4935/6000 [4:48:53<1:00:46,  3.42s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [4:48:57<1:07:25,  3.80s/it]                                                       {'loss': 0.0387, 'grad_norm': 7.738431453704834, 'learning_rate': 1.8033898305084746e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4936/6000 [4:48:57<1:07:25,  3.80s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [4:49:02<1:11:28,  4.03s/it]                                                       {'loss': 0.0033, 'grad_norm': 0.8551788330078125, 'learning_rate': 1.8016949152542373e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4937/6000 [4:49:02<1:11:28,  4.03s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [4:49:05<1:08:52,  3.89s/it]                                                       {'loss': 0.0312, 'grad_norm': 14.449254035949707, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4938/6000 [4:49:05<1:08:52,  3.89s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [4:49:09<1:06:10,  3.74s/it]                                                       {'loss': 0.0424, 'grad_norm': 5.520055770874023, 'learning_rate': 1.7983050847457628e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4939/6000 [4:49:09<1:06:10,  3.74s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [4:49:12<1:04:59,  3.68s/it]                                                       {'loss': 0.0905, 'grad_norm': 15.217089653015137, 'learning_rate': 1.7966101694915256e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4940/6000 [4:49:12<1:04:59,  3.68s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [4:49:16<1:03:22,  3.59s/it]                                                       {'loss': 0.0394, 'grad_norm': 6.534399509429932, 'learning_rate': 1.7949152542372883e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4941/6000 [4:49:16<1:03:22,  3.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [4:49:19<1:02:41,  3.56s/it]                                                       {'loss': 0.0068, 'grad_norm': 1.6150802373886108, 'learning_rate': 1.7932203389830511e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4942/6000 [4:49:19<1:02:41,  3.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [4:49:23<1:02:19,  3.54s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.05623127892613411, 'learning_rate': 1.7915254237288137e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4943/6000 [4:49:23<1:02:19,  3.54s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [4:49:26<1:01:40,  3.50s/it]                                                       {'loss': 0.0645, 'grad_norm': 10.624305725097656, 'learning_rate': 1.7898305084745766e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4944/6000 [4:49:26<1:01:40,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [4:49:30<1:02:51,  3.57s/it]                                                       {'loss': 0.0019, 'grad_norm': 0.5530585646629333, 'learning_rate': 1.7881355932203392e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4945/6000 [4:49:30<1:02:51,  3.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [4:49:33<1:02:04,  3.53s/it]                                                       {'loss': 0.1157, 'grad_norm': 12.78123664855957, 'learning_rate': 1.7864406779661017e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4946/6000 [4:49:33<1:02:04,  3.53s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [4:49:37<1:01:24,  3.50s/it]                                                       {'loss': 0.0255, 'grad_norm': 3.468717098236084, 'learning_rate': 1.7847457627118645e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4947/6000 [4:49:37<1:01:24,  3.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [4:49:41<1:06:13,  3.78s/it]                                                       {'loss': 0.1764, 'grad_norm': 18.133188247680664, 'learning_rate': 1.7830508474576271e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4948/6000 [4:49:41<1:06:13,  3.78s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [4:49:44<1:03:49,  3.64s/it]                                                       {'loss': 0.0505, 'grad_norm': 11.815285682678223, 'learning_rate': 1.78135593220339e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4949/6000 [4:49:44<1:03:49,  3.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [4:49:48<1:02:19,  3.56s/it]                                                       {'loss': 0.2844, 'grad_norm': 17.051815032958984, 'learning_rate': 1.7796610169491526e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4950/6000 [4:49:48<1:02:19,  3.56s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [4:49:52<1:04:29,  3.69s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.2819741666316986, 'learning_rate': 1.7779661016949155e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4951/6000 [4:49:52<1:04:29,  3.69s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [4:49:56<1:05:46,  3.77s/it]                                                       {'loss': 0.0909, 'grad_norm': 14.808387756347656, 'learning_rate': 1.7762711864406781e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4952/6000 [4:49:56<1:05:46,  3.77s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [4:49:59<1:03:19,  3.63s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0027825927827507257, 'learning_rate': 1.774576271186441e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4953/6000 [4:49:59<1:03:19,  3.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [4:50:03<1:04:21,  3.69s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.20448440313339233, 'learning_rate': 1.7728813559322036e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4954/6000 [4:50:03<1:04:21,  3.69s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [4:50:06<1:03:15,  3.63s/it]                                                       {'loss': 0.0825, 'grad_norm': 10.682178497314453, 'learning_rate': 1.7711864406779663e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4955/6000 [4:50:06<1:03:15,  3.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [4:50:10<1:02:14,  3.58s/it]                                                       {'loss': 0.0251, 'grad_norm': 8.000038146972656, 'learning_rate': 1.769491525423729e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4956/6000 [4:50:10<1:02:14,  3.58s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [4:50:14<1:03:00,  3.62s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.014217481948435307, 'learning_rate': 1.7677966101694915e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4957/6000 [4:50:14<1:03:00,  3.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [4:50:17<1:02:00,  3.57s/it]                                                       {'loss': 0.0043, 'grad_norm': 1.5065487623214722, 'learning_rate': 1.7661016949152544e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4958/6000 [4:50:17<1:02:00,  3.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [4:50:21<1:02:29,  3.60s/it]                                                       {'loss': 0.0293, 'grad_norm': 4.7115797996521, 'learning_rate': 1.764406779661017e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4959/6000 [4:50:21<1:02:29,  3.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [4:50:24<1:01:52,  3.57s/it]                                                       {'loss': 0.0417, 'grad_norm': 8.688199043273926, 'learning_rate': 1.7627118644067799e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4960/6000 [4:50:24<1:01:52,  3.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [4:50:28<1:02:53,  3.63s/it]                                                       {'loss': 0.0753, 'grad_norm': 10.49299430847168, 'learning_rate': 1.7610169491525425e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4961/6000 [4:50:28<1:02:53,  3.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [4:50:32<1:04:55,  3.75s/it]                                                       {'loss': 0.0052, 'grad_norm': 1.2567603588104248, 'learning_rate': 1.7593220338983051e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4962/6000 [4:50:32<1:04:55,  3.75s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [4:50:35<1:02:44,  3.63s/it]                                                       {'loss': 0.211, 'grad_norm': 13.732683181762695, 'learning_rate': 1.757627118644068e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4963/6000 [4:50:35<1:02:44,  3.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [4:50:39<1:00:58,  3.53s/it]                                                       {'loss': 0.0042, 'grad_norm': 1.0655721426010132, 'learning_rate': 1.7559322033898306e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4964/6000 [4:50:39<1:00:58,  3.53s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [4:50:42<1:00:38,  3.52s/it]                                                       {'loss': 0.0482, 'grad_norm': 17.09758186340332, 'learning_rate': 1.7542372881355935e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4965/6000 [4:50:42<1:00:38,  3.52s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [4:50:46<1:00:17,  3.50s/it]                                                       {'loss': 0.0148, 'grad_norm': 4.240054130554199, 'learning_rate': 1.7525423728813561e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4966/6000 [4:50:46<1:00:17,  3.50s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [4:50:49<1:00:35,  3.52s/it]                                                       {'loss': 0.0249, 'grad_norm': 8.406143188476562, 'learning_rate': 1.7508474576271188e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4967/6000 [4:50:49<1:00:35,  3.52s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [4:50:53<59:43,  3.47s/it]                                                       {'loss': 0.0282, 'grad_norm': 4.628615379333496, 'learning_rate': 1.7491525423728814e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4968/6000 [4:50:53<59:43,  3.47s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [4:50:56<59:05,  3.44s/it]                                                     {'loss': 0.0801, 'grad_norm': 12.132929801940918, 'learning_rate': 1.747457627118644e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4969/6000 [4:50:56<59:05,  3.44s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [4:50:59<58:52,  3.43s/it]                                                     {'loss': 0.0192, 'grad_norm': 5.66571044921875, 'learning_rate': 1.7457627118644069e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4970/6000 [4:50:59<58:52,  3.43s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [4:51:03<58:37,  3.42s/it]                                                     {'loss': 0.0387, 'grad_norm': 3.0869226455688477, 'learning_rate': 1.7440677966101695e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4971/6000 [4:51:03<58:37,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [4:51:06<58:02,  3.39s/it]                                                     {'loss': 0.0477, 'grad_norm': 8.815370559692383, 'learning_rate': 1.7423728813559324e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4972/6000 [4:51:06<58:02,  3.39s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [4:51:09<57:49,  3.38s/it]                                                     {'loss': 0.0043, 'grad_norm': 1.2715318202972412, 'learning_rate': 1.740677966101695e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4973/6000 [4:51:09<57:49,  3.38s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [4:51:13<59:37,  3.49s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.5956273674964905, 'learning_rate': 1.7389830508474579e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4974/6000 [4:51:13<59:37,  3.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [4:51:17<59:26,  3.48s/it]                                                     {'loss': 0.1914, 'grad_norm': 13.673172950744629, 'learning_rate': 1.7372881355932205e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4975/6000 [4:51:17<59:26,  3.48s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [4:51:20<58:55,  3.45s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.455357164144516, 'learning_rate': 1.7355932203389834e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4976/6000 [4:51:20<58:55,  3.45s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [4:51:23<58:19,  3.42s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.8560877442359924, 'learning_rate': 1.7338983050847458e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4977/6000 [4:51:23<58:19,  3.42s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [4:51:27<58:25,  3.43s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.03450794890522957, 'learning_rate': 1.7322033898305084e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4978/6000 [4:51:27<58:25,  3.43s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [4:51:30<58:48,  3.46s/it]                                                     {'loss': 0.0441, 'grad_norm': 4.518167495727539, 'learning_rate': 1.7305084745762713e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4979/6000 [4:51:30<58:48,  3.46s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [4:51:34<1:00:44,  3.57s/it]                                                       {'loss': 0.104, 'grad_norm': 9.854826927185059, 'learning_rate': 1.728813559322034e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4980/6000 [4:51:34<1:00:44,  3.57s/it]Traceback (most recent call last):
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
    main()
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 104, in main
    trainer.train(resume_from_checkpoint=resume_checkpoint_dir)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 511, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 709, in training_step
    loss = self.gc(queries, targets, no_sync_except_last=_distributed)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 71, in __call__
    return self.cache_step(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 294, in cache_step
    self.forward_backward(model, x, model_cache, rnd_states, no_sync_except_last=no_sync_except_last)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 239, in forward_backward
    y = self.model_call(model, x)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 141, in model_call
    return model(**model_input)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 367, in forward
    tgt_reps = self.encode_input(tgt, self.tgt_chosen_layer) if tgt else None # (bsz_per_device, dim)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 111, in encode_input
    hidden_states = self.encoder(**input, return_dict=True, output_hidden_states=True)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/tail_token_wrapper.py", line 206, in forward
    outputs = self.base(**kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/peft/peft_model.py", line 881, in forward
    return self.get_base_model()(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/vlm_backbone/qwen2_vl/modeling_qwen2_vl.py", line 1784, in forward
    logits = self.lm_head(hidden_states)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.56 GiB of which 621.00 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 20.07 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 112, in <module>
[rank0]:     main()
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/train.py", line 104, in main
[rank0]:     trainer.train(resume_from_checkpoint=resume_checkpoint_dir)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 511, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/trainer.py", line 709, in training_step
[rank0]:     loss = self.gc(queries, targets, no_sync_except_last=_distributed)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 71, in __call__
[rank0]:     return self.cache_step(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 294, in cache_step
[rank0]:     self.forward_backward(model, x, model_cache, rnd_states, no_sync_except_last=no_sync_except_last)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 239, in forward_backward
[rank0]:     y = self.model_call(model, x)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/grad_cache/grad_cache.py", line 141, in model_call
[rank0]:     return model(**model_input)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 367, in forward
[rank0]:     tgt_reps = self.encode_input(tgt, self.tgt_chosen_layer) if tgt else None # (bsz_per_device, dim)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/model.py", line 111, in encode_input
[rank0]:     hidden_states = self.encoder(**input, return_dict=True, output_hidden_states=True)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/tail_token_wrapper.py", line 206, in forward
[rank0]:     outputs = self.base(**kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/peft/peft_model.py", line 881, in forward
[rank0]:     return self.get_base_model()(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/vlm_backbone/qwen2_vl/modeling_qwen2_vl.py", line 1784, in forward
[rank0]:     logits = self.lm_head(hidden_states)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.56 GiB of which 621.00 MiB is free. Including non-PyTorch memory, this process has 22.94 GiB memory in use. Of the allocated memory 20.07 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33m05Nov-Qwen/Qwen2-VL-2B-Instruct[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/public/exps/train/05Nov-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251106_225047-ddhzgqnm/logs[0m
W1107 03:42:52.747000 139967737603904 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1188769 closing signal SIGTERM
E1107 03:42:53.262000 139967737603904 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1188768) of binary: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python3.10
Traceback (most recent call last):
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-07_03:42:52
  host      : node40.enst.fr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1188768)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Job finished at: ven. 07 nov. 2025 03:42:53 CET
