==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name test5-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token False --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct/train.log
W1022 23:55:54.139000 136202762417984 torch/distributed/run.py:779] 
W1022 23:55:54.139000 136202762417984 torch/distributed/run.py:779] *****************************************
W1022 23:55:54.139000 136202762417984 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 23:55:54.139000 136202762417984 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-22 23:56:03,880] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.06it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.83it/s]
wandb: setting up run qhv54ojk
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251022_235604-qhv54ojk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run test5-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/qhv54ojk
[2025-10-22 23:56:05,526] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.14it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.93it/s]
[2025-10-22 23:56:06,150] INFO [src.utils:19] Loading lora adapter from Qwen2VLForConditionalGeneration(
  (visual): Qwen2VisionTransformerPretrainedModel(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
    )
    (rotary_pos_emb): VisionRotaryEmbedding()
    (blocks): ModuleList(
      (0-31): 32 x Qwen2VLVisionBlock(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): VisionFlashAttention2(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (mlp): VisionMlp(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): QuickGELUActivation()
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        )
      )
    )
    (merger): PatchMerger(
      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=5120, out_features=5120, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=5120, out_features=1536, bias=True)
      )
    )
  )
  (model): Qwen2VLModel(
    (embed_tokens): Embedding(151936, 1536)
    (layers): ModuleList(
      (0-27): 28 x Qwen2VLDecoderLayer(
        (self_attn): Qwen2VLFlashAttention2(
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (k_proj): Linear(in_features=1536, out_features=256, bias=True)
          (v_proj): Linear(in_features=1536, out_features=256, bias=True)
          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
          (rotary_emb): Qwen2VLRotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((1536,), eps=1e-06)
    (rotary_emb): Qwen2VLRotaryEmbedding()
  )
  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
)
[2025-10-22 23:56:14,998] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-22 23:56:16,315] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-22 23:56:16,316] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-22 23:56:20,601] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-22 23:56:20,601] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-22 23:56:21,449] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-22 23:56:21,449] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-22 23:56:21,450] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-22 23:56:21,451] INFO [src.utils:19] ==================================================
[2025-10-22 23:56:21,452] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-22 23:56:21,453] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-22 23:56:21,453] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-22 23:56:21,454] INFO [src.utils:19] ==================================================
[2025-10-22 23:56:23,249] INFO [src.trainer:342] ***** Running training *****
[2025-10-22 23:56:23,249] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-22 23:56:23,249] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-22 23:56:23,249] INFO [src.trainer:342] ***** Running training *****
[2025-10-22 23:56:23,249] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-22 23:56:23,249] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-22 23:56:23,249] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-22 23:56:23,249] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-22 23:56:23,250] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-22 23:56:23,250] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-22 23:56:23,250] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-22 23:56:23,251] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-22 23:56:23,251] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-22 23:56:23,251] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-22 23:56:23,257] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-22 23:56:23,259] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-22 23:56:23,263] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
[2025-10-22 23:56:23,266] INFO [src.trainer:352]   Trainable Parameters = ['module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'module.encoder.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector.default.weight']
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[2025-10-22 23:56:24,823] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:24,824] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:25,158] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:25,159] INFO [src.utils:19] 29
[2025-10-22 23:56:25,159] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:25,299] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:25,300] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:25,511] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:25,511] INFO [src.utils:19] 29
[2025-10-22 23:56:25,512] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:25,597] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:25,598] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:25,812] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:25,813] INFO [src.utils:19] 29
[2025-10-22 23:56:25,813] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:25,871] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:25,872] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:26,085] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:26,086] INFO [src.utils:19] 29
[2025-10-22 23:56:26,086] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:26,198] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:26,199] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:26,411] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:26,411] INFO [src.utils:19] 29
[2025-10-22 23:56:26,412] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:26,744] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:26,744] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:26,954] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:26,955] INFO [src.utils:19] 29
[2025-10-22 23:56:26,955] INFO [src.utils:19] torch.Size([8, 137, 1536])
[rank0]:[W1022 23:56:26.561734604 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1022 23:56:26.583342211 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2025-10-22 23:56:27,245] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:27,246] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:27,470] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:27,470] INFO [src.utils:19] 29
[2025-10-22 23:56:27,470] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:27,699] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:27,700] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:27,922] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:27,923] INFO [src.utils:19] 29
[2025-10-22 23:56:27,923] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 1/6000 [00:04<7:57:37,  4.78s/it]                                                  {'loss': 20.6106, 'grad_norm': 1368.5040283203125, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<7:57:37,  4.78s/it][2025-10-22 23:56:28,306] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:28,307] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:28,589] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:28,589] INFO [src.utils:19] 29
[2025-10-22 23:56:28,589] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:28,694] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:28,694] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:28,901] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:28,901] INFO [src.utils:19] 29
[2025-10-22 23:56:28,901] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:29,025] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:29,025] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:29,235] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:29,236] INFO [src.utils:19] 29
[2025-10-22 23:56:29,236] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:29,307] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:29,307] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:29,512] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:29,513] INFO [src.utils:19] 29
[2025-10-22 23:56:29,513] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:29,597] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:29,597] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:29,807] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:29,808] INFO [src.utils:19] 29
[2025-10-22 23:56:29,808] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:30,076] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:30,077] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:30,288] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:30,289] INFO [src.utils:19] 29
[2025-10-22 23:56:30,289] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:30,607] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:30,608] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:30,818] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:30,819] INFO [src.utils:19] 29
[2025-10-22 23:56:30,819] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:31,056] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:31,057] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:31,265] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:31,266] INFO [src.utils:19] 29
[2025-10-22 23:56:31,266] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 2/6000 [00:08<6:29:20,  3.89s/it]                                                  {'loss': 17.9095, 'grad_norm': 2153.340576171875, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:08<6:29:20,  3.89s/it][2025-10-22 23:56:31,601] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:31,602] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:31,854] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:31,854] INFO [src.utils:19] 29
[2025-10-22 23:56:31,855] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:31,931] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:31,932] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:32,138] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:32,139] INFO [src.utils:19] 29
[2025-10-22 23:56:32,139] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:32,225] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:32,225] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:32,430] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:32,431] INFO [src.utils:19] 29
[2025-10-22 23:56:32,431] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:32,535] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:32,535] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:32,741] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:32,741] INFO [src.utils:19] 29
[2025-10-22 23:56:32,741] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:32,934] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:32,934] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:33,146] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:33,146] INFO [src.utils:19] 29
[2025-10-22 23:56:33,147] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:33,386] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:33,387] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:33,598] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:33,598] INFO [src.utils:19] 29
[2025-10-22 23:56:33,599] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:33,875] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:33,876] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:34,089] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:34,090] INFO [src.utils:19] 29
[2025-10-22 23:56:34,090] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:34,358] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:34,359] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:34,569] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:34,569] INFO [src.utils:19] 29
[2025-10-22 23:56:34,570] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 3/6000 [00:11<6:07:26,  3.68s/it]                                                  {'loss': 16.0307, 'grad_norm': 2068.385498046875, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:11<6:07:26,  3.68s/it][2025-10-22 23:56:34,992] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:34,994] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:35,245] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:35,246] INFO [src.utils:19] 29
[2025-10-22 23:56:35,247] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:35,307] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:35,307] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:35,515] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:35,516] INFO [src.utils:19] 29
[2025-10-22 23:56:35,516] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:35,637] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:35,637] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:35,868] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:35,869] INFO [src.utils:19] 29
[2025-10-22 23:56:35,869] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:36,001] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:36,002] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:36,234] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:36,234] INFO [src.utils:19] 29
[2025-10-22 23:56:36,235] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:36,297] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:36,297] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:36,509] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:36,509] INFO [src.utils:19] 29
[2025-10-22 23:56:36,509] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:36,727] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:36,728] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:36,943] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:36,944] INFO [src.utils:19] 29
[2025-10-22 23:56:36,944] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:37,338] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:37,339] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:37,581] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:37,582] INFO [src.utils:19] 29
[2025-10-22 23:56:37,582] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:37,900] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:37,901] INFO [src.utils:19] torch.Size([8, 186, 1536])
[2025-10-22 23:56:38,136] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:38,137] INFO [src.utils:19] 29
[2025-10-22 23:56:38,137] INFO [src.utils:19] torch.Size([8, 186, 1536])
  0%|          | 4/6000 [00:14<5:59:11,  3.59s/it]                                                  {'loss': 16.7002, 'grad_norm': 3714.89453125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:14<5:59:11,  3.59s/it][2025-10-22 23:56:38,505] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:38,506] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:38,860] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:38,861] INFO [src.utils:19] 29
[2025-10-22 23:56:38,861] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:38,923] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:38,923] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:39,143] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:39,144] INFO [src.utils:19] 29
[2025-10-22 23:56:39,144] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:39,214] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:39,215] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:39,420] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:39,421] INFO [src.utils:19] 29
[2025-10-22 23:56:39,421] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:39,545] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:39,546] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:39,750] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:39,751] INFO [src.utils:19] 29
[2025-10-22 23:56:39,751] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:39,853] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:39,853] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:40,074] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:40,074] INFO [src.utils:19] 29
[2025-10-22 23:56:40,075] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:40,297] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:40,298] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:40,523] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:40,524] INFO [src.utils:19] 29
[2025-10-22 23:56:40,524] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:56:40,788] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:40,788] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:40,999] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:41,000] INFO [src.utils:19] 29
[2025-10-22 23:56:41,000] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:41,303] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:41,303] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:41,513] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:41,514] INFO [src.utils:19] 29
[2025-10-22 23:56:41,514] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 5/6000 [00:18<5:50:42,  3.51s/it]                                                  {'loss': 16.2051, 'grad_norm': 1996.7015380859375, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:18<5:50:42,  3.51s/it][2025-10-22 23:56:41,835] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:41,836] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:42,154] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:42,155] INFO [src.utils:19] 29
[2025-10-22 23:56:42,155] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:42,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:42,275] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:42,483] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:42,484] INFO [src.utils:19] 29
[2025-10-22 23:56:42,484] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:42,605] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:42,606] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:42,812] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:42,812] INFO [src.utils:19] 29
[2025-10-22 23:56:42,813] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:42,869] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:42,869] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:43,075] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:43,075] INFO [src.utils:19] 29
[2025-10-22 23:56:43,075] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:43,134] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:43,135] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:43,345] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:43,345] INFO [src.utils:19] 29
[2025-10-22 23:56:43,346] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:43,634] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:43,635] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:43,845] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:43,846] INFO [src.utils:19] 29
[2025-10-22 23:56:43,846] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:44,233] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:44,234] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:44,444] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:44,445] INFO [src.utils:19] 29
[2025-10-22 23:56:44,445] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:44,664] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:44,664] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:44,877] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:44,877] INFO [src.utils:19] 29
[2025-10-22 23:56:44,877] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 6/6000 [00:21<5:45:34,  3.46s/it]                                                  {'loss': 17.5915, 'grad_norm': 1649.3819580078125, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:21<5:45:34,  3.46s/it][2025-10-22 23:56:45,191] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:45,192] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:45,490] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:45,490] INFO [src.utils:19] 29
[2025-10-22 23:56:45,491] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:45,577] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:45,578] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:45,784] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:45,785] INFO [src.utils:19] 29
[2025-10-22 23:56:45,785] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:45,890] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:45,890] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:46,105] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:46,106] INFO [src.utils:19] 29
[2025-10-22 23:56:46,106] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:46,192] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:46,192] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:46,408] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:46,408] INFO [src.utils:19] 29
[2025-10-22 23:56:46,409] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:46,485] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:46,486] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:46,696] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:46,696] INFO [src.utils:19] 29
[2025-10-22 23:56:46,697] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:46,945] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:46,946] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:47,159] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:47,160] INFO [src.utils:19] 29
[2025-10-22 23:56:47,160] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:47,489] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:47,490] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:47,713] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:47,714] INFO [src.utils:19] 29
[2025-10-22 23:56:47,714] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:47,962] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:47,963] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:48,182] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:48,182] INFO [src.utils:19] 29
[2025-10-22 23:56:48,183] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 7/6000 [00:24<5:40:30,  3.41s/it]                                                  {'loss': 16.0834, 'grad_norm': 2170.827880859375, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:24<5:40:30,  3.41s/it][2025-10-22 23:56:48,492] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:48,494] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:48,841] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:48,842] INFO [src.utils:19] 29
[2025-10-22 23:56:48,842] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:48,927] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:48,928] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:49,135] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:49,136] INFO [src.utils:19] 29
[2025-10-22 23:56:49,136] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:49,253] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:49,253] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:49,464] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:49,464] INFO [src.utils:19] 29
[2025-10-22 23:56:49,465] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:49,549] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:49,549] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:49,753] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:49,753] INFO [src.utils:19] 29
[2025-10-22 23:56:49,753] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:49,828] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:49,828] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:50,038] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:50,039] INFO [src.utils:19] 29
[2025-10-22 23:56:50,039] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:50,291] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:50,292] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:50,505] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:50,506] INFO [src.utils:19] 29
[2025-10-22 23:56:50,506] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:50,818] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:50,819] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:51,027] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:51,028] INFO [src.utils:19] 29
[2025-10-22 23:56:51,028] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:51,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:51,275] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:51,485] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:51,486] INFO [src.utils:19] 29
[2025-10-22 23:56:51,486] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 8/6000 [00:28<5:37:00,  3.37s/it]                                                  {'loss': 17.0875, 'grad_norm': 1783.24951171875, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:28<5:37:00,  3.37s/it][2025-10-22 23:56:51,804] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:51,806] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:52,122] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:52,122] INFO [src.utils:19] 29
[2025-10-22 23:56:52,123] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:52,206] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:52,207] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:52,429] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:52,429] INFO [src.utils:19] 29
[2025-10-22 23:56:52,429] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:52,565] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:52,565] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:52,785] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:52,786] INFO [src.utils:19] 29
[2025-10-22 23:56:52,786] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:52,886] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:52,887] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:53,100] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:53,101] INFO [src.utils:19] 29
[2025-10-22 23:56:53,101] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:53,158] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:53,159] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:53,383] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:53,384] INFO [src.utils:19] 29
[2025-10-22 23:56:53,384] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:53,638] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:53,639] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:53,862] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:53,863] INFO [src.utils:19] 29
[2025-10-22 23:56:53,863] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:56:54,191] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:54,192] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:54,413] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:54,413] INFO [src.utils:19] 29
[2025-10-22 23:56:54,414] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:54,685] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:54,686] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:56:54,906] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:54,906] INFO [src.utils:19] 29
[2025-10-22 23:56:54,907] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 9/6000 [00:31<5:38:54,  3.39s/it]                                                  {'loss': 12.725, 'grad_norm': 1615.6026611328125, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:31<5:38:54,  3.39s/it][2025-10-22 23:56:55,311] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:55,313] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:55,570] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:55,570] INFO [src.utils:19] 29
[2025-10-22 23:56:55,571] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:55,622] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:55,622] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:55,830] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:55,831] INFO [src.utils:19] 29
[2025-10-22 23:56:55,831] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:55,843] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:55,843] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:56,047] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:56,048] INFO [src.utils:19] 29
[2025-10-22 23:56:56,048] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:56,182] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:56,183] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:56,387] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:56,388] INFO [src.utils:19] 29
[2025-10-22 23:56:56,388] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:56,555] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:56,555] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:56,766] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:56,767] INFO [src.utils:19] 29
[2025-10-22 23:56:56,767] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:56,982] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:56,982] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:57,193] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:57,193] INFO [src.utils:19] 29
[2025-10-22 23:56:57,194] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:56:57,393] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:57,393] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:57,602] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:57,603] INFO [src.utils:19] 29
[2025-10-22 23:56:57,603] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:57,899] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:57,900] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:58,112] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:58,113] INFO [src.utils:19] 29
[2025-10-22 23:56:58,113] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 10/6000 [00:34<5:33:44,  3.34s/it]                                                   {'loss': 14.4221, 'grad_norm': 2001.775146484375, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:34<5:33:44,  3.34s/it][2025-10-22 23:56:58,534] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:58,535] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:56:58,837] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:58,837] INFO [src.utils:19] 29
[2025-10-22 23:56:58,838] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:56:58,948] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:58,949] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:56:59,210] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:59,211] INFO [src.utils:19] 29
[2025-10-22 23:56:59,211] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:56:59,272] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:59,273] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:59,478] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:59,479] INFO [src.utils:19] 29
[2025-10-22 23:56:59,479] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:59,552] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:59,553] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:59,756] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:56:59,757] INFO [src.utils:19] 29
[2025-10-22 23:56:59,757] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:56:59,892] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:56:59,893] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:57:00,157] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:00,158] INFO [src.utils:19] 29
[2025-10-22 23:57:00,158] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:57:00,524] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:00,524] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:57:00,789] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:00,790] INFO [src.utils:19] 29
[2025-10-22 23:57:00,790] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-22 23:57:01,111] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:01,112] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:01,322] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:01,323] INFO [src.utils:19] 29
[2025-10-22 23:57:01,323] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:01,561] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:01,561] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:01,771] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:01,771] INFO [src.utils:19] 29
[2025-10-22 23:57:01,771] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 11/6000 [00:38<5:42:26,  3.43s/it]                                                   {'loss': 13.6556, 'grad_norm': 1780.301513671875, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:38<5:42:26,  3.43s/it][2025-10-22 23:57:02,141] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:02,142] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:02,455] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:02,455] INFO [src.utils:19] 29
[2025-10-22 23:57:02,456] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:02,542] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:02,542] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:02,761] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:02,762] INFO [src.utils:19] 29
[2025-10-22 23:57:02,762] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:02,847] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:02,848] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:03,087] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:03,087] INFO [src.utils:19] 29
[2025-10-22 23:57:03,088] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:03,179] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:03,180] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:03,418] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:03,418] INFO [src.utils:19] 29
[2025-10-22 23:57:03,419] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:03,524] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:03,525] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:03,743] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:03,744] INFO [src.utils:19] 29
[2025-10-22 23:57:03,744] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:03,995] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:03,996] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:04,217] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:04,218] INFO [src.utils:19] 29
[2025-10-22 23:57:04,218] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:04,502] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:04,503] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:04,751] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:04,751] INFO [src.utils:19] 29
[2025-10-22 23:57:04,752] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:05,047] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:05,048] INFO [src.utils:19] torch.Size([8, 204, 1536])
[2025-10-22 23:57:05,294] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:05,294] INFO [src.utils:19] 29
[2025-10-22 23:57:05,295] INFO [src.utils:19] torch.Size([8, 204, 1536])
  0%|          | 12/6000 [00:42<5:46:02,  3.47s/it]                                                   {'loss': 10.7024, 'grad_norm': 1766.2579345703125, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:42<5:46:02,  3.47s/it][2025-10-22 23:57:05,655] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:05,656] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:05,973] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:05,974] INFO [src.utils:19] 29
[2025-10-22 23:57:05,974] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:06,054] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:06,054] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:06,269] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:06,269] INFO [src.utils:19] 29
[2025-10-22 23:57:06,270] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:06,357] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:06,358] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:06,574] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:06,575] INFO [src.utils:19] 29
[2025-10-22 23:57:06,575] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:06,691] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:06,691] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:06,907] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:06,907] INFO [src.utils:19] 29
[2025-10-22 23:57:06,908] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:07,001] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:07,002] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:07,221] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:07,221] INFO [src.utils:19] 29
[2025-10-22 23:57:07,221] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:07,459] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:07,460] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:07,678] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:07,679] INFO [src.utils:19] 29
[2025-10-22 23:57:07,679] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:07,962] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:07,963] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:08,186] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:08,187] INFO [src.utils:19] 29
[2025-10-22 23:57:08,187] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:08,466] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:08,467] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:08,686] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:08,687] INFO [src.utils:19] 29
[2025-10-22 23:57:08,687] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 13/6000 [00:45<5:42:40,  3.43s/it]                                                   {'loss': 11.441, 'grad_norm': 4411.0732421875, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:45<5:42:40,  3.43s/it][2025-10-22 23:57:09,001] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:09,003] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:09,311] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:09,312] INFO [src.utils:19] 29
[2025-10-22 23:57:09,312] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:09,416] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:09,417] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:09,634] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:09,634] INFO [src.utils:19] 29
[2025-10-22 23:57:09,635] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:09,756] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:09,757] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:09,989] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:09,989] INFO [src.utils:19] 29
[2025-10-22 23:57:09,990] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:10,063] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:10,064] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:10,294] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:10,295] INFO [src.utils:19] 29
[2025-10-22 23:57:10,295] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:10,373] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:10,373] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:10,593] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:10,593] INFO [src.utils:19] 29
[2025-10-22 23:57:10,593] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:10,867] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:10,868] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:11,088] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:11,089] INFO [src.utils:19] 29
[2025-10-22 23:57:11,089] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:11,425] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:11,425] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:11,661] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:11,661] INFO [src.utils:19] 29
[2025-10-22 23:57:11,662] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:11,927] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:11,927] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:12,162] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:12,163] INFO [src.utils:19] 29
[2025-10-22 23:57:12,163] INFO [src.utils:19] torch.Size([8, 177, 1536])
  0%|          | 14/6000 [00:48<5:44:22,  3.45s/it]                                                   {'loss': 10.7657, 'grad_norm': 2970.17041015625, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:48<5:44:22,  3.45s/it][2025-10-22 23:57:12,523] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:12,524] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:12,835] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:12,836] INFO [src.utils:19] 29
[2025-10-22 23:57:12,836] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:12,912] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:12,913] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:13,125] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:13,126] INFO [src.utils:19] 29
[2025-10-22 23:57:13,126] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:13,203] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:13,204] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:13,425] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:13,426] INFO [src.utils:19] 29
[2025-10-22 23:57:13,426] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:13,545] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:13,545] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:13,762] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:13,762] INFO [src.utils:19] 29
[2025-10-22 23:57:13,763] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:13,869] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:13,869] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:14,081] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:14,082] INFO [src.utils:19] 29
[2025-10-22 23:57:14,082] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:14,318] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:14,319] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:14,530] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:14,531] INFO [src.utils:19] 29
[2025-10-22 23:57:14,531] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:14,797] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:14,797] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:15,018] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:15,019] INFO [src.utils:19] 29
[2025-10-22 23:57:15,019] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:15,299] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:15,300] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:15,521] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:15,522] INFO [src.utils:19] 29
[2025-10-22 23:57:15,522] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 15/6000 [00:52<5:41:03,  3.42s/it]                                                   {'loss': 6.0684, 'grad_norm': 2503.124755859375, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:52<5:41:03,  3.42s/it][2025-10-22 23:57:15,863] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:15,864] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:16,160] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:16,161] INFO [src.utils:19] 29
[2025-10-22 23:57:16,161] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:16,235] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:16,235] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:16,447] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:16,447] INFO [src.utils:19] 29
[2025-10-22 23:57:16,447] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:16,524] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:16,524] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:16,740] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:16,741] INFO [src.utils:19] 29
[2025-10-22 23:57:16,741] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:16,846] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:16,846] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:17,065] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:17,065] INFO [src.utils:19] 29
[2025-10-22 23:57:17,065] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:17,184] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:17,184] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:17,399] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:17,400] INFO [src.utils:19] 29
[2025-10-22 23:57:17,400] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:17,637] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:17,638] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:17,849] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:17,850] INFO [src.utils:19] 29
[2025-10-22 23:57:17,850] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:18,157] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:18,158] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:18,379] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:18,380] INFO [src.utils:19] 29
[2025-10-22 23:57:18,380] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:18,659] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:18,659] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:18,881] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:18,882] INFO [src.utils:19] 29
[2025-10-22 23:57:18,882] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 16/6000 [00:55<5:39:19,  3.40s/it]                                                   {'loss': 4.8726, 'grad_norm': 1331.2034912109375, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:55<5:39:19,  3.40s/it][2025-10-22 23:57:19,197] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:19,198] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:19,530] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:19,530] INFO [src.utils:19] 29
[2025-10-22 23:57:19,531] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:19,636] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:19,637] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:19,846] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:19,847] INFO [src.utils:19] 29
[2025-10-22 23:57:19,847] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:19,968] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:19,968] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:20,180] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:20,180] INFO [src.utils:19] 29
[2025-10-22 23:57:20,181] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:20,255] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:20,255] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:20,467] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:20,468] INFO [src.utils:19] 29
[2025-10-22 23:57:20,468] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:20,524] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:20,524] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:20,737] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:20,737] INFO [src.utils:19] 29
[2025-10-22 23:57:20,738] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:21,007] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:21,008] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:21,221] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:21,221] INFO [src.utils:19] 29
[2025-10-22 23:57:21,222] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:21,532] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:21,533] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:21,744] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:21,744] INFO [src.utils:19] 29
[2025-10-22 23:57:21,745] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:21,980] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:21,981] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:22,196] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:22,196] INFO [src.utils:19] 29
[2025-10-22 23:57:22,197] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 17/6000 [00:59<5:37:44,  3.39s/it]                                                   {'loss': 5.5954, 'grad_norm': 1684.5528564453125, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:59<5:37:44,  3.39s/it][2025-10-22 23:57:22,540] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:22,541] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:22,858] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:22,859] INFO [src.utils:19] 29
[2025-10-22 23:57:22,859] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:22,943] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:22,944] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:23,155] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:23,155] INFO [src.utils:19] 29
[2025-10-22 23:57:23,155] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:23,278] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:23,279] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:23,496] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:23,497] INFO [src.utils:19] 29
[2025-10-22 23:57:23,497] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:23,585] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:23,586] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:23,804] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:23,805] INFO [src.utils:19] 29
[2025-10-22 23:57:23,805] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:23,870] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:23,870] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:24,087] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:24,087] INFO [src.utils:19] 29
[2025-10-22 23:57:24,088] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:24,335] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:24,336] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:24,549] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:24,550] INFO [src.utils:19] 29
[2025-10-22 23:57:24,550] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:24,874] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:24,875] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:25,096] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:25,097] INFO [src.utils:19] 29
[2025-10-22 23:57:25,097] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:25,364] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:25,364] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:25,586] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:25,586] INFO [src.utils:19] 29
[2025-10-22 23:57:25,587] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 18/6000 [01:02<5:38:06,  3.39s/it]                                                   {'loss': 4.0736, 'grad_norm': 660.7847900390625, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [01:02<5:38:06,  3.39s/it][2025-10-22 23:57:25,972] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:25,973] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:26,258] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:26,259] INFO [src.utils:19] 29
[2025-10-22 23:57:26,259] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:26,363] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:26,363] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:26,573] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:26,574] INFO [src.utils:19] 29
[2025-10-22 23:57:26,574] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:26,661] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:26,662] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:26,870] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:26,870] INFO [src.utils:19] 29
[2025-10-22 23:57:26,870] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:26,941] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:26,942] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:27,149] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:27,149] INFO [src.utils:19] 29
[2025-10-22 23:57:27,150] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:27,267] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:27,268] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:27,480] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:27,480] INFO [src.utils:19] 29
[2025-10-22 23:57:27,481] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:27,745] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:27,746] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:27,958] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:27,959] INFO [src.utils:19] 29
[2025-10-22 23:57:27,959] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:28,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:28,275] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:28,487] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:28,487] INFO [src.utils:19] 29
[2025-10-22 23:57:28,488] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:28,737] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:28,737] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:28,948] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:28,949] INFO [src.utils:19] 29
[2025-10-22 23:57:28,949] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 19/6000 [01:05<5:35:54,  3.37s/it]                                                   {'loss': 4.409, 'grad_norm': 1009.9605102539062, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [01:05<5:35:54,  3.37s/it][2025-10-22 23:57:29,331] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:29,333] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:29,643] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:29,643] INFO [src.utils:19] 29
[2025-10-22 23:57:29,643] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:29,767] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:29,768] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:29,986] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:29,986] INFO [src.utils:19] 29
[2025-10-22 23:57:29,987] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:30,047] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:30,048] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:30,254] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:30,255] INFO [src.utils:19] 29
[2025-10-22 23:57:30,255] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:30,310] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:30,311] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:30,518] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:30,518] INFO [src.utils:19] 29
[2025-10-22 23:57:30,518] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:30,651] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:30,652] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:30,873] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:30,874] INFO [src.utils:19] 29
[2025-10-22 23:57:30,874] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:31,171] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:31,171] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:31,393] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:31,394] INFO [src.utils:19] 29
[2025-10-22 23:57:31,394] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:57:31,644] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:31,645] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:31,857] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:31,858] INFO [src.utils:19] 29
[2025-10-22 23:57:31,858] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:32,093] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:32,093] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:32,314] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:32,315] INFO [src.utils:19] 29
[2025-10-22 23:57:32,315] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 20/6000 [01:09<5:37:23,  3.39s/it]                                                   {'loss': 3.805, 'grad_norm': 434.0822448730469, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [01:09<5:37:23,  3.39s/it][2025-10-22 23:57:32,733] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:32,734] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:33,027] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:33,027] INFO [src.utils:19] 29
[2025-10-22 23:57:33,028] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:33,099] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:33,099] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:33,309] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:33,310] INFO [src.utils:19] 29
[2025-10-22 23:57:33,310] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:33,385] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:33,386] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:33,621] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:33,621] INFO [src.utils:19] 29
[2025-10-22 23:57:33,622] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:33,744] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:33,745] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:33,981] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:33,981] INFO [src.utils:19] 29
[2025-10-22 23:57:33,981] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:34,093] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:34,093] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:34,306] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:34,307] INFO [src.utils:19] 29
[2025-10-22 23:57:34,307] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:34,532] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:34,533] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:34,745] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:34,745] INFO [src.utils:19] 29
[2025-10-22 23:57:34,746] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:35,015] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:35,016] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:35,253] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:35,253] INFO [src.utils:19] 29
[2025-10-22 23:57:35,253] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:35,563] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:35,563] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-22 23:57:35,800] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:35,801] INFO [src.utils:19] 29
[2025-10-22 23:57:35,801] INFO [src.utils:19] torch.Size([8, 177, 1536])
  0%|          | 21/6000 [01:12<5:39:04,  3.40s/it]                                                   {'loss': 3.613, 'grad_norm': 443.7062683105469, 'learning_rate': 1.05e-05, 'epoch': 0.0}
  0%|          | 21/6000 [01:12<5:39:04,  3.40s/it][2025-10-22 23:57:36,148] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:36,150] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:36,413] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:36,413] INFO [src.utils:19] 29
[2025-10-22 23:57:36,413] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:36,501] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:36,502] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:36,714] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:36,714] INFO [src.utils:19] 29
[2025-10-22 23:57:36,715] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:36,803] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:36,803] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:37,013] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:37,013] INFO [src.utils:19] 29
[2025-10-22 23:57:37,013] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:37,098] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:37,099] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:37,307] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:37,308] INFO [src.utils:19] 29
[2025-10-22 23:57:37,308] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:37,485] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:37,486] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:37,699] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:37,699] INFO [src.utils:19] 29
[2025-10-22 23:57:37,700] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:37,944] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:37,945] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:38,159] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:38,159] INFO [src.utils:19] 29
[2025-10-22 23:57:38,159] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:38,532] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:38,533] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:38,749] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:38,749] INFO [src.utils:19] 29
[2025-10-22 23:57:38,749] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:38,998] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:38,999] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:39,212] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:39,212] INFO [src.utils:19] 29
[2025-10-22 23:57:39,213] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 22/6000 [01:16<5:38:58,  3.40s/it]                                                   {'loss': 3.6537, 'grad_norm': 241.51126098632812, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}
  0%|          | 22/6000 [01:16<5:38:58,  3.40s/it][2025-10-22 23:57:39,605] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:39,606] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:39,912] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:39,912] INFO [src.utils:19] 29
[2025-10-22 23:57:39,913] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:39,964] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:39,965] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:40,185] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:40,185] INFO [src.utils:19] 29
[2025-10-22 23:57:40,185] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:40,242] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:40,243] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:40,450] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:40,451] INFO [src.utils:19] 29
[2025-10-22 23:57:40,451] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:40,588] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:40,589] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:40,797] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:40,798] INFO [src.utils:19] 29
[2025-10-22 23:57:40,798] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:40,923] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:40,923] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:41,146] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:41,146] INFO [src.utils:19] 29
[2025-10-22 23:57:41,147] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:41,364] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:41,365] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:41,587] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:41,588] INFO [src.utils:19] 29
[2025-10-22 23:57:41,588] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:57:41,833] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:41,834] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:42,045] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:42,045] INFO [src.utils:19] 29
[2025-10-22 23:57:42,046] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:42,348] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:42,349] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:42,560] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:42,561] INFO [src.utils:19] 29
[2025-10-22 23:57:42,561] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 23/6000 [01:19<5:37:07,  3.38s/it]                                                   {'loss': 3.5461, 'grad_norm': 253.96388244628906, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.0}
  0%|          | 23/6000 [01:19<5:37:07,  3.38s/it][2025-10-22 23:57:42,876] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:42,877] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:43,170] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:43,171] INFO [src.utils:19] 29
[2025-10-22 23:57:43,171] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:43,242] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:43,242] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:43,443] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:43,444] INFO [src.utils:19] 29
[2025-10-22 23:57:43,444] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:43,545] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:43,545] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:43,755] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:43,755] INFO [src.utils:19] 29
[2025-10-22 23:57:43,756] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:43,860] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:43,861] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:44,069] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:44,069] INFO [src.utils:19] 29
[2025-10-22 23:57:44,070] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:44,228] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:44,228] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:44,434] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:44,434] INFO [src.utils:19] 29
[2025-10-22 23:57:44,434] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:44,666] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:44,666] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:44,872] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:44,872] INFO [src.utils:19] 29
[2025-10-22 23:57:44,873] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-22 23:57:45,162] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:45,163] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:45,375] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:45,376] INFO [src.utils:19] 29
[2025-10-22 23:57:45,377] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:45,643] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:45,644] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:45,857] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:45,857] INFO [src.utils:19] 29
[2025-10-22 23:57:45,858] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 24/6000 [01:22<5:39:51,  3.41s/it]                                                   {'loss': 3.7104, 'grad_norm': 391.2177734375, 'learning_rate': 1.2e-05, 'epoch': 0.0}
  0%|          | 24/6000 [01:22<5:39:51,  3.41s/it][2025-10-22 23:57:46,368] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:46,369] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:46,690] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:46,691] INFO [src.utils:19] 29
[2025-10-22 23:57:46,691] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:46,776] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:46,776] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:46,988] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:46,989] INFO [src.utils:19] 29
[2025-10-22 23:57:46,989] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:47,091] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:47,092] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:47,300] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:47,301] INFO [src.utils:19] 29
[2025-10-22 23:57:47,301] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:47,387] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:47,388] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:47,597] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:47,598] INFO [src.utils:19] 29
[2025-10-22 23:57:47,598] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:47,677] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:47,678] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:47,890] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:47,891] INFO [src.utils:19] 29
[2025-10-22 23:57:47,891] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:48,138] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:48,139] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:48,353] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:48,353] INFO [src.utils:19] 29
[2025-10-22 23:57:48,353] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:57:48,722] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:48,723] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:48,937] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:48,937] INFO [src.utils:19] 29
[2025-10-22 23:57:48,938] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:49,193] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:49,194] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:49,408] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:49,409] INFO [src.utils:19] 29
[2025-10-22 23:57:49,409] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 25/6000 [01:26<5:38:24,  3.40s/it]                                                   {'loss': 3.5505, 'grad_norm': 188.17372131347656, 'learning_rate': 1.25e-05, 'epoch': 0.0}
  0%|          | 25/6000 [01:26<5:38:24,  3.40s/it][2025-10-22 23:57:49,767] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:49,768] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:50,136] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:50,136] INFO [src.utils:19] 29
[2025-10-22 23:57:50,137] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:50,265] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:50,266] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:50,495] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:50,496] INFO [src.utils:19] 29
[2025-10-22 23:57:50,496] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:50,574] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:50,574] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:50,783] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:50,783] INFO [src.utils:19] 29
[2025-10-22 23:57:50,784] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:50,840] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:50,840] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:51,050] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:51,051] INFO [src.utils:19] 29
[2025-10-22 23:57:51,051] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:51,171] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:51,171] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:51,402] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:51,403] INFO [src.utils:19] 29
[2025-10-22 23:57:51,403] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:51,708] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:51,709] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:51,940] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:51,948] INFO [src.utils:19] 29
[2025-10-22 23:57:51,948] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:52,213] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:52,214] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:52,430] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:52,431] INFO [src.utils:19] 29
[2025-10-22 23:57:52,431] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:52,657] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:52,658] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:52,871] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:52,872] INFO [src.utils:19] 29
[2025-10-22 23:57:52,872] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 26/6000 [01:29<5:41:38,  3.43s/it]                                                   {'loss': 3.4452, 'grad_norm': 144.81314086914062, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}
  0%|          | 26/6000 [01:29<5:41:38,  3.43s/it][2025-10-22 23:57:53,237] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:53,237] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:53,566] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:53,567] INFO [src.utils:19] 29
[2025-10-22 23:57:53,567] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:53,663] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:53,663] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:53,890] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:53,890] INFO [src.utils:19] 29
[2025-10-22 23:57:53,890] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:53,995] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:53,996] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:54,204] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:54,204] INFO [src.utils:19] 29
[2025-10-22 23:57:54,204] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:54,291] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:54,291] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:54,502] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:54,502] INFO [src.utils:19] 29
[2025-10-22 23:57:54,502] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:54,576] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:54,577] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:54,804] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:54,805] INFO [src.utils:19] 29
[2025-10-22 23:57:54,805] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:55,076] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:55,077] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:55,304] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:55,305] INFO [src.utils:19] 29
[2025-10-22 23:57:55,305] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-22 23:57:55,646] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:55,647] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:55,859] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:55,860] INFO [src.utils:19] 29
[2025-10-22 23:57:55,860] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:56,112] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:56,113] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:57:56,331] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:56,331] INFO [src.utils:19] 29
[2025-10-22 23:57:56,332] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 27/6000 [01:33<5:41:03,  3.43s/it]                                                   {'loss': 3.5228, 'grad_norm': 224.9904022216797, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.0}
  0%|          | 27/6000 [01:33<5:41:03,  3.43s/it][2025-10-22 23:57:56,693] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:56,694] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:56,969] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:56,970] INFO [src.utils:19] 29
[2025-10-22 23:57:56,970] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:57,034] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:57,034] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:57,262] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:57,263] INFO [src.utils:19] 29
[2025-10-22 23:57:57,264] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:57,344] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:57,345] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:57,562] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:57,563] INFO [src.utils:19] 29
[2025-10-22 23:57:57,563] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:57,687] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:57,688] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:57,908] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:57,908] INFO [src.utils:19] 29
[2025-10-22 23:57:57,908] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:58,299] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:58,299] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:58,535] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:58,536] INFO [src.utils:19] 29
[2025-10-22 23:57:58,536] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:58,783] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:58,784] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:59,016] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:59,017] INFO [src.utils:19] 29
[2025-10-22 23:57:59,017] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-22 23:57:59,302] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:59,302] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:59,523] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:57:59,524] INFO [src.utils:19] 29
[2025-10-22 23:57:59,524] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:57:59,821] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:57:59,822] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:00,044] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:00,044] INFO [src.utils:19] 29
[2025-10-22 23:58:00,044] INFO [src.utils:19] torch.Size([8, 150, 1536])
  0%|          | 28/6000 [01:37<6:07:41,  3.69s/it]                                                   {'loss': 2.984, 'grad_norm': 160.36424255371094, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}
  0%|          | 28/6000 [01:37<6:07:41,  3.69s/it][2025-10-22 23:58:00,957] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:00,959] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:01,248] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:01,249] INFO [src.utils:19] 29
[2025-10-22 23:58:01,249] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:01,325] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:01,326] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:01,537] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:01,537] INFO [src.utils:19] 29
[2025-10-22 23:58:01,538] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:01,660] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:01,661] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:01,873] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:01,874] INFO [src.utils:19] 29
[2025-10-22 23:58:01,874] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:01,981] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:01,982] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:02,190] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:02,191] INFO [src.utils:19] 29
[2025-10-22 23:58:02,191] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:02,253] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:02,254] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:02,467] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:02,467] INFO [src.utils:19] 29
[2025-10-22 23:58:02,468] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:02,702] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:02,702] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:02,917] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:02,917] INFO [src.utils:19] 29
[2025-10-22 23:58:02,918] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:03,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:03,274] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:03,487] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:03,487] INFO [src.utils:19] 29
[2025-10-22 23:58:03,488] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:03,757] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:03,758] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:03,972] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:03,972] INFO [src.utils:19] 29
[2025-10-22 23:58:03,973] INFO [src.utils:19] torch.Size([8, 132, 1536])
  0%|          | 29/6000 [01:40<5:56:23,  3.58s/it]                                                   {'loss': 3.0844, 'grad_norm': 197.25021362304688, 'learning_rate': 1.45e-05, 'epoch': 0.0}
  0%|          | 29/6000 [01:40<5:56:23,  3.58s/it][2025-10-22 23:58:04,304] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:04,306] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:04,622] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:04,622] INFO [src.utils:19] 29
[2025-10-22 23:58:04,623] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:04,727] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:04,728] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:04,939] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:04,939] INFO [src.utils:19] 29
[2025-10-22 23:58:04,940] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:05,042] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:05,043] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:05,268] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:05,268] INFO [src.utils:19] 29
[2025-10-22 23:58:05,269] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:05,344] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:05,344] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:05,567] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:05,568] INFO [src.utils:19] 29
[2025-10-22 23:58:05,568] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:05,659] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:05,659] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:05,873] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:05,873] INFO [src.utils:19] 29
[2025-10-22 23:58:05,873] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:06,136] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:06,137] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:06,352] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:06,352] INFO [src.utils:19] 29
[2025-10-22 23:58:06,352] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:06,641] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:06,641] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:06,866] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:06,866] INFO [src.utils:19] 29
[2025-10-22 23:58:06,867] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:07,112] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:07,113] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:07,337] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:07,337] INFO [src.utils:19] 29
[2025-10-22 23:58:07,338] INFO [src.utils:19] torch.Size([8, 159, 1536])
  0%|          | 30/6000 [01:44<5:49:56,  3.52s/it]                                                   {'loss': 3.6006, 'grad_norm': 180.75306701660156, 'learning_rate': 1.5e-05, 'epoch': 0.01}
  0%|          | 30/6000 [01:44<5:49:56,  3.52s/it][2025-10-22 23:58:07,671] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:07,672] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:07,979] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:07,980] INFO [src.utils:19] 29
[2025-10-22 23:58:07,980] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:08,065] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:08,066] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:08,277] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:08,277] INFO [src.utils:19] 29
[2025-10-22 23:58:08,278] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:08,364] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:08,365] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:08,574] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:08,575] INFO [src.utils:19] 29
[2025-10-22 23:58:08,575] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:08,662] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:08,663] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:08,876] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:08,877] INFO [src.utils:19] 29
[2025-10-22 23:58:08,877] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:08,992] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:08,993] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:09,209] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:09,209] INFO [src.utils:19] 29
[2025-10-22 23:58:09,210] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:09,456] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:09,457] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:09,674] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:09,675] INFO [src.utils:19] 29
[2025-10-22 23:58:09,675] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:09,949] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:09,950] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:10,166] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:10,167] INFO [src.utils:19] 29
[2025-10-22 23:58:10,167] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:10,418] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:10,418] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:10,632] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:10,632] INFO [src.utils:19] 29
[2025-10-22 23:58:10,633] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 31/6000 [01:47<5:43:58,  3.46s/it]                                                   {'loss': 2.9233, 'grad_norm': 117.81301879882812, 'learning_rate': 1.55e-05, 'epoch': 0.01}
  1%|          | 31/6000 [01:47<5:43:58,  3.46s/it][2025-10-22 23:58:11,034] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:11,035] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:11,344] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:11,345] INFO [src.utils:19] 29
[2025-10-22 23:58:11,345] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:11,457] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:11,458] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:11,680] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:11,681] INFO [src.utils:19] 29
[2025-10-22 23:58:11,681] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:11,741] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:11,742] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:11,950] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:11,951] INFO [src.utils:19] 29
[2025-10-22 23:58:11,951] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:12,026] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:12,026] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:12,234] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:12,235] INFO [src.utils:19] 29
[2025-10-22 23:58:12,235] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:12,360] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:12,361] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:12,584] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:12,584] INFO [src.utils:19] 29
[2025-10-22 23:58:12,585] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:12,870] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:12,871] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:13,096] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:13,097] INFO [src.utils:19] 29
[2025-10-22 23:58:13,097] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:13,344] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:13,345] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:13,558] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:13,559] INFO [src.utils:19] 29
[2025-10-22 23:58:13,559] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:13,805] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:13,806] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:14,023] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:14,023] INFO [src.utils:19] 29
[2025-10-22 23:58:14,024] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 32/6000 [01:50<5:43:23,  3.45s/it]                                                   {'loss': 3.054, 'grad_norm': 98.28033447265625, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}
  1%|          | 32/6000 [01:50<5:43:23,  3.45s/it][2025-10-22 23:58:14,461] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:14,461] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:14,758] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:14,759] INFO [src.utils:19] 29
[2025-10-22 23:58:14,759] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:14,835] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:14,835] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:15,059] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:15,060] INFO [src.utils:19] 29
[2025-10-22 23:58:15,060] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:15,135] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:15,135] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:15,345] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:15,345] INFO [src.utils:19] 29
[2025-10-22 23:58:15,345] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:15,449] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:15,449] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:15,659] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:15,660] INFO [src.utils:19] 29
[2025-10-22 23:58:15,660] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:15,784] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:15,785] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:16,009] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:16,009] INFO [src.utils:19] 29
[2025-10-22 23:58:16,010] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:16,253] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:16,253] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:16,476] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:16,477] INFO [src.utils:19] 29
[2025-10-22 23:58:16,477] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:16,742] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:16,743] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:16,957] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:16,958] INFO [src.utils:19] 29
[2025-10-22 23:58:16,958] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:17,224] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:17,225] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:17,439] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:17,440] INFO [src.utils:19] 29
[2025-10-22 23:58:17,440] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 33/6000 [01:54<5:41:06,  3.43s/it]                                                   {'loss': 2.9554, 'grad_norm': 93.75253295898438, 'learning_rate': 1.65e-05, 'epoch': 0.01}
  1%|          | 33/6000 [01:54<5:41:06,  3.43s/it][2025-10-22 23:58:17,814] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:17,815] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:18,089] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:18,090] INFO [src.utils:19] 29
[2025-10-22 23:58:18,090] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:18,214] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:18,215] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:18,426] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:18,426] INFO [src.utils:19] 29
[2025-10-22 23:58:18,426] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:18,528] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:18,528] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:18,739] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:18,740] INFO [src.utils:19] 29
[2025-10-22 23:58:18,740] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:18,798] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:18,798] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:19,008] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:19,009] INFO [src.utils:19] 29
[2025-10-22 23:58:19,009] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:19,108] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:19,108] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:19,322] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:19,323] INFO [src.utils:19] 29
[2025-10-22 23:58:19,323] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:19,606] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:19,607] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:19,822] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:19,822] INFO [src.utils:19] 29
[2025-10-22 23:58:19,823] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:20,137] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:20,138] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:20,354] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:20,355] INFO [src.utils:19] 29
[2025-10-22 23:58:20,355] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:20,579] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:20,580] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:20,795] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:20,795] INFO [src.utils:19] 29
[2025-10-22 23:58:20,795] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|          | 34/6000 [01:57<5:37:50,  3.40s/it]                                                   {'loss': 2.85, 'grad_norm': 72.33268737792969, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}
  1%|          | 34/6000 [01:57<5:37:50,  3.40s/it][2025-10-22 23:58:21,132] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:21,133] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:21,442] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:21,443] INFO [src.utils:19] 29
[2025-10-22 23:58:21,443] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:21,522] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:21,522] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:21,741] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:21,742] INFO [src.utils:19] 29
[2025-10-22 23:58:21,742] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:21,852] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:21,853] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:22,077] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:22,077] INFO [src.utils:19] 29
[2025-10-22 23:58:22,078] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:22,181] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:22,181] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:22,400] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:22,401] INFO [src.utils:19] 29
[2025-10-22 23:58:22,401] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:22,485] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:22,486] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:22,709] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:22,710] INFO [src.utils:19] 29
[2025-10-22 23:58:22,710] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:22,950] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:22,951] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:23,177] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:23,178] INFO [src.utils:19] 29
[2025-10-22 23:58:23,178] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:23,480] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:23,481] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:23,705] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:23,705] INFO [src.utils:19] 29
[2025-10-22 23:58:23,706] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:23,976] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:23,976] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:24,199] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:24,199] INFO [src.utils:19] 29
[2025-10-22 23:58:24,200] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 35/6000 [02:00<5:38:04,  3.40s/it]                                                   {'loss': 2.853, 'grad_norm': 88.27969360351562, 'learning_rate': 1.75e-05, 'epoch': 0.01}
  1%|          | 35/6000 [02:00<5:38:04,  3.40s/it][2025-10-22 23:58:24,566] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:24,567] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:24,861] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:24,861] INFO [src.utils:19] 29
[2025-10-22 23:58:24,862] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:24,917] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:24,918] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:25,129] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:25,129] INFO [src.utils:19] 29
[2025-10-22 23:58:25,130] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:25,187] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:25,188] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:25,399] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:25,399] INFO [src.utils:19] 29
[2025-10-22 23:58:25,400] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:25,519] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:25,519] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:25,731] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:25,732] INFO [src.utils:19] 29
[2025-10-22 23:58:25,732] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:25,858] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:25,858] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:26,073] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:26,073] INFO [src.utils:19] 29
[2025-10-22 23:58:26,073] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:26,287] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:26,288] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:26,501] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:26,501] INFO [src.utils:19] 29
[2025-10-22 23:58:26,502] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:26,771] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:26,772] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:26,986] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:26,987] INFO [src.utils:19] 29
[2025-10-22 23:58:26,987] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:27,271] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:27,271] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:27,486] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:27,487] INFO [src.utils:19] 29
[2025-10-22 23:58:27,487] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|          | 36/6000 [02:04<5:34:35,  3.37s/it]                                                   {'loss': 2.7912, 'grad_norm': 87.37937927246094, 'learning_rate': 1.8e-05, 'epoch': 0.01}
  1%|          | 36/6000 [02:04<5:34:35,  3.37s/it][2025-10-22 23:58:27,814] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:27,816] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:28,137] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:28,138] INFO [src.utils:19] 29
[2025-10-22 23:58:28,138] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:28,215] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:28,216] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:28,426] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:28,426] INFO [src.utils:19] 29
[2025-10-22 23:58:28,427] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:28,530] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:28,530] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:28,742] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:28,743] INFO [src.utils:19] 29
[2025-10-22 23:58:28,743] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:28,859] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:28,860] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:29,076] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:29,077] INFO [src.utils:19] 29
[2025-10-22 23:58:29,077] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:29,155] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:29,156] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:29,371] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:29,371] INFO [src.utils:19] 29
[2025-10-22 23:58:29,372] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:29,618] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:29,619] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:29,833] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:29,834] INFO [src.utils:19] 29
[2025-10-22 23:58:29,834] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:30,155] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:30,156] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:30,375] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:30,376] INFO [src.utils:19] 29
[2025-10-22 23:58:30,376] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:30,656] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:30,657] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:30,873] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:30,873] INFO [src.utils:19] 29
[2025-10-22 23:58:30,874] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|          | 37/6000 [02:07<5:35:20,  3.37s/it]                                                   {'loss': 2.6988, 'grad_norm': 102.1607437133789, 'learning_rate': 1.85e-05, 'epoch': 0.01}
  1%|          | 37/6000 [02:07<5:35:20,  3.37s/it][2025-10-22 23:58:31,200] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:31,200] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:31,511] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:31,512] INFO [src.utils:19] 29
[2025-10-22 23:58:31,512] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:31,615] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:31,615] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:31,827] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:31,828] INFO [src.utils:19] 29
[2025-10-22 23:58:31,828] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:31,953] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:31,953] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:32,168] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:32,168] INFO [src.utils:19] 29
[2025-10-22 23:58:32,169] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:32,238] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:32,238] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:32,446] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:32,447] INFO [src.utils:19] 29
[2025-10-22 23:58:32,447] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:32,507] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:32,507] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:32,723] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:32,724] INFO [src.utils:19] 29
[2025-10-22 23:58:32,724] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:32,992] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:32,993] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:33,208] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:33,208] INFO [src.utils:19] 29
[2025-10-22 23:58:33,209] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:33,559] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:33,560] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:33,775] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:33,775] INFO [src.utils:19] 29
[2025-10-22 23:58:33,776] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:34,014] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:34,015] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:34,229] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:34,230] INFO [src.utils:19] 29
[2025-10-22 23:58:34,230] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 38/6000 [02:11<5:34:26,  3.37s/it]                                                   {'loss': 2.663, 'grad_norm': 94.5190200805664, 'learning_rate': 1.9e-05, 'epoch': 0.01}
  1%|          | 38/6000 [02:11<5:34:26,  3.37s/it][2025-10-22 23:58:34,547] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:34,548] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:34,844] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:34,845] INFO [src.utils:19] 29
[2025-10-22 23:58:34,845] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:34,902] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:34,903] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:35,114] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:35,114] INFO [src.utils:19] 29
[2025-10-22 23:58:35,115] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:35,218] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:35,219] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:35,441] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:35,442] INFO [src.utils:19] 29
[2025-10-22 23:58:35,442] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:35,567] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:35,568] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:35,793] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:35,793] INFO [src.utils:19] 29
[2025-10-22 23:58:35,794] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:35,875] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:35,875] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:36,096] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:36,097] INFO [src.utils:19] 29
[2025-10-22 23:58:36,097] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:36,318] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:36,319] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:36,533] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:36,534] INFO [src.utils:19] 29
[2025-10-22 23:58:36,534] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:36,827] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:36,827] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:37,051] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:37,052] INFO [src.utils:19] 29
[2025-10-22 23:58:37,052] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:37,345] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:37,346] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:37,568] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:37,569] INFO [src.utils:19] 29
[2025-10-22 23:58:37,569] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 39/6000 [02:14<5:33:59,  3.36s/it]                                                   {'loss': 2.3934, 'grad_norm': 129.3906707763672, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}
  1%|          | 39/6000 [02:14<5:33:59,  3.36s/it][2025-10-22 23:58:37,893] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:37,895] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:38,190] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:38,191] INFO [src.utils:19] 29
[2025-10-22 23:58:38,191] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:38,267] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:38,268] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:38,479] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:38,480] INFO [src.utils:19] 29
[2025-10-22 23:58:38,480] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:38,584] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:38,584] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:38,807] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:38,807] INFO [src.utils:19] 29
[2025-10-22 23:58:38,808] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:38,926] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:38,927] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:39,149] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:39,149] INFO [src.utils:19] 29
[2025-10-22 23:58:39,150] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:39,227] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:39,227] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:39,441] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:39,442] INFO [src.utils:19] 29
[2025-10-22 23:58:39,442] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:39,689] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:39,690] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:39,909] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:39,909] INFO [src.utils:19] 29
[2025-10-22 23:58:39,909] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:40,263] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:40,264] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:40,494] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:40,495] INFO [src.utils:19] 29
[2025-10-22 23:58:40,495] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:40,785] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:40,786] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:58:41,014] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:41,014] INFO [src.utils:19] 29
[2025-10-22 23:58:41,015] INFO [src.utils:19] torch.Size([8, 159, 1536])
  1%|          | 40/6000 [02:17<5:36:06,  3.38s/it]                                                   {'loss': 2.5753, 'grad_norm': 98.22616577148438, 'learning_rate': 2e-05, 'epoch': 0.01}
  1%|          | 40/6000 [02:17<5:36:06,  3.38s/it][2025-10-22 23:58:41,321] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:41,322] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:41,623] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:41,624] INFO [src.utils:19] 29
[2025-10-22 23:58:41,624] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:41,712] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:41,713] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:41,928] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:41,929] INFO [src.utils:19] 29
[2025-10-22 23:58:41,929] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:42,055] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:42,056] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:42,271] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:42,271] INFO [src.utils:19] 29
[2025-10-22 23:58:42,272] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:42,361] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:42,362] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:42,574] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:42,575] INFO [src.utils:19] 29
[2025-10-22 23:58:42,575] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:42,630] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:42,631] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:42,843] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:42,844] INFO [src.utils:19] 29
[2025-10-22 23:58:42,844] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:43,099] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:43,100] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:43,314] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:43,315] INFO [src.utils:19] 29
[2025-10-22 23:58:43,315] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:43,651] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:43,652] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:43,866] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:43,866] INFO [src.utils:19] 29
[2025-10-22 23:58:43,867] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:44,114] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:44,115] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:58:44,330] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:44,331] INFO [src.utils:19] 29
[2025-10-22 23:58:44,331] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|          | 41/6000 [02:21<5:34:05,  3.36s/it]                                                   {'loss': 2.0108, 'grad_norm': 99.30582427978516, 'learning_rate': 2.05e-05, 'epoch': 0.01}
  1%|          | 41/6000 [02:21<5:34:05,  3.36s/it][2025-10-22 23:58:44,657] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:44,658] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:44,941] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:44,942] INFO [src.utils:19] 29
[2025-10-22 23:58:44,942] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:45,032] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:45,033] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:45,251] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:45,252] INFO [src.utils:19] 29
[2025-10-22 23:58:45,252] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:45,358] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:45,358] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:45,570] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:45,570] INFO [src.utils:19] 29
[2025-10-22 23:58:45,570] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:45,656] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:45,656] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:45,866] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:45,866] INFO [src.utils:19] 29
[2025-10-22 23:58:45,867] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:45,965] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:45,966] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:46,187] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:46,187] INFO [src.utils:19] 29
[2025-10-22 23:58:46,188] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:46,444] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:46,444] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:46,666] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:46,667] INFO [src.utils:19] 29
[2025-10-22 23:58:46,667] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:46,987] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:46,987] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:47,206] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:47,207] INFO [src.utils:19] 29
[2025-10-22 23:58:47,207] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:47,468] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:47,469] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:58:47,685] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:47,686] INFO [src.utils:19] 29
[2025-10-22 23:58:47,686] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 42/6000 [02:24<5:33:58,  3.36s/it]                                                   {'loss': 1.8149, 'grad_norm': 70.39430236816406, 'learning_rate': 2.1e-05, 'epoch': 0.01}
  1%|          | 42/6000 [02:24<5:33:58,  3.36s/it][2025-10-22 23:58:48,036] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:48,037] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:48,347] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:48,347] INFO [src.utils:19] 29
[2025-10-22 23:58:48,348] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:48,423] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:48,424] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:48,638] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:48,639] INFO [src.utils:19] 29
[2025-10-22 23:58:48,639] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:48,710] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:48,711] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:49,073] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:49,074] INFO [src.utils:19] 29
[2025-10-22 23:58:49,074] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:49,239] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:49,239] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:49,599] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:49,600] INFO [src.utils:19] 29
[2025-10-22 23:58:49,600] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:49,723] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:49,724] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:49,942] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:49,942] INFO [src.utils:19] 29
[2025-10-22 23:58:49,942] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:50,178] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:50,179] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:50,400] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:50,400] INFO [src.utils:19] 29
[2025-10-22 23:58:50,401] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:58:50,668] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:50,669] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:51,035] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:51,035] INFO [src.utils:19] 29
[2025-10-22 23:58:51,036] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:51,557] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:51,558] INFO [src.utils:19] torch.Size([8, 375, 1536])
[2025-10-22 23:58:51,919] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:51,920] INFO [src.utils:19] 29
[2025-10-22 23:58:51,920] INFO [src.utils:19] torch.Size([8, 375, 1536])
  1%|          | 43/6000 [02:28<6:05:43,  3.68s/it]                                                   {'loss': 1.4004, 'grad_norm': 79.2299575805664, 'learning_rate': 2.15e-05, 'epoch': 0.01}
  1%|          | 43/6000 [02:28<6:05:43,  3.68s/it][2025-10-22 23:58:52,504] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:52,506] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:52,812] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:52,812] INFO [src.utils:19] 29
[2025-10-22 23:58:52,813] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:52,933] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:52,933] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:53,151] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:53,152] INFO [src.utils:19] 29
[2025-10-22 23:58:53,152] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:53,210] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:53,211] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:53,485] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:53,486] INFO [src.utils:19] 29
[2025-10-22 23:58:53,486] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:53,571] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:53,571] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:53,847] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:53,848] INFO [src.utils:19] 29
[2025-10-22 23:58:53,848] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:53,995] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:53,995] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:54,217] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:54,217] INFO [src.utils:19] 29
[2025-10-22 23:58:54,218] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:54,502] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:54,503] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:54,727] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:54,727] INFO [src.utils:19] 29
[2025-10-22 23:58:54,727] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:58:54,975] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:54,976] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:55,254] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:55,255] INFO [src.utils:19] 29
[2025-10-22 23:58:55,255] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:55,606] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:55,607] INFO [src.utils:19] torch.Size([8, 231, 1536])
[2025-10-22 23:58:55,885] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:55,886] INFO [src.utils:19] 29
[2025-10-22 23:58:55,886] INFO [src.utils:19] torch.Size([8, 231, 1536])
  1%|          | 44/6000 [02:32<6:10:58,  3.74s/it]                                                   {'loss': 1.5528, 'grad_norm': 68.05076599121094, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.01}
  1%|          | 44/6000 [02:32<6:10:58,  3.74s/it][2025-10-22 23:58:56,358] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:56,359] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:56,666] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:56,667] INFO [src.utils:19] 29
[2025-10-22 23:58:56,667] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:56,744] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:56,745] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:56,966] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:56,966] INFO [src.utils:19] 29
[2025-10-22 23:58:56,967] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:57,024] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:57,024] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:57,244] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:57,244] INFO [src.utils:19] 29
[2025-10-22 23:58:57,245] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:57,364] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:57,365] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:57,583] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:57,583] INFO [src.utils:19] 29
[2025-10-22 23:58:57,584] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:57,718] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:57,719] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:57,943] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:57,944] INFO [src.utils:19] 29
[2025-10-22 23:58:57,944] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:58,186] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:58,187] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:58,412] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:58,413] INFO [src.utils:19] 29
[2025-10-22 23:58:58,413] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:58:58,657] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:58,658] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:58,881] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:58,881] INFO [src.utils:19] 29
[2025-10-22 23:58:58,881] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:59,165] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:59,165] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:58:59,387] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:58:59,388] INFO [src.utils:19] 29
[2025-10-22 23:58:59,388] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 45/6000 [02:36<6:00:58,  3.64s/it]                                                   {'loss': 1.2831, 'grad_norm': 58.26750564575195, 'learning_rate': 2.25e-05, 'epoch': 0.01}
  1%|          | 45/6000 [02:36<6:00:58,  3.64s/it][2025-10-22 23:58:59,727] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:58:59,728] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:00,031] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:00,032] INFO [src.utils:19] 29
[2025-10-22 23:59:00,032] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:00,150] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:00,151] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:00,363] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:00,364] INFO [src.utils:19] 29
[2025-10-22 23:59:00,364] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:00,450] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:00,450] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:00,661] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:00,661] INFO [src.utils:19] 29
[2025-10-22 23:59:00,661] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:00,736] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:00,736] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:00,945] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:00,946] INFO [src.utils:19] 29
[2025-10-22 23:59:00,946] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:01,078] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:01,079] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:01,298] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:01,298] INFO [src.utils:19] 29
[2025-10-22 23:59:01,299] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:01,575] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:01,576] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:01,789] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:01,790] INFO [src.utils:19] 29
[2025-10-22 23:59:01,790] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:02,113] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:02,114] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:02,332] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:02,333] INFO [src.utils:19] 29
[2025-10-22 23:59:02,333] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:02,574] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:02,575] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:02,788] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:02,789] INFO [src.utils:19] 29
[2025-10-22 23:59:02,789] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 46/6000 [02:39<5:55:33,  3.58s/it]                                                   {'loss': 1.1006, 'grad_norm': 61.14345932006836, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01}
  1%|          | 46/6000 [02:39<5:55:33,  3.58s/it][2025-10-22 23:59:03,183] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:03,185] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:03,537] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:03,538] INFO [src.utils:19] 29
[2025-10-22 23:59:03,538] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:03,624] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:03,625] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:03,836] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:03,837] INFO [src.utils:19] 29
[2025-10-22 23:59:03,837] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:03,923] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:03,924] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:04,143] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:04,144] INFO [src.utils:19] 29
[2025-10-22 23:59:04,144] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:04,250] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:04,251] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:04,473] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:04,474] INFO [src.utils:19] 29
[2025-10-22 23:59:04,474] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:04,570] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:04,570] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:04,785] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:04,786] INFO [src.utils:19] 29
[2025-10-22 23:59:04,786] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:05,037] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:05,038] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:05,251] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:05,252] INFO [src.utils:19] 29
[2025-10-22 23:59:05,252] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:05,540] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:05,541] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:05,770] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:05,771] INFO [src.utils:19] 29
[2025-10-22 23:59:05,771] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:06,049] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:06,050] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-22 23:59:06,276] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:06,277] INFO [src.utils:19] 29
[2025-10-22 23:59:06,278] INFO [src.utils:19] torch.Size([8, 159, 1536])
  1%|          | 47/6000 [02:43<5:51:17,  3.54s/it]                                                   {'loss': 1.0941, 'grad_norm': 57.64149856567383, 'learning_rate': 2.35e-05, 'epoch': 0.01}
  1%|          | 47/6000 [02:43<5:51:17,  3.54s/it][2025-10-22 23:59:06,640] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:06,641] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:07,055] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:07,056] INFO [src.utils:19] 29
[2025-10-22 23:59:07,056] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:07,129] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:07,130] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:07,342] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:07,343] INFO [src.utils:19] 29
[2025-10-22 23:59:07,343] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:07,432] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:07,433] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:07,659] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:07,659] INFO [src.utils:19] 29
[2025-10-22 23:59:07,660] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:07,783] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:07,783] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:08,011] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:08,011] INFO [src.utils:19] 29
[2025-10-22 23:59:08,012] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:08,104] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:08,104] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:08,318] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:08,319] INFO [src.utils:19] 29
[2025-10-22 23:59:08,319] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:08,551] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:08,551] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:08,771] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:08,772] INFO [src.utils:19] 29
[2025-10-22 23:59:08,772] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:09,080] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:09,081] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:09,313] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:09,313] INFO [src.utils:19] 29
[2025-10-22 23:59:09,314] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:09,613] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:09,614] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:09,848] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:09,848] INFO [src.utils:19] 29
[2025-10-22 23:59:09,849] INFO [src.utils:19] torch.Size([8, 168, 1536])
  1%|          | 48/6000 [02:46<5:52:07,  3.55s/it]                                                   {'loss': 0.8481, 'grad_norm': 50.23876953125, 'learning_rate': 2.4e-05, 'epoch': 0.01}
  1%|          | 48/6000 [02:46<5:52:07,  3.55s/it][2025-10-22 23:59:10,181] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:10,183] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:10,489] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:10,490] INFO [src.utils:19] 29
[2025-10-22 23:59:10,490] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:10,596] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:10,596] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:10,810] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:10,811] INFO [src.utils:19] 29
[2025-10-22 23:59:10,811] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:10,913] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:10,914] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:11,124] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:11,124] INFO [src.utils:19] 29
[2025-10-22 23:59:11,125] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:11,196] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:11,197] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:11,405] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:11,405] INFO [src.utils:19] 29
[2025-10-22 23:59:11,405] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:11,483] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:11,483] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:11,698] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:11,698] INFO [src.utils:19] 29
[2025-10-22 23:59:11,699] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:11,964] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:11,965] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:12,179] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:12,180] INFO [src.utils:19] 29
[2025-10-22 23:59:12,180] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:12,464] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:12,465] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:12,679] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:12,680] INFO [src.utils:19] 29
[2025-10-22 23:59:12,680] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:12,911] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:12,912] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:13,125] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:13,126] INFO [src.utils:19] 29
[2025-10-22 23:59:13,126] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 49/6000 [02:49<5:44:16,  3.47s/it]                                                   {'loss': 0.4839, 'grad_norm': 38.56942367553711, 'learning_rate': 2.45e-05, 'epoch': 0.01}
  1%|          | 49/6000 [02:49<5:44:16,  3.47s/it][2025-10-22 23:59:13,498] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:13,500] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:13,825] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:13,825] INFO [src.utils:19] 29
[2025-10-22 23:59:13,826] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:13,919] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:13,919] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:14,158] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:14,158] INFO [src.utils:19] 29
[2025-10-22 23:59:14,158] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:14,248] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:14,249] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:14,476] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:14,476] INFO [src.utils:19] 29
[2025-10-22 23:59:14,477] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:14,569] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:14,570] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:14,796] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:14,797] INFO [src.utils:19] 29
[2025-10-22 23:59:14,797] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:14,891] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:14,892] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:15,134] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:15,134] INFO [src.utils:19] 29
[2025-10-22 23:59:15,135] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:15,424] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:15,425] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:15,667] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:15,667] INFO [src.utils:19] 29
[2025-10-22 23:59:15,667] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-22 23:59:15,959] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:15,959] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:16,195] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:16,196] INFO [src.utils:19] 29
[2025-10-22 23:59:16,196] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:16,465] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:16,466] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-22 23:59:16,700] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:16,700] INFO [src.utils:19] 29
[2025-10-22 23:59:16,701] INFO [src.utils:19] torch.Size([8, 168, 1536])
  1%|          | 50/6000 [02:53<5:46:52,  3.50s/it]                                                   {'loss': 0.4387, 'grad_norm': 38.977745056152344, 'learning_rate': 2.5e-05, 'epoch': 0.01}
  1%|          | 50/6000 [02:53<5:46:52,  3.50s/it][2025-10-22 23:59:16,932] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[2025-10-22 23:59:19,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:19,275] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:19,585] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:19,585] INFO [src.utils:19] 29
[2025-10-22 23:59:19,586] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:19,643] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:19,643] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:19,855] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:19,855] INFO [src.utils:19] 29
[2025-10-22 23:59:19,856] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:19,925] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:19,925] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:20,136] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:20,136] INFO [src.utils:19] 29
[2025-10-22 23:59:20,137] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:20,260] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:20,261] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:20,471] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:20,471] INFO [src.utils:19] 29
[2025-10-22 23:59:20,471] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:20,575] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:20,576] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:20,791] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:20,791] INFO [src.utils:19] 29
[2025-10-22 23:59:20,791] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:21,010] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:21,011] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:21,227] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:21,228] INFO [src.utils:19] 29
[2025-10-22 23:59:21,228] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:21,494] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:21,495] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:21,708] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:21,709] INFO [src.utils:19] 29
[2025-10-22 23:59:21,709] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:21,997] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:21,998] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:22,212] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:22,213] INFO [src.utils:19] 29
[2025-10-22 23:59:22,213] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 51/6000 [02:59<6:47:36,  4.11s/it]                                                   {'loss': 0.3349, 'grad_norm': 29.632997512817383, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.01}
  1%|          | 51/6000 [02:59<6:47:36,  4.11s/it][2025-10-22 23:59:22,570] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:22,572] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:22,869] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:22,869] INFO [src.utils:19] 29
[2025-10-22 23:59:22,870] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:22,945] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:22,945] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:23,157] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:23,157] INFO [src.utils:19] 29
[2025-10-22 23:59:23,158] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:23,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:23,275] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:23,489] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:23,489] INFO [src.utils:19] 29
[2025-10-22 23:59:23,490] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:23,592] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:23,593] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:23,802] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:23,802] INFO [src.utils:19] 29
[2025-10-22 23:59:23,803] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:23,877] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:23,877] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:24,091] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:24,092] INFO [src.utils:19] 29
[2025-10-22 23:59:24,092] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:24,330] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:24,331] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:24,545] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:24,545] INFO [src.utils:19] 29
[2025-10-22 23:59:24,545] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:24,858] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:24,859] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:25,075] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:25,076] INFO [src.utils:19] 29
[2025-10-22 23:59:25,076] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:25,344] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:25,345] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:25,561] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:25,561] INFO [src.utils:19] 29
[2025-10-22 23:59:25,562] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 52/6000 [03:02<6:24:02,  3.87s/it]                                                   {'loss': 0.3431, 'grad_norm': 22.167598724365234, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}
  1%|          | 52/6000 [03:02<6:24:02,  3.87s/it][2025-10-22 23:59:25,941] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:25,941] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:26,225] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:26,226] INFO [src.utils:19] 29
[2025-10-22 23:59:26,226] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:26,352] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:26,352] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:26,563] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:26,564] INFO [src.utils:19] 29
[2025-10-22 23:59:26,564] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:26,621] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:26,622] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:26,817] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:26,817] INFO [src.utils:19] 29
[2025-10-22 23:59:26,818] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:26,871] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:26,871] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:27,067] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:27,067] INFO [src.utils:19] 29
[2025-10-22 23:59:27,068] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:27,278] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:27,279] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:27,494] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:27,494] INFO [src.utils:19] 29
[2025-10-22 23:59:27,495] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:27,786] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:27,786] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:28,004] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:28,004] INFO [src.utils:19] 29
[2025-10-22 23:59:28,005] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:28,258] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:28,259] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:28,458] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:28,459] INFO [src.utils:19] 29
[2025-10-22 23:59:28,459] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:28,667] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:28,668] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-22 23:59:28,867] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:28,868] INFO [src.utils:19] 29
[2025-10-22 23:59:28,868] INFO [src.utils:19] torch.Size([8, 114, 1536])
  1%|          | 53/6000 [03:05<6:09:52,  3.73s/it]                                                   {'loss': 0.3695, 'grad_norm': 40.12506866455078, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.01}
  1%|          | 53/6000 [03:05<6:09:52,  3.73s/it][2025-10-22 23:59:29,333] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:29,334] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:29,642] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:29,642] INFO [src.utils:19] 29
[2025-10-22 23:59:29,643] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:29,719] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:29,720] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:29,932] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:29,932] INFO [src.utils:19] 29
[2025-10-22 23:59:29,933] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:30,022] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:30,023] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:30,233] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:30,234] INFO [src.utils:19] 29
[2025-10-22 23:59:30,234] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:30,343] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:30,344] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:30,554] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:30,555] INFO [src.utils:19] 29
[2025-10-22 23:59:30,555] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:30,645] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:30,645] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:30,861] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:30,861] INFO [src.utils:19] 29
[2025-10-22 23:59:30,862] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:31,104] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:31,105] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:31,323] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:31,324] INFO [src.utils:19] 29
[2025-10-22 23:59:31,324] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:31,645] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:31,646] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:31,868] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:31,868] INFO [src.utils:19] 29
[2025-10-22 23:59:31,868] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:32,136] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:32,137] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:32,352] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:32,353] INFO [src.utils:19] 29
[2025-10-22 23:59:32,353] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 54/6000 [03:09<5:59:33,  3.63s/it]                                                   {'loss': 0.2684, 'grad_norm': 18.767024993896484, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}
  1%|          | 54/6000 [03:09<5:59:33,  3.63s/it][2025-10-22 23:59:32,716] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:32,717] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:33,066] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:33,066] INFO [src.utils:19] 29
[2025-10-22 23:59:33,066] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:33,174] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:33,174] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:33,387] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:33,387] INFO [src.utils:19] 29
[2025-10-22 23:59:33,388] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:33,461] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:33,461] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:33,671] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:33,671] INFO [src.utils:19] 29
[2025-10-22 23:59:33,672] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:33,749] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:33,749] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:33,959] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:33,959] INFO [src.utils:19] 29
[2025-10-22 23:59:33,960] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:34,067] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:34,068] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:34,285] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:34,285] INFO [src.utils:19] 29
[2025-10-22 23:59:34,286] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:34,547] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:34,548] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:34,763] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:34,764] INFO [src.utils:19] 29
[2025-10-22 23:59:34,764] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:35,036] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:35,036] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:35,250] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:35,250] INFO [src.utils:19] 29
[2025-10-22 23:59:35,250] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:35,492] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:35,493] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:35,707] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:35,707] INFO [src.utils:19] 29
[2025-10-22 23:59:35,708] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 55/6000 [03:12<5:52:30,  3.56s/it]                                                   {'loss': 0.3347, 'grad_norm': 24.542888641357422, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.01}
  1%|          | 55/6000 [03:12<5:52:30,  3.56s/it][2025-10-22 23:59:36,080] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:36,082] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:36,414] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:36,414] INFO [src.utils:19] 29
[2025-10-22 23:59:36,414] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:36,490] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:36,490] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:36,701] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:36,701] INFO [src.utils:19] 29
[2025-10-22 23:59:36,702] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:36,786] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:36,787] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:36,996] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:36,996] INFO [src.utils:19] 29
[2025-10-22 23:59:36,997] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:37,100] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:37,100] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:37,309] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:37,309] INFO [src.utils:19] 29
[2025-10-22 23:59:37,310] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:37,399] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:37,400] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:37,614] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:37,615] INFO [src.utils:19] 29
[2025-10-22 23:59:37,615] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:37,848] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:37,849] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:38,062] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:38,063] INFO [src.utils:19] 29
[2025-10-22 23:59:38,063] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:38,391] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:38,392] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:38,612] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:38,612] INFO [src.utils:19] 29
[2025-10-22 23:59:38,613] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:38,879] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:38,880] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:39,094] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:39,094] INFO [src.utils:19] 29
[2025-10-22 23:59:39,094] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 56/6000 [03:15<5:46:05,  3.49s/it]                                                   {'loss': 0.1272, 'grad_norm': 17.534704208374023, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}
  1%|          | 56/6000 [03:15<5:46:05,  3.49s/it][2025-10-22 23:59:39,457] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:39,458] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:39,769] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:39,769] INFO [src.utils:19] 29
[2025-10-22 23:59:39,770] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:39,886] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:39,887] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:40,098] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:40,098] INFO [src.utils:19] 29
[2025-10-22 23:59:40,099] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:40,176] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:40,177] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:40,385] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:40,386] INFO [src.utils:19] 29
[2025-10-22 23:59:40,386] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:40,464] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:40,465] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:40,678] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:40,678] INFO [src.utils:19] 29
[2025-10-22 23:59:40,678] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:40,796] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:40,796] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:41,013] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:41,013] INFO [src.utils:19] 29
[2025-10-22 23:59:41,014] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:41,300] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:41,301] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:41,518] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:41,518] INFO [src.utils:19] 29
[2025-10-22 23:59:41,518] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:41,797] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:41,797] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:42,011] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:42,012] INFO [src.utils:19] 29
[2025-10-22 23:59:42,012] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:42,255] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:42,256] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:42,469] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:42,470] INFO [src.utils:19] 29
[2025-10-22 23:59:42,470] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 57/6000 [03:19<5:43:45,  3.47s/it]                                                   {'loss': 0.2552, 'grad_norm': 15.977436065673828, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.01}
  1%|          | 57/6000 [03:19<5:43:45,  3.47s/it][2025-10-22 23:59:42,860] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:42,861] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:43,168] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:43,168] INFO [src.utils:19] 29
[2025-10-22 23:59:43,169] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:43,227] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:43,228] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:43,449] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:43,449] INFO [src.utils:19] 29
[2025-10-22 23:59:43,450] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:43,539] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:43,539] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:43,751] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:43,752] INFO [src.utils:19] 29
[2025-10-22 23:59:43,752] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:43,877] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:43,878] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:44,091] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:44,091] INFO [src.utils:19] 29
[2025-10-22 23:59:44,091] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:44,195] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:44,195] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:44,421] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:44,422] INFO [src.utils:19] 29
[2025-10-22 23:59:44,422] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:44,650] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:44,651] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:44,875] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:44,875] INFO [src.utils:19] 29
[2025-10-22 23:59:44,875] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-22 23:59:45,165] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:45,166] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:45,383] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:45,383] INFO [src.utils:19] 29
[2025-10-22 23:59:45,384] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:45,668] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:45,669] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-22 23:59:45,884] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:45,885] INFO [src.utils:19] 29
[2025-10-22 23:59:45,885] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|          | 58/6000 [03:22<5:40:58,  3.44s/it]                                                   {'loss': 0.3543, 'grad_norm': 39.897220611572266, 'learning_rate': 2.9e-05, 'epoch': 0.01}
  1%|          | 58/6000 [03:22<5:40:58,  3.44s/it][2025-10-22 23:59:46,234] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:46,235] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:46,519] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:46,520] INFO [src.utils:19] 29
[2025-10-22 23:59:46,520] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:46,608] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:46,608] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:46,826] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:46,826] INFO [src.utils:19] 29
[2025-10-22 23:59:46,827] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:46,904] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:46,905] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:47,122] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:47,122] INFO [src.utils:19] 29
[2025-10-22 23:59:47,123] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:47,210] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:47,210] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:47,425] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:47,425] INFO [src.utils:19] 29
[2025-10-22 23:59:47,425] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:47,531] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:47,532] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:47,752] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:47,753] INFO [src.utils:19] 29
[2025-10-22 23:59:47,753] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:48,004] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:48,005] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:48,221] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:48,222] INFO [src.utils:19] 29
[2025-10-22 23:59:48,222] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:48,496] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:48,496] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:48,711] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:48,712] INFO [src.utils:19] 29
[2025-10-22 23:59:48,712] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:48,969] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:48,970] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:49,184] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:49,185] INFO [src.utils:19] 29
[2025-10-22 23:59:49,185] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 59/6000 [03:25<5:36:34,  3.40s/it]                                                   {'loss': 0.3383, 'grad_norm': 44.65935134887695, 'learning_rate': 2.95e-05, 'epoch': 0.01}
  1%|          | 59/6000 [03:25<5:36:34,  3.40s/it][2025-10-22 23:59:49,543] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:49,543] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:49,888] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:49,889] INFO [src.utils:19] 29
[2025-10-22 23:59:49,889] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:49,994] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:49,995] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:50,208] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:50,208] INFO [src.utils:19] 29
[2025-10-22 23:59:50,209] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:50,285] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:50,286] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:50,496] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:50,497] INFO [src.utils:19] 29
[2025-10-22 23:59:50,497] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:50,572] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:50,572] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:50,781] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:50,782] INFO [src.utils:19] 29
[2025-10-22 23:59:50,782] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:50,891] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:50,892] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:51,110] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:51,110] INFO [src.utils:19] 29
[2025-10-22 23:59:51,111] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:51,386] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:51,387] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:51,608] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:51,608] INFO [src.utils:19] 29
[2025-10-22 23:59:51,609] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-22 23:59:51,871] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:51,871] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:52,085] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:52,086] INFO [src.utils:19] 29
[2025-10-22 23:59:52,086] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:52,328] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:52,329] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:52,547] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:52,548] INFO [src.utils:19] 29
[2025-10-22 23:59:52,548] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 60/6000 [03:29<5:37:28,  3.41s/it]                                                   {'loss': 0.3834, 'grad_norm': 23.44429588317871, 'learning_rate': 3e-05, 'epoch': 0.01}
  1%|          | 60/6000 [03:29<5:37:28,  3.41s/it][2025-10-22 23:59:52,937] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:52,938] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:53,228] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:53,228] INFO [src.utils:19] 29
[2025-10-22 23:59:53,228] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:53,285] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:53,286] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:53,485] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:53,485] INFO [src.utils:19] 29
[2025-10-22 23:59:53,486] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:53,601] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:53,602] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:53,811] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:53,812] INFO [src.utils:19] 29
[2025-10-22 23:59:53,812] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:53,936] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:53,937] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:54,147] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:54,147] INFO [src.utils:19] 29
[2025-10-22 23:59:54,148] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:54,223] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:54,223] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:54,424] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:54,424] INFO [src.utils:19] 29
[2025-10-22 23:59:54,425] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:54,646] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:54,646] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:54,848] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:54,849] INFO [src.utils:19] 29
[2025-10-22 23:59:54,849] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-22 23:59:55,194] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:55,194] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:55,415] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:55,416] INFO [src.utils:19] 29
[2025-10-22 23:59:55,417] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:55,704] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:55,705] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-22 23:59:55,921] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:55,921] INFO [src.utils:19] 29
[2025-10-22 23:59:55,922] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 61/6000 [03:32<5:34:22,  3.38s/it]                                                   {'loss': 0.2132, 'grad_norm': 22.92473793029785, 'learning_rate': 3.05e-05, 'epoch': 0.01}
  1%|          | 61/6000 [03:32<5:34:22,  3.38s/it][2025-10-22 23:59:56,330] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:56,331] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:56,667] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:56,668] INFO [src.utils:19] 29
[2025-10-22 23:59:56,668] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:56,757] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:56,758] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:56,978] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:56,978] INFO [src.utils:19] 29
[2025-10-22 23:59:56,979] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:56,992] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:56,993] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:57,213] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:57,213] INFO [src.utils:19] 29
[2025-10-22 23:59:57,214] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:57,320] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:57,320] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:57,541] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:57,542] INFO [src.utils:19] 29
[2025-10-22 23:59:57,542] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:57,699] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:57,700] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:57,923] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:57,923] INFO [src.utils:19] 29
[2025-10-22 23:59:57,924] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:58,183] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:58,184] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:58,409] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:58,409] INFO [src.utils:19] 29
[2025-10-22 23:59:58,410] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-22 23:59:58,620] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:58,620] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:58,850] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:58,851] INFO [src.utils:19] 29
[2025-10-22 23:59:58,851] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:59,126] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:59,127] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-22 23:59:59,350] INFO [src.utils:19] OUTPUTS:
[2025-10-22 23:59:59,350] INFO [src.utils:19] 29
[2025-10-22 23:59:59,351] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 62/6000 [03:36<5:37:27,  3.41s/it]                                                   {'loss': 0.1496, 'grad_norm': 11.017739295959473, 'learning_rate': 3.1e-05, 'epoch': 0.01}
  1%|          | 62/6000 [03:36<5:37:27,  3.41s/it][2025-10-22 23:59:59,727] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-22 23:59:59,728] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:00,034] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:00,034] INFO [src.utils:19] 29
[2025-10-23 00:00:00,035] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:00,092] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:00,093] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:00,309] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:00,310] INFO [src.utils:19] 29
[2025-10-23 00:00:00,310] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:00,417] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:00,417] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:00,628] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:00,629] INFO [src.utils:19] 29
[2025-10-23 00:00:00,629] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:00,754] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:00,754] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:00,964] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:00,965] INFO [src.utils:19] 29
[2025-10-23 00:00:00,965] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:01,036] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:01,037] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:01,251] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:01,251] INFO [src.utils:19] 29
[2025-10-23 00:00:01,252] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:01,487] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:01,487] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:01,707] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:01,708] INFO [src.utils:19] 29
[2025-10-23 00:00:01,708] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:02,134] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:02,135] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:02,350] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:02,351] INFO [src.utils:19] 29
[2025-10-23 00:00:02,351] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:02,643] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:02,644] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:02,858] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:02,859] INFO [src.utils:19] 29
[2025-10-23 00:00:02,859] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 63/6000 [03:39<5:39:25,  3.43s/it]                                                   {'loss': 0.0877, 'grad_norm': 6.24924373626709, 'learning_rate': 3.15e-05, 'epoch': 0.01}
  1%|          | 63/6000 [03:39<5:39:25,  3.43s/it][2025-10-23 00:00:03,219] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:03,220] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:03,557] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:03,557] INFO [src.utils:19] 29
[2025-10-23 00:00:03,558] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:03,646] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:03,647] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:03,863] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:03,864] INFO [src.utils:19] 29
[2025-10-23 00:00:03,864] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:03,954] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:03,955] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:04,169] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:04,170] INFO [src.utils:19] 29
[2025-10-23 00:00:04,170] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:04,256] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:04,257] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:04,469] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:04,469] INFO [src.utils:19] 29
[2025-10-23 00:00:04,470] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:04,556] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:04,557] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:04,773] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:04,774] INFO [src.utils:19] 29
[2025-10-23 00:00:04,774] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:05,028] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:05,029] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:05,244] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:05,245] INFO [src.utils:19] 29
[2025-10-23 00:00:05,245] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:05,550] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:05,551] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:05,767] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:05,768] INFO [src.utils:19] 29
[2025-10-23 00:00:05,768] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:06,019] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:06,020] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:06,236] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:06,237] INFO [src.utils:19] 29
[2025-10-23 00:00:06,237] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 64/6000 [03:43<5:37:31,  3.41s/it]                                                   {'loss': 0.06, 'grad_norm': 7.148139476776123, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.01}
  1%|          | 64/6000 [03:43<5:37:31,  3.41s/it][2025-10-23 00:00:06,593] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:06,594] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:06,933] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:06,933] INFO [src.utils:19] 29
[2025-10-23 00:00:06,934] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:07,013] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:07,014] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:07,226] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:07,227] INFO [src.utils:19] 29
[2025-10-23 00:00:07,227] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:07,313] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:07,314] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:07,525] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:07,526] INFO [src.utils:19] 29
[2025-10-23 00:00:07,526] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:07,634] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:07,634] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:07,851] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:07,851] INFO [src.utils:19] 29
[2025-10-23 00:00:07,852] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:07,939] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:07,940] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:08,156] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:08,156] INFO [src.utils:19] 29
[2025-10-23 00:00:08,157] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:08,393] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:08,394] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:08,609] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:08,609] INFO [src.utils:19] 29
[2025-10-23 00:00:08,610] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:08,885] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:08,886] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:09,100] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:09,101] INFO [src.utils:19] 29
[2025-10-23 00:00:09,101] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:09,370] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:09,371] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:09,585] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:09,585] INFO [src.utils:19] 29
[2025-10-23 00:00:09,586] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 65/6000 [03:46<5:35:24,  3.39s/it]                                                   {'loss': 0.148, 'grad_norm': 11.123710632324219, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.01}
  1%|          | 65/6000 [03:46<5:35:24,  3.39s/it][2025-10-23 00:00:09,965] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:09,966] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:10,311] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:10,311] INFO [src.utils:19] 29
[2025-10-23 00:00:10,312] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:10,425] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:10,425] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:10,691] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:10,692] INFO [src.utils:19] 29
[2025-10-23 00:00:10,692] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:10,770] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:10,770] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:11,000] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:11,001] INFO [src.utils:19] 29
[2025-10-23 00:00:11,001] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:11,088] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:11,088] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:11,314] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:11,315] INFO [src.utils:19] 29
[2025-10-23 00:00:11,315] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:11,443] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:11,443] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:11,711] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:11,712] INFO [src.utils:19] 29
[2025-10-23 00:00:11,712] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:12,076] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:12,077] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:12,347] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:12,347] INFO [src.utils:19] 29
[2025-10-23 00:00:12,348] INFO [src.utils:19] torch.Size([8, 209, 1536])
[2025-10-23 00:00:12,687] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:12,688] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:12,919] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:12,919] INFO [src.utils:19] 29
[2025-10-23 00:00:12,920] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:13,185] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:13,186] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:13,418] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:13,418] INFO [src.utils:19] 29
[2025-10-23 00:00:13,418] INFO [src.utils:19] torch.Size([8, 168, 1536])
  1%|          | 66/6000 [03:50<5:49:10,  3.53s/it]                                                   {'loss': 0.1962, 'grad_norm': 18.126070022583008, 'learning_rate': 3.3e-05, 'epoch': 0.01}
  1%|          | 66/6000 [03:50<5:49:10,  3.53s/it][2025-10-23 00:00:13,703] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:13,704] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:14,009] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:14,009] INFO [src.utils:19] 29
[2025-10-23 00:00:14,010] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:14,114] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:14,114] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:14,327] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:14,328] INFO [src.utils:19] 29
[2025-10-23 00:00:14,328] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:14,485] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:14,486] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:14,708] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:14,708] INFO [src.utils:19] 29
[2025-10-23 00:00:14,709] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:14,784] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:14,785] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:15,007] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:15,008] INFO [src.utils:19] 29
[2025-10-23 00:00:15,008] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:15,023] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:15,023] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:15,245] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:15,245] INFO [src.utils:19] 29
[2025-10-23 00:00:15,245] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:15,527] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:15,528] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:15,742] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:15,742] INFO [src.utils:19] 29
[2025-10-23 00:00:15,743] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:16,135] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:16,136] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:16,366] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:16,367] INFO [src.utils:19] 29
[2025-10-23 00:00:16,367] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:16,613] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:16,614] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:16,838] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:16,839] INFO [src.utils:19] 29
[2025-10-23 00:00:16,839] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 67/6000 [03:53<5:45:05,  3.49s/it]                                                   {'loss': 0.2477, 'grad_norm': 22.141752243041992, 'learning_rate': 3.35e-05, 'epoch': 0.01}
  1%|          | 67/6000 [03:53<5:45:05,  3.49s/it][2025-10-23 00:00:17,177] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:17,179] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:17,473] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:17,474] INFO [src.utils:19] 29
[2025-10-23 00:00:17,474] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:17,550] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:17,550] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:17,762] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:17,763] INFO [src.utils:19] 29
[2025-10-23 00:00:17,763] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:17,850] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:17,850] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:18,062] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:18,062] INFO [src.utils:19] 29
[2025-10-23 00:00:18,063] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:18,169] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:18,170] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:18,380] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:18,381] INFO [src.utils:19] 29
[2025-10-23 00:00:18,381] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:18,468] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:18,468] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:18,682] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:18,683] INFO [src.utils:19] 29
[2025-10-23 00:00:18,683] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:18,933] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:18,933] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:19,147] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:19,148] INFO [src.utils:19] 29
[2025-10-23 00:00:19,148] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:19,427] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:19,428] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:19,644] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:19,645] INFO [src.utils:19] 29
[2025-10-23 00:00:19,645] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:19,919] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:19,919] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:20,135] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:20,136] INFO [src.utils:19] 29
[2025-10-23 00:00:20,136] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 68/6000 [03:56<5:39:09,  3.43s/it]                                                   {'loss': 0.1727, 'grad_norm': 23.292922973632812, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.01}
  1%|          | 68/6000 [03:56<5:39:09,  3.43s/it][2025-10-23 00:00:20,482] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:20,482] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:20,776] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:20,776] INFO [src.utils:19] 29
[2025-10-23 00:00:20,776] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:20,863] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:20,864] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:21,076] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:21,076] INFO [src.utils:19] 29
[2025-10-23 00:00:21,076] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:21,162] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:21,163] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:21,389] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:21,389] INFO [src.utils:19] 29
[2025-10-23 00:00:21,390] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:21,491] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:21,492] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:21,711] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:21,712] INFO [src.utils:19] 29
[2025-10-23 00:00:21,712] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:21,803] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:21,804] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:22,024] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:22,025] INFO [src.utils:19] 29
[2025-10-23 00:00:22,025] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:22,276] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:22,277] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:22,496] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:22,497] INFO [src.utils:19] 29
[2025-10-23 00:00:22,497] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:22,804] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:22,805] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:23,030] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:23,031] INFO [src.utils:19] 29
[2025-10-23 00:00:23,031] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:23,308] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:23,309] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:23,535] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:23,536] INFO [src.utils:19] 29
[2025-10-23 00:00:23,536] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 69/6000 [04:00<5:37:59,  3.42s/it]                                                   {'loss': 0.3285, 'grad_norm': 21.392545700073242, 'learning_rate': 3.45e-05, 'epoch': 0.01}
  1%|          | 69/6000 [04:00<5:37:59,  3.42s/it][2025-10-23 00:00:23,871] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:23,872] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:24,163] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:24,164] INFO [src.utils:19] 29
[2025-10-23 00:00:24,164] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:24,248] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:24,249] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:24,478] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:24,479] INFO [src.utils:19] 29
[2025-10-23 00:00:24,479] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:24,573] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:24,574] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:24,794] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:24,795] INFO [src.utils:19] 29
[2025-10-23 00:00:24,795] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:24,915] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:24,916] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:25,135] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:25,136] INFO [src.utils:19] 29
[2025-10-23 00:00:25,136] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:25,230] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:25,231] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:25,470] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:25,470] INFO [src.utils:19] 29
[2025-10-23 00:00:25,471] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:25,733] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:25,734] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:25,972] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:25,973] INFO [src.utils:19] 29
[2025-10-23 00:00:25,973] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:26,259] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:26,260] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:26,743] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:26,743] INFO [src.utils:19] 29
[2025-10-23 00:00:26,744] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:27,039] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:27,040] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:27,268] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:27,269] INFO [src.utils:19] 29
[2025-10-23 00:00:27,269] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|          | 70/6000 [04:04<5:47:12,  3.51s/it]                                                   {'loss': 0.121, 'grad_norm': 13.320552825927734, 'learning_rate': 3.5e-05, 'epoch': 0.01}
  1%|          | 70/6000 [04:04<5:47:12,  3.51s/it][2025-10-23 00:00:27,596] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:27,598] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:27,954] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:27,955] INFO [src.utils:19] 29
[2025-10-23 00:00:27,955] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:28,081] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:28,081] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:28,297] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:28,297] INFO [src.utils:19] 29
[2025-10-23 00:00:28,298] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:28,420] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:28,420] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:28,630] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:28,630] INFO [src.utils:19] 29
[2025-10-23 00:00:28,631] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:28,687] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:28,688] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:28,896] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:28,897] INFO [src.utils:19] 29
[2025-10-23 00:00:28,897] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:28,955] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:28,955] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:29,169] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:29,169] INFO [src.utils:19] 29
[2025-10-23 00:00:29,170] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:29,465] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:29,466] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:29,678] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:29,679] INFO [src.utils:19] 29
[2025-10-23 00:00:29,679] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:29,997] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:29,998] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:30,212] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:30,213] INFO [src.utils:19] 29
[2025-10-23 00:00:30,213] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:30,433] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:30,434] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:30,647] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:30,648] INFO [src.utils:19] 29
[2025-10-23 00:00:30,648] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|          | 71/6000 [04:07<5:43:17,  3.47s/it]                                                   {'loss': 0.0252, 'grad_norm': 2.9750027656555176, 'learning_rate': 3.55e-05, 'epoch': 0.01}
  1%|          | 71/6000 [04:07<5:43:17,  3.47s/it][2025-10-23 00:00:30,990] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:30,991] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:31,323] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:31,324] INFO [src.utils:19] 29
[2025-10-23 00:00:31,325] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:31,435] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:31,436] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:31,703] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:31,704] INFO [src.utils:19] 29
[2025-10-23 00:00:31,704] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:31,792] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:31,793] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:32,017] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:32,018] INFO [src.utils:19] 29
[2025-10-23 00:00:32,018] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:32,110] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:32,111] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:32,332] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:32,332] INFO [src.utils:19] 29
[2025-10-23 00:00:32,333] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:32,438] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:32,439] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:32,710] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:32,711] INFO [src.utils:19] 29
[2025-10-23 00:00:32,711] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:33,077] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:33,078] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:33,350] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:33,350] INFO [src.utils:19] 29
[2025-10-23 00:00:33,350] INFO [src.utils:19] torch.Size([8, 218, 1536])
[2025-10-23 00:00:33,705] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:33,705] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:33,930] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:33,931] INFO [src.utils:19] 29
[2025-10-23 00:00:33,931] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:34,195] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:34,196] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:00:34,422] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:34,423] INFO [src.utils:19] 29
[2025-10-23 00:00:34,423] INFO [src.utils:19] torch.Size([8, 159, 1536])
  1%|          | 72/6000 [04:11<5:52:19,  3.57s/it]                                                   {'loss': 0.2005, 'grad_norm': 16.968767166137695, 'learning_rate': 3.6e-05, 'epoch': 0.01}
  1%|          | 72/6000 [04:11<5:52:19,  3.57s/it][2025-10-23 00:00:34,748] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:34,750] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:35,056] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:35,056] INFO [src.utils:19] 29
[2025-10-23 00:00:35,056] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:35,126] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:35,127] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:35,338] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:35,339] INFO [src.utils:19] 29
[2025-10-23 00:00:35,339] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:35,458] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:35,458] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:35,688] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:35,688] INFO [src.utils:19] 29
[2025-10-23 00:00:35,688] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:35,811] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:35,811] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:36,040] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:36,040] INFO [src.utils:19] 29
[2025-10-23 00:00:36,040] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:36,122] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:36,122] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:36,336] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:36,337] INFO [src.utils:19] 29
[2025-10-23 00:00:36,337] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:36,574] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:36,574] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:36,789] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:36,789] INFO [src.utils:19] 29
[2025-10-23 00:00:36,790] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:37,106] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:37,106] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:37,339] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:37,340] INFO [src.utils:19] 29
[2025-10-23 00:00:37,340] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:37,645] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:37,645] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:00:37,878] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:37,879] INFO [src.utils:19] 29
[2025-10-23 00:00:37,879] INFO [src.utils:19] torch.Size([8, 168, 1536])
  1%|          | 73/6000 [04:14<5:49:10,  3.53s/it]                                                   {'loss': 0.256, 'grad_norm': 23.450519561767578, 'learning_rate': 3.65e-05, 'epoch': 0.01}
  1%|          | 73/6000 [04:14<5:49:10,  3.53s/it][2025-10-23 00:00:38,234] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:38,235] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:38,533] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:38,533] INFO [src.utils:19] 29
[2025-10-23 00:00:38,533] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:38,603] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:38,603] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:38,816] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:38,816] INFO [src.utils:19] 29
[2025-10-23 00:00:38,816] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:38,894] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:38,894] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:39,107] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:39,108] INFO [src.utils:19] 29
[2025-10-23 00:00:39,108] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:39,212] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:39,213] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:39,425] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:39,426] INFO [src.utils:19] 29
[2025-10-23 00:00:39,426] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:39,533] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:39,533] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:39,755] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:39,756] INFO [src.utils:19] 29
[2025-10-23 00:00:39,756] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:39,986] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:39,987] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:40,201] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:40,202] INFO [src.utils:19] 29
[2025-10-23 00:00:40,202] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:40,472] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:40,472] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:40,688] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:40,689] INFO [src.utils:19] 29
[2025-10-23 00:00:40,689] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:40,969] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:40,970] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:41,190] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:41,190] INFO [src.utils:19] 29
[2025-10-23 00:00:41,191] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|          | 74/6000 [04:17<5:42:32,  3.47s/it]                                                   {'loss': 0.2143, 'grad_norm': 15.622066497802734, 'learning_rate': 3.7e-05, 'epoch': 0.01}
  1%|          | 74/6000 [04:17<5:42:32,  3.47s/it][2025-10-23 00:00:41,542] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:41,543] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:41,894] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:41,894] INFO [src.utils:19] 29
[2025-10-23 00:00:41,895] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:41,984] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:41,984] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:42,198] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:42,198] INFO [src.utils:19] 29
[2025-10-23 00:00:42,199] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:42,323] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:42,323] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:42,535] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:42,535] INFO [src.utils:19] 29
[2025-10-23 00:00:42,535] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:42,619] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:42,620] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:42,828] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:42,829] INFO [src.utils:19] 29
[2025-10-23 00:00:42,829] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:42,889] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:42,890] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:43,104] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:43,104] INFO [src.utils:19] 29
[2025-10-23 00:00:43,105] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:43,366] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:43,367] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:43,581] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:43,582] INFO [src.utils:19] 29
[2025-10-23 00:00:43,582] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:43,897] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:43,897] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:44,113] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:44,113] INFO [src.utils:19] 29
[2025-10-23 00:00:44,114] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:44,366] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:44,367] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:44,581] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:44,581] INFO [src.utils:19] 29
[2025-10-23 00:00:44,582] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 75/6000 [04:21<5:40:08,  3.44s/it]                                                   {'loss': 0.0725, 'grad_norm': 6.8202128410339355, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.01}
  1%|â–         | 75/6000 [04:21<5:40:08,  3.44s/it][2025-10-23 00:00:44,943] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:44,945] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:45,257] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:45,258] INFO [src.utils:19] 29
[2025-10-23 00:00:45,259] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:45,343] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:45,343] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:45,556] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:45,556] INFO [src.utils:19] 29
[2025-10-23 00:00:45,556] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:45,640] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:45,641] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:45,867] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:45,867] INFO [src.utils:19] 29
[2025-10-23 00:00:45,868] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:45,957] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:45,958] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:46,180] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:46,180] INFO [src.utils:19] 29
[2025-10-23 00:00:46,181] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:46,309] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:46,310] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:46,524] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:46,525] INFO [src.utils:19] 29
[2025-10-23 00:00:46,525] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:46,770] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:46,771] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:46,986] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:46,987] INFO [src.utils:19] 29
[2025-10-23 00:00:46,987] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:47,280] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:47,281] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:47,510] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:47,511] INFO [src.utils:19] 29
[2025-10-23 00:00:47,511] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:47,773] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:47,774] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:00:47,999] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:47,999] INFO [src.utils:19] 29
[2025-10-23 00:00:48,000] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|â–         | 76/6000 [04:24<5:41:11,  3.46s/it]                                                   {'loss': 0.2319, 'grad_norm': 44.61885452270508, 'learning_rate': 3.8e-05, 'epoch': 0.01}
  1%|â–         | 76/6000 [04:24<5:41:11,  3.46s/it][2025-10-23 00:00:48,412] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:48,413] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:48,738] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:48,739] INFO [src.utils:19] 29
[2025-10-23 00:00:48,739] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:48,875] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:48,876] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:49,107] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:49,107] INFO [src.utils:19] 29
[2025-10-23 00:00:49,108] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:49,198] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:49,198] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:49,414] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:49,414] INFO [src.utils:19] 29
[2025-10-23 00:00:49,415] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:49,472] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:49,472] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:49,685] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:49,685] INFO [src.utils:19] 29
[2025-10-23 00:00:49,686] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:49,776] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:49,776] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:50,011] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:50,012] INFO [src.utils:19] 29
[2025-10-23 00:00:50,012] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:50,327] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:50,328] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:50,563] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:50,563] INFO [src.utils:19] 29
[2025-10-23 00:00:50,564] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:00:50,847] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:50,847] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:51,062] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:51,063] INFO [src.utils:19] 29
[2025-10-23 00:00:51,063] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:51,287] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:51,288] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:51,502] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:51,502] INFO [src.utils:19] 29
[2025-10-23 00:00:51,502] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 77/6000 [04:28<5:40:22,  3.45s/it]                                                   {'loss': 0.2685, 'grad_norm': 25.332006454467773, 'learning_rate': 3.85e-05, 'epoch': 0.01}
  1%|â–         | 77/6000 [04:28<5:40:22,  3.45s/it][2025-10-23 00:00:51,836] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:51,838] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:52,174] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:52,174] INFO [src.utils:19] 29
[2025-10-23 00:00:52,175] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:52,285] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:52,286] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:52,565] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:52,566] INFO [src.utils:19] 29
[2025-10-23 00:00:52,566] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:52,677] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:52,678] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:52,888] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:52,888] INFO [src.utils:19] 29
[2025-10-23 00:00:52,889] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:52,966] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:52,967] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:53,173] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:53,174] INFO [src.utils:19] 29
[2025-10-23 00:00:53,174] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:53,265] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:53,266] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:53,548] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:53,549] INFO [src.utils:19] 29
[2025-10-23 00:00:53,549] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:53,933] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:53,934] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:54,220] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:54,221] INFO [src.utils:19] 29
[2025-10-23 00:00:54,221] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:00:54,616] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:54,616] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:54,834] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:54,835] INFO [src.utils:19] 29
[2025-10-23 00:00:54,835] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:55,094] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:55,095] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:55,313] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:55,313] INFO [src.utils:19] 29
[2025-10-23 00:00:55,314] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 78/6000 [04:32<5:51:08,  3.56s/it]                                                   {'loss': 0.0444, 'grad_norm': 12.250953674316406, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 78/6000 [04:32<5:51:08,  3.56s/it][2025-10-23 00:00:55,674] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:55,675] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:55,967] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:55,968] INFO [src.utils:19] 29
[2025-10-23 00:00:55,968] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:56,047] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:56,048] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:56,267] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:56,268] INFO [src.utils:19] 29
[2025-10-23 00:00:56,268] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:56,347] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:56,347] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:56,560] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:56,560] INFO [src.utils:19] 29
[2025-10-23 00:00:56,561] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:56,667] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:56,668] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:56,883] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:56,884] INFO [src.utils:19] 29
[2025-10-23 00:00:56,884] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:57,002] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:57,003] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:57,229] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:57,230] INFO [src.utils:19] 29
[2025-10-23 00:00:57,230] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:57,471] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:57,472] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:57,694] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:57,695] INFO [src.utils:19] 29
[2025-10-23 00:00:57,695] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:00:57,966] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:57,967] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:58,183] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:58,184] INFO [src.utils:19] 29
[2025-10-23 00:00:58,184] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:58,459] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:58,459] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:00:58,676] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:58,676] INFO [src.utils:19] 29
[2025-10-23 00:00:58,677] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|â–         | 79/6000 [04:35<5:45:42,  3.50s/it]                                                   {'loss': 0.2464, 'grad_norm': 30.442138671875, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.01}
  1%|â–         | 79/6000 [04:35<5:45:42,  3.50s/it][2025-10-23 00:00:59,064] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:59,066] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:59,403] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:59,403] INFO [src.utils:19] 29
[2025-10-23 00:00:59,404] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:59,491] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:59,492] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:59,705] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:59,705] INFO [src.utils:19] 29
[2025-10-23 00:00:59,706] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:00:59,763] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:00:59,763] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:00:59,977] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:00:59,977] INFO [src.utils:19] 29
[2025-10-23 00:00:59,977] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:00,065] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:00,066] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:00,277] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:00,278] INFO [src.utils:19] 29
[2025-10-23 00:01:00,278] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:00,403] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:00,404] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:00,621] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:00,622] INFO [src.utils:19] 29
[2025-10-23 00:01:00,622] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:00,875] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:00,876] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:01,097] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:01,098] INFO [src.utils:19] 29
[2025-10-23 00:01:01,098] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:01,348] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:01,349] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:01,565] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:01,565] INFO [src.utils:19] 29
[2025-10-23 00:01:01,566] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:01,819] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:01,820] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:02,036] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:02,037] INFO [src.utils:19] 29
[2025-10-23 00:01:02,037] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 80/6000 [04:38<5:43:02,  3.48s/it]                                                   {'loss': 0.1533, 'grad_norm': 18.22411346435547, 'learning_rate': 4e-05, 'epoch': 0.01}
  1%|â–         | 80/6000 [04:38<5:43:02,  3.48s/it][2025-10-23 00:01:02,481] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:02,483] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:02,850] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:02,850] INFO [src.utils:19] 29
[2025-10-23 00:01:02,850] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:02,910] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:02,911] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:03,126] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:03,127] INFO [src.utils:19] 29
[2025-10-23 00:01:03,127] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:03,185] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:03,199] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:03,410] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:03,411] INFO [src.utils:19] 29
[2025-10-23 00:01:03,411] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:03,541] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:03,542] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:03,752] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:03,753] INFO [src.utils:19] 29
[2025-10-23 00:01:03,753] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:03,877] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:03,878] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:04,096] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:04,096] INFO [src.utils:19] 29
[2025-10-23 00:01:04,097] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:04,322] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:04,323] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:04,540] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:04,541] INFO [src.utils:19] 29
[2025-10-23 00:01:04,541] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:04,808] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:04,809] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:05,023] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:05,023] INFO [src.utils:19] 29
[2025-10-23 00:01:05,024] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:05,311] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:05,313] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:05,531] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:05,532] INFO [src.utils:19] 29
[2025-10-23 00:01:05,532] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 81/6000 [04:42<5:41:27,  3.46s/it]                                                   {'loss': 0.0194, 'grad_norm': 3.5515341758728027, 'learning_rate': 4.05e-05, 'epoch': 0.01}
  1%|â–         | 81/6000 [04:42<5:41:27,  3.46s/it][2025-10-23 00:01:05,861] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:05,862] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:06,189] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:06,190] INFO [src.utils:19] 29
[2025-10-23 00:01:06,190] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:06,277] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:06,277] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:06,479] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:06,480] INFO [src.utils:19] 29
[2025-10-23 00:01:06,480] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:06,596] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:06,597] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:06,807] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:06,808] INFO [src.utils:19] 29
[2025-10-23 00:01:06,808] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:06,897] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:06,898] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:07,109] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:07,109] INFO [src.utils:19] 29
[2025-10-23 00:01:07,110] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:07,186] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:07,186] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:07,391] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:07,391] INFO [src.utils:19] 29
[2025-10-23 00:01:07,392] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:07,647] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:07,648] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:07,853] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:07,853] INFO [src.utils:19] 29
[2025-10-23 00:01:07,854] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:08,301] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:08,302] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:08,520] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:08,521] INFO [src.utils:19] 29
[2025-10-23 00:01:08,521] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:08,775] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:08,775] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:08,993] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:08,994] INFO [src.utils:19] 29
[2025-10-23 00:01:08,994] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 82/6000 [04:45<5:41:37,  3.46s/it]                                                   {'loss': 0.1949, 'grad_norm': 15.27376937866211, 'learning_rate': 4.1e-05, 'epoch': 0.01}
  1%|â–         | 82/6000 [04:45<5:41:37,  3.46s/it][2025-10-23 00:01:09,368] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:09,368] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:09,675] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:09,675] INFO [src.utils:19] 29
[2025-10-23 00:01:09,676] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:09,799] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:09,800] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:10,012] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:10,013] INFO [src.utils:19] 29
[2025-10-23 00:01:10,013] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:10,090] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:10,091] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:10,302] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:10,302] INFO [src.utils:19] 29
[2025-10-23 00:01:10,303] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:10,361] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:10,362] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:10,572] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:10,572] INFO [src.utils:19] 29
[2025-10-23 00:01:10,573] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:10,716] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:10,716] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:10,939] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:10,939] INFO [src.utils:19] 29
[2025-10-23 00:01:10,939] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:11,237] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:11,238] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:11,456] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:11,456] INFO [src.utils:19] 29
[2025-10-23 00:01:11,457] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:11,731] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:11,732] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:11,946] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:11,947] INFO [src.utils:19] 29
[2025-10-23 00:01:11,947] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:12,181] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:12,182] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:12,398] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:12,398] INFO [src.utils:19] 29
[2025-10-23 00:01:12,398] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 83/6000 [04:49<5:41:39,  3.46s/it]                                                   {'loss': 0.1171, 'grad_norm': 21.853721618652344, 'learning_rate': 4.15e-05, 'epoch': 0.01}
  1%|â–         | 83/6000 [04:49<5:41:39,  3.46s/it][2025-10-23 00:01:12,800] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:12,801] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:13,086] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:13,087] INFO [src.utils:19] 29
[2025-10-23 00:01:13,087] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:13,176] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:13,176] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:13,407] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:13,408] INFO [src.utils:19] 29
[2025-10-23 00:01:13,408] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:13,496] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:13,497] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:13,718] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:13,719] INFO [src.utils:19] 29
[2025-10-23 00:01:13,719] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:13,838] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:13,839] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:14,057] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:14,058] INFO [src.utils:19] 29
[2025-10-23 00:01:14,058] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:14,146] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:14,146] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:14,379] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:14,380] INFO [src.utils:19] 29
[2025-10-23 00:01:14,380] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:14,650] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:14,651] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:14,890] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:14,891] INFO [src.utils:19] 29
[2025-10-23 00:01:14,891] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:01:15,173] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:15,174] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:15,399] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:15,399] INFO [src.utils:19] 29
[2025-10-23 00:01:15,400] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:15,685] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:15,685] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:15,909] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:15,910] INFO [src.utils:19] 29
[2025-10-23 00:01:15,910] INFO [src.utils:19] torch.Size([8, 150, 1536])
  1%|â–         | 84/6000 [04:52<5:40:51,  3.46s/it]                                                   {'loss': 0.1316, 'grad_norm': 15.972555160522461, 'learning_rate': 4.2e-05, 'epoch': 0.01}
  1%|â–         | 84/6000 [04:52<5:40:51,  3.46s/it][2025-10-23 00:01:16,274] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:16,275] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:16,617] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:16,617] INFO [src.utils:19] 29
[2025-10-23 00:01:16,618] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:16,730] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:16,731] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:17,016] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:17,016] INFO [src.utils:19] 29
[2025-10-23 00:01:17,017] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:17,100] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:17,101] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:17,314] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:17,315] INFO [src.utils:19] 29
[2025-10-23 00:01:17,315] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:17,392] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:17,393] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:17,600] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:17,600] INFO [src.utils:19] 29
[2025-10-23 00:01:17,600] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:17,729] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:17,729] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:18,015] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:18,016] INFO [src.utils:19] 29
[2025-10-23 00:01:18,016] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:18,377] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:18,378] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:18,663] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:18,663] INFO [src.utils:19] 29
[2025-10-23 00:01:18,664] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:01:19,002] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:19,003] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:19,217] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:19,217] INFO [src.utils:19] 29
[2025-10-23 00:01:19,217] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:19,464] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:19,465] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:19,680] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:19,680] INFO [src.utils:19] 29
[2025-10-23 00:01:19,680] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 85/6000 [04:56<5:50:51,  3.56s/it]                                                   {'loss': 0.1546, 'grad_norm': 15.543719291687012, 'learning_rate': 4.25e-05, 'epoch': 0.01}
  1%|â–         | 85/6000 [04:56<5:50:51,  3.56s/it][2025-10-23 00:01:20,041] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:20,043] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:20,331] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:20,332] INFO [src.utils:19] 29
[2025-10-23 00:01:20,332] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:20,385] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:20,386] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:20,586] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:20,586] INFO [src.utils:19] 29
[2025-10-23 00:01:20,587] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:20,694] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:20,695] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:20,917] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:20,918] INFO [src.utils:19] 29
[2025-10-23 00:01:20,918] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:21,069] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:21,070] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:21,293] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:21,293] INFO [src.utils:19] 29
[2025-10-23 00:01:21,294] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:21,370] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:21,371] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:21,573] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:21,573] INFO [src.utils:19] 29
[2025-10-23 00:01:21,574] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:21,787] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:21,788] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:21,989] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:21,989] INFO [src.utils:19] 29
[2025-10-23 00:01:21,990] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:01:22,363] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:22,364] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:22,592] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:22,593] INFO [src.utils:19] 29
[2025-10-23 00:01:22,593] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:22,920] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:22,921] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:23,148] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:23,148] INFO [src.utils:19] 29
[2025-10-23 00:01:23,149] INFO [src.utils:19] torch.Size([8, 159, 1536])
  1%|â–         | 86/6000 [04:59<5:47:33,  3.53s/it]                                                   {'loss': 0.2177, 'grad_norm': 16.341407775878906, 'learning_rate': 4.3e-05, 'epoch': 0.01}
  1%|â–         | 86/6000 [04:59<5:47:33,  3.53s/it][2025-10-23 00:01:23,503] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:23,504] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:23,786] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:23,787] INFO [src.utils:19] 29
[2025-10-23 00:01:23,787] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:23,896] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:23,897] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:24,109] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:24,109] INFO [src.utils:19] 29
[2025-10-23 00:01:24,110] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:24,186] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:24,186] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:24,396] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:24,397] INFO [src.utils:19] 29
[2025-10-23 00:01:24,397] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:24,470] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:24,471] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:24,681] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:24,681] INFO [src.utils:19] 29
[2025-10-23 00:01:24,682] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:24,789] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:24,790] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:25,004] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:25,005] INFO [src.utils:19] 29
[2025-10-23 00:01:25,005] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:25,277] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:25,278] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:25,493] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:25,494] INFO [src.utils:19] 29
[2025-10-23 00:01:25,494] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:25,762] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:25,762] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:25,976] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:25,977] INFO [src.utils:19] 29
[2025-10-23 00:01:25,977] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:26,217] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:26,218] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:26,435] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:26,436] INFO [src.utils:19] 29
[2025-10-23 00:01:26,436] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 87/6000 [05:03<5:40:32,  3.46s/it]                                                   {'loss': 0.0015, 'grad_norm': 0.2434806525707245, 'learning_rate': 4.35e-05, 'epoch': 0.01}
  1%|â–         | 87/6000 [05:03<5:40:32,  3.46s/it][2025-10-23 00:01:26,839] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:26,840] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:27,138] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:27,138] INFO [src.utils:19] 29
[2025-10-23 00:01:27,139] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:27,198] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:27,199] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:27,411] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:27,411] INFO [src.utils:19] 29
[2025-10-23 00:01:27,411] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:27,463] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:27,463] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:27,673] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:27,673] INFO [src.utils:19] 29
[2025-10-23 00:01:27,674] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:27,795] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:27,796] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:28,007] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:28,007] INFO [src.utils:19] 29
[2025-10-23 00:01:28,008] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:28,145] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:28,146] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:28,359] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:28,360] INFO [src.utils:19] 29
[2025-10-23 00:01:28,360] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:28,577] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:28,578] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:28,795] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:28,796] INFO [src.utils:19] 29
[2025-10-23 00:01:28,796] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:29,045] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:29,046] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:29,261] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:29,262] INFO [src.utils:19] 29
[2025-10-23 00:01:29,262] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:29,545] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:29,546] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:29,759] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:29,760] INFO [src.utils:19] 29
[2025-10-23 00:01:29,760] INFO [src.utils:19] torch.Size([8, 132, 1536])
  1%|â–         | 88/6000 [05:06<5:36:14,  3.41s/it]                                                   {'loss': 0.1099, 'grad_norm': 9.271184921264648, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 88/6000 [05:06<5:36:14,  3.41s/it][2025-10-23 00:01:30,073] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:30,073] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:30,370] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:30,371] INFO [src.utils:19] 29
[2025-10-23 00:01:30,371] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:30,446] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:30,447] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:30,649] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:30,649] INFO [src.utils:19] 29
[2025-10-23 00:01:30,649] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:30,774] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:30,774] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:30,987] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:30,987] INFO [src.utils:19] 29
[2025-10-23 00:01:30,987] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:31,092] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:31,092] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:31,305] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:31,306] INFO [src.utils:19] 29
[2025-10-23 00:01:31,306] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:31,365] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:31,365] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:31,569] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:31,570] INFO [src.utils:19] 29
[2025-10-23 00:01:31,570] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:31,817] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:31,818] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:32,027] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:32,028] INFO [src.utils:19] 29
[2025-10-23 00:01:32,028] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:01:32,401] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:32,402] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:32,621] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:32,622] INFO [src.utils:19] 29
[2025-10-23 00:01:32,622] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:32,896] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:32,896] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:01:33,112] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:33,113] INFO [src.utils:19] 29
[2025-10-23 00:01:33,113] INFO [src.utils:19] torch.Size([8, 141, 1536])
  1%|â–         | 89/6000 [05:09<5:34:30,  3.40s/it]                                                   {'loss': 0.0693, 'grad_norm': 15.150273323059082, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}
  1%|â–         | 89/6000 [05:09<5:34:30,  3.40s/it][2025-10-23 00:01:33,460] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:33,461] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:33,771] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:33,772] INFO [src.utils:19] 29
[2025-10-23 00:01:33,772] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:33,846] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:33,847] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:34,063] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:34,064] INFO [src.utils:19] 29
[2025-10-23 00:01:34,064] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:34,142] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:34,143] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:34,365] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:34,366] INFO [src.utils:19] 29
[2025-10-23 00:01:34,366] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:34,485] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:34,486] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:34,707] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:34,708] INFO [src.utils:19] 29
[2025-10-23 00:01:34,708] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:34,816] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:34,817] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:35,032] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:35,033] INFO [src.utils:19] 29
[2025-10-23 00:01:35,033] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:35,267] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:35,267] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:35,486] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:35,487] INFO [src.utils:19] 29
[2025-10-23 00:01:35,487] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:35,758] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:35,758] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:35,982] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:35,983] INFO [src.utils:19] 29
[2025-10-23 00:01:35,983] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:36,269] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:36,270] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:36,493] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:36,494] INFO [src.utils:19] 29
[2025-10-23 00:01:36,494] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 90/6000 [05:13<5:36:35,  3.42s/it]                                                   {'loss': 0.0572, 'grad_norm': 9.49010944366455, 'learning_rate': 4.5e-05, 'epoch': 0.01}
  2%|â–         | 90/6000 [05:13<5:36:35,  3.42s/it][2025-10-23 00:01:36,900] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:36,901] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:37,214] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:37,214] INFO [src.utils:19] 29
[2025-10-23 00:01:37,215] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:37,319] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:37,320] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:37,533] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:37,534] INFO [src.utils:19] 29
[2025-10-23 00:01:37,534] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:37,623] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:37,624] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:37,847] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:37,847] INFO [src.utils:19] 29
[2025-10-23 00:01:37,848] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:37,927] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:37,927] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:38,151] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:38,151] INFO [src.utils:19] 29
[2025-10-23 00:01:38,152] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:38,229] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:38,230] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:38,446] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:38,447] INFO [src.utils:19] 29
[2025-10-23 00:01:38,447] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:38,710] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:38,711] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:38,927] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:38,928] INFO [src.utils:19] 29
[2025-10-23 00:01:38,928] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:39,209] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:39,210] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:39,436] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:39,437] INFO [src.utils:19] 29
[2025-10-23 00:01:39,437] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:39,689] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:39,690] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:01:39,917] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:39,917] INFO [src.utils:19] 29
[2025-10-23 00:01:39,918] INFO [src.utils:19] torch.Size([8, 159, 1536])
  2%|â–         | 91/6000 [05:16<5:34:08,  3.39s/it]                                                   {'loss': 0.2664, 'grad_norm': 24.512537002563477, 'learning_rate': 4.55e-05, 'epoch': 0.02}
  2%|â–         | 91/6000 [05:16<5:34:08,  3.39s/it][2025-10-23 00:01:40,252] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:40,253] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:40,611] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:40,612] INFO [src.utils:19] 29
[2025-10-23 00:01:40,612] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:40,728] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:40,729] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:41,005] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:41,006] INFO [src.utils:19] 29
[2025-10-23 00:01:41,006] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:41,118] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:41,119] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:41,331] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:41,331] INFO [src.utils:19] 29
[2025-10-23 00:01:41,332] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:41,412] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:41,412] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:41,621] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:41,622] INFO [src.utils:19] 29
[2025-10-23 00:01:41,622] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:41,711] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:41,712] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:41,994] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:41,994] INFO [src.utils:19] 29
[2025-10-23 00:01:41,995] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:42,375] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:42,376] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:42,657] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:42,658] INFO [src.utils:19] 29
[2025-10-23 00:01:42,658] INFO [src.utils:19] torch.Size([8, 227, 1536])
[2025-10-23 00:01:43,044] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:43,045] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:43,259] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:43,259] INFO [src.utils:19] 29
[2025-10-23 00:01:43,260] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:43,502] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:43,503] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:43,717] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:43,718] INFO [src.utils:19] 29
[2025-10-23 00:01:43,718] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 92/6000 [05:20<5:46:11,  3.52s/it]                                                   {'loss': 0.1735, 'grad_norm': 10.73491382598877, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.02}
  2%|â–         | 92/6000 [05:20<5:46:11,  3.52s/it][2025-10-23 00:01:44,040] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:44,042] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:44,353] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:44,354] INFO [src.utils:19] 29
[2025-10-23 00:01:44,354] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:44,431] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:44,431] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:44,646] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:44,647] INFO [src.utils:19] 29
[2025-10-23 00:01:44,647] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:44,774] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:44,775] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:44,986] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:44,986] INFO [src.utils:19] 29
[2025-10-23 00:01:44,987] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:45,095] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:45,095] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:45,306] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:45,307] INFO [src.utils:19] 29
[2025-10-23 00:01:45,307] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:45,414] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:45,414] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:45,630] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:45,630] INFO [src.utils:19] 29
[2025-10-23 00:01:45,631] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:45,864] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:45,865] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:46,080] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:46,080] INFO [src.utils:19] 29
[2025-10-23 00:01:46,081] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:46,599] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:46,599] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:46,816] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:46,816] INFO [src.utils:19] 29
[2025-10-23 00:01:46,816] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:47,097] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:47,097] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:47,312] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:47,312] INFO [src.utils:19] 29
[2025-10-23 00:01:47,313] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 93/6000 [05:24<5:48:37,  3.54s/it]                                                   {'loss': 0.0502, 'grad_norm': 7.050439834594727, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.02}
  2%|â–         | 93/6000 [05:24<5:48:37,  3.54s/it][2025-10-23 00:01:47,650] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:47,651] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:47,941] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:47,942] INFO [src.utils:19] 29
[2025-10-23 00:01:47,942] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:48,049] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:48,049] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:48,261] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:48,261] INFO [src.utils:19] 29
[2025-10-23 00:01:48,262] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:48,350] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:48,350] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:48,571] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:48,571] INFO [src.utils:19] 29
[2025-10-23 00:01:48,572] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:48,656] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:48,656] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:48,876] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:48,876] INFO [src.utils:19] 29
[2025-10-23 00:01:48,876] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:48,966] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:48,967] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:49,181] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:49,182] INFO [src.utils:19] 29
[2025-10-23 00:01:49,182] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:49,455] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:49,456] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:49,671] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:49,671] INFO [src.utils:19] 29
[2025-10-23 00:01:49,671] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:49,949] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:49,950] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:50,178] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:50,178] INFO [src.utils:19] 29
[2025-10-23 00:01:50,179] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:50,430] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:50,431] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:50,656] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:50,656] INFO [src.utils:19] 29
[2025-10-23 00:01:50,657] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 94/6000 [05:27<5:42:41,  3.48s/it]                                                   {'loss': 0.1062, 'grad_norm': 15.064213752746582, 'learning_rate': 4.7e-05, 'epoch': 0.02}
  2%|â–         | 94/6000 [05:27<5:42:41,  3.48s/it][2025-10-23 00:01:50,968] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:50,969] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:51,237] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:51,237] INFO [src.utils:19] 29
[2025-10-23 00:01:51,238] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:51,329] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:51,330] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:51,542] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:51,542] INFO [src.utils:19] 29
[2025-10-23 00:01:51,543] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:51,668] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:51,669] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:51,889] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:51,889] INFO [src.utils:19] 29
[2025-10-23 00:01:51,890] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:51,976] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:51,976] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:52,200] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:52,200] INFO [src.utils:19] 29
[2025-10-23 00:01:52,201] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:52,268] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:52,269] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:52,484] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:52,484] INFO [src.utils:19] 29
[2025-10-23 00:01:52,485] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:52,737] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:52,738] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:52,954] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:52,955] INFO [src.utils:19] 29
[2025-10-23 00:01:52,955] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:53,287] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:53,288] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:53,511] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:53,512] INFO [src.utils:19] 29
[2025-10-23 00:01:53,512] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:53,769] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:53,769] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:53,993] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:53,994] INFO [src.utils:19] 29
[2025-10-23 00:01:53,994] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 95/6000 [05:30<5:38:26,  3.44s/it]                                                   {'loss': 0.0326, 'grad_norm': 7.839328289031982, 'learning_rate': 4.75e-05, 'epoch': 0.02}
  2%|â–         | 95/6000 [05:30<5:38:26,  3.44s/it][2025-10-23 00:01:54,369] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:54,370] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:54,669] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:54,670] INFO [src.utils:19] 29
[2025-10-23 00:01:54,670] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:54,746] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:54,746] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:54,957] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:54,958] INFO [src.utils:19] 29
[2025-10-23 00:01:54,958] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:55,017] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:55,017] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:55,239] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:55,239] INFO [src.utils:19] 29
[2025-10-23 00:01:55,240] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:55,360] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:55,361] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:55,580] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:55,580] INFO [src.utils:19] 29
[2025-10-23 00:01:55,581] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:55,710] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:55,711] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:55,927] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:55,928] INFO [src.utils:19] 29
[2025-10-23 00:01:55,928] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:56,174] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:56,175] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:56,392] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:56,392] INFO [src.utils:19] 29
[2025-10-23 00:01:56,393] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:01:56,638] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:56,639] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:56,862] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:56,862] INFO [src.utils:19] 29
[2025-10-23 00:01:56,863] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:57,151] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:57,151] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:01:57,374] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:57,375] INFO [src.utils:19] 29
[2025-10-23 00:01:57,375] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 96/6000 [05:34<5:36:24,  3.42s/it]                                                   {'loss': 0.2745, 'grad_norm': 12.644973754882812, 'learning_rate': 4.8e-05, 'epoch': 0.02}
  2%|â–         | 96/6000 [05:34<5:36:24,  3.42s/it][2025-10-23 00:01:57,736] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:57,737] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:58,022] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:58,023] INFO [src.utils:19] 29
[2025-10-23 00:01:58,023] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:58,130] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:58,130] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:58,357] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:58,357] INFO [src.utils:19] 29
[2025-10-23 00:01:58,358] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:58,434] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:58,435] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:58,645] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:58,645] INFO [src.utils:19] 29
[2025-10-23 00:01:58,646] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:58,716] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:58,716] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:58,924] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:58,925] INFO [src.utils:19] 29
[2025-10-23 00:01:58,925] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:01:59,045] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:59,045] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:59,269] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:59,270] INFO [src.utils:19] 29
[2025-10-23 00:01:59,270] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:59,547] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:01:59,547] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:01:59,775] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:01:59,775] INFO [src.utils:19] 29
[2025-10-23 00:01:59,776] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:00,052] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:00,053] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:00,267] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:00,268] INFO [src.utils:19] 29
[2025-10-23 00:02:00,268] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:00,504] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:00,505] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:00,718] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:00,719] INFO [src.utils:19] 29
[2025-10-23 00:02:00,719] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 97/6000 [05:37<5:34:57,  3.40s/it]                                                   {'loss': 0.3704, 'grad_norm': 18.48926544189453, 'learning_rate': 4.85e-05, 'epoch': 0.02}
  2%|â–         | 97/6000 [05:37<5:34:57,  3.40s/it][2025-10-23 00:02:01,060] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:01,062] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:01,352] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:01,353] INFO [src.utils:19] 29
[2025-10-23 00:02:01,353] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:01,423] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:01,424] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:01,636] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:01,636] INFO [src.utils:19] 29
[2025-10-23 00:02:01,637] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:01,762] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:01,763] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:01,974] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:01,974] INFO [src.utils:19] 29
[2025-10-23 00:02:01,975] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:02,085] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:02,086] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:02,303] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:02,304] INFO [src.utils:19] 29
[2025-10-23 00:02:02,304] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:02,362] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:02,363] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:02,578] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:02,578] INFO [src.utils:19] 29
[2025-10-23 00:02:02,579] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:02,813] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:02,814] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:03,029] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:03,030] INFO [src.utils:19] 29
[2025-10-23 00:02:03,030] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:03,428] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:03,429] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:03,644] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:03,644] INFO [src.utils:19] 29
[2025-10-23 00:02:03,645] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:03,918] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:03,919] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:04,133] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:04,134] INFO [src.utils:19] 29
[2025-10-23 00:02:04,134] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 98/6000 [05:40<5:34:18,  3.40s/it]                                                   {'loss': 0.2232, 'grad_norm': 16.53838539123535, 'learning_rate': 4.9e-05, 'epoch': 0.02}
  2%|â–         | 98/6000 [05:40<5:34:18,  3.40s/it][2025-10-23 00:02:04,496] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:04,497] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:04,782] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:04,782] INFO [src.utils:19] 29
[2025-10-23 00:02:04,783] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:04,856] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:04,857] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:05,063] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:05,063] INFO [src.utils:19] 29
[2025-10-23 00:02:05,064] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:05,119] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:05,119] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:05,332] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:05,332] INFO [src.utils:19] 29
[2025-10-23 00:02:05,333] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:05,441] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:05,441] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:05,653] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:05,653] INFO [src.utils:19] 29
[2025-10-23 00:02:05,654] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:05,784] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:05,785] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:05,998] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:05,999] INFO [src.utils:19] 29
[2025-10-23 00:02:05,999] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:06,235] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:06,236] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:06,440] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:06,441] INFO [src.utils:19] 29
[2025-10-23 00:02:06,441] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:02:06,691] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:06,692] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:06,905] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:06,906] INFO [src.utils:19] 29
[2025-10-23 00:02:06,906] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:07,174] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:07,175] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:07,389] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:07,389] INFO [src.utils:19] 29
[2025-10-23 00:02:07,390] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 99/6000 [05:44<5:31:03,  3.37s/it]                                                   {'loss': 0.0873, 'grad_norm': 18.108638763427734, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}
  2%|â–         | 99/6000 [05:44<5:31:03,  3.37s/it][2025-10-23 00:02:07,774] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:07,776] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:08,062] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:08,063] INFO [src.utils:19] 29
[2025-10-23 00:02:08,063] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:08,154] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:08,155] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:08,367] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:08,368] INFO [src.utils:19] 29
[2025-10-23 00:02:08,368] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:08,446] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:08,447] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:08,656] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:08,657] INFO [src.utils:19] 29
[2025-10-23 00:02:08,657] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:08,742] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:08,743] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:08,952] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:08,953] INFO [src.utils:19] 29
[2025-10-23 00:02:08,953] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:09,059] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:09,060] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:09,277] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:09,277] INFO [src.utils:19] 29
[2025-10-23 00:02:09,278] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:09,531] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:09,532] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:09,749] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:09,750] INFO [src.utils:19] 29
[2025-10-23 00:02:09,750] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:10,026] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:10,026] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:10,243] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:10,243] INFO [src.utils:19] 29
[2025-10-23 00:02:10,243] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:10,492] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:10,493] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:10,709] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:10,710] INFO [src.utils:19] 29
[2025-10-23 00:02:10,710] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 100/6000 [05:47<5:28:52,  3.34s/it]                                                    {'loss': 0.5585, 'grad_norm': 24.93467140197754, 'learning_rate': 5e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [05:47<5:28:52,  3.34s/it][2025-10-23 00:02:10,946] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[2025-10-23 00:02:13,258] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:13,259] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:13,545] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:13,546] INFO [src.utils:19] 29
[2025-10-23 00:02:13,546] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:13,623] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:13,624] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:13,843] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:13,843] INFO [src.utils:19] 29
[2025-10-23 00:02:13,844] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:13,932] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:13,932] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:14,142] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:14,142] INFO [src.utils:19] 29
[2025-10-23 00:02:14,143] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:14,246] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:14,246] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:14,456] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:14,456] INFO [src.utils:19] 29
[2025-10-23 00:02:14,457] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:14,868] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:14,868] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:15,094] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:15,095] INFO [src.utils:19] 29
[2025-10-23 00:02:15,095] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:15,339] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:15,340] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:15,562] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:15,562] INFO [src.utils:19] 29
[2025-10-23 00:02:15,563] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:15,941] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:15,942] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:16,156] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:16,157] INFO [src.utils:19] 29
[2025-10-23 00:02:16,157] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:16,421] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:16,422] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:16,639] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:16,639] INFO [src.utils:19] 29
[2025-10-23 00:02:16,640] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 101/6000 [05:54<7:04:34,  4.32s/it]                                                    {'loss': 0.0949, 'grad_norm': 11.665372848510742, 'learning_rate': 4.9991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 101/6000 [05:54<7:04:34,  4.32s/it][2025-10-23 00:02:17,634] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:17,635] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:17,944] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:17,945] INFO [src.utils:19] 29
[2025-10-23 00:02:17,945] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:18,025] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:18,025] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:18,247] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:18,247] INFO [src.utils:19] 29
[2025-10-23 00:02:18,248] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:18,334] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:18,335] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:18,544] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:18,545] INFO [src.utils:19] 29
[2025-10-23 00:02:18,545] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:18,650] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:18,650] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:18,863] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:18,864] INFO [src.utils:19] 29
[2025-10-23 00:02:18,864] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:18,955] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:18,956] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:19,179] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:19,180] INFO [src.utils:19] 29
[2025-10-23 00:02:19,180] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:19,423] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:19,424] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:19,647] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:19,647] INFO [src.utils:19] 29
[2025-10-23 00:02:19,648] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:19,928] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:19,928] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:20,142] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:20,143] INFO [src.utils:19] 29
[2025-10-23 00:02:20,143] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:20,412] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:20,413] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:20,628] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:20,628] INFO [src.utils:19] 29
[2025-10-23 00:02:20,629] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 102/6000 [05:57<6:36:08,  4.03s/it]                                                    {'loss': 0.0641, 'grad_norm': 14.016359329223633, 'learning_rate': 4.998305084745763e-05, 'epoch': 0.02}
  2%|â–         | 102/6000 [05:57<6:36:08,  4.03s/it][2025-10-23 00:02:21,022] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:21,023] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:21,329] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:21,330] INFO [src.utils:19] 29
[2025-10-23 00:02:21,330] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:21,402] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:21,402] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:21,624] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:21,624] INFO [src.utils:19] 29
[2025-10-23 00:02:21,625] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:21,715] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:21,715] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:21,926] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:21,927] INFO [src.utils:19] 29
[2025-10-23 00:02:21,927] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:22,043] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:22,044] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:22,255] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:22,255] INFO [src.utils:19] 29
[2025-10-23 00:02:22,256] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:22,388] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:22,389] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:22,613] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:22,613] INFO [src.utils:19] 29
[2025-10-23 00:02:22,614] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:22,855] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:22,856] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:23,080] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:23,081] INFO [src.utils:19] 29
[2025-10-23 00:02:23,081] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:23,384] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:23,385] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:23,599] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:23,599] INFO [src.utils:19] 29
[2025-10-23 00:02:23,600] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:23,876] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:23,877] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:24,095] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:24,095] INFO [src.utils:19] 29
[2025-10-23 00:02:24,096] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 103/6000 [06:00<6:18:55,  3.86s/it]                                                    {'loss': 0.045, 'grad_norm': 5.284363269805908, 'learning_rate': 4.997457627118644e-05, 'epoch': 0.02}
  2%|â–         | 103/6000 [06:00<6:18:55,  3.86s/it][2025-10-23 00:02:24,483] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:24,484] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:24,803] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:24,804] INFO [src.utils:19] 29
[2025-10-23 00:02:24,804] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:24,894] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:24,895] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:25,132] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:25,133] INFO [src.utils:19] 29
[2025-10-23 00:02:25,133] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:25,209] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:25,209] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:25,429] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:25,429] INFO [src.utils:19] 29
[2025-10-23 00:02:25,429] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:25,517] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:25,518] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:25,738] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:25,738] INFO [src.utils:19] 29
[2025-10-23 00:02:25,738] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:25,861] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:25,861] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:26,102] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:26,103] INFO [src.utils:19] 29
[2025-10-23 00:02:26,103] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:26,390] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:26,391] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:26,632] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:26,633] INFO [src.utils:19] 29
[2025-10-23 00:02:26,633] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:02:26,917] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:26,918] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:27,144] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:27,145] INFO [src.utils:19] 29
[2025-10-23 00:02:27,145] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:27,405] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:27,406] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:27,629] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:27,629] INFO [src.utils:19] 29
[2025-10-23 00:02:27,630] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 104/6000 [06:04<6:12:12,  3.79s/it]                                                    {'loss': 0.1695, 'grad_norm': 15.507389068603516, 'learning_rate': 4.9966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 104/6000 [06:04<6:12:12,  3.79s/it][2025-10-23 00:02:28,062] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:28,063] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:28,359] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:28,360] INFO [src.utils:19] 29
[2025-10-23 00:02:28,360] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:28,482] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:28,482] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:28,711] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:28,712] INFO [src.utils:19] 29
[2025-10-23 00:02:28,712] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:28,823] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:28,823] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:29,043] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:29,044] INFO [src.utils:19] 29
[2025-10-23 00:02:29,044] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:29,120] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:29,121] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:29,344] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:29,345] INFO [src.utils:19] 29
[2025-10-23 00:02:29,345] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:29,425] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:29,426] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:29,655] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:29,655] INFO [src.utils:19] 29
[2025-10-23 00:02:29,656] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:29,952] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:29,953] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:30,184] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:30,184] INFO [src.utils:19] 29
[2025-10-23 00:02:30,184] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:02:30,483] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:30,484] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:30,709] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:30,710] INFO [src.utils:19] 29
[2025-10-23 00:02:30,710] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:30,957] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:30,957] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:31,182] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:31,183] INFO [src.utils:19] 29
[2025-10-23 00:02:31,183] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 105/6000 [06:07<6:02:40,  3.69s/it]                                                    {'loss': 0.194, 'grad_norm': 16.81595802307129, 'learning_rate': 4.9957627118644066e-05, 'epoch': 0.02}
  2%|â–         | 105/6000 [06:08<6:02:40,  3.69s/it][2025-10-23 00:02:31,565] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:31,566] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:31,871] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:31,872] INFO [src.utils:19] 29
[2025-10-23 00:02:31,872] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:31,931] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:31,931] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:32,145] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:32,145] INFO [src.utils:19] 29
[2025-10-23 00:02:32,146] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:32,222] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:32,222] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:32,432] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:32,432] INFO [src.utils:19] 29
[2025-10-23 00:02:32,433] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:32,563] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:32,563] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:32,772] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:32,773] INFO [src.utils:19] 29
[2025-10-23 00:02:32,773] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:32,970] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:32,970] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:33,186] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:33,187] INFO [src.utils:19] 29
[2025-10-23 00:02:33,187] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:33,417] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:33,417] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:33,632] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:33,633] INFO [src.utils:19] 29
[2025-10-23 00:02:33,633] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:33,939] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:33,940] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:34,154] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:34,154] INFO [src.utils:19] 29
[2025-10-23 00:02:34,155] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:34,464] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:34,464] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:34,679] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:34,680] INFO [src.utils:19] 29
[2025-10-23 00:02:34,680] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 106/6000 [06:11<5:58:28,  3.65s/it]                                                    {'loss': 0.0123, 'grad_norm': 1.9102281332015991, 'learning_rate': 4.9949152542372884e-05, 'epoch': 0.02}
  2%|â–         | 106/6000 [06:11<5:58:28,  3.65s/it][2025-10-23 00:02:35,131] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:35,132] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:35,476] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:35,476] INFO [src.utils:19] 29
[2025-10-23 00:02:35,476] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:35,599] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:35,600] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:35,812] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:35,813] INFO [src.utils:19] 29
[2025-10-23 00:02:35,813] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:35,870] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:35,870] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:36,080] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:36,080] INFO [src.utils:19] 29
[2025-10-23 00:02:36,080] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:36,137] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:36,138] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:36,346] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:36,347] INFO [src.utils:19] 29
[2025-10-23 00:02:36,347] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:36,471] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:36,471] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:36,686] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:36,686] INFO [src.utils:19] 29
[2025-10-23 00:02:36,687] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:36,983] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:36,983] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:37,205] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:37,205] INFO [src.utils:19] 29
[2025-10-23 00:02:37,206] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:37,448] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:37,449] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:37,668] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:37,668] INFO [src.utils:19] 29
[2025-10-23 00:02:37,669] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:37,898] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:37,899] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:38,113] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:38,114] INFO [src.utils:19] 29
[2025-10-23 00:02:38,114] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 107/6000 [06:14<5:52:04,  3.58s/it]                                                    {'loss': 0.0818, 'grad_norm': 6.560858726501465, 'learning_rate': 4.9940677966101695e-05, 'epoch': 0.02}
  2%|â–         | 107/6000 [06:14<5:52:04,  3.58s/it][2025-10-23 00:02:38,526] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:38,527] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:38,877] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:38,878] INFO [src.utils:19] 29
[2025-10-23 00:02:38,878] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:38,969] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:38,970] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:39,190] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:39,190] INFO [src.utils:19] 29
[2025-10-23 00:02:39,191] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:39,300] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:39,300] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:39,514] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:39,515] INFO [src.utils:19] 29
[2025-10-23 00:02:39,515] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:39,600] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:39,601] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:39,811] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:39,811] INFO [src.utils:19] 29
[2025-10-23 00:02:39,812] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:39,891] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:39,891] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:40,115] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:40,115] INFO [src.utils:19] 29
[2025-10-23 00:02:40,138] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:40,389] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:40,389] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:40,615] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:40,615] INFO [src.utils:19] 29
[2025-10-23 00:02:40,615] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:02:41,041] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:41,042] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:41,257] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:41,258] INFO [src.utils:19] 29
[2025-10-23 00:02:41,258] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:41,506] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:41,507] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:41,728] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:41,728] INFO [src.utils:19] 29
[2025-10-23 00:02:41,728] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 108/6000 [06:18<5:50:32,  3.57s/it]                                                    {'loss': 0.0966, 'grad_norm': 9.302449226379395, 'learning_rate': 4.993220338983051e-05, 'epoch': 0.02}
  2%|â–         | 108/6000 [06:18<5:50:32,  3.57s/it][2025-10-23 00:02:42,044] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:42,045] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:42,461] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:42,462] INFO [src.utils:19] 29
[2025-10-23 00:02:42,462] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:42,634] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:42,634] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:42,918] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:42,918] INFO [src.utils:19] 29
[2025-10-23 00:02:42,919] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:43,030] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:43,030] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:43,243] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:43,243] INFO [src.utils:19] 29
[2025-10-23 00:02:43,244] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:43,303] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:43,303] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:43,509] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:43,510] INFO [src.utils:19] 29
[2025-10-23 00:02:43,510] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:43,589] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:43,589] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:43,874] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:43,875] INFO [src.utils:19] 29
[2025-10-23 00:02:43,875] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:44,280] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:44,281] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:44,567] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:44,568] INFO [src.utils:19] 29
[2025-10-23 00:02:44,568] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:02:44,935] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:44,936] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:45,149] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:45,150] INFO [src.utils:19] 29
[2025-10-23 00:02:45,150] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:45,368] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:45,369] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:45,583] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:45,584] INFO [src.utils:19] 29
[2025-10-23 00:02:45,584] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 109/6000 [06:22<6:00:15,  3.67s/it]                                                    {'loss': 0.1096, 'grad_norm': 14.915289878845215, 'learning_rate': 4.9923728813559324e-05, 'epoch': 0.02}
  2%|â–         | 109/6000 [06:22<6:00:15,  3.67s/it][2025-10-23 00:02:45,960] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:45,961] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:46,304] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:46,304] INFO [src.utils:19] 29
[2025-10-23 00:02:46,305] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:46,448] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:46,449] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:46,662] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:46,663] INFO [src.utils:19] 29
[2025-10-23 00:02:46,663] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:46,767] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:46,768] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:46,989] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:46,990] INFO [src.utils:19] 29
[2025-10-23 00:02:46,990] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:47,044] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:47,044] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:47,263] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:47,263] INFO [src.utils:19] 29
[2025-10-23 00:02:47,264] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:47,344] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:47,345] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:47,559] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:47,559] INFO [src.utils:19] 29
[2025-10-23 00:02:47,560] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:47,860] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:47,861] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:48,076] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:48,076] INFO [src.utils:19] 29
[2025-10-23 00:02:48,076] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:48,411] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:48,411] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:48,635] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:48,636] INFO [src.utils:19] 29
[2025-10-23 00:02:48,636] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:48,857] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:48,857] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:49,082] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:49,082] INFO [src.utils:19] 29
[2025-10-23 00:02:49,082] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 110/6000 [06:25<5:53:51,  3.60s/it]                                                    {'loss': 0.0718, 'grad_norm': 9.668103218078613, 'learning_rate': 4.991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 110/6000 [06:25<5:53:51,  3.60s/it][2025-10-23 00:02:49,419] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:49,420] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:49,774] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:49,774] INFO [src.utils:19] 29
[2025-10-23 00:02:49,775] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:49,849] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:49,850] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:50,074] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:50,075] INFO [src.utils:19] 29
[2025-10-23 00:02:50,075] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:50,163] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:50,164] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:50,375] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:50,375] INFO [src.utils:19] 29
[2025-10-23 00:02:50,376] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:50,494] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:50,495] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:50,704] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:50,705] INFO [src.utils:19] 29
[2025-10-23 00:02:50,705] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:50,800] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:50,800] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:51,026] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:51,027] INFO [src.utils:19] 29
[2025-10-23 00:02:51,027] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:51,267] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:51,267] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:51,493] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:51,494] INFO [src.utils:19] 29
[2025-10-23 00:02:51,494] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:02:51,785] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:51,786] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:52,001] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:52,002] INFO [src.utils:19] 29
[2025-10-23 00:02:52,002] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:52,283] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:52,284] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:02:52,498] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:52,499] INFO [src.utils:19] 29
[2025-10-23 00:02:52,499] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 111/6000 [06:29<5:50:48,  3.57s/it]                                                    {'loss': 0.1599, 'grad_norm': 15.50662899017334, 'learning_rate': 4.990677966101695e-05, 'epoch': 0.02}
  2%|â–         | 111/6000 [06:29<5:50:48,  3.57s/it][2025-10-23 00:02:52,936] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:52,937] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:53,305] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:53,306] INFO [src.utils:19] 29
[2025-10-23 00:02:53,306] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:53,431] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:53,432] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:53,675] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:53,676] INFO [src.utils:19] 29
[2025-10-23 00:02:53,676] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:53,756] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:53,756] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:54,026] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:54,027] INFO [src.utils:19] 29
[2025-10-23 00:02:54,027] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:54,119] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:54,120] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:54,383] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:54,384] INFO [src.utils:19] 29
[2025-10-23 00:02:54,384] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:54,494] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:54,495] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:54,742] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:54,742] INFO [src.utils:19] 29
[2025-10-23 00:02:54,743] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:55,066] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:55,067] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:55,314] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:55,314] INFO [src.utils:19] 29
[2025-10-23 00:02:55,315] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:02:55,607] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:55,607] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:55,876] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:55,876] INFO [src.utils:19] 29
[2025-10-23 00:02:55,877] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:56,224] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:56,225] INFO [src.utils:19] torch.Size([8, 213, 1536])
[2025-10-23 00:02:56,495] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:56,496] INFO [src.utils:19] 29
[2025-10-23 00:02:56,496] INFO [src.utils:19] torch.Size([8, 213, 1536])
  2%|â–         | 112/6000 [06:33<6:03:10,  3.70s/it]                                                    {'loss': 0.1215, 'grad_norm': 10.865477561950684, 'learning_rate': 4.9898305084745765e-05, 'epoch': 0.02}
  2%|â–         | 112/6000 [06:33<6:03:10,  3.70s/it][2025-10-23 00:02:56,961] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:56,962] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:57,297] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:57,298] INFO [src.utils:19] 29
[2025-10-23 00:02:57,298] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:57,409] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:57,409] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:57,621] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:57,621] INFO [src.utils:19] 29
[2025-10-23 00:02:57,622] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:57,692] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:57,693] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:57,914] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:57,914] INFO [src.utils:19] 29
[2025-10-23 00:02:57,915] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:57,990] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:57,990] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:58,208] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:58,208] INFO [src.utils:19] 29
[2025-10-23 00:02:58,209] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:58,333] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:58,334] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:58,549] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:58,550] INFO [src.utils:19] 29
[2025-10-23 00:02:58,550] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:58,821] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:58,821] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:59,037] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:59,037] INFO [src.utils:19] 29
[2025-10-23 00:02:59,038] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:02:59,295] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:59,295] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:59,519] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:59,520] INFO [src.utils:19] 29
[2025-10-23 00:02:59,520] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:59,763] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:02:59,764] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:02:59,987] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:02:59,988] INFO [src.utils:19] 29
[2025-10-23 00:02:59,988] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 113/6000 [06:36<5:56:43,  3.64s/it]                                                    {'loss': 0.0233, 'grad_norm': 4.456442832946777, 'learning_rate': 4.9889830508474576e-05, 'epoch': 0.02}
  2%|â–         | 113/6000 [06:36<5:56:43,  3.64s/it][2025-10-23 00:03:00,399] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:00,401] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:00,729] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:00,729] INFO [src.utils:19] 29
[2025-10-23 00:03:00,729] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:00,838] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:00,839] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:01,064] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:01,064] INFO [src.utils:19] 29
[2025-10-23 00:03:01,065] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:01,154] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:01,155] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:01,378] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:01,379] INFO [src.utils:19] 29
[2025-10-23 00:03:01,379] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:01,457] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:01,458] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:01,680] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:01,681] INFO [src.utils:19] 29
[2025-10-23 00:03:01,681] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:01,769] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:01,770] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:01,993] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:01,994] INFO [src.utils:19] 29
[2025-10-23 00:03:01,994] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:02,275] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:02,275] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:02,500] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:02,501] INFO [src.utils:19] 29
[2025-10-23 00:03:02,501] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:02,784] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:02,785] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:03,013] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:03,014] INFO [src.utils:19] 29
[2025-10-23 00:03:03,014] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:03,269] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:03,270] INFO [src.utils:19] torch.Size([8, 159, 1536])
[2025-10-23 00:03:03,496] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:03,496] INFO [src.utils:19] 29
[2025-10-23 00:03:03,497] INFO [src.utils:19] torch.Size([8, 159, 1536])
  2%|â–         | 114/6000 [06:40<5:51:22,  3.58s/it]                                                    {'loss': 0.1364, 'grad_norm': 13.260273933410645, 'learning_rate': 4.9881355932203394e-05, 'epoch': 0.02}
  2%|â–         | 114/6000 [06:40<5:51:22,  3.58s/it][2025-10-23 00:03:03,847] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:03,848] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:04,172] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:04,173] INFO [src.utils:19] 29
[2025-10-23 00:03:04,173] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:04,223] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:04,224] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:04,445] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:04,446] INFO [src.utils:19] 29
[2025-10-23 00:03:04,446] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:04,569] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:04,569] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:04,779] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:04,780] INFO [src.utils:19] 29
[2025-10-23 00:03:04,780] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:04,918] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:04,919] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:05,128] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:05,129] INFO [src.utils:19] 29
[2025-10-23 00:03:05,129] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:05,189] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:05,190] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:05,414] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:05,414] INFO [src.utils:19] 29
[2025-10-23 00:03:05,414] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:05,647] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:05,647] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:05,872] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:05,873] INFO [src.utils:19] 29
[2025-10-23 00:03:05,873] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:03:06,209] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:06,209] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:06,423] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:06,424] INFO [src.utils:19] 29
[2025-10-23 00:03:06,424] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:06,725] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:06,726] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:06,946] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:06,946] INFO [src.utils:19] 29
[2025-10-23 00:03:06,947] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 115/6000 [06:43<5:46:55,  3.54s/it]                                                    {'loss': 0.0498, 'grad_norm': 8.01734447479248, 'learning_rate': 4.9872881355932206e-05, 'epoch': 0.02}
  2%|â–         | 115/6000 [06:43<5:46:55,  3.54s/it][2025-10-23 00:03:07,276] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:07,276] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:07,610] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:07,610] INFO [src.utils:19] 29
[2025-10-23 00:03:07,611] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:07,684] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:07,685] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:07,897] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:07,897] INFO [src.utils:19] 29
[2025-10-23 00:03:07,897] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:07,997] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:07,998] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:08,217] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:08,218] INFO [src.utils:19] 29
[2025-10-23 00:03:08,218] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:08,336] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:08,336] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:08,556] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:08,557] INFO [src.utils:19] 29
[2025-10-23 00:03:08,557] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:08,637] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:08,638] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:08,852] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:08,852] INFO [src.utils:19] 29
[2025-10-23 00:03:08,853] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:09,079] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:09,080] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:09,293] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:09,294] INFO [src.utils:19] 29
[2025-10-23 00:03:09,294] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:09,584] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:09,584] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:09,809] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:09,809] INFO [src.utils:19] 29
[2025-10-23 00:03:09,809] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:10,094] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:10,095] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:10,318] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:10,319] INFO [src.utils:19] 29
[2025-10-23 00:03:10,319] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 116/6000 [06:47<5:41:46,  3.49s/it]                                                    {'loss': 0.1177, 'grad_norm': 19.094253540039062, 'learning_rate': 4.9864406779661024e-05, 'epoch': 0.02}
  2%|â–         | 116/6000 [06:47<5:41:46,  3.49s/it][2025-10-23 00:03:10,710] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:10,711] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:11,049] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:11,049] INFO [src.utils:19] 29
[2025-10-23 00:03:11,049] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:11,172] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:11,172] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:11,402] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:11,403] INFO [src.utils:19] 29
[2025-10-23 00:03:11,403] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:11,417] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:11,418] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:11,628] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:11,628] INFO [src.utils:19] 29
[2025-10-23 00:03:11,628] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:11,701] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:11,701] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:11,909] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:11,910] INFO [src.utils:19] 29
[2025-10-23 00:03:11,910] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:12,063] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:12,063] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:12,299] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:12,300] INFO [src.utils:19] 29
[2025-10-23 00:03:12,300] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:12,605] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:12,606] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:12,839] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:12,840] INFO [src.utils:19] 29
[2025-10-23 00:03:12,840] INFO [src.utils:19] torch.Size([8, 173, 1536])
[2025-10-23 00:03:13,042] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:13,043] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:13,260] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:13,261] INFO [src.utils:19] 29
[2025-10-23 00:03:13,261] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:13,495] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:13,496] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:13,710] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:13,710] INFO [src.utils:19] 29
[2025-10-23 00:03:13,711] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 117/6000 [06:50<5:39:57,  3.47s/it]                                                    {'loss': 0.1684, 'grad_norm': 10.904306411743164, 'learning_rate': 4.9855932203389835e-05, 'epoch': 0.02}
  2%|â–         | 117/6000 [06:50<5:39:57,  3.47s/it][2025-10-23 00:03:14,055] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:14,056] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:14,405] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:14,406] INFO [src.utils:19] 29
[2025-10-23 00:03:14,406] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:14,545] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:14,546] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:14,785] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:14,786] INFO [src.utils:19] 29
[2025-10-23 00:03:14,786] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:14,938] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:14,939] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:15,216] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:15,217] INFO [src.utils:19] 29
[2025-10-23 00:03:15,217] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:15,280] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:15,281] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:15,554] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:15,554] INFO [src.utils:19] 29
[2025-10-23 00:03:15,555] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:15,612] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:15,613] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:15,853] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:15,854] INFO [src.utils:19] 29
[2025-10-23 00:03:15,854] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:16,180] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:16,180] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:16,423] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:16,424] INFO [src.utils:19] 29
[2025-10-23 00:03:16,424] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:16,779] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:16,779] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:17,061] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:17,062] INFO [src.utils:19] 29
[2025-10-23 00:03:17,062] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:17,402] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:17,402] INFO [src.utils:19] torch.Size([8, 240, 1536])
[2025-10-23 00:03:17,682] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:17,683] INFO [src.utils:19] 29
[2025-10-23 00:03:17,683] INFO [src.utils:19] torch.Size([8, 240, 1536])
  2%|â–         | 118/6000 [06:54<5:56:53,  3.64s/it]                                                    {'loss': 0.2023, 'grad_norm': 12.286163330078125, 'learning_rate': 4.9847457627118646e-05, 'epoch': 0.02}
  2%|â–         | 118/6000 [06:54<5:56:53,  3.64s/it][2025-10-23 00:03:18,139] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:18,140] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:18,477] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:18,477] INFO [src.utils:19] 29
[2025-10-23 00:03:18,478] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:18,553] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:18,554] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:18,765] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:18,765] INFO [src.utils:19] 29
[2025-10-23 00:03:18,766] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:18,835] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:18,836] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:19,057] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:19,057] INFO [src.utils:19] 29
[2025-10-23 00:03:19,058] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:19,166] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:19,166] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:19,388] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:19,389] INFO [src.utils:19] 29
[2025-10-23 00:03:19,389] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:19,494] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:19,495] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:19,709] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:19,710] INFO [src.utils:19] 29
[2025-10-23 00:03:19,710] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:19,952] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:19,953] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:20,168] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:20,169] INFO [src.utils:19] 29
[2025-10-23 00:03:20,169] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:20,428] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:20,429] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:20,653] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:20,654] INFO [src.utils:19] 29
[2025-10-23 00:03:20,654] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:20,926] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:20,927] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:03:21,151] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:21,152] INFO [src.utils:19] 29
[2025-10-23 00:03:21,152] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 119/6000 [06:57<5:48:39,  3.56s/it]                                                    {'loss': 0.0288, 'grad_norm': 4.066336154937744, 'learning_rate': 4.983898305084746e-05, 'epoch': 0.02}
  2%|â–         | 119/6000 [06:57<5:48:39,  3.56s/it][2025-10-23 00:03:21,515] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:21,516] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:21,839] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:21,840] INFO [src.utils:19] 29
[2025-10-23 00:03:21,840] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:21,929] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:21,929] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:22,144] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:22,145] INFO [src.utils:19] 29
[2025-10-23 00:03:22,145] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:22,203] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:22,204] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:22,417] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:22,417] INFO [src.utils:19] 29
[2025-10-23 00:03:22,418] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:22,507] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:22,507] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:22,725] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:22,725] INFO [src.utils:19] 29
[2025-10-23 00:03:22,726] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:22,853] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:22,853] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:23,067] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:23,068] INFO [src.utils:19] 29
[2025-10-23 00:03:23,068] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:23,315] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:23,315] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:23,531] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:23,531] INFO [src.utils:19] 29
[2025-10-23 00:03:23,532] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:23,776] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:23,777] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:23,993] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:23,994] INFO [src.utils:19] 29
[2025-10-23 00:03:23,994] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:24,246] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:24,247] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:03:24,463] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:24,464] INFO [src.utils:19] 29
[2025-10-23 00:03:24,464] INFO [src.utils:19] torch.Size([8, 141, 1536])
  2%|â–         | 120/6000 [07:01<5:42:56,  3.50s/it]                                                    {'loss': 0.0967, 'grad_norm': 10.166827201843262, 'learning_rate': 4.9830508474576276e-05, 'epoch': 0.02}
  2%|â–         | 120/6000 [07:01<5:42:56,  3.50s/it][2025-10-23 00:03:24,859] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:24,861] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:25,162] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:25,163] INFO [src.utils:19] 29
[2025-10-23 00:03:25,163] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:25,285] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:25,286] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:25,487] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:25,488] INFO [src.utils:19] 29
[2025-10-23 00:03:25,488] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:25,557] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:25,557] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:25,770] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:25,771] INFO [src.utils:19] 29
[2025-10-23 00:03:25,771] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:25,829] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:25,830] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:26,039] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:26,040] INFO [src.utils:19] 29
[2025-10-23 00:03:26,040] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:26,169] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:26,169] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:26,372] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:26,373] INFO [src.utils:19] 29
[2025-10-23 00:03:26,373] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:26,650] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:26,651] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:26,854] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:26,855] INFO [src.utils:19] 29
[2025-10-23 00:03:26,855] INFO [src.utils:19] torch.Size([8, 119, 1536])
[2025-10-23 00:03:27,107] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:27,107] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:27,321] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:27,322] INFO [src.utils:19] 29
[2025-10-23 00:03:27,322] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:27,544] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:27,545] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:27,762] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:27,762] INFO [src.utils:19] 29
[2025-10-23 00:03:27,763] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 121/6000 [07:04<5:39:12,  3.46s/it]                                                    {'loss': 0.0104, 'grad_norm': 2.7681920528411865, 'learning_rate': 4.982203389830509e-05, 'epoch': 0.02}
  2%|â–         | 121/6000 [07:04<5:39:12,  3.46s/it][2025-10-23 00:03:28,251] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:28,252] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:28,551] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:28,552] INFO [src.utils:19] 29
[2025-10-23 00:03:28,552] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:28,641] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:28,642] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:28,885] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:28,885] INFO [src.utils:19] 29
[2025-10-23 00:03:28,886] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:28,963] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:28,964] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:29,174] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:29,175] INFO [src.utils:19] 29
[2025-10-23 00:03:29,175] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:29,261] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:29,262] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:29,477] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:29,477] INFO [src.utils:19] 29
[2025-10-23 00:03:29,477] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:29,596] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:29,597] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:29,837] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:29,837] INFO [src.utils:19] 29
[2025-10-23 00:03:29,837] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:30,118] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:30,119] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:30,360] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:30,360] INFO [src.utils:19] 29
[2025-10-23 00:03:30,360] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:03:30,641] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:30,642] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:30,856] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:30,856] INFO [src.utils:19] 29
[2025-10-23 00:03:30,857] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:31,121] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:31,122] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:31,337] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:31,337] INFO [src.utils:19] 29
[2025-10-23 00:03:31,338] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 122/6000 [07:08<5:41:05,  3.48s/it]                                                    {'loss': 0.0904, 'grad_norm': 6.993416786193848, 'learning_rate': 4.98135593220339e-05, 'epoch': 0.02}
  2%|â–         | 122/6000 [07:08<5:41:05,  3.48s/it][2025-10-23 00:03:31,792] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:31,792] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:32,123] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:32,123] INFO [src.utils:19] 29
[2025-10-23 00:03:32,124] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:32,197] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:32,198] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:32,418] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:32,419] INFO [src.utils:19] 29
[2025-10-23 00:03:32,419] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:32,477] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:32,477] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:32,686] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:32,686] INFO [src.utils:19] 29
[2025-10-23 00:03:32,687] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:32,791] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:32,791] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:33,001] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:33,002] INFO [src.utils:19] 29
[2025-10-23 00:03:33,002] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:33,128] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:33,129] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:33,352] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:33,353] INFO [src.utils:19] 29
[2025-10-23 00:03:33,353] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:33,597] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:33,597] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:33,819] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:33,820] INFO [src.utils:19] 29
[2025-10-23 00:03:33,820] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:03:34,074] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:34,075] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:34,289] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:34,290] INFO [src.utils:19] 29
[2025-10-23 00:03:34,290] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:34,569] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:34,570] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:34,783] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:34,784] INFO [src.utils:19] 29
[2025-10-23 00:03:34,784] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 123/6000 [07:11<5:37:40,  3.45s/it]                                                    {'loss': 0.0266, 'grad_norm': 4.524608612060547, 'learning_rate': 4.9805084745762716e-05, 'epoch': 0.02}
  2%|â–         | 123/6000 [07:11<5:37:40,  3.45s/it][2025-10-23 00:03:35,091] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:35,092] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:35,396] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:35,397] INFO [src.utils:19] 29
[2025-10-23 00:03:35,397] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:35,475] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:35,475] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:35,686] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:35,687] INFO [src.utils:19] 29
[2025-10-23 00:03:35,687] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:35,825] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:35,826] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:36,037] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:36,037] INFO [src.utils:19] 29
[2025-10-23 00:03:36,038] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:36,140] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:36,141] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:36,357] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:36,358] INFO [src.utils:19] 29
[2025-10-23 00:03:36,358] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:36,408] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:36,409] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:36,622] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:36,623] INFO [src.utils:19] 29
[2025-10-23 00:03:36,623] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:36,870] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:36,870] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:37,090] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:37,091] INFO [src.utils:19] 29
[2025-10-23 00:03:37,091] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:37,429] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:37,430] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:37,643] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:37,644] INFO [src.utils:19] 29
[2025-10-23 00:03:37,644] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:37,911] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:37,912] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:38,126] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:38,126] INFO [src.utils:19] 29
[2025-10-23 00:03:38,127] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 124/6000 [07:14<5:34:25,  3.41s/it]                                                    {'loss': 0.1234, 'grad_norm': 9.37347412109375, 'learning_rate': 4.979661016949153e-05, 'epoch': 0.02}
  2%|â–         | 124/6000 [07:14<5:34:25,  3.41s/it][2025-10-23 00:03:38,447] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:38,448] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:38,775] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:38,776] INFO [src.utils:19] 29
[2025-10-23 00:03:38,776] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:38,833] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:38,834] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:39,046] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:39,047] INFO [src.utils:19] 29
[2025-10-23 00:03:39,047] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:39,150] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:39,151] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:39,362] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:39,363] INFO [src.utils:19] 29
[2025-10-23 00:03:39,363] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:39,488] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:39,489] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:39,699] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:39,699] INFO [src.utils:19] 29
[2025-10-23 00:03:39,700] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:39,888] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:39,888] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:40,104] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:40,105] INFO [src.utils:19] 29
[2025-10-23 00:03:40,105] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:40,324] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:40,324] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:40,539] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:40,540] INFO [src.utils:19] 29
[2025-10-23 00:03:40,540] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:40,855] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:40,855] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:41,070] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:41,070] INFO [src.utils:19] 29
[2025-10-23 00:03:41,071] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:41,373] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:41,374] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:41,587] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:41,587] INFO [src.utils:19] 29
[2025-10-23 00:03:41,588] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 125/6000 [07:18<5:41:22,  3.49s/it]                                                    {'loss': 0.0832, 'grad_norm': 9.95560073852539, 'learning_rate': 4.978813559322034e-05, 'epoch': 0.02}
  2%|â–         | 125/6000 [07:18<5:41:22,  3.49s/it][2025-10-23 00:03:42,119] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:42,119] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:42,431] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:42,432] INFO [src.utils:19] 29
[2025-10-23 00:03:42,432] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:42,520] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:42,521] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:42,760] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:42,761] INFO [src.utils:19] 29
[2025-10-23 00:03:42,761] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:42,844] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:42,844] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:43,055] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:43,056] INFO [src.utils:19] 29
[2025-10-23 00:03:43,056] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:43,160] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:43,161] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:43,370] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:43,371] INFO [src.utils:19] 29
[2025-10-23 00:03:43,371] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:43,478] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:43,478] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:43,725] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:43,726] INFO [src.utils:19] 29
[2025-10-23 00:03:43,726] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:44,010] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:44,011] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:44,254] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:44,254] INFO [src.utils:19] 29
[2025-10-23 00:03:44,255] INFO [src.utils:19] torch.Size([8, 191, 1536])
[2025-10-23 00:03:44,540] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:44,541] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:44,754] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:44,755] INFO [src.utils:19] 29
[2025-10-23 00:03:44,755] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:45,021] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:45,022] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:45,236] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:45,237] INFO [src.utils:19] 29
[2025-10-23 00:03:45,237] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 126/6000 [07:22<5:40:34,  3.48s/it]                                                    {'loss': 0.1396, 'grad_norm': 14.779662132263184, 'learning_rate': 4.977966101694915e-05, 'epoch': 0.02}
  2%|â–         | 126/6000 [07:22<5:40:34,  3.48s/it][2025-10-23 00:03:45,552] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:45,553] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:45,857] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:45,857] INFO [src.utils:19] 29
[2025-10-23 00:03:45,858] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:45,946] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:45,946] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:46,158] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:46,159] INFO [src.utils:19] 29
[2025-10-23 00:03:46,159] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:46,298] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:46,298] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:46,512] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:46,512] INFO [src.utils:19] 29
[2025-10-23 00:03:46,512] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:46,598] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:46,598] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:46,809] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:46,810] INFO [src.utils:19] 29
[2025-10-23 00:03:46,810] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:46,910] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:46,910] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:47,124] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:47,125] INFO [src.utils:19] 29
[2025-10-23 00:03:47,125] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:47,379] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:47,379] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:47,595] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:47,596] INFO [src.utils:19] 29
[2025-10-23 00:03:47,596] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:48,129] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:48,130] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:48,347] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:48,347] INFO [src.utils:19] 29
[2025-10-23 00:03:48,348] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:48,590] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:48,591] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:48,806] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:48,807] INFO [src.utils:19] 29
[2025-10-23 00:03:48,807] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 127/6000 [07:25<5:43:04,  3.50s/it]                                                    {'loss': 0.2762, 'grad_norm': 12.957469940185547, 'learning_rate': 4.977118644067797e-05, 'epoch': 0.02}
  2%|â–         | 127/6000 [07:25<5:43:04,  3.50s/it][2025-10-23 00:03:49,124] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:49,125] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:49,441] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:49,442] INFO [src.utils:19] 29
[2025-10-23 00:03:49,442] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:49,530] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:49,531] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:49,744] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:49,744] INFO [src.utils:19] 29
[2025-10-23 00:03:49,744] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:49,870] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:49,870] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:50,081] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:50,082] INFO [src.utils:19] 29
[2025-10-23 00:03:50,082] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:50,169] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:50,170] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:50,380] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:50,381] INFO [src.utils:19] 29
[2025-10-23 00:03:50,381] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:50,435] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:50,436] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:50,652] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:50,653] INFO [src.utils:19] 29
[2025-10-23 00:03:50,653] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:50,898] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:50,899] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:51,115] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:51,116] INFO [src.utils:19] 29
[2025-10-23 00:03:51,116] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:51,460] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:51,460] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:51,674] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:51,675] INFO [src.utils:19] 29
[2025-10-23 00:03:51,675] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:51,926] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:51,927] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:52,141] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:52,142] INFO [src.utils:19] 29
[2025-10-23 00:03:52,142] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 128/6000 [07:28<5:38:10,  3.46s/it]                                                    {'loss': 0.082, 'grad_norm': 10.594791412353516, 'learning_rate': 4.976271186440678e-05, 'epoch': 0.02}
  2%|â–         | 128/6000 [07:28<5:38:10,  3.46s/it][2025-10-23 00:03:52,515] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:52,516] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:52,856] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:52,857] INFO [src.utils:19] 29
[2025-10-23 00:03:52,857] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:53,007] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:53,007] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:53,235] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:53,236] INFO [src.utils:19] 29
[2025-10-23 00:03:53,236] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:53,295] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:53,296] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:53,491] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:53,491] INFO [src.utils:19] 29
[2025-10-23 00:03:53,491] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:53,541] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:53,541] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:53,736] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:53,736] INFO [src.utils:19] 29
[2025-10-23 00:03:53,737] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:53,860] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:53,861] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:54,092] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:54,092] INFO [src.utils:19] 29
[2025-10-23 00:03:54,093] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:54,423] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:54,424] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:54,657] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:54,658] INFO [src.utils:19] 29
[2025-10-23 00:03:54,658] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:03:54,906] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:54,906] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:55,106] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:55,107] INFO [src.utils:19] 29
[2025-10-23 00:03:55,107] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:55,326] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:55,326] INFO [src.utils:19] torch.Size([8, 114, 1536])
[2025-10-23 00:03:55,531] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:55,531] INFO [src.utils:19] 29
[2025-10-23 00:03:55,532] INFO [src.utils:19] torch.Size([8, 114, 1536])
  2%|â–         | 129/6000 [07:32<5:38:36,  3.46s/it]                                                    {'loss': 0.0872, 'grad_norm': 8.708523750305176, 'learning_rate': 4.97542372881356e-05, 'epoch': 0.02}
  2%|â–         | 129/6000 [07:32<5:38:36,  3.46s/it][2025-10-23 00:03:55,988] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:55,990] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:56,300] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:56,301] INFO [src.utils:19] 29
[2025-10-23 00:03:56,301] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:56,365] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:56,365] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:56,581] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:56,582] INFO [src.utils:19] 29
[2025-10-23 00:03:56,582] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:56,658] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:56,659] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:56,871] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:56,871] INFO [src.utils:19] 29
[2025-10-23 00:03:56,872] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:56,990] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:56,990] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:57,200] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:57,201] INFO [src.utils:19] 29
[2025-10-23 00:03:57,201] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:57,319] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:57,319] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:57,533] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:57,534] INFO [src.utils:19] 29
[2025-10-23 00:03:57,534] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:57,756] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:57,757] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:57,971] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:57,972] INFO [src.utils:19] 29
[2025-10-23 00:03:57,972] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:58,249] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:58,250] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:58,464] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:58,464] INFO [src.utils:19] 29
[2025-10-23 00:03:58,464] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:58,745] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:58,745] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:03:58,959] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:58,960] INFO [src.utils:19] 29
[2025-10-23 00:03:58,960] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 130/6000 [07:35<5:35:18,  3.43s/it]                                                    {'loss': 0.1308, 'grad_norm': 9.45046615600586, 'learning_rate': 4.974576271186441e-05, 'epoch': 0.02}
  2%|â–         | 130/6000 [07:35<5:35:18,  3.43s/it][2025-10-23 00:03:59,357] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:59,358] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:59,705] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:03:59,705] INFO [src.utils:19] 29
[2025-10-23 00:03:59,706] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:03:59,809] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:03:59,809] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:00,021] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:00,021] INFO [src.utils:19] 29
[2025-10-23 00:04:00,022] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:00,079] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:00,080] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:00,289] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:00,290] INFO [src.utils:19] 29
[2025-10-23 00:04:00,290] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:00,359] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:00,359] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:00,572] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:00,573] INFO [src.utils:19] 29
[2025-10-23 00:04:00,573] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:00,715] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:00,716] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:00,930] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:00,931] INFO [src.utils:19] 29
[2025-10-23 00:04:00,931] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:01,194] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:01,195] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:01,410] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:01,411] INFO [src.utils:19] 29
[2025-10-23 00:04:01,411] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:01,651] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:01,652] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:01,866] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:01,866] INFO [src.utils:19] 29
[2025-10-23 00:04:01,867] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:02,103] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:02,104] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:02,322] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:02,323] INFO [src.utils:19] 29
[2025-10-23 00:04:02,323] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 131/6000 [07:39<5:35:37,  3.43s/it]                                                    {'loss': 0.1665, 'grad_norm': 10.713202476501465, 'learning_rate': 4.973728813559323e-05, 'epoch': 0.02}
  2%|â–         | 131/6000 [07:39<5:35:37,  3.43s/it][2025-10-23 00:04:02,717] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:02,719] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:03,063] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:03,063] INFO [src.utils:19] 29
[2025-10-23 00:04:03,064] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:03,152] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:03,152] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:03,365] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:03,366] INFO [src.utils:19] 29
[2025-10-23 00:04:03,366] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:03,490] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:03,491] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:03,701] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:03,702] INFO [src.utils:19] 29
[2025-10-23 00:04:03,702] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:03,787] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:03,788] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:03,997] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:03,998] INFO [src.utils:19] 29
[2025-10-23 00:04:03,998] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:04,058] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:04,058] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:04,272] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:04,272] INFO [src.utils:19] 29
[2025-10-23 00:04:04,272] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:04,526] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:04,527] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:04,745] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:04,746] INFO [src.utils:19] 29
[2025-10-23 00:04:04,746] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:05,086] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:05,086] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:05,302] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:05,303] INFO [src.utils:19] 29
[2025-10-23 00:04:05,303] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:05,557] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:05,557] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:05,772] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:05,772] INFO [src.utils:19] 29
[2025-10-23 00:04:05,773] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 132/6000 [07:42<5:33:44,  3.41s/it]                                                    {'loss': 0.0523, 'grad_norm': 4.719731330871582, 'learning_rate': 4.972881355932204e-05, 'epoch': 0.02}
  2%|â–         | 132/6000 [07:42<5:33:44,  3.41s/it][2025-10-23 00:04:06,132] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:06,134] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:06,440] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:06,440] INFO [src.utils:19] 29
[2025-10-23 00:04:06,441] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:06,543] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:06,544] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:06,767] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:06,768] INFO [src.utils:19] 29
[2025-10-23 00:04:06,768] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:06,847] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:06,848] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:07,057] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:07,058] INFO [src.utils:19] 29
[2025-10-23 00:04:07,058] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:07,145] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:07,145] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:07,355] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:07,356] INFO [src.utils:19] 29
[2025-10-23 00:04:07,356] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:07,474] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:07,475] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:07,700] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:07,700] INFO [src.utils:19] 29
[2025-10-23 00:04:07,701] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:07,971] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:07,972] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:08,197] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:08,198] INFO [src.utils:19] 29
[2025-10-23 00:04:08,198] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:08,458] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:08,459] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:08,677] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:08,678] INFO [src.utils:19] 29
[2025-10-23 00:04:08,678] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:08,937] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:08,938] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:09,153] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:09,153] INFO [src.utils:19] 29
[2025-10-23 00:04:09,154] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 133/6000 [07:45<5:33:42,  3.41s/it]                                                    {'loss': 0.2124, 'grad_norm': 18.373579025268555, 'learning_rate': 4.972033898305085e-05, 'epoch': 0.02}
  2%|â–         | 133/6000 [07:45<5:33:42,  3.41s/it][2025-10-23 00:04:09,553] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:09,554] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:09,860] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:09,860] INFO [src.utils:19] 29
[2025-10-23 00:04:09,861] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:09,964] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:09,964] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:10,196] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:10,196] INFO [src.utils:19] 29
[2025-10-23 00:04:10,196] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:10,285] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:10,286] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:10,524] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:10,524] INFO [src.utils:19] 29
[2025-10-23 00:04:10,525] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:10,615] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:10,616] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:10,851] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:10,852] INFO [src.utils:19] 29
[2025-10-23 00:04:10,852] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:10,974] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:10,974] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:11,203] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:11,204] INFO [src.utils:19] 29
[2025-10-23 00:04:11,204] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:11,484] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:11,485] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:11,717] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:11,718] INFO [src.utils:19] 29
[2025-10-23 00:04:11,718] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:11,999] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:11,999] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:12,240] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:12,240] INFO [src.utils:19] 29
[2025-10-23 00:04:12,240] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:12,521] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:12,522] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:04:12,764] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:12,764] INFO [src.utils:19] 29
[2025-10-23 00:04:12,765] INFO [src.utils:19] torch.Size([8, 177, 1536])
  2%|â–         | 134/6000 [07:49<5:38:59,  3.47s/it]                                                    {'loss': 0.1128, 'grad_norm': 9.439749717712402, 'learning_rate': 4.971186440677966e-05, 'epoch': 0.02}
  2%|â–         | 134/6000 [07:49<5:38:59,  3.47s/it][2025-10-23 00:04:13,112] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:13,113] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:13,412] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:13,413] INFO [src.utils:19] 29
[2025-10-23 00:04:13,413] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:13,516] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:13,517] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:13,731] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:13,731] INFO [src.utils:19] 29
[2025-10-23 00:04:13,731] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:13,822] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:13,823] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:14,043] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:14,043] INFO [src.utils:19] 29
[2025-10-23 00:04:14,044] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:14,125] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:14,126] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:14,348] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:14,349] INFO [src.utils:19] 29
[2025-10-23 00:04:14,349] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:14,441] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:14,441] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:14,656] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:14,657] INFO [src.utils:19] 29
[2025-10-23 00:04:14,657] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:14,924] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:14,925] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:15,140] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:15,140] INFO [src.utils:19] 29
[2025-10-23 00:04:15,141] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:15,443] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:15,443] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:15,671] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:15,671] INFO [src.utils:19] 29
[2025-10-23 00:04:15,671] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:15,919] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:15,920] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:16,146] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:16,147] INFO [src.utils:19] 29
[2025-10-23 00:04:16,148] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 135/6000 [07:52<5:35:53,  3.44s/it]                                                    {'loss': 0.129, 'grad_norm': 12.59504508972168, 'learning_rate': 4.970338983050848e-05, 'epoch': 0.02}
  2%|â–         | 135/6000 [07:52<5:35:53,  3.44s/it][2025-10-23 00:04:16,507] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:16,508] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:16,814] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:16,814] INFO [src.utils:19] 29
[2025-10-23 00:04:16,815] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:16,939] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:16,940] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:17,160] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:17,161] INFO [src.utils:19] 29
[2025-10-23 00:04:17,161] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:17,251] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:17,251] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:17,468] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:17,469] INFO [src.utils:19] 29
[2025-10-23 00:04:17,469] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:17,540] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:17,541] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:17,750] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:17,751] INFO [src.utils:19] 29
[2025-10-23 00:04:17,751] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:17,841] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:17,841] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:18,067] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:18,067] INFO [src.utils:19] 29
[2025-10-23 00:04:18,067] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:18,350] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:18,351] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:18,577] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:18,577] INFO [src.utils:19] 29
[2025-10-23 00:04:18,578] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:18,866] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:18,867] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:19,083] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:19,083] INFO [src.utils:19] 29
[2025-10-23 00:04:19,084] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:19,314] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:19,315] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:19,534] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:19,534] INFO [src.utils:19] 29
[2025-10-23 00:04:19,535] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 136/6000 [07:56<5:34:25,  3.42s/it]                                                    {'loss': 0.069, 'grad_norm': 7.149506568908691, 'learning_rate': 4.969491525423729e-05, 'epoch': 0.02}
  2%|â–         | 136/6000 [07:56<5:34:25,  3.42s/it][2025-10-23 00:04:19,886] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:19,887] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:20,195] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:20,196] INFO [src.utils:19] 29
[2025-10-23 00:04:20,196] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:20,300] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:20,301] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:20,515] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:20,515] INFO [src.utils:19] 29
[2025-10-23 00:04:20,516] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:20,608] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:20,608] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:20,905] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:20,905] INFO [src.utils:19] 29
[2025-10-23 00:04:20,905] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:20,993] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:20,994] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:21,289] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:21,289] INFO [src.utils:19] 29
[2025-10-23 00:04:21,289] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:21,403] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:21,404] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:21,619] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:21,619] INFO [src.utils:19] 29
[2025-10-23 00:04:21,620] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:21,883] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:21,884] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:22,101] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:22,101] INFO [src.utils:19] 29
[2025-10-23 00:04:22,102] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:22,380] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:22,380] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:22,680] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:22,680] INFO [src.utils:19] 29
[2025-10-23 00:04:22,681] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:23,043] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:23,043] INFO [src.utils:19] torch.Size([8, 276, 1536])
[2025-10-23 00:04:23,342] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:23,342] INFO [src.utils:19] 29
[2025-10-23 00:04:23,343] INFO [src.utils:19] torch.Size([8, 276, 1536])
  2%|â–         | 137/6000 [08:00<5:48:51,  3.57s/it]                                                    {'loss': 0.053, 'grad_norm': 7.838707447052002, 'learning_rate': 4.968644067796611e-05, 'epoch': 0.02}
  2%|â–         | 137/6000 [08:00<5:48:51,  3.57s/it][2025-10-23 00:04:23,764] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:23,765] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:24,067] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:24,067] INFO [src.utils:19] 29
[2025-10-23 00:04:24,068] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:24,154] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:24,155] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:24,367] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:24,368] INFO [src.utils:19] 29
[2025-10-23 00:04:24,368] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:24,473] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:24,473] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:24,685] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:24,685] INFO [src.utils:19] 29
[2025-10-23 00:04:24,686] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:24,774] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:24,774] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:24,985] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:24,986] INFO [src.utils:19] 29
[2025-10-23 00:04:24,986] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:25,064] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:25,065] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:25,280] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:25,281] INFO [src.utils:19] 29
[2025-10-23 00:04:25,281] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:25,528] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:25,529] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:25,745] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:25,746] INFO [src.utils:19] 29
[2025-10-23 00:04:25,746] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:26,072] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:26,073] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:26,291] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:26,292] INFO [src.utils:19] 29
[2025-10-23 00:04:26,292] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:26,555] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:26,556] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:26,771] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:26,772] INFO [src.utils:19] 29
[2025-10-23 00:04:26,772] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 138/6000 [08:03<5:42:01,  3.50s/it]                                                    {'loss': 0.1573, 'grad_norm': 12.960235595703125, 'learning_rate': 4.967796610169492e-05, 'epoch': 0.02}
  2%|â–         | 138/6000 [08:03<5:42:01,  3.50s/it][2025-10-23 00:04:27,130] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:27,131] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:27,485] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:27,486] INFO [src.utils:19] 29
[2025-10-23 00:04:27,486] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:27,572] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:27,572] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:27,785] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:27,786] INFO [src.utils:19] 29
[2025-10-23 00:04:27,786] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:27,902] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:27,903] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:28,113] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:28,114] INFO [src.utils:19] 29
[2025-10-23 00:04:28,114] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:28,197] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:28,198] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:28,407] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:28,408] INFO [src.utils:19] 29
[2025-10-23 00:04:28,408] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:28,515] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:28,515] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:28,731] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:28,732] INFO [src.utils:19] 29
[2025-10-23 00:04:28,732] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:28,982] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:28,983] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:29,200] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:29,200] INFO [src.utils:19] 29
[2025-10-23 00:04:29,201] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:29,500] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:29,501] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:29,714] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:29,715] INFO [src.utils:19] 29
[2025-10-23 00:04:29,715] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:29,963] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:29,963] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:30,181] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:30,181] INFO [src.utils:19] 29
[2025-10-23 00:04:30,182] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 139/6000 [08:07<5:43:44,  3.52s/it]                                                    {'loss': 0.1686, 'grad_norm': 14.454405784606934, 'learning_rate': 4.966949152542373e-05, 'epoch': 0.02}
  2%|â–         | 139/6000 [08:07<5:43:44,  3.52s/it][2025-10-23 00:04:30,696] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:30,697] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:31,053] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:31,053] INFO [src.utils:19] 29
[2025-10-23 00:04:31,054] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:31,163] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:31,164] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:31,385] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:31,385] INFO [src.utils:19] 29
[2025-10-23 00:04:31,386] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:31,475] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:31,476] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:31,687] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:31,687] INFO [src.utils:19] 29
[2025-10-23 00:04:31,687] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:31,763] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:31,764] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:31,975] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:31,975] INFO [src.utils:19] 29
[2025-10-23 00:04:31,976] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:32,157] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:32,157] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:32,386] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:32,386] INFO [src.utils:19] 29
[2025-10-23 00:04:32,387] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:32,656] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:32,657] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:32,881] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:32,882] INFO [src.utils:19] 29
[2025-10-23 00:04:32,882] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:33,496] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:33,497] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:33,719] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:33,719] INFO [src.utils:19] 29
[2025-10-23 00:04:33,720] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:33,961] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:33,962] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:34,176] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:34,177] INFO [src.utils:19] 29
[2025-10-23 00:04:34,177] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 140/6000 [08:11<5:53:46,  3.62s/it]                                                    {'loss': 0.1124, 'grad_norm': 11.431146621704102, 'learning_rate': 4.966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 140/6000 [08:11<5:53:46,  3.62s/it][2025-10-23 00:04:34,566] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:34,568] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:34,906] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:34,907] INFO [src.utils:19] 29
[2025-10-23 00:04:34,907] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:34,996] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:34,997] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:35,220] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:35,220] INFO [src.utils:19] 29
[2025-10-23 00:04:35,221] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:35,301] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:35,301] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:35,524] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:35,525] INFO [src.utils:19] 29
[2025-10-23 00:04:35,525] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:35,611] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:35,611] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:35,831] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:35,831] INFO [src.utils:19] 29
[2025-10-23 00:04:35,831] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:35,938] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:35,939] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:36,166] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:36,167] INFO [src.utils:19] 29
[2025-10-23 00:04:36,167] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:36,431] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:36,432] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:36,659] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:36,660] INFO [src.utils:19] 29
[2025-10-23 00:04:36,660] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:04:36,928] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:36,928] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:37,152] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:37,153] INFO [src.utils:19] 29
[2025-10-23 00:04:37,153] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:37,407] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:37,407] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:37,631] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:37,632] INFO [src.utils:19] 29
[2025-10-23 00:04:37,632] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 141/6000 [08:14<5:48:36,  3.57s/it]                                                    {'loss': 0.2511, 'grad_norm': 16.38189697265625, 'learning_rate': 4.965254237288136e-05, 'epoch': 0.02}
  2%|â–         | 141/6000 [08:14<5:48:36,  3.57s/it][2025-10-23 00:04:38,016] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:38,017] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:38,323] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:38,323] INFO [src.utils:19] 29
[2025-10-23 00:04:38,324] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:38,427] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:38,427] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:38,639] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:38,640] INFO [src.utils:19] 29
[2025-10-23 00:04:38,640] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:38,713] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:38,714] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:38,927] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:38,928] INFO [src.utils:19] 29
[2025-10-23 00:04:38,928] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:39,006] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:39,006] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:39,223] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:39,224] INFO [src.utils:19] 29
[2025-10-23 00:04:39,224] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:39,330] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:39,330] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:39,546] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:39,547] INFO [src.utils:19] 29
[2025-10-23 00:04:39,547] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:39,811] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:39,812] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:40,028] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:40,028] INFO [src.utils:19] 29
[2025-10-23 00:04:40,029] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:40,289] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:40,289] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:40,506] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:40,506] INFO [src.utils:19] 29
[2025-10-23 00:04:40,507] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:40,749] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:40,750] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:04:40,970] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:40,971] INFO [src.utils:19] 29
[2025-10-23 00:04:40,971] INFO [src.utils:19] torch.Size([8, 141, 1536])
  2%|â–         | 142/6000 [08:17<5:42:30,  3.51s/it]                                                    {'loss': 0.1197, 'grad_norm': 9.618456840515137, 'learning_rate': 4.964406779661017e-05, 'epoch': 0.02}
  2%|â–         | 142/6000 [08:17<5:42:30,  3.51s/it][2025-10-23 00:04:41,359] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:41,360] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:41,709] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:41,709] INFO [src.utils:19] 29
[2025-10-23 00:04:41,710] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:41,797] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:41,797] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:42,010] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:42,010] INFO [src.utils:19] 29
[2025-10-23 00:04:42,011] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:42,118] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:42,119] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:42,329] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:42,329] INFO [src.utils:19] 29
[2025-10-23 00:04:42,330] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:42,418] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:42,418] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:42,628] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:42,628] INFO [src.utils:19] 29
[2025-10-23 00:04:42,628] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:42,703] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:42,704] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:42,917] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:42,918] INFO [src.utils:19] 29
[2025-10-23 00:04:42,918] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:43,174] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:43,175] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:43,390] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:43,391] INFO [src.utils:19] 29
[2025-10-23 00:04:43,391] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:43,735] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:43,736] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:43,951] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:43,951] INFO [src.utils:19] 29
[2025-10-23 00:04:43,952] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:44,199] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:44,200] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:44,413] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:44,414] INFO [src.utils:19] 29
[2025-10-23 00:04:44,414] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 143/6000 [08:21<5:38:51,  3.47s/it]                                                    {'loss': 0.0355, 'grad_norm': 5.296032905578613, 'learning_rate': 4.963559322033898e-05, 'epoch': 0.02}
  2%|â–         | 143/6000 [08:21<5:38:51,  3.47s/it][2025-10-23 00:04:44,785] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:44,786] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:45,131] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:45,132] INFO [src.utils:19] 29
[2025-10-23 00:04:45,132] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:45,235] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:45,236] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:45,448] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:45,448] INFO [src.utils:19] 29
[2025-10-23 00:04:45,449] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:45,506] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:45,507] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:45,717] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:45,717] INFO [src.utils:19] 29
[2025-10-23 00:04:45,718] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:45,790] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:45,791] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:46,001] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:46,002] INFO [src.utils:19] 29
[2025-10-23 00:04:46,002] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:46,128] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:46,128] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:46,347] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:46,347] INFO [src.utils:19] 29
[2025-10-23 00:04:46,348] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:46,621] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:46,622] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:46,840] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:46,840] INFO [src.utils:19] 29
[2025-10-23 00:04:46,841] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:47,099] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:47,099] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:47,314] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:47,315] INFO [src.utils:19] 29
[2025-10-23 00:04:47,315] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:47,561] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:47,561] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:47,775] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:47,776] INFO [src.utils:19] 29
[2025-10-23 00:04:47,776] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 144/6000 [08:24<5:38:16,  3.47s/it]                                                    {'loss': 0.0233, 'grad_norm': 3.313227653503418, 'learning_rate': 4.96271186440678e-05, 'epoch': 0.02}
  2%|â–         | 144/6000 [08:24<5:38:16,  3.47s/it][2025-10-23 00:04:48,184] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:48,184] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:48,515] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:48,516] INFO [src.utils:19] 29
[2025-10-23 00:04:48,516] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:48,574] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:48,575] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:48,786] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:48,787] INFO [src.utils:19] 29
[2025-10-23 00:04:48,787] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:48,892] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:48,892] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:49,103] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:49,104] INFO [src.utils:19] 29
[2025-10-23 00:04:49,104] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:49,223] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:49,223] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:49,432] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:49,433] INFO [src.utils:19] 29
[2025-10-23 00:04:49,433] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:49,509] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:49,510] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:49,727] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:49,728] INFO [src.utils:19] 29
[2025-10-23 00:04:49,728] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:49,953] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:49,954] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:50,174] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:50,175] INFO [src.utils:19] 29
[2025-10-23 00:04:50,175] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:50,483] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:50,484] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:50,698] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:50,699] INFO [src.utils:19] 29
[2025-10-23 00:04:50,699] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:50,980] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:50,981] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:51,196] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:51,197] INFO [src.utils:19] 29
[2025-10-23 00:04:51,197] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 145/6000 [08:28<5:39:16,  3.48s/it]                                                    {'loss': 0.8443, 'grad_norm': 197.6547393798828, 'learning_rate': 4.961864406779661e-05, 'epoch': 0.02}
  2%|â–         | 145/6000 [08:28<5:39:16,  3.48s/it][2025-10-23 00:04:51,679] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:51,680] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:52,030] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:52,031] INFO [src.utils:19] 29
[2025-10-23 00:04:52,031] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:52,166] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:52,166] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:52,394] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:52,395] INFO [src.utils:19] 29
[2025-10-23 00:04:52,395] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:52,531] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:52,531] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:52,743] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:52,743] INFO [src.utils:19] 29
[2025-10-23 00:04:52,744] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:52,799] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:52,799] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:53,007] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:53,008] INFO [src.utils:19] 29
[2025-10-23 00:04:53,008] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:53,078] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:53,079] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:53,307] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:53,308] INFO [src.utils:19] 29
[2025-10-23 00:04:53,308] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:53,611] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:53,612] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:53,844] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:53,845] INFO [src.utils:19] 29
[2025-10-23 00:04:53,845] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:04:54,175] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:54,175] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:54,390] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:54,391] INFO [src.utils:19] 29
[2025-10-23 00:04:54,391] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:54,615] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:54,615] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:54,828] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:54,829] INFO [src.utils:19] 29
[2025-10-23 00:04:54,829] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 146/6000 [08:31<5:41:14,  3.50s/it]                                                    {'loss': 0.0741, 'grad_norm': 8.803339004516602, 'learning_rate': 4.961016949152543e-05, 'epoch': 0.02}
  2%|â–         | 146/6000 [08:31<5:41:14,  3.50s/it][2025-10-23 00:04:55,249] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:55,250] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:55,578] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:55,579] INFO [src.utils:19] 29
[2025-10-23 00:04:55,579] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:55,667] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:55,668] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:55,882] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:55,882] INFO [src.utils:19] 29
[2025-10-23 00:04:55,883] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:55,970] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:55,970] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:56,180] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:56,180] INFO [src.utils:19] 29
[2025-10-23 00:04:56,181] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:56,267] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:56,267] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:56,479] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:56,479] INFO [src.utils:19] 29
[2025-10-23 00:04:56,480] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:56,567] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:56,568] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:56,784] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:56,785] INFO [src.utils:19] 29
[2025-10-23 00:04:56,785] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:57,039] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:57,040] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:57,256] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:57,257] INFO [src.utils:19] 29
[2025-10-23 00:04:57,258] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:04:57,540] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:57,540] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:57,757] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:57,758] INFO [src.utils:19] 29
[2025-10-23 00:04:57,758] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:58,021] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:58,021] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:04:58,236] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:58,236] INFO [src.utils:19] 29
[2025-10-23 00:04:58,237] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 147/6000 [08:35<5:37:07,  3.46s/it]                                                    {'loss': 0.1637, 'grad_norm': 14.502584457397461, 'learning_rate': 4.9601694915254234e-05, 'epoch': 0.02}
  2%|â–         | 147/6000 [08:35<5:37:07,  3.46s/it][2025-10-23 00:04:58,610] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:58,612] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:58,912] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:58,913] INFO [src.utils:19] 29
[2025-10-23 00:04:58,913] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:58,993] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:58,994] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:59,215] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:59,215] INFO [src.utils:19] 29
[2025-10-23 00:04:59,216] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:04:59,306] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:59,306] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:59,528] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:59,528] INFO [src.utils:19] 29
[2025-10-23 00:04:59,529] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:59,646] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:59,647] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:59,866] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:04:59,867] INFO [src.utils:19] 29
[2025-10-23 00:04:59,867] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:04:59,958] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:04:59,959] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:00,182] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:00,182] INFO [src.utils:19] 29
[2025-10-23 00:05:00,183] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:00,427] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:00,427] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:00,650] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:00,651] INFO [src.utils:19] 29
[2025-10-23 00:05:00,651] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:00,929] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:00,930] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:01,155] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:01,155] INFO [src.utils:19] 29
[2025-10-23 00:05:01,155] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:01,442] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:01,442] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:01,666] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:01,667] INFO [src.utils:19] 29
[2025-10-23 00:05:01,667] INFO [src.utils:19] torch.Size([8, 150, 1536])
  2%|â–         | 148/6000 [08:38<5:35:11,  3.44s/it]                                                    {'loss': 0.0812, 'grad_norm': 12.095131874084473, 'learning_rate': 4.959322033898305e-05, 'epoch': 0.02}
  2%|â–         | 148/6000 [08:38<5:35:11,  3.44s/it][2025-10-23 00:05:01,999] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:02,000] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:02,367] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:02,368] INFO [src.utils:19] 29
[2025-10-23 00:05:02,368] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:02,453] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:02,453] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:02,665] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:02,666] INFO [src.utils:19] 29
[2025-10-23 00:05:02,666] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:02,771] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:02,771] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:02,987] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:02,987] INFO [src.utils:19] 29
[2025-10-23 00:05:02,987] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:03,072] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:03,073] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:03,283] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:03,283] INFO [src.utils:19] 29
[2025-10-23 00:05:03,284] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:03,362] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:03,363] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:03,581] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:03,582] INFO [src.utils:19] 29
[2025-10-23 00:05:03,582] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:03,829] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:03,829] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:04,044] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:04,045] INFO [src.utils:19] 29
[2025-10-23 00:05:04,045] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:04,364] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:04,365] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:04,579] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:04,580] INFO [src.utils:19] 29
[2025-10-23 00:05:04,580] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:04,833] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:04,834] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:05,049] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:05,049] INFO [src.utils:19] 29
[2025-10-23 00:05:05,050] INFO [src.utils:19] torch.Size([8, 132, 1536])
  2%|â–         | 149/6000 [08:41<5:33:42,  3.42s/it]                                                    {'loss': 0.045, 'grad_norm': 6.6881256103515625, 'learning_rate': 4.9584745762711864e-05, 'epoch': 0.02}
  2%|â–         | 149/6000 [08:41<5:33:42,  3.42s/it][2025-10-23 00:05:05,367] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:05,367] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:05,692] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:05,693] INFO [src.utils:19] 29
[2025-10-23 00:05:05,693] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:05,753] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:05,753] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:05,968] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:05,969] INFO [src.utils:19] 29
[2025-10-23 00:05:05,969] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:06,094] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:06,095] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:06,306] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:06,307] INFO [src.utils:19] 29
[2025-10-23 00:05:06,307] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:06,429] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:06,430] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:06,642] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:06,643] INFO [src.utils:19] 29
[2025-10-23 00:05:06,643] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:06,701] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:06,701] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:06,916] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:06,917] INFO [src.utils:19] 29
[2025-10-23 00:05:06,917] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:07,136] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:07,137] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:07,351] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:07,352] INFO [src.utils:19] 29
[2025-10-23 00:05:07,352] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:07,728] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:07,728] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:07,945] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:07,945] INFO [src.utils:19] 29
[2025-10-23 00:05:07,946] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:08,232] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:08,233] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:08,449] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:08,449] INFO [src.utils:19] 29
[2025-10-23 00:05:08,450] INFO [src.utils:19] torch.Size([8, 141, 1536])
  2%|â–Ž         | 150/6000 [08:45<5:32:49,  3.41s/it]                                                    {'loss': 0.0053, 'grad_norm': 1.0520414113998413, 'learning_rate': 4.957627118644068e-05, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [08:45<5:32:49,  3.41s/it][2025-10-23 00:05:08,671] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/test5-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[2025-10-23 00:05:10,951] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:10,952] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:11,233] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:11,233] INFO [src.utils:19] 29
[2025-10-23 00:05:11,233] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:11,340] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:11,341] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:11,553] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:11,553] INFO [src.utils:19] 29
[2025-10-23 00:05:11,554] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:11,658] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:11,659] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:11,870] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:11,870] INFO [src.utils:19] 29
[2025-10-23 00:05:11,871] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:11,948] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:11,948] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:12,160] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:12,161] INFO [src.utils:19] 29
[2025-10-23 00:05:12,161] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:12,240] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:12,240] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:12,454] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:12,454] INFO [src.utils:19] 29
[2025-10-23 00:05:12,455] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:12,729] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:12,730] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:12,944] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:12,945] INFO [src.utils:19] 29
[2025-10-23 00:05:12,945] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:13,355] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:13,356] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:13,573] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:13,574] INFO [src.utils:19] 29
[2025-10-23 00:05:13,574] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:13,815] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:13,816] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:05:14,031] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:14,031] INFO [src.utils:19] 29
[2025-10-23 00:05:14,031] INFO [src.utils:19] torch.Size([8, 141, 1536])
  3%|â–Ž         | 151/6000 [08:50<6:36:22,  4.07s/it]                                                    {'loss': 0.0821, 'grad_norm': 4.8238983154296875, 'learning_rate': 4.956779661016949e-05, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [08:50<6:36:22,  4.07s/it][2025-10-23 00:05:14,359] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:14,360] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:14,689] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:14,690] INFO [src.utils:19] 29
[2025-10-23 00:05:14,690] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:14,747] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:14,748] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:14,949] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:14,950] INFO [src.utils:19] 29
[2025-10-23 00:05:14,950] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:15,082] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:15,083] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:15,302] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:15,303] INFO [src.utils:19] 29
[2025-10-23 00:05:15,303] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:15,422] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:15,423] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:15,643] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:15,644] INFO [src.utils:19] 29
[2025-10-23 00:05:15,644] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:15,706] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:15,707] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:15,910] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:15,910] INFO [src.utils:19] 29
[2025-10-23 00:05:15,910] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:16,143] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:16,144] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:16,347] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:16,348] INFO [src.utils:19] 29
[2025-10-23 00:05:16,348] INFO [src.utils:19] torch.Size([8, 128, 1536])
[2025-10-23 00:05:16,772] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:16,772] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:16,997] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:16,998] INFO [src.utils:19] 29
[2025-10-23 00:05:16,998] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:17,292] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:17,293] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:05:17,519] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:17,519] INFO [src.utils:19] 29
[2025-10-23 00:05:17,520] INFO [src.utils:19] torch.Size([8, 150, 1536])
  3%|â–Ž         | 152/6000 [08:54<6:19:14,  3.89s/it]                                                    {'loss': 0.0514, 'grad_norm': 7.134369373321533, 'learning_rate': 4.955932203389831e-05, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [08:54<6:19:14,  3.89s/it][2025-10-23 00:05:17,832] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:17,834] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:18,165] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:18,166] INFO [src.utils:19] 29
[2025-10-23 00:05:18,166] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:18,241] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:18,241] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:18,452] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:18,452] INFO [src.utils:19] 29
[2025-10-23 00:05:18,453] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:18,558] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:18,559] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:18,769] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:18,769] INFO [src.utils:19] 29
[2025-10-23 00:05:18,770] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:18,875] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:18,876] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:19,085] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:19,085] INFO [src.utils:19] 29
[2025-10-23 00:05:19,086] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:19,165] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:19,165] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:19,379] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:19,380] INFO [src.utils:19] 29
[2025-10-23 00:05:19,380] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:19,622] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:19,623] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:19,838] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:19,838] INFO [src.utils:19] 29
[2025-10-23 00:05:19,839] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:20,135] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:20,136] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:20,350] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:20,351] INFO [src.utils:19] 29
[2025-10-23 00:05:20,351] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:20,622] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:20,623] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:20,838] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:20,838] INFO [src.utils:19] 29
[2025-10-23 00:05:20,839] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 153/6000 [08:57<6:02:25,  3.72s/it]                                                    {'loss': 0.0208, 'grad_norm': 1.537578821182251, 'learning_rate': 4.955084745762712e-05, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [08:57<6:02:25,  3.72s/it][2025-10-23 00:05:21,166] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:21,166] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:21,494] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:21,495] INFO [src.utils:19] 29
[2025-10-23 00:05:21,495] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:21,559] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:21,559] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:21,773] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:21,774] INFO [src.utils:19] 29
[2025-10-23 00:05:21,775] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:21,874] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:21,875] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:22,111] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:22,111] INFO [src.utils:19] 29
[2025-10-23 00:05:22,112] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:22,236] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:22,237] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:22,474] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:22,474] INFO [src.utils:19] 29
[2025-10-23 00:05:22,475] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:22,569] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:22,570] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:22,784] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:22,785] INFO [src.utils:19] 29
[2025-10-23 00:05:22,785] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:23,003] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:23,004] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:23,223] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:23,223] INFO [src.utils:19] 29
[2025-10-23 00:05:23,223] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:23,522] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:23,522] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:23,767] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:23,768] INFO [src.utils:19] 29
[2025-10-23 00:05:23,768] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:24,085] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:24,085] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:05:24,327] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:24,327] INFO [src.utils:19] 29
[2025-10-23 00:05:24,328] INFO [src.utils:19] torch.Size([8, 177, 1536])
  3%|â–Ž         | 154/6000 [09:01<5:56:21,  3.66s/it]                                                    {'loss': 0.1327, 'grad_norm': 15.624638557434082, 'learning_rate': 4.9542372881355934e-05, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [09:01<5:56:21,  3.66s/it][2025-10-23 00:05:24,735] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:24,737] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:25,064] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:25,065] INFO [src.utils:19] 29
[2025-10-23 00:05:25,065] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:25,156] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:25,156] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:25,378] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:25,379] INFO [src.utils:19] 29
[2025-10-23 00:05:25,379] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:25,429] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:25,430] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:25,642] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:25,642] INFO [src.utils:19] 29
[2025-10-23 00:05:25,642] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:25,728] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:25,729] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:25,940] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:25,940] INFO [src.utils:19] 29
[2025-10-23 00:05:25,940] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:26,084] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:26,085] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:26,313] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:26,314] INFO [src.utils:19] 29
[2025-10-23 00:05:26,314] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:26,571] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:26,572] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:26,797] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:26,797] INFO [src.utils:19] 29
[2025-10-23 00:05:26,798] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:27,037] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:27,038] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:27,252] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:27,252] INFO [src.utils:19] 29
[2025-10-23 00:05:27,253] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:27,503] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:27,504] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:27,717] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:27,717] INFO [src.utils:19] 29
[2025-10-23 00:05:27,718] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 155/6000 [09:04<5:48:10,  3.57s/it]                                                    {'loss': 0.081, 'grad_norm': 6.528494358062744, 'learning_rate': 4.9533898305084745e-05, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [09:04<5:48:10,  3.57s/it][2025-10-23 00:05:28,061] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:28,063] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:28,409] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:28,410] INFO [src.utils:19] 29
[2025-10-23 00:05:28,410] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:28,499] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:28,500] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:28,720] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:28,721] INFO [src.utils:19] 29
[2025-10-23 00:05:28,721] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:28,846] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:28,847] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:29,076] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:29,076] INFO [src.utils:19] 29
[2025-10-23 00:05:29,076] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:29,163] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:29,164] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:29,391] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:29,391] INFO [src.utils:19] 29
[2025-10-23 00:05:29,391] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:29,459] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:29,459] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:29,683] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:29,683] INFO [src.utils:19] 29
[2025-10-23 00:05:29,683] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:29,936] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:29,937] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:30,165] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:30,166] INFO [src.utils:19] 29
[2025-10-23 00:05:30,166] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:05:30,479] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:30,480] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:30,716] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:30,717] INFO [src.utils:19] 29
[2025-10-23 00:05:30,717] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:30,985] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:30,986] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:31,218] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:31,218] INFO [src.utils:19] 29
[2025-10-23 00:05:31,219] INFO [src.utils:19] torch.Size([8, 168, 1536])
  3%|â–Ž         | 156/6000 [09:08<5:45:52,  3.55s/it]                                                    {'loss': 0.0505, 'grad_norm': 12.315802574157715, 'learning_rate': 4.952542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [09:08<5:45:52,  3.55s/it][2025-10-23 00:05:31,579] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:31,580] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:31,925] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:31,925] INFO [src.utils:19] 29
[2025-10-23 00:05:31,925] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:32,035] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:32,036] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:32,314] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:32,315] INFO [src.utils:19] 29
[2025-10-23 00:05:32,315] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:32,409] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:32,409] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:32,621] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:32,621] INFO [src.utils:19] 29
[2025-10-23 00:05:32,622] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:32,697] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:32,698] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:32,912] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:32,912] INFO [src.utils:19] 29
[2025-10-23 00:05:32,913] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:33,023] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:33,023] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:33,304] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:33,305] INFO [src.utils:19] 29
[2025-10-23 00:05:33,305] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:33,685] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:33,686] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:33,966] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:33,967] INFO [src.utils:19] 29
[2025-10-23 00:05:33,967] INFO [src.utils:19] torch.Size([8, 236, 1536])
[2025-10-23 00:05:34,340] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:34,341] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:34,558] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:34,559] INFO [src.utils:19] 29
[2025-10-23 00:05:34,559] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:34,808] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:34,809] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:35,025] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:35,026] INFO [src.utils:19] 29
[2025-10-23 00:05:35,026] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 157/6000 [09:11<5:57:35,  3.67s/it]                                                    {'loss': 0.0467, 'grad_norm': 4.417263507843018, 'learning_rate': 4.9516949152542374e-05, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [09:11<5:57:35,  3.67s/it][2025-10-23 00:05:35,532] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:35,533] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:35,844] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:35,845] INFO [src.utils:19] 29
[2025-10-23 00:05:35,845] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:35,902] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:35,903] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:36,115] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:36,115] INFO [src.utils:19] 29
[2025-10-23 00:05:36,116] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:36,194] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:36,194] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:36,405] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:36,405] INFO [src.utils:19] 29
[2025-10-23 00:05:36,406] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:36,528] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:36,528] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:36,739] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:36,740] INFO [src.utils:19] 29
[2025-10-23 00:05:36,740] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:36,850] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:36,851] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:37,067] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:37,067] INFO [src.utils:19] 29
[2025-10-23 00:05:37,068] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:37,284] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:37,285] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:37,500] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:37,501] INFO [src.utils:19] 29
[2025-10-23 00:05:37,501] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:37,772] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:37,773] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:37,986] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:37,987] INFO [src.utils:19] 29
[2025-10-23 00:05:37,987] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:38,277] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:38,278] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:38,493] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:38,493] INFO [src.utils:19] 29
[2025-10-23 00:05:38,493] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 158/6000 [09:15<5:47:06,  3.56s/it]                                                    {'loss': 0.0059, 'grad_norm': 1.0020763874053955, 'learning_rate': 4.950847457627119e-05, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [09:15<5:47:06,  3.56s/it][2025-10-23 00:05:38,824] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:38,825] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:39,115] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:39,116] INFO [src.utils:19] 29
[2025-10-23 00:05:39,116] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:39,192] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:39,192] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:39,404] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:39,404] INFO [src.utils:19] 29
[2025-10-23 00:05:39,405] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:39,493] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:39,493] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:39,707] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:39,708] INFO [src.utils:19] 29
[2025-10-23 00:05:39,708] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:39,812] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:39,812] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:40,023] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:40,023] INFO [src.utils:19] 29
[2025-10-23 00:05:40,024] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:40,132] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:40,132] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:40,348] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:40,348] INFO [src.utils:19] 29
[2025-10-23 00:05:40,349] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:40,582] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:40,583] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:40,799] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:40,799] INFO [src.utils:19] 29
[2025-10-23 00:05:40,800] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:41,078] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:41,079] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:41,294] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:41,295] INFO [src.utils:19] 29
[2025-10-23 00:05:41,295] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:41,560] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:41,561] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:41,775] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:41,776] INFO [src.utils:19] 29
[2025-10-23 00:05:41,776] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 159/6000 [09:18<5:39:36,  3.49s/it]                                                    {'loss': 0.1908, 'grad_norm': 11.309032440185547, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [09:18<5:39:36,  3.49s/it][2025-10-23 00:05:42,155] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:42,157] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:42,449] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:42,450] INFO [src.utils:19] 29
[2025-10-23 00:05:42,450] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:42,541] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:42,541] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:42,763] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:42,764] INFO [src.utils:19] 29
[2025-10-23 00:05:42,764] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:42,839] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:42,840] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:43,053] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:43,053] INFO [src.utils:19] 29
[2025-10-23 00:05:43,054] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:43,142] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:43,142] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:43,354] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:43,355] INFO [src.utils:19] 29
[2025-10-23 00:05:43,355] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:43,678] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:43,679] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:43,907] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:43,908] INFO [src.utils:19] 29
[2025-10-23 00:05:43,908] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:44,167] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:44,168] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:44,393] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:44,394] INFO [src.utils:19] 29
[2025-10-23 00:05:44,394] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:05:45,147] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:45,147] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:45,362] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:45,362] INFO [src.utils:19] 29
[2025-10-23 00:05:45,363] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:45,613] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:45,613] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:45,827] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:45,828] INFO [src.utils:19] 29
[2025-10-23 00:05:45,828] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 160/6000 [09:22<5:55:02,  3.65s/it]                                                    {'loss': 0.0532, 'grad_norm': 5.859992027282715, 'learning_rate': 4.9491525423728815e-05, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [09:22<5:55:02,  3.65s/it][2025-10-23 00:05:46,152] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:46,154] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:46,461] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:46,462] INFO [src.utils:19] 29
[2025-10-23 00:05:46,462] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:46,548] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:46,548] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:46,759] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:46,760] INFO [src.utils:19] 29
[2025-10-23 00:05:46,760] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:46,849] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:46,849] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:47,092] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:47,093] INFO [src.utils:19] 29
[2025-10-23 00:05:47,093] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:47,202] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:47,202] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:47,443] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:47,444] INFO [src.utils:19] 29
[2025-10-23 00:05:47,444] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:47,535] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:47,536] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:47,756] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:47,756] INFO [src.utils:19] 29
[2025-10-23 00:05:47,757] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:48,000] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:48,001] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:48,215] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:48,216] INFO [src.utils:19] 29
[2025-10-23 00:05:48,216] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:48,501] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:48,502] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:48,751] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:48,751] INFO [src.utils:19] 29
[2025-10-23 00:05:48,752] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:49,060] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:49,060] INFO [src.utils:19] torch.Size([8, 195, 1536])
[2025-10-23 00:05:49,305] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:49,306] INFO [src.utils:19] 29
[2025-10-23 00:05:49,306] INFO [src.utils:19] torch.Size([8, 195, 1536])
  3%|â–Ž         | 161/6000 [09:26<5:50:59,  3.61s/it]                                                    {'loss': 0.0901, 'grad_norm': 10.498228073120117, 'learning_rate': 4.9483050847457626e-05, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [09:26<5:50:59,  3.61s/it][2025-10-23 00:05:49,660] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:49,661] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:49,969] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:49,969] INFO [src.utils:19] 29
[2025-10-23 00:05:49,970] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:50,056] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:50,057] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:50,269] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:50,269] INFO [src.utils:19] 29
[2025-10-23 00:05:50,269] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:50,388] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:50,388] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:50,605] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:50,605] INFO [src.utils:19] 29
[2025-10-23 00:05:50,606] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:50,691] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:50,691] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:50,902] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:50,903] INFO [src.utils:19] 29
[2025-10-23 00:05:50,903] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:50,962] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:50,962] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:51,182] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:51,182] INFO [src.utils:19] 29
[2025-10-23 00:05:51,183] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:51,446] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:51,446] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:51,663] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:51,664] INFO [src.utils:19] 29
[2025-10-23 00:05:51,664] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:52,166] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:52,167] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:52,388] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:52,389] INFO [src.utils:19] 29
[2025-10-23 00:05:52,389] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:52,637] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:52,638] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:52,852] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:52,853] INFO [src.utils:19] 29
[2025-10-23 00:05:52,853] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 162/6000 [09:29<5:48:24,  3.58s/it]                                                    {'loss': 0.0062, 'grad_norm': 0.7009117603302002, 'learning_rate': 4.9474576271186444e-05, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [09:29<5:48:24,  3.58s/it][2025-10-23 00:05:53,192] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:53,193] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:53,502] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:53,503] INFO [src.utils:19] 29
[2025-10-23 00:05:53,503] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:53,554] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:53,578] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:53,791] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:53,791] INFO [src.utils:19] 29
[2025-10-23 00:05:53,791] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:53,896] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:53,897] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:54,125] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:54,125] INFO [src.utils:19] 29
[2025-10-23 00:05:54,126] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:54,279] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:54,280] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:54,508] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:54,508] INFO [src.utils:19] 29
[2025-10-23 00:05:54,508] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:54,641] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:54,641] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:54,860] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:54,861] INFO [src.utils:19] 29
[2025-10-23 00:05:54,861] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:55,074] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:55,075] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:55,292] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:55,292] INFO [src.utils:19] 29
[2025-10-23 00:05:55,293] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:55,615] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:55,616] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:55,848] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:55,849] INFO [src.utils:19] 29
[2025-10-23 00:05:55,849] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:56,177] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:56,178] INFO [src.utils:19] torch.Size([8, 168, 1536])
[2025-10-23 00:05:56,413] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:56,414] INFO [src.utils:19] 29
[2025-10-23 00:05:56,414] INFO [src.utils:19] torch.Size([8, 168, 1536])
  3%|â–Ž         | 163/6000 [09:33<5:54:46,  3.65s/it]                                                    {'loss': 0.1027, 'grad_norm': 12.556591033935547, 'learning_rate': 4.9466101694915256e-05, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [09:33<5:54:46,  3.65s/it][2025-10-23 00:05:56,962] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:56,963] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:57,277] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:57,278] INFO [src.utils:19] 29
[2025-10-23 00:05:57,278] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:57,337] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:57,338] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:57,554] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:57,554] INFO [src.utils:19] 29
[2025-10-23 00:05:57,555] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:57,693] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:57,694] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:57,902] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:57,903] INFO [src.utils:19] 29
[2025-10-23 00:05:57,903] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:58,029] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:58,030] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:58,241] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:58,242] INFO [src.utils:19] 29
[2025-10-23 00:05:58,242] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:58,297] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:58,298] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:58,512] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:58,512] INFO [src.utils:19] 29
[2025-10-23 00:05:58,512] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:58,730] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:58,730] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:58,944] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:58,945] INFO [src.utils:19] 29
[2025-10-23 00:05:58,945] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:05:59,311] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:59,312] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:59,529] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:05:59,529] INFO [src.utils:19] 29
[2025-10-23 00:05:59,530] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:05:59,824] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:05:59,824] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:00,040] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:00,041] INFO [src.utils:19] 29
[2025-10-23 00:06:00,041] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 164/6000 [09:36<5:47:03,  3.57s/it]                                                    {'loss': 0.2996, 'grad_norm': 15.252562522888184, 'learning_rate': 4.945762711864407e-05, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [09:36<5:47:03,  3.57s/it][2025-10-23 00:06:00,375] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:00,376] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:00,721] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:00,722] INFO [src.utils:19] 29
[2025-10-23 00:06:00,723] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:00,808] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:00,809] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:01,024] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:01,024] INFO [src.utils:19] 29
[2025-10-23 00:06:01,025] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:01,149] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:01,150] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:01,386] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:01,387] INFO [src.utils:19] 29
[2025-10-23 00:06:01,387] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:01,477] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:01,478] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:01,718] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:01,719] INFO [src.utils:19] 29
[2025-10-23 00:06:01,719] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:01,800] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:01,800] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:02,015] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:02,016] INFO [src.utils:19] 29
[2025-10-23 00:06:02,016] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:02,275] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:02,276] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:02,490] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:02,491] INFO [src.utils:19] 29
[2025-10-23 00:06:02,491] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:02,872] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:02,873] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:03,113] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:03,113] INFO [src.utils:19] 29
[2025-10-23 00:06:03,114] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:03,397] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:03,398] INFO [src.utils:19] torch.Size([8, 177, 1536])
[2025-10-23 00:06:03,640] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:03,641] INFO [src.utils:19] 29
[2025-10-23 00:06:03,641] INFO [src.utils:19] torch.Size([8, 177, 1536])
  3%|â–Ž         | 165/6000 [09:40<5:48:45,  3.59s/it]                                                    {'loss': 0.0273, 'grad_norm': 4.662596225738525, 'learning_rate': 4.9449152542372885e-05, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [09:40<5:48:45,  3.59s/it][2025-10-23 00:06:04,021] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:04,023] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:04,312] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:04,312] INFO [src.utils:19] 29
[2025-10-23 00:06:04,313] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:04,397] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:04,398] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:04,609] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:04,610] INFO [src.utils:19] 29
[2025-10-23 00:06:04,610] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:04,688] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:04,688] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:04,901] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:04,902] INFO [src.utils:19] 29
[2025-10-23 00:06:04,902] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:04,988] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:04,988] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:05,199] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:05,199] INFO [src.utils:19] 29
[2025-10-23 00:06:05,200] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:05,310] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:05,310] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:05,527] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:05,527] INFO [src.utils:19] 29
[2025-10-23 00:06:05,527] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:05,773] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:05,774] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:05,989] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:05,989] INFO [src.utils:19] 29
[2025-10-23 00:06:05,990] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:06,258] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:06,259] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:06,473] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:06,474] INFO [src.utils:19] 29
[2025-10-23 00:06:06,474] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:06,722] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:06,723] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:06,938] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:06,938] INFO [src.utils:19] 29
[2025-10-23 00:06:06,939] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 166/6000 [09:43<5:40:08,  3.50s/it]                                                    {'loss': 0.1385, 'grad_norm': 11.038455963134766, 'learning_rate': 4.9440677966101696e-05, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [09:43<5:40:08,  3.50s/it][2025-10-23 00:06:07,280] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:07,281] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:07,596] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:07,596] INFO [src.utils:19] 29
[2025-10-23 00:06:07,596] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:07,684] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:07,685] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:07,909] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:07,910] INFO [src.utils:19] 29
[2025-10-23 00:06:07,910] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:08,030] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:08,031] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:08,241] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:08,242] INFO [src.utils:19] 29
[2025-10-23 00:06:08,242] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:08,328] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:08,328] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:08,539] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:08,539] INFO [src.utils:19] 29
[2025-10-23 00:06:08,539] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:08,598] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:08,598] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:08,822] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:08,823] INFO [src.utils:19] 29
[2025-10-23 00:06:08,823] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:09,080] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:09,081] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:09,306] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:09,306] INFO [src.utils:19] 29
[2025-10-23 00:06:09,306] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:09,629] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:09,630] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:09,844] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:09,845] INFO [src.utils:19] 29
[2025-10-23 00:06:09,845] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:10,096] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:10,097] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:10,312] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:10,313] INFO [src.utils:19] 29
[2025-10-23 00:06:10,313] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 167/6000 [09:47<5:35:44,  3.45s/it]                                                    {'loss': 0.031, 'grad_norm': 5.513702869415283, 'learning_rate': 4.9432203389830514e-05, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [09:47<5:35:44,  3.45s/it][2025-10-23 00:06:10,690] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:10,691] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:11,035] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:11,036] INFO [src.utils:19] 29
[2025-10-23 00:06:11,036] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:11,124] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:11,125] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:11,351] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:11,352] INFO [src.utils:19] 29
[2025-10-23 00:06:11,352] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:11,411] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:11,411] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:11,623] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:11,623] INFO [src.utils:19] 29
[2025-10-23 00:06:11,623] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:11,717] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:11,717] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:11,928] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:11,929] INFO [src.utils:19] 29
[2025-10-23 00:06:11,929] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:12,062] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:12,063] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:12,293] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:12,294] INFO [src.utils:19] 29
[2025-10-23 00:06:12,294] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:12,558] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:12,559] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:12,789] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:12,789] INFO [src.utils:19] 29
[2025-10-23 00:06:12,790] INFO [src.utils:19] torch.Size([8, 164, 1536])
[2025-10-23 00:06:13,041] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:13,041] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:13,255] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:13,256] INFO [src.utils:19] 29
[2025-10-23 00:06:13,256] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:13,507] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:13,508] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:13,730] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:13,731] INFO [src.utils:19] 29
[2025-10-23 00:06:13,731] INFO [src.utils:19] torch.Size([8, 141, 1536])
  3%|â–Ž         | 168/6000 [09:50<5:34:48,  3.44s/it]                                                    {'loss': 0.1345, 'grad_norm': 10.79959774017334, 'learning_rate': 4.9423728813559326e-05, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [09:50<5:34:48,  3.44s/it][2025-10-23 00:06:14,040] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:14,041] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:14,373] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:14,373] INFO [src.utils:19] 29
[2025-10-23 00:06:14,373] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:14,463] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:14,463] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:14,690] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:14,691] INFO [src.utils:19] 29
[2025-10-23 00:06:14,691] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:14,835] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:14,836] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:15,118] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:15,118] INFO [src.utils:19] 29
[2025-10-23 00:06:15,119] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:15,213] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:15,214] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:15,491] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:15,492] INFO [src.utils:19] 29
[2025-10-23 00:06:15,492] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:15,560] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:15,561] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:15,785] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:15,786] INFO [src.utils:19] 29
[2025-10-23 00:06:15,786] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:16,043] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:16,043] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:16,270] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:16,270] INFO [src.utils:19] 29
[2025-10-23 00:06:16,271] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:16,609] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:16,609] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:16,894] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:16,895] INFO [src.utils:19] 29
[2025-10-23 00:06:16,895] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:17,233] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:17,234] INFO [src.utils:19] torch.Size([8, 249, 1536])
[2025-10-23 00:06:17,517] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:17,518] INFO [src.utils:19] 29
[2025-10-23 00:06:17,518] INFO [src.utils:19] torch.Size([8, 249, 1536])
  3%|â–Ž         | 169/6000 [09:54<5:46:54,  3.57s/it]                                                    {'loss': 0.146, 'grad_norm': 11.784440040588379, 'learning_rate': 4.941525423728814e-05, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [09:54<5:46:54,  3.57s/it][2025-10-23 00:06:17,901] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:17,903] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:18,210] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:18,210] INFO [src.utils:19] 29
[2025-10-23 00:06:18,211] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:18,348] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:18,349] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:18,559] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:18,560] INFO [src.utils:19] 29
[2025-10-23 00:06:18,560] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:18,682] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:18,682] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:18,892] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:18,892] INFO [src.utils:19] 29
[2025-10-23 00:06:18,893] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:18,943] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:18,943] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:19,152] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:19,153] INFO [src.utils:19] 29
[2025-10-23 00:06:19,153] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:19,211] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:19,211] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:19,425] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:19,425] INFO [src.utils:19] 29
[2025-10-23 00:06:19,425] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:19,727] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:19,727] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:19,944] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:19,945] INFO [src.utils:19] 29
[2025-10-23 00:06:19,945] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:20,269] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:20,270] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:20,486] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:20,486] INFO [src.utils:19] 29
[2025-10-23 00:06:20,487] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:20,700] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:20,701] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:20,921] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:20,921] INFO [src.utils:19] 29
[2025-10-23 00:06:20,921] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 170/6000 [09:57<5:40:17,  3.50s/it]                                                    {'loss': 0.1164, 'grad_norm': 7.326638698577881, 'learning_rate': 4.940677966101695e-05, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [09:57<5:40:17,  3.50s/it][2025-10-23 00:06:21,321] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:21,321] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:21,643] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:21,643] INFO [src.utils:19] 29
[2025-10-23 00:06:21,644] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:21,729] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:21,729] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:21,941] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:21,942] INFO [src.utils:19] 29
[2025-10-23 00:06:21,942] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:22,004] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:22,005] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:22,214] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:22,214] INFO [src.utils:19] 29
[2025-10-23 00:06:22,215] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:22,298] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:22,299] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:22,509] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:22,510] INFO [src.utils:19] 29
[2025-10-23 00:06:22,510] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:22,634] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:22,634] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:22,851] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:22,851] INFO [src.utils:19] 29
[2025-10-23 00:06:22,852] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:23,102] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:23,102] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:23,317] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:23,318] INFO [src.utils:19] 29
[2025-10-23 00:06:23,318] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:23,568] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:23,569] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:23,782] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:23,783] INFO [src.utils:19] 29
[2025-10-23 00:06:23,783] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:24,033] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:24,033] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:24,247] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:24,247] INFO [src.utils:19] 29
[2025-10-23 00:06:24,247] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 171/6000 [10:01<5:35:36,  3.45s/it]                                                    {'loss': 0.0533, 'grad_norm': 5.781655788421631, 'learning_rate': 4.9398305084745766e-05, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [10:01<5:35:36,  3.45s/it][2025-10-23 00:06:24,655] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:24,656] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:24,975] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:24,975] INFO [src.utils:19] 29
[2025-10-23 00:06:24,976] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:25,043] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:25,044] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:25,287] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:25,288] INFO [src.utils:19] 29
[2025-10-23 00:06:25,288] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:25,370] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:25,371] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:25,584] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:25,585] INFO [src.utils:19] 29
[2025-10-23 00:06:25,585] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:25,708] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:25,709] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:25,918] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:25,919] INFO [src.utils:19] 29
[2025-10-23 00:06:25,919] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:26,044] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:26,044] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:26,290] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:26,291] INFO [src.utils:19] 29
[2025-10-23 00:06:26,291] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:26,554] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:26,555] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:26,802] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:26,803] INFO [src.utils:19] 29
[2025-10-23 00:06:26,803] INFO [src.utils:19] torch.Size([8, 200, 1536])
[2025-10-23 00:06:27,095] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:27,096] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:27,313] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:27,314] INFO [src.utils:19] 29
[2025-10-23 00:06:27,314] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:27,609] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:27,610] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:27,822] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:27,823] INFO [src.utils:19] 29
[2025-10-23 00:06:27,823] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 172/6000 [10:04<5:38:03,  3.48s/it]                                                    {'loss': 0.1792, 'grad_norm': 17.1776180267334, 'learning_rate': 4.938983050847458e-05, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [10:04<5:38:03,  3.48s/it][2025-10-23 00:06:28,133] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:28,133] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:28,433] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:28,434] INFO [src.utils:19] 29
[2025-10-23 00:06:28,434] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:28,515] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:28,515] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:28,738] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:28,738] INFO [src.utils:19] 29
[2025-10-23 00:06:28,738] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:28,862] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:28,863] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:29,083] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:29,083] INFO [src.utils:19] 29
[2025-10-23 00:06:29,084] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:29,189] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:29,190] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:29,411] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:29,412] INFO [src.utils:19] 29
[2025-10-23 00:06:29,412] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:29,473] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:29,474] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:29,698] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:29,698] INFO [src.utils:19] 29
[2025-10-23 00:06:29,699] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:29,947] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:29,948] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:30,171] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:30,172] INFO [src.utils:19] 29
[2025-10-23 00:06:30,172] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:30,528] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:30,528] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:30,758] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:30,759] INFO [src.utils:19] 29
[2025-10-23 00:06:30,759] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:31,034] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:31,035] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:31,264] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:31,265] INFO [src.utils:19] 29
[2025-10-23 00:06:31,265] INFO [src.utils:19] torch.Size([8, 150, 1536])
  3%|â–Ž         | 173/6000 [10:08<5:37:13,  3.47s/it]                                                    {'loss': 0.1249, 'grad_norm': 14.899706840515137, 'learning_rate': 4.9381355932203396e-05, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [10:08<5:37:13,  3.47s/it][2025-10-23 00:06:31,625] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:31,626] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:31,987] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:31,988] INFO [src.utils:19] 29
[2025-10-23 00:06:31,988] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:32,122] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:32,123] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:32,405] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:32,406] INFO [src.utils:19] 29
[2025-10-23 00:06:32,406] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:32,485] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:32,485] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:32,697] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:32,697] INFO [src.utils:19] 29
[2025-10-23 00:06:32,698] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:32,775] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:32,776] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:32,986] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:32,986] INFO [src.utils:19] 29
[2025-10-23 00:06:32,987] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:33,093] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:33,093] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:33,377] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:33,378] INFO [src.utils:19] 29
[2025-10-23 00:06:33,378] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:33,758] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:33,759] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:34,046] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:34,047] INFO [src.utils:19] 29
[2025-10-23 00:06:34,047] INFO [src.utils:19] torch.Size([8, 254, 1536])
[2025-10-23 00:06:34,381] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:34,382] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:34,595] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:34,595] INFO [src.utils:19] 29
[2025-10-23 00:06:34,596] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:34,837] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:34,837] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:35,053] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:35,054] INFO [src.utils:19] 29
[2025-10-23 00:06:35,054] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 174/6000 [10:12<5:57:10,  3.68s/it]                                                    {'loss': 0.0033, 'grad_norm': 0.6708450317382812, 'learning_rate': 4.937288135593221e-05, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [10:12<5:57:10,  3.68s/it][2025-10-23 00:06:35,771] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:35,772] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:36,122] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:36,123] INFO [src.utils:19] 29
[2025-10-23 00:06:36,123] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:36,249] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:36,249] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:36,461] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:36,461] INFO [src.utils:19] 29
[2025-10-23 00:06:36,462] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:36,548] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:36,548] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:36,759] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:36,760] INFO [src.utils:19] 29
[2025-10-23 00:06:36,760] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:36,819] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:36,820] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:37,030] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:37,030] INFO [src.utils:19] 29
[2025-10-23 00:06:37,031] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:37,117] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:37,117] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:37,332] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:37,332] INFO [src.utils:19] 29
[2025-10-23 00:06:37,333] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:37,619] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:37,619] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:37,839] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:37,839] INFO [src.utils:19] 29
[2025-10-23 00:06:37,840] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:38,116] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:38,117] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:38,335] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:38,336] INFO [src.utils:19] 29
[2025-10-23 00:06:38,336] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:38,560] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:38,561] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:38,774] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:38,774] INFO [src.utils:19] 29
[2025-10-23 00:06:38,775] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 175/6000 [10:15<5:48:56,  3.59s/it]                                                    {'loss': 0.1599, 'grad_norm': 14.807619094848633, 'learning_rate': 4.936440677966102e-05, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [10:15<5:48:56,  3.59s/it][2025-10-23 00:06:39,166] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:39,168] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:39,518] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:39,519] INFO [src.utils:19] 29
[2025-10-23 00:06:39,519] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:39,593] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:39,594] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:39,806] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:39,807] INFO [src.utils:19] 29
[2025-10-23 00:06:39,807] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:39,895] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:39,896] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:40,108] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:40,109] INFO [src.utils:19] 29
[2025-10-23 00:06:40,109] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:40,213] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:40,214] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:40,425] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:40,425] INFO [src.utils:19] 29
[2025-10-23 00:06:40,426] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:40,549] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:40,550] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:40,765] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:40,766] INFO [src.utils:19] 29
[2025-10-23 00:06:40,766] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:40,994] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:40,995] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:41,210] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:41,210] INFO [src.utils:19] 29
[2025-10-23 00:06:41,210] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:41,839] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:41,840] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:42,058] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:42,058] INFO [src.utils:19] 29
[2025-10-23 00:06:42,059] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:42,327] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:42,327] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:42,547] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:42,547] INFO [src.utils:19] 29
[2025-10-23 00:06:42,548] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 176/6000 [10:19<5:52:15,  3.63s/it]                                                    {'loss': 0.0394, 'grad_norm': 8.411833763122559, 'learning_rate': 4.935593220338983e-05, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [10:19<5:52:15,  3.63s/it][2025-10-23 00:06:42,872] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:42,874] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:43,204] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:43,205] INFO [src.utils:19] 29
[2025-10-23 00:06:43,205] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:43,294] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:43,295] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:43,507] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:43,507] INFO [src.utils:19] 29
[2025-10-23 00:06:43,508] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:43,611] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:43,611] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:43,824] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:43,825] INFO [src.utils:19] 29
[2025-10-23 00:06:43,825] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:43,913] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:43,914] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:44,129] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:44,130] INFO [src.utils:19] 29
[2025-10-23 00:06:44,130] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:44,207] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:44,207] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:44,426] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:44,427] INFO [src.utils:19] 29
[2025-10-23 00:06:44,427] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:44,682] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:44,683] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:44,900] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:44,901] INFO [src.utils:19] 29
[2025-10-23 00:06:44,901] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:45,198] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:45,199] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:45,419] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:45,420] INFO [src.utils:19] 29
[2025-10-23 00:06:45,420] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:45,673] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:45,674] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:06:45,891] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:45,892] INFO [src.utils:19] 29
[2025-10-23 00:06:45,892] INFO [src.utils:19] torch.Size([8, 141, 1536])
  3%|â–Ž         | 177/6000 [10:22<5:44:50,  3.55s/it]                                                    {'loss': 0.0258, 'grad_norm': 4.353375434875488, 'learning_rate': 4.934745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [10:22<5:44:50,  3.55s/it][2025-10-23 00:06:46,261] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:46,262] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:46,567] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:46,568] INFO [src.utils:19] 29
[2025-10-23 00:06:46,568] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:46,676] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:46,677] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:46,900] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:46,901] INFO [src.utils:19] 29
[2025-10-23 00:06:46,901] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:46,990] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:46,990] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:47,211] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:47,212] INFO [src.utils:19] 29
[2025-10-23 00:06:47,212] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:47,296] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:47,296] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:47,520] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:47,520] INFO [src.utils:19] 29
[2025-10-23 00:06:47,520] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:47,612] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:47,612] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:47,838] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:47,839] INFO [src.utils:19] 29
[2025-10-23 00:06:47,839] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:48,125] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:48,126] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:48,352] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:48,353] INFO [src.utils:19] 29
[2025-10-23 00:06:48,353] INFO [src.utils:19] torch.Size([8, 155, 1536])
[2025-10-23 00:06:48,637] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:48,638] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:48,862] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:48,863] INFO [src.utils:19] 29
[2025-10-23 00:06:48,863] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:49,114] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:49,115] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:06:49,339] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:49,339] INFO [src.utils:19] 29
[2025-10-23 00:06:49,340] INFO [src.utils:19] torch.Size([8, 150, 1536])
  3%|â–Ž         | 178/6000 [10:26<5:40:44,  3.51s/it]                                                    {'loss': 0.0475, 'grad_norm': 6.696073055267334, 'learning_rate': 4.933898305084746e-05, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [10:26<5:40:44,  3.51s/it][2025-10-23 00:06:49,694] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:49,696] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:50,009] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:50,009] INFO [src.utils:19] 29
[2025-10-23 00:06:50,010] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:50,129] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:50,130] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:50,349] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:50,350] INFO [src.utils:19] 29
[2025-10-23 00:06:50,350] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:50,429] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:50,429] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:50,639] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:50,640] INFO [src.utils:19] 29
[2025-10-23 00:06:50,640] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:50,710] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:50,710] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:50,921] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:50,921] INFO [src.utils:19] 29
[2025-10-23 00:06:50,922] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:51,041] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:51,041] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:51,264] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:51,265] INFO [src.utils:19] 29
[2025-10-23 00:06:51,265] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:51,552] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:51,552] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:51,776] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:51,777] INFO [src.utils:19] 29
[2025-10-23 00:06:51,777] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:06:52,045] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:52,046] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:52,259] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:52,259] INFO [src.utils:19] 29
[2025-10-23 00:06:52,260] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:52,494] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:52,495] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:52,710] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:52,711] INFO [src.utils:19] 29
[2025-10-23 00:06:52,711] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 179/6000 [10:29<5:36:50,  3.47s/it]                                                    {'loss': 0.0415, 'grad_norm': 4.558033466339111, 'learning_rate': 4.933050847457628e-05, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [10:29<5:36:50,  3.47s/it][2025-10-23 00:06:53,084] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:53,085] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:53,427] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:53,428] INFO [src.utils:19] 29
[2025-10-23 00:06:53,428] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:53,518] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:53,518] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:53,757] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:53,758] INFO [src.utils:19] 29
[2025-10-23 00:06:53,758] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:53,818] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:53,819] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:54,032] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:54,033] INFO [src.utils:19] 29
[2025-10-23 00:06:54,033] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:54,137] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:54,137] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:54,346] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:54,347] INFO [src.utils:19] 29
[2025-10-23 00:06:54,347] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:54,470] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:54,471] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:54,711] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:54,712] INFO [src.utils:19] 29
[2025-10-23 00:06:54,712] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:54,993] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:54,994] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:55,235] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:55,235] INFO [src.utils:19] 29
[2025-10-23 00:06:55,236] INFO [src.utils:19] torch.Size([8, 182, 1536])
[2025-10-23 00:06:55,499] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:55,500] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:55,714] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:55,715] INFO [src.utils:19] 29
[2025-10-23 00:06:55,715] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:55,987] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:55,988] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:56,202] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:56,202] INFO [src.utils:19] 29
[2025-10-23 00:06:56,203] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 180/6000 [10:33<5:37:33,  3.48s/it]                                                    {'loss': 0.2622, 'grad_norm': 14.608837127685547, 'learning_rate': 4.932203389830509e-05, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [10:33<5:37:33,  3.48s/it][2025-10-23 00:06:56,544] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:56,544] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:56,882] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:56,882] INFO [src.utils:19] 29
[2025-10-23 00:06:56,883] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:57,007] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:57,008] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:57,224] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:57,224] INFO [src.utils:19] 29
[2025-10-23 00:06:57,225] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:57,347] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:57,348] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:57,559] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:57,559] INFO [src.utils:19] 29
[2025-10-23 00:06:57,560] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:57,616] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:57,617] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:57,828] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:57,828] INFO [src.utils:19] 29
[2025-10-23 00:06:57,829] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:57,887] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:57,888] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:58,103] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:58,104] INFO [src.utils:19] 29
[2025-10-23 00:06:58,104] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:58,390] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:58,391] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:58,609] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:58,609] INFO [src.utils:19] 29
[2025-10-23 00:06:58,610] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:06:58,985] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:58,986] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:59,205] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:59,206] INFO [src.utils:19] 29
[2025-10-23 00:06:59,206] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:59,426] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:06:59,427] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:06:59,640] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:06:59,641] INFO [src.utils:19] 29
[2025-10-23 00:06:59,641] INFO [src.utils:19] torch.Size([8, 132, 1536])
  3%|â–Ž         | 181/6000 [10:36<5:36:01,  3.46s/it]                                                    {'loss': 0.3055, 'grad_norm': 16.71727752685547, 'learning_rate': 4.9313559322033906e-05, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [10:36<5:36:01,  3.46s/it][2025-10-23 00:07:00,014] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:00,016] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:00,345] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:00,345] INFO [src.utils:19] 29
[2025-10-23 00:07:00,345] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:00,452] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:00,452] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:00,664] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:00,664] INFO [src.utils:19] 29
[2025-10-23 00:07:00,665] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:00,723] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:00,724] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:00,944] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:00,945] INFO [src.utils:19] 29
[2025-10-23 00:07:00,945] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:01,023] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:01,024] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:01,243] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:01,244] INFO [src.utils:19] 29
[2025-10-23 00:07:01,244] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:01,370] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:01,370] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:01,586] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:01,587] INFO [src.utils:19] 29
[2025-10-23 00:07:01,587] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:01,855] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:01,856] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:02,079] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:02,079] INFO [src.utils:19] 29
[2025-10-23 00:07:02,080] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:02,329] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:02,330] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:02,555] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:02,555] INFO [src.utils:19] 29
[2025-10-23 00:07:02,556] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:02,801] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:02,802] INFO [src.utils:19] torch.Size([8, 150, 1536])
[2025-10-23 00:07:03,026] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:03,026] INFO [src.utils:19] 29
[2025-10-23 00:07:03,027] INFO [src.utils:19] torch.Size([8, 150, 1536])
  3%|â–Ž         | 182/6000 [10:39<5:33:28,  3.44s/it]                                                    {'loss': 0.0165, 'grad_norm': 2.305588960647583, 'learning_rate': 4.930508474576271e-05, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [10:39<5:33:28,  3.44s/it][2025-10-23 00:07:03,374] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:03,374] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:03,650] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:03,651] INFO [src.utils:19] 29
[2025-10-23 00:07:03,651] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:03,708] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:03,708] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:03,921] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:03,921] INFO [src.utils:19] 29
[2025-10-23 00:07:03,922] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:04,000] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:04,001] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:04,212] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:04,213] INFO [src.utils:19] 29
[2025-10-23 00:07:04,213] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:04,335] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:04,336] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:04,549] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:04,549] INFO [src.utils:19] 29
[2025-10-23 00:07:04,550] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:04,676] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:04,676] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:04,890] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:04,890] INFO [src.utils:19] 29
[2025-10-23 00:07:04,891] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:05,110] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:05,111] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:05,326] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:05,327] INFO [src.utils:19] 29
[2025-10-23 00:07:05,327] INFO [src.utils:19] torch.Size([8, 137, 1536])
[2025-10-23 00:07:05,610] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:05,610] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:05,826] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:05,827] INFO [src.utils:19] 29
[2025-10-23 00:07:05,827] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:06,114] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:06,115] INFO [src.utils:19] torch.Size([8, 141, 1536])
[2025-10-23 00:07:06,331] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:06,332] INFO [src.utils:19] 29
[2025-10-23 00:07:06,332] INFO [src.utils:19] torch.Size([8, 141, 1536])
  3%|â–Ž         | 183/6000 [10:43<5:29:35,  3.40s/it]                                                    {'loss': 0.1336, 'grad_norm': 8.770509719848633, 'learning_rate': 4.929661016949153e-05, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [10:43<5:29:35,  3.40s/it][2025-10-23 00:07:06,710] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:06,711] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:07,010] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:07,010] INFO [src.utils:19] 29
[2025-10-23 00:07:07,010] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:07,087] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:07,088] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:07,307] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:07,308] INFO [src.utils:19] 29
[2025-10-23 00:07:07,308] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:07,361] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:07,361] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:07:07,572] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:07,572] INFO [src.utils:19] 29
[2025-10-23 00:07:07,572] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:07:07,677] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:07,678] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:07:07,888] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:07,889] INFO [src.utils:19] 29
[2025-10-23 00:07:07,889] INFO [src.utils:19] torch.Size([8, 132, 1536])
[2025-10-23 00:07:08,030] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:08,031] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:08,256] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:08,256] INFO [src.utils:19] 29
[2025-10-23 00:07:08,257] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:08,502] INFO [src.utils:19] INPUT_EMBEDS:
[2025-10-23 00:07:08,503] INFO [src.utils:19] torch.Size([8, 146, 1536])
[2025-10-23 00:07:08,732] INFO [src.utils:19] OUTPUTS:
[2025-10-23 00:07:08,733] INFO [src.utils:19] 29
[2025-10-23 00:07:08,733] INFO [src.utils:19] torch.Size([8, 146, 1536])
