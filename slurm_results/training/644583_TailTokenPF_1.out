==> Environment
Python: /home/infres/zzhu-24/anaconda3/envs/vlm2vec/bin/python
Version: Python 3.10.18

/home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=2207 --max_restarts=0 train.py --lora --lora_r 16 --model_name Qwen/Qwen2-VL-2B-Instruct --bf16 --pooling eos --normalize True --temperature 0.02 --dataloader_num_workers 1 --dataset_config /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/train/retrieval.yaml --data_basedir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/data/vlm2vec_train/MMEB-train --run_name TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct --output_dir /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct --grad_cache True --per_device_train_batch_size 16 --gc_q_chunk_size 8 --gc_p_chunk_size 8 --interleave_batch_size 0 --lr_scheduler_type linear --learning_rate 5e-5 --max_steps 6000 --warmup_steps 100 --save_steps 50 --logging_steps 1 --save_safetensors True --remove_unused_columns False --resume_from auto --plus_one_token True --report_to wandb 2>&1 | tee /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/train.log
W1020 23:05:21.083000 130616654071616 torch/distributed/run.py:779] 
W1020 23:05:21.083000 130616654071616 torch/distributed/run.py:779] *****************************************
W1020 23:05:21.083000 130616654071616 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1020 23:05:21.083000 130616654071616 torch/distributed/run.py:779] *****************************************
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/infres/zzhu-24/anaconda3/envs/vlm2vec/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
DropoutAddRMSNorm of flash_attn is not installed!!!
DropoutAddRMSNorm of flash_attn is not installed!!!
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
/home/infres/zzhu-24/PRIM/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @torch.cuda.amp.autocast(enabled=False)
Distributed init debug info:
RANK: 0
LOCAL_RANK: 0
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 0
torch.distributed.get_world_size(): 2
[2025-10-20 23:05:30,682] INFO [src.utils:10] rank0: init wandb
Distributed init debug info:
RANK: 1
LOCAL_RANK: 1
WORLD_SIZE: 2
MASTER_ADDR: 127.0.0.1
MASTER_PORT: 2207
torch.distributed.is_initialized: True
torch.distributed.get_rank(): 1
torch.distributed.get_world_size(): 2
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
wandb: Currently logged in as: zhuzhehua16 (zhuzhehua16-t-l-com-paris) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.12it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.94it/s]
wandb: setting up run 6h9bcgh3
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/wandb/run-20251020_230530-6h9bcgh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct
wandb: â­ï¸ View project at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train
wandb: ðŸš€ View run at https://wandb.ai/zhuzhehua16-t-l-com-paris/vlm2vec_train/runs/6h9bcgh3
[2025-10-20 23:05:32,278] INFO [src.utils:19] Loading backbone [qwen2_vl] from Qwen/Qwen2-VL-2B-Instruct
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  4.24it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.12it/s]
[2025-10-20 23:05:32,955] INFO [src.utils:19] Enabling TailTokenWrapper (learnable tail token).
[2025-10-20 23:05:32,960] INFO [src.utils:19] Loading lora adapter from TailTokenDetachPrefixWrapper(
  (base): Qwen2VLForConditionalGeneration(
    (visual): Qwen2VisionTransformerPretrainedModel(
      (patch_embed): PatchEmbed(
        (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
      )
      (rotary_pos_emb): VisionRotaryEmbedding()
      (blocks): ModuleList(
        (0-31): 32 x Qwen2VLVisionBlock(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): VisionFlashAttention2(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
          )
          (mlp): VisionMlp(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): QuickGELUActivation()
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          )
        )
      )
      (merger): PatchMerger(
        (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=5120, out_features=5120, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=5120, out_features=1536, bias=True)
        )
      )
    )
    (model): Qwen2VLModel(
      (embed_tokens): Embedding(151936, 1536)
      (layers): ModuleList(
        (0-27): 28 x Qwen2VLDecoderLayer(
          (self_attn): Qwen2VLFlashAttention2(
            (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
            (k_proj): Linear(in_features=1536, out_features=256, bias=True)
            (v_proj): Linear(in_features=1536, out_features=256, bias=True)
            (o_proj): Linear(in_features=1536, out_features=1536, bias=False)
            (rotary_emb): Qwen2VLRotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)
            (up_proj): Linear(in_features=1536, out_features=8960, bias=False)
            (down_proj): Linear(in_features=8960, out_features=1536, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
          (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)
        )
      )
      (norm): Qwen2RMSNorm((1536,), eps=1e-06)
      (rotary_emb): Qwen2VLRotaryEmbedding()
    )
    (lm_head): Linear(in_features=1536, out_features=151936, bias=False)
  )
)
[2025-10-20 23:05:41,883] INFO [src.utils:10] rank1: model_backbone: qwen2_vl
[2025-10-20 23:05:43,178] INFO [src.utils:10] rank0: model_backbone: qwen2_vl
[2025-10-20 23:05:43,179] INFO [src.utils:19] Loading processor from: Qwen/Qwen2-VL-2B-Instruct
[2025-10-20 23:05:47,760] INFO [src.utils:19] Loaded mmeb/MSCOCO_t2i dataset with 100000 samples
[2025-10-20 23:05:47,761] INFO [src.utils:19] 		Dataset#0 (dataset_parser=mmeb): MSCOCO_t2i, num_rows=100000, prob=50.0
[2025-10-20 23:05:48,667] INFO [src.utils:19] Loaded mmeb/MSCOCO_i2t dataset with 113287 samples
[2025-10-20 23:05:48,667] INFO [src.utils:19] 		Dataset#1 (dataset_parser=mmeb): MSCOCO_i2t, num_rows=113287, prob=50.0
[2025-10-20 23:05:48,668] INFO [src.utils:19] 
Initializing interleave datasets:
		world_size=2
		total num rows=213287
		global batch size=32
		estimated num step per epoch=6665.21875
		interleave_batch_size=0.0
[2025-10-20 23:05:48,670] INFO [src.utils:19] ==================================================
[2025-10-20 23:05:48,670] INFO [src.utils:19] Print the features of each dataset, make sure that all datasets have valid features.
[2025-10-20 23:05:48,672] INFO [src.utils:19] 		Dataset 0 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-20 23:05:48,673] INFO [src.utils:19] 		Dataset 1 features: ['query_text', 'query_image', 'pos_text', 'pos_image', 'neg_text', 'neg_image', 'global_dataset_name']
[2025-10-20 23:05:48,673] INFO [src.utils:19] ==================================================
[2025-10-20 23:05:50,558] INFO [src.trainer:342] ***** Running training *****
[2025-10-20 23:05:50,558] INFO [src.trainer:342] ***** Running training *****
[2025-10-20 23:05:50,558] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-20 23:05:50,558] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-20 23:05:50,558] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-20 23:05:50,558] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-20 23:05:50,559] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-20 23:05:50,559] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-20 23:05:50,559] INFO [src.trainer:343]   Num examples = 192,000
[2025-10-20 23:05:50,559] INFO [src.trainer:344]   Num Epochs = 9,223,372,036,854,775,807
[2025-10-20 23:05:50,560] INFO [src.trainer:345]   Instantaneous batch size per device = 16
[2025-10-20 23:05:50,560] INFO [src.trainer:348]   Total train batch size (w. parallel, distributed & accumulation) = 32
[2025-10-20 23:05:50,560] INFO [src.trainer:349]   Gradient Accumulation steps = 1
[2025-10-20 23:05:50,561] INFO [src.trainer:350]   Total optimization steps = 6,000
[2025-10-20 23:05:50,570] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
[2025-10-20 23:05:50,573] INFO [src.trainer:351]   Number of trainable parameters = 9,203,712
  0%|          | 0/6000 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[rank0]:[W1020 23:05:53.616693917 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1020 23:05:53.651725002 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/6000 [00:04<6:45:32,  4.06s/it]                                                  {'loss': 11.3157, 'grad_norm': 587.288330078125, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.0}
  0%|          | 1/6000 [00:04<6:45:32,  4.06s/it]  0%|          | 2/6000 [00:06<5:20:36,  3.21s/it]                                                  {'loss': 9.8914, 'grad_norm': 517.7246704101562, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
  0%|          | 2/6000 [00:06<5:20:36,  3.21s/it]  0%|          | 3/6000 [00:09<4:57:57,  2.98s/it]                                                  {'loss': 9.2857, 'grad_norm': 551.9386596679688, 'learning_rate': 1.5e-06, 'epoch': 0.0}
  0%|          | 3/6000 [00:09<4:57:57,  2.98s/it]  0%|          | 4/6000 [00:12<4:45:26,  2.86s/it]                                                  {'loss': 9.2629, 'grad_norm': 496.9521179199219, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
  0%|          | 4/6000 [00:12<4:45:26,  2.86s/it]  0%|          | 5/6000 [00:14<4:39:23,  2.80s/it]                                                  {'loss': 9.7731, 'grad_norm': 493.8416442871094, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 5/6000 [00:14<4:39:23,  2.80s/it]  0%|          | 6/6000 [00:17<4:34:54,  2.75s/it]                                                  {'loss': 9.6004, 'grad_norm': 524.9635009765625, 'learning_rate': 3e-06, 'epoch': 0.0}
  0%|          | 6/6000 [00:17<4:34:54,  2.75s/it]  0%|          | 7/6000 [00:20<4:31:15,  2.72s/it]                                                  {'loss': 9.4869, 'grad_norm': 509.7833251953125, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 7/6000 [00:20<4:31:15,  2.72s/it]  0%|          | 8/6000 [00:22<4:26:42,  2.67s/it]                                                  {'loss': 8.6097, 'grad_norm': 515.5656127929688, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}
  0%|          | 8/6000 [00:22<4:26:42,  2.67s/it]  0%|          | 9/6000 [00:25<4:27:53,  2.68s/it]                                                  {'loss': 6.1104, 'grad_norm': 314.4935607910156, 'learning_rate': 4.5e-06, 'epoch': 0.0}
  0%|          | 9/6000 [00:25<4:27:53,  2.68s/it]  0%|          | 10/6000 [00:27<4:26:31,  2.67s/it]                                                   {'loss': 7.0737, 'grad_norm': 578.0059204101562, 'learning_rate': 5e-06, 'epoch': 0.0}
  0%|          | 10/6000 [00:27<4:26:31,  2.67s/it]  0%|          | 11/6000 [00:30<4:35:41,  2.76s/it]                                                   {'loss': 6.0322, 'grad_norm': 816.0895385742188, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.0}
  0%|          | 11/6000 [00:30<4:35:41,  2.76s/it]  0%|          | 12/6000 [00:33<4:37:02,  2.78s/it]                                                   {'loss': 4.8954, 'grad_norm': 505.06134033203125, 'learning_rate': 6e-06, 'epoch': 0.0}
  0%|          | 12/6000 [00:33<4:37:02,  2.78s/it]  0%|          | 13/6000 [00:36<4:33:39,  2.74s/it]                                                   {'loss': 4.3027, 'grad_norm': 214.46058654785156, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.0}
  0%|          | 13/6000 [00:36<4:33:39,  2.74s/it]  0%|          | 14/6000 [00:39<4:35:32,  2.76s/it]                                                   {'loss': 3.9085, 'grad_norm': 203.45628356933594, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}
  0%|          | 14/6000 [00:39<4:35:32,  2.76s/it]  0%|          | 15/6000 [00:41<4:32:42,  2.73s/it]                                                   {'loss': 3.4828, 'grad_norm': 179.69520568847656, 'learning_rate': 7.5e-06, 'epoch': 0.0}
  0%|          | 15/6000 [00:41<4:32:42,  2.73s/it]  0%|          | 16/6000 [00:44<4:30:00,  2.71s/it]                                                   {'loss': 3.836, 'grad_norm': 116.94832611083984, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}
  0%|          | 16/6000 [00:44<4:30:00,  2.71s/it]  0%|          | 17/6000 [00:47<4:29:12,  2.70s/it]                                                   {'loss': 3.4714, 'grad_norm': 107.02001190185547, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.0}
  0%|          | 17/6000 [00:47<4:29:12,  2.70s/it]  0%|          | 18/6000 [00:49<4:29:59,  2.71s/it]                                                   {'loss': 2.9454, 'grad_norm': 48.719383239746094, 'learning_rate': 9e-06, 'epoch': 0.0}
  0%|          | 18/6000 [00:49<4:29:59,  2.71s/it]  0%|          | 19/6000 [00:52<4:27:58,  2.69s/it]                                                   {'loss': 3.2915, 'grad_norm': 92.28588104248047, 'learning_rate': 9.5e-06, 'epoch': 0.0}
  0%|          | 19/6000 [00:52<4:27:58,  2.69s/it]  0%|          | 20/6000 [00:55<4:25:42,  2.67s/it]                                                   {'loss': 3.111, 'grad_norm': 47.19529724121094, 'learning_rate': 1e-05, 'epoch': 0.0}
  0%|          | 20/6000 [00:55<4:25:42,  2.67s/it]  0%|          | 21/6000 [00:58<4:29:58,  2.71s/it]                                                   {'loss': 2.8736, 'grad_norm': 27.932842254638672, 'learning_rate': 1.05e-05, 'epoch': 0.0}
  0%|          | 21/6000 [00:58<4:29:58,  2.71s/it]  0%|          | 22/6000 [01:00<4:29:43,  2.71s/it]                                                   {'loss': 3.0641, 'grad_norm': 95.80868530273438, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}
  0%|          | 22/6000 [01:00<4:29:43,  2.71s/it]  0%|          | 23/6000 [01:03<4:27:13,  2.68s/it]                                                   {'loss': 3.167, 'grad_norm': 79.64431762695312, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.0}
  0%|          | 23/6000 [01:03<4:27:13,  2.68s/it]  0%|          | 24/6000 [01:06<4:28:02,  2.69s/it]                                                   {'loss': 3.0355, 'grad_norm': 26.84165382385254, 'learning_rate': 1.2e-05, 'epoch': 0.0}
  0%|          | 24/6000 [01:06<4:28:02,  2.69s/it]  0%|          | 25/6000 [01:08<4:26:47,  2.68s/it]                                                   {'loss': 2.8735, 'grad_norm': 30.135061264038086, 'learning_rate': 1.25e-05, 'epoch': 0.0}
  0%|          | 25/6000 [01:08<4:26:47,  2.68s/it]  0%|          | 26/6000 [01:11<4:29:25,  2.71s/it]                                                   {'loss': 2.8384, 'grad_norm': 17.661075592041016, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}
  0%|          | 26/6000 [01:11<4:29:25,  2.71s/it]  0%|          | 27/6000 [01:14<4:31:21,  2.73s/it]                                                   {'loss': 2.8764, 'grad_norm': 21.97965431213379, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.0}
  0%|          | 27/6000 [01:14<4:31:21,  2.73s/it]  0%|          | 28/6000 [01:17<4:56:00,  2.97s/it]                                                   {'loss': 2.8707, 'grad_norm': 41.44736099243164, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}
  0%|          | 28/6000 [01:17<4:56:00,  2.97s/it]  0%|          | 29/6000 [01:20<4:45:11,  2.87s/it]                                                   {'loss': 2.8205, 'grad_norm': 13.678866386413574, 'learning_rate': 1.45e-05, 'epoch': 0.0}
  0%|          | 29/6000 [01:20<4:45:11,  2.87s/it]  0%|          | 30/6000 [01:23<4:39:53,  2.81s/it]                                                   {'loss': 2.8259, 'grad_norm': 16.472068786621094, 'learning_rate': 1.5e-05, 'epoch': 0.01}
  0%|          | 30/6000 [01:23<4:39:53,  2.81s/it]  1%|          | 31/6000 [01:25<4:35:23,  2.77s/it]                                                   {'loss': 2.8353, 'grad_norm': 18.547687530517578, 'learning_rate': 1.55e-05, 'epoch': 0.01}
  1%|          | 31/6000 [01:25<4:35:23,  2.77s/it]  1%|          | 32/6000 [01:28<4:32:35,  2.74s/it]                                                   {'loss': 2.7929, 'grad_norm': 9.188615798950195, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.01}
  1%|          | 32/6000 [01:28<4:32:35,  2.74s/it]  1%|          | 33/6000 [01:31<4:30:36,  2.72s/it]                                                   {'loss': 2.8519, 'grad_norm': 72.8949203491211, 'learning_rate': 1.65e-05, 'epoch': 0.01}
  1%|          | 33/6000 [01:31<4:30:36,  2.72s/it]  1%|          | 34/6000 [01:33<4:29:39,  2.71s/it]                                                   {'loss': 2.8516, 'grad_norm': 10.591041564941406, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.01}
  1%|          | 34/6000 [01:33<4:29:39,  2.71s/it]  1%|          | 35/6000 [01:36<4:29:46,  2.71s/it]                                                   {'loss': 2.8113, 'grad_norm': 9.903040885925293, 'learning_rate': 1.75e-05, 'epoch': 0.01}
  1%|          | 35/6000 [01:36<4:29:46,  2.71s/it]  1%|          | 36/6000 [01:39<4:26:54,  2.69s/it]                                                   {'loss': 2.8039, 'grad_norm': 7.8234734535217285, 'learning_rate': 1.8e-05, 'epoch': 0.01}
  1%|          | 36/6000 [01:39<4:26:54,  2.69s/it]  1%|          | 37/6000 [01:41<4:25:33,  2.67s/it]                                                   {'loss': 2.7943, 'grad_norm': 5.397747039794922, 'learning_rate': 1.85e-05, 'epoch': 0.01}
  1%|          | 37/6000 [01:41<4:25:33,  2.67s/it]  1%|          | 38/6000 [01:44<4:23:59,  2.66s/it]                                                   {'loss': 2.7844, 'grad_norm': 7.07188081741333, 'learning_rate': 1.9e-05, 'epoch': 0.01}
  1%|          | 38/6000 [01:44<4:23:59,  2.66s/it]  1%|          | 39/6000 [01:47<4:24:56,  2.67s/it]                                                   {'loss': 2.8519, 'grad_norm': 5.06279182434082, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.01}
  1%|          | 39/6000 [01:47<4:24:56,  2.67s/it]  1%|          | 40/6000 [01:49<4:25:49,  2.68s/it]                                                   {'loss': 2.805, 'grad_norm': 9.623373985290527, 'learning_rate': 2e-05, 'epoch': 0.01}
  1%|          | 40/6000 [01:49<4:25:49,  2.68s/it]  1%|          | 41/6000 [01:52<4:25:35,  2.67s/it]                                                   {'loss': 2.7864, 'grad_norm': 6.2884602546691895, 'learning_rate': 2.05e-05, 'epoch': 0.01}
  1%|          | 41/6000 [01:52<4:25:35,  2.67s/it]  1%|          | 42/6000 [01:55<4:27:20,  2.69s/it]                                                   {'loss': 2.7782, 'grad_norm': 4.479832649230957, 'learning_rate': 2.1e-05, 'epoch': 0.01}
  1%|          | 42/6000 [01:55<4:27:20,  2.69s/it]  1%|          | 43/6000 [01:58<4:58:40,  3.01s/it]                                                   {'loss': 2.8121, 'grad_norm': 17.910907745361328, 'learning_rate': 2.15e-05, 'epoch': 0.01}
  1%|          | 43/6000 [01:58<4:58:40,  3.01s/it]  1%|          | 44/6000 [02:02<5:02:43,  3.05s/it]                                                   {'loss': 2.778, 'grad_norm': 4.881304740905762, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.01}
  1%|          | 44/6000 [02:02<5:02:43,  3.05s/it]  1%|          | 45/6000 [02:04<4:53:10,  2.95s/it]                                                   {'loss': 2.7959, 'grad_norm': 3.859172821044922, 'learning_rate': 2.25e-05, 'epoch': 0.01}
  1%|          | 45/6000 [02:04<4:53:10,  2.95s/it]  1%|          | 46/6000 [02:07<4:47:29,  2.90s/it]                                                   {'loss': 2.7824, 'grad_norm': 4.692164421081543, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01}
  1%|          | 46/6000 [02:07<4:47:29,  2.90s/it]  1%|          | 47/6000 [02:10<4:41:12,  2.83s/it]                                                   {'loss': 2.7727, 'grad_norm': 3.4040582180023193, 'learning_rate': 2.35e-05, 'epoch': 0.01}
  1%|          | 47/6000 [02:10<4:41:12,  2.83s/it]  1%|          | 48/6000 [02:13<4:39:58,  2.82s/it]                                                   {'loss': 2.7881, 'grad_norm': 3.820789098739624, 'learning_rate': 2.4e-05, 'epoch': 0.01}
  1%|          | 48/6000 [02:13<4:39:58,  2.82s/it]  1%|          | 49/6000 [02:15<4:34:19,  2.77s/it]                                                   {'loss': 2.7834, 'grad_norm': 3.42459774017334, 'learning_rate': 2.45e-05, 'epoch': 0.01}
  1%|          | 49/6000 [02:15<4:34:19,  2.77s/it]  1%|          | 50/6000 [02:18<4:36:56,  2.79s/it]                                                   {'loss': 2.7773, 'grad_norm': 3.513841390609741, 'learning_rate': 2.5e-05, 'epoch': 0.01}
  1%|          | 50/6000 [02:18<4:36:56,  2.79s/it][2025-10-20 23:08:09,322] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-50
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  1%|          | 51/6000 [02:23<5:31:08,  3.34s/it]                                                   {'loss': 2.7937, 'grad_norm': 2.8180456161499023, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.01}
  1%|          | 51/6000 [02:23<5:31:08,  3.34s/it]  1%|          | 52/6000 [02:25<5:10:27,  3.13s/it]                                                   {'loss': 2.79, 'grad_norm': 2.7743303775787354, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}
  1%|          | 52/6000 [02:25<5:10:27,  3.13s/it]  1%|          | 53/6000 [02:28<4:59:08,  3.02s/it]                                                   {'loss': 2.8525, 'grad_norm': 3.211313247680664, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.01}
  1%|          | 53/6000 [02:28<4:59:08,  3.02s/it]  1%|          | 54/6000 [02:31<4:47:03,  2.90s/it]                                                   {'loss': 2.7853, 'grad_norm': 2.7044684886932373, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}
  1%|          | 54/6000 [02:31<4:47:03,  2.90s/it]  1%|          | 55/6000 [02:33<4:39:44,  2.82s/it]                                                   {'loss': 2.7912, 'grad_norm': 3.0437710285186768, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.01}
  1%|          | 55/6000 [02:33<4:39:44,  2.82s/it]  1%|          | 56/6000 [02:36<4:36:56,  2.80s/it]                                                   {'loss': 2.7823, 'grad_norm': 3.1245501041412354, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}
  1%|          | 56/6000 [02:36<4:36:56,  2.80s/it]  1%|          | 57/6000 [02:39<4:33:06,  2.76s/it]                                                   {'loss': 2.7763, 'grad_norm': 2.686063766479492, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.01}
  1%|          | 57/6000 [02:39<4:33:06,  2.76s/it]  1%|          | 58/6000 [02:41<4:30:59,  2.74s/it]                                                   {'loss': 2.7724, 'grad_norm': 2.571989059448242, 'learning_rate': 2.9e-05, 'epoch': 0.01}
  1%|          | 58/6000 [02:41<4:30:59,  2.74s/it]  1%|          | 59/6000 [02:44<4:26:04,  2.69s/it]                                                   {'loss': 2.7785, 'grad_norm': 2.99018931388855, 'learning_rate': 2.95e-05, 'epoch': 0.01}
  1%|          | 59/6000 [02:44<4:26:04,  2.69s/it]  1%|          | 60/6000 [02:47<4:23:24,  2.66s/it]                                                   {'loss': 2.7792, 'grad_norm': 3.149317979812622, 'learning_rate': 3e-05, 'epoch': 0.01}
  1%|          | 60/6000 [02:47<4:23:24,  2.66s/it]  1%|          | 61/6000 [02:49<4:21:51,  2.65s/it]                                                   {'loss': 2.8013, 'grad_norm': 3.4895434379577637, 'learning_rate': 3.05e-05, 'epoch': 0.01}
  1%|          | 61/6000 [02:49<4:21:51,  2.65s/it]  1%|          | 62/6000 [02:52<4:22:49,  2.66s/it]                                                   {'loss': 2.7926, 'grad_norm': 2.966783285140991, 'learning_rate': 3.1e-05, 'epoch': 0.01}
  1%|          | 62/6000 [02:52<4:22:49,  2.66s/it]  1%|          | 63/6000 [02:55<4:22:50,  2.66s/it]                                                   {'loss': 2.7841, 'grad_norm': 3.3866817951202393, 'learning_rate': 3.15e-05, 'epoch': 0.01}
  1%|          | 63/6000 [02:55<4:22:50,  2.66s/it]  1%|          | 64/6000 [02:57<4:21:32,  2.64s/it]                                                   {'loss': 2.7722, 'grad_norm': 2.759335994720459, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.01}
  1%|          | 64/6000 [02:57<4:21:32,  2.64s/it]  1%|          | 65/6000 [03:00<4:19:59,  2.63s/it]                                                   {'loss': 2.7938, 'grad_norm': 3.445103883743286, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.01}
  1%|          | 65/6000 [03:00<4:19:59,  2.63s/it]  1%|          | 66/6000 [03:03<4:32:58,  2.76s/it]                                                   {'loss': 2.7905, 'grad_norm': 4.096024513244629, 'learning_rate': 3.3e-05, 'epoch': 0.01}
  1%|          | 66/6000 [03:03<4:32:58,  2.76s/it]  1%|          | 67/6000 [03:06<4:31:01,  2.74s/it]                                                   {'loss': 2.795, 'grad_norm': 2.576482057571411, 'learning_rate': 3.35e-05, 'epoch': 0.01}
  1%|          | 67/6000 [03:06<4:31:01,  2.74s/it]  1%|          | 68/6000 [03:08<4:26:41,  2.70s/it]                                                   {'loss': 2.7843, 'grad_norm': 2.542675495147705, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.01}
  1%|          | 68/6000 [03:08<4:26:41,  2.70s/it]  1%|          | 69/6000 [03:11<4:25:18,  2.68s/it]                                                   {'loss': 2.789, 'grad_norm': 1.9613909721374512, 'learning_rate': 3.45e-05, 'epoch': 0.01}
  1%|          | 69/6000 [03:11<4:25:18,  2.68s/it]  1%|          | 70/6000 [03:14<4:37:02,  2.80s/it]                                                   {'loss': 2.7946, 'grad_norm': 2.426105260848999, 'learning_rate': 3.5e-05, 'epoch': 0.01}
  1%|          | 70/6000 [03:14<4:37:02,  2.80s/it]  1%|          | 71/6000 [03:16<4:31:35,  2.75s/it]                                                   {'loss': 2.7703, 'grad_norm': 2.729957342147827, 'learning_rate': 3.55e-05, 'epoch': 0.01}
  1%|          | 71/6000 [03:16<4:31:35,  2.75s/it]  1%|          | 72/6000 [03:19<4:39:33,  2.83s/it]                                                   {'loss': 2.7799, 'grad_norm': 3.8648416996002197, 'learning_rate': 3.6e-05, 'epoch': 0.01}
  1%|          | 72/6000 [03:19<4:39:33,  2.83s/it]  1%|          | 73/6000 [03:22<4:35:40,  2.79s/it]                                                   {'loss': 2.8293, 'grad_norm': 3.269425392150879, 'learning_rate': 3.65e-05, 'epoch': 0.01}
  1%|          | 73/6000 [03:22<4:35:40,  2.79s/it]  1%|          | 74/6000 [03:25<4:31:00,  2.74s/it]                                                   {'loss': 2.7799, 'grad_norm': 3.2774224281311035, 'learning_rate': 3.7e-05, 'epoch': 0.01}
  1%|          | 74/6000 [03:25<4:31:00,  2.74s/it]  1%|â–         | 75/6000 [03:27<4:27:52,  2.71s/it]                                                   {'loss': 2.7914, 'grad_norm': 2.118546724319458, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.01}
  1%|â–         | 75/6000 [03:27<4:27:52,  2.71s/it]  1%|â–         | 76/6000 [03:30<4:30:26,  2.74s/it]                                                   {'loss': 2.8024, 'grad_norm': 2.654898166656494, 'learning_rate': 3.8e-05, 'epoch': 0.01}
  1%|â–         | 76/6000 [03:30<4:30:26,  2.74s/it]  1%|â–         | 77/6000 [03:33<4:30:02,  2.74s/it]                                                   {'loss': 2.842, 'grad_norm': 2.188692331314087, 'learning_rate': 3.85e-05, 'epoch': 0.01}
  1%|â–         | 77/6000 [03:33<4:30:02,  2.74s/it]  1%|â–         | 78/6000 [03:36<4:38:51,  2.83s/it]                                                   {'loss': 2.778, 'grad_norm': 2.618650197982788, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 78/6000 [03:36<4:38:51,  2.83s/it]  1%|â–         | 79/6000 [03:39<4:35:01,  2.79s/it]                                                   {'loss': 2.7772, 'grad_norm': 3.5796315670013428, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.01}
  1%|â–         | 79/6000 [03:39<4:35:01,  2.79s/it]  1%|â–         | 80/6000 [03:42<4:42:33,  2.86s/it]                                                   {'loss': 2.7751, 'grad_norm': 5.273881435394287, 'learning_rate': 4e-05, 'epoch': 0.01}
  1%|â–         | 80/6000 [03:42<4:42:33,  2.86s/it]  1%|â–         | 81/6000 [03:44<4:37:58,  2.82s/it]                                                   {'loss': 2.7767, 'grad_norm': 4.937387943267822, 'learning_rate': 4.05e-05, 'epoch': 0.01}
  1%|â–         | 81/6000 [03:44<4:37:58,  2.82s/it]  1%|â–         | 82/6000 [03:47<4:35:08,  2.79s/it]                                                   {'loss': 2.7807, 'grad_norm': 3.8500566482543945, 'learning_rate': 4.1e-05, 'epoch': 0.01}
  1%|â–         | 82/6000 [03:47<4:35:08,  2.79s/it]  1%|â–         | 83/6000 [03:50<4:30:58,  2.75s/it]                                                   {'loss': 2.7903, 'grad_norm': 2.3398261070251465, 'learning_rate': 4.15e-05, 'epoch': 0.01}
  1%|â–         | 83/6000 [03:50<4:30:58,  2.75s/it]  1%|â–         | 84/6000 [03:53<4:31:14,  2.75s/it]                                                   {'loss': 2.7784, 'grad_norm': 3.5369060039520264, 'learning_rate': 4.2e-05, 'epoch': 0.01}
  1%|â–         | 84/6000 [03:53<4:31:14,  2.75s/it]  1%|â–         | 85/6000 [03:56<4:39:06,  2.83s/it]                                                   {'loss': 2.7854, 'grad_norm': 3.9350228309631348, 'learning_rate': 4.25e-05, 'epoch': 0.01}
  1%|â–         | 85/6000 [03:56<4:39:06,  2.83s/it]  1%|â–         | 86/6000 [03:58<4:33:27,  2.77s/it]                                                   {'loss': 2.791, 'grad_norm': 3.966115713119507, 'learning_rate': 4.3e-05, 'epoch': 0.01}
  1%|â–         | 86/6000 [03:58<4:33:27,  2.77s/it]  1%|â–         | 87/6000 [04:01<4:29:29,  2.73s/it]                                                   {'loss': 2.804, 'grad_norm': 4.649837493896484, 'learning_rate': 4.35e-05, 'epoch': 0.01}
  1%|â–         | 87/6000 [04:01<4:29:29,  2.73s/it]  1%|â–         | 88/6000 [04:04<4:26:26,  2.70s/it]                                                   {'loss': 2.7838, 'grad_norm': 3.401066541671753, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}
  1%|â–         | 88/6000 [04:04<4:26:26,  2.70s/it]  1%|â–         | 89/6000 [04:06<4:22:46,  2.67s/it]                                                   {'loss': 2.7792, 'grad_norm': 2.13543963432312, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}
  1%|â–         | 89/6000 [04:06<4:22:46,  2.67s/it]  2%|â–         | 90/6000 [04:09<4:24:38,  2.69s/it]                                                   {'loss': 2.827, 'grad_norm': 2.6433298587799072, 'learning_rate': 4.5e-05, 'epoch': 0.01}
  2%|â–         | 90/6000 [04:09<4:24:38,  2.69s/it]  2%|â–         | 91/6000 [04:12<4:25:21,  2.69s/it]                                                   {'loss': 2.7616, 'grad_norm': 3.1090779304504395, 'learning_rate': 4.55e-05, 'epoch': 0.02}
  2%|â–         | 91/6000 [04:12<4:25:21,  2.69s/it]  2%|â–         | 92/6000 [04:15<4:35:42,  2.80s/it]                                                   {'loss': 2.7787, 'grad_norm': 3.0837039947509766, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.02}
  2%|â–         | 92/6000 [04:15<4:35:42,  2.80s/it]  2%|â–         | 93/6000 [04:17<4:35:46,  2.80s/it]                                                   {'loss': 2.7742, 'grad_norm': 2.318572521209717, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.02}
  2%|â–         | 93/6000 [04:17<4:35:46,  2.80s/it]  2%|â–         | 94/6000 [04:20<4:31:57,  2.76s/it]                                                   {'loss': 2.795, 'grad_norm': 2.5214178562164307, 'learning_rate': 4.7e-05, 'epoch': 0.02}
  2%|â–         | 94/6000 [04:20<4:31:57,  2.76s/it]  2%|â–         | 95/6000 [04:23<4:29:29,  2.74s/it]                                                   {'loss': 2.7737, 'grad_norm': 2.0765774250030518, 'learning_rate': 4.75e-05, 'epoch': 0.02}
  2%|â–         | 95/6000 [04:23<4:29:29,  2.74s/it]  2%|â–         | 96/6000 [04:25<4:27:14,  2.72s/it]                                                   {'loss': 2.7714, 'grad_norm': 2.600318193435669, 'learning_rate': 4.8e-05, 'epoch': 0.02}
  2%|â–         | 96/6000 [04:25<4:27:14,  2.72s/it]  2%|â–         | 97/6000 [04:28<4:24:41,  2.69s/it]                                                   {'loss': 2.7624, 'grad_norm': 3.7605841159820557, 'learning_rate': 4.85e-05, 'epoch': 0.02}
  2%|â–         | 97/6000 [04:28<4:24:41,  2.69s/it]  2%|â–         | 98/6000 [04:31<4:23:13,  2.68s/it]                                                   {'loss': 2.7686, 'grad_norm': 4.912299156188965, 'learning_rate': 4.9e-05, 'epoch': 0.02}
  2%|â–         | 98/6000 [04:31<4:23:13,  2.68s/it]  2%|â–         | 99/6000 [04:33<4:22:06,  2.67s/it]                                                   {'loss': 2.7521, 'grad_norm': 4.7768235206604, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}
  2%|â–         | 99/6000 [04:33<4:22:06,  2.67s/it]  2%|â–         | 100/6000 [04:36<4:20:37,  2.65s/it]                                                    {'loss': 2.7438, 'grad_norm': 11.29746150970459, 'learning_rate': 5e-05, 'epoch': 0.02}
  2%|â–         | 100/6000 [04:36<4:20:37,  2.65s/it][2025-10-20 23:10:27,230] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  2%|â–         | 101/6000 [04:43<6:24:55,  3.92s/it]                                                    {'loss': 3.1209, 'grad_norm': 71.19363403320312, 'learning_rate': 4.9991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 101/6000 [04:43<6:24:55,  3.92s/it]  2%|â–         | 102/6000 [04:45<5:48:01,  3.54s/it]                                                    {'loss': 2.8083, 'grad_norm': 8.155198097229004, 'learning_rate': 4.998305084745763e-05, 'epoch': 0.02}
  2%|â–         | 102/6000 [04:45<5:48:01,  3.54s/it]  2%|â–         | 103/6000 [04:48<5:23:29,  3.29s/it]                                                    {'loss': 2.8108, 'grad_norm': 9.508212089538574, 'learning_rate': 4.997457627118644e-05, 'epoch': 0.02}
  2%|â–         | 103/6000 [04:48<5:23:29,  3.29s/it]  2%|â–         | 104/6000 [04:51<5:10:31,  3.16s/it]                                                    {'loss': 2.7732, 'grad_norm': 9.670023918151855, 'learning_rate': 4.9966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 104/6000 [04:51<5:10:31,  3.16s/it]  2%|â–         | 105/6000 [04:54<4:58:01,  3.03s/it]                                                    {'loss': 2.8271, 'grad_norm': 7.741555690765381, 'learning_rate': 4.9957627118644066e-05, 'epoch': 0.02}
  2%|â–         | 105/6000 [04:54<4:58:01,  3.03s/it]  2%|â–         | 106/6000 [04:57<4:53:06,  2.98s/it]                                                    {'loss': 2.7805, 'grad_norm': 4.054091930389404, 'learning_rate': 4.9949152542372884e-05, 'epoch': 0.02}
  2%|â–         | 106/6000 [04:57<4:53:06,  2.98s/it]  2%|â–         | 107/6000 [04:59<4:42:35,  2.88s/it]                                                    {'loss': 2.7891, 'grad_norm': 4.013233184814453, 'learning_rate': 4.9940677966101695e-05, 'epoch': 0.02}
  2%|â–         | 107/6000 [04:59<4:42:35,  2.88s/it]  2%|â–         | 108/6000 [05:02<4:39:52,  2.85s/it]                                                    {'loss': 2.7719, 'grad_norm': 2.8286800384521484, 'learning_rate': 4.993220338983051e-05, 'epoch': 0.02}
  2%|â–         | 108/6000 [05:02<4:39:52,  2.85s/it]  2%|â–         | 109/6000 [05:05<4:46:37,  2.92s/it]                                                    {'loss': 2.8204, 'grad_norm': 2.74369215965271, 'learning_rate': 4.9923728813559324e-05, 'epoch': 0.02}
  2%|â–         | 109/6000 [05:05<4:46:37,  2.92s/it]  2%|â–         | 110/6000 [05:08<4:38:57,  2.84s/it]                                                    {'loss': 2.8512, 'grad_norm': 2.167577028274536, 'learning_rate': 4.991525423728814e-05, 'epoch': 0.02}
  2%|â–         | 110/6000 [05:08<4:38:57,  2.84s/it]  2%|â–         | 111/6000 [05:11<4:37:00,  2.82s/it]                                                    {'loss': 2.7803, 'grad_norm': 3.2163197994232178, 'learning_rate': 4.990677966101695e-05, 'epoch': 0.02}
  2%|â–         | 111/6000 [05:11<4:37:00,  2.82s/it]  2%|â–         | 112/6000 [05:14<4:47:51,  2.93s/it]                                                    {'loss': 2.7727, 'grad_norm': 2.4294393062591553, 'learning_rate': 4.9898305084745765e-05, 'epoch': 0.02}
  2%|â–         | 112/6000 [05:14<4:47:51,  2.93s/it]  2%|â–         | 113/6000 [05:16<4:39:13,  2.85s/it]                                                    {'loss': 2.7736, 'grad_norm': 2.1284308433532715, 'learning_rate': 4.9889830508474576e-05, 'epoch': 0.02}
  2%|â–         | 113/6000 [05:16<4:39:13,  2.85s/it]  2%|â–         | 114/6000 [05:19<4:35:00,  2.80s/it]                                                    {'loss': 2.7679, 'grad_norm': 1.7735849618911743, 'learning_rate': 4.9881355932203394e-05, 'epoch': 0.02}
  2%|â–         | 114/6000 [05:19<4:35:00,  2.80s/it]  2%|â–         | 115/6000 [05:22<4:31:58,  2.77s/it]                                                    {'loss': 2.8445, 'grad_norm': 2.7347729206085205, 'learning_rate': 4.9872881355932206e-05, 'epoch': 0.02}
  2%|â–         | 115/6000 [05:22<4:31:58,  2.77s/it]  2%|â–         | 116/6000 [05:25<4:29:00,  2.74s/it]                                                    {'loss': 2.7909, 'grad_norm': 2.9070677757263184, 'learning_rate': 4.9864406779661024e-05, 'epoch': 0.02}
  2%|â–         | 116/6000 [05:25<4:29:00,  2.74s/it]  2%|â–         | 117/6000 [05:27<4:28:08,  2.73s/it]                                                    {'loss': 2.9079, 'grad_norm': 2.0420291423797607, 'learning_rate': 4.9855932203389835e-05, 'epoch': 0.02}
  2%|â–         | 117/6000 [05:27<4:28:08,  2.73s/it]  2%|â–         | 118/6000 [05:30<4:42:48,  2.88s/it]                                                    {'loss': 2.7774, 'grad_norm': 4.586893081665039, 'learning_rate': 4.9847457627118646e-05, 'epoch': 0.02}
  2%|â–         | 118/6000 [05:30<4:42:48,  2.88s/it]  2%|â–         | 119/6000 [05:33<4:36:46,  2.82s/it]                                                    {'loss': 2.7602, 'grad_norm': 3.400059223175049, 'learning_rate': 4.983898305084746e-05, 'epoch': 0.02}
  2%|â–         | 119/6000 [05:33<4:36:46,  2.82s/it]  2%|â–         | 120/6000 [05:36<4:32:43,  2.78s/it]                                                    {'loss': 2.7731, 'grad_norm': 3.256852865219116, 'learning_rate': 4.9830508474576276e-05, 'epoch': 0.02}
  2%|â–         | 120/6000 [05:36<4:32:43,  2.78s/it]  2%|â–         | 121/6000 [05:39<4:31:57,  2.78s/it]                                                    {'loss': 2.7667, 'grad_norm': 2.428169012069702, 'learning_rate': 4.982203389830509e-05, 'epoch': 0.02}
  2%|â–         | 121/6000 [05:39<4:31:57,  2.78s/it]  2%|â–         | 122/6000 [05:41<4:32:00,  2.78s/it]                                                    {'loss': 2.7787, 'grad_norm': 2.6959190368652344, 'learning_rate': 4.98135593220339e-05, 'epoch': 0.02}
  2%|â–         | 122/6000 [05:41<4:32:00,  2.78s/it]  2%|â–         | 123/6000 [05:44<4:29:09,  2.75s/it]                                                    {'loss': 2.7855, 'grad_norm': 3.6622397899627686, 'learning_rate': 4.9805084745762716e-05, 'epoch': 0.02}
  2%|â–         | 123/6000 [05:44<4:29:09,  2.75s/it]  2%|â–         | 124/6000 [05:47<4:25:44,  2.71s/it]                                                    {'loss': 2.8062, 'grad_norm': 3.7109649181365967, 'learning_rate': 4.979661016949153e-05, 'epoch': 0.02}
  2%|â–         | 124/6000 [05:47<4:25:44,  2.71s/it]  2%|â–         | 125/6000 [05:50<4:31:41,  2.77s/it]                                                    {'loss': 2.9348, 'grad_norm': 4.561358451843262, 'learning_rate': 4.978813559322034e-05, 'epoch': 0.02}
  2%|â–         | 125/6000 [05:50<4:31:41,  2.77s/it]  2%|â–         | 126/6000 [05:52<4:30:47,  2.77s/it]                                                    {'loss': 2.7591, 'grad_norm': 3.670811653137207, 'learning_rate': 4.977966101694915e-05, 'epoch': 0.02}
  2%|â–         | 126/6000 [05:52<4:30:47,  2.77s/it]  2%|â–         | 127/6000 [05:55<4:33:13,  2.79s/it]                                                    {'loss': 2.7864, 'grad_norm': 3.9804880619049072, 'learning_rate': 4.977118644067797e-05, 'epoch': 0.02}
  2%|â–         | 127/6000 [05:55<4:33:13,  2.79s/it]  2%|â–         | 128/6000 [05:58<4:31:28,  2.77s/it]                                                    {'loss': 2.7948, 'grad_norm': 3.972198963165283, 'learning_rate': 4.976271186440678e-05, 'epoch': 0.02}
  2%|â–         | 128/6000 [05:58<4:31:28,  2.77s/it]  2%|â–         | 129/6000 [06:01<4:27:51,  2.74s/it]                                                    {'loss': 2.8542, 'grad_norm': 2.295084238052368, 'learning_rate': 4.97542372881356e-05, 'epoch': 0.02}
  2%|â–         | 129/6000 [06:01<4:27:51,  2.74s/it]  2%|â–         | 130/6000 [06:03<4:26:46,  2.73s/it]                                                    {'loss': 2.7833, 'grad_norm': 3.399620771408081, 'learning_rate': 4.974576271186441e-05, 'epoch': 0.02}
  2%|â–         | 130/6000 [06:03<4:26:46,  2.73s/it]  2%|â–         | 131/6000 [06:06<4:25:50,  2.72s/it]                                                    {'loss': 2.7891, 'grad_norm': 3.4966323375701904, 'learning_rate': 4.973728813559323e-05, 'epoch': 0.02}
  2%|â–         | 131/6000 [06:06<4:25:50,  2.72s/it]  2%|â–         | 132/6000 [06:09<4:22:54,  2.69s/it]                                                    {'loss': 2.7975, 'grad_norm': 3.8389806747436523, 'learning_rate': 4.972881355932204e-05, 'epoch': 0.02}
  2%|â–         | 132/6000 [06:09<4:22:54,  2.69s/it]  2%|â–         | 133/6000 [06:11<4:22:42,  2.69s/it]                                                    {'loss': 2.7832, 'grad_norm': 2.7723941802978516, 'learning_rate': 4.972033898305085e-05, 'epoch': 0.02}
  2%|â–         | 133/6000 [06:11<4:22:42,  2.69s/it]  2%|â–         | 134/6000 [06:14<4:26:19,  2.72s/it]                                                    {'loss': 2.7795, 'grad_norm': 2.972085952758789, 'learning_rate': 4.971186440677966e-05, 'epoch': 0.02}
  2%|â–         | 134/6000 [06:14<4:26:19,  2.72s/it]  2%|â–         | 135/6000 [06:17<4:23:24,  2.69s/it]                                                    {'loss': 2.7879, 'grad_norm': 2.672499418258667, 'learning_rate': 4.970338983050848e-05, 'epoch': 0.02}
  2%|â–         | 135/6000 [06:17<4:23:24,  2.69s/it]  2%|â–         | 136/6000 [06:19<4:20:46,  2.67s/it]                                                    {'loss': 2.7866, 'grad_norm': 2.317223310470581, 'learning_rate': 4.969491525423729e-05, 'epoch': 0.02}
  2%|â–         | 136/6000 [06:19<4:20:46,  2.67s/it]  2%|â–         | 137/6000 [06:23<4:37:07,  2.84s/it]                                                    {'loss': 2.7805, 'grad_norm': 3.034200429916382, 'learning_rate': 4.968644067796611e-05, 'epoch': 0.02}
  2%|â–         | 137/6000 [06:23<4:37:07,  2.84s/it]  2%|â–         | 138/6000 [06:25<4:31:17,  2.78s/it]                                                    {'loss': 2.7806, 'grad_norm': 2.2430529594421387, 'learning_rate': 4.967796610169492e-05, 'epoch': 0.02}
  2%|â–         | 138/6000 [06:25<4:31:17,  2.78s/it]  2%|â–         | 139/6000 [06:28<4:32:34,  2.79s/it]                                                    {'loss': 2.8275, 'grad_norm': 3.5437965393066406, 'learning_rate': 4.966949152542373e-05, 'epoch': 0.02}
  2%|â–         | 139/6000 [06:28<4:32:34,  2.79s/it]  2%|â–         | 140/6000 [06:31<4:40:32,  2.87s/it]                                                    {'loss': 2.7861, 'grad_norm': 2.7160887718200684, 'learning_rate': 4.966101694915254e-05, 'epoch': 0.02}
  2%|â–         | 140/6000 [06:31<4:40:32,  2.87s/it]  2%|â–         | 141/6000 [06:34<4:34:12,  2.81s/it]                                                    {'loss': 2.7788, 'grad_norm': 1.5506821870803833, 'learning_rate': 4.965254237288136e-05, 'epoch': 0.02}
  2%|â–         | 141/6000 [06:34<4:34:12,  2.81s/it]  2%|â–         | 142/6000 [06:36<4:28:35,  2.75s/it]                                                    {'loss': 2.7739, 'grad_norm': 1.5485103130340576, 'learning_rate': 4.964406779661017e-05, 'epoch': 0.02}
  2%|â–         | 142/6000 [06:36<4:28:35,  2.75s/it]  2%|â–         | 143/6000 [06:39<4:27:56,  2.74s/it]                                                    {'loss': 2.7697, 'grad_norm': 1.5308666229248047, 'learning_rate': 4.963559322033898e-05, 'epoch': 0.02}
  2%|â–         | 143/6000 [06:39<4:27:56,  2.74s/it]  2%|â–         | 144/6000 [06:42<4:26:51,  2.73s/it]                                                    {'loss': 2.7852, 'grad_norm': 1.6541224718093872, 'learning_rate': 4.96271186440678e-05, 'epoch': 0.02}
  2%|â–         | 144/6000 [06:42<4:26:51,  2.73s/it]  2%|â–         | 145/6000 [06:44<4:23:33,  2.70s/it]                                                    {'loss': 2.806, 'grad_norm': 2.221876382827759, 'learning_rate': 4.961864406779661e-05, 'epoch': 0.02}
  2%|â–         | 145/6000 [06:44<4:23:33,  2.70s/it]  2%|â–         | 146/6000 [06:47<4:23:36,  2.70s/it]                                                    {'loss': 2.8139, 'grad_norm': 2.462545394897461, 'learning_rate': 4.961016949152543e-05, 'epoch': 0.02}
  2%|â–         | 146/6000 [06:47<4:23:36,  2.70s/it]  2%|â–         | 147/6000 [06:50<4:21:46,  2.68s/it]                                                    {'loss': 2.7813, 'grad_norm': 2.2115719318389893, 'learning_rate': 4.9601694915254234e-05, 'epoch': 0.02}
  2%|â–         | 147/6000 [06:50<4:21:46,  2.68s/it]  2%|â–         | 148/6000 [06:52<4:21:17,  2.68s/it]                                                    {'loss': 2.7845, 'grad_norm': 1.919121265411377, 'learning_rate': 4.959322033898305e-05, 'epoch': 0.02}
  2%|â–         | 148/6000 [06:52<4:21:17,  2.68s/it]  2%|â–         | 149/6000 [06:55<4:26:45,  2.74s/it]                                                    {'loss': 2.7576, 'grad_norm': 2.045466899871826, 'learning_rate': 4.9584745762711864e-05, 'epoch': 0.02}
  2%|â–         | 149/6000 [06:55<4:26:45,  2.74s/it]  2%|â–Ž         | 150/6000 [06:58<4:22:42,  2.69s/it]                                                    {'loss': 2.7856, 'grad_norm': 2.134246826171875, 'learning_rate': 4.957627118644068e-05, 'epoch': 0.03}
  2%|â–Ž         | 150/6000 [06:58<4:22:42,  2.69s/it][2025-10-20 23:12:49,162] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 151/6000 [07:03<5:21:20,  3.30s/it]                                                    {'loss': 2.7742, 'grad_norm': 1.6880905628204346, 'learning_rate': 4.956779661016949e-05, 'epoch': 0.03}
  3%|â–Ž         | 151/6000 [07:03<5:21:20,  3.30s/it]  3%|â–Ž         | 152/6000 [07:05<5:02:55,  3.11s/it]                                                    {'loss': 2.7995, 'grad_norm': 4.224473476409912, 'learning_rate': 4.955932203389831e-05, 'epoch': 0.03}
  3%|â–Ž         | 152/6000 [07:05<5:02:55,  3.11s/it]  3%|â–Ž         | 153/6000 [07:08<4:47:37,  2.95s/it]                                                    {'loss': 2.781, 'grad_norm': 2.39336895942688, 'learning_rate': 4.955084745762712e-05, 'epoch': 0.03}
  3%|â–Ž         | 153/6000 [07:08<4:47:37,  2.95s/it]  3%|â–Ž         | 154/6000 [07:11<4:41:51,  2.89s/it]                                                    {'loss': 2.7743, 'grad_norm': 2.4048731327056885, 'learning_rate': 4.9542372881355934e-05, 'epoch': 0.03}
  3%|â–Ž         | 154/6000 [07:11<4:41:51,  2.89s/it]  3%|â–Ž         | 155/6000 [07:13<4:38:28,  2.86s/it]                                                    {'loss': 2.7859, 'grad_norm': 2.405144691467285, 'learning_rate': 4.9533898305084745e-05, 'epoch': 0.03}
  3%|â–Ž         | 155/6000 [07:13<4:38:28,  2.86s/it]  3%|â–Ž         | 156/6000 [07:16<4:34:56,  2.82s/it]                                                    {'loss': 2.8318, 'grad_norm': 3.0191664695739746, 'learning_rate': 4.952542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 156/6000 [07:16<4:34:56,  2.82s/it]  3%|â–Ž         | 157/6000 [07:19<4:44:11,  2.92s/it]                                                    {'loss': 2.7603, 'grad_norm': 3.379837989807129, 'learning_rate': 4.9516949152542374e-05, 'epoch': 0.03}
  3%|â–Ž         | 157/6000 [07:19<4:44:11,  2.92s/it]  3%|â–Ž         | 158/6000 [07:22<4:38:38,  2.86s/it]                                                    {'loss': 2.7868, 'grad_norm': 3.2418479919433594, 'learning_rate': 4.950847457627119e-05, 'epoch': 0.03}
  3%|â–Ž         | 158/6000 [07:22<4:38:38,  2.86s/it]  3%|â–Ž         | 159/6000 [07:25<4:33:26,  2.81s/it]                                                    {'loss': 2.7781, 'grad_norm': 2.7142839431762695, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.03}
  3%|â–Ž         | 159/6000 [07:25<4:33:26,  2.81s/it]  3%|â–Ž         | 160/6000 [07:28<4:46:34,  2.94s/it]                                                    {'loss': 2.7969, 'grad_norm': 4.612647533416748, 'learning_rate': 4.9491525423728815e-05, 'epoch': 0.03}
  3%|â–Ž         | 160/6000 [07:28<4:46:34,  2.94s/it]  3%|â–Ž         | 161/6000 [07:31<4:41:50,  2.90s/it]                                                    {'loss': 2.7577, 'grad_norm': 6.781449794769287, 'learning_rate': 4.9483050847457626e-05, 'epoch': 0.03}
  3%|â–Ž         | 161/6000 [07:31<4:41:50,  2.90s/it]  3%|â–Ž         | 162/6000 [07:33<4:35:04,  2.83s/it]                                                    {'loss': 2.7654, 'grad_norm': 6.561830997467041, 'learning_rate': 4.9474576271186444e-05, 'epoch': 0.03}
  3%|â–Ž         | 162/6000 [07:34<4:35:04,  2.83s/it]  3%|â–Ž         | 163/6000 [07:37<4:50:39,  2.99s/it]                                                    {'loss': 2.7981, 'grad_norm': 12.080217361450195, 'learning_rate': 4.9466101694915256e-05, 'epoch': 0.03}
  3%|â–Ž         | 163/6000 [07:37<4:50:39,  2.99s/it]  3%|â–Ž         | 164/6000 [07:39<4:42:15,  2.90s/it]                                                    {'loss': 2.9323, 'grad_norm': 9.83975887298584, 'learning_rate': 4.945762711864407e-05, 'epoch': 0.03}
  3%|â–Ž         | 164/6000 [07:39<4:42:15,  2.90s/it]  3%|â–Ž         | 165/6000 [07:42<4:38:26,  2.86s/it]                                                    {'loss': 2.7867, 'grad_norm': 12.159215927124023, 'learning_rate': 4.9449152542372885e-05, 'epoch': 0.03}
  3%|â–Ž         | 165/6000 [07:42<4:38:26,  2.86s/it]  3%|â–Ž         | 166/6000 [07:45<4:31:36,  2.79s/it]                                                    {'loss': 2.788, 'grad_norm': 6.188231468200684, 'learning_rate': 4.9440677966101696e-05, 'epoch': 0.03}
  3%|â–Ž         | 166/6000 [07:45<4:31:36,  2.79s/it]  3%|â–Ž         | 167/6000 [07:48<4:29:31,  2.77s/it]                                                    {'loss': 2.8655, 'grad_norm': 15.204047203063965, 'learning_rate': 4.9432203389830514e-05, 'epoch': 0.03}
  3%|â–Ž         | 167/6000 [07:48<4:29:31,  2.77s/it]  3%|â–Ž         | 168/6000 [07:50<4:26:07,  2.74s/it]                                                    {'loss': 2.9376, 'grad_norm': 41.792232513427734, 'learning_rate': 4.9423728813559326e-05, 'epoch': 0.03}
  3%|â–Ž         | 168/6000 [07:50<4:26:07,  2.74s/it]  3%|â–Ž         | 169/6000 [07:53<4:35:10,  2.83s/it]                                                    {'loss': 2.8473, 'grad_norm': 5.709512710571289, 'learning_rate': 4.941525423728814e-05, 'epoch': 0.03}
  3%|â–Ž         | 169/6000 [07:53<4:35:10,  2.83s/it]  3%|â–Ž         | 170/6000 [07:56<4:30:29,  2.78s/it]                                                    {'loss': 2.802, 'grad_norm': 4.319115161895752, 'learning_rate': 4.940677966101695e-05, 'epoch': 0.03}
  3%|â–Ž         | 170/6000 [07:56<4:30:29,  2.78s/it]  3%|â–Ž         | 171/6000 [07:59<4:26:54,  2.75s/it]                                                    {'loss': 2.791, 'grad_norm': 4.809695720672607, 'learning_rate': 4.9398305084745766e-05, 'epoch': 0.03}
  3%|â–Ž         | 171/6000 [07:59<4:26:54,  2.75s/it]  3%|â–Ž         | 172/6000 [08:01<4:27:30,  2.75s/it]                                                    {'loss': 2.7934, 'grad_norm': 2.9715499877929688, 'learning_rate': 4.938983050847458e-05, 'epoch': 0.03}
  3%|â–Ž         | 172/6000 [08:01<4:27:30,  2.75s/it]  3%|â–Ž         | 173/6000 [08:04<4:26:33,  2.74s/it]                                                    {'loss': 2.7808, 'grad_norm': 2.7119317054748535, 'learning_rate': 4.9381355932203396e-05, 'epoch': 0.03}
  3%|â–Ž         | 173/6000 [08:04<4:26:33,  2.74s/it]  3%|â–Ž         | 174/6000 [08:07<4:45:05,  2.94s/it]                                                    {'loss': 2.7962, 'grad_norm': 3.640040397644043, 'learning_rate': 4.937288135593221e-05, 'epoch': 0.03}
  3%|â–Ž         | 174/6000 [08:07<4:45:05,  2.94s/it]  3%|â–Ž         | 175/6000 [08:10<4:40:50,  2.89s/it]                                                    {'loss': 2.8013, 'grad_norm': 2.480464458465576, 'learning_rate': 4.936440677966102e-05, 'epoch': 0.03}
  3%|â–Ž         | 175/6000 [08:10<4:40:50,  2.89s/it]  3%|â–Ž         | 176/6000 [08:13<4:44:08,  2.93s/it]                                                    {'loss': 2.7721, 'grad_norm': 2.399817943572998, 'learning_rate': 4.935593220338983e-05, 'epoch': 0.03}
  3%|â–Ž         | 176/6000 [08:13<4:44:08,  2.93s/it]  3%|â–Ž         | 177/6000 [08:16<4:37:23,  2.86s/it]                                                    {'loss': 2.7876, 'grad_norm': 1.3003491163253784, 'learning_rate': 4.934745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 177/6000 [08:16<4:37:23,  2.86s/it]  3%|â–Ž         | 178/6000 [08:19<4:31:49,  2.80s/it]                                                    {'loss': 2.7989, 'grad_norm': 1.9851537942886353, 'learning_rate': 4.933898305084746e-05, 'epoch': 0.03}
  3%|â–Ž         | 178/6000 [08:19<4:31:49,  2.80s/it]  3%|â–Ž         | 179/6000 [08:21<4:26:53,  2.75s/it]                                                    {'loss': 2.7931, 'grad_norm': 1.4941482543945312, 'learning_rate': 4.933050847457628e-05, 'epoch': 0.03}
  3%|â–Ž         | 179/6000 [08:21<4:26:53,  2.75s/it]  3%|â–Ž         | 180/6000 [08:24<4:27:53,  2.76s/it]                                                    {'loss': 2.7887, 'grad_norm': 0.9273829460144043, 'learning_rate': 4.932203389830509e-05, 'epoch': 0.03}
  3%|â–Ž         | 180/6000 [08:24<4:27:53,  2.76s/it]  3%|â–Ž         | 181/6000 [08:27<4:25:27,  2.74s/it]                                                    {'loss': 2.8043, 'grad_norm': 1.0150766372680664, 'learning_rate': 4.9313559322033906e-05, 'epoch': 0.03}
  3%|â–Ž         | 181/6000 [08:27<4:25:27,  2.74s/it]  3%|â–Ž         | 182/6000 [08:29<4:23:58,  2.72s/it]                                                    {'loss': 2.8218, 'grad_norm': 1.1591744422912598, 'learning_rate': 4.930508474576271e-05, 'epoch': 0.03}
  3%|â–Ž         | 182/6000 [08:29<4:23:58,  2.72s/it]  3%|â–Ž         | 183/6000 [08:32<4:23:00,  2.71s/it]                                                    {'loss': 2.7769, 'grad_norm': 1.1162580251693726, 'learning_rate': 4.929661016949153e-05, 'epoch': 0.03}
  3%|â–Ž         | 183/6000 [08:32<4:23:00,  2.71s/it]  3%|â–Ž         | 184/6000 [08:35<4:23:05,  2.71s/it]                                                    {'loss': 2.7815, 'grad_norm': 1.0812351703643799, 'learning_rate': 4.928813559322034e-05, 'epoch': 0.03}
  3%|â–Ž         | 184/6000 [08:35<4:23:05,  2.71s/it]  3%|â–Ž         | 185/6000 [08:38<4:24:13,  2.73s/it]                                                    {'loss': 2.7894, 'grad_norm': 1.2272231578826904, 'learning_rate': 4.927966101694915e-05, 'epoch': 0.03}
  3%|â–Ž         | 185/6000 [08:38<4:24:13,  2.73s/it]  3%|â–Ž         | 186/6000 [08:40<4:22:51,  2.71s/it]                                                    {'loss': 2.778, 'grad_norm': 0.7107340693473816, 'learning_rate': 4.927118644067797e-05, 'epoch': 0.03}
  3%|â–Ž         | 186/6000 [08:40<4:22:51,  2.71s/it]  3%|â–Ž         | 187/6000 [08:43<4:20:50,  2.69s/it]                                                    {'loss': 2.7784, 'grad_norm': 1.2150477170944214, 'learning_rate': 4.926271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 187/6000 [08:43<4:20:50,  2.69s/it]  3%|â–Ž         | 188/6000 [08:46<4:19:49,  2.68s/it]                                                    {'loss': 2.7818, 'grad_norm': 0.9961751103401184, 'learning_rate': 4.92542372881356e-05, 'epoch': 0.03}
  3%|â–Ž         | 188/6000 [08:46<4:19:49,  2.68s/it]  3%|â–Ž         | 189/6000 [08:48<4:20:29,  2.69s/it]                                                    {'loss': 2.78, 'grad_norm': 1.0210374593734741, 'learning_rate': 4.924576271186441e-05, 'epoch': 0.03}
  3%|â–Ž         | 189/6000 [08:48<4:20:29,  2.69s/it]  3%|â–Ž         | 190/6000 [08:51<4:18:38,  2.67s/it]                                                    {'loss': 2.7916, 'grad_norm': 0.9693122506141663, 'learning_rate': 4.923728813559322e-05, 'epoch': 0.03}
  3%|â–Ž         | 190/6000 [08:51<4:18:38,  2.67s/it]  3%|â–Ž         | 191/6000 [08:54<4:19:40,  2.68s/it]                                                    {'loss': 2.7829, 'grad_norm': 0.9392440915107727, 'learning_rate': 4.922881355932203e-05, 'epoch': 0.03}
  3%|â–Ž         | 191/6000 [08:54<4:19:40,  2.68s/it]  3%|â–Ž         | 192/6000 [08:57<4:36:46,  2.86s/it]                                                    {'loss': 2.8773, 'grad_norm': 1.1949188709259033, 'learning_rate': 4.922033898305085e-05, 'epoch': 0.03}
  3%|â–Ž         | 192/6000 [08:57<4:36:46,  2.86s/it]  3%|â–Ž         | 193/6000 [09:00<4:42:16,  2.92s/it]                                                    {'loss': 2.772, 'grad_norm': 1.1836307048797607, 'learning_rate': 4.921186440677966e-05, 'epoch': 0.03}
  3%|â–Ž         | 193/6000 [09:00<4:42:16,  2.92s/it]  3%|â–Ž         | 194/6000 [09:03<4:32:55,  2.82s/it]                                                    {'loss': 2.78, 'grad_norm': 0.9746690392494202, 'learning_rate': 4.920338983050848e-05, 'epoch': 0.03}
  3%|â–Ž         | 194/6000 [09:03<4:32:55,  2.82s/it]  3%|â–Ž         | 195/6000 [09:05<4:29:28,  2.79s/it]                                                    {'loss': 2.8077, 'grad_norm': 0.9589760899543762, 'learning_rate': 4.919491525423729e-05, 'epoch': 0.03}
  3%|â–Ž         | 195/6000 [09:05<4:29:28,  2.79s/it]  3%|â–Ž         | 196/6000 [09:08<4:27:28,  2.77s/it]                                                    {'loss': 2.7903, 'grad_norm': 1.0035144090652466, 'learning_rate': 4.91864406779661e-05, 'epoch': 0.03}
  3%|â–Ž         | 196/6000 [09:08<4:27:28,  2.77s/it]  3%|â–Ž         | 197/6000 [09:11<4:30:53,  2.80s/it]                                                    {'loss': 2.7901, 'grad_norm': 0.8905079364776611, 'learning_rate': 4.9177966101694914e-05, 'epoch': 0.03}
  3%|â–Ž         | 197/6000 [09:11<4:30:53,  2.80s/it]  3%|â–Ž         | 198/6000 [09:14<4:30:47,  2.80s/it]                                                    {'loss': 2.7858, 'grad_norm': 1.1363575458526611, 'learning_rate': 4.916949152542373e-05, 'epoch': 0.03}
  3%|â–Ž         | 198/6000 [09:14<4:30:47,  2.80s/it]  3%|â–Ž         | 199/6000 [09:16<4:25:29,  2.75s/it]                                                    {'loss': 2.771, 'grad_norm': 0.859207272529602, 'learning_rate': 4.916101694915254e-05, 'epoch': 0.03}
  3%|â–Ž         | 199/6000 [09:16<4:25:29,  2.75s/it]  3%|â–Ž         | 200/6000 [09:19<4:36:02,  2.86s/it]                                                    {'loss': 2.7748, 'grad_norm': 0.8886803984642029, 'learning_rate': 4.915254237288136e-05, 'epoch': 0.03}
  3%|â–Ž         | 200/6000 [09:19<4:36:02,  2.86s/it][2025-10-20 23:15:10,670] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  3%|â–Ž         | 201/6000 [09:24<5:28:01,  3.39s/it]                                                    {'loss': 2.8072, 'grad_norm': 1.089603304862976, 'learning_rate': 4.914406779661017e-05, 'epoch': 0.03}
  3%|â–Ž         | 201/6000 [09:24<5:28:01,  3.39s/it]  3%|â–Ž         | 202/6000 [09:27<5:07:06,  3.18s/it]                                                    {'loss': 2.7831, 'grad_norm': 1.0094484090805054, 'learning_rate': 4.913559322033899e-05, 'epoch': 0.03}
  3%|â–Ž         | 202/6000 [09:27<5:07:06,  3.18s/it]  3%|â–Ž         | 203/6000 [09:29<4:54:29,  3.05s/it]                                                    {'loss': 2.7834, 'grad_norm': 1.0484646558761597, 'learning_rate': 4.91271186440678e-05, 'epoch': 0.03}
  3%|â–Ž         | 203/6000 [09:29<4:54:29,  3.05s/it]  3%|â–Ž         | 204/6000 [09:32<4:47:06,  2.97s/it]                                                    {'loss': 2.7818, 'grad_norm': 0.8301875591278076, 'learning_rate': 4.9118644067796607e-05, 'epoch': 0.03}
  3%|â–Ž         | 204/6000 [09:32<4:47:06,  2.97s/it]  3%|â–Ž         | 205/6000 [09:35<4:36:19,  2.86s/it]                                                    {'loss': 2.7764, 'grad_norm': 1.1216989755630493, 'learning_rate': 4.9110169491525425e-05, 'epoch': 0.03}
  3%|â–Ž         | 205/6000 [09:35<4:36:19,  2.86s/it]  3%|â–Ž         | 206/6000 [09:38<4:30:34,  2.80s/it]                                                    {'loss': 2.8218, 'grad_norm': 0.893932580947876, 'learning_rate': 4.9101694915254236e-05, 'epoch': 0.03}
  3%|â–Ž         | 206/6000 [09:38<4:30:34,  2.80s/it]  3%|â–Ž         | 207/6000 [09:40<4:26:34,  2.76s/it]                                                    {'loss': 2.8748, 'grad_norm': 1.1583892107009888, 'learning_rate': 4.9093220338983054e-05, 'epoch': 0.03}
  3%|â–Ž         | 207/6000 [09:40<4:26:34,  2.76s/it]  3%|â–Ž         | 208/6000 [09:43<4:21:36,  2.71s/it]                                                    {'loss': 2.7815, 'grad_norm': 1.5744400024414062, 'learning_rate': 4.9084745762711865e-05, 'epoch': 0.03}
  3%|â–Ž         | 208/6000 [09:43<4:21:36,  2.71s/it]  3%|â–Ž         | 209/6000 [09:45<4:20:32,  2.70s/it]                                                    {'loss': 2.7749, 'grad_norm': 1.2918550968170166, 'learning_rate': 4.907627118644068e-05, 'epoch': 0.03}
  3%|â–Ž         | 209/6000 [09:45<4:20:32,  2.70s/it]  4%|â–Ž         | 210/6000 [09:49<4:33:15,  2.83s/it]                                                    {'loss': 2.7787, 'grad_norm': 1.2139767408370972, 'learning_rate': 4.9067796610169495e-05, 'epoch': 0.04}
  4%|â–Ž         | 210/6000 [09:49<4:33:15,  2.83s/it]  4%|â–Ž         | 211/6000 [09:51<4:33:31,  2.83s/it]                                                    {'loss': 2.7849, 'grad_norm': 1.6448900699615479, 'learning_rate': 4.9059322033898306e-05, 'epoch': 0.04}
  4%|â–Ž         | 211/6000 [09:51<4:33:31,  2.83s/it]  4%|â–Ž         | 212/6000 [09:55<4:41:15,  2.92s/it]                                                    {'loss': 2.7672, 'grad_norm': 1.270814299583435, 'learning_rate': 4.905084745762712e-05, 'epoch': 0.04}
  4%|â–Ž         | 212/6000 [09:55<4:41:15,  2.92s/it]  4%|â–Ž         | 213/6000 [09:57<4:35:42,  2.86s/it]                                                    {'loss': 2.7808, 'grad_norm': 1.5858666896820068, 'learning_rate': 4.9042372881355935e-05, 'epoch': 0.04}
  4%|â–Ž         | 213/6000 [09:57<4:35:42,  2.86s/it]  4%|â–Ž         | 214/6000 [10:00<4:29:28,  2.79s/it]                                                    {'loss': 2.7734, 'grad_norm': 1.0717891454696655, 'learning_rate': 4.9033898305084746e-05, 'epoch': 0.04}
  4%|â–Ž         | 214/6000 [10:00<4:29:28,  2.79s/it]  4%|â–Ž         | 215/6000 [10:03<4:25:55,  2.76s/it]                                                    {'loss': 2.8018, 'grad_norm': 1.2153942584991455, 'learning_rate': 4.9025423728813565e-05, 'epoch': 0.04}
  4%|â–Ž         | 215/6000 [10:03<4:25:55,  2.76s/it]  4%|â–Ž         | 216/6000 [10:05<4:25:49,  2.76s/it]                                                    {'loss': 2.7801, 'grad_norm': 1.7592766284942627, 'learning_rate': 4.9016949152542376e-05, 'epoch': 0.04}
  4%|â–Ž         | 216/6000 [10:05<4:25:49,  2.76s/it]  4%|â–Ž         | 217/6000 [10:08<4:25:59,  2.76s/it]                                                    {'loss': 2.8193, 'grad_norm': 1.0666751861572266, 'learning_rate': 4.9008474576271194e-05, 'epoch': 0.04}
  4%|â–Ž         | 217/6000 [10:08<4:25:59,  2.76s/it]  4%|â–Ž         | 218/6000 [10:11<4:25:37,  2.76s/it]                                                    {'loss': 2.7973, 'grad_norm': 1.7831289768218994, 'learning_rate': 4.9e-05, 'epoch': 0.04}
  4%|â–Ž         | 218/6000 [10:11<4:25:37,  2.76s/it]  4%|â–Ž         | 219/6000 [10:13<4:21:29,  2.71s/it]                                                    {'loss': 2.8215, 'grad_norm': 1.727359652519226, 'learning_rate': 4.8991525423728816e-05, 'epoch': 0.04}
  4%|â–Ž         | 219/6000 [10:13<4:21:29,  2.71s/it]  4%|â–Ž         | 220/6000 [10:16<4:18:56,  2.69s/it]                                                    {'loss': 2.771, 'grad_norm': 1.3245042562484741, 'learning_rate': 4.898305084745763e-05, 'epoch': 0.04}
  4%|â–Ž         | 220/6000 [10:16<4:18:56,  2.69s/it]  4%|â–Ž         | 221/6000 [10:19<4:20:24,  2.70s/it]                                                    {'loss': 2.8067, 'grad_norm': 2.287714719772339, 'learning_rate': 4.8974576271186446e-05, 'epoch': 0.04}
  4%|â–Ž         | 221/6000 [10:19<4:20:24,  2.70s/it]  4%|â–Ž         | 222/6000 [10:21<4:17:37,  2.68s/it]                                                    {'loss': 2.7636, 'grad_norm': 2.7611467838287354, 'learning_rate': 4.896610169491526e-05, 'epoch': 0.04}
  4%|â–Ž         | 222/6000 [10:21<4:17:37,  2.68s/it]  4%|â–Ž         | 223/6000 [10:24<4:24:02,  2.74s/it]                                                    {'loss': 2.7719, 'grad_norm': 2.085975170135498, 'learning_rate': 4.8957627118644075e-05, 'epoch': 0.04}
  4%|â–Ž         | 223/6000 [10:24<4:24:02,  2.74s/it]  4%|â–Ž         | 224/6000 [10:27<4:21:54,  2.72s/it]                                                    {'loss': 2.8201, 'grad_norm': 2.7107644081115723, 'learning_rate': 4.8949152542372886e-05, 'epoch': 0.04}
  4%|â–Ž         | 224/6000 [10:27<4:21:54,  2.72s/it]  4%|â–         | 225/6000 [10:30<4:22:42,  2.73s/it]                                                    {'loss': 2.7672, 'grad_norm': 2.1776247024536133, 'learning_rate': 4.89406779661017e-05, 'epoch': 0.04}
  4%|â–         | 225/6000 [10:30<4:22:42,  2.73s/it]  4%|â–         | 226/6000 [10:33<4:33:42,  2.84s/it]                                                    {'loss': 2.7687, 'grad_norm': 3.5308823585510254, 'learning_rate': 4.893220338983051e-05, 'epoch': 0.04}
  4%|â–         | 226/6000 [10:33<4:33:42,  2.84s/it]  4%|â–         | 227/6000 [10:36<4:28:00,  2.79s/it]                                                    {'loss': 2.8201, 'grad_norm': 3.198465347290039, 'learning_rate': 4.892372881355932e-05, 'epoch': 0.04}
  4%|â–         | 227/6000 [10:36<4:28:00,  2.79s/it]  4%|â–         | 228/6000 [10:38<4:26:07,  2.77s/it]                                                    {'loss': 2.7613, 'grad_norm': 3.5470681190490723, 'learning_rate': 4.891525423728814e-05, 'epoch': 0.04}
  4%|â–         | 228/6000 [10:38<4:26:07,  2.77s/it]  4%|â–         | 229/6000 [10:41<4:23:00,  2.73s/it]                                                    {'loss': 2.7862, 'grad_norm': 2.756030559539795, 'learning_rate': 4.890677966101695e-05, 'epoch': 0.04}
  4%|â–         | 229/6000 [10:41<4:23:00,  2.73s/it]  4%|â–         | 230/6000 [10:44<4:23:41,  2.74s/it]                                                    {'loss': 2.8009, 'grad_norm': 3.3066511154174805, 'learning_rate': 4.889830508474577e-05, 'epoch': 0.04}
  4%|â–         | 230/6000 [10:44<4:23:41,  2.74s/it]  4%|â–         | 231/6000 [10:46<4:21:00,  2.71s/it]                                                    {'loss': 2.7421, 'grad_norm': 3.531954765319824, 'learning_rate': 4.888983050847458e-05, 'epoch': 0.04}
  4%|â–         | 231/6000 [10:46<4:21:00,  2.71s/it]  4%|â–         | 232/6000 [10:49<4:22:27,  2.73s/it]                                                    {'loss': 2.7867, 'grad_norm': 3.744642734527588, 'learning_rate': 4.888135593220339e-05, 'epoch': 0.04}
  4%|â–         | 232/6000 [10:49<4:22:27,  2.73s/it]  4%|â–         | 233/6000 [10:52<4:30:49,  2.82s/it]                                                    {'loss': 2.7786, 'grad_norm': 2.6407999992370605, 'learning_rate': 4.88728813559322e-05, 'epoch': 0.04}
  4%|â–         | 233/6000 [10:52<4:30:49,  2.82s/it]  4%|â–         | 234/6000 [10:55<4:34:38,  2.86s/it]                                                    {'loss': 2.7802, 'grad_norm': 3.5927913188934326, 'learning_rate': 4.886440677966102e-05, 'epoch': 0.04}
  4%|â–         | 234/6000 [10:55<4:34:38,  2.86s/it]  4%|â–         | 235/6000 [10:58<4:28:51,  2.80s/it]                                                    {'loss': 2.8179, 'grad_norm': 4.866008758544922, 'learning_rate': 4.885593220338983e-05, 'epoch': 0.04}
  4%|â–         | 235/6000 [10:58<4:28:51,  2.80s/it]  4%|â–         | 236/6000 [11:00<4:26:14,  2.77s/it]                                                    {'loss': 2.8078, 'grad_norm': 4.062607765197754, 'learning_rate': 4.884745762711865e-05, 'epoch': 0.04}
  4%|â–         | 236/6000 [11:00<4:26:14,  2.77s/it]  4%|â–         | 237/6000 [11:03<4:23:59,  2.75s/it]                                                    {'loss': 2.8175, 'grad_norm': 5.778341293334961, 'learning_rate': 4.883898305084746e-05, 'epoch': 0.04}
  4%|â–         | 237/6000 [11:03<4:23:59,  2.75s/it]  4%|â–         | 238/6000 [11:06<4:34:47,  2.86s/it]                                                    {'loss': 2.8397, 'grad_norm': 2.3673954010009766, 'learning_rate': 4.883050847457628e-05, 'epoch': 0.04}
  4%|â–         | 238/6000 [11:06<4:34:47,  2.86s/it]  4%|â–         | 239/6000 [11:09<4:31:20,  2.83s/it]                                                    {'loss': 2.7582, 'grad_norm': 3.1471831798553467, 'learning_rate': 4.882203389830508e-05, 'epoch': 0.04}
  4%|â–         | 239/6000 [11:09<4:31:20,  2.83s/it]  4%|â–         | 240/6000 [11:12<4:28:35,  2.80s/it]                                                    {'loss': 2.7912, 'grad_norm': 1.9004133939743042, 'learning_rate': 4.88135593220339e-05, 'epoch': 0.04}
  4%|â–         | 240/6000 [11:12<4:28:35,  2.80s/it]  4%|â–         | 241/6000 [11:14<4:25:40,  2.77s/it]                                                    {'loss': 2.7822, 'grad_norm': 3.5767745971679688, 'learning_rate': 4.880508474576271e-05, 'epoch': 0.04}
  4%|â–         | 241/6000 [11:14<4:25:40,  2.77s/it]  4%|â–         | 242/6000 [11:17<4:20:55,  2.72s/it]                                                    {'loss': 2.8157, 'grad_norm': 2.489866018295288, 'learning_rate': 4.879661016949153e-05, 'epoch': 0.04}
  4%|â–         | 242/6000 [11:17<4:20:55,  2.72s/it]  4%|â–         | 243/6000 [11:20<4:28:47,  2.80s/it]                                                    {'loss': 2.7854, 'grad_norm': 2.929304599761963, 'learning_rate': 4.878813559322034e-05, 'epoch': 0.04}
  4%|â–         | 243/6000 [11:20<4:28:47,  2.80s/it]  4%|â–         | 244/6000 [11:23<4:24:10,  2.75s/it]                                                    {'loss': 2.8082, 'grad_norm': 3.9557740688323975, 'learning_rate': 4.877966101694916e-05, 'epoch': 0.04}
  4%|â–         | 244/6000 [11:23<4:24:10,  2.75s/it]  4%|â–         | 245/6000 [11:25<4:22:31,  2.74s/it]                                                    {'loss': 2.778, 'grad_norm': 1.377339243888855, 'learning_rate': 4.877118644067797e-05, 'epoch': 0.04}
  4%|â–         | 245/6000 [11:25<4:22:31,  2.74s/it]  4%|â–         | 246/6000 [11:28<4:24:16,  2.76s/it]                                                    {'loss': 2.7739, 'grad_norm': 2.4682071208953857, 'learning_rate': 4.876271186440678e-05, 'epoch': 0.04}
  4%|â–         | 246/6000 [11:28<4:24:16,  2.76s/it]  4%|â–         | 247/6000 [11:31<4:21:20,  2.73s/it]                                                    {'loss': 2.7693, 'grad_norm': 1.7449907064437866, 'learning_rate': 4.8754237288135593e-05, 'epoch': 0.04}
  4%|â–         | 247/6000 [11:31<4:21:20,  2.73s/it]  4%|â–         | 248/6000 [11:34<4:29:44,  2.81s/it]                                                    {'loss': 2.7711, 'grad_norm': 1.064500331878662, 'learning_rate': 4.8745762711864405e-05, 'epoch': 0.04}
  4%|â–         | 248/6000 [11:34<4:29:44,  2.81s/it]  4%|â–         | 249/6000 [11:36<4:23:56,  2.75s/it]                                                    {'loss': 2.7657, 'grad_norm': 1.8095502853393555, 'learning_rate': 4.873728813559322e-05, 'epoch': 0.04}
  4%|â–         | 249/6000 [11:36<4:23:56,  2.75s/it]  4%|â–         | 250/6000 [11:39<4:19:56,  2.71s/it]                                                    {'loss': 2.7953, 'grad_norm': 1.868348479270935, 'learning_rate': 4.8728813559322034e-05, 'epoch': 0.04}
  4%|â–         | 250/6000 [11:39<4:19:56,  2.71s/it][2025-10-20 23:17:30,331] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  4%|â–         | 251/6000 [11:44<5:12:42,  3.26s/it]                                                    {'loss': 2.7976, 'grad_norm': 1.7919889688491821, 'learning_rate': 4.872033898305085e-05, 'epoch': 0.04}
  4%|â–         | 251/6000 [11:44<5:12:42,  3.26s/it]  4%|â–         | 252/6000 [11:46<5:01:36,  3.15s/it]                                                    {'loss': 2.8022, 'grad_norm': 1.6810855865478516, 'learning_rate': 4.8711864406779663e-05, 'epoch': 0.04}
  4%|â–         | 252/6000 [11:46<5:01:36,  3.15s/it]  4%|â–         | 253/6000 [11:49<4:47:48,  3.00s/it]                                                    {'loss': 2.8068, 'grad_norm': 1.8393498659133911, 'learning_rate': 4.8703389830508475e-05, 'epoch': 0.04}
  4%|â–         | 253/6000 [11:49<4:47:48,  3.00s/it]  4%|â–         | 254/6000 [11:52<4:40:28,  2.93s/it]                                                    {'loss': 2.7696, 'grad_norm': 1.8998661041259766, 'learning_rate': 4.8694915254237286e-05, 'epoch': 0.04}
  4%|â–         | 254/6000 [11:52<4:40:28,  2.93s/it]  4%|â–         | 255/6000 [11:54<4:30:34,  2.83s/it]                                                    {'loss': 2.7637, 'grad_norm': 1.6961778402328491, 'learning_rate': 4.8686440677966104e-05, 'epoch': 0.04}
  4%|â–         | 255/6000 [11:55<4:30:34,  2.83s/it]  4%|â–         | 256/6000 [11:58<4:38:27,  2.91s/it]                                                    {'loss': 2.7878, 'grad_norm': 1.9914147853851318, 'learning_rate': 4.8677966101694915e-05, 'epoch': 0.04}
  4%|â–         | 256/6000 [11:58<4:38:27,  2.91s/it]  4%|â–         | 257/6000 [12:00<4:31:11,  2.83s/it]                                                    {'loss': 2.7744, 'grad_norm': 2.595627546310425, 'learning_rate': 4.8669491525423733e-05, 'epoch': 0.04}
  4%|â–         | 257/6000 [12:00<4:31:11,  2.83s/it]  4%|â–         | 258/6000 [12:03<4:26:33,  2.79s/it]                                                    {'loss': 2.7833, 'grad_norm': 2.474926710128784, 'learning_rate': 4.8661016949152545e-05, 'epoch': 0.04}
  4%|â–         | 258/6000 [12:03<4:26:33,  2.79s/it]  4%|â–         | 259/6000 [12:06<4:22:00,  2.74s/it]                                                    {'loss': 2.7598, 'grad_norm': 4.9145684242248535, 'learning_rate': 4.865254237288136e-05, 'epoch': 0.04}
  4%|â–         | 259/6000 [12:06<4:22:00,  2.74s/it]  4%|â–         | 260/6000 [12:08<4:19:46,  2.72s/it]                                                    {'loss': 2.7948, 'grad_norm': 2.808943271636963, 'learning_rate': 4.8644067796610174e-05, 'epoch': 0.04}
  4%|â–         | 260/6000 [12:08<4:19:46,  2.72s/it]  4%|â–         | 261/6000 [12:11<4:22:57,  2.75s/it]                                                    {'loss': 2.8077, 'grad_norm': 4.507392406463623, 'learning_rate': 4.8635593220338985e-05, 'epoch': 0.04}
  4%|â–         | 261/6000 [12:11<4:22:57,  2.75s/it]  4%|â–         | 262/6000 [12:14<4:20:40,  2.73s/it]                                                    {'loss': 2.81, 'grad_norm': 3.9344873428344727, 'learning_rate': 4.86271186440678e-05, 'epoch': 0.04}
  4%|â–         | 262/6000 [12:14<4:20:40,  2.73s/it]  4%|â–         | 263/6000 [12:17<4:29:28,  2.82s/it]                                                    {'loss': 2.8127, 'grad_norm': 3.4195547103881836, 'learning_rate': 4.8618644067796615e-05, 'epoch': 0.04}
  4%|â–         | 263/6000 [12:17<4:29:28,  2.82s/it]  4%|â–         | 264/6000 [12:19<4:24:06,  2.76s/it]                                                    {'loss': 2.7814, 'grad_norm': 2.60646390914917, 'learning_rate': 4.8610169491525426e-05, 'epoch': 0.04}
  4%|â–         | 264/6000 [12:19<4:24:06,  2.76s/it]  4%|â–         | 265/6000 [12:22<4:25:44,  2.78s/it]                                                    {'loss': 2.7813, 'grad_norm': 1.7822682857513428, 'learning_rate': 4.8601694915254244e-05, 'epoch': 0.04}
  4%|â–         | 265/6000 [12:22<4:25:44,  2.78s/it]  4%|â–         | 266/6000 [12:25<4:25:33,  2.78s/it]                                                    {'loss': 2.7953, 'grad_norm': 2.09368896484375, 'learning_rate': 4.8593220338983055e-05, 'epoch': 0.04}
  4%|â–         | 266/6000 [12:25<4:25:33,  2.78s/it]  4%|â–         | 267/6000 [12:28<4:23:21,  2.76s/it]                                                    {'loss': 2.7782, 'grad_norm': 1.5821677446365356, 'learning_rate': 4.858474576271187e-05, 'epoch': 0.04}
  4%|â–         | 267/6000 [12:28<4:23:21,  2.76s/it]  4%|â–         | 268/6000 [12:30<4:22:24,  2.75s/it]                                                    {'loss': 2.8348, 'grad_norm': 1.9353505373001099, 'learning_rate': 4.857627118644068e-05, 'epoch': 0.04}
  4%|â–         | 268/6000 [12:30<4:22:24,  2.75s/it]  4%|â–         | 269/6000 [12:33<4:24:34,  2.77s/it]                                                    {'loss': 2.774, 'grad_norm': 1.9392908811569214, 'learning_rate': 4.856779661016949e-05, 'epoch': 0.04}
  4%|â–         | 269/6000 [12:33<4:24:34,  2.77s/it]  4%|â–         | 270/6000 [12:36<4:20:49,  2.73s/it]                                                    {'loss': 2.7564, 'grad_norm': 1.9946112632751465, 'learning_rate': 4.855932203389831e-05, 'epoch': 0.04}
  4%|â–         | 270/6000 [12:36<4:20:49,  2.73s/it]  5%|â–         | 271/6000 [12:38<4:17:26,  2.70s/it]                                                    {'loss': 2.7987, 'grad_norm': 2.1631617546081543, 'learning_rate': 4.855084745762712e-05, 'epoch': 0.05}
  5%|â–         | 271/6000 [12:38<4:17:26,  2.70s/it]  5%|â–         | 272/6000 [12:41<4:15:44,  2.68s/it]                                                    {'loss': 2.7974, 'grad_norm': 3.6756443977355957, 'learning_rate': 4.8542372881355937e-05, 'epoch': 0.05}
  5%|â–         | 272/6000 [12:41<4:15:44,  2.68s/it]  5%|â–         | 273/6000 [12:44<4:14:28,  2.67s/it]                                                    {'loss': 2.8165, 'grad_norm': 3.387223720550537, 'learning_rate': 4.853389830508475e-05, 'epoch': 0.05}
  5%|â–         | 273/6000 [12:44<4:14:28,  2.67s/it]  5%|â–         | 274/6000 [12:47<4:24:36,  2.77s/it]                                                    {'loss': 2.7596, 'grad_norm': 3.8946783542633057, 'learning_rate': 4.8525423728813566e-05, 'epoch': 0.05}
  5%|â–         | 274/6000 [12:47<4:24:36,  2.77s/it]  5%|â–         | 275/6000 [12:49<4:22:15,  2.75s/it]                                                    {'loss': 2.8093, 'grad_norm': 3.5375030040740967, 'learning_rate': 4.851694915254237e-05, 'epoch': 0.05}
  5%|â–         | 275/6000 [12:49<4:22:15,  2.75s/it]  5%|â–         | 276/6000 [12:52<4:21:09,  2.74s/it]                                                    {'loss': 2.8608, 'grad_norm': 2.703354835510254, 'learning_rate': 4.850847457627119e-05, 'epoch': 0.05}
  5%|â–         | 276/6000 [12:52<4:21:09,  2.74s/it]  5%|â–         | 277/6000 [12:55<4:17:27,  2.70s/it]                                                    {'loss': 2.7797, 'grad_norm': 2.8175747394561768, 'learning_rate': 4.85e-05, 'epoch': 0.05}
  5%|â–         | 277/6000 [12:55<4:17:27,  2.70s/it]  5%|â–         | 278/6000 [12:57<4:17:10,  2.70s/it]                                                    {'loss': 2.7791, 'grad_norm': 1.6237261295318604, 'learning_rate': 4.849152542372882e-05, 'epoch': 0.05}
  5%|â–         | 278/6000 [12:58<4:17:10,  2.70s/it]  5%|â–         | 279/6000 [13:00<4:18:08,  2.71s/it]                                                    {'loss': 2.8111, 'grad_norm': 1.7817819118499756, 'learning_rate': 4.848305084745763e-05, 'epoch': 0.05}
  5%|â–         | 279/6000 [13:00<4:18:08,  2.71s/it]  5%|â–         | 280/6000 [13:03<4:16:33,  2.69s/it]                                                    {'loss': 2.7822, 'grad_norm': 1.633740782737732, 'learning_rate': 4.847457627118645e-05, 'epoch': 0.05}
  5%|â–         | 280/6000 [13:03<4:16:33,  2.69s/it]  5%|â–         | 281/6000 [13:06<4:16:38,  2.69s/it]                                                    {'loss': 2.7748, 'grad_norm': 1.6666676998138428, 'learning_rate': 4.846610169491526e-05, 'epoch': 0.05}
  5%|â–         | 281/6000 [13:06<4:16:38,  2.69s/it]  5%|â–         | 282/6000 [13:09<4:29:49,  2.83s/it]                                                    {'loss': 2.7827, 'grad_norm': 1.398642897605896, 'learning_rate': 4.845762711864407e-05, 'epoch': 0.05}
  5%|â–         | 282/6000 [13:09<4:29:49,  2.83s/it]  5%|â–         | 283/6000 [13:12<4:35:12,  2.89s/it]                                                    {'loss': 2.7791, 'grad_norm': 1.315597653388977, 'learning_rate': 4.844915254237288e-05, 'epoch': 0.05}
  5%|â–         | 283/6000 [13:12<4:35:12,  2.89s/it]  5%|â–         | 284/6000 [13:15<4:47:56,  3.02s/it]                                                    {'loss': 2.7817, 'grad_norm': 1.539353847503662, 'learning_rate': 4.84406779661017e-05, 'epoch': 0.05}
  5%|â–         | 284/6000 [13:15<4:47:56,  3.02s/it]  5%|â–         | 285/6000 [13:18<4:43:24,  2.98s/it]                                                    {'loss': 2.7717, 'grad_norm': 1.3577687740325928, 'learning_rate': 4.843220338983051e-05, 'epoch': 0.05}
  5%|â–         | 285/6000 [13:18<4:43:24,  2.98s/it]  5%|â–         | 286/6000 [13:21<4:32:23,  2.86s/it]                                                    {'loss': 2.7795, 'grad_norm': 1.122705340385437, 'learning_rate': 4.842372881355933e-05, 'epoch': 0.05}
  5%|â–         | 286/6000 [13:21<4:32:23,  2.86s/it]  5%|â–         | 287/6000 [13:23<4:28:32,  2.82s/it]                                                    {'loss': 2.7931, 'grad_norm': 1.2494823932647705, 'learning_rate': 4.841525423728814e-05, 'epoch': 0.05}
  5%|â–         | 287/6000 [13:23<4:28:32,  2.82s/it]  5%|â–         | 288/6000 [13:26<4:23:27,  2.77s/it]                                                    {'loss': 2.7775, 'grad_norm': 1.317891240119934, 'learning_rate': 4.840677966101695e-05, 'epoch': 0.05}
  5%|â–         | 288/6000 [13:26<4:23:27,  2.77s/it]  5%|â–         | 289/6000 [13:29<4:24:53,  2.78s/it]                                                    {'loss': 2.7724, 'grad_norm': 1.388071894645691, 'learning_rate': 4.839830508474576e-05, 'epoch': 0.05}
  5%|â–         | 289/6000 [13:29<4:24:53,  2.78s/it]  5%|â–         | 290/6000 [13:31<4:22:42,  2.76s/it]                                                    {'loss': 2.8107, 'grad_norm': 1.3270446062088013, 'learning_rate': 4.8389830508474574e-05, 'epoch': 0.05}
  5%|â–         | 290/6000 [13:31<4:22:42,  2.76s/it]  5%|â–         | 291/6000 [13:34<4:19:25,  2.73s/it]                                                    {'loss': 2.7863, 'grad_norm': 2.0649173259735107, 'learning_rate': 4.838135593220339e-05, 'epoch': 0.05}
  5%|â–         | 291/6000 [13:34<4:19:25,  2.73s/it]  5%|â–         | 292/6000 [13:37<4:16:57,  2.70s/it]                                                    {'loss': 2.7678, 'grad_norm': 1.4991198778152466, 'learning_rate': 4.83728813559322e-05, 'epoch': 0.05}
  5%|â–         | 292/6000 [13:37<4:16:57,  2.70s/it]  5%|â–         | 293/6000 [13:39<4:15:03,  2.68s/it]                                                    {'loss': 2.8422, 'grad_norm': 0.9812328815460205, 'learning_rate': 4.836440677966102e-05, 'epoch': 0.05}
  5%|â–         | 293/6000 [13:39<4:15:03,  2.68s/it]  5%|â–         | 294/6000 [13:42<4:15:21,  2.69s/it]                                                    {'loss': 2.7943, 'grad_norm': 1.3841584920883179, 'learning_rate': 4.835593220338983e-05, 'epoch': 0.05}
  5%|â–         | 294/6000 [13:42<4:15:21,  2.69s/it]  5%|â–         | 295/6000 [13:45<4:15:01,  2.68s/it]                                                    {'loss': 2.7793, 'grad_norm': 1.2572399377822876, 'learning_rate': 4.834745762711865e-05, 'epoch': 0.05}
  5%|â–         | 295/6000 [13:45<4:15:01,  2.68s/it]  5%|â–         | 296/6000 [13:48<4:18:35,  2.72s/it]                                                    {'loss': 2.77, 'grad_norm': 1.862438678741455, 'learning_rate': 4.833898305084746e-05, 'epoch': 0.05}
  5%|â–         | 296/6000 [13:48<4:18:35,  2.72s/it]  5%|â–         | 297/6000 [13:50<4:18:05,  2.72s/it]                                                    {'loss': 2.7805, 'grad_norm': 2.2609150409698486, 'learning_rate': 4.833050847457627e-05, 'epoch': 0.05}
  5%|â–         | 297/6000 [13:50<4:18:05,  2.72s/it]  5%|â–         | 298/6000 [13:53<4:22:07,  2.76s/it]                                                    {'loss': 2.7959, 'grad_norm': 6.584348678588867, 'learning_rate': 4.8322033898305084e-05, 'epoch': 0.05}
  5%|â–         | 298/6000 [13:53<4:22:07,  2.76s/it]  5%|â–         | 299/6000 [13:57<4:43:19,  2.98s/it]                                                    {'loss': 2.8045, 'grad_norm': 4.7461838722229, 'learning_rate': 4.83135593220339e-05, 'epoch': 0.05}
  5%|â–         | 299/6000 [13:57<4:43:19,  2.98s/it]  5%|â–Œ         | 300/6000 [13:59<4:35:29,  2.90s/it]                                                    {'loss': 2.7752, 'grad_norm': 1.7775498628616333, 'learning_rate': 4.8305084745762714e-05, 'epoch': 0.05}
  5%|â–Œ         | 300/6000 [13:59<4:35:29,  2.90s/it][2025-10-20 23:19:50,588] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  5%|â–Œ         | 301/6000 [14:04<5:38:15,  3.56s/it]                                                    {'loss': 2.803, 'grad_norm': 1.6616653203964233, 'learning_rate': 4.829661016949153e-05, 'epoch': 0.05}
  5%|â–Œ         | 301/6000 [14:04<5:38:15,  3.56s/it]  5%|â–Œ         | 302/6000 [14:07<5:14:16,  3.31s/it]                                                    {'loss': 2.7758, 'grad_norm': 1.2607945203781128, 'learning_rate': 4.828813559322034e-05, 'epoch': 0.05}
  5%|â–Œ         | 302/6000 [14:07<5:14:16,  3.31s/it]  5%|â–Œ         | 303/6000 [14:10<4:58:22,  3.14s/it]                                                    {'loss': 2.7754, 'grad_norm': 2.36034893989563, 'learning_rate': 4.8279661016949154e-05, 'epoch': 0.05}
  5%|â–Œ         | 303/6000 [14:10<4:58:22,  3.14s/it]  5%|â–Œ         | 304/6000 [14:13<4:48:18,  3.04s/it]                                                    {'loss': 2.8021, 'grad_norm': 2.7125322818756104, 'learning_rate': 4.8271186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 304/6000 [14:13<4:48:18,  3.04s/it]  5%|â–Œ         | 305/6000 [14:15<4:36:16,  2.91s/it]                                                    {'loss': 2.775, 'grad_norm': 2.924708366394043, 'learning_rate': 4.8262711864406784e-05, 'epoch': 0.05}
  5%|â–Œ         | 305/6000 [14:15<4:36:16,  2.91s/it]  5%|â–Œ         | 306/6000 [14:18<4:29:43,  2.84s/it]                                                    {'loss': 2.7783, 'grad_norm': 14.709872245788574, 'learning_rate': 4.8254237288135595e-05, 'epoch': 0.05}
  5%|â–Œ         | 306/6000 [14:18<4:29:43,  2.84s/it]  5%|â–Œ         | 307/6000 [14:21<4:24:06,  2.78s/it]                                                    {'loss': 2.7832, 'grad_norm': 3.282872200012207, 'learning_rate': 4.824576271186441e-05, 'epoch': 0.05}
  5%|â–Œ         | 307/6000 [14:21<4:24:06,  2.78s/it]  5%|â–Œ         | 308/6000 [14:23<4:20:21,  2.74s/it]                                                    {'loss': 2.7948, 'grad_norm': 1.3341618776321411, 'learning_rate': 4.8237288135593224e-05, 'epoch': 0.05}
  5%|â–Œ         | 308/6000 [14:23<4:20:21,  2.74s/it]  5%|â–Œ         | 309/6000 [14:26<4:22:41,  2.77s/it]                                                    {'loss': 2.7699, 'grad_norm': 1.1525839567184448, 'learning_rate': 4.8228813559322036e-05, 'epoch': 0.05}
  5%|â–Œ         | 309/6000 [14:26<4:22:41,  2.77s/it]  5%|â–Œ         | 310/6000 [14:29<4:20:01,  2.74s/it]                                                    {'loss': 2.8215, 'grad_norm': 1.241517186164856, 'learning_rate': 4.822033898305085e-05, 'epoch': 0.05}
  5%|â–Œ         | 310/6000 [14:29<4:20:01,  2.74s/it]  5%|â–Œ         | 311/6000 [14:31<4:17:49,  2.72s/it]                                                    {'loss': 2.7787, 'grad_norm': 1.30447518825531, 'learning_rate': 4.821186440677966e-05, 'epoch': 0.05}
  5%|â–Œ         | 311/6000 [14:31<4:17:49,  2.72s/it]  5%|â–Œ         | 312/6000 [14:34<4:16:57,  2.71s/it]                                                    {'loss': 2.7889, 'grad_norm': 1.5929795503616333, 'learning_rate': 4.8203389830508476e-05, 'epoch': 0.05}
  5%|â–Œ         | 312/6000 [14:34<4:16:57,  2.71s/it]  5%|â–Œ         | 313/6000 [14:37<4:16:24,  2.71s/it]                                                    {'loss': 2.8363, 'grad_norm': 1.2886053323745728, 'learning_rate': 4.819491525423729e-05, 'epoch': 0.05}
  5%|â–Œ         | 313/6000 [14:37<4:16:24,  2.71s/it]  5%|â–Œ         | 314/6000 [14:40<4:15:20,  2.69s/it]                                                    {'loss': 2.8076, 'grad_norm': 1.9922738075256348, 'learning_rate': 4.8186440677966105e-05, 'epoch': 0.05}
  5%|â–Œ         | 314/6000 [14:40<4:15:20,  2.69s/it]  5%|â–Œ         | 315/6000 [14:42<4:13:45,  2.68s/it]                                                    {'loss': 2.7781, 'grad_norm': 1.3188538551330566, 'learning_rate': 4.817796610169492e-05, 'epoch': 0.05}
  5%|â–Œ         | 315/6000 [14:42<4:13:45,  2.68s/it]  5%|â–Œ         | 316/6000 [14:45<4:13:00,  2.67s/it]                                                    {'loss': 2.7688, 'grad_norm': 1.3409910202026367, 'learning_rate': 4.8169491525423735e-05, 'epoch': 0.05}
  5%|â–Œ         | 316/6000 [14:45<4:13:00,  2.67s/it]  5%|â–Œ         | 317/6000 [14:48<4:17:58,  2.72s/it]                                                    {'loss': 2.8627, 'grad_norm': 2.1000399589538574, 'learning_rate': 4.8161016949152546e-05, 'epoch': 0.05}
  5%|â–Œ         | 317/6000 [14:48<4:17:58,  2.72s/it]  5%|â–Œ         | 318/6000 [14:51<4:26:11,  2.81s/it]                                                    {'loss': 2.7711, 'grad_norm': 1.2572726011276245, 'learning_rate': 4.815254237288136e-05, 'epoch': 0.05}
  5%|â–Œ         | 318/6000 [14:51<4:26:11,  2.81s/it]  5%|â–Œ         | 319/6000 [14:53<4:22:04,  2.77s/it]                                                    {'loss': 2.7708, 'grad_norm': 1.6610108613967896, 'learning_rate': 4.814406779661017e-05, 'epoch': 0.05}
  5%|â–Œ         | 319/6000 [14:53<4:22:04,  2.77s/it]  5%|â–Œ         | 320/6000 [14:56<4:21:10,  2.76s/it]                                                    {'loss': 2.7577, 'grad_norm': 1.9376740455627441, 'learning_rate': 4.813559322033899e-05, 'epoch': 0.05}
  5%|â–Œ         | 320/6000 [14:56<4:21:10,  2.76s/it]  5%|â–Œ         | 321/6000 [14:59<4:30:34,  2.86s/it]                                                    {'loss': 2.792, 'grad_norm': 1.9198795557022095, 'learning_rate': 4.81271186440678e-05, 'epoch': 0.05}
  5%|â–Œ         | 321/6000 [14:59<4:30:34,  2.86s/it]  5%|â–Œ         | 322/6000 [15:02<4:26:16,  2.81s/it]                                                    {'loss': 2.7727, 'grad_norm': 2.1919262409210205, 'learning_rate': 4.8118644067796616e-05, 'epoch': 0.05}
  5%|â–Œ         | 322/6000 [15:02<4:26:16,  2.81s/it]  5%|â–Œ         | 323/6000 [15:05<4:38:45,  2.95s/it]                                                    {'loss': 2.7775, 'grad_norm': 1.910197138786316, 'learning_rate': 4.811016949152543e-05, 'epoch': 0.05}
  5%|â–Œ         | 323/6000 [15:05<4:38:45,  2.95s/it]  5%|â–Œ         | 324/6000 [15:08<4:30:25,  2.86s/it]                                                    {'loss': 2.7882, 'grad_norm': 1.5045206546783447, 'learning_rate': 4.810169491525424e-05, 'epoch': 0.05}
  5%|â–Œ         | 324/6000 [15:08<4:30:25,  2.86s/it]  5%|â–Œ         | 325/6000 [15:10<4:24:55,  2.80s/it]                                                    {'loss': 2.764, 'grad_norm': 2.765265703201294, 'learning_rate': 4.809322033898305e-05, 'epoch': 0.05}
  5%|â–Œ         | 325/6000 [15:10<4:24:55,  2.80s/it]  5%|â–Œ         | 326/6000 [15:13<4:20:48,  2.76s/it]                                                    {'loss': 2.7892, 'grad_norm': 2.4522340297698975, 'learning_rate': 4.808474576271187e-05, 'epoch': 0.05}
  5%|â–Œ         | 326/6000 [15:13<4:20:48,  2.76s/it]  5%|â–Œ         | 327/6000 [15:16<4:18:14,  2.73s/it]                                                    {'loss': 2.7786, 'grad_norm': 2.3767647743225098, 'learning_rate': 4.807627118644068e-05, 'epoch': 0.05}
  5%|â–Œ         | 327/6000 [15:16<4:18:14,  2.73s/it]  5%|â–Œ         | 328/6000 [15:19<4:18:35,  2.74s/it]                                                    {'loss': 2.741, 'grad_norm': 3.6310908794403076, 'learning_rate': 4.80677966101695e-05, 'epoch': 0.05}
  5%|â–Œ         | 328/6000 [15:19<4:18:35,  2.74s/it]  5%|â–Œ         | 329/6000 [15:21<4:16:54,  2.72s/it]                                                    {'loss': 2.8176, 'grad_norm': 3.588446617126465, 'learning_rate': 4.805932203389831e-05, 'epoch': 0.05}
  5%|â–Œ         | 329/6000 [15:21<4:16:54,  2.72s/it]  6%|â–Œ         | 330/6000 [15:24<4:15:37,  2.71s/it]                                                    {'loss': 2.7852, 'grad_norm': 2.601137161254883, 'learning_rate': 4.805084745762712e-05, 'epoch': 0.06}
  6%|â–Œ         | 330/6000 [15:24<4:15:37,  2.71s/it]  6%|â–Œ         | 331/6000 [15:27<4:15:03,  2.70s/it]                                                    {'loss': 2.803, 'grad_norm': 3.6976540088653564, 'learning_rate': 4.804237288135594e-05, 'epoch': 0.06}
  6%|â–Œ         | 331/6000 [15:27<4:15:03,  2.70s/it]  6%|â–Œ         | 332/6000 [15:29<4:12:14,  2.67s/it]                                                    {'loss': 2.7589, 'grad_norm': 2.727834463119507, 'learning_rate': 4.803389830508474e-05, 'epoch': 0.06}
  6%|â–Œ         | 332/6000 [15:29<4:12:14,  2.67s/it]  6%|â–Œ         | 333/6000 [15:32<4:18:36,  2.74s/it]                                                    {'loss': 2.7761, 'grad_norm': 2.592926502227783, 'learning_rate': 4.802542372881356e-05, 'epoch': 0.06}
  6%|â–Œ         | 333/6000 [15:32<4:18:36,  2.74s/it]  6%|â–Œ         | 334/6000 [15:35<4:16:11,  2.71s/it]                                                    {'loss': 2.8056, 'grad_norm': 3.071019172668457, 'learning_rate': 4.801694915254237e-05, 'epoch': 0.06}
  6%|â–Œ         | 334/6000 [15:35<4:16:11,  2.71s/it]  6%|â–Œ         | 335/6000 [15:37<4:16:41,  2.72s/it]                                                    {'loss': 2.807, 'grad_norm': 2.8551807403564453, 'learning_rate': 4.800847457627119e-05, 'epoch': 0.06}
  6%|â–Œ         | 335/6000 [15:37<4:16:41,  2.72s/it]  6%|â–Œ         | 336/6000 [15:40<4:13:17,  2.68s/it]                                                    {'loss': 2.7814, 'grad_norm': 1.5970728397369385, 'learning_rate': 4.8e-05, 'epoch': 0.06}
  6%|â–Œ         | 336/6000 [15:40<4:13:17,  2.68s/it]  6%|â–Œ         | 337/6000 [15:43<4:16:31,  2.72s/it]                                                    {'loss': 2.7817, 'grad_norm': 1.6533186435699463, 'learning_rate': 4.799152542372882e-05, 'epoch': 0.06}
  6%|â–Œ         | 337/6000 [15:43<4:16:31,  2.72s/it]  6%|â–Œ         | 338/6000 [15:45<4:14:07,  2.69s/it]                                                    {'loss': 2.786, 'grad_norm': 2.003222703933716, 'learning_rate': 4.798305084745763e-05, 'epoch': 0.06}
  6%|â–Œ         | 338/6000 [15:45<4:14:07,  2.69s/it]  6%|â–Œ         | 339/6000 [15:48<4:13:37,  2.69s/it]                                                    {'loss': 2.7733, 'grad_norm': 1.3465144634246826, 'learning_rate': 4.797457627118644e-05, 'epoch': 0.06}
  6%|â–Œ         | 339/6000 [15:48<4:13:37,  2.69s/it]  6%|â–Œ         | 340/6000 [15:51<4:20:59,  2.77s/it]                                                    {'loss': 2.7598, 'grad_norm': 1.9262652397155762, 'learning_rate': 4.796610169491525e-05, 'epoch': 0.06}
  6%|â–Œ         | 340/6000 [15:51<4:20:59,  2.77s/it]  6%|â–Œ         | 341/6000 [15:54<4:17:06,  2.73s/it]                                                    {'loss': 2.7587, 'grad_norm': 1.787028431892395, 'learning_rate': 4.795762711864407e-05, 'epoch': 0.06}
  6%|â–Œ         | 341/6000 [15:54<4:17:06,  2.73s/it]  6%|â–Œ         | 342/6000 [15:56<4:14:56,  2.70s/it]                                                    {'loss': 2.8124, 'grad_norm': 1.9797945022583008, 'learning_rate': 4.794915254237288e-05, 'epoch': 0.06}
  6%|â–Œ         | 342/6000 [15:56<4:14:56,  2.70s/it]  6%|â–Œ         | 343/6000 [16:00<4:31:10,  2.88s/it]                                                    {'loss': 2.8119, 'grad_norm': 1.9937958717346191, 'learning_rate': 4.79406779661017e-05, 'epoch': 0.06}
  6%|â–Œ         | 343/6000 [16:00<4:31:10,  2.88s/it]  6%|â–Œ         | 344/6000 [16:02<4:25:18,  2.81s/it]                                                    {'loss': 2.7776, 'grad_norm': 2.099369764328003, 'learning_rate': 4.793220338983051e-05, 'epoch': 0.06}
  6%|â–Œ         | 344/6000 [16:02<4:25:18,  2.81s/it]  6%|â–Œ         | 345/6000 [16:05<4:21:50,  2.78s/it]                                                    {'loss': 2.8247, 'grad_norm': 2.115022897720337, 'learning_rate': 4.792372881355933e-05, 'epoch': 0.06}
  6%|â–Œ         | 345/6000 [16:05<4:21:50,  2.78s/it]  6%|â–Œ         | 346/6000 [16:08<4:19:32,  2.75s/it]                                                    {'loss': 2.8166, 'grad_norm': 2.166188955307007, 'learning_rate': 4.7915254237288134e-05, 'epoch': 0.06}
  6%|â–Œ         | 346/6000 [16:08<4:19:32,  2.75s/it]  6%|â–Œ         | 347/6000 [16:10<4:15:58,  2.72s/it]                                                    {'loss': 2.795, 'grad_norm': 1.8473814725875854, 'learning_rate': 4.790677966101695e-05, 'epoch': 0.06}
  6%|â–Œ         | 347/6000 [16:10<4:15:58,  2.72s/it]  6%|â–Œ         | 348/6000 [16:13<4:19:27,  2.75s/it]                                                    {'loss': 2.7908, 'grad_norm': 2.087998867034912, 'learning_rate': 4.7898305084745764e-05, 'epoch': 0.06}
  6%|â–Œ         | 348/6000 [16:13<4:19:27,  2.75s/it]  6%|â–Œ         | 349/6000 [16:16<4:16:54,  2.73s/it]                                                    {'loss': 2.7949, 'grad_norm': 1.9538902044296265, 'learning_rate': 4.788983050847458e-05, 'epoch': 0.06}
  6%|â–Œ         | 349/6000 [16:16<4:16:54,  2.73s/it]  6%|â–Œ         | 350/6000 [16:19<4:16:57,  2.73s/it]                                                    {'loss': 2.7848, 'grad_norm': 1.7885489463806152, 'learning_rate': 4.788135593220339e-05, 'epoch': 0.06}
  6%|â–Œ         | 350/6000 [16:19<4:16:57,  2.73s/it][2025-10-20 23:22:09,868] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  6%|â–Œ         | 351/6000 [16:24<5:20:00,  3.40s/it]                                                    {'loss': 2.7392, 'grad_norm': 2.931255340576172, 'learning_rate': 4.7872881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 351/6000 [16:24<5:20:00,  3.40s/it]  6%|â–Œ         | 352/6000 [16:26<5:00:26,  3.19s/it]                                                    {'loss': 2.7522, 'grad_norm': 2.5969693660736084, 'learning_rate': 4.786440677966102e-05, 'epoch': 0.06}
  6%|â–Œ         | 352/6000 [16:26<5:00:26,  3.19s/it]  6%|â–Œ         | 353/6000 [16:29<4:45:32,  3.03s/it]                                                    {'loss': 2.8206, 'grad_norm': 2.1961591243743896, 'learning_rate': 4.7855932203389834e-05, 'epoch': 0.06}
  6%|â–Œ         | 353/6000 [16:29<4:45:32,  3.03s/it]  6%|â–Œ         | 354/6000 [16:32<4:35:09,  2.92s/it]                                                    {'loss': 2.805, 'grad_norm': 3.3533668518066406, 'learning_rate': 4.7847457627118645e-05, 'epoch': 0.06}
  6%|â–Œ         | 354/6000 [16:32<4:35:09,  2.92s/it]  6%|â–Œ         | 355/6000 [16:34<4:27:42,  2.85s/it]                                                    {'loss': 2.8304, 'grad_norm': 3.8111109733581543, 'learning_rate': 4.7838983050847456e-05, 'epoch': 0.06}
  6%|â–Œ         | 355/6000 [16:34<4:27:42,  2.85s/it]  6%|â–Œ         | 356/6000 [16:37<4:29:39,  2.87s/it]                                                    {'loss': 2.7603, 'grad_norm': 3.567300796508789, 'learning_rate': 4.7830508474576274e-05, 'epoch': 0.06}
  6%|â–Œ         | 356/6000 [16:37<4:29:39,  2.87s/it]  6%|â–Œ         | 357/6000 [16:40<4:23:58,  2.81s/it]                                                    {'loss': 2.8024, 'grad_norm': 3.3225319385528564, 'learning_rate': 4.7822033898305086e-05, 'epoch': 0.06}
  6%|â–Œ         | 357/6000 [16:40<4:23:58,  2.81s/it]  6%|â–Œ         | 358/6000 [16:42<4:18:28,  2.75s/it]                                                    {'loss': 2.7805, 'grad_norm': 2.942783832550049, 'learning_rate': 4.7813559322033904e-05, 'epoch': 0.06}
  6%|â–Œ         | 358/6000 [16:42<4:18:28,  2.75s/it]  6%|â–Œ         | 359/6000 [16:45<4:16:37,  2.73s/it]                                                    {'loss': 2.7782, 'grad_norm': 2.899491548538208, 'learning_rate': 4.7805084745762715e-05, 'epoch': 0.06}
  6%|â–Œ         | 359/6000 [16:45<4:16:37,  2.73s/it]  6%|â–Œ         | 360/6000 [16:48<4:14:02,  2.70s/it]                                                    {'loss': 2.8282, 'grad_norm': 3.3464207649230957, 'learning_rate': 4.7796610169491526e-05, 'epoch': 0.06}
  6%|â–Œ         | 360/6000 [16:48<4:14:02,  2.70s/it]  6%|â–Œ         | 361/6000 [16:50<4:12:08,  2.68s/it]                                                    {'loss': 2.7997, 'grad_norm': 3.1539740562438965, 'learning_rate': 4.778813559322034e-05, 'epoch': 0.06}
  6%|â–Œ         | 361/6000 [16:50<4:12:08,  2.68s/it]  6%|â–Œ         | 362/6000 [16:53<4:09:41,  2.66s/it]                                                    {'loss': 2.7583, 'grad_norm': 2.28875994682312, 'learning_rate': 4.7779661016949156e-05, 'epoch': 0.06}
  6%|â–Œ         | 362/6000 [16:53<4:09:41,  2.66s/it]  6%|â–Œ         | 363/6000 [16:56<4:10:25,  2.67s/it]                                                    {'loss': 2.8161, 'grad_norm': 2.731558084487915, 'learning_rate': 4.777118644067797e-05, 'epoch': 0.06}
  6%|â–Œ         | 363/6000 [16:56<4:10:25,  2.67s/it]  6%|â–Œ         | 364/6000 [16:59<4:15:10,  2.72s/it]                                                    {'loss': 2.7782, 'grad_norm': 2.029787063598633, 'learning_rate': 4.7762711864406785e-05, 'epoch': 0.06}
  6%|â–Œ         | 364/6000 [16:59<4:15:10,  2.72s/it]  6%|â–Œ         | 365/6000 [17:01<4:13:33,  2.70s/it]                                                    {'loss': 2.7739, 'grad_norm': 1.7089670896530151, 'learning_rate': 4.7754237288135596e-05, 'epoch': 0.06}
  6%|â–Œ         | 365/6000 [17:01<4:13:33,  2.70s/it]  6%|â–Œ         | 366/6000 [17:04<4:13:05,  2.70s/it]                                                    {'loss': 2.7777, 'grad_norm': 1.5647209882736206, 'learning_rate': 4.7745762711864414e-05, 'epoch': 0.06}
  6%|â–Œ         | 366/6000 [17:04<4:13:05,  2.70s/it]  6%|â–Œ         | 367/6000 [17:07<4:12:06,  2.69s/it]                                                    {'loss': 2.7779, 'grad_norm': 1.364536166191101, 'learning_rate': 4.773728813559322e-05, 'epoch': 0.06}
  6%|â–Œ         | 367/6000 [17:07<4:12:06,  2.69s/it]  6%|â–Œ         | 368/6000 [17:10<4:25:13,  2.83s/it]                                                    {'loss': 2.7724, 'grad_norm': 1.3863688707351685, 'learning_rate': 4.772881355932204e-05, 'epoch': 0.06}
  6%|â–Œ         | 368/6000 [17:10<4:25:13,  2.83s/it]  6%|â–Œ         | 369/6000 [17:12<4:21:54,  2.79s/it]                                                    {'loss': 2.7987, 'grad_norm': 1.7589843273162842, 'learning_rate': 4.772033898305085e-05, 'epoch': 0.06}
  6%|â–Œ         | 369/6000 [17:12<4:21:54,  2.79s/it]  6%|â–Œ         | 370/6000 [17:15<4:19:13,  2.76s/it]                                                    {'loss': 2.768, 'grad_norm': 1.4392077922821045, 'learning_rate': 4.7711864406779666e-05, 'epoch': 0.06}
  6%|â–Œ         | 370/6000 [17:15<4:19:13,  2.76s/it]  6%|â–Œ         | 371/6000 [17:18<4:16:09,  2.73s/it]                                                    {'loss': 2.7738, 'grad_norm': 1.2834867238998413, 'learning_rate': 4.770338983050848e-05, 'epoch': 0.06}
  6%|â–Œ         | 371/6000 [17:18<4:16:09,  2.73s/it]  6%|â–Œ         | 372/6000 [17:20<4:14:46,  2.72s/it]                                                    {'loss': 2.7806, 'grad_norm': 1.285212516784668, 'learning_rate': 4.769491525423729e-05, 'epoch': 0.06}
  6%|â–Œ         | 372/6000 [17:20<4:14:46,  2.72s/it]  6%|â–Œ         | 373/6000 [17:23<4:13:04,  2.70s/it]                                                    {'loss': 2.8973, 'grad_norm': 0.9820420742034912, 'learning_rate': 4.768644067796611e-05, 'epoch': 0.06}
  6%|â–Œ         | 373/6000 [17:23<4:13:04,  2.70s/it]  6%|â–Œ         | 374/6000 [17:26<4:14:18,  2.71s/it]                                                    {'loss': 2.7926, 'grad_norm': 1.6393355131149292, 'learning_rate': 4.767796610169492e-05, 'epoch': 0.06}
  6%|â–Œ         | 374/6000 [17:26<4:14:18,  2.71s/it]  6%|â–‹         | 375/6000 [17:29<4:13:32,  2.70s/it]                                                    {'loss': 2.7949, 'grad_norm': 1.74013090133667, 'learning_rate': 4.766949152542373e-05, 'epoch': 0.06}
  6%|â–‹         | 375/6000 [17:29<4:13:32,  2.70s/it]  6%|â–‹         | 376/6000 [17:31<4:13:14,  2.70s/it]                                                    {'loss': 2.7793, 'grad_norm': 1.5046207904815674, 'learning_rate': 4.766101694915254e-05, 'epoch': 0.06}
  6%|â–‹         | 376/6000 [17:31<4:13:14,  2.70s/it]  6%|â–‹         | 377/6000 [17:34<4:18:58,  2.76s/it]                                                    {'loss': 2.8164, 'grad_norm': 1.6891753673553467, 'learning_rate': 4.765254237288136e-05, 'epoch': 0.06}
  6%|â–‹         | 377/6000 [17:34<4:18:58,  2.76s/it]  6%|â–‹         | 378/6000 [17:37<4:19:12,  2.77s/it]                                                    {'loss': 2.7581, 'grad_norm': 1.859819769859314, 'learning_rate': 4.764406779661017e-05, 'epoch': 0.06}
  6%|â–‹         | 378/6000 [17:37<4:19:12,  2.77s/it]  6%|â–‹         | 379/6000 [17:40<4:17:52,  2.75s/it]                                                    {'loss': 2.7889, 'grad_norm': 1.6948387622833252, 'learning_rate': 4.763559322033899e-05, 'epoch': 0.06}
  6%|â–‹         | 379/6000 [17:40<4:17:52,  2.75s/it]  6%|â–‹         | 380/6000 [17:43<4:25:34,  2.84s/it]                                                    {'loss': 2.7771, 'grad_norm': 2.1508495807647705, 'learning_rate': 4.76271186440678e-05, 'epoch': 0.06}
  6%|â–‹         | 380/6000 [17:43<4:25:34,  2.84s/it]  6%|â–‹         | 381/6000 [17:45<4:19:53,  2.78s/it]                                                    {'loss': 2.7893, 'grad_norm': 2.1869897842407227, 'learning_rate': 4.761864406779661e-05, 'epoch': 0.06}
  6%|â–‹         | 381/6000 [17:45<4:19:53,  2.78s/it]  6%|â–‹         | 382/6000 [17:48<4:17:49,  2.75s/it]                                                    {'loss': 2.7581, 'grad_norm': 2.0452873706817627, 'learning_rate': 4.761016949152542e-05, 'epoch': 0.06}
  6%|â–‹         | 382/6000 [17:48<4:17:49,  2.75s/it]  6%|â–‹         | 383/6000 [17:51<4:17:22,  2.75s/it]                                                    {'loss': 2.7987, 'grad_norm': 1.9192745685577393, 'learning_rate': 4.760169491525424e-05, 'epoch': 0.06}
  6%|â–‹         | 383/6000 [17:51<4:17:22,  2.75s/it]  6%|â–‹         | 384/6000 [17:53<4:15:55,  2.73s/it]                                                    {'loss': 2.8017, 'grad_norm': 2.5892441272735596, 'learning_rate': 4.759322033898305e-05, 'epoch': 0.06}
  6%|â–‹         | 384/6000 [17:53<4:15:55,  2.73s/it]  6%|â–‹         | 385/6000 [17:56<4:24:44,  2.83s/it]                                                    {'loss': 2.7911, 'grad_norm': 2.56856369972229, 'learning_rate': 4.758474576271187e-05, 'epoch': 0.06}
  6%|â–‹         | 385/6000 [17:56<4:24:44,  2.83s/it]  6%|â–‹         | 386/6000 [17:59<4:22:28,  2.81s/it]                                                    {'loss': 2.7856, 'grad_norm': 2.2254600524902344, 'learning_rate': 4.757627118644068e-05, 'epoch': 0.06}
  6%|â–‹         | 386/6000 [17:59<4:22:28,  2.81s/it]  6%|â–‹         | 387/6000 [18:02<4:31:55,  2.91s/it]                                                    {'loss': 2.7676, 'grad_norm': 2.732297658920288, 'learning_rate': 4.75677966101695e-05, 'epoch': 0.06}
  6%|â–‹         | 387/6000 [18:02<4:31:55,  2.91s/it]  6%|â–‹         | 388/6000 [18:05<4:30:12,  2.89s/it]                                                    {'loss': 2.8176, 'grad_norm': 1.6177510023117065, 'learning_rate': 4.755932203389831e-05, 'epoch': 0.06}
  6%|â–‹         | 388/6000 [18:05<4:30:12,  2.89s/it]  6%|â–‹         | 389/6000 [18:08<4:24:01,  2.82s/it]                                                    {'loss': 2.7863, 'grad_norm': 1.965978980064392, 'learning_rate': 4.755084745762712e-05, 'epoch': 0.06}
  6%|â–‹         | 389/6000 [18:08<4:24:01,  2.82s/it]  6%|â–‹         | 390/6000 [18:11<4:20:44,  2.79s/it]                                                    {'loss': 2.7688, 'grad_norm': 1.6441787481307983, 'learning_rate': 4.754237288135593e-05, 'epoch': 0.07}
  6%|â–‹         | 390/6000 [18:11<4:20:44,  2.79s/it]  7%|â–‹         | 391/6000 [18:13<4:15:56,  2.74s/it]                                                    {'loss': 2.7661, 'grad_norm': 2.190671920776367, 'learning_rate': 4.7533898305084744e-05, 'epoch': 0.07}
  7%|â–‹         | 391/6000 [18:13<4:15:56,  2.74s/it]  7%|â–‹         | 392/6000 [18:16<4:15:39,  2.74s/it]                                                    {'loss': 2.7834, 'grad_norm': 1.9501293897628784, 'learning_rate': 4.752542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 392/6000 [18:16<4:15:39,  2.74s/it]  7%|â–‹         | 393/6000 [18:19<4:14:43,  2.73s/it]                                                    {'loss': 2.7808, 'grad_norm': 1.7587316036224365, 'learning_rate': 4.751694915254237e-05, 'epoch': 0.07}
  7%|â–‹         | 393/6000 [18:19<4:14:43,  2.73s/it]  7%|â–‹         | 394/6000 [18:21<4:14:19,  2.72s/it]                                                    {'loss': 2.7976, 'grad_norm': 1.4534027576446533, 'learning_rate': 4.750847457627119e-05, 'epoch': 0.07}
  7%|â–‹         | 394/6000 [18:21<4:14:19,  2.72s/it]  7%|â–‹         | 395/6000 [18:24<4:14:30,  2.72s/it]                                                    {'loss': 2.7869, 'grad_norm': 1.6027705669403076, 'learning_rate': 4.75e-05, 'epoch': 0.07}
  7%|â–‹         | 395/6000 [18:24<4:14:30,  2.72s/it]  7%|â–‹         | 396/6000 [18:27<4:13:14,  2.71s/it]                                                    {'loss': 2.7997, 'grad_norm': 1.6542032957077026, 'learning_rate': 4.7491525423728814e-05, 'epoch': 0.07}
  7%|â–‹         | 396/6000 [18:27<4:13:14,  2.71s/it]  7%|â–‹         | 397/6000 [18:30<4:22:44,  2.81s/it]                                                    {'loss': 2.772, 'grad_norm': 1.4764264822006226, 'learning_rate': 4.7483050847457625e-05, 'epoch': 0.07}
  7%|â–‹         | 397/6000 [18:30<4:22:44,  2.81s/it]  7%|â–‹         | 398/6000 [18:32<4:17:26,  2.76s/it]                                                    {'loss': 2.7718, 'grad_norm': 1.392695426940918, 'learning_rate': 4.747457627118644e-05, 'epoch': 0.07}
  7%|â–‹         | 398/6000 [18:32<4:17:26,  2.76s/it]  7%|â–‹         | 399/6000 [18:35<4:15:37,  2.74s/it]                                                    {'loss': 2.7775, 'grad_norm': 1.5239993333816528, 'learning_rate': 4.7466101694915255e-05, 'epoch': 0.07}
  7%|â–‹         | 399/6000 [18:35<4:15:37,  2.74s/it]  7%|â–‹         | 400/6000 [18:38<4:13:26,  2.72s/it]                                                    {'loss': 2.7723, 'grad_norm': 1.310943841934204, 'learning_rate': 4.745762711864407e-05, 'epoch': 0.07}
  7%|â–‹         | 400/6000 [18:38<4:13:26,  2.72s/it][2025-10-20 23:24:29,080] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  7%|â–‹         | 401/6000 [18:42<5:06:55,  3.29s/it]                                                    {'loss': 2.7709, 'grad_norm': 1.0978190898895264, 'learning_rate': 4.7449152542372884e-05, 'epoch': 0.07}
  7%|â–‹         | 401/6000 [18:42<5:06:55,  3.29s/it]  7%|â–‹         | 402/6000 [18:45<4:48:00,  3.09s/it]                                                    {'loss': 2.7753, 'grad_norm': 1.2402455806732178, 'learning_rate': 4.74406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 402/6000 [18:45<4:48:00,  3.09s/it]  7%|â–‹         | 403/6000 [18:48<4:36:53,  2.97s/it]                                                    {'loss': 2.7729, 'grad_norm': 1.7858290672302246, 'learning_rate': 4.7432203389830506e-05, 'epoch': 0.07}
  7%|â–‹         | 403/6000 [18:48<4:36:53,  2.97s/it]  7%|â–‹         | 404/6000 [18:51<4:33:03,  2.93s/it]                                                    {'loss': 2.7792, 'grad_norm': 1.3913758993148804, 'learning_rate': 4.7423728813559325e-05, 'epoch': 0.07}
  7%|â–‹         | 404/6000 [18:51<4:33:03,  2.93s/it]  7%|â–‹         | 405/6000 [18:53<4:26:10,  2.85s/it]                                                    {'loss': 2.7629, 'grad_norm': 1.6926695108413696, 'learning_rate': 4.7415254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 405/6000 [18:53<4:26:10,  2.85s/it]  7%|â–‹         | 406/6000 [18:56<4:21:18,  2.80s/it]                                                    {'loss': 2.8124, 'grad_norm': 40.06987380981445, 'learning_rate': 4.7406779661016954e-05, 'epoch': 0.07}
  7%|â–‹         | 406/6000 [18:56<4:21:18,  2.80s/it]  7%|â–‹         | 407/6000 [18:59<4:19:18,  2.78s/it]                                                    {'loss': 2.7621, 'grad_norm': 2.634582996368408, 'learning_rate': 4.7398305084745765e-05, 'epoch': 0.07}
  7%|â–‹         | 407/6000 [18:59<4:19:18,  2.78s/it]  7%|â–‹         | 408/6000 [19:02<4:36:37,  2.97s/it]                                                    {'loss': 2.8433, 'grad_norm': 21.943191528320312, 'learning_rate': 4.738983050847458e-05, 'epoch': 0.07}
  7%|â–‹         | 408/6000 [19:02<4:36:37,  2.97s/it]  7%|â–‹         | 409/6000 [19:05<4:29:14,  2.89s/it]                                                    {'loss': 2.7702, 'grad_norm': 1.4452470541000366, 'learning_rate': 4.7381355932203395e-05, 'epoch': 0.07}
  7%|â–‹         | 409/6000 [19:05<4:29:14,  2.89s/it]  7%|â–‹         | 410/6000 [19:07<4:22:30,  2.82s/it]                                                    {'loss': 2.7932, 'grad_norm': 1.7217603921890259, 'learning_rate': 4.7372881355932206e-05, 'epoch': 0.07}
  7%|â–‹         | 410/6000 [19:07<4:22:30,  2.82s/it]  7%|â–‹         | 411/6000 [19:11<4:37:33,  2.98s/it]                                                    {'loss': 2.7759, 'grad_norm': 1.96840500831604, 'learning_rate': 4.736440677966102e-05, 'epoch': 0.07}
  7%|â–‹         | 411/6000 [19:11<4:37:33,  2.98s/it]  7%|â–‹         | 412/6000 [19:13<4:26:45,  2.86s/it]                                                    {'loss': 2.8155, 'grad_norm': 1.3415606021881104, 'learning_rate': 4.735593220338983e-05, 'epoch': 0.07}
  7%|â–‹         | 412/6000 [19:13<4:26:45,  2.86s/it]  7%|â–‹         | 413/6000 [19:16<4:25:54,  2.86s/it]                                                    {'loss': 2.7738, 'grad_norm': 1.3687188625335693, 'learning_rate': 4.7347457627118646e-05, 'epoch': 0.07}
  7%|â–‹         | 413/6000 [19:16<4:25:54,  2.86s/it]  7%|â–‹         | 414/6000 [19:19<4:18:24,  2.78s/it]                                                    {'loss': 2.7921, 'grad_norm': 1.41191828250885, 'learning_rate': 4.733898305084746e-05, 'epoch': 0.07}
  7%|â–‹         | 414/6000 [19:19<4:18:24,  2.78s/it]  7%|â–‹         | 415/6000 [19:22<4:19:14,  2.79s/it]                                                    {'loss': 2.7667, 'grad_norm': 1.3492605686187744, 'learning_rate': 4.7330508474576276e-05, 'epoch': 0.07}
  7%|â–‹         | 415/6000 [19:22<4:19:14,  2.79s/it]  7%|â–‹         | 416/6000 [19:24<4:16:22,  2.75s/it]                                                    {'loss': 2.8035, 'grad_norm': 1.330322265625, 'learning_rate': 4.732203389830509e-05, 'epoch': 0.07}
  7%|â–‹         | 416/6000 [19:24<4:16:22,  2.75s/it]  7%|â–‹         | 417/6000 [19:27<4:13:30,  2.72s/it]                                                    {'loss': 2.8144, 'grad_norm': 2.615373373031616, 'learning_rate': 4.73135593220339e-05, 'epoch': 0.07}
  7%|â–‹         | 417/6000 [19:27<4:13:30,  2.72s/it]  7%|â–‹         | 418/6000 [19:30<4:18:10,  2.78s/it]                                                    {'loss': 2.7805, 'grad_norm': 1.3554023504257202, 'learning_rate': 4.730508474576271e-05, 'epoch': 0.07}
  7%|â–‹         | 418/6000 [19:30<4:18:10,  2.78s/it]  7%|â–‹         | 419/6000 [19:33<4:28:29,  2.89s/it]                                                    {'loss': 2.7773, 'grad_norm': 1.8138498067855835, 'learning_rate': 4.729661016949153e-05, 'epoch': 0.07}
  7%|â–‹         | 419/6000 [19:33<4:28:29,  2.89s/it]  7%|â–‹         | 420/6000 [19:36<4:23:17,  2.83s/it]                                                    {'loss': 2.795, 'grad_norm': 2.2294962406158447, 'learning_rate': 4.728813559322034e-05, 'epoch': 0.07}
  7%|â–‹         | 420/6000 [19:36<4:23:17,  2.83s/it]  7%|â–‹         | 421/6000 [19:38<4:20:12,  2.80s/it]                                                    {'loss': 2.7542, 'grad_norm': 2.791247606277466, 'learning_rate': 4.727966101694916e-05, 'epoch': 0.07}
  7%|â–‹         | 421/6000 [19:38<4:20:12,  2.80s/it]  7%|â–‹         | 422/6000 [19:41<4:15:48,  2.75s/it]                                                    {'loss': 2.779, 'grad_norm': 2.570617437362671, 'learning_rate': 4.727118644067797e-05, 'epoch': 0.07}
  7%|â–‹         | 422/6000 [19:41<4:15:48,  2.75s/it]  7%|â–‹         | 423/6000 [19:44<4:13:42,  2.73s/it]                                                    {'loss': 2.772, 'grad_norm': 2.3658063411712646, 'learning_rate': 4.7262711864406786e-05, 'epoch': 0.07}
  7%|â–‹         | 423/6000 [19:44<4:13:42,  2.73s/it]  7%|â–‹         | 424/6000 [19:46<4:10:54,  2.70s/it]                                                    {'loss': 2.7626, 'grad_norm': 3.57667875289917, 'learning_rate': 4.72542372881356e-05, 'epoch': 0.07}
  7%|â–‹         | 424/6000 [19:46<4:10:54,  2.70s/it]  7%|â–‹         | 425/6000 [19:49<4:08:15,  2.67s/it]                                                    {'loss': 2.7816, 'grad_norm': 3.1989707946777344, 'learning_rate': 4.724576271186441e-05, 'epoch': 0.07}
  7%|â–‹         | 425/6000 [19:49<4:08:15,  2.67s/it]  7%|â–‹         | 426/6000 [19:52<4:06:56,  2.66s/it]                                                    {'loss': 2.7354, 'grad_norm': 3.406700372695923, 'learning_rate': 4.723728813559322e-05, 'epoch': 0.07}
  7%|â–‹         | 426/6000 [19:52<4:06:56,  2.66s/it]  7%|â–‹         | 427/6000 [19:54<4:08:00,  2.67s/it]                                                    {'loss': 2.7794, 'grad_norm': 5.7576470375061035, 'learning_rate': 4.722881355932204e-05, 'epoch': 0.07}
  7%|â–‹         | 427/6000 [19:54<4:08:00,  2.67s/it]  7%|â–‹         | 428/6000 [19:57<4:07:35,  2.67s/it]                                                    {'loss': 2.844, 'grad_norm': 7.250178337097168, 'learning_rate': 4.722033898305085e-05, 'epoch': 0.07}
  7%|â–‹         | 428/6000 [19:57<4:07:35,  2.67s/it]  7%|â–‹         | 429/6000 [20:00<4:07:24,  2.66s/it]                                                    {'loss': 2.8083, 'grad_norm': 7.320207595825195, 'learning_rate': 4.721186440677967e-05, 'epoch': 0.07}
  7%|â–‹         | 429/6000 [20:00<4:07:24,  2.66s/it]  7%|â–‹         | 430/6000 [20:02<4:06:08,  2.65s/it]                                                    {'loss': 2.8381, 'grad_norm': 5.062579154968262, 'learning_rate': 4.720338983050848e-05, 'epoch': 0.07}
  7%|â–‹         | 430/6000 [20:02<4:06:08,  2.65s/it]  7%|â–‹         | 431/6000 [20:05<4:05:48,  2.65s/it]                                                    {'loss': 2.7895, 'grad_norm': 4.549731731414795, 'learning_rate': 4.719491525423729e-05, 'epoch': 0.07}
  7%|â–‹         | 431/6000 [20:05<4:05:48,  2.65s/it]  7%|â–‹         | 432/6000 [20:07<4:03:56,  2.63s/it]                                                    {'loss': 2.7999, 'grad_norm': 3.7730650901794434, 'learning_rate': 4.71864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 432/6000 [20:07<4:03:56,  2.63s/it]  7%|â–‹         | 433/6000 [20:10<4:02:10,  2.61s/it]                                                    {'loss': 2.7911, 'grad_norm': 3.959733724594116, 'learning_rate': 4.717796610169491e-05, 'epoch': 0.07}
  7%|â–‹         | 433/6000 [20:10<4:02:10,  2.61s/it]  7%|â–‹         | 434/6000 [20:13<4:04:25,  2.63s/it]                                                    {'loss': 2.7736, 'grad_norm': 4.6940178871154785, 'learning_rate': 4.716949152542373e-05, 'epoch': 0.07}
  7%|â–‹         | 434/6000 [20:13<4:04:25,  2.63s/it]  7%|â–‹         | 435/6000 [20:15<4:06:33,  2.66s/it]                                                    {'loss': 2.7523, 'grad_norm': 2.8302628993988037, 'learning_rate': 4.716101694915254e-05, 'epoch': 0.07}
  7%|â–‹         | 435/6000 [20:15<4:06:33,  2.66s/it]  7%|â–‹         | 436/6000 [20:18<4:07:53,  2.67s/it]                                                    {'loss': 2.7977, 'grad_norm': 2.235405683517456, 'learning_rate': 4.715254237288136e-05, 'epoch': 0.07}
  7%|â–‹         | 436/6000 [20:18<4:07:53,  2.67s/it]  7%|â–‹         | 437/6000 [20:21<4:11:37,  2.71s/it]                                                    {'loss': 2.7996, 'grad_norm': 2.4004971981048584, 'learning_rate': 4.714406779661017e-05, 'epoch': 0.07}
  7%|â–‹         | 437/6000 [20:21<4:11:37,  2.71s/it]  7%|â–‹         | 438/6000 [20:24<4:14:34,  2.75s/it]                                                    {'loss': 2.7776, 'grad_norm': 1.946079134941101, 'learning_rate': 4.713559322033898e-05, 'epoch': 0.07}
  7%|â–‹         | 438/6000 [20:24<4:14:34,  2.75s/it]  7%|â–‹         | 439/6000 [20:26<4:13:35,  2.74s/it]                                                    {'loss': 2.8057, 'grad_norm': 1.6736148595809937, 'learning_rate': 4.7127118644067794e-05, 'epoch': 0.07}
  7%|â–‹         | 439/6000 [20:26<4:13:35,  2.74s/it]  7%|â–‹         | 440/6000 [20:29<4:13:30,  2.74s/it]                                                    {'loss': 2.791, 'grad_norm': 2.2016892433166504, 'learning_rate': 4.711864406779661e-05, 'epoch': 0.07}
  7%|â–‹         | 440/6000 [20:29<4:13:30,  2.74s/it]  7%|â–‹         | 441/6000 [20:32<4:20:41,  2.81s/it]                                                    {'loss': 2.778, 'grad_norm': 13.24854850769043, 'learning_rate': 4.7110169491525423e-05, 'epoch': 0.07}
  7%|â–‹         | 441/6000 [20:32<4:20:41,  2.81s/it]  7%|â–‹         | 442/6000 [20:35<4:25:05,  2.86s/it]                                                    {'loss': 2.7826, 'grad_norm': 17.49553680419922, 'learning_rate': 4.710169491525424e-05, 'epoch': 0.07}
  7%|â–‹         | 442/6000 [20:35<4:25:05,  2.86s/it]  7%|â–‹         | 443/6000 [20:38<4:20:30,  2.81s/it]                                                    {'loss': 2.8425, 'grad_norm': 11.413475036621094, 'learning_rate': 4.709322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 443/6000 [20:38<4:20:30,  2.81s/it]  7%|â–‹         | 444/6000 [20:41<4:17:53,  2.78s/it]                                                    {'loss': 2.8302, 'grad_norm': 4.092933654785156, 'learning_rate': 4.708474576271187e-05, 'epoch': 0.07}
  7%|â–‹         | 444/6000 [20:41<4:17:53,  2.78s/it]  7%|â–‹         | 445/6000 [20:43<4:16:41,  2.77s/it]                                                    {'loss': 2.7774, 'grad_norm': 17.579784393310547, 'learning_rate': 4.707627118644068e-05, 'epoch': 0.07}
  7%|â–‹         | 445/6000 [20:43<4:16:41,  2.77s/it]  7%|â–‹         | 446/6000 [20:46<4:12:43,  2.73s/it]                                                    {'loss': 2.7767, 'grad_norm': 3.0633292198181152, 'learning_rate': 4.7067796610169493e-05, 'epoch': 0.07}
  7%|â–‹         | 446/6000 [20:46<4:12:43,  2.73s/it]  7%|â–‹         | 447/6000 [20:49<4:10:36,  2.71s/it]                                                    {'loss': 2.7735, 'grad_norm': 1.029404640197754, 'learning_rate': 4.7059322033898305e-05, 'epoch': 0.07}
  7%|â–‹         | 447/6000 [20:49<4:10:36,  2.71s/it]  7%|â–‹         | 448/6000 [20:51<4:08:36,  2.69s/it]                                                    {'loss': 2.7853, 'grad_norm': 1.2724632024765015, 'learning_rate': 4.705084745762712e-05, 'epoch': 0.07}
  7%|â–‹         | 448/6000 [20:51<4:08:36,  2.69s/it]  7%|â–‹         | 449/6000 [20:54<4:09:58,  2.70s/it]                                                    {'loss': 2.7686, 'grad_norm': 1.1708879470825195, 'learning_rate': 4.7042372881355934e-05, 'epoch': 0.07}
  7%|â–‹         | 449/6000 [20:54<4:09:58,  2.70s/it]  8%|â–Š         | 450/6000 [20:57<4:10:14,  2.71s/it]                                                    {'loss': 2.7741, 'grad_norm': 1.2912449836730957, 'learning_rate': 4.703389830508475e-05, 'epoch': 0.07}
  8%|â–Š         | 450/6000 [20:57<4:10:14,  2.71s/it][2025-10-20 23:26:48,003] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 451/6000 [21:01<5:02:42,  3.27s/it]                                                    {'loss': 2.7884, 'grad_norm': 1.40798819065094, 'learning_rate': 4.702542372881356e-05, 'epoch': 0.08}
  8%|â–Š         | 451/6000 [21:01<5:02:42,  3.27s/it]  8%|â–Š         | 452/6000 [21:04<4:54:26,  3.18s/it]                                                    {'loss': 2.786, 'grad_norm': 1.1109323501586914, 'learning_rate': 4.7016949152542375e-05, 'epoch': 0.08}
  8%|â–Š         | 452/6000 [21:04<4:54:26,  3.18s/it]  8%|â–Š         | 453/6000 [21:07<4:45:14,  3.09s/it]                                                    {'loss': 2.7712, 'grad_norm': 1.1624579429626465, 'learning_rate': 4.7008474576271186e-05, 'epoch': 0.08}
  8%|â–Š         | 453/6000 [21:07<4:45:14,  3.09s/it]  8%|â–Š         | 454/6000 [21:10<4:33:21,  2.96s/it]                                                    {'loss': 2.8518, 'grad_norm': 0.9823721647262573, 'learning_rate': 4.7e-05, 'epoch': 0.08}
  8%|â–Š         | 454/6000 [21:10<4:33:21,  2.96s/it]  8%|â–Š         | 455/6000 [21:12<4:24:19,  2.86s/it]                                                    {'loss': 2.7706, 'grad_norm': 0.9617066979408264, 'learning_rate': 4.6991525423728815e-05, 'epoch': 0.08}
  8%|â–Š         | 455/6000 [21:12<4:24:19,  2.86s/it]  8%|â–Š         | 456/6000 [21:15<4:17:47,  2.79s/it]                                                    {'loss': 2.7727, 'grad_norm': 0.7474566102027893, 'learning_rate': 4.6983050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 456/6000 [21:15<4:17:47,  2.79s/it]  8%|â–Š         | 457/6000 [21:18<4:13:22,  2.74s/it]                                                    {'loss': 2.8114, 'grad_norm': 0.8055999279022217, 'learning_rate': 4.6974576271186445e-05, 'epoch': 0.08}
  8%|â–Š         | 457/6000 [21:18<4:13:22,  2.74s/it]  8%|â–Š         | 458/6000 [21:20<4:11:16,  2.72s/it]                                                    {'loss': 2.8083, 'grad_norm': 0.8395607471466064, 'learning_rate': 4.6966101694915256e-05, 'epoch': 0.08}
  8%|â–Š         | 458/6000 [21:20<4:11:16,  2.72s/it]  8%|â–Š         | 459/6000 [21:23<4:09:16,  2.70s/it]                                                    {'loss': 2.7747, 'grad_norm': 0.9721062779426575, 'learning_rate': 4.6957627118644074e-05, 'epoch': 0.08}
  8%|â–Š         | 459/6000 [21:23<4:09:16,  2.70s/it]  8%|â–Š         | 460/6000 [21:26<4:07:09,  2.68s/it]                                                    {'loss': 2.7821, 'grad_norm': 0.9162372946739197, 'learning_rate': 4.694915254237288e-05, 'epoch': 0.08}
  8%|â–Š         | 460/6000 [21:26<4:07:09,  2.68s/it]  8%|â–Š         | 461/6000 [21:28<4:08:07,  2.69s/it]                                                    {'loss': 2.8057, 'grad_norm': 0.8388301134109497, 'learning_rate': 4.6940677966101697e-05, 'epoch': 0.08}
  8%|â–Š         | 461/6000 [21:28<4:08:07,  2.69s/it]  8%|â–Š         | 462/6000 [21:31<4:06:17,  2.67s/it]                                                    {'loss': 2.7707, 'grad_norm': 0.9809954166412354, 'learning_rate': 4.693220338983051e-05, 'epoch': 0.08}
  8%|â–Š         | 462/6000 [21:31<4:06:17,  2.67s/it]  8%|â–Š         | 463/6000 [21:34<4:07:34,  2.68s/it]                                                    {'loss': 2.7806, 'grad_norm': 0.9081180095672607, 'learning_rate': 4.6923728813559326e-05, 'epoch': 0.08}
  8%|â–Š         | 463/6000 [21:34<4:07:34,  2.68s/it]  8%|â–Š         | 464/6000 [21:36<4:06:36,  2.67s/it]                                                    {'loss': 2.7855, 'grad_norm': 0.8715722560882568, 'learning_rate': 4.691525423728814e-05, 'epoch': 0.08}
  8%|â–Š         | 464/6000 [21:36<4:06:36,  2.67s/it]  8%|â–Š         | 465/6000 [21:39<4:11:13,  2.72s/it]                                                    {'loss': 2.7706, 'grad_norm': 0.8699790835380554, 'learning_rate': 4.6906779661016955e-05, 'epoch': 0.08}
  8%|â–Š         | 465/6000 [21:39<4:11:13,  2.72s/it]  8%|â–Š         | 466/6000 [21:42<4:08:05,  2.69s/it]                                                    {'loss': 2.7799, 'grad_norm': 0.8612192869186401, 'learning_rate': 4.6898305084745767e-05, 'epoch': 0.08}
  8%|â–Š         | 466/6000 [21:42<4:08:05,  2.69s/it]  8%|â–Š         | 467/6000 [21:44<4:07:05,  2.68s/it]                                                    {'loss': 2.7882, 'grad_norm': 0.7104119062423706, 'learning_rate': 4.688983050847458e-05, 'epoch': 0.08}
  8%|â–Š         | 467/6000 [21:44<4:07:05,  2.68s/it]  8%|â–Š         | 468/6000 [21:47<4:08:39,  2.70s/it]                                                    {'loss': 2.7793, 'grad_norm': 0.7943100333213806, 'learning_rate': 4.688135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 468/6000 [21:47<4:08:39,  2.70s/it]  8%|â–Š         | 469/6000 [21:50<4:06:07,  2.67s/it]                                                    {'loss': 2.7731, 'grad_norm': 0.7717834115028381, 'learning_rate': 4.687288135593221e-05, 'epoch': 0.08}
  8%|â–Š         | 469/6000 [21:50<4:06:07,  2.67s/it]  8%|â–Š         | 470/6000 [21:52<4:06:44,  2.68s/it]                                                    {'loss': 2.7685, 'grad_norm': 0.7241281270980835, 'learning_rate': 4.686440677966102e-05, 'epoch': 0.08}
  8%|â–Š         | 470/6000 [21:53<4:06:44,  2.68s/it]  8%|â–Š         | 471/6000 [21:55<4:04:12,  2.65s/it]                                                    {'loss': 2.8426, 'grad_norm': 0.7733606100082397, 'learning_rate': 4.6855932203389837e-05, 'epoch': 0.08}
  8%|â–Š         | 471/6000 [21:55<4:04:12,  2.65s/it]  8%|â–Š         | 472/6000 [21:58<4:03:35,  2.64s/it]                                                    {'loss': 2.8065, 'grad_norm': 0.8185741901397705, 'learning_rate': 4.684745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 472/6000 [21:58<4:03:35,  2.64s/it]  8%|â–Š         | 473/6000 [22:00<4:03:17,  2.64s/it]                                                    {'loss': 2.7698, 'grad_norm': 0.8459742069244385, 'learning_rate': 4.6838983050847466e-05, 'epoch': 0.08}
  8%|â–Š         | 473/6000 [22:00<4:03:17,  2.64s/it]  8%|â–Š         | 474/6000 [22:03<4:02:52,  2.64s/it]                                                    {'loss': 2.7768, 'grad_norm': 0.8536418676376343, 'learning_rate': 4.683050847457627e-05, 'epoch': 0.08}
  8%|â–Š         | 474/6000 [22:03<4:02:52,  2.64s/it]  8%|â–Š         | 475/6000 [22:06<4:03:23,  2.64s/it]                                                    {'loss': 2.7749, 'grad_norm': 0.8583251237869263, 'learning_rate': 4.682203389830508e-05, 'epoch': 0.08}
  8%|â–Š         | 475/6000 [22:06<4:03:23,  2.64s/it]  8%|â–Š         | 476/6000 [22:08<4:01:57,  2.63s/it]                                                    {'loss': 2.7929, 'grad_norm': 0.7874875068664551, 'learning_rate': 4.68135593220339e-05, 'epoch': 0.08}
  8%|â–Š         | 476/6000 [22:08<4:01:57,  2.63s/it]  8%|â–Š         | 477/6000 [22:11<4:01:45,  2.63s/it]                                                    {'loss': 2.7768, 'grad_norm': 0.7906013131141663, 'learning_rate': 4.680508474576271e-05, 'epoch': 0.08}
  8%|â–Š         | 477/6000 [22:11<4:01:45,  2.63s/it]  8%|â–Š         | 478/6000 [22:13<4:02:07,  2.63s/it]                                                    {'loss': 2.7773, 'grad_norm': 0.9720460176467896, 'learning_rate': 4.679661016949153e-05, 'epoch': 0.08}
  8%|â–Š         | 478/6000 [22:14<4:02:07,  2.63s/it]  8%|â–Š         | 479/6000 [22:16<4:02:45,  2.64s/it]                                                    {'loss': 2.7907, 'grad_norm': 1.0235835313796997, 'learning_rate': 4.678813559322034e-05, 'epoch': 0.08}
  8%|â–Š         | 479/6000 [22:16<4:02:45,  2.64s/it]  8%|â–Š         | 480/6000 [22:19<4:02:38,  2.64s/it]                                                    {'loss': 2.7755, 'grad_norm': 0.7977710366249084, 'learning_rate': 4.677966101694916e-05, 'epoch': 0.08}
  8%|â–Š         | 480/6000 [22:19<4:02:38,  2.64s/it]  8%|â–Š         | 481/6000 [22:22<4:06:15,  2.68s/it]                                                    {'loss': 2.7656, 'grad_norm': 1.0194677114486694, 'learning_rate': 4.677118644067797e-05, 'epoch': 0.08}
  8%|â–Š         | 481/6000 [22:22<4:06:15,  2.68s/it]  8%|â–Š         | 482/6000 [22:24<4:06:55,  2.68s/it]                                                    {'loss': 2.7734, 'grad_norm': 1.0788341760635376, 'learning_rate': 4.676271186440678e-05, 'epoch': 0.08}
  8%|â–Š         | 482/6000 [22:24<4:06:55,  2.68s/it]  8%|â–Š         | 483/6000 [22:27<4:07:14,  2.69s/it]                                                    {'loss': 2.7931, 'grad_norm': 0.994637668132782, 'learning_rate': 4.675423728813559e-05, 'epoch': 0.08}
  8%|â–Š         | 483/6000 [22:27<4:07:14,  2.69s/it]  8%|â–Š         | 484/6000 [22:30<4:09:34,  2.71s/it]                                                    {'loss': 2.7728, 'grad_norm': 0.9140066504478455, 'learning_rate': 4.674576271186441e-05, 'epoch': 0.08}
  8%|â–Š         | 484/6000 [22:30<4:09:34,  2.71s/it]  8%|â–Š         | 485/6000 [22:33<4:21:07,  2.84s/it]                                                    {'loss': 2.7757, 'grad_norm': 1.091578722000122, 'learning_rate': 4.673728813559322e-05, 'epoch': 0.08}
  8%|â–Š         | 485/6000 [22:33<4:21:07,  2.84s/it]  8%|â–Š         | 486/6000 [22:36<4:16:11,  2.79s/it]                                                    {'loss': 2.7943, 'grad_norm': 0.9584707617759705, 'learning_rate': 4.672881355932204e-05, 'epoch': 0.08}
  8%|â–Š         | 486/6000 [22:36<4:16:11,  2.79s/it]  8%|â–Š         | 487/6000 [22:38<4:15:58,  2.79s/it]                                                    {'loss': 2.7863, 'grad_norm': 0.8940070271492004, 'learning_rate': 4.672033898305085e-05, 'epoch': 0.08}
  8%|â–Š         | 487/6000 [22:38<4:15:58,  2.79s/it]  8%|â–Š         | 488/6000 [22:41<4:18:17,  2.81s/it]                                                    {'loss': 2.7823, 'grad_norm': 0.9885470271110535, 'learning_rate': 4.671186440677966e-05, 'epoch': 0.08}
  8%|â–Š         | 488/6000 [22:41<4:18:17,  2.81s/it]  8%|â–Š         | 489/6000 [22:44<4:18:03,  2.81s/it]                                                    {'loss': 2.781, 'grad_norm': 0.9788755178451538, 'learning_rate': 4.6703389830508474e-05, 'epoch': 0.08}
  8%|â–Š         | 489/6000 [22:44<4:18:03,  2.81s/it]  8%|â–Š         | 490/6000 [22:47<4:18:12,  2.81s/it]                                                    {'loss': 2.8191, 'grad_norm': 0.6901305317878723, 'learning_rate': 4.669491525423729e-05, 'epoch': 0.08}
  8%|â–Š         | 490/6000 [22:47<4:18:12,  2.81s/it]  8%|â–Š         | 491/6000 [22:50<4:18:10,  2.81s/it]                                                    {'loss': 2.7728, 'grad_norm': 0.9916359186172485, 'learning_rate': 4.66864406779661e-05, 'epoch': 0.08}
  8%|â–Š         | 491/6000 [22:50<4:18:10,  2.81s/it]  8%|â–Š         | 492/6000 [22:52<4:13:12,  2.76s/it]                                                    {'loss': 2.8116, 'grad_norm': 1.00930917263031, 'learning_rate': 4.667796610169492e-05, 'epoch': 0.08}
  8%|â–Š         | 492/6000 [22:52<4:13:12,  2.76s/it]  8%|â–Š         | 493/6000 [22:55<4:12:16,  2.75s/it]                                                    {'loss': 2.7872, 'grad_norm': 0.858623743057251, 'learning_rate': 4.666949152542373e-05, 'epoch': 0.08}
  8%|â–Š         | 493/6000 [22:55<4:12:16,  2.75s/it]  8%|â–Š         | 494/6000 [22:58<4:08:58,  2.71s/it]                                                    {'loss': 2.7732, 'grad_norm': 0.9657235145568848, 'learning_rate': 4.666101694915255e-05, 'epoch': 0.08}
  8%|â–Š         | 494/6000 [22:58<4:08:58,  2.71s/it]  8%|â–Š         | 495/6000 [23:00<4:11:29,  2.74s/it]                                                    {'loss': 2.7734, 'grad_norm': 0.9073861837387085, 'learning_rate': 4.6652542372881355e-05, 'epoch': 0.08}
  8%|â–Š         | 495/6000 [23:00<4:11:29,  2.74s/it]  8%|â–Š         | 496/6000 [23:03<4:07:57,  2.70s/it]                                                    {'loss': 2.7646, 'grad_norm': 0.8615910410881042, 'learning_rate': 4.6644067796610166e-05, 'epoch': 0.08}
  8%|â–Š         | 496/6000 [23:03<4:07:57,  2.70s/it]  8%|â–Š         | 497/6000 [23:06<4:05:08,  2.67s/it]                                                    {'loss': 2.7803, 'grad_norm': 0.9249362945556641, 'learning_rate': 4.6635593220338984e-05, 'epoch': 0.08}
  8%|â–Š         | 497/6000 [23:06<4:05:08,  2.67s/it]  8%|â–Š         | 498/6000 [23:08<4:04:33,  2.67s/it]                                                    {'loss': 2.772, 'grad_norm': 1.1857355833053589, 'learning_rate': 4.6627118644067795e-05, 'epoch': 0.08}
  8%|â–Š         | 498/6000 [23:08<4:04:33,  2.67s/it]  8%|â–Š         | 499/6000 [23:11<4:04:33,  2.67s/it]                                                    {'loss': 2.7708, 'grad_norm': 0.9466894865036011, 'learning_rate': 4.6618644067796614e-05, 'epoch': 0.08}
  8%|â–Š         | 499/6000 [23:11<4:04:33,  2.67s/it]  8%|â–Š         | 500/6000 [23:14<4:06:36,  2.69s/it]                                                    {'loss': 2.7751, 'grad_norm': 1.203235387802124, 'learning_rate': 4.6610169491525425e-05, 'epoch': 0.08}
  8%|â–Š         | 500/6000 [23:14<4:06:36,  2.69s/it][2025-10-20 23:29:04,964] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-500
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|â–Š         | 501/6000 [23:18<4:59:55,  3.27s/it]                                                    {'loss': 2.8034, 'grad_norm': 0.8893136978149414, 'learning_rate': 4.660169491525424e-05, 'epoch': 0.08}
  8%|â–Š         | 501/6000 [23:18<4:59:55,  3.27s/it]  8%|â–Š         | 502/6000 [23:21<4:46:25,  3.13s/it]                                                    {'loss': 2.7701, 'grad_norm': 1.0575741529464722, 'learning_rate': 4.6593220338983054e-05, 'epoch': 0.08}
  8%|â–Š         | 502/6000 [23:21<4:46:25,  3.13s/it]  8%|â–Š         | 503/6000 [23:24<4:39:44,  3.05s/it]                                                    {'loss': 2.8166, 'grad_norm': 1.2244316339492798, 'learning_rate': 4.6584745762711865e-05, 'epoch': 0.08}
  8%|â–Š         | 503/6000 [23:24<4:39:44,  3.05s/it]  8%|â–Š         | 504/6000 [23:27<4:29:43,  2.94s/it]                                                    {'loss': 2.7823, 'grad_norm': 1.1692653894424438, 'learning_rate': 4.657627118644068e-05, 'epoch': 0.08}
  8%|â–Š         | 504/6000 [23:27<4:29:43,  2.94s/it]  8%|â–Š         | 505/6000 [23:29<4:22:55,  2.87s/it]                                                    {'loss': 2.8197, 'grad_norm': 1.3337578773498535, 'learning_rate': 4.6567796610169495e-05, 'epoch': 0.08}
  8%|â–Š         | 505/6000 [23:29<4:22:55,  2.87s/it]  8%|â–Š         | 506/6000 [23:32<4:28:34,  2.93s/it]                                                    {'loss': 2.756, 'grad_norm': 1.3254292011260986, 'learning_rate': 4.6559322033898306e-05, 'epoch': 0.08}
  8%|â–Š         | 506/6000 [23:32<4:28:34,  2.93s/it]  8%|â–Š         | 507/6000 [23:35<4:23:06,  2.87s/it]                                                    {'loss': 2.8029, 'grad_norm': 1.1165955066680908, 'learning_rate': 4.6550847457627124e-05, 'epoch': 0.08}
  8%|â–Š         | 507/6000 [23:35<4:23:06,  2.87s/it]  8%|â–Š         | 508/6000 [23:38<4:16:01,  2.80s/it]                                                    {'loss': 2.7868, 'grad_norm': 1.3107439279556274, 'learning_rate': 4.6542372881355935e-05, 'epoch': 0.08}
  8%|â–Š         | 508/6000 [23:38<4:16:01,  2.80s/it]  8%|â–Š         | 509/6000 [23:40<4:10:46,  2.74s/it]                                                    {'loss': 2.7964, 'grad_norm': 1.326019048690796, 'learning_rate': 4.653389830508475e-05, 'epoch': 0.08}
  8%|â–Š         | 509/6000 [23:40<4:10:46,  2.74s/it]  8%|â–Š         | 510/6000 [23:43<4:12:55,  2.76s/it]                                                    {'loss': 2.7816, 'grad_norm': 1.7832814455032349, 'learning_rate': 4.652542372881356e-05, 'epoch': 0.09}
  8%|â–Š         | 510/6000 [23:43<4:12:55,  2.76s/it]  9%|â–Š         | 511/6000 [23:46<4:13:05,  2.77s/it]                                                    {'loss': 2.7511, 'grad_norm': 2.1245298385620117, 'learning_rate': 4.6516949152542376e-05, 'epoch': 0.09}
  9%|â–Š         | 511/6000 [23:46<4:13:05,  2.77s/it]  9%|â–Š         | 512/6000 [23:49<4:10:03,  2.73s/it]                                                    {'loss': 2.7728, 'grad_norm': 1.543271780014038, 'learning_rate': 4.650847457627119e-05, 'epoch': 0.09}
  9%|â–Š         | 512/6000 [23:49<4:10:03,  2.73s/it]  9%|â–Š         | 513/6000 [23:52<4:13:42,  2.77s/it]                                                    {'loss': 2.7686, 'grad_norm': 2.1719651222229004, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.09}
  9%|â–Š         | 513/6000 [23:52<4:13:42,  2.77s/it]  9%|â–Š         | 514/6000 [23:54<4:13:22,  2.77s/it]                                                    {'loss': 2.8204, 'grad_norm': 3.0656421184539795, 'learning_rate': 4.649152542372882e-05, 'epoch': 0.09}
  9%|â–Š         | 514/6000 [23:54<4:13:22,  2.77s/it]  9%|â–Š         | 515/6000 [23:57<4:11:20,  2.75s/it]                                                    {'loss': 2.7369, 'grad_norm': 2.4339427947998047, 'learning_rate': 4.6483050847457635e-05, 'epoch': 0.09}
  9%|â–Š         | 515/6000 [23:57<4:11:20,  2.75s/it]  9%|â–Š         | 516/6000 [24:00<4:18:10,  2.82s/it]                                                    {'loss': 2.7832, 'grad_norm': 2.4847097396850586, 'learning_rate': 4.6474576271186446e-05, 'epoch': 0.09}
  9%|â–Š         | 516/6000 [24:00<4:18:10,  2.82s/it]  9%|â–Š         | 517/6000 [24:03<4:15:09,  2.79s/it]                                                    {'loss': 2.8001, 'grad_norm': 3.6424973011016846, 'learning_rate': 4.646610169491525e-05, 'epoch': 0.09}
  9%|â–Š         | 517/6000 [24:03<4:15:09,  2.79s/it]  9%|â–Š         | 518/6000 [24:05<4:11:34,  2.75s/it]                                                    {'loss': 2.7798, 'grad_norm': 2.6991679668426514, 'learning_rate': 4.645762711864407e-05, 'epoch': 0.09}
  9%|â–Š         | 518/6000 [24:05<4:11:34,  2.75s/it]  9%|â–Š         | 519/6000 [24:08<4:09:20,  2.73s/it]                                                    {'loss': 2.7622, 'grad_norm': 2.2215213775634766, 'learning_rate': 4.644915254237288e-05, 'epoch': 0.09}
  9%|â–Š         | 519/6000 [24:08<4:09:20,  2.73s/it]  9%|â–Š         | 520/6000 [24:11<4:14:01,  2.78s/it]                                                    {'loss': 2.774, 'grad_norm': 2.643650531768799, 'learning_rate': 4.64406779661017e-05, 'epoch': 0.09}
  9%|â–Š         | 520/6000 [24:11<4:14:01,  2.78s/it]  9%|â–Š         | 521/6000 [24:14<4:10:06,  2.74s/it]                                                    {'loss': 2.7798, 'grad_norm': 1.8125500679016113, 'learning_rate': 4.643220338983051e-05, 'epoch': 0.09}
  9%|â–Š         | 521/6000 [24:14<4:10:06,  2.74s/it]  9%|â–Š         | 522/6000 [24:16<4:08:34,  2.72s/it]                                                    {'loss': 2.7532, 'grad_norm': 2.0772502422332764, 'learning_rate': 4.642372881355933e-05, 'epoch': 0.09}
  9%|â–Š         | 522/6000 [24:16<4:08:34,  2.72s/it]  9%|â–Š         | 523/6000 [24:19<4:09:41,  2.74s/it]                                                    {'loss': 2.8165, 'grad_norm': 2.9128425121307373, 'learning_rate': 4.641525423728814e-05, 'epoch': 0.09}
  9%|â–Š         | 523/6000 [24:19<4:09:41,  2.74s/it]  9%|â–Š         | 524/6000 [24:22<4:06:53,  2.71s/it]                                                    {'loss': 2.8466, 'grad_norm': 1.4266552925109863, 'learning_rate': 4.640677966101695e-05, 'epoch': 0.09}
  9%|â–Š         | 524/6000 [24:22<4:06:53,  2.71s/it]  9%|â–‰         | 525/6000 [24:24<4:04:55,  2.68s/it]                                                    {'loss': 2.7835, 'grad_norm': 1.8751509189605713, 'learning_rate': 4.639830508474576e-05, 'epoch': 0.09}
  9%|â–‰         | 525/6000 [24:24<4:04:55,  2.68s/it]  9%|â–‰         | 526/6000 [24:27<4:03:01,  2.66s/it]                                                    {'loss': 2.8278, 'grad_norm': 1.3571805953979492, 'learning_rate': 4.638983050847458e-05, 'epoch': 0.09}
  9%|â–‰         | 526/6000 [24:27<4:03:01,  2.66s/it]  9%|â–‰         | 527/6000 [24:30<4:02:56,  2.66s/it]                                                    {'loss': 2.7753, 'grad_norm': 1.6067211627960205, 'learning_rate': 4.638135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 527/6000 [24:30<4:02:56,  2.66s/it]  9%|â–‰         | 528/6000 [24:32<4:04:26,  2.68s/it]                                                    {'loss': 2.7639, 'grad_norm': 1.3642092943191528, 'learning_rate': 4.637288135593221e-05, 'epoch': 0.09}
  9%|â–‰         | 528/6000 [24:32<4:04:26,  2.68s/it]  9%|â–‰         | 529/6000 [24:35<4:03:19,  2.67s/it]                                                    {'loss': 2.7775, 'grad_norm': 1.303240180015564, 'learning_rate': 4.636440677966102e-05, 'epoch': 0.09}
  9%|â–‰         | 529/6000 [24:35<4:03:19,  2.67s/it]  9%|â–‰         | 530/6000 [24:38<4:09:54,  2.74s/it]                                                    {'loss': 2.7918, 'grad_norm': 1.167320966720581, 'learning_rate': 4.635593220338984e-05, 'epoch': 0.09}
  9%|â–‰         | 530/6000 [24:38<4:09:54,  2.74s/it]  9%|â–‰         | 531/6000 [24:40<4:06:42,  2.71s/it]                                                    {'loss': 2.7693, 'grad_norm': 1.4595006704330444, 'learning_rate': 4.634745762711864e-05, 'epoch': 0.09}
  9%|â–‰         | 531/6000 [24:41<4:06:42,  2.71s/it]  9%|â–‰         | 532/6000 [24:43<4:05:55,  2.70s/it]                                                    {'loss': 2.7431, 'grad_norm': 1.8051211833953857, 'learning_rate': 4.633898305084746e-05, 'epoch': 0.09}
  9%|â–‰         | 532/6000 [24:43<4:05:55,  2.70s/it]  9%|â–‰         | 533/6000 [24:46<4:03:42,  2.67s/it]                                                    {'loss': 2.7707, 'grad_norm': 1.14300537109375, 'learning_rate': 4.633050847457627e-05, 'epoch': 0.09}
  9%|â–‰         | 533/6000 [24:46<4:03:42,  2.67s/it]  9%|â–‰         | 534/6000 [24:48<4:03:51,  2.68s/it]                                                    {'loss': 2.7786, 'grad_norm': 1.5926450490951538, 'learning_rate': 4.632203389830509e-05, 'epoch': 0.09}
  9%|â–‰         | 534/6000 [24:48<4:03:51,  2.68s/it]  9%|â–‰         | 535/6000 [24:51<4:03:26,  2.67s/it]                                                    {'loss': 2.7968, 'grad_norm': 1.7020385265350342, 'learning_rate': 4.63135593220339e-05, 'epoch': 0.09}
  9%|â–‰         | 535/6000 [24:51<4:03:26,  2.67s/it]  9%|â–‰         | 536/6000 [24:54<4:02:43,  2.67s/it]                                                    {'loss': 2.7428, 'grad_norm': 2.01322078704834, 'learning_rate': 4.630508474576272e-05, 'epoch': 0.09}
  9%|â–‰         | 536/6000 [24:54<4:02:43,  2.67s/it]  9%|â–‰         | 537/6000 [24:56<4:02:08,  2.66s/it]                                                    {'loss': 2.7758, 'grad_norm': 1.6650149822235107, 'learning_rate': 4.629661016949153e-05, 'epoch': 0.09}
  9%|â–‰         | 537/6000 [24:56<4:02:08,  2.66s/it]  9%|â–‰         | 538/6000 [24:59<4:00:24,  2.64s/it]                                                    {'loss': 2.7529, 'grad_norm': 2.060915946960449, 'learning_rate': 4.628813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 538/6000 [24:59<4:00:24,  2.64s/it]  9%|â–‰         | 539/6000 [25:02<3:59:16,  2.63s/it]                                                    {'loss': 2.7246, 'grad_norm': 3.186648368835449, 'learning_rate': 4.627966101694915e-05, 'epoch': 0.09}
  9%|â–‰         | 539/6000 [25:02<3:59:16,  2.63s/it]  9%|â–‰         | 540/6000 [25:04<3:58:51,  2.62s/it]                                                    {'loss': 2.8198, 'grad_norm': 3.993881940841675, 'learning_rate': 4.6271186440677964e-05, 'epoch': 0.09}
  9%|â–‰         | 540/6000 [25:04<3:58:51,  2.62s/it]  9%|â–‰         | 541/6000 [25:07<4:05:06,  2.69s/it]                                                    {'loss': 2.8786, 'grad_norm': 8.856953620910645, 'learning_rate': 4.626271186440678e-05, 'epoch': 0.09}
  9%|â–‰         | 541/6000 [25:07<4:05:06,  2.69s/it]  9%|â–‰         | 542/6000 [25:10<4:04:57,  2.69s/it]                                                    {'loss': 2.7481, 'grad_norm': 4.202499866485596, 'learning_rate': 4.6254237288135594e-05, 'epoch': 0.09}
  9%|â–‰         | 542/6000 [25:10<4:04:57,  2.69s/it]  9%|â–‰         | 543/6000 [25:12<4:03:36,  2.68s/it]                                                    {'loss': 2.7716, 'grad_norm': 3.739025354385376, 'learning_rate': 4.624576271186441e-05, 'epoch': 0.09}
  9%|â–‰         | 543/6000 [25:12<4:03:36,  2.68s/it]  9%|â–‰         | 544/6000 [25:15<4:04:26,  2.69s/it]                                                    {'loss': 2.7524, 'grad_norm': 3.6209945678710938, 'learning_rate': 4.623728813559322e-05, 'epoch': 0.09}
  9%|â–‰         | 544/6000 [25:15<4:04:26,  2.69s/it]  9%|â–‰         | 545/6000 [25:18<4:06:59,  2.72s/it]                                                    {'loss': 2.7495, 'grad_norm': 4.179198265075684, 'learning_rate': 4.6228813559322034e-05, 'epoch': 0.09}
  9%|â–‰         | 545/6000 [25:18<4:06:59,  2.72s/it]  9%|â–‰         | 546/6000 [25:21<4:06:09,  2.71s/it]                                                    {'loss': 2.7915, 'grad_norm': 5.521938800811768, 'learning_rate': 4.6220338983050846e-05, 'epoch': 0.09}
  9%|â–‰         | 546/6000 [25:21<4:06:09,  2.71s/it]  9%|â–‰         | 547/6000 [25:23<4:07:46,  2.73s/it]                                                    {'loss': 2.7799, 'grad_norm': 4.170745849609375, 'learning_rate': 4.6211864406779664e-05, 'epoch': 0.09}
  9%|â–‰         | 547/6000 [25:23<4:07:46,  2.73s/it]  9%|â–‰         | 548/6000 [25:26<4:07:20,  2.72s/it]                                                    {'loss': 2.7822, 'grad_norm': 4.264259338378906, 'learning_rate': 4.6203389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 548/6000 [25:26<4:07:20,  2.72s/it]  9%|â–‰         | 549/6000 [25:29<4:05:30,  2.70s/it]                                                    {'loss': 2.7878, 'grad_norm': 4.037440299987793, 'learning_rate': 4.619491525423729e-05, 'epoch': 0.09}
  9%|â–‰         | 549/6000 [25:29<4:05:30,  2.70s/it]  9%|â–‰         | 550/6000 [25:31<4:05:00,  2.70s/it]                                                    {'loss': 2.7972, 'grad_norm': 3.8687024116516113, 'learning_rate': 4.6186440677966104e-05, 'epoch': 0.09}
  9%|â–‰         | 550/6000 [25:31<4:05:00,  2.70s/it][2025-10-20 23:31:22,711] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-550
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  9%|â–‰         | 551/6000 [25:37<5:23:02,  3.56s/it]                                                    {'loss': 2.7465, 'grad_norm': 4.680906295776367, 'learning_rate': 4.617796610169492e-05, 'epoch': 0.09}
  9%|â–‰         | 551/6000 [25:37<5:23:02,  3.56s/it]  9%|â–‰         | 552/6000 [25:40<4:58:48,  3.29s/it]                                                    {'loss': 2.7977, 'grad_norm': 3.480966806411743, 'learning_rate': 4.6169491525423734e-05, 'epoch': 0.09}
  9%|â–‰         | 552/6000 [25:40<4:58:48,  3.29s/it]  9%|â–‰         | 553/6000 [25:42<4:45:29,  3.14s/it]                                                    {'loss': 2.7993, 'grad_norm': 3.9008493423461914, 'learning_rate': 4.6161016949152545e-05, 'epoch': 0.09}
  9%|â–‰         | 553/6000 [25:42<4:45:29,  3.14s/it]  9%|â–‰         | 554/6000 [25:45<4:34:10,  3.02s/it]                                                    {'loss': 2.7968, 'grad_norm': 2.7676284313201904, 'learning_rate': 4.6152542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 554/6000 [25:45<4:34:10,  3.02s/it]  9%|â–‰         | 555/6000 [25:48<4:23:45,  2.91s/it]                                                    {'loss': 2.74, 'grad_norm': 2.6163501739501953, 'learning_rate': 4.6144067796610174e-05, 'epoch': 0.09}
  9%|â–‰         | 555/6000 [25:48<4:23:45,  2.91s/it]  9%|â–‰         | 556/6000 [25:50<4:16:13,  2.82s/it]                                                    {'loss': 2.7667, 'grad_norm': 2.4742214679718018, 'learning_rate': 4.6135593220338986e-05, 'epoch': 0.09}
  9%|â–‰         | 556/6000 [25:50<4:16:13,  2.82s/it]  9%|â–‰         | 557/6000 [25:53<4:12:56,  2.79s/it]                                                    {'loss': 2.7535, 'grad_norm': 2.613046169281006, 'learning_rate': 4.6127118644067804e-05, 'epoch': 0.09}
  9%|â–‰         | 557/6000 [25:53<4:12:56,  2.79s/it]  9%|â–‰         | 558/6000 [25:56<4:13:27,  2.79s/it]                                                    {'loss': 2.7548, 'grad_norm': 2.8474197387695312, 'learning_rate': 4.6118644067796615e-05, 'epoch': 0.09}
  9%|â–‰         | 558/6000 [25:56<4:13:27,  2.79s/it]  9%|â–‰         | 559/6000 [25:59<4:13:46,  2.80s/it]                                                    {'loss': 2.7558, 'grad_norm': 2.0488510131835938, 'learning_rate': 4.6110169491525426e-05, 'epoch': 0.09}
  9%|â–‰         | 559/6000 [25:59<4:13:46,  2.80s/it]  9%|â–‰         | 560/6000 [26:01<4:08:12,  2.74s/it]                                                    {'loss': 2.7732, 'grad_norm': 2.034761905670166, 'learning_rate': 4.610169491525424e-05, 'epoch': 0.09}
  9%|â–‰         | 560/6000 [26:01<4:08:12,  2.74s/it]  9%|â–‰         | 561/6000 [26:04<4:17:23,  2.84s/it]                                                    {'loss': 2.7344, 'grad_norm': 5.054083824157715, 'learning_rate': 4.609322033898305e-05, 'epoch': 0.09}
  9%|â–‰         | 561/6000 [26:04<4:17:23,  2.84s/it]  9%|â–‰         | 562/6000 [26:07<4:11:45,  2.78s/it]                                                    {'loss': 2.8455, 'grad_norm': 2.5748400688171387, 'learning_rate': 4.608474576271187e-05, 'epoch': 0.09}
  9%|â–‰         | 562/6000 [26:07<4:11:45,  2.78s/it]  9%|â–‰         | 563/6000 [26:10<4:09:51,  2.76s/it]                                                    {'loss': 2.7654, 'grad_norm': 2.643195390701294, 'learning_rate': 4.607627118644068e-05, 'epoch': 0.09}
  9%|â–‰         | 563/6000 [26:10<4:09:51,  2.76s/it]  9%|â–‰         | 564/6000 [26:13<4:08:29,  2.74s/it]                                                    {'loss': 2.8076, 'grad_norm': 3.5130019187927246, 'learning_rate': 4.6067796610169496e-05, 'epoch': 0.09}
  9%|â–‰         | 564/6000 [26:13<4:08:29,  2.74s/it]  9%|â–‰         | 565/6000 [26:15<4:12:42,  2.79s/it]                                                    {'loss': 2.7475, 'grad_norm': 3.7334132194519043, 'learning_rate': 4.605932203389831e-05, 'epoch': 0.09}
  9%|â–‰         | 565/6000 [26:15<4:12:42,  2.79s/it]  9%|â–‰         | 566/6000 [26:18<4:10:26,  2.77s/it]                                                    {'loss': 2.7409, 'grad_norm': 3.3565473556518555, 'learning_rate': 4.605084745762712e-05, 'epoch': 0.09}
  9%|â–‰         | 566/6000 [26:18<4:10:26,  2.77s/it]  9%|â–‰         | 567/6000 [26:21<4:18:28,  2.85s/it]                                                    {'loss': 2.794, 'grad_norm': 6.674378395080566, 'learning_rate': 4.604237288135593e-05, 'epoch': 0.09}
  9%|â–‰         | 567/6000 [26:21<4:18:28,  2.85s/it]  9%|â–‰         | 568/6000 [26:24<4:15:24,  2.82s/it]                                                    {'loss': 2.8111, 'grad_norm': 11.562843322753906, 'learning_rate': 4.603389830508475e-05, 'epoch': 0.09}
  9%|â–‰         | 568/6000 [26:24<4:15:24,  2.82s/it]  9%|â–‰         | 569/6000 [26:27<4:12:48,  2.79s/it]                                                    {'loss': 2.7333, 'grad_norm': 8.04625415802002, 'learning_rate': 4.602542372881356e-05, 'epoch': 0.09}
  9%|â–‰         | 569/6000 [26:27<4:12:48,  2.79s/it] 10%|â–‰         | 570/6000 [26:29<4:10:27,  2.77s/it]                                                    {'loss': 2.8176, 'grad_norm': 5.370673179626465, 'learning_rate': 4.601694915254238e-05, 'epoch': 0.1}
 10%|â–‰         | 570/6000 [26:29<4:10:27,  2.77s/it] 10%|â–‰         | 571/6000 [26:33<4:42:30,  3.12s/it]                                                    {'loss': 2.6955, 'grad_norm': 7.876293182373047, 'learning_rate': 4.600847457627119e-05, 'epoch': 0.1}
 10%|â–‰         | 571/6000 [26:33<4:42:30,  3.12s/it] 10%|â–‰         | 572/6000 [26:36<4:32:47,  3.02s/it]                                                    {'loss': 2.7828, 'grad_norm': 5.635707378387451, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.1}
 10%|â–‰         | 572/6000 [26:36<4:32:47,  3.02s/it] 10%|â–‰         | 573/6000 [26:39<4:23:02,  2.91s/it]                                                    {'loss': 2.8006, 'grad_norm': 4.666008472442627, 'learning_rate': 4.599152542372882e-05, 'epoch': 0.1}
 10%|â–‰         | 573/6000 [26:39<4:23:02,  2.91s/it] 10%|â–‰         | 574/6000 [26:41<4:18:28,  2.86s/it]                                                    {'loss': 2.7698, 'grad_norm': 6.732757091522217, 'learning_rate': 4.598305084745763e-05, 'epoch': 0.1}
 10%|â–‰         | 574/6000 [26:41<4:18:28,  2.86s/it] 10%|â–‰         | 575/6000 [26:44<4:12:37,  2.79s/it]                                                    {'loss': 2.7544, 'grad_norm': 6.4030280113220215, 'learning_rate': 4.597457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 575/6000 [26:44<4:12:37,  2.79s/it] 10%|â–‰         | 576/6000 [26:47<4:12:45,  2.80s/it]                                                    {'loss': 2.7767, 'grad_norm': 9.095226287841797, 'learning_rate': 4.596610169491526e-05, 'epoch': 0.1}
 10%|â–‰         | 576/6000 [26:47<4:12:45,  2.80s/it] 10%|â–‰         | 577/6000 [26:50<4:15:53,  2.83s/it]                                                    {'loss': 2.803, 'grad_norm': 8.917922973632812, 'learning_rate': 4.595762711864407e-05, 'epoch': 0.1}
 10%|â–‰         | 577/6000 [26:50<4:15:53,  2.83s/it] 10%|â–‰         | 578/6000 [26:53<4:28:09,  2.97s/it]                                                    {'loss': 2.8164, 'grad_norm': 5.622683048248291, 'learning_rate': 4.594915254237288e-05, 'epoch': 0.1}
 10%|â–‰         | 578/6000 [26:53<4:28:09,  2.97s/it] 10%|â–‰         | 579/6000 [26:56<4:32:27,  3.02s/it]                                                    {'loss': 2.7938, 'grad_norm': 4.72584867477417, 'learning_rate': 4.59406779661017e-05, 'epoch': 0.1}
 10%|â–‰         | 579/6000 [26:56<4:32:27,  3.02s/it] 10%|â–‰         | 580/6000 [26:59<4:25:06,  2.93s/it]                                                    {'loss': 2.7533, 'grad_norm': 3.981311798095703, 'learning_rate': 4.593220338983051e-05, 'epoch': 0.1}
 10%|â–‰         | 580/6000 [26:59<4:25:06,  2.93s/it] 10%|â–‰         | 581/6000 [27:02<4:39:37,  3.10s/it]                                                    {'loss': 2.8231, 'grad_norm': 3.515056848526001, 'learning_rate': 4.592372881355932e-05, 'epoch': 0.1}
 10%|â–‰         | 581/6000 [27:02<4:39:37,  3.10s/it] 10%|â–‰         | 582/6000 [27:06<4:53:16,  3.25s/it]                                                    {'loss': 2.7308, 'grad_norm': 3.255966901779175, 'learning_rate': 4.591525423728813e-05, 'epoch': 0.1}
 10%|â–‰         | 582/6000 [27:06<4:53:16,  3.25s/it] 10%|â–‰         | 583/6000 [27:09<4:41:28,  3.12s/it]                                                    {'loss': 2.7689, 'grad_norm': 2.1022207736968994, 'learning_rate': 4.590677966101695e-05, 'epoch': 0.1}
 10%|â–‰         | 583/6000 [27:09<4:41:28,  3.12s/it] 10%|â–‰         | 584/6000 [27:12<4:29:58,  2.99s/it]                                                    {'loss': 2.8266, 'grad_norm': 1.9643797874450684, 'learning_rate': 4.589830508474576e-05, 'epoch': 0.1}
 10%|â–‰         | 584/6000 [27:12<4:29:58,  2.99s/it] 10%|â–‰         | 585/6000 [27:15<4:34:15,  3.04s/it]                                                    {'loss': 2.7807, 'grad_norm': 2.227400779724121, 'learning_rate': 4.588983050847458e-05, 'epoch': 0.1}
 10%|â–‰         | 585/6000 [27:15<4:34:15,  3.04s/it] 10%|â–‰         | 586/6000 [27:17<4:23:31,  2.92s/it]                                                    {'loss': 2.7951, 'grad_norm': 1.7991701364517212, 'learning_rate': 4.588135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 586/6000 [27:17<4:23:31,  2.92s/it] 10%|â–‰         | 587/6000 [27:20<4:15:36,  2.83s/it]                                                    {'loss': 2.7954, 'grad_norm': 1.8126654624938965, 'learning_rate': 4.587288135593221e-05, 'epoch': 0.1}
 10%|â–‰         | 587/6000 [27:20<4:15:36,  2.83s/it] 10%|â–‰         | 588/6000 [27:23<4:17:09,  2.85s/it]                                                    {'loss': 2.7878, 'grad_norm': 1.682789921760559, 'learning_rate': 4.5864406779661014e-05, 'epoch': 0.1}
 10%|â–‰         | 588/6000 [27:23<4:17:09,  2.85s/it] 10%|â–‰         | 589/6000 [27:26<4:14:21,  2.82s/it]                                                    {'loss': 2.7833, 'grad_norm': 1.5266609191894531, 'learning_rate': 4.585593220338983e-05, 'epoch': 0.1}
 10%|â–‰         | 589/6000 [27:26<4:14:21,  2.82s/it] 10%|â–‰         | 590/6000 [27:28<4:14:06,  2.82s/it]                                                    {'loss': 2.7914, 'grad_norm': 1.5959645509719849, 'learning_rate': 4.5847457627118644e-05, 'epoch': 0.1}
 10%|â–‰         | 590/6000 [27:28<4:14:06,  2.82s/it] 10%|â–‰         | 591/6000 [27:31<4:10:21,  2.78s/it]                                                    {'loss': 2.7643, 'grad_norm': 1.3258031606674194, 'learning_rate': 4.583898305084746e-05, 'epoch': 0.1}
 10%|â–‰         | 591/6000 [27:31<4:10:21,  2.78s/it] 10%|â–‰         | 592/6000 [27:34<4:06:56,  2.74s/it]                                                    {'loss': 2.7716, 'grad_norm': 1.0854454040527344, 'learning_rate': 4.583050847457627e-05, 'epoch': 0.1}
 10%|â–‰         | 592/6000 [27:34<4:06:56,  2.74s/it] 10%|â–‰         | 593/6000 [27:36<4:05:39,  2.73s/it]                                                    {'loss': 2.7625, 'grad_norm': 1.5899566411972046, 'learning_rate': 4.582203389830509e-05, 'epoch': 0.1}
 10%|â–‰         | 593/6000 [27:37<4:05:39,  2.73s/it] 10%|â–‰         | 594/6000 [27:39<4:09:04,  2.76s/it]                                                    {'loss': 2.7634, 'grad_norm': 1.6081807613372803, 'learning_rate': 4.58135593220339e-05, 'epoch': 0.1}
 10%|â–‰         | 594/6000 [27:39<4:09:04,  2.76s/it] 10%|â–‰         | 595/6000 [27:42<4:17:59,  2.86s/it]                                                    {'loss': 2.7691, 'grad_norm': 1.6188298463821411, 'learning_rate': 4.5805084745762714e-05, 'epoch': 0.1}
 10%|â–‰         | 595/6000 [27:42<4:17:59,  2.86s/it] 10%|â–‰         | 596/6000 [27:46<4:37:16,  3.08s/it]                                                    {'loss': 2.7411, 'grad_norm': 2.103682518005371, 'learning_rate': 4.5796610169491525e-05, 'epoch': 0.1}
 10%|â–‰         | 596/6000 [27:46<4:37:16,  3.08s/it] 10%|â–‰         | 597/6000 [27:49<4:23:56,  2.93s/it]                                                    {'loss': 2.7652, 'grad_norm': 2.119145393371582, 'learning_rate': 4.578813559322034e-05, 'epoch': 0.1}
 10%|â–‰         | 597/6000 [27:49<4:23:56,  2.93s/it] 10%|â–‰         | 598/6000 [27:51<4:17:55,  2.86s/it]                                                    {'loss': 2.792, 'grad_norm': 2.629884719848633, 'learning_rate': 4.5779661016949154e-05, 'epoch': 0.1}
 10%|â–‰         | 598/6000 [27:51<4:17:55,  2.86s/it] 10%|â–‰         | 599/6000 [27:54<4:11:40,  2.80s/it]                                                    {'loss': 2.8087, 'grad_norm': 2.4001450538635254, 'learning_rate': 4.5771186440677966e-05, 'epoch': 0.1}
 10%|â–‰         | 599/6000 [27:54<4:11:40,  2.80s/it] 10%|â–ˆ         | 600/6000 [27:57<4:09:05,  2.77s/it]                                                    {'loss': 2.7993, 'grad_norm': 2.8918888568878174, 'learning_rate': 4.5762711864406784e-05, 'epoch': 0.1}
 10%|â–ˆ         | 600/6000 [27:57<4:09:05,  2.77s/it][2025-10-20 23:33:47,934] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-600
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 10%|â–ˆ         | 601/6000 [28:01<5:02:12,  3.36s/it]                                                    {'loss': 2.7353, 'grad_norm': 4.080942153930664, 'learning_rate': 4.5754237288135595e-05, 'epoch': 0.1}
 10%|â–ˆ         | 601/6000 [28:01<5:02:12,  3.36s/it] 10%|â–ˆ         | 602/6000 [28:04<4:44:37,  3.16s/it]                                                    {'loss': 2.732, 'grad_norm': 3.313246250152588, 'learning_rate': 4.5745762711864406e-05, 'epoch': 0.1}
 10%|â–ˆ         | 602/6000 [28:04<4:44:37,  3.16s/it] 10%|â–ˆ         | 603/6000 [28:07<4:30:04,  3.00s/it]                                                    {'loss': 2.8802, 'grad_norm': 19.532672882080078, 'learning_rate': 4.573728813559322e-05, 'epoch': 0.1}
 10%|â–ˆ         | 603/6000 [28:07<4:30:04,  3.00s/it] 10%|â–ˆ         | 604/6000 [28:10<4:37:34,  3.09s/it]                                                    {'loss': 2.7828, 'grad_norm': 3.894754648208618, 'learning_rate': 4.5728813559322036e-05, 'epoch': 0.1}
 10%|â–ˆ         | 604/6000 [28:10<4:37:34,  3.09s/it] 10%|â–ˆ         | 605/6000 [28:13<4:27:39,  2.98s/it]                                                    {'loss': 2.8056, 'grad_norm': 2.969815969467163, 'learning_rate': 4.572033898305085e-05, 'epoch': 0.1}
 10%|â–ˆ         | 605/6000 [28:13<4:27:39,  2.98s/it] 10%|â–ˆ         | 606/6000 [28:16<4:28:13,  2.98s/it]                                                    {'loss': 2.7565, 'grad_norm': 3.034529447555542, 'learning_rate': 4.5711864406779665e-05, 'epoch': 0.1}
 10%|â–ˆ         | 606/6000 [28:16<4:28:13,  2.98s/it] 10%|â–ˆ         | 607/6000 [28:18<4:20:54,  2.90s/it]                                                    {'loss': 2.8233, 'grad_norm': 5.185002326965332, 'learning_rate': 4.5703389830508476e-05, 'epoch': 0.1}
 10%|â–ˆ         | 607/6000 [28:18<4:20:54,  2.90s/it] 10%|â–ˆ         | 608/6000 [28:21<4:18:46,  2.88s/it]                                                    {'loss': 2.783, 'grad_norm': 3.8046605587005615, 'learning_rate': 4.5694915254237294e-05, 'epoch': 0.1}
 10%|â–ˆ         | 608/6000 [28:21<4:18:46,  2.88s/it] 10%|â–ˆ         | 609/6000 [28:24<4:11:20,  2.80s/it]                                                    {'loss': 2.8032, 'grad_norm': 5.278773307800293, 'learning_rate': 4.5686440677966106e-05, 'epoch': 0.1}
 10%|â–ˆ         | 609/6000 [28:24<4:11:20,  2.80s/it] 10%|â–ˆ         | 610/6000 [28:27<4:13:08,  2.82s/it]                                                    {'loss': 2.7396, 'grad_norm': 3.5269813537597656, 'learning_rate': 4.567796610169492e-05, 'epoch': 0.1}
 10%|â–ˆ         | 610/6000 [28:27<4:13:08,  2.82s/it] 10%|â–ˆ         | 611/6000 [28:29<4:10:35,  2.79s/it]                                                    {'loss': 2.8356, 'grad_norm': 2.810577630996704, 'learning_rate': 4.566949152542373e-05, 'epoch': 0.1}
 10%|â–ˆ         | 611/6000 [28:29<4:10:35,  2.79s/it] 10%|â–ˆ         | 612/6000 [28:32<4:10:57,  2.79s/it]                                                    {'loss': 2.7505, 'grad_norm': 3.5566020011901855, 'learning_rate': 4.5661016949152546e-05, 'epoch': 0.1}
 10%|â–ˆ         | 612/6000 [28:32<4:10:57,  2.79s/it] 10%|â–ˆ         | 613/6000 [28:35<4:10:27,  2.79s/it]                                                    {'loss': 2.8395, 'grad_norm': 3.4629995822906494, 'learning_rate': 4.565254237288136e-05, 'epoch': 0.1}
 10%|â–ˆ         | 613/6000 [28:35<4:10:27,  2.79s/it] 10%|â–ˆ         | 614/6000 [28:38<4:06:42,  2.75s/it]                                                    {'loss': 2.7467, 'grad_norm': 3.1821019649505615, 'learning_rate': 4.5644067796610176e-05, 'epoch': 0.1}
 10%|â–ˆ         | 614/6000 [28:38<4:06:42,  2.75s/it] 10%|â–ˆ         | 615/6000 [28:40<4:05:44,  2.74s/it]                                                    {'loss': 2.7796, 'grad_norm': 3.3527817726135254, 'learning_rate': 4.563559322033899e-05, 'epoch': 0.1}
 10%|â–ˆ         | 615/6000 [28:40<4:05:44,  2.74s/it] 10%|â–ˆ         | 616/6000 [28:43<4:03:44,  2.72s/it]                                                    {'loss': 2.7586, 'grad_norm': 3.0418646335601807, 'learning_rate': 4.56271186440678e-05, 'epoch': 0.1}
 10%|â–ˆ         | 616/6000 [28:43<4:03:44,  2.72s/it] 10%|â–ˆ         | 617/6000 [28:46<4:03:43,  2.72s/it]                                                    {'loss': 2.7979, 'grad_norm': 3.0880205631256104, 'learning_rate': 4.561864406779661e-05, 'epoch': 0.1}
 10%|â–ˆ         | 617/6000 [28:46<4:03:43,  2.72s/it] 10%|â–ˆ         | 618/6000 [28:48<4:03:01,  2.71s/it]                                                    {'loss': 2.7979, 'grad_norm': 3.5794997215270996, 'learning_rate': 4.561016949152543e-05, 'epoch': 0.1}
 10%|â–ˆ         | 618/6000 [28:49<4:03:01,  2.71s/it] 10%|â–ˆ         | 619/6000 [28:51<4:01:19,  2.69s/it]                                                    {'loss': 2.7679, 'grad_norm': 2.282806158065796, 'learning_rate': 4.560169491525424e-05, 'epoch': 0.1}
 10%|â–ˆ         | 619/6000 [28:51<4:01:19,  2.69s/it] 10%|â–ˆ         | 620/6000 [28:54<3:59:06,  2.67s/it]                                                    {'loss': 2.8351, 'grad_norm': 3.3529019355773926, 'learning_rate': 4.559322033898305e-05, 'epoch': 0.1}
 10%|â–ˆ         | 620/6000 [28:54<3:59:06,  2.67s/it] 10%|â–ˆ         | 621/6000 [28:56<3:59:00,  2.67s/it]                                                    {'loss': 2.8305, 'grad_norm': 2.4364254474639893, 'learning_rate': 4.558474576271187e-05, 'epoch': 0.1}
 10%|â–ˆ         | 621/6000 [28:56<3:59:00,  2.67s/it] 10%|â–ˆ         | 622/6000 [28:59<3:57:57,  2.65s/it]                                                    {'loss': 2.8007, 'grad_norm': 2.3115484714508057, 'learning_rate': 4.557627118644068e-05, 'epoch': 0.1}
 10%|â–ˆ         | 622/6000 [28:59<3:57:57,  2.65s/it] 10%|â–ˆ         | 623/6000 [29:02<4:00:04,  2.68s/it]                                                    {'loss': 2.777, 'grad_norm': 2.1039493083953857, 'learning_rate': 4.556779661016949e-05, 'epoch': 0.1}
 10%|â–ˆ         | 623/6000 [29:02<4:00:04,  2.68s/it] 10%|â–ˆ         | 624/6000 [29:04<3:58:31,  2.66s/it]                                                    {'loss': 2.7703, 'grad_norm': 1.7434784173965454, 'learning_rate': 4.55593220338983e-05, 'epoch': 0.1}
 10%|â–ˆ         | 624/6000 [29:04<3:58:31,  2.66s/it] 10%|â–ˆ         | 625/6000 [29:07<4:04:43,  2.73s/it]                                                    {'loss': 2.8174, 'grad_norm': 2.28389310836792, 'learning_rate': 4.555084745762712e-05, 'epoch': 0.1}
 10%|â–ˆ         | 625/6000 [29:07<4:04:43,  2.73s/it] 10%|â–ˆ         | 626/6000 [29:10<4:03:24,  2.72s/it]                                                    {'loss': 2.7519, 'grad_norm': 2.213473081588745, 'learning_rate': 4.554237288135593e-05, 'epoch': 0.1}
 10%|â–ˆ         | 626/6000 [29:10<4:03:24,  2.72s/it] 10%|â–ˆ         | 627/6000 [29:13<4:21:32,  2.92s/it]                                                    {'loss': 2.7389, 'grad_norm': 2.0977671146392822, 'learning_rate': 4.553389830508475e-05, 'epoch': 0.1}
 10%|â–ˆ         | 627/6000 [29:13<4:21:32,  2.92s/it] 10%|â–ˆ         | 628/6000 [29:16<4:16:53,  2.87s/it]                                                    {'loss': 2.7873, 'grad_norm': 1.7943603992462158, 'learning_rate': 4.552542372881356e-05, 'epoch': 0.1}
 10%|â–ˆ         | 628/6000 [29:16<4:16:53,  2.87s/it] 10%|â–ˆ         | 629/6000 [29:19<4:11:44,  2.81s/it]                                                    {'loss': 2.7753, 'grad_norm': 1.9397348165512085, 'learning_rate': 4.551694915254238e-05, 'epoch': 0.1}
 10%|â–ˆ         | 629/6000 [29:19<4:11:44,  2.81s/it] 10%|â–ˆ         | 630/6000 [29:21<4:07:05,  2.76s/it]                                                    {'loss': 2.7923, 'grad_norm': 2.1136598587036133, 'learning_rate': 4.550847457627119e-05, 'epoch': 0.1}
 10%|â–ˆ         | 630/6000 [29:21<4:07:05,  2.76s/it] 11%|â–ˆ         | 631/6000 [29:24<4:05:32,  2.74s/it]                                                    {'loss': 2.7585, 'grad_norm': 2.2956364154815674, 'learning_rate': 4.55e-05, 'epoch': 0.11}
 11%|â–ˆ         | 631/6000 [29:24<4:05:32,  2.74s/it] 11%|â–ˆ         | 632/6000 [29:27<4:05:56,  2.75s/it]                                                    {'loss': 2.8643, 'grad_norm': 2.4583606719970703, 'learning_rate': 4.549152542372881e-05, 'epoch': 0.11}
 11%|â–ˆ         | 632/6000 [29:27<4:05:56,  2.75s/it] 11%|â–ˆ         | 633/6000 [29:30<4:05:57,  2.75s/it]                                                    {'loss': 2.7878, 'grad_norm': 2.457414388656616, 'learning_rate': 4.548305084745763e-05, 'epoch': 0.11}
 11%|â–ˆ         | 633/6000 [29:30<4:05:57,  2.75s/it] 11%|â–ˆ         | 634/6000 [29:33<4:13:38,  2.84s/it]                                                    {'loss': 2.7465, 'grad_norm': 2.83240008354187, 'learning_rate': 4.547457627118644e-05, 'epoch': 0.11}
 11%|â–ˆ         | 634/6000 [29:33<4:13:38,  2.84s/it] 11%|â–ˆ         | 635/6000 [29:36<4:13:40,  2.84s/it]                                                    {'loss': 2.7865, 'grad_norm': 4.353342533111572, 'learning_rate': 4.546610169491526e-05, 'epoch': 0.11}
 11%|â–ˆ         | 635/6000 [29:36<4:13:40,  2.84s/it] 11%|â–ˆ         | 636/6000 [29:38<4:11:03,  2.81s/it]                                                    {'loss': 2.7835, 'grad_norm': 2.6837735176086426, 'learning_rate': 4.545762711864407e-05, 'epoch': 0.11}
 11%|â–ˆ         | 636/6000 [29:38<4:11:03,  2.81s/it] 11%|â–ˆ         | 637/6000 [29:41<4:09:05,  2.79s/it]                                                    {'loss': 2.7948, 'grad_norm': 2.5630156993865967, 'learning_rate': 4.544915254237288e-05, 'epoch': 0.11}
 11%|â–ˆ         | 637/6000 [29:41<4:09:05,  2.79s/it] 11%|â–ˆ         | 638/6000 [29:44<4:17:19,  2.88s/it]                                                    {'loss': 2.7335, 'grad_norm': 2.6360650062561035, 'learning_rate': 4.5440677966101694e-05, 'epoch': 0.11}
 11%|â–ˆ         | 638/6000 [29:44<4:17:19,  2.88s/it] 11%|â–ˆ         | 639/6000 [29:47<4:12:49,  2.83s/it]                                                    {'loss': 2.798, 'grad_norm': 3.955343723297119, 'learning_rate': 4.543220338983051e-05, 'epoch': 0.11}
 11%|â–ˆ         | 639/6000 [29:47<4:12:49,  2.83s/it] 11%|â–ˆ         | 640/6000 [29:50<4:20:58,  2.92s/it]                                                    {'loss': 2.814, 'grad_norm': 2.877798557281494, 'learning_rate': 4.542372881355932e-05, 'epoch': 0.11}
 11%|â–ˆ         | 640/6000 [29:50<4:20:58,  2.92s/it] 11%|â–ˆ         | 641/6000 [29:53<4:27:41,  3.00s/it]                                                    {'loss': 2.7651, 'grad_norm': 3.059394121170044, 'learning_rate': 4.5415254237288135e-05, 'epoch': 0.11}
 11%|â–ˆ         | 641/6000 [29:53<4:27:41,  3.00s/it] 11%|â–ˆ         | 642/6000 [29:56<4:18:02,  2.89s/it]                                                    {'loss': 2.7313, 'grad_norm': 3.4763474464416504, 'learning_rate': 4.540677966101695e-05, 'epoch': 0.11}
 11%|â–ˆ         | 642/6000 [29:56<4:18:02,  2.89s/it] 11%|â–ˆ         | 643/6000 [29:59<4:14:17,  2.85s/it]                                                    {'loss': 2.7821, 'grad_norm': 2.812352418899536, 'learning_rate': 4.5398305084745764e-05, 'epoch': 0.11}
 11%|â–ˆ         | 643/6000 [29:59<4:14:17,  2.85s/it] 11%|â–ˆ         | 644/6000 [30:01<4:12:26,  2.83s/it]                                                    {'loss': 2.8258, 'grad_norm': 3.711418628692627, 'learning_rate': 4.538983050847458e-05, 'epoch': 0.11}
 11%|â–ˆ         | 644/6000 [30:01<4:12:26,  2.83s/it] 11%|â–ˆ         | 645/6000 [30:04<4:07:10,  2.77s/it]                                                    {'loss': 2.7241, 'grad_norm': 3.015134572982788, 'learning_rate': 4.5381355932203387e-05, 'epoch': 0.11}
 11%|â–ˆ         | 645/6000 [30:04<4:07:10,  2.77s/it] 11%|â–ˆ         | 646/6000 [30:07<4:14:05,  2.85s/it]                                                    {'loss': 2.7546, 'grad_norm': 3.3998568058013916, 'learning_rate': 4.5372881355932205e-05, 'epoch': 0.11}
 11%|â–ˆ         | 646/6000 [30:07<4:14:05,  2.85s/it] 11%|â–ˆ         | 647/6000 [30:10<4:09:33,  2.80s/it]                                                    {'loss': 2.8431, 'grad_norm': 2.358860492706299, 'learning_rate': 4.5364406779661016e-05, 'epoch': 0.11}
 11%|â–ˆ         | 647/6000 [30:10<4:09:33,  2.80s/it] 11%|â–ˆ         | 648/6000 [30:13<4:18:59,  2.90s/it]                                                    {'loss': 2.7692, 'grad_norm': 3.976508617401123, 'learning_rate': 4.5355932203389834e-05, 'epoch': 0.11}
 11%|â–ˆ         | 648/6000 [30:13<4:18:59,  2.90s/it] 11%|â–ˆ         | 649/6000 [30:15<4:12:35,  2.83s/it]                                                    {'loss': 2.7667, 'grad_norm': 4.211917877197266, 'learning_rate': 4.5347457627118645e-05, 'epoch': 0.11}
 11%|â–ˆ         | 649/6000 [30:15<4:12:35,  2.83s/it] 11%|â–ˆ         | 650/6000 [30:18<4:08:23,  2.79s/it]                                                    {'loss': 2.8001, 'grad_norm': 2.5672764778137207, 'learning_rate': 4.533898305084746e-05, 'epoch': 0.11}
 11%|â–ˆ         | 650/6000 [30:18<4:08:23,  2.79s/it][2025-10-20 23:36:09,427] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-650
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 11%|â–ˆ         | 651/6000 [30:23<4:58:16,  3.35s/it]                                                    {'loss': 2.7928, 'grad_norm': 2.7282209396362305, 'learning_rate': 4.5330508474576275e-05, 'epoch': 0.11}
 11%|â–ˆ         | 651/6000 [30:23<4:58:16,  3.35s/it] 11%|â–ˆ         | 652/6000 [30:26<4:50:24,  3.26s/it]                                                    {'loss': 2.7908, 'grad_norm': 3.8349645137786865, 'learning_rate': 4.5322033898305086e-05, 'epoch': 0.11}
 11%|â–ˆ         | 652/6000 [30:26<4:50:24,  3.26s/it] 11%|â–ˆ         | 653/6000 [30:29<4:37:56,  3.12s/it]                                                    {'loss': 2.7847, 'grad_norm': 4.122769832611084, 'learning_rate': 4.53135593220339e-05, 'epoch': 0.11}
 11%|â–ˆ         | 653/6000 [30:29<4:37:56,  3.12s/it] 11%|â–ˆ         | 654/6000 [30:31<4:26:12,  2.99s/it]                                                    {'loss': 2.7628, 'grad_norm': 3.032318353652954, 'learning_rate': 4.5305084745762715e-05, 'epoch': 0.11}
 11%|â–ˆ         | 654/6000 [30:31<4:26:12,  2.99s/it] 11%|â–ˆ         | 655/6000 [30:34<4:17:36,  2.89s/it]                                                    {'loss': 2.7793, 'grad_norm': 2.4027395248413086, 'learning_rate': 4.5296610169491527e-05, 'epoch': 0.11}
 11%|â–ˆ         | 655/6000 [30:34<4:17:36,  2.89s/it] 11%|â–ˆ         | 656/6000 [30:37<4:11:31,  2.82s/it]                                                    {'loss': 2.7447, 'grad_norm': 2.699209451675415, 'learning_rate': 4.5288135593220345e-05, 'epoch': 0.11}
 11%|â–ˆ         | 656/6000 [30:37<4:11:31,  2.82s/it] 11%|â–ˆ         | 657/6000 [30:40<4:11:55,  2.83s/it]                                                    {'loss': 2.7757, 'grad_norm': 2.498737096786499, 'learning_rate': 4.5279661016949156e-05, 'epoch': 0.11}
 11%|â–ˆ         | 657/6000 [30:40<4:11:55,  2.83s/it] 11%|â–ˆ         | 658/6000 [30:43<4:18:41,  2.91s/it]                                                    {'loss': 2.8214, 'grad_norm': 3.7092766761779785, 'learning_rate': 4.5271186440677974e-05, 'epoch': 0.11}
 11%|â–ˆ         | 658/6000 [30:43<4:18:41,  2.91s/it] 11%|â–ˆ         | 659/6000 [30:45<4:11:34,  2.83s/it]                                                    {'loss': 2.7669, 'grad_norm': 3.0488016605377197, 'learning_rate': 4.526271186440678e-05, 'epoch': 0.11}
 11%|â–ˆ         | 659/6000 [30:45<4:11:34,  2.83s/it] 11%|â–ˆ         | 660/6000 [30:48<4:08:29,  2.79s/it]                                                    {'loss': 2.7781, 'grad_norm': 3.6063902378082275, 'learning_rate': 4.5254237288135596e-05, 'epoch': 0.11}
 11%|â–ˆ         | 660/6000 [30:48<4:08:29,  2.79s/it] 11%|â–ˆ         | 661/6000 [30:51<4:05:51,  2.76s/it]                                                    {'loss': 2.8043, 'grad_norm': 3.5555198192596436, 'learning_rate': 4.524576271186441e-05, 'epoch': 0.11}
 11%|â–ˆ         | 661/6000 [30:51<4:05:51,  2.76s/it] 11%|â–ˆ         | 662/6000 [30:53<4:04:10,  2.74s/it]                                                    {'loss': 2.7856, 'grad_norm': 2.509591817855835, 'learning_rate': 4.523728813559322e-05, 'epoch': 0.11}
 11%|â–ˆ         | 662/6000 [30:53<4:04:10,  2.74s/it] 11%|â–ˆ         | 663/6000 [30:56<4:02:36,  2.73s/it]                                                    {'loss': 2.7805, 'grad_norm': 2.962803602218628, 'learning_rate': 4.522881355932204e-05, 'epoch': 0.11}
 11%|â–ˆ         | 663/6000 [30:56<4:02:36,  2.73s/it] 11%|â–ˆ         | 664/6000 [30:59<4:04:55,  2.75s/it]                                                    {'loss': 2.8403, 'grad_norm': 3.222730875015259, 'learning_rate': 4.522033898305085e-05, 'epoch': 0.11}
 11%|â–ˆ         | 664/6000 [30:59<4:04:55,  2.75s/it] 11%|â–ˆ         | 665/6000 [31:02<4:04:02,  2.74s/it]                                                    {'loss': 2.7627, 'grad_norm': 2.652611017227173, 'learning_rate': 4.5211864406779666e-05, 'epoch': 0.11}
 11%|â–ˆ         | 665/6000 [31:02<4:04:02,  2.74s/it] 11%|â–ˆ         | 666/6000 [31:04<4:03:00,  2.73s/it]                                                    {'loss': 2.7847, 'grad_norm': 3.344275712966919, 'learning_rate': 4.520338983050848e-05, 'epoch': 0.11}
 11%|â–ˆ         | 666/6000 [31:04<4:03:00,  2.73s/it] 11%|â–ˆ         | 667/6000 [31:07<4:04:16,  2.75s/it]                                                    {'loss': 2.8033, 'grad_norm': 2.6262896060943604, 'learning_rate': 4.519491525423729e-05, 'epoch': 0.11}
 11%|â–ˆ         | 667/6000 [31:07<4:04:16,  2.75s/it] 11%|â–ˆ         | 668/6000 [31:10<4:03:01,  2.73s/it]                                                    {'loss': 2.7927, 'grad_norm': 2.0748655796051025, 'learning_rate': 4.51864406779661e-05, 'epoch': 0.11}
 11%|â–ˆ         | 668/6000 [31:10<4:03:01,  2.73s/it] 11%|â–ˆ         | 669/6000 [31:12<4:02:23,  2.73s/it]                                                    {'loss': 2.78, 'grad_norm': 2.5539021492004395, 'learning_rate': 4.517796610169492e-05, 'epoch': 0.11}
 11%|â–ˆ         | 669/6000 [31:12<4:02:23,  2.73s/it] 11%|â–ˆ         | 670/6000 [31:15<4:06:35,  2.78s/it]                                                    {'loss': 2.7767, 'grad_norm': 2.408322334289551, 'learning_rate': 4.516949152542373e-05, 'epoch': 0.11}
 11%|â–ˆ         | 670/6000 [31:15<4:06:35,  2.78s/it] 11%|â–ˆ         | 671/6000 [31:18<4:05:15,  2.76s/it]                                                    {'loss': 2.7841, 'grad_norm': 2.090664863586426, 'learning_rate': 4.516101694915255e-05, 'epoch': 0.11}
 11%|â–ˆ         | 671/6000 [31:18<4:05:15,  2.76s/it] 11%|â–ˆ         | 672/6000 [31:21<4:01:17,  2.72s/it]                                                    {'loss': 2.8093, 'grad_norm': 3.0234692096710205, 'learning_rate': 4.515254237288136e-05, 'epoch': 0.11}
 11%|â–ˆ         | 672/6000 [31:21<4:01:17,  2.72s/it] 11%|â–ˆ         | 673/6000 [31:24<4:07:04,  2.78s/it]                                                    {'loss': 2.813, 'grad_norm': 1.7663449048995972, 'learning_rate': 4.514406779661017e-05, 'epoch': 0.11}
 11%|â–ˆ         | 673/6000 [31:24<4:07:04,  2.78s/it] 11%|â–ˆ         | 674/6000 [31:26<4:04:25,  2.75s/it]                                                    {'loss': 2.755, 'grad_norm': 2.2028872966766357, 'learning_rate': 4.513559322033898e-05, 'epoch': 0.11}
 11%|â–ˆ         | 674/6000 [31:26<4:04:25,  2.75s/it] 11%|â–ˆâ–        | 675/6000 [31:29<4:01:31,  2.72s/it]                                                    {'loss': 2.8051, 'grad_norm': 3.0274572372436523, 'learning_rate': 4.51271186440678e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 675/6000 [31:29<4:01:31,  2.72s/it] 11%|â–ˆâ–        | 676/6000 [31:32<4:00:13,  2.71s/it]                                                    {'loss': 2.8167, 'grad_norm': 2.207430839538574, 'learning_rate': 4.511864406779661e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 676/6000 [31:32<4:00:13,  2.71s/it] 11%|â–ˆâ–        | 677/6000 [31:34<3:57:42,  2.68s/it]                                                    {'loss': 2.748, 'grad_norm': 2.0377161502838135, 'learning_rate': 4.511016949152543e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 677/6000 [31:34<3:57:42,  2.68s/it] 11%|â–ˆâ–        | 678/6000 [31:37<3:58:16,  2.69s/it]                                                    {'loss': 2.7485, 'grad_norm': 2.3706579208374023, 'learning_rate': 4.510169491525424e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 678/6000 [31:37<3:58:16,  2.69s/it] 11%|â–ˆâ–        | 679/6000 [31:40<3:57:55,  2.68s/it]                                                    {'loss': 2.7849, 'grad_norm': 2.019017457962036, 'learning_rate': 4.509322033898306e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 679/6000 [31:40<3:57:55,  2.68s/it] 11%|â–ˆâ–        | 680/6000 [31:42<3:58:38,  2.69s/it]                                                    {'loss': 2.7663, 'grad_norm': 1.9700132608413696, 'learning_rate': 4.508474576271187e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 680/6000 [31:42<3:58:38,  2.69s/it] 11%|â–ˆâ–        | 681/6000 [31:45<4:08:07,  2.80s/it]                                                    {'loss': 2.8461, 'grad_norm': 61.486392974853516, 'learning_rate': 4.507627118644068e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 681/6000 [31:45<4:08:07,  2.80s/it] 11%|â–ˆâ–        | 682/6000 [31:48<4:07:21,  2.79s/it]                                                    {'loss': 2.7418, 'grad_norm': 2.4935286045074463, 'learning_rate': 4.506779661016949e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 682/6000 [31:48<4:07:21,  2.79s/it] 11%|â–ˆâ–        | 683/6000 [31:51<4:04:38,  2.76s/it]                                                    {'loss': 2.7307, 'grad_norm': 2.753445863723755, 'learning_rate': 4.5059322033898304e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 683/6000 [31:51<4:04:38,  2.76s/it] 11%|â–ˆâ–        | 684/6000 [31:54<4:03:03,  2.74s/it]                                                    {'loss': 2.8414, 'grad_norm': 2.810123920440674, 'learning_rate': 4.505084745762712e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 684/6000 [31:54<4:03:03,  2.74s/it] 11%|â–ˆâ–        | 685/6000 [31:56<4:00:48,  2.72s/it]                                                    {'loss': 2.7636, 'grad_norm': 2.9755918979644775, 'learning_rate': 4.504237288135593e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 685/6000 [31:56<4:00:48,  2.72s/it] 11%|â–ˆâ–        | 686/6000 [32:00<4:15:55,  2.89s/it]                                                    {'loss': 2.7787, 'grad_norm': 2.4844069480895996, 'learning_rate': 4.503389830508475e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 686/6000 [32:00<4:15:55,  2.89s/it] 11%|â–ˆâ–        | 687/6000 [32:02<4:08:52,  2.81s/it]                                                    {'loss': 2.761, 'grad_norm': 3.0844428539276123, 'learning_rate': 4.502542372881356e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 687/6000 [32:02<4:08:52,  2.81s/it] 11%|â–ˆâ–        | 688/6000 [32:05<4:05:36,  2.77s/it]                                                    {'loss': 2.8293, 'grad_norm': 2.969423770904541, 'learning_rate': 4.5016949152542373e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 688/6000 [32:05<4:05:36,  2.77s/it] 11%|â–ˆâ–        | 689/6000 [32:08<4:03:21,  2.75s/it]                                                    {'loss': 2.766, 'grad_norm': 3.353813886642456, 'learning_rate': 4.5008474576271185e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 689/6000 [32:08<4:03:21,  2.75s/it] 12%|â–ˆâ–        | 690/6000 [32:10<4:02:29,  2.74s/it]                                                    {'loss': 2.73, 'grad_norm': 2.9285476207733154, 'learning_rate': 4.5e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 690/6000 [32:10<4:02:29,  2.74s/it] 12%|â–ˆâ–        | 691/6000 [32:13<4:03:05,  2.75s/it]                                                    {'loss': 2.7726, 'grad_norm': 2.790388584136963, 'learning_rate': 4.4991525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 691/6000 [32:13<4:03:05,  2.75s/it] 12%|â–ˆâ–        | 692/6000 [32:16<4:01:15,  2.73s/it]                                                    {'loss': 2.7247, 'grad_norm': 3.4272539615631104, 'learning_rate': 4.498305084745763e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 692/6000 [32:16<4:01:15,  2.73s/it] 12%|â–ˆâ–        | 693/6000 [32:18<3:59:48,  2.71s/it]                                                    {'loss': 2.8087, 'grad_norm': 4.18402099609375, 'learning_rate': 4.4974576271186443e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 693/6000 [32:18<3:59:48,  2.71s/it] 12%|â–ˆâ–        | 694/6000 [32:21<4:00:08,  2.72s/it]                                                    {'loss': 2.7854, 'grad_norm': 5.822963237762451, 'learning_rate': 4.4966101694915255e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 694/6000 [32:21<4:00:08,  2.72s/it] 12%|â–ˆâ–        | 695/6000 [32:24<3:59:25,  2.71s/it]                                                    {'loss': 2.7733, 'grad_norm': 3.7006890773773193, 'learning_rate': 4.4957627118644066e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 695/6000 [32:24<3:59:25,  2.71s/it] 12%|â–ˆâ–        | 696/6000 [32:27<4:08:27,  2.81s/it]                                                    {'loss': 2.7762, 'grad_norm': 4.501211643218994, 'learning_rate': 4.4949152542372884e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 696/6000 [32:27<4:08:27,  2.81s/it] 12%|â–ˆâ–        | 697/6000 [32:29<4:04:11,  2.76s/it]                                                    {'loss': 2.7798, 'grad_norm': 3.6271698474884033, 'learning_rate': 4.4940677966101695e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 697/6000 [32:29<4:04:11,  2.76s/it] 12%|â–ˆâ–        | 698/6000 [32:32<4:02:53,  2.75s/it]                                                    {'loss': 2.8709, 'grad_norm': 4.533545970916748, 'learning_rate': 4.4932203389830513e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 698/6000 [32:32<4:02:53,  2.75s/it] 12%|â–ˆâ–        | 699/6000 [32:35<4:02:40,  2.75s/it]                                                    {'loss': 2.7578, 'grad_norm': 3.379706382751465, 'learning_rate': 4.4923728813559325e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 699/6000 [32:35<4:02:40,  2.75s/it] 12%|â–ˆâ–        | 700/6000 [32:38<4:04:03,  2.76s/it]                                                    {'loss': 2.7781, 'grad_norm': 3.0658583641052246, 'learning_rate': 4.491525423728814e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 700/6000 [32:38<4:04:03,  2.76s/it][2025-10-20 23:38:28,999] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-700
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|â–ˆâ–        | 701/6000 [32:43<4:57:39,  3.37s/it]                                                    {'loss': 2.803, 'grad_norm': 3.7888681888580322, 'learning_rate': 4.4906779661016954e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 701/6000 [32:43<4:57:39,  3.37s/it] 12%|â–ˆâ–        | 702/6000 [32:46<4:51:01,  3.30s/it]                                                    {'loss': 2.7616, 'grad_norm': 3.788576602935791, 'learning_rate': 4.4898305084745765e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 702/6000 [32:46<4:51:01,  3.30s/it] 12%|â–ˆâ–        | 703/6000 [32:48<4:35:57,  3.13s/it]                                                    {'loss': 2.7719, 'grad_norm': 4.255724906921387, 'learning_rate': 4.488983050847458e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 703/6000 [32:48<4:35:57,  3.13s/it] 12%|â–ˆâ–        | 704/6000 [32:51<4:33:38,  3.10s/it]                                                    {'loss': 2.7476, 'grad_norm': 5.241267204284668, 'learning_rate': 4.488135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 704/6000 [32:51<4:33:38,  3.10s/it] 12%|â–ˆâ–        | 705/6000 [32:54<4:25:05,  3.00s/it]                                                    {'loss': 2.8187, 'grad_norm': 3.1076877117156982, 'learning_rate': 4.4872881355932206e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 705/6000 [32:54<4:25:05,  3.00s/it] 12%|â–ˆâ–        | 706/6000 [32:57<4:16:58,  2.91s/it]                                                    {'loss': 2.766, 'grad_norm': 2.424997091293335, 'learning_rate': 4.486440677966102e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 706/6000 [32:57<4:16:58,  2.91s/it] 12%|â–ˆâ–        | 707/6000 [33:00<4:12:17,  2.86s/it]                                                    {'loss': 2.7782, 'grad_norm': 2.8868041038513184, 'learning_rate': 4.4855932203389835e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 707/6000 [33:00<4:12:17,  2.86s/it] 12%|â–ˆâ–        | 708/6000 [33:02<4:08:31,  2.82s/it]                                                    {'loss': 2.7877, 'grad_norm': 3.1339173316955566, 'learning_rate': 4.484745762711865e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 708/6000 [33:02<4:08:31,  2.82s/it] 12%|â–ˆâ–        | 709/6000 [33:05<4:04:50,  2.78s/it]                                                    {'loss': 2.7809, 'grad_norm': 2.0074098110198975, 'learning_rate': 4.483898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 709/6000 [33:05<4:04:50,  2.78s/it] 12%|â–ˆâ–        | 710/6000 [33:08<4:10:45,  2.84s/it]                                                    {'loss': 2.7454, 'grad_norm': 2.0649118423461914, 'learning_rate': 4.483050847457627e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 710/6000 [33:08<4:10:45,  2.84s/it] 12%|â–ˆâ–        | 711/6000 [33:11<4:07:11,  2.80s/it]                                                    {'loss': 2.7606, 'grad_norm': 1.5108073949813843, 'learning_rate': 4.482203389830509e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 711/6000 [33:11<4:07:11,  2.80s/it] 12%|â–ˆâ–        | 712/6000 [33:14<4:06:30,  2.80s/it]                                                    {'loss': 2.7695, 'grad_norm': 1.9005765914916992, 'learning_rate': 4.48135593220339e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 712/6000 [33:14<4:06:30,  2.80s/it] 12%|â–ˆâ–        | 713/6000 [33:16<4:04:03,  2.77s/it]                                                    {'loss': 2.7705, 'grad_norm': 1.7771694660186768, 'learning_rate': 4.480508474576272e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 713/6000 [33:16<4:04:03,  2.77s/it] 12%|â–ˆâ–        | 714/6000 [33:19<4:02:54,  2.76s/it]                                                    {'loss': 2.7589, 'grad_norm': 1.8146893978118896, 'learning_rate': 4.479661016949153e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 714/6000 [33:19<4:02:54,  2.76s/it] 12%|â–ˆâ–        | 715/6000 [33:22<4:01:20,  2.74s/it]                                                    {'loss': 2.792, 'grad_norm': 1.8216501474380493, 'learning_rate': 4.4788135593220346e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 715/6000 [33:22<4:01:20,  2.74s/it] 12%|â–ˆâ–        | 716/6000 [33:24<3:59:21,  2.72s/it]                                                    {'loss': 2.8231, 'grad_norm': 1.813903570175171, 'learning_rate': 4.477966101694915e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 716/6000 [33:24<3:59:21,  2.72s/it] 12%|â–ˆâ–        | 717/6000 [33:27<4:09:40,  2.84s/it]                                                    {'loss': 2.7932, 'grad_norm': 1.603135108947754, 'learning_rate': 4.477118644067797e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 717/6000 [33:27<4:09:40,  2.84s/it] 12%|â–ˆâ–        | 718/6000 [33:30<4:05:17,  2.79s/it]                                                    {'loss': 2.7745, 'grad_norm': 1.68330979347229, 'learning_rate': 4.476271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 718/6000 [33:30<4:05:17,  2.79s/it] 12%|â–ˆâ–        | 719/6000 [33:33<4:05:12,  2.79s/it]                                                    {'loss': 2.7423, 'grad_norm': 1.8592597246170044, 'learning_rate': 4.47542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 719/6000 [33:33<4:05:12,  2.79s/it] 12%|â–ˆâ–        | 720/6000 [33:36<4:02:11,  2.75s/it]                                                    {'loss': 2.7751, 'grad_norm': 1.5742093324661255, 'learning_rate': 4.474576271186441e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 720/6000 [33:36<4:02:11,  2.75s/it] 12%|â–ˆâ–        | 721/6000 [33:38<4:00:03,  2.73s/it]                                                    {'loss': 2.7722, 'grad_norm': 1.8907450437545776, 'learning_rate': 4.473728813559323e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 721/6000 [33:38<4:00:03,  2.73s/it] 12%|â–ˆâ–        | 722/6000 [33:41<4:00:58,  2.74s/it]                                                    {'loss': 2.7443, 'grad_norm': 1.9645646810531616, 'learning_rate': 4.472881355932204e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 722/6000 [33:41<4:00:58,  2.74s/it] 12%|â–ˆâ–        | 723/6000 [33:44<4:11:09,  2.86s/it]                                                    {'loss': 2.8056, 'grad_norm': 2.1199440956115723, 'learning_rate': 4.472033898305085e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 723/6000 [33:44<4:11:09,  2.86s/it] 12%|â–ˆâ–        | 724/6000 [33:47<4:04:32,  2.78s/it]                                                    {'loss': 2.7919, 'grad_norm': 1.7589349746704102, 'learning_rate': 4.471186440677966e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 724/6000 [33:47<4:04:32,  2.78s/it] 12%|â–ˆâ–        | 725/6000 [33:49<4:00:36,  2.74s/it]                                                    {'loss': 2.7501, 'grad_norm': 2.2668161392211914, 'learning_rate': 4.470338983050847e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 725/6000 [33:49<4:00:36,  2.74s/it] 12%|â–ˆâ–        | 726/6000 [33:52<3:57:54,  2.71s/it]                                                    {'loss': 2.758, 'grad_norm': 2.4445137977600098, 'learning_rate': 4.469491525423729e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 726/6000 [33:52<3:57:54,  2.71s/it] 12%|â–ˆâ–        | 727/6000 [33:55<3:56:35,  2.69s/it]                                                    {'loss': 2.781, 'grad_norm': 2.539975881576538, 'learning_rate': 4.46864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 727/6000 [33:55<3:56:35,  2.69s/it] 12%|â–ˆâ–        | 728/6000 [33:57<3:55:04,  2.68s/it]                                                    {'loss': 2.7781, 'grad_norm': 2.7093122005462646, 'learning_rate': 4.467796610169492e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 728/6000 [33:57<3:55:04,  2.68s/it] 12%|â–ˆâ–        | 729/6000 [34:00<3:54:58,  2.67s/it]                                                    {'loss': 2.7767, 'grad_norm': 2.626314878463745, 'learning_rate': 4.466949152542373e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 729/6000 [34:00<3:54:58,  2.67s/it] 12%|â–ˆâ–        | 730/6000 [34:03<3:55:02,  2.68s/it]                                                    {'loss': 2.7907, 'grad_norm': 3.1761558055877686, 'learning_rate': 4.466101694915254e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 730/6000 [34:03<3:55:02,  2.68s/it] 12%|â–ˆâ–        | 731/6000 [34:05<3:54:54,  2.68s/it]                                                    {'loss': 2.7248, 'grad_norm': 2.9159388542175293, 'learning_rate': 4.4652542372881354e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 731/6000 [34:05<3:54:54,  2.68s/it] 12%|â–ˆâ–        | 732/6000 [34:08<3:57:45,  2.71s/it]                                                    {'loss': 2.7295, 'grad_norm': 4.906296253204346, 'learning_rate': 4.464406779661017e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 732/6000 [34:08<3:57:45,  2.71s/it] 12%|â–ˆâ–        | 733/6000 [34:11<4:01:41,  2.75s/it]                                                    {'loss': 2.7949, 'grad_norm': 3.373445749282837, 'learning_rate': 4.463559322033898e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 733/6000 [34:11<4:01:41,  2.75s/it] 12%|â–ˆâ–        | 734/6000 [34:14<4:10:15,  2.85s/it]                                                    {'loss': 2.7455, 'grad_norm': 3.499774694442749, 'learning_rate': 4.46271186440678e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 734/6000 [34:14<4:10:15,  2.85s/it] 12%|â–ˆâ–        | 735/6000 [34:17<4:05:00,  2.79s/it]                                                    {'loss': 2.7163, 'grad_norm': 3.7463483810424805, 'learning_rate': 4.461864406779661e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 735/6000 [34:17<4:05:00,  2.79s/it] 12%|â–ˆâ–        | 736/6000 [34:19<4:00:30,  2.74s/it]                                                    {'loss': 2.7625, 'grad_norm': 7.433061122894287, 'learning_rate': 4.461016949152543e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 736/6000 [34:19<4:00:30,  2.74s/it] 12%|â–ˆâ–        | 737/6000 [34:22<3:59:38,  2.73s/it]                                                    {'loss': 2.8201, 'grad_norm': 4.839433670043945, 'learning_rate': 4.460169491525424e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 737/6000 [34:22<3:59:38,  2.73s/it] 12%|â–ˆâ–        | 738/6000 [34:25<3:56:10,  2.69s/it]                                                    {'loss': 2.886, 'grad_norm': 7.830250263214111, 'learning_rate': 4.459322033898305e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 738/6000 [34:25<3:56:10,  2.69s/it] 12%|â–ˆâ–        | 739/6000 [34:27<3:55:43,  2.69s/it]                                                    {'loss': 2.7223, 'grad_norm': 10.200017929077148, 'learning_rate': 4.4584745762711864e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 739/6000 [34:27<3:55:43,  2.69s/it] 12%|â–ˆâ–        | 740/6000 [34:30<3:56:46,  2.70s/it]                                                    {'loss': 2.6598, 'grad_norm': 5.7654290199279785, 'learning_rate': 4.457627118644068e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 740/6000 [34:30<3:56:46,  2.70s/it] 12%|â–ˆâ–        | 741/6000 [34:33<3:55:24,  2.69s/it]                                                    {'loss': 2.8468, 'grad_norm': 6.325593948364258, 'learning_rate': 4.4567796610169494e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 741/6000 [34:33<3:55:24,  2.69s/it] 12%|â–ˆâ–        | 742/6000 [34:35<3:54:04,  2.67s/it]                                                    {'loss': 2.9822, 'grad_norm': 17.730100631713867, 'learning_rate': 4.455932203389831e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 742/6000 [34:35<3:54:04,  2.67s/it] 12%|â–ˆâ–        | 743/6000 [34:38<3:51:26,  2.64s/it]                                                    {'loss': 2.7738, 'grad_norm': 6.061521530151367, 'learning_rate': 4.455084745762712e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 743/6000 [34:38<3:51:26,  2.64s/it] 12%|â–ˆâ–        | 744/6000 [34:41<3:51:33,  2.64s/it]                                                    {'loss': 2.7816, 'grad_norm': 10.580170631408691, 'learning_rate': 4.4542372881355934e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 744/6000 [34:41<3:51:33,  2.64s/it] 12%|â–ˆâ–        | 745/6000 [34:43<3:51:33,  2.64s/it]                                                    {'loss': 2.7744, 'grad_norm': 4.937826156616211, 'learning_rate': 4.4533898305084746e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 745/6000 [34:43<3:51:33,  2.64s/it] 12%|â–ˆâ–        | 746/6000 [34:46<3:52:46,  2.66s/it]                                                    {'loss': 2.7804, 'grad_norm': 9.863078117370605, 'learning_rate': 4.452542372881356e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 746/6000 [34:46<3:52:46,  2.66s/it] 12%|â–ˆâ–        | 747/6000 [34:49<3:54:18,  2.68s/it]                                                    {'loss': 2.8125, 'grad_norm': 6.107516765594482, 'learning_rate': 4.4516949152542375e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 747/6000 [34:49<3:54:18,  2.68s/it] 12%|â–ˆâ–        | 748/6000 [34:51<3:58:09,  2.72s/it]                                                    {'loss': 2.6811, 'grad_norm': 4.403968811035156, 'learning_rate': 4.4508474576271186e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 748/6000 [34:51<3:58:09,  2.72s/it] 12%|â–ˆâ–        | 749/6000 [34:55<4:17:52,  2.95s/it]                                                    {'loss': 2.7167, 'grad_norm': 14.290698051452637, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 749/6000 [34:55<4:17:52,  2.95s/it] 12%|â–ˆâ–Ž        | 750/6000 [34:58<4:18:13,  2.95s/it]                                                    {'loss': 2.8083, 'grad_norm': 5.492709159851074, 'learning_rate': 4.4491525423728816e-05, 'epoch': 0.12}
 12%|â–ˆâ–Ž        | 750/6000 [34:58<4:18:13,  2.95s/it][2025-10-20 23:40:49,142] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-750
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 751/6000 [35:04<5:37:09,  3.85s/it]                                                    {'loss': 2.8009, 'grad_norm': 3.4387872219085693, 'learning_rate': 4.448305084745763e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 751/6000 [35:04<5:37:09,  3.85s/it] 13%|â–ˆâ–Ž        | 752/6000 [35:07<5:15:57,  3.61s/it]                                                    {'loss': 2.8424, 'grad_norm': 3.198561429977417, 'learning_rate': 4.447457627118644e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 752/6000 [35:07<5:15:57,  3.61s/it] 13%|â–ˆâ–Ž        | 753/6000 [35:10<4:52:52,  3.35s/it]                                                    {'loss': 2.8099, 'grad_norm': 2.633437395095825, 'learning_rate': 4.4466101694915256e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 753/6000 [35:10<4:52:52,  3.35s/it] 13%|â–ˆâ–Ž        | 754/6000 [35:12<4:36:44,  3.17s/it]                                                    {'loss': 2.7707, 'grad_norm': 2.177243709564209, 'learning_rate': 4.445762711864407e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 754/6000 [35:12<4:36:44,  3.17s/it] 13%|â–ˆâ–Ž        | 755/6000 [35:15<4:23:50,  3.02s/it]                                                    {'loss': 2.7746, 'grad_norm': 2.0767455101013184, 'learning_rate': 4.4449152542372886e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 755/6000 [35:15<4:23:50,  3.02s/it] 13%|â–ˆâ–Ž        | 756/6000 [35:18<4:14:09,  2.91s/it]                                                    {'loss': 2.7688, 'grad_norm': 1.8766310214996338, 'learning_rate': 4.44406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 756/6000 [35:18<4:14:09,  2.91s/it] 13%|â–ˆâ–Ž        | 757/6000 [35:20<4:11:49,  2.88s/it]                                                    {'loss': 2.7638, 'grad_norm': 2.3028647899627686, 'learning_rate': 4.4432203389830515e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 757/6000 [35:21<4:11:49,  2.88s/it] 13%|â–ˆâ–Ž        | 758/6000 [35:23<4:15:07,  2.92s/it]                                                    {'loss': 2.7837, 'grad_norm': 1.690431833267212, 'learning_rate': 4.4423728813559326e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 758/6000 [35:24<4:15:07,  2.92s/it] 13%|â–ˆâ–Ž        | 759/6000 [35:26<4:08:32,  2.85s/it]                                                    {'loss': 2.7647, 'grad_norm': 1.9442906379699707, 'learning_rate': 4.441525423728814e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 759/6000 [35:26<4:08:32,  2.85s/it] 13%|â–ˆâ–Ž        | 760/6000 [35:29<4:04:59,  2.81s/it]                                                    {'loss': 2.785, 'grad_norm': 1.6762111186981201, 'learning_rate': 4.440677966101695e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 760/6000 [35:29<4:04:59,  2.81s/it] 13%|â–ˆâ–Ž        | 761/6000 [35:32<4:02:28,  2.78s/it]                                                    {'loss': 2.7922, 'grad_norm': 1.9162019491195679, 'learning_rate': 4.439830508474577e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 761/6000 [35:32<4:02:28,  2.78s/it] 13%|â–ˆâ–Ž        | 762/6000 [35:34<4:03:38,  2.79s/it]                                                    {'loss': 2.777, 'grad_norm': 1.6607245206832886, 'learning_rate': 4.438983050847458e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 762/6000 [35:34<4:03:38,  2.79s/it] 13%|â–ˆâ–Ž        | 763/6000 [35:37<4:00:04,  2.75s/it]                                                    {'loss': 2.771, 'grad_norm': 1.5992776155471802, 'learning_rate': 4.4381355932203396e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 763/6000 [35:37<4:00:04,  2.75s/it] 13%|â–ˆâ–Ž        | 764/6000 [35:40<4:04:59,  2.81s/it]                                                    {'loss': 2.7721, 'grad_norm': 1.5571750402450562, 'learning_rate': 4.437288135593221e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 764/6000 [35:40<4:04:59,  2.81s/it] 13%|â–ˆâ–Ž        | 765/6000 [35:43<4:00:30,  2.76s/it]                                                    {'loss': 2.8134, 'grad_norm': 1.0515645742416382, 'learning_rate': 4.436440677966102e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 765/6000 [35:43<4:00:30,  2.76s/it] 13%|â–ˆâ–Ž        | 766/6000 [35:45<3:58:58,  2.74s/it]                                                    {'loss': 2.7758, 'grad_norm': 1.3369791507720947, 'learning_rate': 4.435593220338983e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 766/6000 [35:45<3:58:58,  2.74s/it] 13%|â–ˆâ–Ž        | 767/6000 [35:48<4:07:10,  2.83s/it]                                                    {'loss': 2.7429, 'grad_norm': 1.7532429695129395, 'learning_rate': 4.434745762711864e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 767/6000 [35:48<4:07:10,  2.83s/it] 13%|â–ˆâ–Ž        | 768/6000 [35:51<4:03:12,  2.79s/it]                                                    {'loss': 2.7619, 'grad_norm': 1.378467321395874, 'learning_rate': 4.433898305084746e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 768/6000 [35:51<4:03:12,  2.79s/it] 13%|â–ˆâ–Ž        | 769/6000 [35:54<4:06:08,  2.82s/it]                                                    {'loss': 2.7699, 'grad_norm': 1.304060697555542, 'learning_rate': 4.433050847457627e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 769/6000 [35:54<4:06:08,  2.82s/it] 13%|â–ˆâ–Ž        | 770/6000 [35:57<4:01:55,  2.78s/it]                                                    {'loss': 2.8107, 'grad_norm': 1.5118008852005005, 'learning_rate': 4.432203389830509e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 770/6000 [35:57<4:01:55,  2.78s/it] 13%|â–ˆâ–Ž        | 771/6000 [35:59<3:58:35,  2.74s/it]                                                    {'loss': 2.7625, 'grad_norm': 1.55729079246521, 'learning_rate': 4.43135593220339e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 771/6000 [35:59<3:58:35,  2.74s/it] 13%|â–ˆâ–Ž        | 772/6000 [36:02<3:54:28,  2.69s/it]                                                    {'loss': 2.7574, 'grad_norm': 1.7197521924972534, 'learning_rate': 4.430508474576272e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 772/6000 [36:02<3:54:28,  2.69s/it] 13%|â–ˆâ–Ž        | 773/6000 [36:05<3:52:57,  2.67s/it]                                                    {'loss': 2.7783, 'grad_norm': 1.5646103620529175, 'learning_rate': 4.429661016949152e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 773/6000 [36:05<3:52:57,  2.67s/it] 13%|â–ˆâ–Ž        | 774/6000 [36:07<3:53:50,  2.68s/it]                                                    {'loss': 2.7907, 'grad_norm': 1.5105632543563843, 'learning_rate': 4.428813559322034e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 774/6000 [36:07<3:53:50,  2.68s/it] 13%|â–ˆâ–Ž        | 775/6000 [36:10<3:56:47,  2.72s/it]                                                    {'loss': 2.7598, 'grad_norm': 1.9800175428390503, 'learning_rate': 4.427966101694915e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 775/6000 [36:10<3:56:47,  2.72s/it] 13%|â–ˆâ–Ž        | 776/6000 [36:13<3:56:26,  2.72s/it]                                                    {'loss': 2.7901, 'grad_norm': 1.5942096710205078, 'learning_rate': 4.427118644067797e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 776/6000 [36:13<3:56:26,  2.72s/it] 13%|â–ˆâ–Ž        | 777/6000 [36:16<3:59:33,  2.75s/it]                                                    {'loss': 2.7224, 'grad_norm': 2.0650100708007812, 'learning_rate': 4.426271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 777/6000 [36:16<3:59:33,  2.75s/it] 13%|â–ˆâ–Ž        | 778/6000 [36:19<4:06:08,  2.83s/it]                                                    {'loss': 2.7602, 'grad_norm': 1.8017849922180176, 'learning_rate': 4.42542372881356e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 778/6000 [36:19<4:06:08,  2.83s/it] 13%|â–ˆâ–Ž        | 779/6000 [36:21<4:01:44,  2.78s/it]                                                    {'loss': 2.8127, 'grad_norm': 2.1481027603149414, 'learning_rate': 4.424576271186441e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 779/6000 [36:21<4:01:44,  2.78s/it] 13%|â–ˆâ–Ž        | 780/6000 [36:24<4:02:28,  2.79s/it]                                                    {'loss': 2.8125, 'grad_norm': 2.6380562782287598, 'learning_rate': 4.423728813559322e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 780/6000 [36:24<4:02:28,  2.79s/it] 13%|â–ˆâ–Ž        | 781/6000 [36:27<4:02:07,  2.78s/it]                                                    {'loss': 2.7579, 'grad_norm': 3.4962079524993896, 'learning_rate': 4.422881355932203e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 781/6000 [36:27<4:02:07,  2.78s/it] 13%|â–ˆâ–Ž        | 782/6000 [36:29<3:59:01,  2.75s/it]                                                    {'loss': 2.7498, 'grad_norm': 1.940755009651184, 'learning_rate': 4.422033898305085e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 782/6000 [36:29<3:59:01,  2.75s/it] 13%|â–ˆâ–Ž        | 783/6000 [36:32<3:56:50,  2.72s/it]                                                    {'loss': 2.7244, 'grad_norm': 2.855909824371338, 'learning_rate': 4.421186440677966e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 783/6000 [36:32<3:56:50,  2.72s/it] 13%|â–ˆâ–Ž        | 784/6000 [36:35<3:55:54,  2.71s/it]                                                    {'loss': 2.7914, 'grad_norm': 2.641309976577759, 'learning_rate': 4.420338983050848e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 784/6000 [36:35<3:55:54,  2.71s/it] 13%|â–ˆâ–Ž        | 785/6000 [36:37<3:53:46,  2.69s/it]                                                    {'loss': 2.7893, 'grad_norm': 3.250255584716797, 'learning_rate': 4.419491525423729e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 785/6000 [36:37<3:53:46,  2.69s/it] 13%|â–ˆâ–Ž        | 786/6000 [36:40<3:52:53,  2.68s/it]                                                    {'loss': 2.7412, 'grad_norm': 3.2292418479919434, 'learning_rate': 4.41864406779661e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 786/6000 [36:40<3:52:53,  2.68s/it] 13%|â–ˆâ–Ž        | 787/6000 [36:43<3:53:41,  2.69s/it]                                                    {'loss': 2.9095, 'grad_norm': 4.456857681274414, 'learning_rate': 4.4177966101694914e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 787/6000 [36:43<3:53:41,  2.69s/it] 13%|â–ˆâ–Ž        | 788/6000 [36:46<3:52:59,  2.68s/it]                                                    {'loss': 2.7379, 'grad_norm': 2.765157699584961, 'learning_rate': 4.4169491525423726e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 788/6000 [36:46<3:52:59,  2.68s/it] 13%|â–ˆâ–Ž        | 789/6000 [36:48<3:55:37,  2.71s/it]                                                    {'loss': 2.7612, 'grad_norm': 3.579807996749878, 'learning_rate': 4.4161016949152544e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 789/6000 [36:48<3:55:37,  2.71s/it] 13%|â–ˆâ–Ž        | 790/6000 [36:51<3:55:18,  2.71s/it]                                                    {'loss': 2.7639, 'grad_norm': 2.6503844261169434, 'learning_rate': 4.4152542372881355e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 790/6000 [36:51<3:55:18,  2.71s/it] 13%|â–ˆâ–Ž        | 791/6000 [36:54<3:54:22,  2.70s/it]                                                    {'loss': 2.8175, 'grad_norm': 3.601470947265625, 'learning_rate': 4.414406779661017e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 791/6000 [36:54<3:54:22,  2.70s/it] 13%|â–ˆâ–Ž        | 792/6000 [36:56<3:54:51,  2.71s/it]                                                    {'loss': 2.7292, 'grad_norm': 2.7346558570861816, 'learning_rate': 4.4135593220338984e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 792/6000 [36:56<3:54:51,  2.71s/it] 13%|â–ˆâ–Ž        | 793/6000 [36:59<3:55:29,  2.71s/it]                                                    {'loss': 2.7426, 'grad_norm': 3.063196897506714, 'learning_rate': 4.41271186440678e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 793/6000 [36:59<3:55:29,  2.71s/it] 13%|â–ˆâ–Ž        | 794/6000 [37:02<3:56:26,  2.72s/it]                                                    {'loss': 2.7528, 'grad_norm': 4.100666522979736, 'learning_rate': 4.4118644067796614e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 794/6000 [37:02<3:56:26,  2.72s/it] 13%|â–ˆâ–Ž        | 795/6000 [37:05<4:04:46,  2.82s/it]                                                    {'loss': 2.8437, 'grad_norm': 6.111586570739746, 'learning_rate': 4.4110169491525425e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 795/6000 [37:05<4:04:46,  2.82s/it] 13%|â–ˆâ–Ž        | 796/6000 [37:08<4:01:03,  2.78s/it]                                                    {'loss': 2.7222, 'grad_norm': 7.200246810913086, 'learning_rate': 4.4101694915254236e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 796/6000 [37:08<4:01:03,  2.78s/it] 13%|â–ˆâ–Ž        | 797/6000 [37:10<3:59:50,  2.77s/it]                                                    {'loss': 2.735, 'grad_norm': 3.60275936126709, 'learning_rate': 4.4093220338983054e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 797/6000 [37:10<3:59:50,  2.77s/it] 13%|â–ˆâ–Ž        | 798/6000 [37:13<3:55:47,  2.72s/it]                                                    {'loss': 2.7745, 'grad_norm': 2.927022933959961, 'learning_rate': 4.4084745762711866e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 798/6000 [37:13<3:55:47,  2.72s/it] 13%|â–ˆâ–Ž        | 799/6000 [37:16<3:54:50,  2.71s/it]                                                    {'loss': 2.8005, 'grad_norm': 6.120463848114014, 'learning_rate': 4.4076271186440684e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 799/6000 [37:16<3:54:50,  2.71s/it] 13%|â–ˆâ–Ž        | 800/6000 [37:18<3:55:25,  2.72s/it]                                                    {'loss': 2.792, 'grad_norm': 5.0358805656433105, 'learning_rate': 4.4067796610169495e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 800/6000 [37:18<3:55:25,  2.72s/it][2025-10-20 23:43:09,644] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-800
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 13%|â–ˆâ–Ž        | 801/6000 [37:23<4:48:23,  3.33s/it]                                                    {'loss': 2.7814, 'grad_norm': 4.945838928222656, 'learning_rate': 4.4059322033898306e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 801/6000 [37:23<4:48:23,  3.33s/it] 13%|â–ˆâ–Ž        | 802/6000 [37:26<4:33:09,  3.15s/it]                                                    {'loss': 2.8118, 'grad_norm': 3.4730384349823, 'learning_rate': 4.405084745762712e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 802/6000 [37:26<4:33:09,  3.15s/it] 13%|â–ˆâ–Ž        | 803/6000 [37:29<4:20:33,  3.01s/it]                                                    {'loss': 2.7829, 'grad_norm': 14.867712020874023, 'learning_rate': 4.4042372881355936e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 803/6000 [37:29<4:20:33,  3.01s/it] 13%|â–ˆâ–Ž        | 804/6000 [37:31<4:11:51,  2.91s/it]                                                    {'loss': 2.7786, 'grad_norm': 6.473569869995117, 'learning_rate': 4.403389830508475e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 804/6000 [37:31<4:11:51,  2.91s/it] 13%|â–ˆâ–Ž        | 805/6000 [37:34<4:05:33,  2.84s/it]                                                    {'loss': 2.8129, 'grad_norm': 2.8428802490234375, 'learning_rate': 4.4025423728813565e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 805/6000 [37:34<4:05:33,  2.84s/it] 13%|â–ˆâ–Ž        | 806/6000 [37:37<4:03:43,  2.82s/it]                                                    {'loss': 2.834, 'grad_norm': 2.5244438648223877, 'learning_rate': 4.4016949152542376e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 806/6000 [37:37<4:03:43,  2.82s/it] 13%|â–ˆâ–Ž        | 807/6000 [37:39<4:00:49,  2.78s/it]                                                    {'loss': 2.7755, 'grad_norm': 2.212132692337036, 'learning_rate': 4.400847457627119e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 807/6000 [37:39<4:00:49,  2.78s/it] 13%|â–ˆâ–Ž        | 808/6000 [37:42<3:58:56,  2.76s/it]                                                    {'loss': 2.7672, 'grad_norm': 1.7610613107681274, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 808/6000 [37:42<3:58:56,  2.76s/it] 13%|â–ˆâ–Ž        | 809/6000 [37:45<3:56:48,  2.74s/it]                                                    {'loss': 2.77, 'grad_norm': 2.115772008895874, 'learning_rate': 4.399152542372881e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 809/6000 [37:45<3:56:48,  2.74s/it] 14%|â–ˆâ–Ž        | 810/6000 [37:48<3:58:30,  2.76s/it]                                                    {'loss': 2.7668, 'grad_norm': 2.204864740371704, 'learning_rate': 4.398305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 810/6000 [37:48<3:58:30,  2.76s/it] 14%|â–ˆâ–Ž        | 811/6000 [37:50<3:56:03,  2.73s/it]                                                    {'loss': 2.7546, 'grad_norm': 1.9461567401885986, 'learning_rate': 4.397457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 811/6000 [37:50<3:56:03,  2.73s/it] 14%|â–ˆâ–Ž        | 812/6000 [37:53<3:52:42,  2.69s/it]                                                    {'loss': 2.803, 'grad_norm': 1.215773582458496, 'learning_rate': 4.396610169491526e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 812/6000 [37:53<3:52:42,  2.69s/it] 14%|â–ˆâ–Ž        | 813/6000 [37:56<4:10:39,  2.90s/it]                                                    {'loss': 2.7548, 'grad_norm': 1.7406396865844727, 'learning_rate': 4.395762711864407e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 813/6000 [37:56<4:10:39,  2.90s/it] 14%|â–ˆâ–Ž        | 814/6000 [37:59<4:04:24,  2.83s/it]                                                    {'loss': 2.7955, 'grad_norm': 2.075993776321411, 'learning_rate': 4.394915254237289e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 814/6000 [37:59<4:04:24,  2.83s/it] 14%|â–ˆâ–Ž        | 815/6000 [38:02<3:59:20,  2.77s/it]                                                    {'loss': 2.7965, 'grad_norm': 1.721720814704895, 'learning_rate': 4.39406779661017e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 815/6000 [38:02<3:59:20,  2.77s/it] 14%|â–ˆâ–Ž        | 816/6000 [38:04<3:56:40,  2.74s/it]                                                    {'loss': 2.8084, 'grad_norm': 1.8628122806549072, 'learning_rate': 4.393220338983051e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 816/6000 [38:04<3:56:40,  2.74s/it] 14%|â–ˆâ–Ž        | 817/6000 [38:08<4:13:16,  2.93s/it]                                                    {'loss': 2.7861, 'grad_norm': 1.9371479749679565, 'learning_rate': 4.392372881355932e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 817/6000 [38:08<4:13:16,  2.93s/it] 14%|â–ˆâ–Ž        | 818/6000 [38:10<4:05:49,  2.85s/it]                                                    {'loss': 2.7659, 'grad_norm': 1.300240397453308, 'learning_rate': 4.391525423728814e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 818/6000 [38:10<4:05:49,  2.85s/it] 14%|â–ˆâ–Ž        | 819/6000 [38:13<4:01:27,  2.80s/it]                                                    {'loss': 2.7243, 'grad_norm': 2.286726236343384, 'learning_rate': 4.390677966101695e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 819/6000 [38:13<4:01:27,  2.80s/it] 14%|â–ˆâ–Ž        | 820/6000 [38:16<3:58:38,  2.76s/it]                                                    {'loss': 2.7625, 'grad_norm': 1.887411117553711, 'learning_rate': 4.389830508474577e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 820/6000 [38:16<3:58:38,  2.76s/it] 14%|â–ˆâ–Ž        | 821/6000 [38:18<3:56:23,  2.74s/it]                                                    {'loss': 2.783, 'grad_norm': 2.551628351211548, 'learning_rate': 4.388983050847458e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 821/6000 [38:18<3:56:23,  2.74s/it] 14%|â–ˆâ–Ž        | 822/6000 [38:21<3:54:03,  2.71s/it]                                                    {'loss': 2.7837, 'grad_norm': 2.0756804943084717, 'learning_rate': 4.388135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 822/6000 [38:21<3:54:03,  2.71s/it] 14%|â–ˆâ–Ž        | 823/6000 [38:24<3:53:34,  2.71s/it]                                                    {'loss': 2.7556, 'grad_norm': 2.1777846813201904, 'learning_rate': 4.38728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 823/6000 [38:24<3:53:34,  2.71s/it] 14%|â–ˆâ–Ž        | 824/6000 [38:26<3:52:30,  2.70s/it]                                                    {'loss': 2.7471, 'grad_norm': 2.9254932403564453, 'learning_rate': 4.386440677966102e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 824/6000 [38:26<3:52:30,  2.70s/it] 14%|â–ˆâ–        | 825/6000 [38:29<4:00:42,  2.79s/it]                                                    {'loss': 2.8734, 'grad_norm': 2.3484201431274414, 'learning_rate': 4.385593220338983e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 825/6000 [38:29<4:00:42,  2.79s/it] 14%|â–ˆâ–        | 826/6000 [38:32<3:58:27,  2.77s/it]                                                    {'loss': 2.7539, 'grad_norm': 2.4791996479034424, 'learning_rate': 4.384745762711865e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 826/6000 [38:32<3:58:27,  2.77s/it] 14%|â–ˆâ–        | 827/6000 [38:35<3:55:15,  2.73s/it]                                                    {'loss': 2.774, 'grad_norm': 2.4187262058258057, 'learning_rate': 4.383898305084746e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 827/6000 [38:35<3:55:15,  2.73s/it] 14%|â–ˆâ–        | 828/6000 [38:37<3:54:15,  2.72s/it]                                                    {'loss': 2.8191, 'grad_norm': 3.1461503505706787, 'learning_rate': 4.383050847457627e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 828/6000 [38:37<3:54:15,  2.72s/it] 14%|â–ˆâ–        | 829/6000 [38:40<3:53:51,  2.71s/it]                                                    {'loss': 2.7815, 'grad_norm': 2.4173619747161865, 'learning_rate': 4.382203389830509e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 829/6000 [38:40<3:53:51,  2.71s/it] 14%|â–ˆâ–        | 830/6000 [38:44<4:15:09,  2.96s/it]                                                    {'loss': 2.8286, 'grad_norm': 2.948528528213501, 'learning_rate': 4.38135593220339e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 830/6000 [38:44<4:15:09,  2.96s/it] 14%|â–ˆâ–        | 831/6000 [38:46<4:11:51,  2.92s/it]                                                    {'loss': 2.8125, 'grad_norm': 2.0802831649780273, 'learning_rate': 4.380508474576271e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 831/6000 [38:46<4:11:51,  2.92s/it] 14%|â–ˆâ–        | 832/6000 [38:49<4:03:48,  2.83s/it]                                                    {'loss': 2.796, 'grad_norm': 1.9475374221801758, 'learning_rate': 4.3796610169491524e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 832/6000 [38:49<4:03:48,  2.83s/it] 14%|â–ˆâ–        | 833/6000 [38:52<3:58:48,  2.77s/it]                                                    {'loss': 2.7577, 'grad_norm': 3.343369722366333, 'learning_rate': 4.378813559322034e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 833/6000 [38:52<3:58:48,  2.77s/it] 14%|â–ˆâ–        | 834/6000 [38:54<3:55:51,  2.74s/it]                                                    {'loss': 2.7726, 'grad_norm': 1.5537089109420776, 'learning_rate': 4.377966101694915e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 834/6000 [38:54<3:55:51,  2.74s/it] 14%|â–ˆâ–        | 835/6000 [38:57<4:04:14,  2.84s/it]                                                    {'loss': 2.7791, 'grad_norm': 1.8205137252807617, 'learning_rate': 4.377118644067797e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 835/6000 [38:57<4:04:14,  2.84s/it] 14%|â–ˆâ–        | 836/6000 [39:00<3:57:25,  2.76s/it]                                                    {'loss': 2.7404, 'grad_norm': 2.467299699783325, 'learning_rate': 4.376271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 836/6000 [39:00<3:57:25,  2.76s/it] 14%|â–ˆâ–        | 837/6000 [39:03<4:16:49,  2.98s/it]                                                    {'loss': 2.7483, 'grad_norm': 1.5907695293426514, 'learning_rate': 4.3754237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 837/6000 [39:03<4:16:49,  2.98s/it] 14%|â–ˆâ–        | 838/6000 [39:07<4:18:41,  3.01s/it]                                                    {'loss': 2.7703, 'grad_norm': 2.454674243927002, 'learning_rate': 4.3745762711864405e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 838/6000 [39:07<4:18:41,  3.01s/it] 14%|â–ˆâ–        | 839/6000 [39:09<4:10:20,  2.91s/it]                                                    {'loss': 2.7869, 'grad_norm': 1.7072635889053345, 'learning_rate': 4.373728813559322e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 839/6000 [39:09<4:10:20,  2.91s/it] 14%|â–ˆâ–        | 840/6000 [39:12<4:05:00,  2.85s/it]                                                    {'loss': 2.7705, 'grad_norm': 1.8427542448043823, 'learning_rate': 4.3728813559322035e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 840/6000 [39:12<4:05:00,  2.85s/it] 14%|â–ˆâ–        | 841/6000 [39:15<4:12:02,  2.93s/it]                                                    {'loss': 2.7698, 'grad_norm': 1.7983185052871704, 'learning_rate': 4.372033898305085e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 841/6000 [39:15<4:12:02,  2.93s/it] 14%|â–ˆâ–        | 842/6000 [39:18<4:05:34,  2.86s/it]                                                    {'loss': 2.7462, 'grad_norm': 1.9892754554748535, 'learning_rate': 4.3711864406779664e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 842/6000 [39:18<4:05:34,  2.86s/it] 14%|â–ˆâ–        | 843/6000 [39:21<4:06:34,  2.87s/it]                                                    {'loss': 2.7797, 'grad_norm': 2.062755823135376, 'learning_rate': 4.370338983050848e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 843/6000 [39:21<4:06:34,  2.87s/it] 14%|â–ˆâ–        | 844/6000 [39:24<4:08:00,  2.89s/it]                                                    {'loss': 2.844, 'grad_norm': 3.7948410511016846, 'learning_rate': 4.3694915254237286e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 844/6000 [39:24<4:08:00,  2.89s/it] 14%|â–ˆâ–        | 845/6000 [39:26<4:01:22,  2.81s/it]                                                    {'loss': 2.8686, 'grad_norm': 2.196652412414551, 'learning_rate': 4.3686440677966105e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 845/6000 [39:26<4:01:22,  2.81s/it] 14%|â–ˆâ–        | 846/6000 [39:29<4:01:10,  2.81s/it]                                                    {'loss': 2.7679, 'grad_norm': 2.4125442504882812, 'learning_rate': 4.3677966101694916e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 846/6000 [39:29<4:01:10,  2.81s/it] 14%|â–ˆâ–        | 847/6000 [39:32<3:59:07,  2.78s/it]                                                    {'loss': 2.6792, 'grad_norm': 3.0936598777770996, 'learning_rate': 4.3669491525423734e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 847/6000 [39:32<3:59:07,  2.78s/it] 14%|â–ˆâ–        | 848/6000 [39:35<4:04:45,  2.85s/it]                                                    {'loss': 2.7562, 'grad_norm': 2.5702931880950928, 'learning_rate': 4.3661016949152545e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 848/6000 [39:35<4:04:45,  2.85s/it] 14%|â–ˆâ–        | 849/6000 [39:38<4:03:17,  2.83s/it]                                                    {'loss': 2.74, 'grad_norm': 2.379061460494995, 'learning_rate': 4.3652542372881356e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 849/6000 [39:38<4:03:17,  2.83s/it] 14%|â–ˆâ–        | 850/6000 [39:40<4:00:30,  2.80s/it]                                                    {'loss': 2.8219, 'grad_norm': 3.0291192531585693, 'learning_rate': 4.3644067796610175e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 850/6000 [39:40<4:00:30,  2.80s/it][2025-10-20 23:45:31,506] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-850
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 14%|â–ˆâ–        | 851/6000 [39:45<4:45:03,  3.32s/it]                                                    {'loss': 2.8099, 'grad_norm': 2.9832746982574463, 'learning_rate': 4.3635593220338986e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 851/6000 [39:45<4:45:03,  3.32s/it] 14%|â–ˆâ–        | 852/6000 [39:47<4:28:19,  3.13s/it]                                                    {'loss': 2.7457, 'grad_norm': 2.081552028656006, 'learning_rate': 4.36271186440678e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 852/6000 [39:47<4:28:19,  3.13s/it] 14%|â–ˆâ–        | 853/6000 [39:50<4:15:54,  2.98s/it]                                                    {'loss': 2.816, 'grad_norm': 2.0361642837524414, 'learning_rate': 4.361864406779661e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 853/6000 [39:50<4:15:54,  2.98s/it] 14%|â–ˆâ–        | 854/6000 [39:53<4:08:11,  2.89s/it]                                                    {'loss': 2.8074, 'grad_norm': 1.701574444770813, 'learning_rate': 4.3610169491525426e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 854/6000 [39:53<4:08:11,  2.89s/it] 14%|â–ˆâ–        | 855/6000 [39:55<4:02:38,  2.83s/it]                                                    {'loss': 2.8505, 'grad_norm': 2.3174679279327393, 'learning_rate': 4.360169491525424e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 855/6000 [39:55<4:02:38,  2.83s/it] 14%|â–ˆâ–        | 856/6000 [39:58<4:00:50,  2.81s/it]                                                    {'loss': 2.8225, 'grad_norm': 1.7777565717697144, 'learning_rate': 4.3593220338983056e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 856/6000 [39:58<4:00:50,  2.81s/it] 14%|â–ˆâ–        | 857/6000 [40:01<3:57:21,  2.77s/it]                                                    {'loss': 2.7856, 'grad_norm': 1.8120514154434204, 'learning_rate': 4.358474576271187e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 857/6000 [40:01<3:57:21,  2.77s/it] 14%|â–ˆâ–        | 858/6000 [40:04<3:54:59,  2.74s/it]                                                    {'loss': 2.7248, 'grad_norm': 2.042952060699463, 'learning_rate': 4.357627118644068e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 858/6000 [40:04<3:54:59,  2.74s/it] 14%|â–ˆâ–        | 859/6000 [40:06<3:52:44,  2.72s/it]                                                    {'loss': 2.7275, 'grad_norm': 2.384608745574951, 'learning_rate': 4.356779661016949e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 859/6000 [40:06<3:52:44,  2.72s/it] 14%|â–ˆâ–        | 860/6000 [40:09<4:01:50,  2.82s/it]                                                    {'loss': 2.7643, 'grad_norm': 2.4365394115448, 'learning_rate': 4.355932203389831e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 860/6000 [40:09<4:01:50,  2.82s/it] 14%|â–ˆâ–        | 861/6000 [40:12<3:57:44,  2.78s/it]                                                    {'loss': 2.7731, 'grad_norm': 3.1159770488739014, 'learning_rate': 4.355084745762712e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 861/6000 [40:12<3:57:44,  2.78s/it] 14%|â–ˆâ–        | 862/6000 [40:15<3:57:15,  2.77s/it]                                                    {'loss': 2.7798, 'grad_norm': 3.372492790222168, 'learning_rate': 4.354237288135594e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 862/6000 [40:15<3:57:15,  2.77s/it] 14%|â–ˆâ–        | 863/6000 [40:17<3:56:34,  2.76s/it]                                                    {'loss': 2.7639, 'grad_norm': 3.836815595626831, 'learning_rate': 4.353389830508475e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 863/6000 [40:17<3:56:34,  2.76s/it] 14%|â–ˆâ–        | 864/6000 [40:20<3:53:50,  2.73s/it]                                                    {'loss': 2.7775, 'grad_norm': 2.8540709018707275, 'learning_rate': 4.3525423728813566e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 864/6000 [40:20<3:53:50,  2.73s/it] 14%|â–ˆâ–        | 865/6000 [40:23<4:02:19,  2.83s/it]                                                    {'loss': 2.7159, 'grad_norm': 4.095752239227295, 'learning_rate': 4.351694915254238e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 865/6000 [40:23<4:02:19,  2.83s/it] 14%|â–ˆâ–        | 866/6000 [40:26<3:57:09,  2.77s/it]                                                    {'loss': 2.7497, 'grad_norm': 2.5872268676757812, 'learning_rate': 4.350847457627119e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 866/6000 [40:26<3:57:09,  2.77s/it] 14%|â–ˆâ–        | 867/6000 [40:29<3:55:24,  2.75s/it]                                                    {'loss': 2.7836, 'grad_norm': 2.9172847270965576, 'learning_rate': 4.35e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 867/6000 [40:29<3:55:24,  2.75s/it] 14%|â–ˆâ–        | 868/6000 [40:31<3:50:42,  2.70s/it]                                                    {'loss': 2.7896, 'grad_norm': 2.2716872692108154, 'learning_rate': 4.349152542372882e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 868/6000 [40:31<3:50:42,  2.70s/it] 14%|â–ˆâ–        | 869/6000 [40:34<3:49:09,  2.68s/it]                                                    {'loss': 2.7501, 'grad_norm': 1.8777947425842285, 'learning_rate': 4.348305084745763e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 869/6000 [40:34<3:49:09,  2.68s/it] 14%|â–ˆâ–        | 870/6000 [40:36<3:48:38,  2.67s/it]                                                    {'loss': 2.7406, 'grad_norm': 1.7526816129684448, 'learning_rate': 4.347457627118644e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 870/6000 [40:36<3:48:38,  2.67s/it] 15%|â–ˆâ–        | 871/6000 [40:39<3:48:31,  2.67s/it]                                                    {'loss': 2.7939, 'grad_norm': 1.6075862646102905, 'learning_rate': 4.346610169491526e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 871/6000 [40:39<3:48:31,  2.67s/it] 15%|â–ˆâ–        | 872/6000 [40:42<3:49:11,  2.68s/it]                                                    {'loss': 2.7916, 'grad_norm': 1.7821089029312134, 'learning_rate': 4.345762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 872/6000 [40:42<3:49:11,  2.68s/it] 15%|â–ˆâ–        | 873/6000 [40:45<3:50:30,  2.70s/it]                                                    {'loss': 2.7735, 'grad_norm': 1.709831714630127, 'learning_rate': 4.344915254237288e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 873/6000 [40:45<3:50:30,  2.70s/it] 15%|â–ˆâ–        | 874/6000 [40:47<3:49:02,  2.68s/it]                                                    {'loss': 2.9299, 'grad_norm': 1.8663372993469238, 'learning_rate': 4.344067796610169e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 874/6000 [40:47<3:49:02,  2.68s/it] 15%|â–ˆâ–        | 875/6000 [40:50<3:56:15,  2.77s/it]                                                    {'loss': 2.7854, 'grad_norm': 1.447485089302063, 'learning_rate': 4.343220338983051e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 875/6000 [40:50<3:56:15,  2.77s/it] 15%|â–ˆâ–        | 876/6000 [40:53<3:53:35,  2.74s/it]                                                    {'loss': 2.7834, 'grad_norm': 1.4642014503479004, 'learning_rate': 4.342372881355932e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 876/6000 [40:53<3:53:35,  2.74s/it] 15%|â–ˆâ–        | 877/6000 [40:56<3:55:36,  2.76s/it]                                                    {'loss': 2.7718, 'grad_norm': 1.707782506942749, 'learning_rate': 4.341525423728814e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 877/6000 [40:56<3:55:36,  2.76s/it] 15%|â–ˆâ–        | 878/6000 [40:58<3:54:12,  2.74s/it]                                                    {'loss': 2.7556, 'grad_norm': 1.4122138023376465, 'learning_rate': 4.340677966101695e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 878/6000 [40:58<3:54:12,  2.74s/it] 15%|â–ˆâ–        | 879/6000 [41:02<4:06:07,  2.88s/it]                                                    {'loss': 2.7466, 'grad_norm': 1.8855016231536865, 'learning_rate': 4.339830508474576e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 879/6000 [41:02<4:06:07,  2.88s/it] 15%|â–ˆâ–        | 880/6000 [41:04<3:59:46,  2.81s/it]                                                    {'loss': 2.7456, 'grad_norm': 1.498708963394165, 'learning_rate': 4.3389830508474574e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 880/6000 [41:04<3:59:46,  2.81s/it] 15%|â–ˆâ–        | 881/6000 [41:07<3:55:33,  2.76s/it]                                                    {'loss': 2.7625, 'grad_norm': 1.7253426313400269, 'learning_rate': 4.338135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 881/6000 [41:07<3:55:33,  2.76s/it] 15%|â–ˆâ–        | 882/6000 [41:10<3:54:15,  2.75s/it]                                                    {'loss': 2.7901, 'grad_norm': 2.1092681884765625, 'learning_rate': 4.3372881355932203e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 882/6000 [41:10<3:54:15,  2.75s/it] 15%|â–ˆâ–        | 883/6000 [41:12<3:51:53,  2.72s/it]                                                    {'loss': 2.7786, 'grad_norm': 1.7185237407684326, 'learning_rate': 4.336440677966102e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 883/6000 [41:12<3:51:53,  2.72s/it] 15%|â–ˆâ–        | 884/6000 [41:15<3:54:52,  2.75s/it]                                                    {'loss': 2.746, 'grad_norm': 1.7402395009994507, 'learning_rate': 4.335593220338983e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 884/6000 [41:15<3:54:52,  2.75s/it] 15%|â–ˆâ–        | 885/6000 [41:18<3:54:42,  2.75s/it]                                                    {'loss': 2.772, 'grad_norm': 1.7668428421020508, 'learning_rate': 4.334745762711865e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 885/6000 [41:18<3:54:42,  2.75s/it] 15%|â–ˆâ–        | 886/6000 [41:20<3:53:42,  2.74s/it]                                                    {'loss': 2.7046, 'grad_norm': 4.330704212188721, 'learning_rate': 4.333898305084746e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 886/6000 [41:20<3:53:42,  2.74s/it] 15%|â–ˆâ–        | 887/6000 [41:23<3:54:38,  2.75s/it]                                                    {'loss': 2.7286, 'grad_norm': 4.541859149932861, 'learning_rate': 4.3330508474576273e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 887/6000 [41:23<3:54:38,  2.75s/it] 15%|â–ˆâ–        | 888/6000 [41:26<3:55:19,  2.76s/it]                                                    {'loss': 2.8366, 'grad_norm': 3.344250440597534, 'learning_rate': 4.3322033898305085e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 888/6000 [41:26<3:55:19,  2.76s/it] 15%|â–ˆâ–        | 889/6000 [41:29<3:52:47,  2.73s/it]                                                    {'loss': 2.758, 'grad_norm': 2.4441351890563965, 'learning_rate': 4.33135593220339e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 889/6000 [41:29<3:52:47,  2.73s/it] 15%|â–ˆâ–        | 890/6000 [41:31<3:51:48,  2.72s/it]                                                    {'loss': 2.769, 'grad_norm': 2.789372444152832, 'learning_rate': 4.3305084745762714e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 890/6000 [41:31<3:51:48,  2.72s/it] 15%|â–ˆâ–        | 891/6000 [41:34<3:49:18,  2.69s/it]                                                    {'loss': 2.7999, 'grad_norm': 3.0357298851013184, 'learning_rate': 4.3296610169491525e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 891/6000 [41:34<3:49:18,  2.69s/it] 15%|â–ˆâ–        | 892/6000 [41:37<3:48:07,  2.68s/it]                                                    {'loss': 2.7614, 'grad_norm': 2.3895211219787598, 'learning_rate': 4.3288135593220343e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 892/6000 [41:37<3:48:07,  2.68s/it] 15%|â–ˆâ–        | 893/6000 [41:39<3:48:53,  2.69s/it]                                                    {'loss': 2.7581, 'grad_norm': 3.7338993549346924, 'learning_rate': 4.3279661016949155e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 893/6000 [41:39<3:48:53,  2.69s/it] 15%|â–ˆâ–        | 894/6000 [41:42<3:51:19,  2.72s/it]                                                    {'loss': 2.753, 'grad_norm': 2.5923876762390137, 'learning_rate': 4.3271186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 894/6000 [41:42<3:51:19,  2.72s/it] 15%|â–ˆâ–        | 895/6000 [41:45<3:50:32,  2.71s/it]                                                    {'loss': 2.7423, 'grad_norm': 2.1661434173583984, 'learning_rate': 4.326271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 895/6000 [41:45<3:50:32,  2.71s/it] 15%|â–ˆâ–        | 896/6000 [41:47<3:48:59,  2.69s/it]                                                    {'loss': 2.7153, 'grad_norm': 3.578885316848755, 'learning_rate': 4.3254237288135595e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 896/6000 [41:48<3:48:59,  2.69s/it] 15%|â–ˆâ–        | 897/6000 [41:50<3:49:56,  2.70s/it]                                                    {'loss': 2.6806, 'grad_norm': 3.090198278427124, 'learning_rate': 4.3245762711864407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 897/6000 [41:50<3:49:56,  2.70s/it] 15%|â–ˆâ–        | 898/6000 [41:53<3:48:44,  2.69s/it]                                                    {'loss': 2.7697, 'grad_norm': 3.334792137145996, 'learning_rate': 4.3237288135593225e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 898/6000 [41:53<3:48:44,  2.69s/it] 15%|â–ˆâ–        | 899/6000 [41:56<4:09:24,  2.93s/it]                                                    {'loss': 2.7465, 'grad_norm': 4.360837936401367, 'learning_rate': 4.3228813559322036e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 899/6000 [41:56<4:09:24,  2.93s/it] 15%|â–ˆâ–Œ        | 900/6000 [41:59<4:05:03,  2.88s/it]                                                    {'loss': 2.8959, 'grad_norm': 4.451846599578857, 'learning_rate': 4.3220338983050854e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 900/6000 [41:59<4:05:03,  2.88s/it][2025-10-20 23:47:50,424] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-900
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|â–ˆâ–Œ        | 901/6000 [42:04<4:58:27,  3.51s/it]                                                    {'loss': 2.7687, 'grad_norm': 2.6315388679504395, 'learning_rate': 4.321186440677966e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 901/6000 [42:04<4:58:27,  3.51s/it] 15%|â–ˆâ–Œ        | 902/6000 [42:07<4:35:28,  3.24s/it]                                                    {'loss': 2.7379, 'grad_norm': 2.2076523303985596, 'learning_rate': 4.3203389830508477e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 902/6000 [42:07<4:35:28,  3.24s/it] 15%|â–ˆâ–Œ        | 903/6000 [42:09<4:21:34,  3.08s/it]                                                    {'loss': 2.7125, 'grad_norm': 3.0109944343566895, 'learning_rate': 4.319491525423729e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 903/6000 [42:09<4:21:34,  3.08s/it] 15%|â–ˆâ–Œ        | 904/6000 [42:12<4:10:45,  2.95s/it]                                                    {'loss': 2.9167, 'grad_norm': 3.7508270740509033, 'learning_rate': 4.3186440677966106e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 904/6000 [42:12<4:10:45,  2.95s/it] 15%|â–ˆâ–Œ        | 905/6000 [42:15<4:18:44,  3.05s/it]                                                    {'loss': 2.7762, 'grad_norm': 2.74371600151062, 'learning_rate': 4.317796610169492e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 905/6000 [42:15<4:18:44,  3.05s/it] 15%|â–ˆâ–Œ        | 906/6000 [42:18<4:13:13,  2.98s/it]                                                    {'loss': 2.7088, 'grad_norm': 3.4105470180511475, 'learning_rate': 4.3169491525423735e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 906/6000 [42:18<4:13:13,  2.98s/it] 15%|â–ˆâ–Œ        | 907/6000 [42:21<4:15:28,  3.01s/it]                                                    {'loss': 2.8131, 'grad_norm': 2.6137914657592773, 'learning_rate': 4.3161016949152547e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 907/6000 [42:21<4:15:28,  3.01s/it] 15%|â–ˆâ–Œ        | 908/6000 [42:24<4:15:10,  3.01s/it]                                                    {'loss': 2.7661, 'grad_norm': 2.6557862758636475, 'learning_rate': 4.315254237288136e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 908/6000 [42:24<4:15:10,  3.01s/it] 15%|â–ˆâ–Œ        | 909/6000 [42:27<4:06:08,  2.90s/it]                                                    {'loss': 2.7571, 'grad_norm': 2.8674476146698, 'learning_rate': 4.314406779661017e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 909/6000 [42:27<4:06:08,  2.90s/it] 15%|â–ˆâ–Œ        | 910/6000 [42:30<3:58:41,  2.81s/it]                                                    {'loss': 2.7384, 'grad_norm': 2.3021342754364014, 'learning_rate': 4.313559322033899e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 910/6000 [42:30<3:58:41,  2.81s/it] 15%|â–ˆâ–Œ        | 911/6000 [42:32<3:57:13,  2.80s/it]                                                    {'loss': 2.7672, 'grad_norm': 3.0860085487365723, 'learning_rate': 4.31271186440678e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 911/6000 [42:32<3:57:13,  2.80s/it] 15%|â–ˆâ–Œ        | 912/6000 [42:35<3:53:18,  2.75s/it]                                                    {'loss': 2.8107, 'grad_norm': 3.8126890659332275, 'learning_rate': 4.311864406779661e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 912/6000 [42:35<3:53:18,  2.75s/it] 15%|â–ˆâ–Œ        | 913/6000 [42:38<3:50:38,  2.72s/it]                                                    {'loss': 2.738, 'grad_norm': 2.400973081588745, 'learning_rate': 4.311016949152543e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 913/6000 [42:38<3:50:38,  2.72s/it] 15%|â–ˆâ–Œ        | 914/6000 [42:41<4:00:57,  2.84s/it]                                                    {'loss': 2.8406, 'grad_norm': 3.836015224456787, 'learning_rate': 4.310169491525424e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 914/6000 [42:41<4:00:57,  2.84s/it] 15%|â–ˆâ–Œ        | 915/6000 [42:44<4:19:56,  3.07s/it]                                                    {'loss': 2.7902, 'grad_norm': 2.5559377670288086, 'learning_rate': 4.309322033898305e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 915/6000 [42:44<4:19:56,  3.07s/it] 15%|â–ˆâ–Œ        | 916/6000 [42:47<4:09:06,  2.94s/it]                                                    {'loss': 2.8022, 'grad_norm': 1.7566299438476562, 'learning_rate': 4.308474576271186e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 916/6000 [42:47<4:09:06,  2.94s/it] 15%|â–ˆâ–Œ        | 917/6000 [42:50<4:02:49,  2.87s/it]                                                    {'loss': 2.7636, 'grad_norm': 1.5475143194198608, 'learning_rate': 4.307627118644068e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 917/6000 [42:50<4:02:49,  2.87s/it] 15%|â–ˆâ–Œ        | 918/6000 [42:52<3:58:56,  2.82s/it]                                                    {'loss': 2.7829, 'grad_norm': 1.585524320602417, 'learning_rate': 4.306779661016949e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 918/6000 [42:52<3:58:56,  2.82s/it] 15%|â–ˆâ–Œ        | 919/6000 [42:55<3:55:43,  2.78s/it]                                                    {'loss': 2.8299, 'grad_norm': 1.3789490461349487, 'learning_rate': 4.305932203389831e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 919/6000 [42:55<3:55:43,  2.78s/it] 15%|â–ˆâ–Œ        | 920/6000 [42:58<3:59:21,  2.83s/it]                                                    {'loss': 2.7814, 'grad_norm': 1.1107295751571655, 'learning_rate': 4.305084745762712e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 920/6000 [42:58<3:59:21,  2.83s/it] 15%|â–ˆâ–Œ        | 921/6000 [43:01<3:55:34,  2.78s/it]                                                    {'loss': 2.7634, 'grad_norm': 1.32789146900177, 'learning_rate': 4.304237288135594e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 921/6000 [43:01<3:55:34,  2.78s/it] 15%|â–ˆâ–Œ        | 922/6000 [43:03<3:52:23,  2.75s/it]                                                    {'loss': 2.7408, 'grad_norm': 2.224020481109619, 'learning_rate': 4.303389830508475e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 922/6000 [43:03<3:52:23,  2.75s/it] 15%|â–ˆâ–Œ        | 923/6000 [43:06<3:50:37,  2.73s/it]                                                    {'loss': 2.7929, 'grad_norm': 1.434166669845581, 'learning_rate': 4.302542372881356e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 923/6000 [43:06<3:50:37,  2.73s/it] 15%|â–ˆâ–Œ        | 924/6000 [43:09<3:47:21,  2.69s/it]                                                    {'loss': 2.8152, 'grad_norm': 2.4900221824645996, 'learning_rate': 4.301694915254237e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 924/6000 [43:09<3:47:21,  2.69s/it] 15%|â–ˆâ–Œ        | 925/6000 [43:11<3:49:19,  2.71s/it]                                                    {'loss': 2.788, 'grad_norm': 1.8051284551620483, 'learning_rate': 4.300847457627119e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 925/6000 [43:11<3:49:19,  2.71s/it] 15%|â–ˆâ–Œ        | 926/6000 [43:14<3:52:04,  2.74s/it]                                                    {'loss': 2.8273, 'grad_norm': 4.719217300415039, 'learning_rate': 4.3e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 926/6000 [43:14<3:52:04,  2.74s/it] 15%|â–ˆâ–Œ        | 927/6000 [43:17<3:49:36,  2.72s/it]                                                    {'loss': 2.7582, 'grad_norm': 1.4364372491836548, 'learning_rate': 4.299152542372882e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 927/6000 [43:17<3:49:36,  2.72s/it] 15%|â–ˆâ–Œ        | 928/6000 [43:20<3:57:37,  2.81s/it]                                                    {'loss': 2.787, 'grad_norm': 1.4218014478683472, 'learning_rate': 4.298305084745763e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 928/6000 [43:20<3:57:37,  2.81s/it] 15%|â–ˆâ–Œ        | 929/6000 [43:23<3:55:20,  2.78s/it]                                                    {'loss': 2.7469, 'grad_norm': 2.182408332824707, 'learning_rate': 4.297457627118644e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 929/6000 [43:23<3:55:20,  2.78s/it] 16%|â–ˆâ–Œ        | 930/6000 [43:25<3:52:54,  2.76s/it]                                                    {'loss': 2.7835, 'grad_norm': 2.3052449226379395, 'learning_rate': 4.2966101694915254e-05, 'epoch': 0.15}
 16%|â–ˆâ–Œ        | 930/6000 [43:25<3:52:54,  2.76s/it] 16%|â–ˆâ–Œ        | 931/6000 [43:28<3:51:13,  2.74s/it]                                                    {'loss': 2.7772, 'grad_norm': 2.161508083343506, 'learning_rate': 4.2957627118644065e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 931/6000 [43:28<3:51:13,  2.74s/it] 16%|â–ˆâ–Œ        | 932/6000 [43:31<3:48:41,  2.71s/it]                                                    {'loss': 2.7476, 'grad_norm': 1.7931888103485107, 'learning_rate': 4.294915254237288e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 932/6000 [43:31<3:48:41,  2.71s/it] 16%|â–ˆâ–Œ        | 933/6000 [43:33<3:48:12,  2.70s/it]                                                    {'loss': 2.7689, 'grad_norm': 1.3552544116973877, 'learning_rate': 4.2940677966101694e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 933/6000 [43:33<3:48:12,  2.70s/it] 16%|â–ˆâ–Œ        | 934/6000 [43:36<3:57:29,  2.81s/it]                                                    {'loss': 2.7497, 'grad_norm': 1.8738470077514648, 'learning_rate': 4.293220338983051e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 934/6000 [43:36<3:57:29,  2.81s/it] 16%|â–ˆâ–Œ        | 935/6000 [43:39<3:52:40,  2.76s/it]                                                    {'loss': 2.8031, 'grad_norm': 2.558290719985962, 'learning_rate': 4.2923728813559324e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 935/6000 [43:39<3:52:40,  2.76s/it] 16%|â–ˆâ–Œ        | 936/6000 [43:42<3:50:01,  2.73s/it]                                                    {'loss': 2.8249, 'grad_norm': 2.071434736251831, 'learning_rate': 4.291525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 936/6000 [43:42<3:50:01,  2.73s/it] 16%|â–ˆâ–Œ        | 937/6000 [43:44<3:50:02,  2.73s/it]                                                    {'loss': 2.8179, 'grad_norm': 1.8917229175567627, 'learning_rate': 4.2906779661016946e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 937/6000 [43:44<3:50:02,  2.73s/it] 16%|â–ˆâ–Œ        | 938/6000 [43:47<3:48:27,  2.71s/it]                                                    {'loss': 2.7302, 'grad_norm': 8.935487747192383, 'learning_rate': 4.2898305084745764e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 938/6000 [43:47<3:48:27,  2.71s/it] 16%|â–ˆâ–Œ        | 939/6000 [43:50<3:48:29,  2.71s/it]                                                    {'loss': 2.8186, 'grad_norm': 4.403163433074951, 'learning_rate': 4.2889830508474575e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 939/6000 [43:50<3:48:29,  2.71s/it] 16%|â–ˆâ–Œ        | 940/6000 [43:52<3:48:30,  2.71s/it]                                                    {'loss': 2.7538, 'grad_norm': 2.569796323776245, 'learning_rate': 4.2881355932203394e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 940/6000 [43:52<3:48:30,  2.71s/it] 16%|â–ˆâ–Œ        | 941/6000 [43:56<4:01:21,  2.86s/it]                                                    {'loss': 2.8263, 'grad_norm': 2.066138982772827, 'learning_rate': 4.2872881355932205e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 941/6000 [43:56<4:01:21,  2.86s/it] 16%|â–ˆâ–Œ        | 942/6000 [43:58<3:56:52,  2.81s/it]                                                    {'loss': 2.7708, 'grad_norm': 2.239795446395874, 'learning_rate': 4.286440677966102e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 942/6000 [43:58<3:56:52,  2.81s/it] 16%|â–ˆâ–Œ        | 943/6000 [44:01<3:53:10,  2.77s/it]                                                    {'loss': 2.7804, 'grad_norm': 1.5446909666061401, 'learning_rate': 4.2855932203389834e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 943/6000 [44:01<3:53:10,  2.77s/it] 16%|â–ˆâ–Œ        | 944/6000 [44:04<3:49:45,  2.73s/it]                                                    {'loss': 2.7462, 'grad_norm': 1.0568785667419434, 'learning_rate': 4.2847457627118645e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 944/6000 [44:04<3:49:45,  2.73s/it] 16%|â–ˆâ–Œ        | 945/6000 [44:07<3:55:47,  2.80s/it]                                                    {'loss': 2.8287, 'grad_norm': 1.0613296031951904, 'learning_rate': 4.283898305084746e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 945/6000 [44:07<3:55:47,  2.80s/it] 16%|â–ˆâ–Œ        | 946/6000 [44:09<3:53:00,  2.77s/it]                                                    {'loss': 2.7568, 'grad_norm': 0.8857444524765015, 'learning_rate': 4.2830508474576275e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 946/6000 [44:09<3:53:00,  2.77s/it] 16%|â–ˆâ–Œ        | 947/6000 [44:12<3:51:57,  2.75s/it]                                                    {'loss': 2.7569, 'grad_norm': 1.0306684970855713, 'learning_rate': 4.2822033898305086e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 947/6000 [44:12<3:51:57,  2.75s/it] 16%|â–ˆâ–Œ        | 948/6000 [44:15<3:52:48,  2.76s/it]                                                    {'loss': 2.7768, 'grad_norm': 0.9029603004455566, 'learning_rate': 4.2813559322033904e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 948/6000 [44:15<3:52:48,  2.76s/it] 16%|â–ˆâ–Œ        | 949/6000 [44:18<4:01:07,  2.86s/it]                                                    {'loss': 2.7679, 'grad_norm': 1.0162166357040405, 'learning_rate': 4.2805084745762715e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 949/6000 [44:18<4:01:07,  2.86s/it] 16%|â–ˆâ–Œ        | 950/6000 [44:21<4:01:17,  2.87s/it]                                                    {'loss': 2.7773, 'grad_norm': 1.119724988937378, 'learning_rate': 4.279661016949153e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 950/6000 [44:21<4:01:17,  2.87s/it][2025-10-20 23:50:12,093] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-950
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 16%|â–ˆâ–Œ        | 951/6000 [44:27<5:18:26,  3.78s/it]                                                    {'loss': 2.7714, 'grad_norm': 0.8824267387390137, 'learning_rate': 4.278813559322034e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 951/6000 [44:27<5:18:26,  3.78s/it] 16%|â–ˆâ–Œ        | 952/6000 [44:29<4:49:48,  3.44s/it]                                                    {'loss': 2.746, 'grad_norm': 1.2615549564361572, 'learning_rate': 4.277966101694915e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 952/6000 [44:29<4:49:48,  3.44s/it] 16%|â–ˆâ–Œ        | 953/6000 [44:32<4:32:23,  3.24s/it]                                                    {'loss': 2.7752, 'grad_norm': 1.270470142364502, 'learning_rate': 4.277118644067797e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 953/6000 [44:32<4:32:23,  3.24s/it] 16%|â–ˆâ–Œ        | 954/6000 [44:35<4:18:42,  3.08s/it]                                                    {'loss': 2.7895, 'grad_norm': 1.0573760271072388, 'learning_rate': 4.276271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 954/6000 [44:35<4:18:42,  3.08s/it] 16%|â–ˆâ–Œ        | 955/6000 [44:38<4:09:51,  2.97s/it]                                                    {'loss': 2.8226, 'grad_norm': 1.6016089916229248, 'learning_rate': 4.27542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 955/6000 [44:38<4:09:51,  2.97s/it] 16%|â–ˆâ–Œ        | 956/6000 [44:40<4:06:17,  2.93s/it]                                                    {'loss': 2.7464, 'grad_norm': 1.3500016927719116, 'learning_rate': 4.274576271186441e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 956/6000 [44:40<4:06:17,  2.93s/it] 16%|â–ˆâ–Œ        | 957/6000 [44:43<3:58:27,  2.84s/it]                                                    {'loss': 2.7489, 'grad_norm': 1.456146240234375, 'learning_rate': 4.2737288135593226e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 957/6000 [44:43<3:58:27,  2.84s/it] 16%|â–ˆâ–Œ        | 958/6000 [44:46<3:57:47,  2.83s/it]                                                    {'loss': 2.8177, 'grad_norm': 1.3455942869186401, 'learning_rate': 4.272881355932204e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 958/6000 [44:46<3:57:47,  2.83s/it] 16%|â–ˆâ–Œ        | 959/6000 [44:48<3:52:16,  2.76s/it]                                                    {'loss': 2.772, 'grad_norm': 1.2477610111236572, 'learning_rate': 4.272033898305085e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 959/6000 [44:48<3:52:16,  2.76s/it] 16%|â–ˆâ–Œ        | 960/6000 [44:51<3:50:55,  2.75s/it]                                                    {'loss': 2.791, 'grad_norm': 1.4769752025604248, 'learning_rate': 4.271186440677966e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 960/6000 [44:51<3:50:55,  2.75s/it] 16%|â–ˆâ–Œ        | 961/6000 [44:54<3:50:42,  2.75s/it]                                                    {'loss': 2.9433, 'grad_norm': 1.5776594877243042, 'learning_rate': 4.270338983050848e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 961/6000 [44:54<3:50:42,  2.75s/it] 16%|â–ˆâ–Œ        | 962/6000 [44:57<3:58:03,  2.84s/it]                                                    {'loss': 2.7516, 'grad_norm': 2.233550786972046, 'learning_rate': 4.269491525423729e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 962/6000 [44:57<3:58:03,  2.84s/it] 16%|â–ˆâ–Œ        | 963/6000 [45:00<3:53:06,  2.78s/it]                                                    {'loss': 2.8524, 'grad_norm': 1.5996426343917847, 'learning_rate': 4.268644067796611e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 963/6000 [45:00<3:53:06,  2.78s/it] 16%|â–ˆâ–Œ        | 964/6000 [45:02<3:49:38,  2.74s/it]                                                    {'loss': 2.7863, 'grad_norm': 1.3001408576965332, 'learning_rate': 4.267796610169492e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 964/6000 [45:02<3:49:38,  2.74s/it] 16%|â–ˆâ–Œ        | 965/6000 [45:05<3:50:48,  2.75s/it]                                                    {'loss': 2.7217, 'grad_norm': 2.474839210510254, 'learning_rate': 4.266949152542373e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 965/6000 [45:05<3:50:48,  2.75s/it] 16%|â–ˆâ–Œ        | 966/6000 [45:08<3:51:03,  2.75s/it]                                                    {'loss': 2.7742, 'grad_norm': 1.5849703550338745, 'learning_rate': 4.266101694915254e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 966/6000 [45:08<3:51:03,  2.75s/it] 16%|â–ˆâ–Œ        | 967/6000 [45:11<3:50:35,  2.75s/it]                                                    {'loss': 2.7295, 'grad_norm': 1.8569021224975586, 'learning_rate': 4.265254237288136e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 967/6000 [45:11<3:50:35,  2.75s/it] 16%|â–ˆâ–Œ        | 968/6000 [45:14<3:58:51,  2.85s/it]                                                    {'loss': 2.8135, 'grad_norm': 2.5854122638702393, 'learning_rate': 4.264406779661017e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 968/6000 [45:14<3:58:51,  2.85s/it] 16%|â–ˆâ–Œ        | 969/6000 [45:16<3:56:39,  2.82s/it]                                                    {'loss': 2.689, 'grad_norm': 2.3078830242156982, 'learning_rate': 4.263559322033899e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 969/6000 [45:16<3:56:39,  2.82s/it] 16%|â–ˆâ–Œ        | 970/6000 [45:19<3:56:18,  2.82s/it]                                                    {'loss': 2.8522, 'grad_norm': 5.9805402755737305, 'learning_rate': 4.26271186440678e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 970/6000 [45:19<3:56:18,  2.82s/it] 16%|â–ˆâ–Œ        | 971/6000 [45:22<3:51:11,  2.76s/it]                                                    {'loss': 2.8255, 'grad_norm': 2.563556432723999, 'learning_rate': 4.261864406779662e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 971/6000 [45:22<3:51:11,  2.76s/it] 16%|â–ˆâ–Œ        | 972/6000 [45:24<3:49:07,  2.73s/it]                                                    {'loss': 2.7611, 'grad_norm': 2.8634684085845947, 'learning_rate': 4.261016949152542e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 972/6000 [45:24<3:49:07,  2.73s/it] 16%|â–ˆâ–Œ        | 973/6000 [45:27<3:46:46,  2.71s/it]                                                    {'loss': 2.7535, 'grad_norm': 2.1851449012756348, 'learning_rate': 4.2601694915254234e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 973/6000 [45:27<3:46:46,  2.71s/it] 16%|â–ˆâ–Œ        | 974/6000 [45:30<3:45:56,  2.70s/it]                                                    {'loss': 2.9069, 'grad_norm': 4.584702014923096, 'learning_rate': 4.259322033898305e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 974/6000 [45:30<3:45:56,  2.70s/it] 16%|â–ˆâ–‹        | 975/6000 [45:32<3:44:16,  2.68s/it]                                                    {'loss': 2.7994, 'grad_norm': 1.7369979619979858, 'learning_rate': 4.258474576271186e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 975/6000 [45:32<3:44:16,  2.68s/it] 16%|â–ˆâ–‹        | 976/6000 [45:35<3:47:09,  2.71s/it]                                                    {'loss': 2.8043, 'grad_norm': 2.9884033203125, 'learning_rate': 4.257627118644068e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 976/6000 [45:35<3:47:09,  2.71s/it] 16%|â–ˆâ–‹        | 977/6000 [45:38<3:44:28,  2.68s/it]                                                    {'loss': 2.8178, 'grad_norm': 1.3203181028366089, 'learning_rate': 4.256779661016949e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 977/6000 [45:38<3:44:28,  2.68s/it] 16%|â–ˆâ–‹        | 978/6000 [45:40<3:42:16,  2.66s/it]                                                    {'loss': 2.755, 'grad_norm': 1.544170618057251, 'learning_rate': 4.255932203389831e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 978/6000 [45:40<3:42:16,  2.66s/it] 16%|â–ˆâ–‹        | 979/6000 [45:43<3:41:47,  2.65s/it]                                                    {'loss': 2.7269, 'grad_norm': 2.609434127807617, 'learning_rate': 4.255084745762712e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 979/6000 [45:43<3:41:47,  2.65s/it] 16%|â–ˆâ–‹        | 980/6000 [45:46<3:43:54,  2.68s/it]                                                    {'loss': 2.7938, 'grad_norm': 2.559687376022339, 'learning_rate': 4.254237288135593e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 980/6000 [45:46<3:43:54,  2.68s/it] 16%|â–ˆâ–‹        | 981/6000 [45:48<3:42:28,  2.66s/it]                                                    {'loss': 2.7633, 'grad_norm': 2.9545533657073975, 'learning_rate': 4.2533898305084744e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 981/6000 [45:48<3:42:28,  2.66s/it] 16%|â–ˆâ–‹        | 982/6000 [45:51<3:43:11,  2.67s/it]                                                    {'loss': 2.7349, 'grad_norm': 3.0154314041137695, 'learning_rate': 4.252542372881356e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 982/6000 [45:51<3:43:11,  2.67s/it] 16%|â–ˆâ–‹        | 983/6000 [45:54<3:43:45,  2.68s/it]                                                    {'loss': 2.7827, 'grad_norm': 1.8054916858673096, 'learning_rate': 4.2516949152542374e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 983/6000 [45:54<3:43:45,  2.68s/it] 16%|â–ˆâ–‹        | 984/6000 [45:56<3:43:43,  2.68s/it]                                                    {'loss': 2.7628, 'grad_norm': 1.9101264476776123, 'learning_rate': 4.250847457627119e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 984/6000 [45:56<3:43:43,  2.68s/it] 16%|â–ˆâ–‹        | 985/6000 [45:59<3:46:33,  2.71s/it]                                                    {'loss': 2.7423, 'grad_norm': 1.986230731010437, 'learning_rate': 4.25e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 985/6000 [45:59<3:46:33,  2.71s/it] 16%|â–ˆâ–‹        | 986/6000 [46:02<3:44:14,  2.68s/it]                                                    {'loss': 2.7391, 'grad_norm': 2.2648632526397705, 'learning_rate': 4.2491525423728814e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 986/6000 [46:02<3:44:14,  2.68s/it] 16%|â–ˆâ–‹        | 987/6000 [46:05<3:48:15,  2.73s/it]                                                    {'loss': 2.6942, 'grad_norm': 2.733091115951538, 'learning_rate': 4.2483050847457626e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 987/6000 [46:05<3:48:15,  2.73s/it] 16%|â–ˆâ–‹        | 988/6000 [46:07<3:47:03,  2.72s/it]                                                    {'loss': 2.74, 'grad_norm': 2.4254512786865234, 'learning_rate': 4.2474576271186444e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 988/6000 [46:07<3:47:03,  2.72s/it] 16%|â–ˆâ–‹        | 989/6000 [46:10<3:46:05,  2.71s/it]                                                    {'loss': 2.8389, 'grad_norm': 4.424947261810303, 'learning_rate': 4.2466101694915255e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 989/6000 [46:10<3:46:05,  2.71s/it] 16%|â–ˆâ–‹        | 990/6000 [46:13<3:45:46,  2.70s/it]                                                    {'loss': 2.8752, 'grad_norm': 5.966546535491943, 'learning_rate': 4.245762711864407e-05, 'epoch': 0.17}
 16%|â–ˆâ–‹        | 990/6000 [46:13<3:45:46,  2.70s/it] 17%|â–ˆâ–‹        | 991/6000 [46:16<3:57:53,  2.85s/it]                                                    {'loss': 2.7733, 'grad_norm': 3.388148307800293, 'learning_rate': 4.2449152542372884e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 991/6000 [46:16<3:57:53,  2.85s/it] 17%|â–ˆâ–‹        | 992/6000 [46:19<3:52:22,  2.78s/it]                                                    {'loss': 2.7914, 'grad_norm': 4.9482526779174805, 'learning_rate': 4.24406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 992/6000 [46:19<3:52:22,  2.78s/it] 17%|â–ˆâ–‹        | 993/6000 [46:21<3:51:36,  2.78s/it]                                                    {'loss': 2.8243, 'grad_norm': 4.009250640869141, 'learning_rate': 4.2432203389830514e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 993/6000 [46:21<3:51:36,  2.78s/it] 17%|â–ˆâ–‹        | 994/6000 [46:24<3:52:10,  2.78s/it]                                                    {'loss': 2.7294, 'grad_norm': 6.329092025756836, 'learning_rate': 4.242372881355932e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 994/6000 [46:24<3:52:10,  2.78s/it] 17%|â–ˆâ–‹        | 995/6000 [46:27<3:48:36,  2.74s/it]                                                    {'loss': 2.7526, 'grad_norm': 2.5669751167297363, 'learning_rate': 4.2415254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 995/6000 [46:27<3:48:36,  2.74s/it] 17%|â–ˆâ–‹        | 996/6000 [46:30<3:48:01,  2.73s/it]                                                    {'loss': 2.8398, 'grad_norm': 3.4780380725860596, 'learning_rate': 4.240677966101695e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 996/6000 [46:30<3:48:01,  2.73s/it] 17%|â–ˆâ–‹        | 997/6000 [46:33<3:54:13,  2.81s/it]                                                    {'loss': 2.7578, 'grad_norm': 2.3769795894622803, 'learning_rate': 4.2398305084745766e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 997/6000 [46:33<3:54:13,  2.81s/it] 17%|â–ˆâ–‹        | 998/6000 [46:35<3:48:49,  2.74s/it]                                                    {'loss': 2.764, 'grad_norm': 2.0602357387542725, 'learning_rate': 4.238983050847458e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 998/6000 [46:35<3:48:49,  2.74s/it] 17%|â–ˆâ–‹        | 999/6000 [46:38<3:47:01,  2.72s/it]                                                    {'loss': 2.7328, 'grad_norm': 1.589563250541687, 'learning_rate': 4.2381355932203395e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 999/6000 [46:38<3:47:01,  2.72s/it] 17%|â–ˆâ–‹        | 1000/6000 [46:41<3:47:49,  2.73s/it]                                                     {'loss': 2.8152, 'grad_norm': 2.673884391784668, 'learning_rate': 4.2372881355932206e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1000/6000 [46:41<3:47:49,  2.73s/it][2025-10-20 23:52:31,811] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1000
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 17%|â–ˆâ–‹        | 1001/6000 [46:45<4:34:55,  3.30s/it]                                                     {'loss': 2.7516, 'grad_norm': 1.4627416133880615, 'learning_rate': 4.236440677966102e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1001/6000 [46:45<4:34:55,  3.30s/it] 17%|â–ˆâ–‹        | 1002/6000 [46:48<4:18:40,  3.11s/it]                                                     {'loss': 2.827, 'grad_norm': 1.6701128482818604, 'learning_rate': 4.235593220338983e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1002/6000 [46:48<4:18:40,  3.11s/it] 17%|â–ˆâ–‹        | 1003/6000 [46:50<4:06:06,  2.96s/it]                                                     {'loss': 2.7735, 'grad_norm': 0.9793943166732788, 'learning_rate': 4.234745762711865e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1003/6000 [46:50<4:06:06,  2.96s/it] 17%|â–ˆâ–‹        | 1004/6000 [46:53<3:57:15,  2.85s/it]                                                     {'loss': 2.784, 'grad_norm': 1.0162606239318848, 'learning_rate': 4.233898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1004/6000 [46:53<3:57:15,  2.85s/it] 17%|â–ˆâ–‹        | 1005/6000 [46:56<3:53:09,  2.80s/it]                                                     {'loss': 2.7613, 'grad_norm': 2.0881810188293457, 'learning_rate': 4.2330508474576276e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1005/6000 [46:56<3:53:09,  2.80s/it] 17%|â–ˆâ–‹        | 1006/6000 [46:58<3:49:08,  2.75s/it]                                                     {'loss': 2.7677, 'grad_norm': 1.2401589155197144, 'learning_rate': 4.232203389830509e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1006/6000 [46:58<3:49:08,  2.75s/it] 17%|â–ˆâ–‹        | 1007/6000 [47:01<3:49:45,  2.76s/it]                                                     {'loss': 2.7655, 'grad_norm': 0.9656910300254822, 'learning_rate': 4.23135593220339e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1007/6000 [47:01<3:49:45,  2.76s/it] 17%|â–ˆâ–‹        | 1008/6000 [47:04<3:48:34,  2.75s/it]                                                     {'loss': 2.7648, 'grad_norm': 1.0400959253311157, 'learning_rate': 4.230508474576271e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1008/6000 [47:04<3:48:34,  2.75s/it] 17%|â–ˆâ–‹        | 1009/6000 [47:07<3:46:58,  2.73s/it]                                                     {'loss': 2.7806, 'grad_norm': 1.03208589553833, 'learning_rate': 4.229661016949153e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1009/6000 [47:07<3:46:58,  2.73s/it] 17%|â–ˆâ–‹        | 1010/6000 [47:09<3:43:27,  2.69s/it]                                                     {'loss': 2.7734, 'grad_norm': 0.9242509007453918, 'learning_rate': 4.228813559322034e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1010/6000 [47:09<3:43:27,  2.69s/it] 17%|â–ˆâ–‹        | 1011/6000 [47:12<3:43:17,  2.69s/it]                                                     {'loss': 2.7719, 'grad_norm': 0.9888632297515869, 'learning_rate': 4.227966101694916e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1011/6000 [47:12<3:43:17,  2.69s/it] 17%|â–ˆâ–‹        | 1012/6000 [47:15<3:46:00,  2.72s/it]                                                     {'loss': 2.8364, 'grad_norm': 1.0888197422027588, 'learning_rate': 4.227118644067797e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1012/6000 [47:15<3:46:00,  2.72s/it] 17%|â–ˆâ–‹        | 1013/6000 [47:17<3:49:55,  2.77s/it]                                                     {'loss': 2.7473, 'grad_norm': 1.3072509765625, 'learning_rate': 4.226271186440679e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1013/6000 [47:17<3:49:55,  2.77s/it] 17%|â–ˆâ–‹        | 1014/6000 [47:20<3:45:10,  2.71s/it]                                                     {'loss': 2.7477, 'grad_norm': 1.396823525428772, 'learning_rate': 4.22542372881356e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1014/6000 [47:20<3:45:10,  2.71s/it] 17%|â–ˆâ–‹        | 1015/6000 [47:23<3:45:26,  2.71s/it]                                                     {'loss': 2.7917, 'grad_norm': 1.2183489799499512, 'learning_rate': 4.224576271186441e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1015/6000 [47:23<3:45:26,  2.71s/it] 17%|â–ˆâ–‹        | 1016/6000 [47:25<3:44:51,  2.71s/it]                                                     {'loss': 2.835, 'grad_norm': 1.5182379484176636, 'learning_rate': 4.223728813559322e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1016/6000 [47:25<3:44:51,  2.71s/it] 17%|â–ˆâ–‹        | 1017/6000 [47:28<3:46:10,  2.72s/it]                                                     {'loss': 2.7789, 'grad_norm': 1.578152060508728, 'learning_rate': 4.222881355932203e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1017/6000 [47:28<3:46:10,  2.72s/it] 17%|â–ˆâ–‹        | 1018/6000 [47:31<3:46:01,  2.72s/it]                                                     {'loss': 2.7627, 'grad_norm': 1.589817762374878, 'learning_rate': 4.222033898305085e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1018/6000 [47:31<3:46:01,  2.72s/it] 17%|â–ˆâ–‹        | 1019/6000 [47:34<3:44:42,  2.71s/it]                                                     {'loss': 2.7889, 'grad_norm': 1.3644487857818604, 'learning_rate': 4.221186440677966e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1019/6000 [47:34<3:44:42,  2.71s/it] 17%|â–ˆâ–‹        | 1020/6000 [47:36<3:45:01,  2.71s/it]                                                     {'loss': 2.7626, 'grad_norm': 1.2396951913833618, 'learning_rate': 4.220338983050848e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1020/6000 [47:36<3:45:01,  2.71s/it] 17%|â–ˆâ–‹        | 1021/6000 [47:39<3:45:26,  2.72s/it]                                                     {'loss': 2.7952, 'grad_norm': 1.4730256795883179, 'learning_rate': 4.219491525423729e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1021/6000 [47:39<3:45:26,  2.72s/it] 17%|â–ˆâ–‹        | 1022/6000 [47:42<3:47:16,  2.74s/it]                                                     {'loss': 2.7607, 'grad_norm': 1.3453351259231567, 'learning_rate': 4.21864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1022/6000 [47:42<3:47:16,  2.74s/it] 17%|â–ˆâ–‹        | 1023/6000 [47:45<3:45:09,  2.71s/it]                                                     {'loss': 2.7899, 'grad_norm': 1.2366968393325806, 'learning_rate': 4.217796610169491e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1023/6000 [47:45<3:45:09,  2.71s/it] 17%|â–ˆâ–‹        | 1024/6000 [47:47<3:43:08,  2.69s/it]                                                     {'loss': 2.7492, 'grad_norm': 1.274129867553711, 'learning_rate': 4.216949152542373e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1024/6000 [47:47<3:43:08,  2.69s/it] 17%|â–ˆâ–‹        | 1025/6000 [47:50<3:41:38,  2.67s/it]                                                     {'loss': 2.7882, 'grad_norm': 1.4551620483398438, 'learning_rate': 4.216101694915254e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1025/6000 [47:50<3:41:38,  2.67s/it] 17%|â–ˆâ–‹        | 1026/6000 [47:52<3:41:33,  2.67s/it]                                                     {'loss': 2.7579, 'grad_norm': 1.1947970390319824, 'learning_rate': 4.215254237288136e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1026/6000 [47:52<3:41:33,  2.67s/it] 17%|â–ˆâ–‹        | 1027/6000 [47:55<3:42:48,  2.69s/it]                                                     {'loss': 2.7221, 'grad_norm': 1.5295169353485107, 'learning_rate': 4.214406779661017e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1027/6000 [47:55<3:42:48,  2.69s/it] 17%|â–ˆâ–‹        | 1028/6000 [47:58<3:41:44,  2.68s/it]                                                     {'loss': 2.7679, 'grad_norm': 1.270412802696228, 'learning_rate': 4.213559322033899e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1028/6000 [47:58<3:41:44,  2.68s/it] 17%|â–ˆâ–‹        | 1029/6000 [48:00<3:41:09,  2.67s/it]                                                     {'loss': 2.7793, 'grad_norm': 1.6188474893569946, 'learning_rate': 4.2127118644067795e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1029/6000 [48:00<3:41:09,  2.67s/it] 17%|â–ˆâ–‹        | 1030/6000 [48:03<3:38:50,  2.64s/it]                                                     {'loss': 2.8058, 'grad_norm': 2.2771506309509277, 'learning_rate': 4.211864406779661e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1030/6000 [48:03<3:38:50,  2.64s/it] 17%|â–ˆâ–‹        | 1031/6000 [48:06<3:38:58,  2.64s/it]                                                     {'loss': 2.9169, 'grad_norm': 3.422771692276001, 'learning_rate': 4.2110169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1031/6000 [48:06<3:38:58,  2.64s/it] 17%|â–ˆâ–‹        | 1032/6000 [48:08<3:38:53,  2.64s/it]                                                     {'loss': 2.694, 'grad_norm': 2.1810693740844727, 'learning_rate': 4.210169491525424e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1032/6000 [48:08<3:38:53,  2.64s/it] 17%|â–ˆâ–‹        | 1033/6000 [48:11<3:40:06,  2.66s/it]                                                     {'loss': 2.7009, 'grad_norm': 2.416119337081909, 'learning_rate': 4.209322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1033/6000 [48:11<3:40:06,  2.66s/it] 17%|â–ˆâ–‹        | 1034/6000 [48:14<3:41:29,  2.68s/it]                                                     {'loss': 2.7472, 'grad_norm': 2.2650859355926514, 'learning_rate': 4.208474576271187e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1034/6000 [48:14<3:41:29,  2.68s/it] 17%|â–ˆâ–‹        | 1035/6000 [48:16<3:42:33,  2.69s/it]                                                     {'loss': 2.7995, 'grad_norm': 3.099219799041748, 'learning_rate': 4.207627118644068e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1035/6000 [48:16<3:42:33,  2.69s/it] 17%|â–ˆâ–‹        | 1036/6000 [48:19<3:42:50,  2.69s/it]                                                     {'loss': 2.8401, 'grad_norm': 3.1112220287323, 'learning_rate': 4.2067796610169494e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1036/6000 [48:19<3:42:50,  2.69s/it] 17%|â–ˆâ–‹        | 1037/6000 [48:22<3:43:15,  2.70s/it]                                                     {'loss': 2.8173, 'grad_norm': 2.8696908950805664, 'learning_rate': 4.2059322033898305e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1037/6000 [48:22<3:43:15,  2.70s/it] 17%|â–ˆâ–‹        | 1038/6000 [48:25<3:51:20,  2.80s/it]                                                     {'loss': 2.8261, 'grad_norm': 2.8337581157684326, 'learning_rate': 4.2050847457627116e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1038/6000 [48:25<3:51:20,  2.80s/it] 17%|â–ˆâ–‹        | 1039/6000 [48:28<3:51:17,  2.80s/it]                                                     {'loss': 2.8301, 'grad_norm': 3.6945488452911377, 'learning_rate': 4.2042372881355934e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1039/6000 [48:28<3:51:17,  2.80s/it] 17%|â–ˆâ–‹        | 1040/6000 [48:31<3:51:56,  2.81s/it]                                                     {'loss': 2.7779, 'grad_norm': 2.462949752807617, 'learning_rate': 4.2033898305084746e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1040/6000 [48:31<3:51:56,  2.81s/it] 17%|â–ˆâ–‹        | 1041/6000 [48:33<3:48:27,  2.76s/it]                                                     {'loss': 2.7513, 'grad_norm': 4.049567222595215, 'learning_rate': 4.2025423728813564e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1041/6000 [48:33<3:48:27,  2.76s/it] 17%|â–ˆâ–‹        | 1042/6000 [48:36<3:47:13,  2.75s/it]                                                     {'loss': 2.7922, 'grad_norm': 2.105634927749634, 'learning_rate': 4.2016949152542375e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1042/6000 [48:36<3:47:13,  2.75s/it] 17%|â–ˆâ–‹        | 1043/6000 [48:39<3:44:57,  2.72s/it]                                                     {'loss': 2.8041, 'grad_norm': 3.7059075832366943, 'learning_rate': 4.2008474576271186e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1043/6000 [48:39<3:44:57,  2.72s/it] 17%|â–ˆâ–‹        | 1044/6000 [48:41<3:43:43,  2.71s/it]                                                     {'loss': 2.7877, 'grad_norm': 3.2585103511810303, 'learning_rate': 4.2e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1044/6000 [48:41<3:43:43,  2.71s/it] 17%|â–ˆâ–‹        | 1045/6000 [48:44<3:45:54,  2.74s/it]                                                     {'loss': 2.8393, 'grad_norm': 2.244410514831543, 'learning_rate': 4.1991525423728816e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1045/6000 [48:44<3:45:54,  2.74s/it] 17%|â–ˆâ–‹        | 1046/6000 [48:47<3:46:46,  2.75s/it]                                                     {'loss': 2.7941, 'grad_norm': 1.786900281906128, 'learning_rate': 4.198305084745763e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1046/6000 [48:47<3:46:46,  2.75s/it] 17%|â–ˆâ–‹        | 1047/6000 [48:50<3:55:53,  2.86s/it]                                                     {'loss': 2.8198, 'grad_norm': 1.3366515636444092, 'learning_rate': 4.1974576271186445e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1047/6000 [48:50<3:55:53,  2.86s/it] 17%|â–ˆâ–‹        | 1048/6000 [48:53<3:51:32,  2.81s/it]                                                     {'loss': 2.781, 'grad_norm': 0.8970292210578918, 'learning_rate': 4.1966101694915256e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1048/6000 [48:53<3:51:32,  2.81s/it] 17%|â–ˆâ–‹        | 1049/6000 [48:55<3:48:54,  2.77s/it]                                                     {'loss': 2.8166, 'grad_norm': 0.7422232627868652, 'learning_rate': 4.1957627118644074e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 1049/6000 [48:55<3:48:54,  2.77s/it] 18%|â–ˆâ–Š        | 1050/6000 [48:59<4:02:59,  2.95s/it]                                                     {'loss': 2.7713, 'grad_norm': 0.7829431891441345, 'learning_rate': 4.1949152542372886e-05, 'epoch': 0.17}
 18%|â–ˆâ–Š        | 1050/6000 [48:59<4:02:59,  2.95s/it][2025-10-20 23:54:49,944] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1050
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1051/6000 [49:03<4:45:47,  3.46s/it]                                                     {'loss': 2.7937, 'grad_norm': 0.6801878809928894, 'learning_rate': 4.19406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1051/6000 [49:03<4:45:47,  3.46s/it] 18%|â–ˆâ–Š        | 1052/6000 [49:06<4:27:44,  3.25s/it]                                                     {'loss': 2.7734, 'grad_norm': 0.7170343995094299, 'learning_rate': 4.193220338983051e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1052/6000 [49:06<4:27:44,  3.25s/it] 18%|â–ˆâ–Š        | 1053/6000 [49:09<4:21:02,  3.17s/it]                                                     {'loss': 2.788, 'grad_norm': 0.7797891497612, 'learning_rate': 4.1923728813559326e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1053/6000 [49:09<4:21:02,  3.17s/it] 18%|â–ˆâ–Š        | 1054/6000 [49:12<4:12:52,  3.07s/it]                                                     {'loss': 2.7704, 'grad_norm': 0.946245014667511, 'learning_rate': 4.191525423728814e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1054/6000 [49:12<4:12:52,  3.07s/it] 18%|â–ˆâ–Š        | 1055/6000 [49:15<4:02:03,  2.94s/it]                                                     {'loss': 2.7918, 'grad_norm': 0.6331969499588013, 'learning_rate': 4.1906779661016956e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1055/6000 [49:15<4:02:03,  2.94s/it] 18%|â–ˆâ–Š        | 1056/6000 [49:17<3:55:40,  2.86s/it]                                                     {'loss': 2.7646, 'grad_norm': 0.6807515621185303, 'learning_rate': 4.189830508474577e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1056/6000 [49:17<3:55:40,  2.86s/it] 18%|â–ˆâ–Š        | 1057/6000 [49:20<3:52:15,  2.82s/it]                                                     {'loss': 2.7836, 'grad_norm': 0.6068056225776672, 'learning_rate': 4.188983050847458e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1057/6000 [49:20<3:52:15,  2.82s/it] 18%|â–ˆâ–Š        | 1058/6000 [49:23<3:47:54,  2.77s/it]                                                     {'loss': 2.7819, 'grad_norm': 0.6408765912055969, 'learning_rate': 4.188135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1058/6000 [49:23<3:47:54,  2.77s/it] 18%|â–ˆâ–Š        | 1059/6000 [49:25<3:46:12,  2.75s/it]                                                     {'loss': 2.8079, 'grad_norm': 0.5761363506317139, 'learning_rate': 4.18728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1059/6000 [49:25<3:46:12,  2.75s/it] 18%|â–ˆâ–Š        | 1060/6000 [49:28<3:43:19,  2.71s/it]                                                     {'loss': 2.7861, 'grad_norm': 0.5622303485870361, 'learning_rate': 4.186440677966102e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1060/6000 [49:28<3:43:19,  2.71s/it] 18%|â–ˆâ–Š        | 1061/6000 [49:31<3:51:06,  2.81s/it]                                                     {'loss': 2.7713, 'grad_norm': 0.6443614363670349, 'learning_rate': 4.185593220338983e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1061/6000 [49:31<3:51:06,  2.81s/it] 18%|â–ˆâ–Š        | 1062/6000 [49:34<3:49:43,  2.79s/it]                                                     {'loss': 2.8149, 'grad_norm': 0.6027871370315552, 'learning_rate': 4.184745762711865e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1062/6000 [49:34<3:49:43,  2.79s/it] 18%|â–ˆâ–Š        | 1063/6000 [49:36<3:47:04,  2.76s/it]                                                     {'loss': 2.7825, 'grad_norm': 0.8173140287399292, 'learning_rate': 4.183898305084746e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1063/6000 [49:36<3:47:04,  2.76s/it] 18%|â–ˆâ–Š        | 1064/6000 [49:39<3:47:21,  2.76s/it]                                                     {'loss': 2.7759, 'grad_norm': 0.8090605139732361, 'learning_rate': 4.183050847457628e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1064/6000 [49:39<3:47:21,  2.76s/it] 18%|â–ˆâ–Š        | 1065/6000 [49:42<3:44:52,  2.73s/it]                                                     {'loss': 2.7858, 'grad_norm': 1.0587784051895142, 'learning_rate': 4.182203389830508e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1065/6000 [49:42<3:44:52,  2.73s/it] 18%|â–ˆâ–Š        | 1066/6000 [49:45<3:45:20,  2.74s/it]                                                     {'loss': 2.8116, 'grad_norm': 0.7997065186500549, 'learning_rate': 4.18135593220339e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1066/6000 [49:45<3:45:20,  2.74s/it] 18%|â–ˆâ–Š        | 1067/6000 [49:47<3:44:57,  2.74s/it]                                                     {'loss': 2.7669, 'grad_norm': 1.1118227243423462, 'learning_rate': 4.180508474576271e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1067/6000 [49:47<3:44:57,  2.74s/it] 18%|â–ˆâ–Š        | 1068/6000 [49:50<3:42:11,  2.70s/it]                                                     {'loss': 2.7883, 'grad_norm': 0.8493652939796448, 'learning_rate': 4.179661016949153e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1068/6000 [49:50<3:42:11,  2.70s/it] 18%|â–ˆâ–Š        | 1069/6000 [49:53<3:41:46,  2.70s/it]                                                     {'loss': 2.7803, 'grad_norm': 0.8078469038009644, 'learning_rate': 4.178813559322034e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1069/6000 [49:53<3:41:46,  2.70s/it] 18%|â–ˆâ–Š        | 1070/6000 [49:55<3:41:47,  2.70s/it]                                                     {'loss': 2.7771, 'grad_norm': 0.9668447375297546, 'learning_rate': 4.177966101694916e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1070/6000 [49:55<3:41:47,  2.70s/it] 18%|â–ˆâ–Š        | 1071/6000 [49:58<3:39:06,  2.67s/it]                                                     {'loss': 2.7673, 'grad_norm': 0.7381404638290405, 'learning_rate': 4.177118644067797e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1071/6000 [49:58<3:39:06,  2.67s/it] 18%|â–ˆâ–Š        | 1072/6000 [50:01<3:39:15,  2.67s/it]                                                     {'loss': 2.774, 'grad_norm': 0.8943634033203125, 'learning_rate': 4.176271186440678e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1072/6000 [50:01<3:39:15,  2.67s/it] 18%|â–ˆâ–Š        | 1073/6000 [50:03<3:40:15,  2.68s/it]                                                     {'loss': 2.7713, 'grad_norm': 1.0998705625534058, 'learning_rate': 4.175423728813559e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1073/6000 [50:03<3:40:15,  2.68s/it] 18%|â–ˆâ–Š        | 1074/6000 [50:06<3:39:59,  2.68s/it]                                                     {'loss': 2.7454, 'grad_norm': 1.067406177520752, 'learning_rate': 4.174576271186441e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1074/6000 [50:06<3:39:59,  2.68s/it] 18%|â–ˆâ–Š        | 1075/6000 [50:09<3:46:37,  2.76s/it]                                                     {'loss': 2.7769, 'grad_norm': 0.9419894814491272, 'learning_rate': 4.173728813559322e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1075/6000 [50:09<3:46:37,  2.76s/it] 18%|â–ˆâ–Š        | 1076/6000 [50:12<3:44:34,  2.74s/it]                                                     {'loss': 2.7892, 'grad_norm': 1.0219730138778687, 'learning_rate': 4.172881355932204e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1076/6000 [50:12<3:44:34,  2.74s/it] 18%|â–ˆâ–Š        | 1077/6000 [50:14<3:43:04,  2.72s/it]                                                     {'loss': 2.7887, 'grad_norm': 1.042740821838379, 'learning_rate': 4.172033898305085e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1077/6000 [50:14<3:43:04,  2.72s/it] 18%|â–ˆâ–Š        | 1078/6000 [50:17<3:42:09,  2.71s/it]                                                     {'loss': 2.7467, 'grad_norm': 1.0683636665344238, 'learning_rate': 4.171186440677966e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1078/6000 [50:17<3:42:09,  2.71s/it] 18%|â–ˆâ–Š        | 1079/6000 [50:20<3:50:15,  2.81s/it]                                                     {'loss': 2.7378, 'grad_norm': 1.407885193824768, 'learning_rate': 4.1703389830508474e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1079/6000 [50:20<3:50:15,  2.81s/it] 18%|â–ˆâ–Š        | 1080/6000 [50:23<3:46:45,  2.77s/it]                                                     {'loss': 2.7816, 'grad_norm': 1.159217119216919, 'learning_rate': 4.1694915254237285e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1080/6000 [50:23<3:46:45,  2.77s/it] 18%|â–ˆâ–Š        | 1081/6000 [50:25<3:42:40,  2.72s/it]                                                     {'loss': 2.7948, 'grad_norm': 1.3506138324737549, 'learning_rate': 4.16864406779661e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1081/6000 [50:25<3:42:40,  2.72s/it] 18%|â–ˆâ–Š        | 1082/6000 [50:28<3:42:22,  2.71s/it]                                                     {'loss': 2.8159, 'grad_norm': 1.6623488664627075, 'learning_rate': 4.1677966101694915e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1082/6000 [50:28<3:42:22,  2.71s/it] 18%|â–ˆâ–Š        | 1083/6000 [50:31<3:41:28,  2.70s/it]                                                     {'loss': 2.7646, 'grad_norm': 1.7678231000900269, 'learning_rate': 4.166949152542373e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1083/6000 [50:31<3:41:28,  2.70s/it] 18%|â–ˆâ–Š        | 1084/6000 [50:33<3:41:25,  2.70s/it]                                                     {'loss': 2.7649, 'grad_norm': 1.5593856573104858, 'learning_rate': 4.1661016949152544e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1084/6000 [50:33<3:41:25,  2.70s/it] 18%|â–ˆâ–Š        | 1085/6000 [50:36<3:40:04,  2.69s/it]                                                     {'loss': 2.782, 'grad_norm': 1.6067991256713867, 'learning_rate': 4.165254237288136e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1085/6000 [50:36<3:40:04,  2.69s/it] 18%|â–ˆâ–Š        | 1086/6000 [50:39<3:44:51,  2.75s/it]                                                     {'loss': 2.8005, 'grad_norm': 2.4246037006378174, 'learning_rate': 4.164406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1086/6000 [50:39<3:44:51,  2.75s/it] 18%|â–ˆâ–Š        | 1087/6000 [50:42<3:44:31,  2.74s/it]                                                     {'loss': 2.8072, 'grad_norm': 1.8193336725234985, 'learning_rate': 4.1635593220338985e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1087/6000 [50:42<3:44:31,  2.74s/it] 18%|â–ˆâ–Š        | 1088/6000 [50:44<3:43:22,  2.73s/it]                                                     {'loss': 2.808, 'grad_norm': 1.909060001373291, 'learning_rate': 4.1627118644067796e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1088/6000 [50:44<3:43:22,  2.73s/it] 18%|â–ˆâ–Š        | 1089/6000 [50:48<4:02:51,  2.97s/it]                                                     {'loss': 2.8262, 'grad_norm': 31.436019897460938, 'learning_rate': 4.1618644067796614e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1089/6000 [50:48<4:02:51,  2.97s/it] 18%|â–ˆâ–Š        | 1090/6000 [50:51<3:55:17,  2.88s/it]                                                     {'loss': 2.7931, 'grad_norm': 1.6017874479293823, 'learning_rate': 4.1610169491525425e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1090/6000 [50:51<3:55:17,  2.88s/it] 18%|â–ˆâ–Š        | 1091/6000 [50:53<3:50:56,  2.82s/it]                                                     {'loss': 2.7507, 'grad_norm': 2.103943347930908, 'learning_rate': 4.160169491525424e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1091/6000 [50:53<3:50:56,  2.82s/it] 18%|â–ˆâ–Š        | 1092/6000 [50:56<3:48:06,  2.79s/it]                                                     {'loss': 2.7677, 'grad_norm': 1.5258102416992188, 'learning_rate': 4.1593220338983055e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1092/6000 [50:56<3:48:06,  2.79s/it] 18%|â–ˆâ–Š        | 1093/6000 [50:59<3:45:00,  2.75s/it]                                                     {'loss': 2.7757, 'grad_norm': 1.6751400232315063, 'learning_rate': 4.1584745762711866e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1093/6000 [50:59<3:45:00,  2.75s/it] 18%|â–ˆâ–Š        | 1094/6000 [51:01<3:43:31,  2.73s/it]                                                     {'loss': 2.8103, 'grad_norm': 1.6900237798690796, 'learning_rate': 4.157627118644068e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1094/6000 [51:01<3:43:31,  2.73s/it] 18%|â–ˆâ–Š        | 1095/6000 [51:04<3:42:52,  2.73s/it]                                                     {'loss': 2.7671, 'grad_norm': 2.052870035171509, 'learning_rate': 4.1567796610169495e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1095/6000 [51:04<3:42:52,  2.73s/it] 18%|â–ˆâ–Š        | 1096/6000 [51:07<3:46:31,  2.77s/it]                                                     {'loss': 2.7547, 'grad_norm': 1.5883405208587646, 'learning_rate': 4.1559322033898307e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1096/6000 [51:07<3:46:31,  2.77s/it] 18%|â–ˆâ–Š        | 1097/6000 [51:10<3:45:15,  2.76s/it]                                                     {'loss': 2.77, 'grad_norm': 1.5523649454116821, 'learning_rate': 4.1550847457627125e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1097/6000 [51:10<3:45:15,  2.76s/it] 18%|â–ˆâ–Š        | 1098/6000 [51:13<4:02:05,  2.96s/it]                                                     {'loss': 2.7912, 'grad_norm': 3.8393523693084717, 'learning_rate': 4.1542372881355936e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1098/6000 [51:13<4:02:05,  2.96s/it] 18%|â–ˆâ–Š        | 1099/6000 [51:16<4:10:28,  3.07s/it]                                                     {'loss': 2.777, 'grad_norm': 5.781590938568115, 'learning_rate': 4.153389830508475e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1099/6000 [51:16<4:10:28,  3.07s/it] 18%|â–ˆâ–Š        | 1100/6000 [51:19<3:59:44,  2.94s/it]                                                     {'loss': 2.774, 'grad_norm': 1.7889480590820312, 'learning_rate': 4.152542372881356e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1100/6000 [51:19<3:59:44,  2.94s/it][2025-10-20 23:57:10,236] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1100
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 18%|â–ˆâ–Š        | 1101/6000 [51:24<4:42:48,  3.46s/it]                                                     {'loss': 2.7962, 'grad_norm': 1.4520227909088135, 'learning_rate': 4.151694915254237e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1101/6000 [51:24<4:42:48,  3.46s/it] 18%|â–ˆâ–Š        | 1102/6000 [51:26<4:22:58,  3.22s/it]                                                     {'loss': 2.7967, 'grad_norm': 0.9325108528137207, 'learning_rate': 4.150847457627119e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1102/6000 [51:26<4:22:58,  3.22s/it] 18%|â–ˆâ–Š        | 1103/6000 [51:29<4:08:59,  3.05s/it]                                                     {'loss': 2.768, 'grad_norm': 0.888500988483429, 'learning_rate': 4.15e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1103/6000 [51:29<4:08:59,  3.05s/it] 18%|â–ˆâ–Š        | 1104/6000 [51:32<3:59:12,  2.93s/it]                                                     {'loss': 2.7798, 'grad_norm': 0.7640004754066467, 'learning_rate': 4.149152542372882e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1104/6000 [51:32<3:59:12,  2.93s/it] 18%|â–ˆâ–Š        | 1105/6000 [51:34<3:52:36,  2.85s/it]                                                     {'loss': 2.7848, 'grad_norm': 1.1137254238128662, 'learning_rate': 4.148305084745763e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1105/6000 [51:34<3:52:36,  2.85s/it] 18%|â–ˆâ–Š        | 1106/6000 [51:37<3:47:48,  2.79s/it]                                                     {'loss': 2.7646, 'grad_norm': 1.316247582435608, 'learning_rate': 4.1474576271186446e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1106/6000 [51:37<3:47:48,  2.79s/it] 18%|â–ˆâ–Š        | 1107/6000 [51:40<3:43:15,  2.74s/it]                                                     {'loss': 2.7513, 'grad_norm': 0.9570779800415039, 'learning_rate': 4.146610169491526e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1107/6000 [51:40<3:43:15,  2.74s/it] 18%|â–ˆâ–Š        | 1108/6000 [51:42<3:43:51,  2.75s/it]                                                     {'loss': 2.7734, 'grad_norm': 0.8162968754768372, 'learning_rate': 4.145762711864407e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1108/6000 [51:42<3:43:51,  2.75s/it] 18%|â–ˆâ–Š        | 1109/6000 [51:45<3:40:52,  2.71s/it]                                                     {'loss': 2.8103, 'grad_norm': 1.1609959602355957, 'learning_rate': 4.144915254237288e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1109/6000 [51:45<3:40:52,  2.71s/it] 18%|â–ˆâ–Š        | 1110/6000 [51:48<3:40:51,  2.71s/it]                                                     {'loss': 2.757, 'grad_norm': 0.9764036536216736, 'learning_rate': 4.14406779661017e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 1110/6000 [51:48<3:40:51,  2.71s/it] 19%|â–ˆâ–Š        | 1111/6000 [51:50<3:37:27,  2.67s/it]                                                     {'loss': 2.855, 'grad_norm': 0.9402159452438354, 'learning_rate': 4.143220338983051e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1111/6000 [51:50<3:37:27,  2.67s/it] 19%|â–ˆâ–Š        | 1112/6000 [51:53<3:35:34,  2.65s/it]                                                     {'loss': 2.7732, 'grad_norm': 1.1442992687225342, 'learning_rate': 4.142372881355933e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1112/6000 [51:53<3:35:34,  2.65s/it] 19%|â–ˆâ–Š        | 1113/6000 [51:55<3:35:43,  2.65s/it]                                                     {'loss': 2.7883, 'grad_norm': 1.1334400177001953, 'learning_rate': 4.141525423728814e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1113/6000 [51:55<3:35:43,  2.65s/it] 19%|â–ˆâ–Š        | 1114/6000 [51:58<3:35:55,  2.65s/it]                                                     {'loss': 2.7851, 'grad_norm': 1.0832250118255615, 'learning_rate': 4.140677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1114/6000 [51:58<3:35:55,  2.65s/it] 19%|â–ˆâ–Š        | 1115/6000 [52:01<3:37:33,  2.67s/it]                                                     {'loss': 2.7558, 'grad_norm': 1.2363439798355103, 'learning_rate': 4.139830508474576e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1115/6000 [52:01<3:37:33,  2.67s/it] 19%|â–ˆâ–Š        | 1116/6000 [52:04<3:37:33,  2.67s/it]                                                     {'loss': 2.7647, 'grad_norm': 1.1420484781265259, 'learning_rate': 4.138983050847458e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1116/6000 [52:04<3:37:33,  2.67s/it] 19%|â–ˆâ–Š        | 1117/6000 [52:06<3:39:10,  2.69s/it]                                                     {'loss': 2.7958, 'grad_norm': 1.4423937797546387, 'learning_rate': 4.138135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1117/6000 [52:06<3:39:10,  2.69s/it] 19%|â–ˆâ–Š        | 1118/6000 [52:09<3:38:17,  2.68s/it]                                                     {'loss': 2.7784, 'grad_norm': 1.212753415107727, 'learning_rate': 4.13728813559322e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1118/6000 [52:09<3:38:17,  2.68s/it] 19%|â–ˆâ–Š        | 1119/6000 [52:12<3:41:19,  2.72s/it]                                                     {'loss': 2.7649, 'grad_norm': 1.5045251846313477, 'learning_rate': 4.136440677966102e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1119/6000 [52:12<3:41:19,  2.72s/it] 19%|â–ˆâ–Š        | 1120/6000 [52:14<3:40:14,  2.71s/it]                                                     {'loss': 2.8024, 'grad_norm': 1.4014887809753418, 'learning_rate': 4.135593220338983e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1120/6000 [52:14<3:40:14,  2.71s/it] 19%|â–ˆâ–Š        | 1121/6000 [52:17<3:38:30,  2.69s/it]                                                     {'loss': 2.7361, 'grad_norm': 1.5494242906570435, 'learning_rate': 4.134745762711865e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1121/6000 [52:17<3:38:30,  2.69s/it] 19%|â–ˆâ–Š        | 1122/6000 [52:20<3:42:51,  2.74s/it]                                                     {'loss': 2.7891, 'grad_norm': 1.8169256448745728, 'learning_rate': 4.1338983050847454e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1122/6000 [52:20<3:42:51,  2.74s/it] 19%|â–ˆâ–Š        | 1123/6000 [52:23<3:42:24,  2.74s/it]                                                     {'loss': 2.7136, 'grad_norm': 3.013427972793579, 'learning_rate': 4.133050847457627e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1123/6000 [52:23<3:42:24,  2.74s/it] 19%|â–ˆâ–Š        | 1124/6000 [52:26<3:49:13,  2.82s/it]                                                     {'loss': 2.7974, 'grad_norm': 1.8138868808746338, 'learning_rate': 4.1322033898305084e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 1124/6000 [52:26<3:49:13,  2.82s/it] 19%|â–ˆâ–‰        | 1125/6000 [52:28<3:47:52,  2.80s/it]                                                     {'loss': 2.7744, 'grad_norm': 1.6629431247711182, 'learning_rate': 4.13135593220339e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1125/6000 [52:28<3:47:52,  2.80s/it] 19%|â–ˆâ–‰        | 1126/6000 [52:31<3:45:22,  2.77s/it]                                                     {'loss': 2.8096, 'grad_norm': 1.8052817583084106, 'learning_rate': 4.130508474576271e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1126/6000 [52:31<3:45:22,  2.77s/it] 19%|â–ˆâ–‰        | 1127/6000 [52:34<3:44:41,  2.77s/it]                                                     {'loss': 2.7548, 'grad_norm': 1.5812418460845947, 'learning_rate': 4.129661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1127/6000 [52:34<3:44:41,  2.77s/it] 19%|â–ˆâ–‰        | 1128/6000 [52:37<3:41:42,  2.73s/it]                                                     {'loss': 2.7512, 'grad_norm': 1.5212366580963135, 'learning_rate': 4.128813559322034e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1128/6000 [52:37<3:41:42,  2.73s/it] 19%|â–ˆâ–‰        | 1129/6000 [52:39<3:39:23,  2.70s/it]                                                     {'loss': 2.7572, 'grad_norm': 1.7199349403381348, 'learning_rate': 4.1279661016949153e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1129/6000 [52:39<3:39:23,  2.70s/it] 19%|â–ˆâ–‰        | 1130/6000 [52:42<3:40:33,  2.72s/it]                                                     {'loss': 2.7782, 'grad_norm': 2.33310866355896, 'learning_rate': 4.1271186440677965e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1130/6000 [52:42<3:40:33,  2.72s/it] 19%|â–ˆâ–‰        | 1131/6000 [52:45<3:37:28,  2.68s/it]                                                     {'loss': 2.7807, 'grad_norm': 1.9716405868530273, 'learning_rate': 4.126271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1131/6000 [52:45<3:37:28,  2.68s/it] 19%|â–ˆâ–‰        | 1132/6000 [52:47<3:36:40,  2.67s/it]                                                     {'loss': 2.7771, 'grad_norm': 2.554828405380249, 'learning_rate': 4.1254237288135594e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1132/6000 [52:47<3:36:40,  2.67s/it] 19%|â–ˆâ–‰        | 1133/6000 [52:50<3:45:06,  2.78s/it]                                                     {'loss': 2.8127, 'grad_norm': 4.0928425788879395, 'learning_rate': 4.124576271186441e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1133/6000 [52:50<3:45:06,  2.78s/it] 19%|â–ˆâ–‰        | 1134/6000 [52:53<3:52:03,  2.86s/it]                                                     {'loss': 2.7134, 'grad_norm': 2.039041042327881, 'learning_rate': 4.1237288135593223e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1134/6000 [52:53<3:52:03,  2.86s/it] 19%|â–ˆâ–‰        | 1135/6000 [52:56<3:48:55,  2.82s/it]                                                     {'loss': 2.798, 'grad_norm': 2.176912784576416, 'learning_rate': 4.1228813559322035e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1135/6000 [52:56<3:48:55,  2.82s/it] 19%|â–ˆâ–‰        | 1136/6000 [52:59<3:46:25,  2.79s/it]                                                     {'loss': 2.7529, 'grad_norm': 1.7868348360061646, 'learning_rate': 4.1220338983050846e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1136/6000 [52:59<3:46:25,  2.79s/it] 19%|â–ˆâ–‰        | 1137/6000 [53:01<3:44:23,  2.77s/it]                                                     {'loss': 2.8096, 'grad_norm': 1.7745529413223267, 'learning_rate': 4.1211864406779664e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1137/6000 [53:01<3:44:23,  2.77s/it] 19%|â–ˆâ–‰        | 1138/6000 [53:04<3:40:40,  2.72s/it]                                                     {'loss': 2.7923, 'grad_norm': 1.4759230613708496, 'learning_rate': 4.1203389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1138/6000 [53:04<3:40:40,  2.72s/it] 19%|â–ˆâ–‰        | 1139/6000 [53:07<3:41:01,  2.73s/it]                                                     {'loss': 2.769, 'grad_norm': 2.6519603729248047, 'learning_rate': 4.119491525423729e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1139/6000 [53:07<3:41:01,  2.73s/it] 19%|â–ˆâ–‰        | 1140/6000 [53:10<3:42:06,  2.74s/it]                                                     {'loss': 2.7806, 'grad_norm': 2.1691880226135254, 'learning_rate': 4.1186440677966105e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1140/6000 [53:10<3:42:06,  2.74s/it] 19%|â–ˆâ–‰        | 1141/6000 [53:12<3:40:40,  2.72s/it]                                                     {'loss': 2.7776, 'grad_norm': 1.7266343832015991, 'learning_rate': 4.1177966101694916e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1141/6000 [53:12<3:40:40,  2.72s/it] 19%|â–ˆâ–‰        | 1142/6000 [53:15<3:40:08,  2.72s/it]                                                     {'loss': 2.8261, 'grad_norm': 2.232347011566162, 'learning_rate': 4.1169491525423734e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1142/6000 [53:15<3:40:08,  2.72s/it] 19%|â–ˆâ–‰        | 1143/6000 [53:18<3:37:02,  2.68s/it]                                                     {'loss': 2.8055, 'grad_norm': 1.9957324266433716, 'learning_rate': 4.1161016949152545e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1143/6000 [53:18<3:37:02,  2.68s/it] 19%|â–ˆâ–‰        | 1144/6000 [53:20<3:36:00,  2.67s/it]                                                     {'loss': 2.8273, 'grad_norm': 1.1781352758407593, 'learning_rate': 4.115254237288136e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1144/6000 [53:20<3:36:00,  2.67s/it] 19%|â–ˆâ–‰        | 1145/6000 [53:23<3:36:31,  2.68s/it]                                                     {'loss': 2.8519, 'grad_norm': 1.3706356287002563, 'learning_rate': 4.114406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1145/6000 [53:23<3:36:31,  2.68s/it] 19%|â–ˆâ–‰        | 1146/6000 [53:26<3:40:16,  2.72s/it]                                                     {'loss': 2.7604, 'grad_norm': 1.207249402999878, 'learning_rate': 4.1135593220338986e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1146/6000 [53:26<3:40:16,  2.72s/it] 19%|â–ˆâ–‰        | 1147/6000 [53:28<3:38:41,  2.70s/it]                                                     {'loss': 2.7748, 'grad_norm': 1.2632578611373901, 'learning_rate': 4.11271186440678e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1147/6000 [53:28<3:38:41,  2.70s/it] 19%|â–ˆâ–‰        | 1148/6000 [53:31<3:37:07,  2.69s/it]                                                     {'loss': 2.7903, 'grad_norm': 1.9414901733398438, 'learning_rate': 4.1118644067796615e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1148/6000 [53:31<3:37:07,  2.69s/it] 19%|â–ˆâ–‰        | 1149/6000 [53:34<3:46:15,  2.80s/it]                                                     {'loss': 2.7834, 'grad_norm': 1.115592360496521, 'learning_rate': 4.111016949152543e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1149/6000 [53:34<3:46:15,  2.80s/it] 19%|â–ˆâ–‰        | 1150/6000 [53:37<3:45:02,  2.78s/it]                                                     {'loss': 2.7828, 'grad_norm': 0.87205970287323, 'learning_rate': 4.110169491525424e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1150/6000 [53:37<3:45:02,  2.78s/it][2025-10-20 23:59:28,068] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1150
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 19%|â–ˆâ–‰        | 1151/6000 [53:41<4:30:22,  3.35s/it]                                                     {'loss': 2.7509, 'grad_norm': 1.272843360900879, 'learning_rate': 4.109322033898305e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1151/6000 [53:41<4:30:22,  3.35s/it] 19%|â–ˆâ–‰        | 1152/6000 [53:44<4:20:09,  3.22s/it]                                                     {'loss': 2.7704, 'grad_norm': 1.1051878929138184, 'learning_rate': 4.108474576271187e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1152/6000 [53:44<4:20:09,  3.22s/it] 19%|â–ˆâ–‰        | 1153/6000 [53:47<4:10:34,  3.10s/it]                                                     {'loss': 2.7859, 'grad_norm': 0.7344928979873657, 'learning_rate': 4.107627118644068e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1153/6000 [53:47<4:10:34,  3.10s/it] 19%|â–ˆâ–‰        | 1154/6000 [53:50<4:01:56,  3.00s/it]                                                     {'loss': 2.7663, 'grad_norm': 0.740743100643158, 'learning_rate': 4.10677966101695e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1154/6000 [53:50<4:01:56,  3.00s/it] 19%|â–ˆâ–‰        | 1155/6000 [53:53<3:55:29,  2.92s/it]                                                     {'loss': 2.7641, 'grad_norm': 0.8107942938804626, 'learning_rate': 4.105932203389831e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1155/6000 [53:53<3:55:29,  2.92s/it] 19%|â–ˆâ–‰        | 1156/6000 [53:55<3:49:47,  2.85s/it]                                                     {'loss': 2.7549, 'grad_norm': 1.54721999168396, 'learning_rate': 4.1050847457627126e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1156/6000 [53:55<3:49:47,  2.85s/it] 19%|â–ˆâ–‰        | 1157/6000 [53:58<3:48:27,  2.83s/it]                                                     {'loss': 2.7618, 'grad_norm': 1.1558837890625, 'learning_rate': 4.104237288135593e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1157/6000 [53:58<3:48:27,  2.83s/it] 19%|â–ˆâ–‰        | 1158/6000 [54:01<3:44:10,  2.78s/it]                                                     {'loss': 2.75, 'grad_norm': 1.6317518949508667, 'learning_rate': 4.103389830508475e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1158/6000 [54:01<3:44:10,  2.78s/it] 19%|â–ˆâ–‰        | 1159/6000 [54:03<3:40:26,  2.73s/it]                                                     {'loss': 2.912, 'grad_norm': 0.9921668171882629, 'learning_rate': 4.102542372881356e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1159/6000 [54:03<3:40:26,  2.73s/it] 19%|â–ˆâ–‰        | 1160/6000 [54:06<3:38:01,  2.70s/it]                                                     {'loss': 2.8056, 'grad_norm': 1.2631272077560425, 'learning_rate': 4.101694915254237e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1160/6000 [54:06<3:38:01,  2.70s/it] 19%|â–ˆâ–‰        | 1161/6000 [54:09<3:35:50,  2.68s/it]                                                     {'loss': 2.7396, 'grad_norm': 1.1409592628479004, 'learning_rate': 4.100847457627119e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1161/6000 [54:09<3:35:50,  2.68s/it] 19%|â–ˆâ–‰        | 1162/6000 [54:11<3:33:52,  2.65s/it]                                                     {'loss': 2.7978, 'grad_norm': 0.9864324927330017, 'learning_rate': 4.1e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1162/6000 [54:11<3:33:52,  2.65s/it] 19%|â–ˆâ–‰        | 1163/6000 [54:14<3:35:01,  2.67s/it]                                                     {'loss': 2.7563, 'grad_norm': 1.1492000818252563, 'learning_rate': 4.099152542372882e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1163/6000 [54:14<3:35:01,  2.67s/it] 19%|â–ˆâ–‰        | 1164/6000 [54:17<3:34:43,  2.66s/it]                                                     {'loss': 2.741, 'grad_norm': 1.1377202272415161, 'learning_rate': 4.098305084745763e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1164/6000 [54:17<3:34:43,  2.66s/it] 19%|â–ˆâ–‰        | 1165/6000 [54:19<3:35:17,  2.67s/it]                                                     {'loss': 2.8113, 'grad_norm': 1.075995922088623, 'learning_rate': 4.097457627118644e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1165/6000 [54:19<3:35:17,  2.67s/it] 19%|â–ˆâ–‰        | 1166/6000 [54:22<3:33:03,  2.64s/it]                                                     {'loss': 2.961, 'grad_norm': 1.389887809753418, 'learning_rate': 4.096610169491525e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1166/6000 [54:22<3:33:03,  2.64s/it] 19%|â–ˆâ–‰        | 1167/6000 [54:25<3:45:22,  2.80s/it]                                                     {'loss': 2.7473, 'grad_norm': 1.5747298002243042, 'learning_rate': 4.095762711864407e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1167/6000 [54:25<3:45:22,  2.80s/it] 19%|â–ˆâ–‰        | 1168/6000 [54:28<3:41:10,  2.75s/it]                                                     {'loss': 2.7679, 'grad_norm': 1.3471786975860596, 'learning_rate': 4.094915254237288e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1168/6000 [54:28<3:41:10,  2.75s/it] 19%|â–ˆâ–‰        | 1169/6000 [54:30<3:38:19,  2.71s/it]                                                     {'loss': 2.7895, 'grad_norm': 1.813735008239746, 'learning_rate': 4.09406779661017e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 1169/6000 [54:30<3:38:19,  2.71s/it] 20%|â–ˆâ–‰        | 1170/6000 [54:33<3:37:12,  2.70s/it]                                                     {'loss': 2.8155, 'grad_norm': 1.8335182666778564, 'learning_rate': 4.093220338983051e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1170/6000 [54:33<3:37:12,  2.70s/it] 20%|â–ˆâ–‰        | 1171/6000 [54:36<3:39:09,  2.72s/it]                                                     {'loss': 2.7596, 'grad_norm': 1.642943024635315, 'learning_rate': 4.092372881355932e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1171/6000 [54:36<3:39:09,  2.72s/it] 20%|â–ˆâ–‰        | 1172/6000 [54:38<3:38:03,  2.71s/it]                                                     {'loss': 2.7166, 'grad_norm': 1.8053863048553467, 'learning_rate': 4.0915254237288134e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1172/6000 [54:38<3:38:03,  2.71s/it] 20%|â–ˆâ–‰        | 1173/6000 [54:41<3:36:50,  2.70s/it]                                                     {'loss': 2.7121, 'grad_norm': 2.5586352348327637, 'learning_rate': 4.090677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1173/6000 [54:41<3:36:50,  2.70s/it] 20%|â–ˆâ–‰        | 1174/6000 [54:44<3:37:19,  2.70s/it]                                                     {'loss': 2.7425, 'grad_norm': 1.889721393585205, 'learning_rate': 4.089830508474576e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1174/6000 [54:44<3:37:19,  2.70s/it] 20%|â–ˆâ–‰        | 1175/6000 [54:47<3:38:07,  2.71s/it]                                                     {'loss': 2.7821, 'grad_norm': 3.071719169616699, 'learning_rate': 4.088983050847458e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1175/6000 [54:47<3:38:07,  2.71s/it] 20%|â–ˆâ–‰        | 1176/6000 [54:49<3:36:21,  2.69s/it]                                                     {'loss': 2.779, 'grad_norm': 1.8300272226333618, 'learning_rate': 4.088135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1176/6000 [54:49<3:36:21,  2.69s/it] 20%|â–ˆâ–‰        | 1177/6000 [54:52<3:34:43,  2.67s/it]                                                     {'loss': 2.665, 'grad_norm': 3.530999183654785, 'learning_rate': 4.087288135593221e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1177/6000 [54:52<3:34:43,  2.67s/it] 20%|â–ˆâ–‰        | 1178/6000 [54:55<3:44:27,  2.79s/it]                                                     {'loss': 2.7517, 'grad_norm': 3.1939237117767334, 'learning_rate': 4.086440677966102e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1178/6000 [54:55<3:44:27,  2.79s/it] 20%|â–ˆâ–‰        | 1179/6000 [54:58<3:50:56,  2.87s/it]                                                     {'loss': 2.7627, 'grad_norm': 2.2305586338043213, 'learning_rate': 4.085593220338983e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1179/6000 [54:58<3:50:56,  2.87s/it] 20%|â–ˆâ–‰        | 1180/6000 [55:01<3:53:35,  2.91s/it]                                                     {'loss': 2.9842, 'grad_norm': 4.69730806350708, 'learning_rate': 4.0847457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1180/6000 [55:01<3:53:35,  2.91s/it] 20%|â–ˆâ–‰        | 1181/6000 [55:04<3:48:26,  2.84s/it]                                                     {'loss': 2.8064, 'grad_norm': 3.8988113403320312, 'learning_rate': 4.0838983050847456e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1181/6000 [55:04<3:48:26,  2.84s/it] 20%|â–ˆâ–‰        | 1182/6000 [55:07<4:05:16,  3.05s/it]                                                     {'loss': 2.7832, 'grad_norm': 2.925419807434082, 'learning_rate': 4.0830508474576274e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1182/6000 [55:07<4:05:16,  3.05s/it] 20%|â–ˆâ–‰        | 1183/6000 [55:10<4:01:12,  3.00s/it]                                                     {'loss': 2.8251, 'grad_norm': 3.0289556980133057, 'learning_rate': 4.0822033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1183/6000 [55:10<4:01:12,  3.00s/it] 20%|â–ˆâ–‰        | 1184/6000 [55:13<3:53:53,  2.91s/it]                                                     {'loss': 2.7739, 'grad_norm': 2.3048737049102783, 'learning_rate': 4.08135593220339e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1184/6000 [55:13<3:53:53,  2.91s/it] 20%|â–ˆâ–‰        | 1185/6000 [55:15<3:46:31,  2.82s/it]                                                     {'loss': 2.7587, 'grad_norm': 3.6830413341522217, 'learning_rate': 4.0805084745762714e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1185/6000 [55:15<3:46:31,  2.82s/it] 20%|â–ˆâ–‰        | 1186/6000 [55:18<3:43:05,  2.78s/it]                                                     {'loss': 2.7367, 'grad_norm': 2.080305337905884, 'learning_rate': 4.0796610169491526e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1186/6000 [55:18<3:43:05,  2.78s/it] 20%|â–ˆâ–‰        | 1187/6000 [55:21<3:40:05,  2.74s/it]                                                     {'loss': 2.8368, 'grad_norm': 1.7646865844726562, 'learning_rate': 4.078813559322034e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1187/6000 [55:21<3:40:05,  2.74s/it] 20%|â–ˆâ–‰        | 1188/6000 [55:23<3:36:27,  2.70s/it]                                                     {'loss': 2.8954, 'grad_norm': 1.8356218338012695, 'learning_rate': 4.0779661016949155e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1188/6000 [55:23<3:36:27,  2.70s/it] 20%|â–ˆâ–‰        | 1189/6000 [55:26<3:35:35,  2.69s/it]                                                     {'loss': 2.7904, 'grad_norm': 1.4371213912963867, 'learning_rate': 4.0771186440677966e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1189/6000 [55:26<3:35:35,  2.69s/it] 20%|â–ˆâ–‰        | 1190/6000 [55:29<3:38:51,  2.73s/it]                                                     {'loss': 2.7685, 'grad_norm': 1.3429255485534668, 'learning_rate': 4.0762711864406784e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1190/6000 [55:29<3:38:51,  2.73s/it] 20%|â–ˆâ–‰        | 1191/6000 [55:32<3:39:56,  2.74s/it]                                                     {'loss': 2.7273, 'grad_norm': 1.4589780569076538, 'learning_rate': 4.0754237288135596e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1191/6000 [55:32<3:39:56,  2.74s/it] 20%|â–ˆâ–‰        | 1192/6000 [55:34<3:39:52,  2.74s/it]                                                     {'loss': 2.7359, 'grad_norm': 1.700968623161316, 'learning_rate': 4.0745762711864414e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1192/6000 [55:34<3:39:52,  2.74s/it] 20%|â–ˆâ–‰        | 1193/6000 [55:37<3:38:48,  2.73s/it]                                                     {'loss': 2.7807, 'grad_norm': 1.343170404434204, 'learning_rate': 4.073728813559322e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1193/6000 [55:37<3:38:48,  2.73s/it] 20%|â–ˆâ–‰        | 1194/6000 [55:40<3:39:40,  2.74s/it]                                                     {'loss': 2.7352, 'grad_norm': 1.4709868431091309, 'learning_rate': 4.0728813559322036e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1194/6000 [55:40<3:39:40,  2.74s/it] 20%|â–ˆâ–‰        | 1195/6000 [55:43<3:38:25,  2.73s/it]                                                     {'loss': 2.7552, 'grad_norm': 1.0991899967193604, 'learning_rate': 4.072033898305085e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1195/6000 [55:43<3:38:25,  2.73s/it] 20%|â–ˆâ–‰        | 1196/6000 [55:45<3:37:26,  2.72s/it]                                                     {'loss': 2.7198, 'grad_norm': 1.5750420093536377, 'learning_rate': 4.0711864406779666e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1196/6000 [55:45<3:37:26,  2.72s/it] 20%|â–ˆâ–‰        | 1197/6000 [55:48<3:39:29,  2.74s/it]                                                     {'loss': 2.7789, 'grad_norm': 1.2429225444793701, 'learning_rate': 4.070338983050848e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1197/6000 [55:48<3:39:29,  2.74s/it] 20%|â–ˆâ–‰        | 1198/6000 [55:51<3:39:27,  2.74s/it]                                                     {'loss': 2.7862, 'grad_norm': 1.9856348037719727, 'learning_rate': 4.0694915254237295e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1198/6000 [55:51<3:39:27,  2.74s/it] 20%|â–ˆâ–‰        | 1199/6000 [55:53<3:37:57,  2.72s/it]                                                     {'loss': 2.784, 'grad_norm': 1.6036869287490845, 'learning_rate': 4.0686440677966106e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 1199/6000 [55:53<3:37:57,  2.72s/it] 20%|â–ˆâ–ˆ        | 1200/6000 [55:56<3:36:14,  2.70s/it]                                                     {'loss': 2.7372, 'grad_norm': 1.5278161764144897, 'learning_rate': 4.067796610169492e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1200/6000 [55:56<3:36:14,  2.70s/it][2025-10-21 00:01:47,361] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1200
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 20%|â–ˆâ–ˆ        | 1201/6000 [56:01<4:24:08,  3.30s/it]                                                     {'loss': 2.7768, 'grad_norm': 2.23604679107666, 'learning_rate': 4.066949152542373e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1201/6000 [56:01<4:24:08,  3.30s/it] 20%|â–ˆâ–ˆ        | 1202/6000 [56:03<4:08:33,  3.11s/it]                                                     {'loss': 2.7776, 'grad_norm': 1.6540908813476562, 'learning_rate': 4.066101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1202/6000 [56:03<4:08:33,  3.11s/it] 20%|â–ˆâ–ˆ        | 1203/6000 [56:06<3:58:55,  2.99s/it]                                                     {'loss': 2.7825, 'grad_norm': 1.6379157304763794, 'learning_rate': 4.065254237288136e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1203/6000 [56:06<3:58:55,  2.99s/it] 20%|â–ˆâ–ˆ        | 1204/6000 [56:09<4:01:53,  3.03s/it]                                                     {'loss': 2.7734, 'grad_norm': 2.3818516731262207, 'learning_rate': 4.064406779661017e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1204/6000 [56:09<4:01:53,  3.03s/it] 20%|â–ˆâ–ˆ        | 1205/6000 [56:12<3:54:03,  2.93s/it]                                                     {'loss': 2.7732, 'grad_norm': 1.7698619365692139, 'learning_rate': 4.063559322033899e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1205/6000 [56:12<3:54:03,  2.93s/it] 20%|â–ˆâ–ˆ        | 1206/6000 [56:15<3:47:35,  2.85s/it]                                                     {'loss': 2.8131, 'grad_norm': 2.2965636253356934, 'learning_rate': 4.06271186440678e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1206/6000 [56:15<3:47:35,  2.85s/it] 20%|â–ˆâ–ˆ        | 1207/6000 [56:17<3:43:12,  2.79s/it]                                                     {'loss': 2.7001, 'grad_norm': 2.2007875442504883, 'learning_rate': 4.061864406779661e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1207/6000 [56:17<3:43:12,  2.79s/it] 20%|â–ˆâ–ˆ        | 1208/6000 [56:20<3:39:00,  2.74s/it]                                                     {'loss': 2.7513, 'grad_norm': 1.7480676174163818, 'learning_rate': 4.061016949152542e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1208/6000 [56:20<3:39:00,  2.74s/it] 20%|â–ˆâ–ˆ        | 1209/6000 [56:23<3:36:50,  2.72s/it]                                                     {'loss': 2.7497, 'grad_norm': 1.6617964506149292, 'learning_rate': 4.060169491525424e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1209/6000 [56:23<3:36:50,  2.72s/it] 20%|â–ˆâ–ˆ        | 1210/6000 [56:25<3:37:13,  2.72s/it]                                                     {'loss': 2.8325, 'grad_norm': 2.9501004219055176, 'learning_rate': 4.059322033898305e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1210/6000 [56:25<3:37:13,  2.72s/it] 20%|â–ˆâ–ˆ        | 1211/6000 [56:28<3:35:59,  2.71s/it]                                                     {'loss': 2.7653, 'grad_norm': 1.9526586532592773, 'learning_rate': 4.058474576271187e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1211/6000 [56:28<3:35:59,  2.71s/it] 20%|â–ˆâ–ˆ        | 1212/6000 [56:31<3:36:17,  2.71s/it]                                                     {'loss': 2.7325, 'grad_norm': 1.5493903160095215, 'learning_rate': 4.057627118644068e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1212/6000 [56:31<3:36:17,  2.71s/it] 20%|â–ˆâ–ˆ        | 1213/6000 [56:33<3:34:26,  2.69s/it]                                                     {'loss': 2.7709, 'grad_norm': 1.7639740705490112, 'learning_rate': 4.05677966101695e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1213/6000 [56:33<3:34:26,  2.69s/it] 20%|â–ˆâ–ˆ        | 1214/6000 [56:36<3:35:28,  2.70s/it]                                                     {'loss': 2.7287, 'grad_norm': 1.7813760042190552, 'learning_rate': 4.055932203389831e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1214/6000 [56:36<3:35:28,  2.70s/it] 20%|â–ˆâ–ˆ        | 1215/6000 [56:39<3:35:06,  2.70s/it]                                                     {'loss': 2.6923, 'grad_norm': 1.7915972471237183, 'learning_rate': 4.055084745762712e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1215/6000 [56:39<3:35:06,  2.70s/it] 20%|â–ˆâ–ˆ        | 1216/6000 [56:41<3:32:33,  2.67s/it]                                                     {'loss': 2.7782, 'grad_norm': 1.6467267274856567, 'learning_rate': 4.054237288135593e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1216/6000 [56:41<3:32:33,  2.67s/it] 20%|â–ˆâ–ˆ        | 1217/6000 [56:44<3:44:14,  2.81s/it]                                                     {'loss': 2.7913, 'grad_norm': 2.2741506099700928, 'learning_rate': 4.053389830508475e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1217/6000 [56:45<3:44:14,  2.81s/it] 20%|â–ˆâ–ˆ        | 1218/6000 [56:47<3:40:23,  2.77s/it]                                                     {'loss': 2.8009, 'grad_norm': 2.1529510021209717, 'learning_rate': 4.052542372881356e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1218/6000 [56:47<3:40:23,  2.77s/it] 20%|â–ˆâ–ˆ        | 1219/6000 [56:50<3:45:02,  2.82s/it]                                                     {'loss': 2.8148, 'grad_norm': 2.9314637184143066, 'learning_rate': 4.051694915254238e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1219/6000 [56:50<3:45:02,  2.82s/it] 20%|â–ˆâ–ˆ        | 1220/6000 [56:53<3:41:56,  2.79s/it]                                                     {'loss': 2.7461, 'grad_norm': 1.5428493022918701, 'learning_rate': 4.050847457627119e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1220/6000 [56:53<3:41:56,  2.79s/it] 20%|â–ˆâ–ˆ        | 1221/6000 [56:56<3:40:59,  2.77s/it]                                                     {'loss': 2.7704, 'grad_norm': 2.8152506351470947, 'learning_rate': 4.05e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1221/6000 [56:56<3:40:59,  2.77s/it] 20%|â–ˆâ–ˆ        | 1222/6000 [56:58<3:39:07,  2.75s/it]                                                     {'loss': 2.7903, 'grad_norm': 3.2282419204711914, 'learning_rate': 4.049152542372881e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1222/6000 [56:58<3:39:07,  2.75s/it] 20%|â–ˆâ–ˆ        | 1223/6000 [57:01<3:36:14,  2.72s/it]                                                     {'loss': 2.7495, 'grad_norm': 2.7341148853302, 'learning_rate': 4.0483050847457624e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1223/6000 [57:01<3:36:14,  2.72s/it] 20%|â–ˆâ–ˆ        | 1224/6000 [57:04<3:34:46,  2.70s/it]                                                     {'loss': 2.8167, 'grad_norm': 3.0999107360839844, 'learning_rate': 4.047457627118644e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1224/6000 [57:04<3:34:46,  2.70s/it] 20%|â–ˆâ–ˆ        | 1225/6000 [57:06<3:37:58,  2.74s/it]                                                     {'loss': 2.7871, 'grad_norm': 1.3210753202438354, 'learning_rate': 4.0466101694915254e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1225/6000 [57:06<3:37:58,  2.74s/it] 20%|â–ˆâ–ˆ        | 1226/6000 [57:09<3:43:42,  2.81s/it]                                                     {'loss': 2.7659, 'grad_norm': 1.792828917503357, 'learning_rate': 4.045762711864407e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1226/6000 [57:09<3:43:42,  2.81s/it] 20%|â–ˆâ–ˆ        | 1227/6000 [57:12<3:49:09,  2.88s/it]                                                     {'loss': 2.7779, 'grad_norm': 2.5188751220703125, 'learning_rate': 4.044915254237288e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1227/6000 [57:12<3:49:09,  2.88s/it] 20%|â–ˆâ–ˆ        | 1228/6000 [57:15<3:44:34,  2.82s/it]                                                     {'loss': 2.8072, 'grad_norm': 1.2464594841003418, 'learning_rate': 4.0440677966101694e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1228/6000 [57:15<3:44:34,  2.82s/it] 20%|â–ˆâ–ˆ        | 1229/6000 [57:18<3:39:49,  2.76s/it]                                                     {'loss': 2.7416, 'grad_norm': 1.765460729598999, 'learning_rate': 4.0432203389830506e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1229/6000 [57:18<3:39:49,  2.76s/it] 20%|â–ˆâ–ˆ        | 1230/6000 [57:20<3:37:03,  2.73s/it]                                                     {'loss': 2.785, 'grad_norm': 1.3226147890090942, 'learning_rate': 4.0423728813559324e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 1230/6000 [57:20<3:37:03,  2.73s/it] 21%|â–ˆâ–ˆ        | 1231/6000 [57:23<3:36:17,  2.72s/it]                                                     {'loss': 2.8138, 'grad_norm': 1.4202157258987427, 'learning_rate': 4.0415254237288135e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1231/6000 [57:23<3:36:17,  2.72s/it] 21%|â–ˆâ–ˆ        | 1232/6000 [57:26<3:40:30,  2.77s/it]                                                     {'loss': 2.7543, 'grad_norm': 1.1666630506515503, 'learning_rate': 4.040677966101695e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1232/6000 [57:26<3:40:30,  2.77s/it] 21%|â–ˆâ–ˆ        | 1233/6000 [57:29<3:43:18,  2.81s/it]                                                     {'loss': 2.7635, 'grad_norm': 1.3741204738616943, 'learning_rate': 4.0398305084745764e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1233/6000 [57:29<3:43:18,  2.81s/it] 21%|â–ˆâ–ˆ        | 1234/6000 [57:32<3:48:17,  2.87s/it]                                                     {'loss': 2.7671, 'grad_norm': 2.0293352603912354, 'learning_rate': 4.038983050847458e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1234/6000 [57:32<3:48:17,  2.87s/it] 21%|â–ˆâ–ˆ        | 1235/6000 [57:35<3:43:09,  2.81s/it]                                                     {'loss': 2.7413, 'grad_norm': 1.5357677936553955, 'learning_rate': 4.0381355932203394e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1235/6000 [57:35<3:43:09,  2.81s/it] 21%|â–ˆâ–ˆ        | 1236/6000 [57:37<3:41:19,  2.79s/it]                                                     {'loss': 2.8277, 'grad_norm': 1.5956648588180542, 'learning_rate': 4.0372881355932205e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1236/6000 [57:37<3:41:19,  2.79s/it] 21%|â–ˆâ–ˆ        | 1237/6000 [57:40<3:38:29,  2.75s/it]                                                     {'loss': 2.7822, 'grad_norm': 1.275483250617981, 'learning_rate': 4.0364406779661016e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1237/6000 [57:40<3:38:29,  2.75s/it] 21%|â–ˆâ–ˆ        | 1238/6000 [57:43<3:37:23,  2.74s/it]                                                     {'loss': 2.7302, 'grad_norm': 1.6449171304702759, 'learning_rate': 4.0355932203389834e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1238/6000 [57:43<3:37:23,  2.74s/it] 21%|â–ˆâ–ˆ        | 1239/6000 [57:45<3:34:21,  2.70s/it]                                                     {'loss': 2.7637, 'grad_norm': 1.3989752531051636, 'learning_rate': 4.0347457627118646e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1239/6000 [57:45<3:34:21,  2.70s/it] 21%|â–ˆâ–ˆ        | 1240/6000 [57:48<3:35:45,  2.72s/it]                                                     {'loss': 2.7482, 'grad_norm': 1.2450975179672241, 'learning_rate': 4.0338983050847464e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1240/6000 [57:48<3:35:45,  2.72s/it] 21%|â–ˆâ–ˆ        | 1241/6000 [57:51<3:33:10,  2.69s/it]                                                     {'loss': 2.7407, 'grad_norm': 1.407392144203186, 'learning_rate': 4.0330508474576275e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1241/6000 [57:51<3:33:10,  2.69s/it] 21%|â–ˆâ–ˆ        | 1242/6000 [57:53<3:34:58,  2.71s/it]                                                     {'loss': 2.7416, 'grad_norm': 1.7384833097457886, 'learning_rate': 4.0322033898305086e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1242/6000 [57:53<3:34:58,  2.71s/it] 21%|â–ˆâ–ˆ        | 1243/6000 [57:56<3:35:40,  2.72s/it]                                                     {'loss': 2.785, 'grad_norm': 2.0552427768707275, 'learning_rate': 4.03135593220339e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1243/6000 [57:56<3:35:40,  2.72s/it] 21%|â–ˆâ–ˆ        | 1244/6000 [57:59<3:33:25,  2.69s/it]                                                     {'loss': 2.708, 'grad_norm': 1.8751782178878784, 'learning_rate': 4.030508474576271e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1244/6000 [57:59<3:33:25,  2.69s/it] 21%|â–ˆâ–ˆ        | 1245/6000 [58:01<3:33:17,  2.69s/it]                                                     {'loss': 2.7194, 'grad_norm': 1.914217233657837, 'learning_rate': 4.029661016949153e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1245/6000 [58:01<3:33:17,  2.69s/it] 21%|â–ˆâ–ˆ        | 1246/6000 [58:04<3:31:38,  2.67s/it]                                                     {'loss': 2.7409, 'grad_norm': 1.8390520811080933, 'learning_rate': 4.028813559322034e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1246/6000 [58:04<3:31:38,  2.67s/it] 21%|â–ˆâ–ˆ        | 1247/6000 [58:07<3:32:05,  2.68s/it]                                                     {'loss': 2.8554, 'grad_norm': 2.3127377033233643, 'learning_rate': 4.0279661016949156e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1247/6000 [58:07<3:32:05,  2.68s/it] 21%|â–ˆâ–ˆ        | 1248/6000 [58:10<3:33:07,  2.69s/it]                                                     {'loss': 2.6984, 'grad_norm': 2.111159563064575, 'learning_rate': 4.027118644067797e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1248/6000 [58:10<3:33:07,  2.69s/it] 21%|â–ˆâ–ˆ        | 1249/6000 [58:12<3:33:10,  2.69s/it]                                                     {'loss': 2.7922, 'grad_norm': 3.01653790473938, 'learning_rate': 4.0262711864406786e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1249/6000 [58:12<3:33:10,  2.69s/it] 21%|â–ˆâ–ˆ        | 1250/6000 [58:15<3:32:23,  2.68s/it]                                                     {'loss': 2.7918, 'grad_norm': 2.5921530723571777, 'learning_rate': 4.025423728813559e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1250/6000 [58:15<3:32:23,  2.68s/it][2025-10-21 00:04:06,140] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1250
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 21%|â–ˆâ–ˆ        | 1251/6000 [58:20<4:20:10,  3.29s/it]                                                     {'loss': 2.7801, 'grad_norm': 2.474534034729004, 'learning_rate': 4.024576271186441e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1251/6000 [58:20<4:20:10,  3.29s/it] 21%|â–ˆâ–ˆ        | 1252/6000 [58:22<4:04:55,  3.09s/it]                                                     {'loss': 2.8213, 'grad_norm': 3.791982650756836, 'learning_rate': 4.023728813559322e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1252/6000 [58:22<4:04:55,  3.09s/it] 21%|â–ˆâ–ˆ        | 1253/6000 [58:25<4:06:42,  3.12s/it]                                                     {'loss': 2.8673, 'grad_norm': 3.0703718662261963, 'learning_rate': 4.022881355932204e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1253/6000 [58:25<4:06:42,  3.12s/it] 21%|â–ˆâ–ˆ        | 1254/6000 [58:28<3:54:07,  2.96s/it]                                                     {'loss': 2.7345, 'grad_norm': 2.041415214538574, 'learning_rate': 4.022033898305085e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1254/6000 [58:28<3:54:07,  2.96s/it] 21%|â–ˆâ–ˆ        | 1255/6000 [58:31<3:47:40,  2.88s/it]                                                     {'loss': 2.6914, 'grad_norm': 1.8993395566940308, 'learning_rate': 4.021186440677967e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1255/6000 [58:31<3:47:40,  2.88s/it] 21%|â–ˆâ–ˆ        | 1256/6000 [58:33<3:45:20,  2.85s/it]                                                     {'loss': 2.8365, 'grad_norm': 2.7303497791290283, 'learning_rate': 4.020338983050848e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1256/6000 [58:33<3:45:20,  2.85s/it] 21%|â–ˆâ–ˆ        | 1257/6000 [58:36<3:40:06,  2.78s/it]                                                     {'loss': 2.8215, 'grad_norm': 1.654237985610962, 'learning_rate': 4.019491525423729e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1257/6000 [58:36<3:40:06,  2.78s/it] 21%|â–ˆâ–ˆ        | 1258/6000 [58:39<3:41:12,  2.80s/it]                                                     {'loss': 2.8755, 'grad_norm': 2.2410032749176025, 'learning_rate': 4.01864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1258/6000 [58:39<3:41:12,  2.80s/it] 21%|â–ˆâ–ˆ        | 1259/6000 [58:42<3:38:21,  2.76s/it]                                                     {'loss': 2.8153, 'grad_norm': 1.5386404991149902, 'learning_rate': 4.017796610169492e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1259/6000 [58:42<3:38:21,  2.76s/it] 21%|â–ˆâ–ˆ        | 1260/6000 [58:44<3:35:41,  2.73s/it]                                                     {'loss': 2.7567, 'grad_norm': 1.1680301427841187, 'learning_rate': 4.016949152542373e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1260/6000 [58:44<3:35:41,  2.73s/it] 21%|â–ˆâ–ˆ        | 1261/6000 [58:47<3:34:22,  2.71s/it]                                                     {'loss': 2.6741, 'grad_norm': 3.4450912475585938, 'learning_rate': 4.016101694915255e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1261/6000 [58:47<3:34:22,  2.71s/it] 21%|â–ˆâ–ˆ        | 1262/6000 [58:50<3:42:30,  2.82s/it]                                                     {'loss': 2.7752, 'grad_norm': 1.364928126335144, 'learning_rate': 4.015254237288136e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1262/6000 [58:50<3:42:30,  2.82s/it] 21%|â–ˆâ–ˆ        | 1263/6000 [58:53<3:41:34,  2.81s/it]                                                     {'loss': 2.8141, 'grad_norm': 1.3486348390579224, 'learning_rate': 4.014406779661017e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1263/6000 [58:53<3:41:34,  2.81s/it] 21%|â–ˆâ–ˆ        | 1264/6000 [58:55<3:38:23,  2.77s/it]                                                     {'loss': 2.7772, 'grad_norm': 0.9693689942359924, 'learning_rate': 4.013559322033898e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1264/6000 [58:55<3:38:23,  2.77s/it] 21%|â–ˆâ–ˆ        | 1265/6000 [58:58<3:36:25,  2.74s/it]                                                     {'loss': 2.7736, 'grad_norm': 1.1850553750991821, 'learning_rate': 4.012711864406779e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1265/6000 [58:58<3:36:25,  2.74s/it] 21%|â–ˆâ–ˆ        | 1266/6000 [59:01<3:39:13,  2.78s/it]                                                     {'loss': 2.7273, 'grad_norm': 1.25421941280365, 'learning_rate': 4.011864406779661e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1266/6000 [59:01<3:39:13,  2.78s/it] 21%|â–ˆâ–ˆ        | 1267/6000 [59:04<3:43:44,  2.84s/it]                                                     {'loss': 2.7807, 'grad_norm': 1.3142883777618408, 'learning_rate': 4.011016949152542e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1267/6000 [59:04<3:43:44,  2.84s/it] 21%|â–ˆâ–ˆ        | 1268/6000 [59:07<3:39:08,  2.78s/it]                                                     {'loss': 2.7404, 'grad_norm': 1.7287050485610962, 'learning_rate': 4.010169491525424e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1268/6000 [59:07<3:39:08,  2.78s/it] 21%|â–ˆâ–ˆ        | 1269/6000 [59:09<3:36:41,  2.75s/it]                                                     {'loss': 2.7981, 'grad_norm': 1.745659589767456, 'learning_rate': 4.009322033898305e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1269/6000 [59:09<3:36:41,  2.75s/it] 21%|â–ˆâ–ˆ        | 1270/6000 [59:12<3:33:51,  2.71s/it]                                                     {'loss': 2.8385, 'grad_norm': 1.8000977039337158, 'learning_rate': 4.008474576271187e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1270/6000 [59:12<3:33:51,  2.71s/it] 21%|â–ˆâ–ˆ        | 1271/6000 [59:15<3:35:21,  2.73s/it]                                                     {'loss': 2.7179, 'grad_norm': 1.2828216552734375, 'learning_rate': 4.007627118644068e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1271/6000 [59:15<3:35:21,  2.73s/it] 21%|â–ˆâ–ˆ        | 1272/6000 [59:18<3:42:06,  2.82s/it]                                                     {'loss': 2.759, 'grad_norm': 1.608201026916504, 'learning_rate': 4.006779661016949e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1272/6000 [59:18<3:42:06,  2.82s/it] 21%|â–ˆâ–ˆ        | 1273/6000 [59:20<3:38:25,  2.77s/it]                                                     {'loss': 2.7385, 'grad_norm': 1.4584048986434937, 'learning_rate': 4.0059322033898304e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1273/6000 [59:20<3:38:25,  2.77s/it] 21%|â–ˆâ–ˆ        | 1274/6000 [59:23<3:35:22,  2.73s/it]                                                     {'loss': 2.8184, 'grad_norm': 1.3284797668457031, 'learning_rate': 4.005084745762712e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 1274/6000 [59:23<3:35:22,  2.73s/it] 21%|â–ˆâ–ˆâ–       | 1275/6000 [59:26<3:34:42,  2.73s/it]                                                     {'loss': 2.679, 'grad_norm': 1.9947153329849243, 'learning_rate': 4.004237288135593e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1275/6000 [59:26<3:34:42,  2.73s/it] 21%|â–ˆâ–ˆâ–       | 1276/6000 [59:29<3:36:32,  2.75s/it]                                                     {'loss': 2.7516, 'grad_norm': 1.4112290143966675, 'learning_rate': 4.003389830508475e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1276/6000 [59:29<3:36:32,  2.75s/it] 21%|â–ˆâ–ˆâ–       | 1277/6000 [59:31<3:34:17,  2.72s/it]                                                     {'loss': 2.8049, 'grad_norm': 1.6422414779663086, 'learning_rate': 4.002542372881356e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1277/6000 [59:31<3:34:17,  2.72s/it] 21%|â–ˆâ–ˆâ–       | 1278/6000 [59:34<3:33:30,  2.71s/it]                                                     {'loss': 2.7905, 'grad_norm': 1.953674077987671, 'learning_rate': 4.0016949152542374e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1278/6000 [59:34<3:33:30,  2.71s/it] 21%|â–ˆâ–ˆâ–       | 1279/6000 [59:37<3:31:31,  2.69s/it]                                                     {'loss': 2.7487, 'grad_norm': 1.505274772644043, 'learning_rate': 4.0008474576271185e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1279/6000 [59:37<3:31:31,  2.69s/it] 21%|â–ˆâ–ˆâ–       | 1280/6000 [59:39<3:31:54,  2.69s/it]                                                     {'loss': 2.7855, 'grad_norm': 2.1674768924713135, 'learning_rate': 4e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1280/6000 [59:39<3:31:54,  2.69s/it] 21%|â–ˆâ–ˆâ–       | 1281/6000 [59:42<3:33:27,  2.71s/it]                                                     {'loss': 2.6464, 'grad_norm': 2.1469767093658447, 'learning_rate': 3.9991525423728815e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1281/6000 [59:42<3:33:27,  2.71s/it] 21%|â–ˆâ–ˆâ–       | 1282/6000 [59:45<3:31:48,  2.69s/it]                                                     {'loss': 2.893, 'grad_norm': 3.4901981353759766, 'learning_rate': 3.998305084745763e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1282/6000 [59:45<3:31:48,  2.69s/it] 21%|â–ˆâ–ˆâ–       | 1283/6000 [59:47<3:30:18,  2.68s/it]                                                     {'loss': 2.7649, 'grad_norm': 2.0844337940216064, 'learning_rate': 3.9974576271186444e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1283/6000 [59:47<3:30:18,  2.68s/it] 21%|â–ˆâ–ˆâ–       | 1284/6000 [59:50<3:31:08,  2.69s/it]                                                     {'loss': 2.8082, 'grad_norm': 2.5421833992004395, 'learning_rate': 3.996610169491526e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1284/6000 [59:50<3:31:08,  2.69s/it] 21%|â–ˆâ–ˆâ–       | 1285/6000 [59:53<3:32:11,  2.70s/it]                                                     {'loss': 2.888, 'grad_norm': 3.299813985824585, 'learning_rate': 3.9957627118644066e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1285/6000 [59:53<3:32:11,  2.70s/it] 21%|â–ˆâ–ˆâ–       | 1286/6000 [59:55<3:32:55,  2.71s/it]                                                     {'loss': 2.6774, 'grad_norm': 1.9889918565750122, 'learning_rate': 3.994915254237288e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1286/6000 [59:55<3:32:55,  2.71s/it] 21%|â–ˆâ–ˆâ–       | 1287/6000 [59:58<3:35:20,  2.74s/it]                                                     {'loss': 2.7488, 'grad_norm': 1.3607252836227417, 'learning_rate': 3.9940677966101696e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1287/6000 [59:58<3:35:20,  2.74s/it] 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:00:01<3:36:12,  2.75s/it]                                                       {'loss': 2.8118, 'grad_norm': 1.4301631450653076, 'learning_rate': 3.993220338983051e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1288/6000 [1:00:01<3:36:12,  2.75s/it] 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:00:04<3:33:06,  2.71s/it]                                                       {'loss': 2.7913, 'grad_norm': 1.779965877532959, 'learning_rate': 3.9923728813559325e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 1289/6000 [1:00:04<3:33:06,  2.71s/it] 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:00:06<3:33:04,  2.71s/it]                                                       {'loss': 2.7292, 'grad_norm': 1.4529006481170654, 'learning_rate': 3.9915254237288136e-05, 'epoch': 0.21}
 22%|â–ˆâ–ˆâ–       | 1290/6000 [1:00:06<3:33:04,  2.71s/it] 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:00:09<3:31:26,  2.69s/it]                                                       {'loss': 2.8063, 'grad_norm': 1.5583020448684692, 'learning_rate': 3.9906779661016955e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1291/6000 [1:00:09<3:31:26,  2.69s/it] 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:00:12<3:30:13,  2.68s/it]                                                       {'loss': 2.7603, 'grad_norm': 1.771601915359497, 'learning_rate': 3.9898305084745766e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1292/6000 [1:00:12<3:30:13,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:00:14<3:32:06,  2.70s/it]                                                       {'loss': 2.7334, 'grad_norm': 1.3736793994903564, 'learning_rate': 3.988983050847458e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1293/6000 [1:00:14<3:32:06,  2.70s/it] 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:00:17<3:30:23,  2.68s/it]                                                       {'loss': 2.7557, 'grad_norm': 1.716552972793579, 'learning_rate': 3.988135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1294/6000 [1:00:17<3:30:23,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:00:20<3:28:54,  2.66s/it]                                                       {'loss': 2.7862, 'grad_norm': 1.3098530769348145, 'learning_rate': 3.9872881355932206e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1295/6000 [1:00:20<3:28:54,  2.66s/it] 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:00:22<3:29:18,  2.67s/it]                                                       {'loss': 2.8048, 'grad_norm': 1.6008174419403076, 'learning_rate': 3.986440677966102e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1296/6000 [1:00:22<3:29:18,  2.67s/it] 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:00:25<3:35:45,  2.75s/it]                                                       {'loss': 2.7228, 'grad_norm': 1.4542980194091797, 'learning_rate': 3.9855932203389836e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1297/6000 [1:00:25<3:35:45,  2.75s/it] 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:00:28<3:36:33,  2.76s/it]                                                       {'loss': 2.7538, 'grad_norm': 1.2893773317337036, 'learning_rate': 3.984745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1298/6000 [1:00:28<3:36:33,  2.76s/it] 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:00:31<3:35:29,  2.75s/it]                                                       {'loss': 2.7128, 'grad_norm': 1.9618691205978394, 'learning_rate': 3.983898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1299/6000 [1:00:31<3:35:29,  2.75s/it] 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:00:34<3:34:16,  2.74s/it]                                                       {'loss': 2.8007, 'grad_norm': 1.739971399307251, 'learning_rate': 3.983050847457627e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1300/6000 [1:00:34<3:34:16,  2.74s/it][2025-10-21 00:06:24,789] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1300
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:00:38<4:20:30,  3.33s/it]                                                       {'loss': 2.8362, 'grad_norm': 2.126239061355591, 'learning_rate': 3.982203389830509e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1301/6000 [1:00:38<4:20:30,  3.33s/it] 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:00:41<4:04:06,  3.12s/it]                                                       {'loss': 2.7291, 'grad_norm': 1.7076061964035034, 'learning_rate': 3.98135593220339e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1302/6000 [1:00:41<4:04:06,  3.12s/it] 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:00:43<3:52:40,  2.97s/it]                                                       {'loss': 2.8133, 'grad_norm': 1.959920883178711, 'learning_rate': 3.980508474576272e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1303/6000 [1:00:43<3:52:40,  2.97s/it] 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:00:46<3:45:49,  2.89s/it]                                                       {'loss': 2.7292, 'grad_norm': 2.0860660076141357, 'learning_rate': 3.979661016949153e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1304/6000 [1:00:46<3:45:49,  2.89s/it] 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:00:49<3:39:48,  2.81s/it]                                                       {'loss': 2.7751, 'grad_norm': 1.543852686882019, 'learning_rate': 3.978813559322034e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1305/6000 [1:00:49<3:39:48,  2.81s/it] 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:00:52<3:38:50,  2.80s/it]                                                       {'loss': 2.7802, 'grad_norm': 1.7822636365890503, 'learning_rate': 3.977966101694916e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1306/6000 [1:00:52<3:38:50,  2.80s/it] 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:00:54<3:35:07,  2.75s/it]                                                       {'loss': 2.8052, 'grad_norm': 2.1409595012664795, 'learning_rate': 3.977118644067796e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1307/6000 [1:00:54<3:35:07,  2.75s/it] 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:00:57<3:35:39,  2.76s/it]                                                       {'loss': 2.7422, 'grad_norm': 1.559759497642517, 'learning_rate': 3.976271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1308/6000 [1:00:57<3:35:39,  2.76s/it] 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:01:00<3:33:02,  2.72s/it]                                                       {'loss': 2.8084, 'grad_norm': 2.5134599208831787, 'learning_rate': 3.975423728813559e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1309/6000 [1:01:00<3:33:02,  2.72s/it] 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:01:03<3:37:28,  2.78s/it]                                                       {'loss': 2.6915, 'grad_norm': 2.608572483062744, 'learning_rate': 3.974576271186441e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1310/6000 [1:01:03<3:37:28,  2.78s/it] 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:01:05<3:33:39,  2.73s/it]                                                       {'loss': 2.8024, 'grad_norm': 1.3225375413894653, 'learning_rate': 3.973728813559322e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1311/6000 [1:01:05<3:33:39,  2.73s/it] 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:01:08<3:31:08,  2.70s/it]                                                       {'loss': 2.8209, 'grad_norm': 2.0768842697143555, 'learning_rate': 3.972881355932204e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1312/6000 [1:01:08<3:31:08,  2.70s/it] 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:01:10<3:30:22,  2.69s/it]                                                       {'loss': 2.823, 'grad_norm': 1.4051167964935303, 'learning_rate': 3.972033898305085e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1313/6000 [1:01:10<3:30:22,  2.69s/it] 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:01:13<3:29:29,  2.68s/it]                                                       {'loss': 2.7812, 'grad_norm': 1.087529182434082, 'learning_rate': 3.971186440677966e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1314/6000 [1:01:13<3:29:29,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:01:16<3:29:10,  2.68s/it]                                                       {'loss': 2.7698, 'grad_norm': 1.0179269313812256, 'learning_rate': 3.970338983050847e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1315/6000 [1:01:16<3:29:10,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:01:19<3:31:37,  2.71s/it]                                                       {'loss': 2.8229, 'grad_norm': 1.722771167755127, 'learning_rate': 3.969491525423729e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1316/6000 [1:01:19<3:31:37,  2.71s/it] 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:01:21<3:30:10,  2.69s/it]                                                       {'loss': 2.7324, 'grad_norm': 1.9958337545394897, 'learning_rate': 3.96864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1317/6000 [1:01:21<3:30:10,  2.69s/it] 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:01:24<3:28:55,  2.68s/it]                                                       {'loss': 2.7644, 'grad_norm': 1.0032278299331665, 'learning_rate': 3.967796610169492e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1318/6000 [1:01:24<3:28:55,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:01:27<3:28:50,  2.68s/it]                                                       {'loss': 2.7738, 'grad_norm': 0.8986557126045227, 'learning_rate': 3.966949152542373e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1319/6000 [1:01:27<3:28:50,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:01:29<3:29:07,  2.68s/it]                                                       {'loss': 2.7537, 'grad_norm': 1.1849111318588257, 'learning_rate': 3.966101694915255e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1320/6000 [1:01:29<3:29:07,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:01:32<3:29:16,  2.68s/it]                                                       {'loss': 2.762, 'grad_norm': 1.2493605613708496, 'learning_rate': 3.9652542372881354e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1321/6000 [1:01:32<3:29:16,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:01:35<3:39:35,  2.82s/it]                                                       {'loss': 2.7647, 'grad_norm': 1.0675489902496338, 'learning_rate': 3.964406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1322/6000 [1:01:35<3:39:35,  2.82s/it] 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:01:38<3:37:36,  2.79s/it]                                                       {'loss': 2.7845, 'grad_norm': 1.1311925649642944, 'learning_rate': 3.9635593220338983e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1323/6000 [1:01:38<3:37:36,  2.79s/it] 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:01:40<3:33:58,  2.75s/it]                                                       {'loss': 2.85, 'grad_norm': 0.9326841235160828, 'learning_rate': 3.96271186440678e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1324/6000 [1:01:40<3:33:58,  2.75s/it] 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:01:43<3:33:40,  2.74s/it]                                                       {'loss': 2.7795, 'grad_norm': 1.2421082258224487, 'learning_rate': 3.961864406779661e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1325/6000 [1:01:43<3:33:40,  2.74s/it] 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:01:46<3:31:10,  2.71s/it]                                                       {'loss': 2.7651, 'grad_norm': 1.4415920972824097, 'learning_rate': 3.9610169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1326/6000 [1:01:46<3:31:10,  2.71s/it] 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:01:48<3:30:29,  2.70s/it]                                                       {'loss': 2.7494, 'grad_norm': 1.634497046470642, 'learning_rate': 3.960169491525424e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1327/6000 [1:01:48<3:30:29,  2.70s/it] 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:01:51<3:30:05,  2.70s/it]                                                       {'loss': 2.84, 'grad_norm': 1.9647796154022217, 'learning_rate': 3.9593220338983053e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1328/6000 [1:01:51<3:30:05,  2.70s/it] 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:01:54<3:37:15,  2.79s/it]                                                       {'loss': 2.8528, 'grad_norm': 3.979102373123169, 'learning_rate': 3.9584745762711865e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1329/6000 [1:01:54<3:37:15,  2.79s/it] 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:01:57<3:33:56,  2.75s/it]                                                       {'loss': 2.8528, 'grad_norm': 3.5852911472320557, 'learning_rate': 3.9576271186440676e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1330/6000 [1:01:57<3:33:56,  2.75s/it] 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:02:00<3:33:22,  2.74s/it]                                                       {'loss': 2.8198, 'grad_norm': 2.9547877311706543, 'learning_rate': 3.9567796610169494e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1331/6000 [1:02:00<3:33:22,  2.74s/it] 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:02:02<3:30:28,  2.71s/it]                                                       {'loss': 2.767, 'grad_norm': 2.348407030105591, 'learning_rate': 3.9559322033898305e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1332/6000 [1:02:02<3:30:28,  2.71s/it] 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:02:05<3:31:38,  2.72s/it]                                                       {'loss': 2.7706, 'grad_norm': 1.8458547592163086, 'learning_rate': 3.9550847457627123e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1333/6000 [1:02:05<3:31:38,  2.72s/it] 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:02:08<3:30:04,  2.70s/it]                                                       {'loss': 2.7654, 'grad_norm': 2.3976292610168457, 'learning_rate': 3.9542372881355935e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1334/6000 [1:02:08<3:30:04,  2.70s/it] 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:02:10<3:28:39,  2.68s/it]                                                       {'loss': 2.7864, 'grad_norm': 1.8226953744888306, 'learning_rate': 3.9533898305084746e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1335/6000 [1:02:10<3:28:39,  2.68s/it] 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:02:13<3:27:43,  2.67s/it]                                                       {'loss': 2.7477, 'grad_norm': 1.5745823383331299, 'learning_rate': 3.952542372881356e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1336/6000 [1:02:13<3:27:43,  2.67s/it] 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:02:15<3:26:12,  2.65s/it]                                                       {'loss': 2.7748, 'grad_norm': 1.4163342714309692, 'learning_rate': 3.9516949152542375e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1337/6000 [1:02:15<3:26:12,  2.65s/it] 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:02:18<3:25:54,  2.65s/it]                                                       {'loss': 2.8059, 'grad_norm': 1.733678936958313, 'learning_rate': 3.9508474576271187e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1338/6000 [1:02:18<3:25:54,  2.65s/it] 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:02:21<3:26:16,  2.66s/it]                                                       {'loss': 2.7991, 'grad_norm': 1.179646611213684, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1339/6000 [1:02:21<3:26:16,  2.66s/it] 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:02:23<3:25:59,  2.65s/it]                                                       {'loss': 2.7655, 'grad_norm': 1.113317608833313, 'learning_rate': 3.9491525423728816e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1340/6000 [1:02:23<3:25:59,  2.65s/it] 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:02:26<3:26:22,  2.66s/it]                                                       {'loss': 2.7771, 'grad_norm': 1.1938239336013794, 'learning_rate': 3.9483050847457634e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1341/6000 [1:02:26<3:26:22,  2.66s/it] 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:02:29<3:35:01,  2.77s/it]                                                       {'loss': 2.8486, 'grad_norm': 0.9867194294929504, 'learning_rate': 3.9474576271186445e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1342/6000 [1:02:29<3:35:01,  2.77s/it] 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:02:32<3:41:01,  2.85s/it]                                                       {'loss': 2.7481, 'grad_norm': 0.989640474319458, 'learning_rate': 3.9466101694915257e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1343/6000 [1:02:32<3:41:01,  2.85s/it] 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:02:35<3:36:45,  2.79s/it]                                                       {'loss': 2.8138, 'grad_norm': 1.0590951442718506, 'learning_rate': 3.945762711864407e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1344/6000 [1:02:35<3:36:45,  2.79s/it] 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:02:38<3:40:48,  2.85s/it]                                                       {'loss': 2.7611, 'grad_norm': 1.1580119132995605, 'learning_rate': 3.9449152542372886e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1345/6000 [1:02:38<3:40:48,  2.85s/it] 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:02:40<3:36:27,  2.79s/it]                                                       {'loss': 2.7957, 'grad_norm': 1.1609047651290894, 'learning_rate': 3.94406779661017e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1346/6000 [1:02:40<3:36:27,  2.79s/it] 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:02:43<3:35:08,  2.77s/it]                                                       {'loss': 2.7636, 'grad_norm': 1.1958874464035034, 'learning_rate': 3.943220338983051e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1347/6000 [1:02:43<3:35:08,  2.77s/it] 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:02:46<3:31:59,  2.73s/it]                                                       {'loss': 2.789, 'grad_norm': 1.1715494394302368, 'learning_rate': 3.9423728813559327e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1348/6000 [1:02:46<3:31:59,  2.73s/it] 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:02:49<3:39:18,  2.83s/it]                                                       {'loss': 2.7481, 'grad_norm': 1.3238329887390137, 'learning_rate': 3.941525423728814e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 1349/6000 [1:02:49<3:39:18,  2.83s/it] 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:02:52<3:45:43,  2.91s/it]                                                       {'loss': 2.8087, 'grad_norm': 0.9378068447113037, 'learning_rate': 3.940677966101695e-05, 'epoch': 0.23}
 22%|â–ˆâ–ˆâ–Ž       | 1350/6000 [1:02:52<3:45:43,  2.91s/it][2025-10-21 00:08:43,269] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1350
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:02:57<4:26:19,  3.44s/it]                                                       {'loss': 2.7614, 'grad_norm': 0.9708905816078186, 'learning_rate': 3.939830508474576e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1351/6000 [1:02:57<4:26:19,  3.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:02:59<4:09:04,  3.22s/it]                                                       {'loss': 2.7499, 'grad_norm': 0.9353471398353577, 'learning_rate': 3.938983050847458e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1352/6000 [1:02:59<4:09:04,  3.22s/it] 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:03:02<4:00:21,  3.10s/it]                                                       {'loss': 2.7439, 'grad_norm': 1.1968672275543213, 'learning_rate': 3.938135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1353/6000 [1:03:02<4:00:21,  3.10s/it] 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:03:05<3:50:37,  2.98s/it]                                                       {'loss': 2.8116, 'grad_norm': 0.987437903881073, 'learning_rate': 3.937288135593221e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1354/6000 [1:03:05<3:50:37,  2.98s/it] 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:03:08<3:45:44,  2.92s/it]                                                       {'loss': 2.7293, 'grad_norm': 1.3193635940551758, 'learning_rate': 3.936440677966102e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1355/6000 [1:03:08<3:45:44,  2.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:03:11<3:53:17,  3.01s/it]                                                       {'loss': 2.7385, 'grad_norm': 1.2354985475540161, 'learning_rate': 3.935593220338983e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1356/6000 [1:03:11<3:53:17,  3.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:03:14<3:49:47,  2.97s/it]                                                       {'loss': 2.7708, 'grad_norm': 1.4782999753952026, 'learning_rate': 3.934745762711864e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1357/6000 [1:03:14<3:49:47,  2.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:03:16<3:43:00,  2.88s/it]                                                       {'loss': 2.8277, 'grad_norm': 1.1981135606765747, 'learning_rate': 3.933898305084746e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1358/6000 [1:03:16<3:43:00,  2.88s/it] 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:03:19<3:46:04,  2.92s/it]                                                       {'loss': 2.7352, 'grad_norm': 1.4125570058822632, 'learning_rate': 3.933050847457627e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1359/6000 [1:03:19<3:46:04,  2.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:03:22<3:39:56,  2.84s/it]                                                       {'loss': 2.7563, 'grad_norm': 1.4899951219558716, 'learning_rate': 3.932203389830509e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1360/6000 [1:03:22<3:39:56,  2.84s/it] 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:03:25<3:34:26,  2.77s/it]                                                       {'loss': 2.829, 'grad_norm': 1.9106359481811523, 'learning_rate': 3.93135593220339e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1361/6000 [1:03:25<3:34:26,  2.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:03:28<3:36:29,  2.80s/it]                                                       {'loss': 2.7922, 'grad_norm': 1.6995824575424194, 'learning_rate': 3.930508474576272e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1362/6000 [1:03:28<3:36:29,  2.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:03:30<3:34:50,  2.78s/it]                                                       {'loss': 2.8111, 'grad_norm': 1.7998650074005127, 'learning_rate': 3.929661016949153e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1363/6000 [1:03:30<3:34:50,  2.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:03:33<3:31:44,  2.74s/it]                                                       {'loss': 2.7942, 'grad_norm': 1.525148630142212, 'learning_rate': 3.928813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1364/6000 [1:03:33<3:31:44,  2.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:03:36<3:39:00,  2.84s/it]                                                       {'loss': 2.7143, 'grad_norm': 1.7425694465637207, 'learning_rate': 3.927966101694915e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1365/6000 [1:03:36<3:39:00,  2.84s/it] 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:03:39<3:46:05,  2.93s/it]                                                       {'loss': 2.83, 'grad_norm': 2.2618141174316406, 'learning_rate': 3.927118644067797e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1366/6000 [1:03:39<3:46:05,  2.93s/it] 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:03:42<3:50:30,  2.99s/it]                                                       {'loss': 2.7625, 'grad_norm': 1.4263299703598022, 'learning_rate': 3.926271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1367/6000 [1:03:42<3:50:30,  2.99s/it] 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:03:45<3:43:14,  2.89s/it]                                                       {'loss': 2.7075, 'grad_norm': 1.8205101490020752, 'learning_rate': 3.925423728813559e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1368/6000 [1:03:45<3:43:14,  2.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:03:48<3:37:34,  2.82s/it]                                                       {'loss': 2.7362, 'grad_norm': 1.6492046117782593, 'learning_rate': 3.924576271186441e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1369/6000 [1:03:48<3:37:34,  2.82s/it] 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:03:51<3:54:12,  3.04s/it]                                                       {'loss': 2.7552, 'grad_norm': 1.8052778244018555, 'learning_rate': 3.923728813559322e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1370/6000 [1:03:51<3:54:12,  3.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:03:54<3:49:43,  2.98s/it]                                                       {'loss': 2.7459, 'grad_norm': 1.7482081651687622, 'learning_rate': 3.9228813559322034e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1371/6000 [1:03:54<3:49:43,  2.98s/it] 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:03:57<3:42:55,  2.89s/it]                                                       {'loss': 2.767, 'grad_norm': 2.1840662956237793, 'learning_rate': 3.9220338983050845e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1372/6000 [1:03:57<3:42:55,  2.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:03:59<3:40:14,  2.86s/it]                                                       {'loss': 2.76, 'grad_norm': 2.0261566638946533, 'learning_rate': 3.921186440677966e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1373/6000 [1:03:59<3:40:14,  2.86s/it] 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:04:02<3:39:31,  2.85s/it]                                                       {'loss': 2.7443, 'grad_norm': 2.0852179527282715, 'learning_rate': 3.9203389830508474e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1374/6000 [1:04:02<3:39:31,  2.85s/it] 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:04:05<3:34:36,  2.78s/it]                                                       {'loss': 2.7623, 'grad_norm': 1.8581587076187134, 'learning_rate': 3.919491525423729e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1375/6000 [1:04:05<3:34:36,  2.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:04:08<3:35:57,  2.80s/it]                                                       {'loss': 2.7767, 'grad_norm': 2.589724063873291, 'learning_rate': 3.9186440677966104e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1376/6000 [1:04:08<3:35:57,  2.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:04:10<3:31:44,  2.75s/it]                                                       {'loss': 2.8845, 'grad_norm': 3.4632339477539062, 'learning_rate': 3.917796610169492e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1377/6000 [1:04:10<3:31:44,  2.75s/it] 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:04:13<3:28:14,  2.70s/it]                                                       {'loss': 2.7656, 'grad_norm': 1.5002681016921997, 'learning_rate': 3.9169491525423726e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1378/6000 [1:04:13<3:28:14,  2.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:04:16<3:28:16,  2.70s/it]                                                       {'loss': 2.7296, 'grad_norm': 1.731399416923523, 'learning_rate': 3.9161016949152544e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1379/6000 [1:04:16<3:28:16,  2.70s/it] 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:04:18<3:26:52,  2.69s/it]                                                       {'loss': 2.7664, 'grad_norm': 1.9032700061798096, 'learning_rate': 3.9152542372881355e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1380/6000 [1:04:18<3:26:52,  2.69s/it] 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:04:21<3:35:23,  2.80s/it]                                                       {'loss': 2.8176, 'grad_norm': 2.2383508682250977, 'learning_rate': 3.9144067796610174e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1381/6000 [1:04:21<3:35:23,  2.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:04:24<3:33:38,  2.78s/it]                                                       {'loss': 2.7414, 'grad_norm': 1.653206706047058, 'learning_rate': 3.9135593220338985e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1382/6000 [1:04:24<3:33:38,  2.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:04:27<3:35:05,  2.80s/it]                                                       {'loss': 2.752, 'grad_norm': 1.3423789739608765, 'learning_rate': 3.91271186440678e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1383/6000 [1:04:27<3:35:05,  2.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:04:30<3:39:08,  2.85s/it]                                                       {'loss': 2.7664, 'grad_norm': 1.5628793239593506, 'learning_rate': 3.9118644067796614e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1384/6000 [1:04:30<3:39:08,  2.85s/it] 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:04:33<3:34:52,  2.79s/it]                                                       {'loss': 2.7527, 'grad_norm': 1.1849730014801025, 'learning_rate': 3.9110169491525425e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1385/6000 [1:04:33<3:34:52,  2.79s/it] 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:04:35<3:33:16,  2.77s/it]                                                       {'loss': 2.7437, 'grad_norm': 1.3741610050201416, 'learning_rate': 3.910169491525424e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1386/6000 [1:04:35<3:33:16,  2.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:04:38<3:30:31,  2.74s/it]                                                       {'loss': 2.7756, 'grad_norm': 1.4218127727508545, 'learning_rate': 3.9093220338983055e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1387/6000 [1:04:38<3:30:31,  2.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:04:41<3:31:01,  2.75s/it]                                                       {'loss': 2.7861, 'grad_norm': 1.100831389427185, 'learning_rate': 3.9084745762711866e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1388/6000 [1:04:41<3:31:01,  2.75s/it] 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:04:44<3:44:40,  2.92s/it]                                                       {'loss': 2.7945, 'grad_norm': 1.2341119050979614, 'learning_rate': 3.907627118644068e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1389/6000 [1:04:44<3:44:40,  2.92s/it] 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:04:47<3:39:30,  2.86s/it]                                                       {'loss': 2.7147, 'grad_norm': 1.3577576875686646, 'learning_rate': 3.9067796610169495e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1390/6000 [1:04:47<3:39:30,  2.86s/it] 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:04:49<3:35:08,  2.80s/it]                                                       {'loss': 2.7454, 'grad_norm': 1.2540515661239624, 'learning_rate': 3.905932203389831e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1391/6000 [1:04:49<3:35:08,  2.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:04:52<3:37:16,  2.83s/it]                                                       {'loss': 2.77, 'grad_norm': 1.1871297359466553, 'learning_rate': 3.905084745762712e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1392/6000 [1:04:52<3:37:16,  2.83s/it] 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:04:55<3:35:19,  2.80s/it]                                                       {'loss': 2.736, 'grad_norm': 1.496198058128357, 'learning_rate': 3.904237288135593e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1393/6000 [1:04:55<3:35:19,  2.80s/it] 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:04:58<3:31:26,  2.75s/it]                                                       {'loss': 2.7852, 'grad_norm': 1.5328196287155151, 'learning_rate': 3.903389830508475e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1394/6000 [1:04:58<3:31:26,  2.75s/it] 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:05:00<3:29:56,  2.74s/it]                                                       {'loss': 2.8167, 'grad_norm': 2.061629056930542, 'learning_rate': 3.902542372881356e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1395/6000 [1:05:00<3:29:56,  2.74s/it] 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:05:03<3:28:04,  2.71s/it]                                                       {'loss': 2.7484, 'grad_norm': 1.5940055847167969, 'learning_rate': 3.901694915254238e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1396/6000 [1:05:03<3:28:04,  2.71s/it] 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:05:06<3:26:29,  2.69s/it]                                                       {'loss': 2.8159, 'grad_norm': 1.317814588546753, 'learning_rate': 3.900847457627119e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1397/6000 [1:05:06<3:26:29,  2.69s/it] 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:05:08<3:25:37,  2.68s/it]                                                       {'loss': 2.7477, 'grad_norm': 1.7508827447891235, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1398/6000 [1:05:08<3:25:37,  2.68s/it] 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:05:11<3:24:21,  2.66s/it]                                                       {'loss': 2.7384, 'grad_norm': 1.3971190452575684, 'learning_rate': 3.899152542372882e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1399/6000 [1:05:11<3:24:21,  2.66s/it] 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:05:14<3:24:04,  2.66s/it]                                                       {'loss': 2.7776, 'grad_norm': 1.7320693731307983, 'learning_rate': 3.898305084745763e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1400/6000 [1:05:14<3:24:04,  2.66s/it][2025-10-21 00:11:04,938] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1400
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:05:18<4:10:11,  3.26s/it]                                                       {'loss': 2.7441, 'grad_norm': 1.2093427181243896, 'learning_rate': 3.897457627118644e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1401/6000 [1:05:18<4:10:11,  3.26s/it] 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:05:21<3:56:58,  3.09s/it]                                                       {'loss': 2.7869, 'grad_norm': 1.6888089179992676, 'learning_rate': 3.896610169491526e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1402/6000 [1:05:21<3:56:58,  3.09s/it] 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:05:24<3:47:39,  2.97s/it]                                                       {'loss': 2.7893, 'grad_norm': 1.7015591859817505, 'learning_rate': 3.895762711864407e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1403/6000 [1:05:24<3:47:39,  2.97s/it] 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:05:26<3:41:29,  2.89s/it]                                                       {'loss': 2.8054, 'grad_norm': 2.0025439262390137, 'learning_rate': 3.894915254237289e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1404/6000 [1:05:26<3:41:29,  2.89s/it] 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:05:29<3:36:44,  2.83s/it]                                                       {'loss': 2.7505, 'grad_norm': 1.1341099739074707, 'learning_rate': 3.89406779661017e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1405/6000 [1:05:29<3:36:44,  2.83s/it] 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:05:32<3:32:15,  2.77s/it]                                                       {'loss': 2.7436, 'grad_norm': 1.2654963731765747, 'learning_rate': 3.893220338983051e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1406/6000 [1:05:32<3:32:15,  2.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:05:35<3:38:20,  2.85s/it]                                                       {'loss': 2.7193, 'grad_norm': 1.4498753547668457, 'learning_rate': 3.892372881355932e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1407/6000 [1:05:35<3:38:20,  2.85s/it] 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:05:37<3:33:06,  2.78s/it]                                                       {'loss': 2.7312, 'grad_norm': 1.359750747680664, 'learning_rate': 3.891525423728814e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1408/6000 [1:05:37<3:33:06,  2.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:05:40<3:31:30,  2.76s/it]                                                       {'loss': 2.7754, 'grad_norm': 1.6342291831970215, 'learning_rate': 3.890677966101695e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1409/6000 [1:05:40<3:31:30,  2.76s/it] 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:05:43<3:38:50,  2.86s/it]                                                       {'loss': 2.8083, 'grad_norm': 1.4920340776443481, 'learning_rate': 3.889830508474576e-05, 'epoch': 0.23}
 24%|â–ˆâ–ˆâ–Ž       | 1410/6000 [1:05:43<3:38:50,  2.86s/it] 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:05:46<3:33:51,  2.80s/it]                                                       {'loss': 2.7337, 'grad_norm': 1.584124207496643, 'learning_rate': 3.888983050847458e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1411/6000 [1:05:46<3:33:51,  2.80s/it] 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:05:49<3:41:19,  2.89s/it]                                                       {'loss': 2.7654, 'grad_norm': 1.219207525253296, 'learning_rate': 3.888135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1412/6000 [1:05:49<3:41:19,  2.89s/it] 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:05:52<3:36:27,  2.83s/it]                                                       {'loss': 2.8476, 'grad_norm': 2.152031898498535, 'learning_rate': 3.88728813559322e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1413/6000 [1:05:52<3:36:27,  2.83s/it] 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:05:54<3:32:39,  2.78s/it]                                                       {'loss': 2.7119, 'grad_norm': 1.3783621788024902, 'learning_rate': 3.8864406779661014e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1414/6000 [1:05:54<3:32:39,  2.78s/it] 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:05:57<3:38:09,  2.85s/it]                                                       {'loss': 2.8363, 'grad_norm': 1.6403194665908813, 'learning_rate': 3.885593220338983e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1415/6000 [1:05:57<3:38:09,  2.85s/it] 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:06:00<3:34:01,  2.80s/it]                                                       {'loss': 2.7595, 'grad_norm': 0.9747061729431152, 'learning_rate': 3.884745762711864e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1416/6000 [1:06:00<3:34:01,  2.80s/it] 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:06:03<3:33:45,  2.80s/it]                                                       {'loss': 2.7726, 'grad_norm': 1.1499855518341064, 'learning_rate': 3.883898305084746e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1417/6000 [1:06:03<3:33:45,  2.80s/it] 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:06:06<3:31:35,  2.77s/it]                                                       {'loss': 2.7355, 'grad_norm': 1.4695005416870117, 'learning_rate': 3.883050847457627e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1418/6000 [1:06:06<3:31:35,  2.77s/it] 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:06:08<3:33:33,  2.80s/it]                                                       {'loss': 2.7517, 'grad_norm': 1.4357808828353882, 'learning_rate': 3.882203389830509e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1419/6000 [1:06:08<3:33:33,  2.80s/it] 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:06:11<3:30:49,  2.76s/it]                                                       {'loss': 2.7578, 'grad_norm': 1.2061692476272583, 'learning_rate': 3.88135593220339e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1420/6000 [1:06:11<3:30:49,  2.76s/it] 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:06:14<3:28:03,  2.73s/it]                                                       {'loss': 2.7104, 'grad_norm': 1.6905020475387573, 'learning_rate': 3.880508474576271e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1421/6000 [1:06:14<3:28:03,  2.73s/it] 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:06:16<3:25:44,  2.70s/it]                                                       {'loss': 2.7946, 'grad_norm': 1.3263529539108276, 'learning_rate': 3.8796610169491524e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1422/6000 [1:06:16<3:25:44,  2.70s/it] 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:06:19<3:24:10,  2.68s/it]                                                       {'loss': 2.7432, 'grad_norm': 1.3602478504180908, 'learning_rate': 3.878813559322034e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1423/6000 [1:06:19<3:24:10,  2.68s/it] 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:06:22<3:23:13,  2.66s/it]                                                       {'loss': 2.7252, 'grad_norm': 1.324952244758606, 'learning_rate': 3.8779661016949154e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1424/6000 [1:06:22<3:23:13,  2.66s/it] 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:06:24<3:26:21,  2.71s/it]                                                       {'loss': 2.7869, 'grad_norm': 1.4179335832595825, 'learning_rate': 3.877118644067797e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1425/6000 [1:06:24<3:26:21,  2.71s/it] 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:06:27<3:28:02,  2.73s/it]                                                       {'loss': 2.7523, 'grad_norm': 1.9428550004959106, 'learning_rate': 3.876271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1426/6000 [1:06:27<3:28:02,  2.73s/it] 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:06:30<3:26:53,  2.71s/it]                                                       {'loss': 2.6953, 'grad_norm': 1.9359769821166992, 'learning_rate': 3.8754237288135594e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1427/6000 [1:06:30<3:26:53,  2.71s/it] 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:06:33<3:25:52,  2.70s/it]                                                       {'loss': 2.6945, 'grad_norm': 1.7624025344848633, 'learning_rate': 3.8745762711864406e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1428/6000 [1:06:33<3:25:52,  2.70s/it] 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:06:35<3:25:22,  2.70s/it]                                                       {'loss': 2.6843, 'grad_norm': 2.2754313945770264, 'learning_rate': 3.8737288135593224e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1429/6000 [1:06:35<3:25:22,  2.70s/it] 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:06:38<3:24:18,  2.68s/it]                                                       {'loss': 2.8025, 'grad_norm': 2.5512073040008545, 'learning_rate': 3.8728813559322035e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1430/6000 [1:06:38<3:24:18,  2.68s/it] 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:06:41<3:23:40,  2.67s/it]                                                       {'loss': 2.7157, 'grad_norm': 5.54697847366333, 'learning_rate': 3.8720338983050846e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1431/6000 [1:06:41<3:23:40,  2.67s/it] 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:06:43<3:23:49,  2.68s/it]                                                       {'loss': 2.8509, 'grad_norm': 6.130456924438477, 'learning_rate': 3.8711864406779664e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1432/6000 [1:06:43<3:23:49,  2.68s/it] 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:06:46<3:34:16,  2.82s/it]                                                       {'loss': 2.8917, 'grad_norm': 4.263348579406738, 'learning_rate': 3.8703389830508476e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1433/6000 [1:06:46<3:34:16,  2.82s/it] 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:06:49<3:40:04,  2.89s/it]                                                       {'loss': 2.9467, 'grad_norm': 4.97767972946167, 'learning_rate': 3.8694915254237294e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1434/6000 [1:06:49<3:40:04,  2.89s/it] 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:06:52<3:34:50,  2.82s/it]                                                       {'loss': 2.7816, 'grad_norm': 3.321112871170044, 'learning_rate': 3.86864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1435/6000 [1:06:52<3:34:50,  2.82s/it] 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:06:55<3:33:56,  2.81s/it]                                                       {'loss': 2.7734, 'grad_norm': 5.45548152923584, 'learning_rate': 3.8677966101694916e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1436/6000 [1:06:55<3:33:56,  2.81s/it] 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:06:58<3:38:44,  2.88s/it]                                                       {'loss': 2.7903, 'grad_norm': 2.875999927520752, 'learning_rate': 3.866949152542373e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1437/6000 [1:06:58<3:38:44,  2.88s/it] 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:07:01<3:34:30,  2.82s/it]                                                       {'loss': 2.7254, 'grad_norm': 7.995619297027588, 'learning_rate': 3.8661016949152546e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1438/6000 [1:07:01<3:34:30,  2.82s/it] 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:07:03<3:31:15,  2.78s/it]                                                       {'loss': 2.8522, 'grad_norm': 5.029325008392334, 'learning_rate': 3.865254237288136e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1439/6000 [1:07:03<3:31:15,  2.78s/it] 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:07:06<3:29:32,  2.76s/it]                                                       {'loss': 2.806, 'grad_norm': 2.6031320095062256, 'learning_rate': 3.8644067796610175e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1440/6000 [1:07:06<3:29:32,  2.76s/it] 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:07:09<3:28:05,  2.74s/it]                                                       {'loss': 2.7949, 'grad_norm': 2.9955227375030518, 'learning_rate': 3.8635593220338986e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1441/6000 [1:07:09<3:28:05,  2.74s/it] 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:07:12<3:30:57,  2.78s/it]                                                       {'loss': 2.7774, 'grad_norm': 1.8856257200241089, 'learning_rate': 3.86271186440678e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1442/6000 [1:07:12<3:30:57,  2.78s/it] 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:07:14<3:29:16,  2.76s/it]                                                       {'loss': 2.7256, 'grad_norm': 1.7492432594299316, 'learning_rate': 3.861864406779661e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1443/6000 [1:07:14<3:29:16,  2.76s/it] 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:07:17<3:27:28,  2.73s/it]                                                       {'loss': 2.7281, 'grad_norm': 1.4548794031143188, 'learning_rate': 3.861016949152543e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1444/6000 [1:07:17<3:27:28,  2.73s/it] 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:07:20<3:25:48,  2.71s/it]                                                       {'loss': 2.7508, 'grad_norm': 1.48112952709198, 'learning_rate': 3.860169491525424e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1445/6000 [1:07:20<3:25:48,  2.71s/it] 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:07:22<3:24:30,  2.69s/it]                                                       {'loss': 2.7212, 'grad_norm': 1.994938850402832, 'learning_rate': 3.8593220338983056e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1446/6000 [1:07:22<3:24:30,  2.69s/it] 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:07:25<3:22:09,  2.66s/it]                                                       {'loss': 2.7319, 'grad_norm': 1.3140965700149536, 'learning_rate': 3.858474576271187e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1447/6000 [1:07:25<3:22:09,  2.66s/it] 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:07:27<3:21:24,  2.65s/it]                                                       {'loss': 2.7988, 'grad_norm': 1.470497488975525, 'learning_rate': 3.8576271186440686e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1448/6000 [1:07:27<3:21:24,  2.65s/it] 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:07:30<3:20:58,  2.65s/it]                                                       {'loss': 2.793, 'grad_norm': 1.7075592279434204, 'learning_rate': 3.856779661016949e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1449/6000 [1:07:30<3:20:58,  2.65s/it] 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:07:33<3:22:11,  2.67s/it]                                                       {'loss': 2.7734, 'grad_norm': 1.365938425064087, 'learning_rate': 3.855932203389831e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1450/6000 [1:07:33<3:22:11,  2.67s/it][2025-10-21 00:13:24,093] INFO [src.utils:19] Saving model to /home/infres/zzhu-24/PRIM/VLM2Vec/experiments/public/exps/train/TailTokenPF_1-Qwen/Qwen2-VL-2B-Instruct/checkpoint-1450
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:07:37<4:07:11,  3.26s/it]                                                       {'loss': 2.6895, 'grad_norm': 1.5396537780761719, 'learning_rate': 3.855084745762712e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1451/6000 [1:07:37<4:07:11,  3.26s/it] 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:07:40<3:52:57,  3.07s/it]                                                       {'loss': 2.7476, 'grad_norm': 1.6138508319854736, 'learning_rate': 3.854237288135593e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1452/6000 [1:07:40<3:52:57,  3.07s/it] 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:07:43<3:42:19,  2.93s/it]                                                       {'loss': 2.7248, 'grad_norm': 1.3380123376846313, 'learning_rate': 3.853389830508475e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1453/6000 [1:07:43<3:42:19,  2.93s/it]